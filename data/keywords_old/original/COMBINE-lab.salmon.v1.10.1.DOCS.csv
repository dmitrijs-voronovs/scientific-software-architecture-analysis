id,quality_attribute,keyword,matched_word,match_idx,sentence,source,filename,author,repo,version,wiki,url
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CODE_OF_CONDUCT.md:3213,Availability,avail,available,3213," for clarifying the standards of acceptable; behavior and are expected to take appropriate and fair corrective action in; response to any instances of unacceptable behavior. Project maintainers have the right and responsibility to remove, edit, or; reject comments, commits, code, wiki edits, issues, and other contributions; that are not aligned to this Code of Conduct, or to ban temporarily or; permanently any contributor for other behaviors that they deem inappropriate,; threatening, offensive, or harmful. ## Scope. This Code of Conduct applies both within project spaces and in public spaces; when an individual is representing the project or its community. Examples of; representing a project or community include using an official project e-mail; address, posting via an official social media account, or acting as an appointed; representative at an online or offline event. Representation of a project may be; further defined and clarified by project maintainers. ## Enforcement. Instances of abusive, harassing, or otherwise unacceptable behavior may be; reported by contacting the project team at salmon_maintainers@gmail.com. All; complaints will be reviewed and investigated and will result in a response that; is deemed necessary and appropriate to the circumstances. The project team is; obligated to maintain confidentiality with regard to the reporter of an incident.; Further details of specific enforcement policies may be posted separately. Project maintainers who do not follow or enforce the Code of Conduct in good; faith may face temporary or permanent repercussions as determined by other; members of the project's leadership. ## Attribution. This Code of Conduct is adapted from the [Contributor Covenant][homepage], version 1.4,; available at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html. [homepage]: https://www.contributor-covenant.org. For answers to common questions about this code of conduct, see; https://www.contributor-covenant.org/faq; ",MatchSource.DOCS,CODE_OF_CONDUCT.md,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CODE_OF_CONDUCT.md
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CODE_OF_CONDUCT.md:3148,Energy Efficiency,adapt,adapted,3148," for clarifying the standards of acceptable; behavior and are expected to take appropriate and fair corrective action in; response to any instances of unacceptable behavior. Project maintainers have the right and responsibility to remove, edit, or; reject comments, commits, code, wiki edits, issues, and other contributions; that are not aligned to this Code of Conduct, or to ban temporarily or; permanently any contributor for other behaviors that they deem inappropriate,; threatening, offensive, or harmful. ## Scope. This Code of Conduct applies both within project spaces and in public spaces; when an individual is representing the project or its community. Examples of; representing a project or community include using an official project e-mail; address, posting via an official social media account, or acting as an appointed; representative at an online or offline event. Representation of a project may be; further defined and clarified by project maintainers. ## Enforcement. Instances of abusive, harassing, or otherwise unacceptable behavior may be; reported by contacting the project team at salmon_maintainers@gmail.com. All; complaints will be reviewed and investigated and will result in a response that; is deemed necessary and appropriate to the circumstances. The project team is; obligated to maintain confidentiality with regard to the reporter of an incident.; Further details of specific enforcement policies may be posted separately. Project maintainers who do not follow or enforce the Code of Conduct in good; faith may face temporary or permanent repercussions as determined by other; members of the project's leadership. ## Attribution. This Code of Conduct is adapted from the [Contributor Covenant][homepage], version 1.4,; available at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html. [homepage]: https://www.contributor-covenant.org. For answers to common questions about this code of conduct, see; https://www.contributor-covenant.org/faq; ",MatchSource.DOCS,CODE_OF_CONDUCT.md,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CODE_OF_CONDUCT.md
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CODE_OF_CONDUCT.md:3148,Modifiability,adapt,adapted,3148," for clarifying the standards of acceptable; behavior and are expected to take appropriate and fair corrective action in; response to any instances of unacceptable behavior. Project maintainers have the right and responsibility to remove, edit, or; reject comments, commits, code, wiki edits, issues, and other contributions; that are not aligned to this Code of Conduct, or to ban temporarily or; permanently any contributor for other behaviors that they deem inappropriate,; threatening, offensive, or harmful. ## Scope. This Code of Conduct applies both within project spaces and in public spaces; when an individual is representing the project or its community. Examples of; representing a project or community include using an official project e-mail; address, posting via an official social media account, or acting as an appointed; representative at an online or offline event. Representation of a project may be; further defined and clarified by project maintainers. ## Enforcement. Instances of abusive, harassing, or otherwise unacceptable behavior may be; reported by contacting the project team at salmon_maintainers@gmail.com. All; complaints will be reviewed and investigated and will result in a response that; is deemed necessary and appropriate to the circumstances. The project team is; obligated to maintain confidentiality with regard to the reporter of an incident.; Further details of specific enforcement policies may be posted separately. Project maintainers who do not follow or enforce the Code of Conduct in good; faith may face temporary or permanent repercussions as determined by other; members of the project's leadership. ## Attribution. This Code of Conduct is adapted from the [Contributor Covenant][homepage], version 1.4,; available at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html. [homepage]: https://www.contributor-covenant.org. For answers to common questions about this code of conduct, see; https://www.contributor-covenant.org/faq; ",MatchSource.DOCS,CODE_OF_CONDUCT.md,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CODE_OF_CONDUCT.md
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CODE_OF_CONDUCT.md:991,Security,attack,attacks,991,"ledge to making participation in our project and; our community a harassment-free experience for everyone, regardless of age, body; size, disability, ethnicity, sex characteristics, gender identity and expression,; level of experience, education, socio-economic status, nationality, personal; appearance, race, religion, or sexual identity and orientation. ## Our Standards. Examples of behavior that contributes to creating a positive environment; include:. * Focusing on what is best for the community; * Showing empathy towards other community members; * Being respectful of differing viewpoints and experiences; * Using welcoming and inclusive language; * Gracefully accepting constructive criticism. Examples of unacceptable behavior by participants include:. * Trolling, insulting/derogatory comments, and personal or political attacks; * Public or private harassment; * Publishing others' private information, such as a physical or electronic; address (or real name if they are choosing to use a pseudonym), without explicit permission (doxing); * The use of sexualized language or imagery and unwelcome sexual attention or; advances; * Other conduct which could reasonably be considered inappropriate in a; professional setting. ## Our Responsibilities. Project maintainers are responsible for clarifying the standards of acceptable; behavior and are expected to take appropriate and fair corrective action in; response to any instances of unacceptable behavior. Project maintainers have the right and responsibility to remove, edit, or; reject comments, commits, code, wiki edits, issues, and other contributions; that are not aligned to this Code of Conduct, or to ban temporarily or; permanently any contributor for other behaviors that they deem inappropriate,; threatening, offensive, or harmful. ## Scope. This Code of Conduct applies both within project spaces and in public spaces; when an individual is representing the project or its community. Examples of; representing a project o",MatchSource.DOCS,CODE_OF_CONDUCT.md,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CODE_OF_CONDUCT.md
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CODE_OF_CONDUCT.md:1931,Security,threat,threatening,1931,"nclusive language; * Gracefully accepting constructive criticism. Examples of unacceptable behavior by participants include:. * Trolling, insulting/derogatory comments, and personal or political attacks; * Public or private harassment; * Publishing others' private information, such as a physical or electronic; address (or real name if they are choosing to use a pseudonym), without explicit permission (doxing); * The use of sexualized language or imagery and unwelcome sexual attention or; advances; * Other conduct which could reasonably be considered inappropriate in a; professional setting. ## Our Responsibilities. Project maintainers are responsible for clarifying the standards of acceptable; behavior and are expected to take appropriate and fair corrective action in; response to any instances of unacceptable behavior. Project maintainers have the right and responsibility to remove, edit, or; reject comments, commits, code, wiki edits, issues, and other contributions; that are not aligned to this Code of Conduct, or to ban temporarily or; permanently any contributor for other behaviors that they deem inappropriate,; threatening, offensive, or harmful. ## Scope. This Code of Conduct applies both within project spaces and in public spaces; when an individual is representing the project or its community. Examples of; representing a project or community include using an official project e-mail; address, posting via an official social media account, or acting as an appointed; representative at an online or offline event. Representation of a project may be; further defined and clarified by project maintainers. ## Enforcement. Instances of abusive, harassing, or otherwise unacceptable behavior may be; reported by contacting the project team at salmon_maintainers@gmail.com. All; complaints will be reviewed and investigated and will result in a response that; is deemed necessary and appropriate to the circumstances. The project team is; obligated to maintain confidentiality ",MatchSource.DOCS,CODE_OF_CONDUCT.md,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CODE_OF_CONDUCT.md
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CODE_OF_CONDUCT.md:2781,Security,confidential,confidentiality,2781," for clarifying the standards of acceptable; behavior and are expected to take appropriate and fair corrective action in; response to any instances of unacceptable behavior. Project maintainers have the right and responsibility to remove, edit, or; reject comments, commits, code, wiki edits, issues, and other contributions; that are not aligned to this Code of Conduct, or to ban temporarily or; permanently any contributor for other behaviors that they deem inappropriate,; threatening, offensive, or harmful. ## Scope. This Code of Conduct applies both within project spaces and in public spaces; when an individual is representing the project or its community. Examples of; representing a project or community include using an official project e-mail; address, posting via an official social media account, or acting as an appointed; representative at an online or offline event. Representation of a project may be; further defined and clarified by project maintainers. ## Enforcement. Instances of abusive, harassing, or otherwise unacceptable behavior may be; reported by contacting the project team at salmon_maintainers@gmail.com. All; complaints will be reviewed and investigated and will result in a response that; is deemed necessary and appropriate to the circumstances. The project team is; obligated to maintain confidentiality with regard to the reporter of an incident.; Further details of specific enforcement policies may be posted separately. Project maintainers who do not follow or enforce the Code of Conduct in good; faith may face temporary or permanent repercussions as determined by other; members of the project's leadership. ## Attribution. This Code of Conduct is adapted from the [Contributor Covenant][homepage], version 1.4,; available at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html. [homepage]: https://www.contributor-covenant.org. For answers to common questions about this code of conduct, see; https://www.contributor-covenant.org/faq; ",MatchSource.DOCS,CODE_OF_CONDUCT.md,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CODE_OF_CONDUCT.md
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CONTRIBUTING.md:301,Deployability,release,released,301,"## Contributing code. Any code that you contribute will be licensed under the GPLv3-license adopted by salmon. However, by contributing; code to this project, you also extend permission for your contribution to be re-licensed under the BSD 3-clause ; license (under which we anticipate Salmon will be released once existing GPL code can be removed). Code contributions should be made via pull requests. Please make all PRs to the _develop_ branch ; of the repository. PRs made to the _master_ branch may be rejected if they cannot be cleanly rebased ; on _develop_. Before you make a PR, please check that:. * Your PR describes the purpose of your commit. Is it fixing a bug, adding functionality, etc.?; * Commit messages have been made using [*conventional commits*](https://www.conventionalcommits.org/en/v1.0.0/) — please format all of your commit messages as such.; * Any non-obvious code is documented (we don't yet have formal documentation guidelines yet, so use common sense); ",MatchSource.DOCS,CONTRIBUTING.md,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CONTRIBUTING.md
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CONTRIBUTING.md:714,Integrability,message,messages,714,"## Contributing code. Any code that you contribute will be licensed under the GPLv3-license adopted by salmon. However, by contributing; code to this project, you also extend permission for your contribution to be re-licensed under the BSD 3-clause ; license (under which we anticipate Salmon will be released once existing GPL code can be removed). Code contributions should be made via pull requests. Please make all PRs to the _develop_ branch ; of the repository. PRs made to the _master_ branch may be rejected if they cannot be cleanly rebased ; on _develop_. Before you make a PR, please check that:. * Your PR describes the purpose of your commit. Is it fixing a bug, adding functionality, etc.?; * Commit messages have been made using [*conventional commits*](https://www.conventionalcommits.org/en/v1.0.0/) — please format all of your commit messages as such.; * Any non-obvious code is documented (we don't yet have formal documentation guidelines yet, so use common sense); ",MatchSource.DOCS,CONTRIBUTING.md,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CONTRIBUTING.md
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CONTRIBUTING.md:852,Integrability,message,messages,852,"## Contributing code. Any code that you contribute will be licensed under the GPLv3-license adopted by salmon. However, by contributing; code to this project, you also extend permission for your contribution to be re-licensed under the BSD 3-clause ; license (under which we anticipate Salmon will be released once existing GPL code can be removed). Code contributions should be made via pull requests. Please make all PRs to the _develop_ branch ; of the repository. PRs made to the _master_ branch may be rejected if they cannot be cleanly rebased ; on _develop_. Before you make a PR, please check that:. * Your PR describes the purpose of your commit. Is it fixing a bug, adding functionality, etc.?; * Commit messages have been made using [*conventional commits*](https://www.conventionalcommits.org/en/v1.0.0/) — please format all of your commit messages as such.; * Any non-obvious code is documented (we don't yet have formal documentation guidelines yet, so use common sense); ",MatchSource.DOCS,CONTRIBUTING.md,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CONTRIBUTING.md
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CONTRIBUTING.md:168,Modifiability,extend,extend,168,"## Contributing code. Any code that you contribute will be licensed under the GPLv3-license adopted by salmon. However, by contributing; code to this project, you also extend permission for your contribution to be re-licensed under the BSD 3-clause ; license (under which we anticipate Salmon will be released once existing GPL code can be removed). Code contributions should be made via pull requests. Please make all PRs to the _develop_ branch ; of the repository. PRs made to the _master_ branch may be rejected if they cannot be cleanly rebased ; on _develop_. Before you make a PR, please check that:. * Your PR describes the purpose of your commit. Is it fixing a bug, adding functionality, etc.?; * Commit messages have been made using [*conventional commits*](https://www.conventionalcommits.org/en/v1.0.0/) — please format all of your commit messages as such.; * Any non-obvious code is documented (we don't yet have formal documentation guidelines yet, so use common sense); ",MatchSource.DOCS,CONTRIBUTING.md,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CONTRIBUTING.md
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CONTRIBUTING.md:948,Usability,guid,guidelines,948,"## Contributing code. Any code that you contribute will be licensed under the GPLv3-license adopted by salmon. However, by contributing; code to this project, you also extend permission for your contribution to be re-licensed under the BSD 3-clause ; license (under which we anticipate Salmon will be released once existing GPL code can be removed). Code contributions should be made via pull requests. Please make all PRs to the _develop_ branch ; of the repository. PRs made to the _master_ branch may be rejected if they cannot be cleanly rebased ; on _develop_. Before you make a PR, please check that:. * Your PR describes the purpose of your commit. Is it fixing a bug, adding functionality, etc.?; * Commit messages have been made using [*conventional commits*](https://www.conventionalcommits.org/en/v1.0.0/) — please format all of your commit messages as such.; * Any non-obvious code is documented (we don't yet have formal documentation guidelines yet, so use common sense); ",MatchSource.DOCS,CONTRIBUTING.md,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CONTRIBUTING.md
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/README.md:2154,Availability,avail,available,2154,"ment* (accurate but fast-to-compute proxies for traditional read alignments), and ; massively-parallel stochastic collapsed variational inference. The result is a versatile tool that fits nicely; into many different pipelines. For example, you can choose to make use of our *selective-alignment* algorithm by providing Salmon with raw sequencing reads, or, if it is more convenient, you can provide Salmon with regular alignments (e.g. an **unsorted** BAM file with alignments to the transcriptome produced with your favorite aligner), and it will use the same **wicked**-fast, state-of-the-art inference algorithm to estimate transcript-level abundances for your experiment. Give salmon a try! You can find the latest binary releases [here](https://github.com/COMBINE-lab/salmon/releases). The current version number of the master branch of Salmon can be found [**here**](http://combine-lab.github.io/salmon/version_info/latest). Documentation; ==============. The documentation for Salmon is available on [ReadTheDocs](http://readthedocs.org), check it out [here](http://salmon.readthedocs.org). Salmon is, and will continue to be, [freely and actively supported on a best-effort basis](https://oceangenomics.com/about/#open).; If you need industrial-grade technical support, please consider the options at [oceangenomics.com/contact](http://oceangenomics.com/contact). Decoy sequences in transcriptomes; =================================. tl;dr: fast is good but fast and accurate is better!; [Alignment and mapping methodology influence transcript abundance estimation](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-020-02151-8), and accounting for the [accounting for fragments of unexpected origin can improve transcript quantification](https://www.biorxiv.org/content/10.1101/2021.01.17.426996v1). To this end, salmon provides the ability to index both the transcriptome as well as decoy seuqence that can be considered during mapping and quantification. The decoy sequence ac",MatchSource.DOCS,README.md,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/README.md
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/README.md:246,Deployability,install,install,246,"<img alt=""salmon logo"" src=""https://github.com/COMBINE-lab/salmon/raw/master/doc/salmon_logo.png"" width=""600"">. [![Documentation Status](https://readthedocs.org/projects/salmon/badge/?version=latest)](http://salmon.readthedocs.org/en/latest); [![install with bioconda](https://img.shields.io/badge/install%20with-bioconda-brightgreen.svg?style=flat-square)](http://bioconda.github.io/recipes/salmon/README.html); ![GitHub tag (latest SemVer)](https://img.shields.io/github/v/tag/combine-lab/salmon?style=flat-square). **Try out the new [alevin-fry](https://alevin-fry.readthedocs.io/en/latest/) framework for single-cell analysis; tutorials can be found [here](https://combine-lab.github.io/alevin-fry-tutorials/)!**. **Help guide the development of Salmon, [take our survey](https://docs.google.com/forms/d/e/1FAIpQLSeWhBNE_fA_0uVHvbAlAulDmfmowv7rAYla879DZpqCARyRTQ/viewform)**. What is Salmon?; ===============. Salmon is a **wicked**-fast program to produce a highly-accurate, transcript-level quantification estimates from ; RNA-seq data. Salmon achieves its accuracy and speed via a number of different innovations, including the ; use of *selective-alignment* (accurate but fast-to-compute proxies for traditional read alignments), and ; massively-parallel stochastic collapsed variational inference. The result is a versatile tool that fits nicely; into many different pipelines. For example, you can choose to make use of our *selective-alignment* algorithm by providing Salmon with raw sequencing reads, or, if it is more convenient, you can provide Salmon with regular alignments (e.g. an **unsorted** BAM file with alignments to the transcriptome produced with your favorite aligner), and it will use the same **wicked**-fast, state-of-the-art inference algorithm to estimate transcript-level abundances for your experiment. Give salmon a try! You can find the latest binary releases [here](https://github.com/COMBINE-lab/salmon/releases). The current version number of the master branch of",MatchSource.DOCS,README.md,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/README.md
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/README.md:298,Deployability,install,install,298,"<img alt=""salmon logo"" src=""https://github.com/COMBINE-lab/salmon/raw/master/doc/salmon_logo.png"" width=""600"">. [![Documentation Status](https://readthedocs.org/projects/salmon/badge/?version=latest)](http://salmon.readthedocs.org/en/latest); [![install with bioconda](https://img.shields.io/badge/install%20with-bioconda-brightgreen.svg?style=flat-square)](http://bioconda.github.io/recipes/salmon/README.html); ![GitHub tag (latest SemVer)](https://img.shields.io/github/v/tag/combine-lab/salmon?style=flat-square). **Try out the new [alevin-fry](https://alevin-fry.readthedocs.io/en/latest/) framework for single-cell analysis; tutorials can be found [here](https://combine-lab.github.io/alevin-fry-tutorials/)!**. **Help guide the development of Salmon, [take our survey](https://docs.google.com/forms/d/e/1FAIpQLSeWhBNE_fA_0uVHvbAlAulDmfmowv7rAYla879DZpqCARyRTQ/viewform)**. What is Salmon?; ===============. Salmon is a **wicked**-fast program to produce a highly-accurate, transcript-level quantification estimates from ; RNA-seq data. Salmon achieves its accuracy and speed via a number of different innovations, including the ; use of *selective-alignment* (accurate but fast-to-compute proxies for traditional read alignments), and ; massively-parallel stochastic collapsed variational inference. The result is a versatile tool that fits nicely; into many different pipelines. For example, you can choose to make use of our *selective-alignment* algorithm by providing Salmon with raw sequencing reads, or, if it is more convenient, you can provide Salmon with regular alignments (e.g. an **unsorted** BAM file with alignments to the transcriptome produced with your favorite aligner), and it will use the same **wicked**-fast, state-of-the-art inference algorithm to estimate transcript-level abundances for your experiment. Give salmon a try! You can find the latest binary releases [here](https://github.com/COMBINE-lab/salmon/releases). The current version number of the master branch of",MatchSource.DOCS,README.md,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/README.md
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/README.md:1376,Deployability,pipeline,pipelines,1376,"at-square)](http://bioconda.github.io/recipes/salmon/README.html); ![GitHub tag (latest SemVer)](https://img.shields.io/github/v/tag/combine-lab/salmon?style=flat-square). **Try out the new [alevin-fry](https://alevin-fry.readthedocs.io/en/latest/) framework for single-cell analysis; tutorials can be found [here](https://combine-lab.github.io/alevin-fry-tutorials/)!**. **Help guide the development of Salmon, [take our survey](https://docs.google.com/forms/d/e/1FAIpQLSeWhBNE_fA_0uVHvbAlAulDmfmowv7rAYla879DZpqCARyRTQ/viewform)**. What is Salmon?; ===============. Salmon is a **wicked**-fast program to produce a highly-accurate, transcript-level quantification estimates from ; RNA-seq data. Salmon achieves its accuracy and speed via a number of different innovations, including the ; use of *selective-alignment* (accurate but fast-to-compute proxies for traditional read alignments), and ; massively-parallel stochastic collapsed variational inference. The result is a versatile tool that fits nicely; into many different pipelines. For example, you can choose to make use of our *selective-alignment* algorithm by providing Salmon with raw sequencing reads, or, if it is more convenient, you can provide Salmon with regular alignments (e.g. an **unsorted** BAM file with alignments to the transcriptome produced with your favorite aligner), and it will use the same **wicked**-fast, state-of-the-art inference algorithm to estimate transcript-level abundances for your experiment. Give salmon a try! You can find the latest binary releases [here](https://github.com/COMBINE-lab/salmon/releases). The current version number of the master branch of Salmon can be found [**here**](http://combine-lab.github.io/salmon/version_info/latest). Documentation; ==============. The documentation for Salmon is available on [ReadTheDocs](http://readthedocs.org), check it out [here](http://salmon.readthedocs.org). Salmon is, and will continue to be, [freely and actively supported on a best-effort basi",MatchSource.DOCS,README.md,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/README.md
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/README.md:1886,Deployability,release,releases,1886,"**. What is Salmon?; ===============. Salmon is a **wicked**-fast program to produce a highly-accurate, transcript-level quantification estimates from ; RNA-seq data. Salmon achieves its accuracy and speed via a number of different innovations, including the ; use of *selective-alignment* (accurate but fast-to-compute proxies for traditional read alignments), and ; massively-parallel stochastic collapsed variational inference. The result is a versatile tool that fits nicely; into many different pipelines. For example, you can choose to make use of our *selective-alignment* algorithm by providing Salmon with raw sequencing reads, or, if it is more convenient, you can provide Salmon with regular alignments (e.g. an **unsorted** BAM file with alignments to the transcriptome produced with your favorite aligner), and it will use the same **wicked**-fast, state-of-the-art inference algorithm to estimate transcript-level abundances for your experiment. Give salmon a try! You can find the latest binary releases [here](https://github.com/COMBINE-lab/salmon/releases). The current version number of the master branch of Salmon can be found [**here**](http://combine-lab.github.io/salmon/version_info/latest). Documentation; ==============. The documentation for Salmon is available on [ReadTheDocs](http://readthedocs.org), check it out [here](http://salmon.readthedocs.org). Salmon is, and will continue to be, [freely and actively supported on a best-effort basis](https://oceangenomics.com/about/#open).; If you need industrial-grade technical support, please consider the options at [oceangenomics.com/contact](http://oceangenomics.com/contact). Decoy sequences in transcriptomes; =================================. tl;dr: fast is good but fast and accurate is better!; [Alignment and mapping methodology influence transcript abundance estimation](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-020-02151-8), and accounting for the [accounting for fragments of unexpected o",MatchSource.DOCS,README.md,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/README.md
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/README.md:1940,Deployability,release,releases,1940,"d**-fast program to produce a highly-accurate, transcript-level quantification estimates from ; RNA-seq data. Salmon achieves its accuracy and speed via a number of different innovations, including the ; use of *selective-alignment* (accurate but fast-to-compute proxies for traditional read alignments), and ; massively-parallel stochastic collapsed variational inference. The result is a versatile tool that fits nicely; into many different pipelines. For example, you can choose to make use of our *selective-alignment* algorithm by providing Salmon with raw sequencing reads, or, if it is more convenient, you can provide Salmon with regular alignments (e.g. an **unsorted** BAM file with alignments to the transcriptome produced with your favorite aligner), and it will use the same **wicked**-fast, state-of-the-art inference algorithm to estimate transcript-level abundances for your experiment. Give salmon a try! You can find the latest binary releases [here](https://github.com/COMBINE-lab/salmon/releases). The current version number of the master branch of Salmon can be found [**here**](http://combine-lab.github.io/salmon/version_info/latest). Documentation; ==============. The documentation for Salmon is available on [ReadTheDocs](http://readthedocs.org), check it out [here](http://salmon.readthedocs.org). Salmon is, and will continue to be, [freely and actively supported on a best-effort basis](https://oceangenomics.com/about/#open).; If you need industrial-grade technical support, please consider the options at [oceangenomics.com/contact](http://oceangenomics.com/contact). Decoy sequences in transcriptomes; =================================. tl;dr: fast is good but fast and accurate is better!; [Alignment and mapping methodology influence transcript abundance estimation](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-020-02151-8), and accounting for the [accounting for fragments of unexpected origin can improve transcript quantification](https://www.b",MatchSource.DOCS,README.md,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/README.md
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/README.md:3385,Energy Efficiency,efficient,efficiently,3385,").; If you need industrial-grade technical support, please consider the options at [oceangenomics.com/contact](http://oceangenomics.com/contact). Decoy sequences in transcriptomes; =================================. tl;dr: fast is good but fast and accurate is better!; [Alignment and mapping methodology influence transcript abundance estimation](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-020-02151-8), and accounting for the [accounting for fragments of unexpected origin can improve transcript quantification](https://www.biorxiv.org/content/10.1101/2021.01.17.426996v1). To this end, salmon provides the ability to index both the transcriptome as well as decoy seuqence that can be considered during mapping and quantification. The decoy sequence accounts for reads that might otherwise be (spuriously) attributed to some annotated transcript. This [tutorial](https://combine-lab.github.io/alevin-tutorial/2019/selective-alignment/) provides a step-by-step guide on how to efficiently index the reference transcriptome and genome to produce a decoy-aware index. Specifically, there are 3 possible ways in which the salmon index can be created:. * cDNA-only index : salmon_index - https://combine-lab.github.io/salmon/getting_started/. This method will result in the smallest index and require the least resources to build, but will be the most prone to possible spurious alignments. * SA mashmap index: salmon_partial_sa_index - (regions of genome that have high sequence similarity to the transcriptome) - Details can be found in [this README](https://github.com/COMBINE-lab/SalmonTools/blob/master/README.md) and using [this script](https://raw.githubusercontent.com/COMBINE-lab/SalmonTools/master/scripts/generateDecoyTranscriptome.sh). While running mashmap can require considerable resources, the resulting decoy files are fairly small. This will result in an index bigger than the cDNA-only index, but still mucch smaller than the full genome index below. It will conf",MatchSource.DOCS,README.md,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/README.md
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/README.md:5793,Energy Efficiency,monitor,monitored,5793,"coyTranscriptome.sh). While running mashmap can require considerable resources, the resulting decoy files are fairly small. This will result in an index bigger than the cDNA-only index, but still mucch smaller than the full genome index below. It will confer many, though not all, of the benefits of using the entire genome as a decoy sequence. * SAF genome index: salmon_sa_index - (the full genome is used as decoy) - The tutorial for creating such an index can be found [here](https://combine-lab.github.io/alevin-tutorial/2019/selective-alignment/). This will result in the largest index, but likely does the best job in avoiding spurious alignments to annotated transcripts. . **Facing problems with Indexing?**, Check if anyone else already had this problem in the issues section or fill the index generation [request form](https://forms.gle/3baJc5SYrkSWb1z48). ### **NOTE**:; If you are generating an index to be used for single-cell or single-nucleus quantification with [alevin-fry](https://github.com/COMBINE-lab/alevin-fry), then we recommend you consider building a spliced+intron (_splici_) reference. This serves much of the purpose of a decoy-aware index when quantifying with alevin-fry, while also providing the capability to attribute splicing status to mapped fragments. More details about the _splici_ reference and the Unspliced/Spliced/Ambiguous quantification mode it enables can be found [here](https://combine-lab.github.io/alevin-fry-tutorials/2021/improving-txome-specificity/). Chat live about Salmon; ======================. You can chat with the Salmon developers and other users via Gitter (**Note**: Gitter is much less frequently monitored than GitHub, so if you have an important problem or question, please consider opening an issue here on GitHub)!. [![Join the chat at https://gitter.im/COMBINE-lab/salmon](https://badges.gitter.im/Join%20Chat.svg)](https://gitter.im/COMBINE-lab/salmon?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge); ",MatchSource.DOCS,README.md,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/README.md
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/README.md:4755,Safety,avoid,avoiding,4755," the most prone to possible spurious alignments. * SA mashmap index: salmon_partial_sa_index - (regions of genome that have high sequence similarity to the transcriptome) - Details can be found in [this README](https://github.com/COMBINE-lab/SalmonTools/blob/master/README.md) and using [this script](https://raw.githubusercontent.com/COMBINE-lab/SalmonTools/master/scripts/generateDecoyTranscriptome.sh). While running mashmap can require considerable resources, the resulting decoy files are fairly small. This will result in an index bigger than the cDNA-only index, but still mucch smaller than the full genome index below. It will confer many, though not all, of the benefits of using the entire genome as a decoy sequence. * SAF genome index: salmon_sa_index - (the full genome is used as decoy) - The tutorial for creating such an index can be found [here](https://combine-lab.github.io/alevin-tutorial/2019/selective-alignment/). This will result in the largest index, but likely does the best job in avoiding spurious alignments to annotated transcripts. . **Facing problems with Indexing?**, Check if anyone else already had this problem in the issues section or fill the index generation [request form](https://forms.gle/3baJc5SYrkSWb1z48). ### **NOTE**:; If you are generating an index to be used for single-cell or single-nucleus quantification with [alevin-fry](https://github.com/COMBINE-lab/alevin-fry), then we recommend you consider building a spliced+intron (_splici_) reference. This serves much of the purpose of a decoy-aware index when quantifying with alevin-fry, while also providing the capability to attribute splicing status to mapped fragments. More details about the _splici_ reference and the Unspliced/Spliced/Ambiguous quantification mode it enables can be found [here](https://combine-lab.github.io/alevin-fry-tutorials/2021/improving-txome-specificity/). Chat live about Salmon; ======================. You can chat with the Salmon developers and other users via Gi",MatchSource.DOCS,README.md,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/README.md
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/README.md:17,Testability,log,logo,17,"<img alt=""salmon logo"" src=""https://github.com/COMBINE-lab/salmon/raw/master/doc/salmon_logo.png"" width=""600"">. [![Documentation Status](https://readthedocs.org/projects/salmon/badge/?version=latest)](http://salmon.readthedocs.org/en/latest); [![install with bioconda](https://img.shields.io/badge/install%20with-bioconda-brightgreen.svg?style=flat-square)](http://bioconda.github.io/recipes/salmon/README.html); ![GitHub tag (latest SemVer)](https://img.shields.io/github/v/tag/combine-lab/salmon?style=flat-square). **Try out the new [alevin-fry](https://alevin-fry.readthedocs.io/en/latest/) framework for single-cell analysis; tutorials can be found [here](https://combine-lab.github.io/alevin-fry-tutorials/)!**. **Help guide the development of Salmon, [take our survey](https://docs.google.com/forms/d/e/1FAIpQLSeWhBNE_fA_0uVHvbAlAulDmfmowv7rAYla879DZpqCARyRTQ/viewform)**. What is Salmon?; ===============. Salmon is a **wicked**-fast program to produce a highly-accurate, transcript-level quantification estimates from ; RNA-seq data. Salmon achieves its accuracy and speed via a number of different innovations, including the ; use of *selective-alignment* (accurate but fast-to-compute proxies for traditional read alignments), and ; massively-parallel stochastic collapsed variational inference. The result is a versatile tool that fits nicely; into many different pipelines. For example, you can choose to make use of our *selective-alignment* algorithm by providing Salmon with raw sequencing reads, or, if it is more convenient, you can provide Salmon with regular alignments (e.g. an **unsorted** BAM file with alignments to the transcriptome produced with your favorite aligner), and it will use the same **wicked**-fast, state-of-the-art inference algorithm to estimate transcript-level abundances for your experiment. Give salmon a try! You can find the latest binary releases [here](https://github.com/COMBINE-lab/salmon/releases). The current version number of the master branch of",MatchSource.DOCS,README.md,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/README.md
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/README.md:725,Usability,guid,guide,725,"<img alt=""salmon logo"" src=""https://github.com/COMBINE-lab/salmon/raw/master/doc/salmon_logo.png"" width=""600"">. [![Documentation Status](https://readthedocs.org/projects/salmon/badge/?version=latest)](http://salmon.readthedocs.org/en/latest); [![install with bioconda](https://img.shields.io/badge/install%20with-bioconda-brightgreen.svg?style=flat-square)](http://bioconda.github.io/recipes/salmon/README.html); ![GitHub tag (latest SemVer)](https://img.shields.io/github/v/tag/combine-lab/salmon?style=flat-square). **Try out the new [alevin-fry](https://alevin-fry.readthedocs.io/en/latest/) framework for single-cell analysis; tutorials can be found [here](https://combine-lab.github.io/alevin-fry-tutorials/)!**. **Help guide the development of Salmon, [take our survey](https://docs.google.com/forms/d/e/1FAIpQLSeWhBNE_fA_0uVHvbAlAulDmfmowv7rAYla879DZpqCARyRTQ/viewform)**. What is Salmon?; ===============. Salmon is a **wicked**-fast program to produce a highly-accurate, transcript-level quantification estimates from ; RNA-seq data. Salmon achieves its accuracy and speed via a number of different innovations, including the ; use of *selective-alignment* (accurate but fast-to-compute proxies for traditional read alignments), and ; massively-parallel stochastic collapsed variational inference. The result is a versatile tool that fits nicely; into many different pipelines. For example, you can choose to make use of our *selective-alignment* algorithm by providing Salmon with raw sequencing reads, or, if it is more convenient, you can provide Salmon with regular alignments (e.g. an **unsorted** BAM file with alignments to the transcriptome produced with your favorite aligner), and it will use the same **wicked**-fast, state-of-the-art inference algorithm to estimate transcript-level abundances for your experiment. Give salmon a try! You can find the latest binary releases [here](https://github.com/COMBINE-lab/salmon/releases). The current version number of the master branch of",MatchSource.DOCS,README.md,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/README.md
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/README.md:3369,Usability,guid,guide,3369,").; If you need industrial-grade technical support, please consider the options at [oceangenomics.com/contact](http://oceangenomics.com/contact). Decoy sequences in transcriptomes; =================================. tl;dr: fast is good but fast and accurate is better!; [Alignment and mapping methodology influence transcript abundance estimation](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-020-02151-8), and accounting for the [accounting for fragments of unexpected origin can improve transcript quantification](https://www.biorxiv.org/content/10.1101/2021.01.17.426996v1). To this end, salmon provides the ability to index both the transcriptome as well as decoy seuqence that can be considered during mapping and quantification. The decoy sequence accounts for reads that might otherwise be (spuriously) attributed to some annotated transcript. This [tutorial](https://combine-lab.github.io/alevin-tutorial/2019/selective-alignment/) provides a step-by-step guide on how to efficiently index the reference transcriptome and genome to produce a decoy-aware index. Specifically, there are 3 possible ways in which the salmon index can be created:. * cDNA-only index : salmon_index - https://combine-lab.github.io/salmon/getting_started/. This method will result in the smallest index and require the least resources to build, but will be the most prone to possible spurious alignments. * SA mashmap index: salmon_partial_sa_index - (regions of genome that have high sequence similarity to the transcriptome) - Details can be found in [this README](https://github.com/COMBINE-lab/SalmonTools/blob/master/README.md) and using [this script](https://raw.githubusercontent.com/COMBINE-lab/SalmonTools/master/scripts/generateDecoyTranscriptome.sh). While running mashmap can require considerable resources, the resulting decoy files are fairly small. This will result in an index bigger than the cDNA-only index, but still mucch smaller than the full genome index below. It will conf",MatchSource.DOCS,README.md,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/README.md
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/FileFormats.md:210,Usability,simpl,simply,210,"Transcript Index Format; =======================. The sorted list (array) is the structure used by our program; to count the k-mers from the reads and it relies on a transcript; index. The index is (currently) simply a sorted array containing; all of the kmers, in encoded (uint64_t) numeric order, that were; seen in the trancsripts. The file format is as follows. ````; kmer_len[uint32_t]; num_kmers[uint32_t]; k_1[uint_64t] . . . k_{num_kmers}[uint64_t]; ````",MatchSource.DOCS,doc/FileFormats.md,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/FileFormats.md
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/steps_to_prepare_release.md:21,Deployability,release,release,21,"# Steps to prepare a release of salmon; -----. 1. Tag corresponding commit of pufferfish so that it can be stably pulled in for source builds.; 2. Alter `fetchPufferfish.sh` to fetch the corresponding tagged version (and update the sha256 sum).; 3. Bump salmon version in `include/SalmonConfig.hpp`, then rebuild and run the `bump_version.sh` script.; 4. Ensure that everything builds cleanly on Linux (taken care of by CI) and OSX.; 5. Merge the develop branch changes into master.; 6. Tag the salmon release with a new version number.; 7. Update the docker tag and build an image for docker hub.; 8. Bump the Bioconda version and build a new Bioconda release.; 9. Add release notes for the tagged master version.; 10. Upload the pre-compiled linux binary (from the CI server) to GitHub.; 11. Place a new version file on the website and update the old one.; 12. (not technically part of release) Reset the relevant changes (steps 1,2) on the develop branch so they now point to a non-tagged pufferfish.; ",MatchSource.DOCS,doc/steps_to_prepare_release.md,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/steps_to_prepare_release.md
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/steps_to_prepare_release.md:221,Deployability,update,update,221,"# Steps to prepare a release of salmon; -----. 1. Tag corresponding commit of pufferfish so that it can be stably pulled in for source builds.; 2. Alter `fetchPufferfish.sh` to fetch the corresponding tagged version (and update the sha256 sum).; 3. Bump salmon version in `include/SalmonConfig.hpp`, then rebuild and run the `bump_version.sh` script.; 4. Ensure that everything builds cleanly on Linux (taken care of by CI) and OSX.; 5. Merge the develop branch changes into master.; 6. Tag the salmon release with a new version number.; 7. Update the docker tag and build an image for docker hub.; 8. Bump the Bioconda version and build a new Bioconda release.; 9. Add release notes for the tagged master version.; 10. Upload the pre-compiled linux binary (from the CI server) to GitHub.; 11. Place a new version file on the website and update the old one.; 12. (not technically part of release) Reset the relevant changes (steps 1,2) on the develop branch so they now point to a non-tagged pufferfish.; ",MatchSource.DOCS,doc/steps_to_prepare_release.md,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/steps_to_prepare_release.md
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/steps_to_prepare_release.md:502,Deployability,release,release,502,"# Steps to prepare a release of salmon; -----. 1. Tag corresponding commit of pufferfish so that it can be stably pulled in for source builds.; 2. Alter `fetchPufferfish.sh` to fetch the corresponding tagged version (and update the sha256 sum).; 3. Bump salmon version in `include/SalmonConfig.hpp`, then rebuild and run the `bump_version.sh` script.; 4. Ensure that everything builds cleanly on Linux (taken care of by CI) and OSX.; 5. Merge the develop branch changes into master.; 6. Tag the salmon release with a new version number.; 7. Update the docker tag and build an image for docker hub.; 8. Bump the Bioconda version and build a new Bioconda release.; 9. Add release notes for the tagged master version.; 10. Upload the pre-compiled linux binary (from the CI server) to GitHub.; 11. Place a new version file on the website and update the old one.; 12. (not technically part of release) Reset the relevant changes (steps 1,2) on the develop branch so they now point to a non-tagged pufferfish.; ",MatchSource.DOCS,doc/steps_to_prepare_release.md,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/steps_to_prepare_release.md
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/steps_to_prepare_release.md:653,Deployability,release,release,653,"# Steps to prepare a release of salmon; -----. 1. Tag corresponding commit of pufferfish so that it can be stably pulled in for source builds.; 2. Alter `fetchPufferfish.sh` to fetch the corresponding tagged version (and update the sha256 sum).; 3. Bump salmon version in `include/SalmonConfig.hpp`, then rebuild and run the `bump_version.sh` script.; 4. Ensure that everything builds cleanly on Linux (taken care of by CI) and OSX.; 5. Merge the develop branch changes into master.; 6. Tag the salmon release with a new version number.; 7. Update the docker tag and build an image for docker hub.; 8. Bump the Bioconda version and build a new Bioconda release.; 9. Add release notes for the tagged master version.; 10. Upload the pre-compiled linux binary (from the CI server) to GitHub.; 11. Place a new version file on the website and update the old one.; 12. (not technically part of release) Reset the relevant changes (steps 1,2) on the develop branch so they now point to a non-tagged pufferfish.; ",MatchSource.DOCS,doc/steps_to_prepare_release.md,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/steps_to_prepare_release.md
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/steps_to_prepare_release.md:670,Deployability,release,release,670,"# Steps to prepare a release of salmon; -----. 1. Tag corresponding commit of pufferfish so that it can be stably pulled in for source builds.; 2. Alter `fetchPufferfish.sh` to fetch the corresponding tagged version (and update the sha256 sum).; 3. Bump salmon version in `include/SalmonConfig.hpp`, then rebuild and run the `bump_version.sh` script.; 4. Ensure that everything builds cleanly on Linux (taken care of by CI) and OSX.; 5. Merge the develop branch changes into master.; 6. Tag the salmon release with a new version number.; 7. Update the docker tag and build an image for docker hub.; 8. Bump the Bioconda version and build a new Bioconda release.; 9. Add release notes for the tagged master version.; 10. Upload the pre-compiled linux binary (from the CI server) to GitHub.; 11. Place a new version file on the website and update the old one.; 12. (not technically part of release) Reset the relevant changes (steps 1,2) on the develop branch so they now point to a non-tagged pufferfish.; ",MatchSource.DOCS,doc/steps_to_prepare_release.md,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/steps_to_prepare_release.md
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/steps_to_prepare_release.md:838,Deployability,update,update,838,"# Steps to prepare a release of salmon; -----. 1. Tag corresponding commit of pufferfish so that it can be stably pulled in for source builds.; 2. Alter `fetchPufferfish.sh` to fetch the corresponding tagged version (and update the sha256 sum).; 3. Bump salmon version in `include/SalmonConfig.hpp`, then rebuild and run the `bump_version.sh` script.; 4. Ensure that everything builds cleanly on Linux (taken care of by CI) and OSX.; 5. Merge the develop branch changes into master.; 6. Tag the salmon release with a new version number.; 7. Update the docker tag and build an image for docker hub.; 8. Bump the Bioconda version and build a new Bioconda release.; 9. Add release notes for the tagged master version.; 10. Upload the pre-compiled linux binary (from the CI server) to GitHub.; 11. Place a new version file on the website and update the old one.; 12. (not technically part of release) Reset the relevant changes (steps 1,2) on the develop branch so they now point to a non-tagged pufferfish.; ",MatchSource.DOCS,doc/steps_to_prepare_release.md,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/steps_to_prepare_release.md
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/steps_to_prepare_release.md:888,Deployability,release,release,888,"# Steps to prepare a release of salmon; -----. 1. Tag corresponding commit of pufferfish so that it can be stably pulled in for source builds.; 2. Alter `fetchPufferfish.sh` to fetch the corresponding tagged version (and update the sha256 sum).; 3. Bump salmon version in `include/SalmonConfig.hpp`, then rebuild and run the `bump_version.sh` script.; 4. Ensure that everything builds cleanly on Linux (taken care of by CI) and OSX.; 5. Merge the develop branch changes into master.; 6. Tag the salmon release with a new version number.; 7. Update the docker tag and build an image for docker hub.; 8. Bump the Bioconda version and build a new Bioconda release.; 9. Add release notes for the tagged master version.; 10. Upload the pre-compiled linux binary (from the CI server) to GitHub.; 11. Place a new version file on the website and update the old one.; 12. (not technically part of release) Reset the relevant changes (steps 1,2) on the develop branch so they now point to a non-tagged pufferfish.; ",MatchSource.DOCS,doc/steps_to_prepare_release.md,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/steps_to_prepare_release.md
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/tests/README.md:18,Testability,test,test,18,# How to run unit test; ```; ./run.sh <PATH to a new Salmon Binary containg Alevin>; ```; # Contents of unit_test_data.tar.gz. * *alevin*; * __alevin.log__: logs of a run of salmon with the test data ; * __counts.mat__: Cell(row)xGene(Column) counts ; * __eq_classes.txt__: Global eqClass ; * *cell* ; * __cell__eq_classes.txt__: EqClass for one Cell ; * __quant.sf__: Abundance of one cell . * *src-py*; * __get_correlation.py__: python script to get correlation of one cell; ,MatchSource.DOCS,tests/README.md,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/tests/README.md
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/tests/README.md:157,Testability,log,logs,157,# How to run unit test; ```; ./run.sh <PATH to a new Salmon Binary containg Alevin>; ```; # Contents of unit_test_data.tar.gz. * *alevin*; * __alevin.log__: logs of a run of salmon with the test data ; * __counts.mat__: Cell(row)xGene(Column) counts ; * __eq_classes.txt__: Global eqClass ; * *cell* ; * __cell__eq_classes.txt__: EqClass for one Cell ; * __quant.sf__: Abundance of one cell . * *src-py*; * __get_correlation.py__: python script to get correlation of one cell; ,MatchSource.DOCS,tests/README.md,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/tests/README.md
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/tests/README.md:190,Testability,test,test,190,# How to run unit test; ```; ./run.sh <PATH to a new Salmon Binary containg Alevin>; ```; # Contents of unit_test_data.tar.gz. * *alevin*; * __alevin.log__: logs of a run of salmon with the test data ; * __counts.mat__: Cell(row)xGene(Column) counts ; * __eq_classes.txt__: Global eqClass ; * *cell* ; * __cell__eq_classes.txt__: EqClass for one Cell ; * __quant.sf__: Abundance of one cell . * *src-py*; * __get_correlation.py__: python script to get correlation of one cell; ,MatchSource.DOCS,tests/README.md,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/tests/README.md
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/.github/ISSUE_TEMPLATE/bug_report.md:433,Availability,down,downloaded,433,"---; name: Bug report; about: Create a report to help us improve. ---. **Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**. **Describe the bug**; A clear and concise description of what the bug is. **To Reproduce**; Steps and data to reproduce the behavior:. Specifically, please provide at least the following information:. * Which version of salmon was used?; * How was salmon installed (compiled, downloaded executable, through bioconda)?; * Which reference (e.g. transcriptome) was used?; * Which read files were used?; * Which which program options were used?. **Expected behavior**; A clear and concise description of what you expected to happen. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX]; - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux the output of `uname -a` and `lsb_release -a`]. **Additional context**; Add any other context about the problem here.; ",MatchSource.DOCS,.github/ISSUE_TEMPLATE/bug_report.md,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/.github/ISSUE_TEMPLATE/bug_report.md
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/.github/ISSUE_TEMPLATE/bug_report.md:412,Deployability,install,installed,412,"---; name: Bug report; about: Create a report to help us improve. ---. **Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**. **Describe the bug**; A clear and concise description of what the bug is. **To Reproduce**; Steps and data to reproduce the behavior:. Specifically, please provide at least the following information:. * Which version of salmon was used?; * How was salmon installed (compiled, downloaded executable, through bioconda)?; * Which reference (e.g. transcriptome) was used?; * Which read files were used?; * Which which program options were used?. **Expected behavior**; A clear and concise description of what you expected to happen. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX]; - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux the output of `uname -a` and `lsb_release -a`]. **Additional context**; Add any other context about the problem here.; ",MatchSource.DOCS,.github/ISSUE_TEMPLATE/bug_report.md,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/.github/ISSUE_TEMPLATE/bug_report.md
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/.github/ISSUE_TEMPLATE/bug_report.md:181,Usability,clear,clear,181,"---; name: Bug report; about: Create a report to help us improve. ---. **Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**. **Describe the bug**; A clear and concise description of what the bug is. **To Reproduce**; Steps and data to reproduce the behavior:. Specifically, please provide at least the following information:. * Which version of salmon was used?; * How was salmon installed (compiled, downloaded executable, through bioconda)?; * Which reference (e.g. transcriptome) was used?; * Which read files were used?; * Which which program options were used?. **Expected behavior**; A clear and concise description of what you expected to happen. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX]; - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux the output of `uname -a` and `lsb_release -a`]. **Additional context**; Add any other context about the problem here.; ",MatchSource.DOCS,.github/ISSUE_TEMPLATE/bug_report.md,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/.github/ISSUE_TEMPLATE/bug_report.md
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/.github/ISSUE_TEMPLATE/bug_report.md:624,Usability,clear,clear,624,"---; name: Bug report; about: Create a report to help us improve. ---. **Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**. **Describe the bug**; A clear and concise description of what the bug is. **To Reproduce**; Steps and data to reproduce the behavior:. Specifically, please provide at least the following information:. * Which version of salmon was used?; * How was salmon installed (compiled, downloaded executable, through bioconda)?; * Which reference (e.g. transcriptome) was used?; * Which read files were used?; * Which which program options were used?. **Expected behavior**; A clear and concise description of what you expected to happen. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX]; - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux the output of `uname -a` and `lsb_release -a`]. **Additional context**; Add any other context about the problem here.; ",MatchSource.DOCS,.github/ISSUE_TEMPLATE/bug_report.md,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/.github/ISSUE_TEMPLATE/bug_report.md
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst:1174,Availability,error,errors,1174,"n and analysis of 3' tagged-end single-cell sequencing data. Currently alevin supports the following single-cell protocols:. 1. Drop-seq; 2. 10x-Chromium v1/2/3; 3. inDropV2; 4. CELSeq 1/2; 5. Quartz-Seq2; 6. sci-RNA-seq3. Alevin works under the same indexing scheme (as salmon) for the reference, and consumes the set of FASTA/Q files(s) containing the Cellular Barcode(CB) + Unique Molecule identifier (UMI) in one read file and the read sequence in the other. Given just the transcriptome and the raw read files, alevin generates a cell-by-gene count matrix (in a fraction of the time compared to other tools). Alevin works in two phases. In the first phase it quickly parses the read file containing the CB and UMI information to generate the frequency distribution of all the observed CBs, and creates a lightweight data-structure for fast-look up and correction of the CB. In the second round, alevin utilizes the read-sequences contained in the files to map the reads to the transcriptome, identify potential PCR/sequencing errors in the UMIs, and performs hybrid de-duplication while accounting for UMI collisions. Finally, a post-abundance estimation CB whitelisting procedure is done and a cell-by-gene count matrix is generated. Using Alevin; ------------. Alevin requires the following minimal set of necessary input parameters (generally providing the flags *in that order* is recommended):. * ``-l``: library type (same as salmon), we recommend using `ISR` for both Drop-seq and 10x-v2 chemistry.; * ``-1``: CB+UMI file(s), alevin requires the path to the *FASTQ* file containing CB+UMI raw sequences to be given under this command line flag. Alevin also supports parsing of data from multiple files as long as the order is the same as in `-2` flag.; * ``-2``: Read-sequence file(s), alevin requires the path to the *FASTQ* file containing raw read-sequences to be given under this command line flag. Alevin also supports parsing of data from multiple files as long as the order is the ",MatchSource.DOCS,doc/source/alevin.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst:2578,Availability,avail,available,2578,"pe (same as salmon), we recommend using `ISR` for both Drop-seq and 10x-v2 chemistry.; * ``-1``: CB+UMI file(s), alevin requires the path to the *FASTQ* file containing CB+UMI raw sequences to be given under this command line flag. Alevin also supports parsing of data from multiple files as long as the order is the same as in `-2` flag.; * ``-2``: Read-sequence file(s), alevin requires the path to the *FASTQ* file containing raw read-sequences to be given under this command line flag. Alevin also supports parsing of data from multiple files as long as the order is the same as in `-1` flag.; * ``--dropseq / --chromium / --chromiumV3``: the protocol, this flag tells the type of single-cell protocol of the input sequencing-library.; * ``-i``: index, file containing the salmon index of the reference transcriptome, as generated by `salmon index` command.; * ``-p``: number of threads, the number of threads which can be used by alevin to perform the quantification, by default alevin utilizes *all* the available threads in the system, although we recommend using ~10 threads which in our testing gave the best memory-time trade-off.; * ``-o``: output, path to folder where the output gene-count matrix (along with other meta-data) would be dumped.; * ``--tgMap``: transcript to gene map file, a tsv (tab-separated) file --- with *no header*, containing two columns mapping of each transcript present in the reference to the corresponding gene (the first column is a transcript and the second is the corresponding gene). Once all the above requirement are satisfied, alevin can be run using the following command::. > salmon alevin -l ISR -1 cb.fastq.gz -2 reads.fastq.gz --chromium -i salmon_index_directory -p 10 -o alevin_output --tgMap txp2gene.tsv. Providing multiple read files to Alevin; ------------. Often, a single library may be split into multiple FASTA/Q files. Also, sometimes one may wish; to quantify multiple replicates or samples together, treating them as if they are one lib",MatchSource.DOCS,doc/source/alevin.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst:5749,Availability,avail,available,5749,"en goes through both the barcode and ; read files in unison to assign reads to cells using the initial barcode mapping. Since the pipe or the input ; stream can't be reset to read from the beginning again, alevin can't read in the barcodes, and might crash. Description of important options; --------------------------------. Alevin exposes a number of useful optional command-line parameters to the user.; The particularly important ones are explained here, but you can always run; ``salmon alevin -h`` to see them all. """"""""""""""""""""""""""""""""""""""""""""""""""""; ``-p`` / ``--numThreads``; """""""""""""""""""""""""""""""""""""""""""""""""""". The number of threads that will be used for quantification. Alevin is designed to work; well with many threads, so, if you have a sufficient number of processors, larger; values here can speed up the run substantially. In our testing we found that usually 10 threads gives the best time-memory trade-off. .. note:: Default number of threads. 	The default behavior is for Alevin to probe the number of available hardware threads and to use this number.; Thus, if you want to use fewer threads (e.g., if you are running multiple; instances of Salmon simultaneously), you will likely want to set this option explicitly in ; accordance with the desired per-process resource usage.; ; """"""""""""""""""""""""; ``--whitelist``; """""""""""""""""""""""". This is an optional argument, where user can explicitly specify the whitelist CB to use for cell detection and CB sequence correction. If not given, alevin generates its own set of putative CBs. .. note:: Not 10x 737k whitelist. This flag does not use the technologically defined whitelisted cellular barcodes provided by 10x, instead it's a per experiment level list of subsampled cellular barcodes that need to quantified for consistency with other tools for example an input would be a file generated by cellranger with the name `barcodes.tsv` (uncompressed). """"""""""""""""""""""""; ``--noQuant``; """""""""""""""""""""""". Generally used in parallel with ``--dumpfq``. If Alevin is passed",MatchSource.DOCS,doc/source/alevin.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst:7582,Availability,down,down,7582,"a file generated by cellranger with the name `barcodes.tsv` (uncompressed). """"""""""""""""""""""""; ``--noQuant``; """""""""""""""""""""""". Generally used in parallel with ``--dumpfq``. If Alevin is passed the ``--noQuant`` option, the pipeline will stop before starting the mapping. The general use-case is when we only need to concatenate the CB on the read-id of the second file and break the execution afterwards. """"""""""""""""""""""""; ``--noDedup``; """""""""""""""""""""""". If Alevin is passed the ``--noDedup`` option, the pipeline only performs CB correction, maps the read-sequences to the transcriptome generating the interim data-structure of CB-EqClass-UMI-count. Used in parallel with ``--dumpBarcodeEq`` or ``--dumpBfh`` for the purposes of obtaining raw information or debugging. """"""""""""""""""""""""; ``--mrna``; """""""""""""""""""""""". The list of mitochondrial genes which are to be used as a feature for CB whitelising naive Bayes classification. .. note:: It is generally advisable to not use nuclear mitrochondrial genes in this as they can be both up and/or down regulated which might cancel out the usefulness of this feature. Please check issue `#367 <https://github.com/COMBINE-lab/salmon/issues/367>`_ in salmon repo to know more about it. """"""""""""""""""""""""; ``--rrna``; """""""""""""""""""""""". The list of ribosomal genes which are to be used as a feature for CB whitelising naive Bayes classification. """"""""""""""""""""""""; ``--dumpfq``; """""""""""""""""""""""". Generally used along with ``--noQuant``. If activated, alevin will sequence correct the CB and attach the corrected CB sequence to the read-id in the second file and dumps the result to standard-out (``stdout``). """"""""""""""""""""""""; ``--dumpBfh``; """""""""""""""""""""""". Alevin internally uses a potentially big data-structure to concisely maintain all the required information for quantification. This flags dumps the full CB-EqClass-UMI-count data-structure for the purposed of allowing raw data analysis and debugging. """"""""""""""""""""""""; ``--dumpFeatures``; """""""""""""""""""""""". If activated, alevin dumps all the features use",MatchSource.DOCS,doc/source/alevin.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst:11562,Availability,down,downstream,11562,"te inferential replicates of the experiemnt, `--numCellBootstraps` has to be paired with `--dumpFeatures` which generates a file with name `quants_boot_mat.gz`. The output format is the same as `quants_mat.gz` and we fit the 3D cube of the cell-inference-gene counts in 2D as follows: if an experiment has C cells, G genes and N inferential replicates; alevin output file `quants_boot_mat.gz` would contain C*N rows and G columns while, starting from the top, the first N rows would represent first cell and it's N inferential replicate. For more information on importing and using inferential replicates for single-cell data in generating accurate differential expression analysis, check out `tximport <https://github.com/mikelove/tximport>`_ and our `Swish <https://www.biorxiv.org/content/10.1101/561084v2>`_ paper. """"""""""""""""""""""""""""""""""""""""""""; ``--debug``; """"""""""""""""""""""""""""""""""""""""""""; Alevin peforms intelligent white-listing downstream of the quantification pipeline and has to make some assumptions like chosing a fraction of reads to learn low confidence CB and in turn might erroneously exit -- if the data results in no mapped or deduplicated reads to a CB in low confidence region. The problem doesn’t happen when provided with external whitelist but if there is an error and the user is aware of this being just a warning, the error can be skipped by running Alevin with this flag. """"""""""""""""""""""""""""""""""""""""""""; ``--minScoreFraction``; """""""""""""""""""""""""""""""""""""""""""". This value controls the minimum allowed score for a mapping to be considered valid.; It matters only when ``--validateMappings`` has been passed to Salmon. The maximum; possible score for a fragment is ``ms = read_len * ma`` (or ``ms = (left_read_len + right_read_len) * ma``; for paired-end reads). The argument to ``--minScoreFraction`` determines what fraction of the maximum; score ``s`` a mapping must achieve to be potentially retained. For a minimum score fraction of ``f``, only; mappings with a score > ``f * s`` will be kept. Mappings",MatchSource.DOCS,doc/source/alevin.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst:11908,Availability,error,error,11908,"s: if an experiment has C cells, G genes and N inferential replicates; alevin output file `quants_boot_mat.gz` would contain C*N rows and G columns while, starting from the top, the first N rows would represent first cell and it's N inferential replicate. For more information on importing and using inferential replicates for single-cell data in generating accurate differential expression analysis, check out `tximport <https://github.com/mikelove/tximport>`_ and our `Swish <https://www.biorxiv.org/content/10.1101/561084v2>`_ paper. """"""""""""""""""""""""""""""""""""""""""""; ``--debug``; """"""""""""""""""""""""""""""""""""""""""""; Alevin peforms intelligent white-listing downstream of the quantification pipeline and has to make some assumptions like chosing a fraction of reads to learn low confidence CB and in turn might erroneously exit -- if the data results in no mapped or deduplicated reads to a CB in low confidence region. The problem doesn’t happen when provided with external whitelist but if there is an error and the user is aware of this being just a warning, the error can be skipped by running Alevin with this flag. """"""""""""""""""""""""""""""""""""""""""""; ``--minScoreFraction``; """""""""""""""""""""""""""""""""""""""""""". This value controls the minimum allowed score for a mapping to be considered valid.; It matters only when ``--validateMappings`` has been passed to Salmon. The maximum; possible score for a fragment is ``ms = read_len * ma`` (or ``ms = (left_read_len + right_read_len) * ma``; for paired-end reads). The argument to ``--minScoreFraction`` determines what fraction of the maximum; score ``s`` a mapping must achieve to be potentially retained. For a minimum score fraction of ``f``, only; mappings with a score > ``f * s`` will be kept. Mappings with lower scores will be considered as low-quality,; and will be discarded. It is worth noting that mapping validation uses extension alignment. This means that the read need not; map end-to-end. Instead, the score of the mapping will be the position along the alignment with the; ",MatchSource.DOCS,doc/source/alevin.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst:11970,Availability,error,error,11970,"s: if an experiment has C cells, G genes and N inferential replicates; alevin output file `quants_boot_mat.gz` would contain C*N rows and G columns while, starting from the top, the first N rows would represent first cell and it's N inferential replicate. For more information on importing and using inferential replicates for single-cell data in generating accurate differential expression analysis, check out `tximport <https://github.com/mikelove/tximport>`_ and our `Swish <https://www.biorxiv.org/content/10.1101/561084v2>`_ paper. """"""""""""""""""""""""""""""""""""""""""""; ``--debug``; """"""""""""""""""""""""""""""""""""""""""""; Alevin peforms intelligent white-listing downstream of the quantification pipeline and has to make some assumptions like chosing a fraction of reads to learn low confidence CB and in turn might erroneously exit -- if the data results in no mapped or deduplicated reads to a CB in low confidence region. The problem doesn’t happen when provided with external whitelist but if there is an error and the user is aware of this being just a warning, the error can be skipped by running Alevin with this flag. """"""""""""""""""""""""""""""""""""""""""""; ``--minScoreFraction``; """""""""""""""""""""""""""""""""""""""""""". This value controls the minimum allowed score for a mapping to be considered valid.; It matters only when ``--validateMappings`` has been passed to Salmon. The maximum; possible score for a fragment is ``ms = read_len * ma`` (or ``ms = (left_read_len + right_read_len) * ma``; for paired-end reads). The argument to ``--minScoreFraction`` determines what fraction of the maximum; score ``s`` a mapping must achieve to be potentially retained. For a minimum score fraction of ``f``, only; mappings with a score > ``f * s`` will be kept. Mappings with lower scores will be considered as low-quality,; and will be discarded. It is worth noting that mapping validation uses extension alignment. This means that the read need not; map end-to-end. Instead, the score of the mapping will be the position along the alignment with the; ",MatchSource.DOCS,doc/source/alevin.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst:15048,Availability,down,downstream,15048,"` is performed allowing a maximum hamming distance 2 b/w ``w1`` and read2 substring of w1 length within the required bounds; the first match is returned. . Output; ------. Typical 10x experiment can range form hundreds to tens of thousand of cells -- resulting in huge size of the count-matrices. Traditionally single-cell tools dumps the Cell-v-Gene count matrix in various formats. Although, this itself is an open area of research but by default alevin dumps a per-cell level gene-count matrix in a binary-compressed format with the row and column indexes in a separate file. A typical run of alevin will generate 4 files:. * *quants\_mat.gz* -- Compressed count matrix.; * *quants\_mat\_cols.txt* -- Column Header (Gene-ids) of the matrix.; * *quants\_mat\_rows.txt* -- Row Index (CB-ids) of the matrix.; * *quants\_tier\_mat.gz* -- Tier categorization of the matrix. . .. note:: Working with R packages. Alevin generates multiple metadata files like the hash codes of the reference transcriptome and it's crucial for working with downstream R package like `tximeta <https://bioconductor.org/packages/release/bioc/html/tximeta.html>`_ . Hence along with the above files, it's advisable to keep the complete output folder generated by alevin. . Along with the Cell-v-Gene count matrix, alevin dumps a 3-fold categorization of each estimated count value of a gene(each cell disjointly) in the form of tiers. Tier 1 is the set of genes where all the reads are uniquely mapping. Tier 2 is genes that have ambiguously mapping reads, but connected to unique read evidence as well, that can be used by the EM to resolve the multimapping reads. Tier 3 is the genes that have no unique evidence and the read counts are, therefore, distributed between these genes according to an uninformative prior. Alevin can also dump the count-matrix in a human readable -- matrix-market-exchange (_mtx_) format, if given flag `--dumpMtx` which generates a new output file called `quants_mat.mtx`. Output Quality Check",MatchSource.DOCS,doc/source/alevin.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst:16644,Availability,down,downstream,16644,"timapping reads. Tier 3 is the genes that have no unique evidence and the read counts are, therefore, distributed between these genes according to an uninformative prior. Alevin can also dump the count-matrix in a human readable -- matrix-market-exchange (_mtx_) format, if given flag `--dumpMtx` which generates a new output file called `quants_mat.mtx`. Output Quality Check; -------------. Alevin generated gene-count matrix can be visualized for various quality checks using `alevinQC <https://csoneson.github.io/alevinQC/>`_ , a shiny based R package and it is actively supported by `Charlotte Soneson <https://csoneson.github.io/>`_. Tutorial & Parsers; ------------------. We have compiled a step-by-step resource to help get started with aleivn. We have tutorials on how to get input, run and generate output using alevin's framework which can be found here at `Alevin Tutorials <https://combine-lab.github.io/alevin-tutorial/#blog>`_.; The tutorial also covers the topic of integrating alevin with downstream analysis tools like Seurat and Monocle. If you are interested in parsing various output binary formats like `quants_mat.gz`, `quants_tier_mat.gz`, `cell_umigraph.gz` etc. of alevin in python, checkout our companion repo for `python parsing <https://github.com/k3yavi/vpolo/blob/master/vpolo/alevin/parser.py>`_. This repo is also available on pip and can be installed through `pip install vpolo`. We cover how to use this library on our alevin-tutorial website too. Alevin Logs; ------------. Alevin generates `alevin_meta_info.json` file with the following json entries. Please note based on the command line flags provided during the time alevin was run, some of the below json entries may not be present. * total_reads -- Total number of reads in the experiment as observed by alevin.; * reads_with_N -- Total number of reads with at least one nucleotide `N` in their cellular barcode sequence (and are not used for quantification).; * noisy_cb_reads -- Total number of reads fro",MatchSource.DOCS,doc/source/alevin.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst:16985,Availability,avail,available,16985,"Check; -------------. Alevin generated gene-count matrix can be visualized for various quality checks using `alevinQC <https://csoneson.github.io/alevinQC/>`_ , a shiny based R package and it is actively supported by `Charlotte Soneson <https://csoneson.github.io/>`_. Tutorial & Parsers; ------------------. We have compiled a step-by-step resource to help get started with aleivn. We have tutorials on how to get input, run and generate output using alevin's framework which can be found here at `Alevin Tutorials <https://combine-lab.github.io/alevin-tutorial/#blog>`_.; The tutorial also covers the topic of integrating alevin with downstream analysis tools like Seurat and Monocle. If you are interested in parsing various output binary formats like `quants_mat.gz`, `quants_tier_mat.gz`, `cell_umigraph.gz` etc. of alevin in python, checkout our companion repo for `python parsing <https://github.com/k3yavi/vpolo/blob/master/vpolo/alevin/parser.py>`_. This repo is also available on pip and can be installed through `pip install vpolo`. We cover how to use this library on our alevin-tutorial website too. Alevin Logs; ------------. Alevin generates `alevin_meta_info.json` file with the following json entries. Please note based on the command line flags provided during the time alevin was run, some of the below json entries may not be present. * total_reads -- Total number of reads in the experiment as observed by alevin.; * reads_with_N -- Total number of reads with at least one nucleotide `N` in their cellular barcode sequence (and are not used for quantification).; * noisy_cb_reads -- Total number of reads from noisy cellular barcodes (and are not used for quantification). A cellular barcode can be marked noisy based on many different conditions, for example all the barcodes below ""knee"" threshold or all the barcodes below provided threshold on `--expectCells` / `--forceCells`.; * noisy_umi_reads -- Total number of reads with at least one nucleotide `N` in their UMI sequence",MatchSource.DOCS,doc/source/alevin.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst:19483,Availability,avail,available,19483,"by alevin for the quantification.; * initial_whitelist -- Total number of whitelisted cellular barcodes by ""knee"" based thresholding.; * low_conf_cbs -- Total number of low confidence cellular barcodes quantified for intelligent whitelisting.; * num_features -- Total number of features used intelligent whitelisting of the cellular barcodes.; * final_num_cbs -- Total number of cellular barcodes present in the output quant matrix.; * deduplicated_umis -- Total number of UMIs present in the experiment post UMI deduplication across all cells.; * mean_umis_per_cell -- Mean of the number of UMIs (post deduplication) present in each cell.; * mean_genes_per_cell -- Mean of the number of genes expressed (>0 counts) in each cell.; * no_read_mapping_cbs -- Total number of cellular barcodes with no reads mapped to them.; * num_bootstraps -- Total number of bootstrap inferential replicates generated for each cell. Misc; ----. **Finally**, the purpose of making this software available is because we believe; it may be useful for people dealing with single-cell RNA-seq data. We want the; software to be as useful, robust, and accurate as possible. So, if you have any; feedback --- something useful to report, or just some interesting ideas or; suggestions --- please contact us (`asrivastava@cs.stonybrook.edu` and/or; `rob.patro@cs.stonybrook.edu`). If you encounter any bugs, please file a; *detailed* bug report at the `Salmon GitHub repository; <https://github.com/COMBINE-lab/salmon>`_. .. The paper describing this method is published in BioArxiv XXXX. (update this when it appears). BibTex; ----; | @article{srivastava2019alevin,; | title={Alevin efficiently estimates accurate gene abundances from dscRNA-seq data},; | author={Srivastava, Avi and Malik, Laraib and Smith, Tom and Sudbery, Ian and Patro, Rob},; | journal={Genome biology},; | volume={20},; | number={1},; | pages={65},; | year={2019},; | publisher={BioMed Central}; | }. | @article{Srivastava2020,; | doi = {10.1093/bioinform",MatchSource.DOCS,doc/source/alevin.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst:19622,Availability,robust,robust,19622,"e"" based thresholding.; * low_conf_cbs -- Total number of low confidence cellular barcodes quantified for intelligent whitelisting.; * num_features -- Total number of features used intelligent whitelisting of the cellular barcodes.; * final_num_cbs -- Total number of cellular barcodes present in the output quant matrix.; * deduplicated_umis -- Total number of UMIs present in the experiment post UMI deduplication across all cells.; * mean_umis_per_cell -- Mean of the number of UMIs (post deduplication) present in each cell.; * mean_genes_per_cell -- Mean of the number of genes expressed (>0 counts) in each cell.; * no_read_mapping_cbs -- Total number of cellular barcodes with no reads mapped to them.; * num_bootstraps -- Total number of bootstrap inferential replicates generated for each cell. Misc; ----. **Finally**, the purpose of making this software available is because we believe; it may be useful for people dealing with single-cell RNA-seq data. We want the; software to be as useful, robust, and accurate as possible. So, if you have any; feedback --- something useful to report, or just some interesting ideas or; suggestions --- please contact us (`asrivastava@cs.stonybrook.edu` and/or; `rob.patro@cs.stonybrook.edu`). If you encounter any bugs, please file a; *detailed* bug report at the `Salmon GitHub repository; <https://github.com/COMBINE-lab/salmon>`_. .. The paper describing this method is published in BioArxiv XXXX. (update this when it appears). BibTex; ----; | @article{srivastava2019alevin,; | title={Alevin efficiently estimates accurate gene abundances from dscRNA-seq data},; | author={Srivastava, Avi and Malik, Laraib and Smith, Tom and Sudbery, Ian and Patro, Rob},; | journal={Genome biology},; | volume={20},; | number={1},; | pages={65},; | year={2019},; | publisher={BioMed Central}; | }. | @article{Srivastava2020,; | doi = {10.1093/bioinformatics/btaa450},; | url = {https://doi.org/10.1093/bioinformatics/btaa450},; | year = {2020},; | month = jul,; |",MatchSource.DOCS,doc/source/alevin.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst:47,Deployability,integrat,integrated,47,"Alevin; ================. Alevin is a tool --- integrated with the salmon software --- that introduces a family of algorithms for quantification and analysis of 3' tagged-end single-cell sequencing data. Currently alevin supports the following single-cell protocols:. 1. Drop-seq; 2. 10x-Chromium v1/2/3; 3. inDropV2; 4. CELSeq 1/2; 5. Quartz-Seq2; 6. sci-RNA-seq3. Alevin works under the same indexing scheme (as salmon) for the reference, and consumes the set of FASTA/Q files(s) containing the Cellular Barcode(CB) + Unique Molecule identifier (UMI) in one read file and the read sequence in the other. Given just the transcriptome and the raw read files, alevin generates a cell-by-gene count matrix (in a fraction of the time compared to other tools). Alevin works in two phases. In the first phase it quickly parses the read file containing the CB and UMI information to generate the frequency distribution of all the observed CBs, and creates a lightweight data-structure for fast-look up and correction of the CB. In the second round, alevin utilizes the read-sequences contained in the files to map the reads to the transcriptome, identify potential PCR/sequencing errors in the UMIs, and performs hybrid de-duplication while accounting for UMI collisions. Finally, a post-abundance estimation CB whitelisting procedure is done and a cell-by-gene count matrix is generated. Using Alevin; ------------. Alevin requires the following minimal set of necessary input parameters (generally providing the flags *in that order* is recommended):. * ``-l``: library type (same as salmon), we recommend using `ISR` for both Drop-seq and 10x-v2 chemistry.; * ``-1``: CB+UMI file(s), alevin requires the path to the *FASTQ* file containing CB+UMI raw sequences to be given under this command line flag. Alevin also supports parsing of data from multiple files as long as the order is the same as in `-2` flag.; * ``-2``: Read-sequence file(s), alevin requires the path to the *FASTQ* file containing raw ",MatchSource.DOCS,doc/source/alevin.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst:6775,Deployability,pipeline,pipeline,6775,"ds and to use this number.; Thus, if you want to use fewer threads (e.g., if you are running multiple; instances of Salmon simultaneously), you will likely want to set this option explicitly in ; accordance with the desired per-process resource usage.; ; """"""""""""""""""""""""; ``--whitelist``; """""""""""""""""""""""". This is an optional argument, where user can explicitly specify the whitelist CB to use for cell detection and CB sequence correction. If not given, alevin generates its own set of putative CBs. .. note:: Not 10x 737k whitelist. This flag does not use the technologically defined whitelisted cellular barcodes provided by 10x, instead it's a per experiment level list of subsampled cellular barcodes that need to quantified for consistency with other tools for example an input would be a file generated by cellranger with the name `barcodes.tsv` (uncompressed). """"""""""""""""""""""""; ``--noQuant``; """""""""""""""""""""""". Generally used in parallel with ``--dumpfq``. If Alevin is passed the ``--noQuant`` option, the pipeline will stop before starting the mapping. The general use-case is when we only need to concatenate the CB on the read-id of the second file and break the execution afterwards. """"""""""""""""""""""""; ``--noDedup``; """""""""""""""""""""""". If Alevin is passed the ``--noDedup`` option, the pipeline only performs CB correction, maps the read-sequences to the transcriptome generating the interim data-structure of CB-EqClass-UMI-count. Used in parallel with ``--dumpBarcodeEq`` or ``--dumpBfh`` for the purposes of obtaining raw information or debugging. """"""""""""""""""""""""; ``--mrna``; """""""""""""""""""""""". The list of mitochondrial genes which are to be used as a feature for CB whitelising naive Bayes classification. .. note:: It is generally advisable to not use nuclear mitrochondrial genes in this as they can be both up and/or down regulated which might cancel out the usefulness of this feature. Please check issue `#367 <https://github.com/COMBINE-lab/salmon/issues/367>`_ in salmon repo to know more about it. """"""""""",MatchSource.DOCS,doc/source/alevin.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst:7050,Deployability,pipeline,pipeline,7050,"ment, where user can explicitly specify the whitelist CB to use for cell detection and CB sequence correction. If not given, alevin generates its own set of putative CBs. .. note:: Not 10x 737k whitelist. This flag does not use the technologically defined whitelisted cellular barcodes provided by 10x, instead it's a per experiment level list of subsampled cellular barcodes that need to quantified for consistency with other tools for example an input would be a file generated by cellranger with the name `barcodes.tsv` (uncompressed). """"""""""""""""""""""""; ``--noQuant``; """""""""""""""""""""""". Generally used in parallel with ``--dumpfq``. If Alevin is passed the ``--noQuant`` option, the pipeline will stop before starting the mapping. The general use-case is when we only need to concatenate the CB on the read-id of the second file and break the execution afterwards. """"""""""""""""""""""""; ``--noDedup``; """""""""""""""""""""""". If Alevin is passed the ``--noDedup`` option, the pipeline only performs CB correction, maps the read-sequences to the transcriptome generating the interim data-structure of CB-EqClass-UMI-count. Used in parallel with ``--dumpBarcodeEq`` or ``--dumpBfh`` for the purposes of obtaining raw information or debugging. """"""""""""""""""""""""; ``--mrna``; """""""""""""""""""""""". The list of mitochondrial genes which are to be used as a feature for CB whitelising naive Bayes classification. .. note:: It is generally advisable to not use nuclear mitrochondrial genes in this as they can be both up and/or down regulated which might cancel out the usefulness of this feature. Please check issue `#367 <https://github.com/COMBINE-lab/salmon/issues/367>`_ in salmon repo to know more about it. """"""""""""""""""""""""; ``--rrna``; """""""""""""""""""""""". The list of ribosomal genes which are to be used as a feature for CB whitelising naive Bayes classification. """"""""""""""""""""""""; ``--dumpfq``; """""""""""""""""""""""". Generally used along with ``--noQuant``. If activated, alevin will sequence correct the CB and attach the corrected CB sequence to the rea",MatchSource.DOCS,doc/source/alevin.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst:11595,Deployability,pipeline,pipeline,11595,"te inferential replicates of the experiemnt, `--numCellBootstraps` has to be paired with `--dumpFeatures` which generates a file with name `quants_boot_mat.gz`. The output format is the same as `quants_mat.gz` and we fit the 3D cube of the cell-inference-gene counts in 2D as follows: if an experiment has C cells, G genes and N inferential replicates; alevin output file `quants_boot_mat.gz` would contain C*N rows and G columns while, starting from the top, the first N rows would represent first cell and it's N inferential replicate. For more information on importing and using inferential replicates for single-cell data in generating accurate differential expression analysis, check out `tximport <https://github.com/mikelove/tximport>`_ and our `Swish <https://www.biorxiv.org/content/10.1101/561084v2>`_ paper. """"""""""""""""""""""""""""""""""""""""""""; ``--debug``; """"""""""""""""""""""""""""""""""""""""""""; Alevin peforms intelligent white-listing downstream of the quantification pipeline and has to make some assumptions like chosing a fraction of reads to learn low confidence CB and in turn might erroneously exit -- if the data results in no mapped or deduplicated reads to a CB in low confidence region. The problem doesn’t happen when provided with external whitelist but if there is an error and the user is aware of this being just a warning, the error can be skipped by running Alevin with this flag. """"""""""""""""""""""""""""""""""""""""""""; ``--minScoreFraction``; """""""""""""""""""""""""""""""""""""""""""". This value controls the minimum allowed score for a mapping to be considered valid.; It matters only when ``--validateMappings`` has been passed to Salmon. The maximum; possible score for a fragment is ``ms = read_len * ma`` (or ``ms = (left_read_len + right_read_len) * ma``; for paired-end reads). The argument to ``--minScoreFraction`` determines what fraction of the maximum; score ``s`` a mapping must achieve to be potentially retained. For a minimum score fraction of ``f``, only; mappings with a score > ``f * s`` will be kept. Mappings",MatchSource.DOCS,doc/source/alevin.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst:15118,Deployability,release,release,15118,"uired bounds; the first match is returned. . Output; ------. Typical 10x experiment can range form hundreds to tens of thousand of cells -- resulting in huge size of the count-matrices. Traditionally single-cell tools dumps the Cell-v-Gene count matrix in various formats. Although, this itself is an open area of research but by default alevin dumps a per-cell level gene-count matrix in a binary-compressed format with the row and column indexes in a separate file. A typical run of alevin will generate 4 files:. * *quants\_mat.gz* -- Compressed count matrix.; * *quants\_mat\_cols.txt* -- Column Header (Gene-ids) of the matrix.; * *quants\_mat\_rows.txt* -- Row Index (CB-ids) of the matrix.; * *quants\_tier\_mat.gz* -- Tier categorization of the matrix. . .. note:: Working with R packages. Alevin generates multiple metadata files like the hash codes of the reference transcriptome and it's crucial for working with downstream R package like `tximeta <https://bioconductor.org/packages/release/bioc/html/tximeta.html>`_ . Hence along with the above files, it's advisable to keep the complete output folder generated by alevin. . Along with the Cell-v-Gene count matrix, alevin dumps a 3-fold categorization of each estimated count value of a gene(each cell disjointly) in the form of tiers. Tier 1 is the set of genes where all the reads are uniquely mapping. Tier 2 is genes that have ambiguously mapping reads, but connected to unique read evidence as well, that can be used by the EM to resolve the multimapping reads. Tier 3 is the genes that have no unique evidence and the read counts are, therefore, distributed between these genes according to an uninformative prior. Alevin can also dump the count-matrix in a human readable -- matrix-market-exchange (_mtx_) format, if given flag `--dumpMtx` which generates a new output file called `quants_mat.mtx`. Output Quality Check; -------------. Alevin generated gene-count matrix can be visualized for various quality checks using `alevinQC",MatchSource.DOCS,doc/source/alevin.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst:16620,Deployability,integrat,integrating,16620,"timapping reads. Tier 3 is the genes that have no unique evidence and the read counts are, therefore, distributed between these genes according to an uninformative prior. Alevin can also dump the count-matrix in a human readable -- matrix-market-exchange (_mtx_) format, if given flag `--dumpMtx` which generates a new output file called `quants_mat.mtx`. Output Quality Check; -------------. Alevin generated gene-count matrix can be visualized for various quality checks using `alevinQC <https://csoneson.github.io/alevinQC/>`_ , a shiny based R package and it is actively supported by `Charlotte Soneson <https://csoneson.github.io/>`_. Tutorial & Parsers; ------------------. We have compiled a step-by-step resource to help get started with aleivn. We have tutorials on how to get input, run and generate output using alevin's framework which can be found here at `Alevin Tutorials <https://combine-lab.github.io/alevin-tutorial/#blog>`_.; The tutorial also covers the topic of integrating alevin with downstream analysis tools like Seurat and Monocle. If you are interested in parsing various output binary formats like `quants_mat.gz`, `quants_tier_mat.gz`, `cell_umigraph.gz` etc. of alevin in python, checkout our companion repo for `python parsing <https://github.com/k3yavi/vpolo/blob/master/vpolo/alevin/parser.py>`_. This repo is also available on pip and can be installed through `pip install vpolo`. We cover how to use this library on our alevin-tutorial website too. Alevin Logs; ------------. Alevin generates `alevin_meta_info.json` file with the following json entries. Please note based on the command line flags provided during the time alevin was run, some of the below json entries may not be present. * total_reads -- Total number of reads in the experiment as observed by alevin.; * reads_with_N -- Total number of reads with at least one nucleotide `N` in their cellular barcode sequence (and are not used for quantification).; * noisy_cb_reads -- Total number of reads fro",MatchSource.DOCS,doc/source/alevin.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst:17013,Deployability,install,installed,17013,"Check; -------------. Alevin generated gene-count matrix can be visualized for various quality checks using `alevinQC <https://csoneson.github.io/alevinQC/>`_ , a shiny based R package and it is actively supported by `Charlotte Soneson <https://csoneson.github.io/>`_. Tutorial & Parsers; ------------------. We have compiled a step-by-step resource to help get started with aleivn. We have tutorials on how to get input, run and generate output using alevin's framework which can be found here at `Alevin Tutorials <https://combine-lab.github.io/alevin-tutorial/#blog>`_.; The tutorial also covers the topic of integrating alevin with downstream analysis tools like Seurat and Monocle. If you are interested in parsing various output binary formats like `quants_mat.gz`, `quants_tier_mat.gz`, `cell_umigraph.gz` etc. of alevin in python, checkout our companion repo for `python parsing <https://github.com/k3yavi/vpolo/blob/master/vpolo/alevin/parser.py>`_. This repo is also available on pip and can be installed through `pip install vpolo`. We cover how to use this library on our alevin-tutorial website too. Alevin Logs; ------------. Alevin generates `alevin_meta_info.json` file with the following json entries. Please note based on the command line flags provided during the time alevin was run, some of the below json entries may not be present. * total_reads -- Total number of reads in the experiment as observed by alevin.; * reads_with_N -- Total number of reads with at least one nucleotide `N` in their cellular barcode sequence (and are not used for quantification).; * noisy_cb_reads -- Total number of reads from noisy cellular barcodes (and are not used for quantification). A cellular barcode can be marked noisy based on many different conditions, for example all the barcodes below ""knee"" threshold or all the barcodes below provided threshold on `--expectCells` / `--forceCells`.; * noisy_umi_reads -- Total number of reads with at least one nucleotide `N` in their UMI sequence",MatchSource.DOCS,doc/source/alevin.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst:17036,Deployability,install,install,17036,"Check; -------------. Alevin generated gene-count matrix can be visualized for various quality checks using `alevinQC <https://csoneson.github.io/alevinQC/>`_ , a shiny based R package and it is actively supported by `Charlotte Soneson <https://csoneson.github.io/>`_. Tutorial & Parsers; ------------------. We have compiled a step-by-step resource to help get started with aleivn. We have tutorials on how to get input, run and generate output using alevin's framework which can be found here at `Alevin Tutorials <https://combine-lab.github.io/alevin-tutorial/#blog>`_.; The tutorial also covers the topic of integrating alevin with downstream analysis tools like Seurat and Monocle. If you are interested in parsing various output binary formats like `quants_mat.gz`, `quants_tier_mat.gz`, `cell_umigraph.gz` etc. of alevin in python, checkout our companion repo for `python parsing <https://github.com/k3yavi/vpolo/blob/master/vpolo/alevin/parser.py>`_. This repo is also available on pip and can be installed through `pip install vpolo`. We cover how to use this library on our alevin-tutorial website too. Alevin Logs; ------------. Alevin generates `alevin_meta_info.json` file with the following json entries. Please note based on the command line flags provided during the time alevin was run, some of the below json entries may not be present. * total_reads -- Total number of reads in the experiment as observed by alevin.; * reads_with_N -- Total number of reads with at least one nucleotide `N` in their cellular barcode sequence (and are not used for quantification).; * noisy_cb_reads -- Total number of reads from noisy cellular barcodes (and are not used for quantification). A cellular barcode can be marked noisy based on many different conditions, for example all the barcodes below ""knee"" threshold or all the barcodes below provided threshold on `--expectCells` / `--forceCells`.; * noisy_umi_reads -- Total number of reads with at least one nucleotide `N` in their UMI sequence",MatchSource.DOCS,doc/source/alevin.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst:20069,Deployability,update,update,20069,"of the number of UMIs (post deduplication) present in each cell.; * mean_genes_per_cell -- Mean of the number of genes expressed (>0 counts) in each cell.; * no_read_mapping_cbs -- Total number of cellular barcodes with no reads mapped to them.; * num_bootstraps -- Total number of bootstrap inferential replicates generated for each cell. Misc; ----. **Finally**, the purpose of making this software available is because we believe; it may be useful for people dealing with single-cell RNA-seq data. We want the; software to be as useful, robust, and accurate as possible. So, if you have any; feedback --- something useful to report, or just some interesting ideas or; suggestions --- please contact us (`asrivastava@cs.stonybrook.edu` and/or; `rob.patro@cs.stonybrook.edu`). If you encounter any bugs, please file a; *detailed* bug report at the `Salmon GitHub repository; <https://github.com/COMBINE-lab/salmon>`_. .. The paper describing this method is published in BioArxiv XXXX. (update this when it appears). BibTex; ----; | @article{srivastava2019alevin,; | title={Alevin efficiently estimates accurate gene abundances from dscRNA-seq data},; | author={Srivastava, Avi and Malik, Laraib and Smith, Tom and Sudbery, Ian and Patro, Rob},; | journal={Genome biology},; | volume={20},; | number={1},; | pages={65},; | year={2019},; | publisher={BioMed Central}; | }. | @article{Srivastava2020,; | doi = {10.1093/bioinformatics/btaa450},; | url = {https://doi.org/10.1093/bioinformatics/btaa450},; | year = {2020},; | month = jul,; | publisher = {Oxford University Press ({OUP})},; | volume = {36},; | number = {Supplement{\_}1},; | pages = {i292--i299},; | author = {Avi Srivastava and Laraib Malik and Hirak Sarkar and Rob Patro},; | title = {A Bayesian framework for inter-cellular information sharing improves {dscRNA}-seq quantification},; | journal = {Bioinformatics}; | }. DOI; ----; * https://doi.org/10.1186/s13059-019-1670-y; * https://doi.org/10.1093/bioinformatics/btaa450. References;",MatchSource.DOCS,doc/source/alevin.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst:22282,Deployability,pipeline,pipelines,22282," Rob},; | journal={Genome biology},; | volume={20},; | number={1},; | pages={65},; | year={2019},; | publisher={BioMed Central}; | }. | @article{Srivastava2020,; | doi = {10.1093/bioinformatics/btaa450},; | url = {https://doi.org/10.1093/bioinformatics/btaa450},; | year = {2020},; | month = jul,; | publisher = {Oxford University Press ({OUP})},; | volume = {36},; | number = {Supplement{\_}1},; | pages = {i292--i299},; | author = {Avi Srivastava and Laraib Malik and Hirak Sarkar and Rob Patro},; | title = {A Bayesian framework for inter-cellular information sharing improves {dscRNA}-seq quantification},; | journal = {Bioinformatics}; | }. DOI; ----; * https://doi.org/10.1186/s13059-019-1670-y; * https://doi.org/10.1093/bioinformatics/btaa450. References; ----------. .. [#swish] Zhu, Anqi, et al. ""Nonparametric expression analysis using inferential replicate counts."" BioRxiv (2019): 561084. .. [#monocle] Qiu, Xiaojie, et al. ""Reversed graph embedding resolves complex single-cell trajectories."" Nature methods 14.10 (2017): 979. .. [#seurat] Butler, Andrew, et al. ""Integrating single-cell transcriptomic data across different conditions, technologies, and species."" Nature biotechnology 36.5 (2018): 411. .. [#dropseq] Macosko, Evan Z., et al. ""Highly parallel genome-wide expression profiling of individual cells using nanoliter droplets."" Cell 161.5 (2015): 1202-1214.; ; .. [#tenx] Zheng, Grace XY, et al. ""Massively parallel digital transcriptional profiling of single cells."" Nature communications 8 (2017): 14049. .. [#salmon] Patro, Rob, et al. ""Salmon provides fast and bias-aware quantification of transcript expression."" Nature Methods (2017). Advanced Online Publication. doi: 10.1038/nmeth.4197. .. [#dropest] Petukhov, Viktor, et al. ""Accurate estimation of molecular counts in droplet-based single-cell RNA-seq experiments."" bioRxiv (2017): 171496. .. [#cellranger] https://support.10xgenomics.com/single-cell-gene-expression/software/pipelines/latest/algorithms/overview; ",MatchSource.DOCS,doc/source/alevin.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst:13435,Energy Efficiency,adapt,adaptor,13435,"mines what fraction of the maximum; score ``s`` a mapping must achieve to be potentially retained. For a minimum score fraction of ``f``, only; mappings with a score > ``f * s`` will be kept. Mappings with lower scores will be considered as low-quality,; and will be discarded. It is worth noting that mapping validation uses extension alignment. This means that the read need not; map end-to-end. Instead, the score of the mapping will be the position along the alignment with the; highest score. This is the score which must reach the fraction threshold for the read to be considered; as valid. Single-cell protocol specific notes; ------------------------------------. In cases where single-cell protocol supports variable length cellbarcodes, alevin adds nucleotide padding to make the lengths uniform.; Furthermore, the padding scheme ensures that there are no collisions added in the process. The padding scheme is as follows:. 1. sci-RNA-seq3: The barcode is composed of 9-10 bp hairpin adaptor and 10 bp reverse transcription index making it 19-20 bp long. If the bacode is 20 bp long, alevin adds *A* and it adds *AC* if it is 19 bp long. Thus, the length of barcode in the output is 21 bp.; 2. inDropV2: 8-11 bp barcode1 along with 8 bp barcode2 makes up the barcode. For barcode lengths of 16, 17, 18, and 19 bp, alevin adds *AAAC*, *AAG*, *AT*, and *A* respectively. Thus, the length of barcode in the output is 20 bp. Furthermore, the position of barcode1 is dependent on finding exact match of sequence ``w1``. If exact match is not found, a search for ``w1`` is performed allowing a maximum hamming distance 2 b/w ``w1`` and read2 substring of w1 length within the required bounds; the first match is returned. . Output; ------. Typical 10x experiment can range form hundreds to tens of thousand of cells -- resulting in huge size of the count-matrices. Traditionally single-cell tools dumps the Cell-v-Gene count matrix in various formats. Although, this itself is an open area of res",MatchSource.DOCS,doc/source/alevin.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst:20163,Energy Efficiency,efficient,efficiently,20163," of cellular barcodes with no reads mapped to them.; * num_bootstraps -- Total number of bootstrap inferential replicates generated for each cell. Misc; ----. **Finally**, the purpose of making this software available is because we believe; it may be useful for people dealing with single-cell RNA-seq data. We want the; software to be as useful, robust, and accurate as possible. So, if you have any; feedback --- something useful to report, or just some interesting ideas or; suggestions --- please contact us (`asrivastava@cs.stonybrook.edu` and/or; `rob.patro@cs.stonybrook.edu`). If you encounter any bugs, please file a; *detailed* bug report at the `Salmon GitHub repository; <https://github.com/COMBINE-lab/salmon>`_. .. The paper describing this method is published in BioArxiv XXXX. (update this when it appears). BibTex; ----; | @article{srivastava2019alevin,; | title={Alevin efficiently estimates accurate gene abundances from dscRNA-seq data},; | author={Srivastava, Avi and Malik, Laraib and Smith, Tom and Sudbery, Ian and Patro, Rob},; | journal={Genome biology},; | volume={20},; | number={1},; | pages={65},; | year={2019},; | publisher={BioMed Central}; | }. | @article{Srivastava2020,; | doi = {10.1093/bioinformatics/btaa450},; | url = {https://doi.org/10.1093/bioinformatics/btaa450},; | year = {2020},; | month = jul,; | publisher = {Oxford University Press ({OUP})},; | volume = {36},; | number = {Supplement{\_}1},; | pages = {i292--i299},; | author = {Avi Srivastava and Laraib Malik and Hirak Sarkar and Rob Patro},; | title = {A Bayesian framework for inter-cellular information sharing improves {dscRNA}-seq quantification},; | journal = {Bioinformatics}; | }. DOI; ----; * https://doi.org/10.1186/s13059-019-1670-y; * https://doi.org/10.1093/bioinformatics/btaa450. References; ----------. .. [#swish] Zhu, Anqi, et al. ""Nonparametric expression analysis using inferential replicate counts."" BioRxiv (2019): 561084. .. [#monocle] Qiu, Xiaojie, et al. ""Reversed graph emb",MatchSource.DOCS,doc/source/alevin.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst:47,Integrability,integrat,integrated,47,"Alevin; ================. Alevin is a tool --- integrated with the salmon software --- that introduces a family of algorithms for quantification and analysis of 3' tagged-end single-cell sequencing data. Currently alevin supports the following single-cell protocols:. 1. Drop-seq; 2. 10x-Chromium v1/2/3; 3. inDropV2; 4. CELSeq 1/2; 5. Quartz-Seq2; 6. sci-RNA-seq3. Alevin works under the same indexing scheme (as salmon) for the reference, and consumes the set of FASTA/Q files(s) containing the Cellular Barcode(CB) + Unique Molecule identifier (UMI) in one read file and the read sequence in the other. Given just the transcriptome and the raw read files, alevin generates a cell-by-gene count matrix (in a fraction of the time compared to other tools). Alevin works in two phases. In the first phase it quickly parses the read file containing the CB and UMI information to generate the frequency distribution of all the observed CBs, and creates a lightweight data-structure for fast-look up and correction of the CB. In the second round, alevin utilizes the read-sequences contained in the files to map the reads to the transcriptome, identify potential PCR/sequencing errors in the UMIs, and performs hybrid de-duplication while accounting for UMI collisions. Finally, a post-abundance estimation CB whitelisting procedure is done and a cell-by-gene count matrix is generated. Using Alevin; ------------. Alevin requires the following minimal set of necessary input parameters (generally providing the flags *in that order* is recommended):. * ``-l``: library type (same as salmon), we recommend using `ISR` for both Drop-seq and 10x-v2 chemistry.; * ``-1``: CB+UMI file(s), alevin requires the path to the *FASTQ* file containing CB+UMI raw sequences to be given under this command line flag. Alevin also supports parsing of data from multiple files as long as the order is the same as in `-2` flag.; * ``-2``: Read-sequence file(s), alevin requires the path to the *FASTQ* file containing raw ",MatchSource.DOCS,doc/source/alevin.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst:256,Integrability,protocol,protocols,256,"Alevin; ================. Alevin is a tool --- integrated with the salmon software --- that introduces a family of algorithms for quantification and analysis of 3' tagged-end single-cell sequencing data. Currently alevin supports the following single-cell protocols:. 1. Drop-seq; 2. 10x-Chromium v1/2/3; 3. inDropV2; 4. CELSeq 1/2; 5. Quartz-Seq2; 6. sci-RNA-seq3. Alevin works under the same indexing scheme (as salmon) for the reference, and consumes the set of FASTA/Q files(s) containing the Cellular Barcode(CB) + Unique Molecule identifier (UMI) in one read file and the read sequence in the other. Given just the transcriptome and the raw read files, alevin generates a cell-by-gene count matrix (in a fraction of the time compared to other tools). Alevin works in two phases. In the first phase it quickly parses the read file containing the CB and UMI information to generate the frequency distribution of all the observed CBs, and creates a lightweight data-structure for fast-look up and correction of the CB. In the second round, alevin utilizes the read-sequences contained in the files to map the reads to the transcriptome, identify potential PCR/sequencing errors in the UMIs, and performs hybrid de-duplication while accounting for UMI collisions. Finally, a post-abundance estimation CB whitelisting procedure is done and a cell-by-gene count matrix is generated. Using Alevin; ------------. Alevin requires the following minimal set of necessary input parameters (generally providing the flags *in that order* is recommended):. * ``-l``: library type (same as salmon), we recommend using `ISR` for both Drop-seq and 10x-v2 chemistry.; * ``-1``: CB+UMI file(s), alevin requires the path to the *FASTQ* file containing CB+UMI raw sequences to be given under this command line flag. Alevin also supports parsing of data from multiple files as long as the order is the same as in `-2` flag.; * ``-2``: Read-sequence file(s), alevin requires the path to the *FASTQ* file containing raw ",MatchSource.DOCS,doc/source/alevin.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst:2215,Integrability,protocol,protocol,2215,"accounting for UMI collisions. Finally, a post-abundance estimation CB whitelisting procedure is done and a cell-by-gene count matrix is generated. Using Alevin; ------------. Alevin requires the following minimal set of necessary input parameters (generally providing the flags *in that order* is recommended):. * ``-l``: library type (same as salmon), we recommend using `ISR` for both Drop-seq and 10x-v2 chemistry.; * ``-1``: CB+UMI file(s), alevin requires the path to the *FASTQ* file containing CB+UMI raw sequences to be given under this command line flag. Alevin also supports parsing of data from multiple files as long as the order is the same as in `-2` flag.; * ``-2``: Read-sequence file(s), alevin requires the path to the *FASTQ* file containing raw read-sequences to be given under this command line flag. Alevin also supports parsing of data from multiple files as long as the order is the same as in `-1` flag.; * ``--dropseq / --chromium / --chromiumV3``: the protocol, this flag tells the type of single-cell protocol of the input sequencing-library.; * ``-i``: index, file containing the salmon index of the reference transcriptome, as generated by `salmon index` command.; * ``-p``: number of threads, the number of threads which can be used by alevin to perform the quantification, by default alevin utilizes *all* the available threads in the system, although we recommend using ~10 threads which in our testing gave the best memory-time trade-off.; * ``-o``: output, path to folder where the output gene-count matrix (along with other meta-data) would be dumped.; * ``--tgMap``: transcript to gene map file, a tsv (tab-separated) file --- with *no header*, containing two columns mapping of each transcript present in the reference to the corresponding gene (the first column is a transcript and the second is the corresponding gene). Once all the above requirement are satisfied, alevin can be run using the following command::. > salmon alevin -l ISR -1 cb.fastq.gz -2 rea",MatchSource.DOCS,doc/source/alevin.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst:2265,Integrability,protocol,protocol,2265,"accounting for UMI collisions. Finally, a post-abundance estimation CB whitelisting procedure is done and a cell-by-gene count matrix is generated. Using Alevin; ------------. Alevin requires the following minimal set of necessary input parameters (generally providing the flags *in that order* is recommended):. * ``-l``: library type (same as salmon), we recommend using `ISR` for both Drop-seq and 10x-v2 chemistry.; * ``-1``: CB+UMI file(s), alevin requires the path to the *FASTQ* file containing CB+UMI raw sequences to be given under this command line flag. Alevin also supports parsing of data from multiple files as long as the order is the same as in `-2` flag.; * ``-2``: Read-sequence file(s), alevin requires the path to the *FASTQ* file containing raw read-sequences to be given under this command line flag. Alevin also supports parsing of data from multiple files as long as the order is the same as in `-1` flag.; * ``--dropseq / --chromium / --chromiumV3``: the protocol, this flag tells the type of single-cell protocol of the input sequencing-library.; * ``-i``: index, file containing the salmon index of the reference transcriptome, as generated by `salmon index` command.; * ``-p``: number of threads, the number of threads which can be used by alevin to perform the quantification, by default alevin utilizes *all* the available threads in the system, although we recommend using ~10 threads which in our testing gave the best memory-time trade-off.; * ``-o``: output, path to folder where the output gene-count matrix (along with other meta-data) would be dumped.; * ``--tgMap``: transcript to gene map file, a tsv (tab-separated) file --- with *no header*, containing two columns mapping of each transcript present in the reference to the corresponding gene (the first column is a transcript and the second is the corresponding gene). Once all the above requirement are satisfied, alevin can be run using the following command::. > salmon alevin -l ISR -1 cb.fastq.gz -2 rea",MatchSource.DOCS,doc/source/alevin.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst:13050,Integrability,protocol,protocol,13050,""""""""""""""""""""""""""""""""""""""""""". This value controls the minimum allowed score for a mapping to be considered valid.; It matters only when ``--validateMappings`` has been passed to Salmon. The maximum; possible score for a fragment is ``ms = read_len * ma`` (or ``ms = (left_read_len + right_read_len) * ma``; for paired-end reads). The argument to ``--minScoreFraction`` determines what fraction of the maximum; score ``s`` a mapping must achieve to be potentially retained. For a minimum score fraction of ``f``, only; mappings with a score > ``f * s`` will be kept. Mappings with lower scores will be considered as low-quality,; and will be discarded. It is worth noting that mapping validation uses extension alignment. This means that the read need not; map end-to-end. Instead, the score of the mapping will be the position along the alignment with the; highest score. This is the score which must reach the fraction threshold for the read to be considered; as valid. Single-cell protocol specific notes; ------------------------------------. In cases where single-cell protocol supports variable length cellbarcodes, alevin adds nucleotide padding to make the lengths uniform.; Furthermore, the padding scheme ensures that there are no collisions added in the process. The padding scheme is as follows:. 1. sci-RNA-seq3: The barcode is composed of 9-10 bp hairpin adaptor and 10 bp reverse transcription index making it 19-20 bp long. If the bacode is 20 bp long, alevin adds *A* and it adds *AC* if it is 19 bp long. Thus, the length of barcode in the output is 21 bp.; 2. inDropV2: 8-11 bp barcode1 along with 8 bp barcode2 makes up the barcode. For barcode lengths of 16, 17, 18, and 19 bp, alevin adds *AAAC*, *AAG*, *AT*, and *A* respectively. Thus, the length of barcode in the output is 20 bp. Furthermore, the position of barcode1 is dependent on finding exact match of sequence ``w1``. If exact match is not found, a search for ``w1`` is performed allowing a maximum hamming distance 2 b/w ``w1`",MatchSource.DOCS,doc/source/alevin.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst:13140,Integrability,protocol,protocol,13140,".; It matters only when ``--validateMappings`` has been passed to Salmon. The maximum; possible score for a fragment is ``ms = read_len * ma`` (or ``ms = (left_read_len + right_read_len) * ma``; for paired-end reads). The argument to ``--minScoreFraction`` determines what fraction of the maximum; score ``s`` a mapping must achieve to be potentially retained. For a minimum score fraction of ``f``, only; mappings with a score > ``f * s`` will be kept. Mappings with lower scores will be considered as low-quality,; and will be discarded. It is worth noting that mapping validation uses extension alignment. This means that the read need not; map end-to-end. Instead, the score of the mapping will be the position along the alignment with the; highest score. This is the score which must reach the fraction threshold for the read to be considered; as valid. Single-cell protocol specific notes; ------------------------------------. In cases where single-cell protocol supports variable length cellbarcodes, alevin adds nucleotide padding to make the lengths uniform.; Furthermore, the padding scheme ensures that there are no collisions added in the process. The padding scheme is as follows:. 1. sci-RNA-seq3: The barcode is composed of 9-10 bp hairpin adaptor and 10 bp reverse transcription index making it 19-20 bp long. If the bacode is 20 bp long, alevin adds *A* and it adds *AC* if it is 19 bp long. Thus, the length of barcode in the output is 21 bp.; 2. inDropV2: 8-11 bp barcode1 along with 8 bp barcode2 makes up the barcode. For barcode lengths of 16, 17, 18, and 19 bp, alevin adds *AAAC*, *AAG*, *AT*, and *A* respectively. Thus, the length of barcode in the output is 20 bp. Furthermore, the position of barcode1 is dependent on finding exact match of sequence ``w1``. If exact match is not found, a search for ``w1`` is performed allowing a maximum hamming distance 2 b/w ``w1`` and read2 substring of w1 length within the required bounds; the first match is returned. . Output; ---",MatchSource.DOCS,doc/source/alevin.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst:13913,Integrability,depend,dependent,13913," the; highest score. This is the score which must reach the fraction threshold for the read to be considered; as valid. Single-cell protocol specific notes; ------------------------------------. In cases where single-cell protocol supports variable length cellbarcodes, alevin adds nucleotide padding to make the lengths uniform.; Furthermore, the padding scheme ensures that there are no collisions added in the process. The padding scheme is as follows:. 1. sci-RNA-seq3: The barcode is composed of 9-10 bp hairpin adaptor and 10 bp reverse transcription index making it 19-20 bp long. If the bacode is 20 bp long, alevin adds *A* and it adds *AC* if it is 19 bp long. Thus, the length of barcode in the output is 21 bp.; 2. inDropV2: 8-11 bp barcode1 along with 8 bp barcode2 makes up the barcode. For barcode lengths of 16, 17, 18, and 19 bp, alevin adds *AAAC*, *AAG*, *AT*, and *A* respectively. Thus, the length of barcode in the output is 20 bp. Furthermore, the position of barcode1 is dependent on finding exact match of sequence ``w1``. If exact match is not found, a search for ``w1`` is performed allowing a maximum hamming distance 2 b/w ``w1`` and read2 substring of w1 length within the required bounds; the first match is returned. . Output; ------. Typical 10x experiment can range form hundreds to tens of thousand of cells -- resulting in huge size of the count-matrices. Traditionally single-cell tools dumps the Cell-v-Gene count matrix in various formats. Although, this itself is an open area of research but by default alevin dumps a per-cell level gene-count matrix in a binary-compressed format with the row and column indexes in a separate file. A typical run of alevin will generate 4 files:. * *quants\_mat.gz* -- Compressed count matrix.; * *quants\_mat\_cols.txt* -- Column Header (Gene-ids) of the matrix.; * *quants\_mat\_rows.txt* -- Row Index (CB-ids) of the matrix.; * *quants\_tier\_mat.gz* -- Tier categorization of the matrix. . .. note:: Working with R packag",MatchSource.DOCS,doc/source/alevin.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst:16620,Integrability,integrat,integrating,16620,"timapping reads. Tier 3 is the genes that have no unique evidence and the read counts are, therefore, distributed between these genes according to an uninformative prior. Alevin can also dump the count-matrix in a human readable -- matrix-market-exchange (_mtx_) format, if given flag `--dumpMtx` which generates a new output file called `quants_mat.mtx`. Output Quality Check; -------------. Alevin generated gene-count matrix can be visualized for various quality checks using `alevinQC <https://csoneson.github.io/alevinQC/>`_ , a shiny based R package and it is actively supported by `Charlotte Soneson <https://csoneson.github.io/>`_. Tutorial & Parsers; ------------------. We have compiled a step-by-step resource to help get started with aleivn. We have tutorials on how to get input, run and generate output using alevin's framework which can be found here at `Alevin Tutorials <https://combine-lab.github.io/alevin-tutorial/#blog>`_.; The tutorial also covers the topic of integrating alevin with downstream analysis tools like Seurat and Monocle. If you are interested in parsing various output binary formats like `quants_mat.gz`, `quants_tier_mat.gz`, `cell_umigraph.gz` etc. of alevin in python, checkout our companion repo for `python parsing <https://github.com/k3yavi/vpolo/blob/master/vpolo/alevin/parser.py>`_. This repo is also available on pip and can be installed through `pip install vpolo`. We cover how to use this library on our alevin-tutorial website too. Alevin Logs; ------------. Alevin generates `alevin_meta_info.json` file with the following json entries. Please note based on the command line flags provided during the time alevin was run, some of the below json entries may not be present. * total_reads -- Total number of reads in the experiment as observed by alevin.; * reads_with_N -- Total number of reads with at least one nucleotide `N` in their cellular barcode sequence (and are not used for quantification).; * noisy_cb_reads -- Total number of reads fro",MatchSource.DOCS,doc/source/alevin.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst:13158,Modifiability,variab,variable,13158,".; It matters only when ``--validateMappings`` has been passed to Salmon. The maximum; possible score for a fragment is ``ms = read_len * ma`` (or ``ms = (left_read_len + right_read_len) * ma``; for paired-end reads). The argument to ``--minScoreFraction`` determines what fraction of the maximum; score ``s`` a mapping must achieve to be potentially retained. For a minimum score fraction of ``f``, only; mappings with a score > ``f * s`` will be kept. Mappings with lower scores will be considered as low-quality,; and will be discarded. It is worth noting that mapping validation uses extension alignment. This means that the read need not; map end-to-end. Instead, the score of the mapping will be the position along the alignment with the; highest score. This is the score which must reach the fraction threshold for the read to be considered; as valid. Single-cell protocol specific notes; ------------------------------------. In cases where single-cell protocol supports variable length cellbarcodes, alevin adds nucleotide padding to make the lengths uniform.; Furthermore, the padding scheme ensures that there are no collisions added in the process. The padding scheme is as follows:. 1. sci-RNA-seq3: The barcode is composed of 9-10 bp hairpin adaptor and 10 bp reverse transcription index making it 19-20 bp long. If the bacode is 20 bp long, alevin adds *A* and it adds *AC* if it is 19 bp long. Thus, the length of barcode in the output is 21 bp.; 2. inDropV2: 8-11 bp barcode1 along with 8 bp barcode2 makes up the barcode. For barcode lengths of 16, 17, 18, and 19 bp, alevin adds *AAAC*, *AAG*, *AT*, and *A* respectively. Thus, the length of barcode in the output is 20 bp. Furthermore, the position of barcode1 is dependent on finding exact match of sequence ``w1``. If exact match is not found, a search for ``w1`` is performed allowing a maximum hamming distance 2 b/w ``w1`` and read2 substring of w1 length within the required bounds; the first match is returned. . Output; ---",MatchSource.DOCS,doc/source/alevin.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst:13435,Modifiability,adapt,adaptor,13435,"mines what fraction of the maximum; score ``s`` a mapping must achieve to be potentially retained. For a minimum score fraction of ``f``, only; mappings with a score > ``f * s`` will be kept. Mappings with lower scores will be considered as low-quality,; and will be discarded. It is worth noting that mapping validation uses extension alignment. This means that the read need not; map end-to-end. Instead, the score of the mapping will be the position along the alignment with the; highest score. This is the score which must reach the fraction threshold for the read to be considered; as valid. Single-cell protocol specific notes; ------------------------------------. In cases where single-cell protocol supports variable length cellbarcodes, alevin adds nucleotide padding to make the lengths uniform.; Furthermore, the padding scheme ensures that there are no collisions added in the process. The padding scheme is as follows:. 1. sci-RNA-seq3: The barcode is composed of 9-10 bp hairpin adaptor and 10 bp reverse transcription index making it 19-20 bp long. If the bacode is 20 bp long, alevin adds *A* and it adds *AC* if it is 19 bp long. Thus, the length of barcode in the output is 21 bp.; 2. inDropV2: 8-11 bp barcode1 along with 8 bp barcode2 makes up the barcode. For barcode lengths of 16, 17, 18, and 19 bp, alevin adds *AAAC*, *AAG*, *AT*, and *A* respectively. Thus, the length of barcode in the output is 20 bp. Furthermore, the position of barcode1 is dependent on finding exact match of sequence ``w1``. If exact match is not found, a search for ``w1`` is performed allowing a maximum hamming distance 2 b/w ``w1`` and read2 substring of w1 length within the required bounds; the first match is returned. . Output; ------. Typical 10x experiment can range form hundreds to tens of thousand of cells -- resulting in huge size of the count-matrices. Traditionally single-cell tools dumps the Cell-v-Gene count matrix in various formats. Although, this itself is an open area of res",MatchSource.DOCS,doc/source/alevin.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst:1198,Performance,perform,performs,1198,"n and analysis of 3' tagged-end single-cell sequencing data. Currently alevin supports the following single-cell protocols:. 1. Drop-seq; 2. 10x-Chromium v1/2/3; 3. inDropV2; 4. CELSeq 1/2; 5. Quartz-Seq2; 6. sci-RNA-seq3. Alevin works under the same indexing scheme (as salmon) for the reference, and consumes the set of FASTA/Q files(s) containing the Cellular Barcode(CB) + Unique Molecule identifier (UMI) in one read file and the read sequence in the other. Given just the transcriptome and the raw read files, alevin generates a cell-by-gene count matrix (in a fraction of the time compared to other tools). Alevin works in two phases. In the first phase it quickly parses the read file containing the CB and UMI information to generate the frequency distribution of all the observed CBs, and creates a lightweight data-structure for fast-look up and correction of the CB. In the second round, alevin utilizes the read-sequences contained in the files to map the reads to the transcriptome, identify potential PCR/sequencing errors in the UMIs, and performs hybrid de-duplication while accounting for UMI collisions. Finally, a post-abundance estimation CB whitelisting procedure is done and a cell-by-gene count matrix is generated. Using Alevin; ------------. Alevin requires the following minimal set of necessary input parameters (generally providing the flags *in that order* is recommended):. * ``-l``: library type (same as salmon), we recommend using `ISR` for both Drop-seq and 10x-v2 chemistry.; * ``-1``: CB+UMI file(s), alevin requires the path to the *FASTQ* file containing CB+UMI raw sequences to be given under this command line flag. Alevin also supports parsing of data from multiple files as long as the order is the same as in `-2` flag.; * ``-2``: Read-sequence file(s), alevin requires the path to the *FASTQ* file containing raw read-sequences to be given under this command line flag. Alevin also supports parsing of data from multiple files as long as the order is the ",MatchSource.DOCS,doc/source/alevin.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst:2513,Performance,perform,perform,2513,"pe (same as salmon), we recommend using `ISR` for both Drop-seq and 10x-v2 chemistry.; * ``-1``: CB+UMI file(s), alevin requires the path to the *FASTQ* file containing CB+UMI raw sequences to be given under this command line flag. Alevin also supports parsing of data from multiple files as long as the order is the same as in `-2` flag.; * ``-2``: Read-sequence file(s), alevin requires the path to the *FASTQ* file containing raw read-sequences to be given under this command line flag. Alevin also supports parsing of data from multiple files as long as the order is the same as in `-1` flag.; * ``--dropseq / --chromium / --chromiumV3``: the protocol, this flag tells the type of single-cell protocol of the input sequencing-library.; * ``-i``: index, file containing the salmon index of the reference transcriptome, as generated by `salmon index` command.; * ``-p``: number of threads, the number of threads which can be used by alevin to perform the quantification, by default alevin utilizes *all* the available threads in the system, although we recommend using ~10 threads which in our testing gave the best memory-time trade-off.; * ``-o``: output, path to folder where the output gene-count matrix (along with other meta-data) would be dumped.; * ``--tgMap``: transcript to gene map file, a tsv (tab-separated) file --- with *no header*, containing two columns mapping of each transcript present in the reference to the corresponding gene (the first column is a transcript and the second is the corresponding gene). Once all the above requirement are satisfied, alevin can be run using the following command::. > salmon alevin -l ISR -1 cb.fastq.gz -2 reads.fastq.gz --chromium -i salmon_index_directory -p 10 -o alevin_output --tgMap txp2gene.tsv. Providing multiple read files to Alevin; ------------. Often, a single library may be split into multiple FASTA/Q files. Also, sometimes one may wish; to quantify multiple replicates or samples together, treating them as if they are one lib",MatchSource.DOCS,doc/source/alevin.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst:4627,Performance,perform,performs,4627,"r to provide a *space-separated* list of files to all of it's options; that expect input files (i.e. ``-1``, ``-2``). The; order of the files in the left and right lists must be the same. There are a number of ways to; provide alevin with multiple CB and read files, and treat these as a single library. For the examples; below, assume we have two replicates ``lib_A`` and ``lib_B``. The left and right reads for; ``lib_A`` are ``lib_A_cb.fq`` and ``lib_A_reads.fq``, respectively. The left and right reads for; ``lib_B`` are ``lib_B_cb.fq`` and ``lib_B_read.fq``, respectively. The following are both valid; ways to input these reads to alevin::. > salmon alevin -l ISR -1 lib_A_cb.fq lib_B_cb.fq -2 lib_A_read.fq lib_B_read.fq . Similarly, both of these approaches can be adopted if the files are gzipped as well::. > salmon alevin -l ISR -1 lib_A_cb.fq.gz lib_B_cb.fq.gz -2 lib_A_read.fq.gz lib_B_read.fq.gz. .. note:: Don't provide data through input stream; To keep the time-memory trade-off within acceptable bounds, alevin performs multiple passes over the Cellular; Barcode file. Alevin goes through the barcode file once by itself, and then goes through both the barcode and ; read files in unison to assign reads to cells using the initial barcode mapping. Since the pipe or the input ; stream can't be reset to read from the beginning again, alevin can't read in the barcodes, and might crash. Description of important options; --------------------------------. Alevin exposes a number of useful optional command-line parameters to the user.; The particularly important ones are explained here, but you can always run; ``salmon alevin -h`` to see them all. """"""""""""""""""""""""""""""""""""""""""""""""""""; ``-p`` / ``--numThreads``; """""""""""""""""""""""""""""""""""""""""""""""""""". The number of threads that will be used for quantification. Alevin is designed to work; well with many threads, so, if you have a sufficient number of processors, larger; values here can speed up the run substantially. In our testing we found that us",MatchSource.DOCS,doc/source/alevin.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst:7064,Performance,perform,performs,7064,"ment, where user can explicitly specify the whitelist CB to use for cell detection and CB sequence correction. If not given, alevin generates its own set of putative CBs. .. note:: Not 10x 737k whitelist. This flag does not use the technologically defined whitelisted cellular barcodes provided by 10x, instead it's a per experiment level list of subsampled cellular barcodes that need to quantified for consistency with other tools for example an input would be a file generated by cellranger with the name `barcodes.tsv` (uncompressed). """"""""""""""""""""""""; ``--noQuant``; """""""""""""""""""""""". Generally used in parallel with ``--dumpfq``. If Alevin is passed the ``--noQuant`` option, the pipeline will stop before starting the mapping. The general use-case is when we only need to concatenate the CB on the read-id of the second file and break the execution afterwards. """"""""""""""""""""""""; ``--noDedup``; """""""""""""""""""""""". If Alevin is passed the ``--noDedup`` option, the pipeline only performs CB correction, maps the read-sequences to the transcriptome generating the interim data-structure of CB-EqClass-UMI-count. Used in parallel with ``--dumpBarcodeEq`` or ``--dumpBfh`` for the purposes of obtaining raw information or debugging. """"""""""""""""""""""""; ``--mrna``; """""""""""""""""""""""". The list of mitochondrial genes which are to be used as a feature for CB whitelising naive Bayes classification. .. note:: It is generally advisable to not use nuclear mitrochondrial genes in this as they can be both up and/or down regulated which might cancel out the usefulness of this feature. Please check issue `#367 <https://github.com/COMBINE-lab/salmon/issues/367>`_ in salmon repo to know more about it. """"""""""""""""""""""""; ``--rrna``; """""""""""""""""""""""". The list of ribosomal genes which are to be used as a feature for CB whitelising naive Bayes classification. """"""""""""""""""""""""; ``--dumpfq``; """""""""""""""""""""""". Generally used along with ``--noQuant``. If activated, alevin will sequence correct the CB and attach the corrected CB sequence to the rea",MatchSource.DOCS,doc/source/alevin.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst:8967,Performance,perform,performs,8967,"`--noQuant``. If activated, alevin will sequence correct the CB and attach the corrected CB sequence to the read-id in the second file and dumps the result to standard-out (``stdout``). """"""""""""""""""""""""; ``--dumpBfh``; """""""""""""""""""""""". Alevin internally uses a potentially big data-structure to concisely maintain all the required information for quantification. This flags dumps the full CB-EqClass-UMI-count data-structure for the purposed of allowing raw data analysis and debugging. """"""""""""""""""""""""; ``--dumpFeatures``; """""""""""""""""""""""". If activated, alevin dumps all the features used by the CB classification and their counts at each cell level. It's generally used in pair with other command line flags. """"""""""""""""""""""""; ``--dumpMtx``; """""""""""""""""""""""". This flags is used to internally convert the default binary format of alevin for gene-count matrix into a human readable mtx (matrix market exchange) sparse format. . """"""""""""""""""""""""""""""""""""""""""""; ``--forceCells``; """"""""""""""""""""""""""""""""""""""""""""; Alevin performs a heuristic based initial CB white-listing by finding the knee in the distribution of the CB frequency. Although knee finding algorithm works pretty well in most of the case, it sometimes over shoot and results in very less number of CB. With this flag, by looking at the CB frequency distribution, a user can explicitly specify the number of CB to consider for initial white-listing. . """"""""""""""""""""""""""""""""""""""""""""; ``--expectCells``; """"""""""""""""""""""""""""""""""""""""""""; Just like `forceCells` flag, it's yet another way of skipping the knee calculation heuristics, if it's failing. This command line flag uses the cellranger type white-listing procedure. As specified in their algorithm overview page, ""All barcodes whose total UMI counts exceed m/10 are called as cells"", where m is the frequency of the top 1% cells as specified by the parameter of this command line flag. """"""""""""""""""""""""""""""""""""""""""""; ``--numCellBootstraps``; """"""""""""""""""""""""""""""""""""""""""""; Alevin provides an estimate of the inferential uncertainty in the estimation o",MatchSource.DOCS,doc/source/alevin.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst:10024,Performance,perform,performing,10024,"performs a heuristic based initial CB white-listing by finding the knee in the distribution of the CB frequency. Although knee finding algorithm works pretty well in most of the case, it sometimes over shoot and results in very less number of CB. With this flag, by looking at the CB frequency distribution, a user can explicitly specify the number of CB to consider for initial white-listing. . """"""""""""""""""""""""""""""""""""""""""""; ``--expectCells``; """"""""""""""""""""""""""""""""""""""""""""; Just like `forceCells` flag, it's yet another way of skipping the knee calculation heuristics, if it's failing. This command line flag uses the cellranger type white-listing procedure. As specified in their algorithm overview page, ""All barcodes whose total UMI counts exceed m/10 are called as cells"", where m is the frequency of the top 1% cells as specified by the parameter of this command line flag. """"""""""""""""""""""""""""""""""""""""""""; ``--numCellBootstraps``; """"""""""""""""""""""""""""""""""""""""""""; Alevin provides an estimate of the inferential uncertainty in the estimation of per cell level gene count matrix by performing bootstrapping of the reads in per-cell level equivalence classes. This command line flag informs Alevin to perform certain number of bootstrap and generate the mean and variance of the count matrix. This option generates three additional file, namely, `quants_mean_mat.gz`, `quants_var_mat.gz` and `quants_boot_rows.txt`. The format of the files stay the same as `quants_mat.gz` while the row order is saved in `quants_boot_rows.txt` and the column order is stays the same as in file `quants_mat_cols.txt`. .. note:: Alevin can also dump the full bootstrap cell-gene count matrix of a experiment. To generate inferential replicates of the experiemnt, `--numCellBootstraps` has to be paired with `--dumpFeatures` which generates a file with name `quants_boot_mat.gz`. The output format is the same as `quants_mat.gz` and we fit the 3D cube of the cell-inference-gene counts in 2D as follows: if an experiment has C cells, G genes and",MatchSource.DOCS,doc/source/alevin.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst:10142,Performance,perform,perform,10142,"er shoot and results in very less number of CB. With this flag, by looking at the CB frequency distribution, a user can explicitly specify the number of CB to consider for initial white-listing. . """"""""""""""""""""""""""""""""""""""""""""; ``--expectCells``; """"""""""""""""""""""""""""""""""""""""""""; Just like `forceCells` flag, it's yet another way of skipping the knee calculation heuristics, if it's failing. This command line flag uses the cellranger type white-listing procedure. As specified in their algorithm overview page, ""All barcodes whose total UMI counts exceed m/10 are called as cells"", where m is the frequency of the top 1% cells as specified by the parameter of this command line flag. """"""""""""""""""""""""""""""""""""""""""""; ``--numCellBootstraps``; """"""""""""""""""""""""""""""""""""""""""""; Alevin provides an estimate of the inferential uncertainty in the estimation of per cell level gene count matrix by performing bootstrapping of the reads in per-cell level equivalence classes. This command line flag informs Alevin to perform certain number of bootstrap and generate the mean and variance of the count matrix. This option generates three additional file, namely, `quants_mean_mat.gz`, `quants_var_mat.gz` and `quants_boot_rows.txt`. The format of the files stay the same as `quants_mat.gz` while the row order is saved in `quants_boot_rows.txt` and the column order is stays the same as in file `quants_mat_cols.txt`. .. note:: Alevin can also dump the full bootstrap cell-gene count matrix of a experiment. To generate inferential replicates of the experiemnt, `--numCellBootstraps` has to be paired with `--dumpFeatures` which generates a file with name `quants_boot_mat.gz`. The output format is the same as `quants_mat.gz` and we fit the 3D cube of the cell-inference-gene counts in 2D as follows: if an experiment has C cells, G genes and N inferential replicates; alevin output file `quants_boot_mat.gz` would contain C*N rows and G columns while, starting from the top, the first N rows would represent first cell and it's N inferential",MatchSource.DOCS,doc/source/alevin.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst:14018,Performance,perform,performed,14018,"ic notes; ------------------------------------. In cases where single-cell protocol supports variable length cellbarcodes, alevin adds nucleotide padding to make the lengths uniform.; Furthermore, the padding scheme ensures that there are no collisions added in the process. The padding scheme is as follows:. 1. sci-RNA-seq3: The barcode is composed of 9-10 bp hairpin adaptor and 10 bp reverse transcription index making it 19-20 bp long. If the bacode is 20 bp long, alevin adds *A* and it adds *AC* if it is 19 bp long. Thus, the length of barcode in the output is 21 bp.; 2. inDropV2: 8-11 bp barcode1 along with 8 bp barcode2 makes up the barcode. For barcode lengths of 16, 17, 18, and 19 bp, alevin adds *AAAC*, *AAG*, *AT*, and *A* respectively. Thus, the length of barcode in the output is 20 bp. Furthermore, the position of barcode1 is dependent on finding exact match of sequence ``w1``. If exact match is not found, a search for ``w1`` is performed allowing a maximum hamming distance 2 b/w ``w1`` and read2 substring of w1 length within the required bounds; the first match is returned. . Output; ------. Typical 10x experiment can range form hundreds to tens of thousand of cells -- resulting in huge size of the count-matrices. Traditionally single-cell tools dumps the Cell-v-Gene count matrix in various formats. Although, this itself is an open area of research but by default alevin dumps a per-cell level gene-count matrix in a binary-compressed format with the row and column indexes in a separate file. A typical run of alevin will generate 4 files:. * *quants\_mat.gz* -- Compressed count matrix.; * *quants\_mat\_cols.txt* -- Column Header (Gene-ids) of the matrix.; * *quants\_mat\_rows.txt* -- Row Index (CB-ids) of the matrix.; * *quants\_tier\_mat.gz* -- Tier categorization of the matrix. . .. note:: Working with R packages. Alevin generates multiple metadata files like the hash codes of the reference transcriptome and it's crucial for working with downstream R packa",MatchSource.DOCS,doc/source/alevin.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst:6170,Safety,detect,detection,6170," the user.; The particularly important ones are explained here, but you can always run; ``salmon alevin -h`` to see them all. """"""""""""""""""""""""""""""""""""""""""""""""""""; ``-p`` / ``--numThreads``; """""""""""""""""""""""""""""""""""""""""""""""""""". The number of threads that will be used for quantification. Alevin is designed to work; well with many threads, so, if you have a sufficient number of processors, larger; values here can speed up the run substantially. In our testing we found that usually 10 threads gives the best time-memory trade-off. .. note:: Default number of threads. 	The default behavior is for Alevin to probe the number of available hardware threads and to use this number.; Thus, if you want to use fewer threads (e.g., if you are running multiple; instances of Salmon simultaneously), you will likely want to set this option explicitly in ; accordance with the desired per-process resource usage.; ; """"""""""""""""""""""""; ``--whitelist``; """""""""""""""""""""""". This is an optional argument, where user can explicitly specify the whitelist CB to use for cell detection and CB sequence correction. If not given, alevin generates its own set of putative CBs. .. note:: Not 10x 737k whitelist. This flag does not use the technologically defined whitelisted cellular barcodes provided by 10x, instead it's a per experiment level list of subsampled cellular barcodes that need to quantified for consistency with other tools for example an input would be a file generated by cellranger with the name `barcodes.tsv` (uncompressed). """"""""""""""""""""""""; ``--noQuant``; """""""""""""""""""""""". Generally used in parallel with ``--dumpfq``. If Alevin is passed the ``--noQuant`` option, the pipeline will stop before starting the mapping. The general use-case is when we only need to concatenate the CB on the read-id of the second file and break the execution afterwards. """"""""""""""""""""""""; ``--noDedup``; """""""""""""""""""""""". If Alevin is passed the ``--noDedup`` option, the pipeline only performs CB correction, maps the read-sequences to the transcriptome generat",MatchSource.DOCS,doc/source/alevin.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst:5077,Security,expose,exposes,5077,"``lib_B`` are ``lib_B_cb.fq`` and ``lib_B_read.fq``, respectively. The following are both valid; ways to input these reads to alevin::. > salmon alevin -l ISR -1 lib_A_cb.fq lib_B_cb.fq -2 lib_A_read.fq lib_B_read.fq . Similarly, both of these approaches can be adopted if the files are gzipped as well::. > salmon alevin -l ISR -1 lib_A_cb.fq.gz lib_B_cb.fq.gz -2 lib_A_read.fq.gz lib_B_read.fq.gz. .. note:: Don't provide data through input stream; To keep the time-memory trade-off within acceptable bounds, alevin performs multiple passes over the Cellular; Barcode file. Alevin goes through the barcode file once by itself, and then goes through both the barcode and ; read files in unison to assign reads to cells using the initial barcode mapping. Since the pipe or the input ; stream can't be reset to read from the beginning again, alevin can't read in the barcodes, and might crash. Description of important options; --------------------------------. Alevin exposes a number of useful optional command-line parameters to the user.; The particularly important ones are explained here, but you can always run; ``salmon alevin -h`` to see them all. """"""""""""""""""""""""""""""""""""""""""""""""""""; ``-p`` / ``--numThreads``; """""""""""""""""""""""""""""""""""""""""""""""""""". The number of threads that will be used for quantification. Alevin is designed to work; well with many threads, so, if you have a sufficient number of processors, larger; values here can speed up the run substantially. In our testing we found that usually 10 threads gives the best time-memory trade-off. .. note:: Default number of threads. 	The default behavior is for Alevin to probe the number of available hardware threads and to use this number.; Thus, if you want to use fewer threads (e.g., if you are running multiple; instances of Salmon simultaneously), you will likely want to set this option explicitly in ; accordance with the desired per-process resource usage.; ; """"""""""""""""""""""""; ``--whitelist``; """""""""""""""""""""""". This is an optional argument, where ",MatchSource.DOCS,doc/source/alevin.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst:12207,Security,validat,validateMappings,12207," using inferential replicates for single-cell data in generating accurate differential expression analysis, check out `tximport <https://github.com/mikelove/tximport>`_ and our `Swish <https://www.biorxiv.org/content/10.1101/561084v2>`_ paper. """"""""""""""""""""""""""""""""""""""""""""; ``--debug``; """"""""""""""""""""""""""""""""""""""""""""; Alevin peforms intelligent white-listing downstream of the quantification pipeline and has to make some assumptions like chosing a fraction of reads to learn low confidence CB and in turn might erroneously exit -- if the data results in no mapped or deduplicated reads to a CB in low confidence region. The problem doesn’t happen when provided with external whitelist but if there is an error and the user is aware of this being just a warning, the error can be skipped by running Alevin with this flag. """"""""""""""""""""""""""""""""""""""""""""; ``--minScoreFraction``; """""""""""""""""""""""""""""""""""""""""""". This value controls the minimum allowed score for a mapping to be considered valid.; It matters only when ``--validateMappings`` has been passed to Salmon. The maximum; possible score for a fragment is ``ms = read_len * ma`` (or ``ms = (left_read_len + right_read_len) * ma``; for paired-end reads). The argument to ``--minScoreFraction`` determines what fraction of the maximum; score ``s`` a mapping must achieve to be potentially retained. For a minimum score fraction of ``f``, only; mappings with a score > ``f * s`` will be kept. Mappings with lower scores will be considered as low-quality,; and will be discarded. It is worth noting that mapping validation uses extension alignment. This means that the read need not; map end-to-end. Instead, the score of the mapping will be the position along the alignment with the; highest score. This is the score which must reach the fraction threshold for the read to be considered; as valid. Single-cell protocol specific notes; ------------------------------------. In cases where single-cell protocol supports variable length cellbarcodes, alevin adds nucleotide paddi",MatchSource.DOCS,doc/source/alevin.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst:12751,Security,validat,validation,12751,"ts in no mapped or deduplicated reads to a CB in low confidence region. The problem doesn’t happen when provided with external whitelist but if there is an error and the user is aware of this being just a warning, the error can be skipped by running Alevin with this flag. """"""""""""""""""""""""""""""""""""""""""""; ``--minScoreFraction``; """""""""""""""""""""""""""""""""""""""""""". This value controls the minimum allowed score for a mapping to be considered valid.; It matters only when ``--validateMappings`` has been passed to Salmon. The maximum; possible score for a fragment is ``ms = read_len * ma`` (or ``ms = (left_read_len + right_read_len) * ma``; for paired-end reads). The argument to ``--minScoreFraction`` determines what fraction of the maximum; score ``s`` a mapping must achieve to be potentially retained. For a minimum score fraction of ``f``, only; mappings with a score > ``f * s`` will be kept. Mappings with lower scores will be considered as low-quality,; and will be discarded. It is worth noting that mapping validation uses extension alignment. This means that the read need not; map end-to-end. Instead, the score of the mapping will be the position along the alignment with the; highest score. This is the score which must reach the fraction threshold for the read to be considered; as valid. Single-cell protocol specific notes; ------------------------------------. In cases where single-cell protocol supports variable length cellbarcodes, alevin adds nucleotide padding to make the lengths uniform.; Furthermore, the padding scheme ensures that there are no collisions added in the process. The padding scheme is as follows:. 1. sci-RNA-seq3: The barcode is composed of 9-10 bp hairpin adaptor and 10 bp reverse transcription index making it 19-20 bp long. If the bacode is 20 bp long, alevin adds *A* and it adds *AC* if it is 19 bp long. Thus, the length of barcode in the output is 21 bp.; 2. inDropV2: 8-11 bp barcode1 along with 8 bp barcode2 makes up the barcode. For barcode lengths of 16, 17, 18,",MatchSource.DOCS,doc/source/alevin.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst:14972,Security,hash,hash,14972,"` is performed allowing a maximum hamming distance 2 b/w ``w1`` and read2 substring of w1 length within the required bounds; the first match is returned. . Output; ------. Typical 10x experiment can range form hundreds to tens of thousand of cells -- resulting in huge size of the count-matrices. Traditionally single-cell tools dumps the Cell-v-Gene count matrix in various formats. Although, this itself is an open area of research but by default alevin dumps a per-cell level gene-count matrix in a binary-compressed format with the row and column indexes in a separate file. A typical run of alevin will generate 4 files:. * *quants\_mat.gz* -- Compressed count matrix.; * *quants\_mat\_cols.txt* -- Column Header (Gene-ids) of the matrix.; * *quants\_mat\_rows.txt* -- Row Index (CB-ids) of the matrix.; * *quants\_tier\_mat.gz* -- Tier categorization of the matrix. . .. note:: Working with R packages. Alevin generates multiple metadata files like the hash codes of the reference transcriptome and it's crucial for working with downstream R package like `tximeta <https://bioconductor.org/packages/release/bioc/html/tximeta.html>`_ . Hence along with the above files, it's advisable to keep the complete output folder generated by alevin. . Along with the Cell-v-Gene count matrix, alevin dumps a 3-fold categorization of each estimated count value of a gene(each cell disjointly) in the form of tiers. Tier 1 is the set of genes where all the reads are uniquely mapping. Tier 2 is genes that have ambiguously mapping reads, but connected to unique read evidence as well, that can be used by the EM to resolve the multimapping reads. Tier 3 is the genes that have no unique evidence and the read counts are, therefore, distributed between these genes according to an uninformative prior. Alevin can also dump the count-matrix in a human readable -- matrix-market-exchange (_mtx_) format, if given flag `--dumpMtx` which generates a new output file called `quants_mat.mtx`. Output Quality Check",MatchSource.DOCS,doc/source/alevin.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst:2664,Testability,test,testing,2664,"pe (same as salmon), we recommend using `ISR` for both Drop-seq and 10x-v2 chemistry.; * ``-1``: CB+UMI file(s), alevin requires the path to the *FASTQ* file containing CB+UMI raw sequences to be given under this command line flag. Alevin also supports parsing of data from multiple files as long as the order is the same as in `-2` flag.; * ``-2``: Read-sequence file(s), alevin requires the path to the *FASTQ* file containing raw read-sequences to be given under this command line flag. Alevin also supports parsing of data from multiple files as long as the order is the same as in `-1` flag.; * ``--dropseq / --chromium / --chromiumV3``: the protocol, this flag tells the type of single-cell protocol of the input sequencing-library.; * ``-i``: index, file containing the salmon index of the reference transcriptome, as generated by `salmon index` command.; * ``-p``: number of threads, the number of threads which can be used by alevin to perform the quantification, by default alevin utilizes *all* the available threads in the system, although we recommend using ~10 threads which in our testing gave the best memory-time trade-off.; * ``-o``: output, path to folder where the output gene-count matrix (along with other meta-data) would be dumped.; * ``--tgMap``: transcript to gene map file, a tsv (tab-separated) file --- with *no header*, containing two columns mapping of each transcript present in the reference to the corresponding gene (the first column is a transcript and the second is the corresponding gene). Once all the above requirement are satisfied, alevin can be run using the following command::. > salmon alevin -l ISR -1 cb.fastq.gz -2 reads.fastq.gz --chromium -i salmon_index_directory -p 10 -o alevin_output --tgMap txp2gene.tsv. Providing multiple read files to Alevin; ------------. Often, a single library may be split into multiple FASTA/Q files. Also, sometimes one may wish; to quantify multiple replicates or samples together, treating them as if they are one lib",MatchSource.DOCS,doc/source/alevin.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst:5574,Testability,test,testing,5574,"le bounds, alevin performs multiple passes over the Cellular; Barcode file. Alevin goes through the barcode file once by itself, and then goes through both the barcode and ; read files in unison to assign reads to cells using the initial barcode mapping. Since the pipe or the input ; stream can't be reset to read from the beginning again, alevin can't read in the barcodes, and might crash. Description of important options; --------------------------------. Alevin exposes a number of useful optional command-line parameters to the user.; The particularly important ones are explained here, but you can always run; ``salmon alevin -h`` to see them all. """"""""""""""""""""""""""""""""""""""""""""""""""""; ``-p`` / ``--numThreads``; """""""""""""""""""""""""""""""""""""""""""""""""""". The number of threads that will be used for quantification. Alevin is designed to work; well with many threads, so, if you have a sufficient number of processors, larger; values here can speed up the run substantially. In our testing we found that usually 10 threads gives the best time-memory trade-off. .. note:: Default number of threads. 	The default behavior is for Alevin to probe the number of available hardware threads and to use this number.; Thus, if you want to use fewer threads (e.g., if you are running multiple; instances of Salmon simultaneously), you will likely want to set this option explicitly in ; accordance with the desired per-process resource usage.; ; """"""""""""""""""""""""; ``--whitelist``; """""""""""""""""""""""". This is an optional argument, where user can explicitly specify the whitelist CB to use for cell detection and CB sequence correction. If not given, alevin generates its own set of putative CBs. .. note:: Not 10x 737k whitelist. This flag does not use the technologically defined whitelisted cellular barcodes provided by 10x, instead it's a per experiment level list of subsampled cellular barcodes that need to quantified for consistency with other tools for example an input would be a file generated by cellranger with the name `bar",MatchSource.DOCS,doc/source/alevin.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst:11673,Usability,learn,learn,11673,"te inferential replicates of the experiemnt, `--numCellBootstraps` has to be paired with `--dumpFeatures` which generates a file with name `quants_boot_mat.gz`. The output format is the same as `quants_mat.gz` and we fit the 3D cube of the cell-inference-gene counts in 2D as follows: if an experiment has C cells, G genes and N inferential replicates; alevin output file `quants_boot_mat.gz` would contain C*N rows and G columns while, starting from the top, the first N rows would represent first cell and it's N inferential replicate. For more information on importing and using inferential replicates for single-cell data in generating accurate differential expression analysis, check out `tximport <https://github.com/mikelove/tximport>`_ and our `Swish <https://www.biorxiv.org/content/10.1101/561084v2>`_ paper. """"""""""""""""""""""""""""""""""""""""""""; ``--debug``; """"""""""""""""""""""""""""""""""""""""""""; Alevin peforms intelligent white-listing downstream of the quantification pipeline and has to make some assumptions like chosing a fraction of reads to learn low confidence CB and in turn might erroneously exit -- if the data results in no mapped or deduplicated reads to a CB in low confidence region. The problem doesn’t happen when provided with external whitelist but if there is an error and the user is aware of this being just a warning, the error can be skipped by running Alevin with this flag. """"""""""""""""""""""""""""""""""""""""""""; ``--minScoreFraction``; """""""""""""""""""""""""""""""""""""""""""". This value controls the minimum allowed score for a mapping to be considered valid.; It matters only when ``--validateMappings`` has been passed to Salmon. The maximum; possible score for a fragment is ``ms = read_len * ma`` (or ``ms = (left_read_len + right_read_len) * ma``; for paired-end reads). The argument to ``--minScoreFraction`` determines what fraction of the maximum; score ``s`` a mapping must achieve to be potentially retained. For a minimum score fraction of ``f``, only; mappings with a score > ``f * s`` will be kept. Mappings",MatchSource.DOCS,doc/source/alevin.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst:19677,Usability,feedback,feedback,19677,"ligent whitelisting.; * num_features -- Total number of features used intelligent whitelisting of the cellular barcodes.; * final_num_cbs -- Total number of cellular barcodes present in the output quant matrix.; * deduplicated_umis -- Total number of UMIs present in the experiment post UMI deduplication across all cells.; * mean_umis_per_cell -- Mean of the number of UMIs (post deduplication) present in each cell.; * mean_genes_per_cell -- Mean of the number of genes expressed (>0 counts) in each cell.; * no_read_mapping_cbs -- Total number of cellular barcodes with no reads mapped to them.; * num_bootstraps -- Total number of bootstrap inferential replicates generated for each cell. Misc; ----. **Finally**, the purpose of making this software available is because we believe; it may be useful for people dealing with single-cell RNA-seq data. We want the; software to be as useful, robust, and accurate as possible. So, if you have any; feedback --- something useful to report, or just some interesting ideas or; suggestions --- please contact us (`asrivastava@cs.stonybrook.edu` and/or; `rob.patro@cs.stonybrook.edu`). If you encounter any bugs, please file a; *detailed* bug report at the `Salmon GitHub repository; <https://github.com/COMBINE-lab/salmon>`_. .. The paper describing this method is published in BioArxiv XXXX. (update this when it appears). BibTex; ----; | @article{srivastava2019alevin,; | title={Alevin efficiently estimates accurate gene abundances from dscRNA-seq data},; | author={Srivastava, Avi and Malik, Laraib and Smith, Tom and Sudbery, Ian and Patro, Rob},; | journal={Genome biology},; | volume={20},; | number={1},; | pages={65},; | year={2019},; | publisher={BioMed Central}; | }. | @article{Srivastava2020,; | doi = {10.1093/bioinformatics/btaa450},; | url = {https://doi.org/10.1093/bioinformatics/btaa450},; | year = {2020},; | month = jul,; | publisher = {Oxford University Press ({OUP})},; | volume = {36},; | number = {Supplement{\_}1},; | pages = {i2",MatchSource.DOCS,doc/source/alevin.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/alevin.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst:154,Availability,avail,available,154,"Requirements; ============. Binary Releases; ---------------. Pre-compiled binaries of the latest release of Salmon for a number different; platforms are available available under the `Releases tab; <https://github.com/COMBINE-lab/salmon/releases>`_ of Salmon's `GitHub; repository <https://github.com/COMBINE-lab/salmon>`_. You should be able to; get started quickly by finding a binary from the list that is compatible with; your platform. Additionally, you can obtain a Docker image of the latest version; from DockerHub using:. ::. > docker pull combinelab/salmon; . Requirements for Building from Source; -------------------------------------. * A C++11 conformant compiler (currently tested with GCC>=4.7 and Clang>=3.4); * CMake_. Salmon uses the CMake build system to check, fetch and install; dependencies, and to compile and install Salmon. CMake is available for all; major platforms (though Salmon is currently unsupported on Windows.); ; Installation; ============. After downloading the Salmon source distribution and unpacking it, change into the top-level directory:. ::. > cd salmon. Then, create and out-of-source build directory and change into it:. ::. > mkdir build; > cd build. Salmon makes extensive use of Boost_. We recommend installing the most; recent version (1.55) systemwide if possible. If Boost is not installed on your; system, the build process will fetch, compile and install it locally. However,; if you already have a recent version of Boost available on your system, it make; sense to tell the build system to use that. If you have Boost installed you can tell CMake where to look for it. Likewise,; if you already have `Intel's Threading Building Blocks; <http://threadingbuildingblocks.org/>`_ library installed, you can tell CMake; where it is as well. The flags for CMake are as follows:. * -DFETCH_BOOST=TRUE -- If you don't have Boost installed (or have an older; version of it), you can provide the FETCH_BOOST flag instead of the; BOOST_ROOT variable, whi",MatchSource.DOCS,doc/source/building.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst:164,Availability,avail,available,164,"Requirements; ============. Binary Releases; ---------------. Pre-compiled binaries of the latest release of Salmon for a number different; platforms are available available under the `Releases tab; <https://github.com/COMBINE-lab/salmon/releases>`_ of Salmon's `GitHub; repository <https://github.com/COMBINE-lab/salmon>`_. You should be able to; get started quickly by finding a binary from the list that is compatible with; your platform. Additionally, you can obtain a Docker image of the latest version; from DockerHub using:. ::. > docker pull combinelab/salmon; . Requirements for Building from Source; -------------------------------------. * A C++11 conformant compiler (currently tested with GCC>=4.7 and Clang>=3.4); * CMake_. Salmon uses the CMake build system to check, fetch and install; dependencies, and to compile and install Salmon. CMake is available for all; major platforms (though Salmon is currently unsupported on Windows.); ; Installation; ============. After downloading the Salmon source distribution and unpacking it, change into the top-level directory:. ::. > cd salmon. Then, create and out-of-source build directory and change into it:. ::. > mkdir build; > cd build. Salmon makes extensive use of Boost_. We recommend installing the most; recent version (1.55) systemwide if possible. If Boost is not installed on your; system, the build process will fetch, compile and install it locally. However,; if you already have a recent version of Boost available on your system, it make; sense to tell the build system to use that. If you have Boost installed you can tell CMake where to look for it. Likewise,; if you already have `Intel's Threading Building Blocks; <http://threadingbuildingblocks.org/>`_ library installed, you can tell CMake; where it is as well. The flags for CMake are as follows:. * -DFETCH_BOOST=TRUE -- If you don't have Boost installed (or have an older; version of it), you can provide the FETCH_BOOST flag instead of the; BOOST_ROOT variable, whi",MatchSource.DOCS,doc/source/building.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst:860,Availability,avail,available,860,"Requirements; ============. Binary Releases; ---------------. Pre-compiled binaries of the latest release of Salmon for a number different; platforms are available available under the `Releases tab; <https://github.com/COMBINE-lab/salmon/releases>`_ of Salmon's `GitHub; repository <https://github.com/COMBINE-lab/salmon>`_. You should be able to; get started quickly by finding a binary from the list that is compatible with; your platform. Additionally, you can obtain a Docker image of the latest version; from DockerHub using:. ::. > docker pull combinelab/salmon; . Requirements for Building from Source; -------------------------------------. * A C++11 conformant compiler (currently tested with GCC>=4.7 and Clang>=3.4); * CMake_. Salmon uses the CMake build system to check, fetch and install; dependencies, and to compile and install Salmon. CMake is available for all; major platforms (though Salmon is currently unsupported on Windows.); ; Installation; ============. After downloading the Salmon source distribution and unpacking it, change into the top-level directory:. ::. > cd salmon. Then, create and out-of-source build directory and change into it:. ::. > mkdir build; > cd build. Salmon makes extensive use of Boost_. We recommend installing the most; recent version (1.55) systemwide if possible. If Boost is not installed on your; system, the build process will fetch, compile and install it locally. However,; if you already have a recent version of Boost available on your system, it make; sense to tell the build system to use that. If you have Boost installed you can tell CMake where to look for it. Likewise,; if you already have `Intel's Threading Building Blocks; <http://threadingbuildingblocks.org/>`_ library installed, you can tell CMake; where it is as well. The flags for CMake are as follows:. * -DFETCH_BOOST=TRUE -- If you don't have Boost installed (or have an older; version of it), you can provide the FETCH_BOOST flag instead of the; BOOST_ROOT variable, whi",MatchSource.DOCS,doc/source/building.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst:985,Availability,down,downloading,985,"nary Releases; ---------------. Pre-compiled binaries of the latest release of Salmon for a number different; platforms are available available under the `Releases tab; <https://github.com/COMBINE-lab/salmon/releases>`_ of Salmon's `GitHub; repository <https://github.com/COMBINE-lab/salmon>`_. You should be able to; get started quickly by finding a binary from the list that is compatible with; your platform. Additionally, you can obtain a Docker image of the latest version; from DockerHub using:. ::. > docker pull combinelab/salmon; . Requirements for Building from Source; -------------------------------------. * A C++11 conformant compiler (currently tested with GCC>=4.7 and Clang>=3.4); * CMake_. Salmon uses the CMake build system to check, fetch and install; dependencies, and to compile and install Salmon. CMake is available for all; major platforms (though Salmon is currently unsupported on Windows.); ; Installation; ============. After downloading the Salmon source distribution and unpacking it, change into the top-level directory:. ::. > cd salmon. Then, create and out-of-source build directory and change into it:. ::. > mkdir build; > cd build. Salmon makes extensive use of Boost_. We recommend installing the most; recent version (1.55) systemwide if possible. If Boost is not installed on your; system, the build process will fetch, compile and install it locally. However,; if you already have a recent version of Boost available on your system, it make; sense to tell the build system to use that. If you have Boost installed you can tell CMake where to look for it. Likewise,; if you already have `Intel's Threading Building Blocks; <http://threadingbuildingblocks.org/>`_ library installed, you can tell CMake; where it is as well. The flags for CMake are as follows:. * -DFETCH_BOOST=TRUE -- If you don't have Boost installed (or have an older; version of it), you can provide the FETCH_BOOST flag instead of the; BOOST_ROOT variable, which will cause CMake to fetch a",MatchSource.DOCS,doc/source/building.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst:1479,Availability,avail,available,1479,"the latest version; from DockerHub using:. ::. > docker pull combinelab/salmon; . Requirements for Building from Source; -------------------------------------. * A C++11 conformant compiler (currently tested with GCC>=4.7 and Clang>=3.4); * CMake_. Salmon uses the CMake build system to check, fetch and install; dependencies, and to compile and install Salmon. CMake is available for all; major platforms (though Salmon is currently unsupported on Windows.); ; Installation; ============. After downloading the Salmon source distribution and unpacking it, change into the top-level directory:. ::. > cd salmon. Then, create and out-of-source build directory and change into it:. ::. > mkdir build; > cd build. Salmon makes extensive use of Boost_. We recommend installing the most; recent version (1.55) systemwide if possible. If Boost is not installed on your; system, the build process will fetch, compile and install it locally. However,; if you already have a recent version of Boost available on your system, it make; sense to tell the build system to use that. If you have Boost installed you can tell CMake where to look for it. Likewise,; if you already have `Intel's Threading Building Blocks; <http://threadingbuildingblocks.org/>`_ library installed, you can tell CMake; where it is as well. The flags for CMake are as follows:. * -DFETCH_BOOST=TRUE -- If you don't have Boost installed (or have an older; version of it), you can provide the FETCH_BOOST flag instead of the; BOOST_ROOT variable, which will cause CMake to fetch and build Boost locally. * -DBOOST_ROOT=<boostdir> -- Tells CMake where an existing installtion of Boost; resides, and looks for the appropritate version in <boostdir>. This is the; top-level directory where Boost is installed (e.g. /opt/local). * -DTBB_INSTALL_DIR=<tbbroot> -- Tells CMake where an existing installation of; Intel's TBB is installed (<tbbroot>), and looks for the apropriate headers; and libraries there. This is the top-level directory where",MatchSource.DOCS,doc/source/building.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst:3520,Availability,down,downloading,3520,"tate version in <boostdir>. This is the; top-level directory where Boost is installed (e.g. /opt/local). * -DTBB_INSTALL_DIR=<tbbroot> -- Tells CMake where an existing installation of; Intel's TBB is installed (<tbbroot>), and looks for the apropriate headers; and libraries there. This is the top-level directory where TBB is installed; (e.g. /opt/local). * -DCMAKE_INSTALL_PREFIX=<install_dir> -- <install_dir> is the directory to; which you wish Salmon to be installed. If you don't specify this option,; it will be installed locally in the top-level directory (i.e. the directory; directly above ""build""). There are a number of other libraries upon which Salmon depends, but CMake ; should fetch these for you automatically. Setting the appropriate flags, you can then run the CMake configure step as; follows:. ::; ; > cmake [FLAGS] .. The above command is the cmake configuration step, which *should* complain if; anything goes wrong. Next, you have to run the build step. Depending on what; libraries need to be fetched and installed, this could take a while; (specifically if the installation needs to install Boost). To start the build,; just run make. ::. > make. If the build is successful, the appropriate executables and libraries should be; created. There are two points to note about the build process. First, if the; build system is downloading and compiling boost, you may see a large number of; warnings during compilation; these are normal. Second, note that CMake has; colored output by default, and the steps which create or link libraries are; printed in red. This is the color chosen by CMake for linking messages, and; does not denote an error in the build process. ; ; Finally, after everything is built, the libraries and executable can be; installed with:. ::; ; > make install. You can test the installation by running. ::. > make test. This should run a simple test and tell you if it succeeded or not. .. _CMake : http://www.cmake.org ; .. _Boost: http://www.boost.org; ",MatchSource.DOCS,doc/source/building.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst:3833,Availability,error,error,3833,"tate version in <boostdir>. This is the; top-level directory where Boost is installed (e.g. /opt/local). * -DTBB_INSTALL_DIR=<tbbroot> -- Tells CMake where an existing installation of; Intel's TBB is installed (<tbbroot>), and looks for the apropriate headers; and libraries there. This is the top-level directory where TBB is installed; (e.g. /opt/local). * -DCMAKE_INSTALL_PREFIX=<install_dir> -- <install_dir> is the directory to; which you wish Salmon to be installed. If you don't specify this option,; it will be installed locally in the top-level directory (i.e. the directory; directly above ""build""). There are a number of other libraries upon which Salmon depends, but CMake ; should fetch these for you automatically. Setting the appropriate flags, you can then run the CMake configure step as; follows:. ::; ; > cmake [FLAGS] .. The above command is the cmake configuration step, which *should* complain if; anything goes wrong. Next, you have to run the build step. Depending on what; libraries need to be fetched and installed, this could take a while; (specifically if the installation needs to install Boost). To start the build,; just run make. ::. > make. If the build is successful, the appropriate executables and libraries should be; created. There are two points to note about the build process. First, if the; build system is downloading and compiling boost, you may see a large number of; warnings during compilation; these are normal. Second, note that CMake has; colored output by default, and the steps which create or link libraries are; printed in red. This is the color chosen by CMake for linking messages, and; does not denote an error in the build process. ; ; Finally, after everything is built, the libraries and executable can be; installed with:. ::; ; > make install. You can test the installation by running. ::. > make test. This should run a simple test and tell you if it succeeded or not. .. _CMake : http://www.cmake.org ; .. _Boost: http://www.boost.org; ",MatchSource.DOCS,doc/source/building.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst:98,Deployability,release,release,98,"Requirements; ============. Binary Releases; ---------------. Pre-compiled binaries of the latest release of Salmon for a number different; platforms are available available under the `Releases tab; <https://github.com/COMBINE-lab/salmon/releases>`_ of Salmon's `GitHub; repository <https://github.com/COMBINE-lab/salmon>`_. You should be able to; get started quickly by finding a binary from the list that is compatible with; your platform. Additionally, you can obtain a Docker image of the latest version; from DockerHub using:. ::. > docker pull combinelab/salmon; . Requirements for Building from Source; -------------------------------------. * A C++11 conformant compiler (currently tested with GCC>=4.7 and Clang>=3.4); * CMake_. Salmon uses the CMake build system to check, fetch and install; dependencies, and to compile and install Salmon. CMake is available for all; major platforms (though Salmon is currently unsupported on Windows.); ; Installation; ============. After downloading the Salmon source distribution and unpacking it, change into the top-level directory:. ::. > cd salmon. Then, create and out-of-source build directory and change into it:. ::. > mkdir build; > cd build. Salmon makes extensive use of Boost_. We recommend installing the most; recent version (1.55) systemwide if possible. If Boost is not installed on your; system, the build process will fetch, compile and install it locally. However,; if you already have a recent version of Boost available on your system, it make; sense to tell the build system to use that. If you have Boost installed you can tell CMake where to look for it. Likewise,; if you already have `Intel's Threading Building Blocks; <http://threadingbuildingblocks.org/>`_ library installed, you can tell CMake; where it is as well. The flags for CMake are as follows:. * -DFETCH_BOOST=TRUE -- If you don't have Boost installed (or have an older; version of it), you can provide the FETCH_BOOST flag instead of the; BOOST_ROOT variable, whi",MatchSource.DOCS,doc/source/building.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst:238,Deployability,release,releases,238,"Requirements; ============. Binary Releases; ---------------. Pre-compiled binaries of the latest release of Salmon for a number different; platforms are available available under the `Releases tab; <https://github.com/COMBINE-lab/salmon/releases>`_ of Salmon's `GitHub; repository <https://github.com/COMBINE-lab/salmon>`_. You should be able to; get started quickly by finding a binary from the list that is compatible with; your platform. Additionally, you can obtain a Docker image of the latest version; from DockerHub using:. ::. > docker pull combinelab/salmon; . Requirements for Building from Source; -------------------------------------. * A C++11 conformant compiler (currently tested with GCC>=4.7 and Clang>=3.4); * CMake_. Salmon uses the CMake build system to check, fetch and install; dependencies, and to compile and install Salmon. CMake is available for all; major platforms (though Salmon is currently unsupported on Windows.); ; Installation; ============. After downloading the Salmon source distribution and unpacking it, change into the top-level directory:. ::. > cd salmon. Then, create and out-of-source build directory and change into it:. ::. > mkdir build; > cd build. Salmon makes extensive use of Boost_. We recommend installing the most; recent version (1.55) systemwide if possible. If Boost is not installed on your; system, the build process will fetch, compile and install it locally. However,; if you already have a recent version of Boost available on your system, it make; sense to tell the build system to use that. If you have Boost installed you can tell CMake where to look for it. Likewise,; if you already have `Intel's Threading Building Blocks; <http://threadingbuildingblocks.org/>`_ library installed, you can tell CMake; where it is as well. The flags for CMake are as follows:. * -DFETCH_BOOST=TRUE -- If you don't have Boost installed (or have an older; version of it), you can provide the FETCH_BOOST flag instead of the; BOOST_ROOT variable, whi",MatchSource.DOCS,doc/source/building.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst:793,Deployability,install,install,793,"Requirements; ============. Binary Releases; ---------------. Pre-compiled binaries of the latest release of Salmon for a number different; platforms are available available under the `Releases tab; <https://github.com/COMBINE-lab/salmon/releases>`_ of Salmon's `GitHub; repository <https://github.com/COMBINE-lab/salmon>`_. You should be able to; get started quickly by finding a binary from the list that is compatible with; your platform. Additionally, you can obtain a Docker image of the latest version; from DockerHub using:. ::. > docker pull combinelab/salmon; . Requirements for Building from Source; -------------------------------------. * A C++11 conformant compiler (currently tested with GCC>=4.7 and Clang>=3.4); * CMake_. Salmon uses the CMake build system to check, fetch and install; dependencies, and to compile and install Salmon. CMake is available for all; major platforms (though Salmon is currently unsupported on Windows.); ; Installation; ============. After downloading the Salmon source distribution and unpacking it, change into the top-level directory:. ::. > cd salmon. Then, create and out-of-source build directory and change into it:. ::. > mkdir build; > cd build. Salmon makes extensive use of Boost_. We recommend installing the most; recent version (1.55) systemwide if possible. If Boost is not installed on your; system, the build process will fetch, compile and install it locally. However,; if you already have a recent version of Boost available on your system, it make; sense to tell the build system to use that. If you have Boost installed you can tell CMake where to look for it. Likewise,; if you already have `Intel's Threading Building Blocks; <http://threadingbuildingblocks.org/>`_ library installed, you can tell CMake; where it is as well. The flags for CMake are as follows:. * -DFETCH_BOOST=TRUE -- If you don't have Boost installed (or have an older; version of it), you can provide the FETCH_BOOST flag instead of the; BOOST_ROOT variable, whi",MatchSource.DOCS,doc/source/building.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst:835,Deployability,install,install,835,"Requirements; ============. Binary Releases; ---------------. Pre-compiled binaries of the latest release of Salmon for a number different; platforms are available available under the `Releases tab; <https://github.com/COMBINE-lab/salmon/releases>`_ of Salmon's `GitHub; repository <https://github.com/COMBINE-lab/salmon>`_. You should be able to; get started quickly by finding a binary from the list that is compatible with; your platform. Additionally, you can obtain a Docker image of the latest version; from DockerHub using:. ::. > docker pull combinelab/salmon; . Requirements for Building from Source; -------------------------------------. * A C++11 conformant compiler (currently tested with GCC>=4.7 and Clang>=3.4); * CMake_. Salmon uses the CMake build system to check, fetch and install; dependencies, and to compile and install Salmon. CMake is available for all; major platforms (though Salmon is currently unsupported on Windows.); ; Installation; ============. After downloading the Salmon source distribution and unpacking it, change into the top-level directory:. ::. > cd salmon. Then, create and out-of-source build directory and change into it:. ::. > mkdir build; > cd build. Salmon makes extensive use of Boost_. We recommend installing the most; recent version (1.55) systemwide if possible. If Boost is not installed on your; system, the build process will fetch, compile and install it locally. However,; if you already have a recent version of Boost available on your system, it make; sense to tell the build system to use that. If you have Boost installed you can tell CMake where to look for it. Likewise,; if you already have `Intel's Threading Building Blocks; <http://threadingbuildingblocks.org/>`_ library installed, you can tell CMake; where it is as well. The flags for CMake are as follows:. * -DFETCH_BOOST=TRUE -- If you don't have Boost installed (or have an older; version of it), you can provide the FETCH_BOOST flag instead of the; BOOST_ROOT variable, whi",MatchSource.DOCS,doc/source/building.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst:1251,Deployability,install,installing,1251,"GitHub; repository <https://github.com/COMBINE-lab/salmon>`_. You should be able to; get started quickly by finding a binary from the list that is compatible with; your platform. Additionally, you can obtain a Docker image of the latest version; from DockerHub using:. ::. > docker pull combinelab/salmon; . Requirements for Building from Source; -------------------------------------. * A C++11 conformant compiler (currently tested with GCC>=4.7 and Clang>=3.4); * CMake_. Salmon uses the CMake build system to check, fetch and install; dependencies, and to compile and install Salmon. CMake is available for all; major platforms (though Salmon is currently unsupported on Windows.); ; Installation; ============. After downloading the Salmon source distribution and unpacking it, change into the top-level directory:. ::. > cd salmon. Then, create and out-of-source build directory and change into it:. ::. > mkdir build; > cd build. Salmon makes extensive use of Boost_. We recommend installing the most; recent version (1.55) systemwide if possible. If Boost is not installed on your; system, the build process will fetch, compile and install it locally. However,; if you already have a recent version of Boost available on your system, it make; sense to tell the build system to use that. If you have Boost installed you can tell CMake where to look for it. Likewise,; if you already have `Intel's Threading Building Blocks; <http://threadingbuildingblocks.org/>`_ library installed, you can tell CMake; where it is as well. The flags for CMake are as follows:. * -DFETCH_BOOST=TRUE -- If you don't have Boost installed (or have an older; version of it), you can provide the FETCH_BOOST flag instead of the; BOOST_ROOT variable, which will cause CMake to fetch and build Boost locally. * -DBOOST_ROOT=<boostdir> -- Tells CMake where an existing installtion of Boost; resides, and looks for the appropritate version in <boostdir>. This is the; top-level directory where Boost is installed (e.g. /",MatchSource.DOCS,doc/source/building.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst:1334,Deployability,install,installed,1334,"y finding a binary from the list that is compatible with; your platform. Additionally, you can obtain a Docker image of the latest version; from DockerHub using:. ::. > docker pull combinelab/salmon; . Requirements for Building from Source; -------------------------------------. * A C++11 conformant compiler (currently tested with GCC>=4.7 and Clang>=3.4); * CMake_. Salmon uses the CMake build system to check, fetch and install; dependencies, and to compile and install Salmon. CMake is available for all; major platforms (though Salmon is currently unsupported on Windows.); ; Installation; ============. After downloading the Salmon source distribution and unpacking it, change into the top-level directory:. ::. > cd salmon. Then, create and out-of-source build directory and change into it:. ::. > mkdir build; > cd build. Salmon makes extensive use of Boost_. We recommend installing the most; recent version (1.55) systemwide if possible. If Boost is not installed on your; system, the build process will fetch, compile and install it locally. However,; if you already have a recent version of Boost available on your system, it make; sense to tell the build system to use that. If you have Boost installed you can tell CMake where to look for it. Likewise,; if you already have `Intel's Threading Building Blocks; <http://threadingbuildingblocks.org/>`_ library installed, you can tell CMake; where it is as well. The flags for CMake are as follows:. * -DFETCH_BOOST=TRUE -- If you don't have Boost installed (or have an older; version of it), you can provide the FETCH_BOOST flag instead of the; BOOST_ROOT variable, which will cause CMake to fetch and build Boost locally. * -DBOOST_ROOT=<boostdir> -- Tells CMake where an existing installtion of Boost; resides, and looks for the appropritate version in <boostdir>. This is the; top-level directory where Boost is installed (e.g. /opt/local). * -DTBB_INSTALL_DIR=<tbbroot> -- Tells CMake where an existing installation of; Intel's TBB is",MatchSource.DOCS,doc/source/building.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst:1403,Deployability,install,install,1403,"y finding a binary from the list that is compatible with; your platform. Additionally, you can obtain a Docker image of the latest version; from DockerHub using:. ::. > docker pull combinelab/salmon; . Requirements for Building from Source; -------------------------------------. * A C++11 conformant compiler (currently tested with GCC>=4.7 and Clang>=3.4); * CMake_. Salmon uses the CMake build system to check, fetch and install; dependencies, and to compile and install Salmon. CMake is available for all; major platforms (though Salmon is currently unsupported on Windows.); ; Installation; ============. After downloading the Salmon source distribution and unpacking it, change into the top-level directory:. ::. > cd salmon. Then, create and out-of-source build directory and change into it:. ::. > mkdir build; > cd build. Salmon makes extensive use of Boost_. We recommend installing the most; recent version (1.55) systemwide if possible. If Boost is not installed on your; system, the build process will fetch, compile and install it locally. However,; if you already have a recent version of Boost available on your system, it make; sense to tell the build system to use that. If you have Boost installed you can tell CMake where to look for it. Likewise,; if you already have `Intel's Threading Building Blocks; <http://threadingbuildingblocks.org/>`_ library installed, you can tell CMake; where it is as well. The flags for CMake are as follows:. * -DFETCH_BOOST=TRUE -- If you don't have Boost installed (or have an older; version of it), you can provide the FETCH_BOOST flag instead of the; BOOST_ROOT variable, which will cause CMake to fetch and build Boost locally. * -DBOOST_ROOT=<boostdir> -- Tells CMake where an existing installtion of Boost; resides, and looks for the appropritate version in <boostdir>. This is the; top-level directory where Boost is installed (e.g. /opt/local). * -DTBB_INSTALL_DIR=<tbbroot> -- Tells CMake where an existing installation of; Intel's TBB is",MatchSource.DOCS,doc/source/building.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst:1576,Deployability,install,installed,1576,"lding from Source; -------------------------------------. * A C++11 conformant compiler (currently tested with GCC>=4.7 and Clang>=3.4); * CMake_. Salmon uses the CMake build system to check, fetch and install; dependencies, and to compile and install Salmon. CMake is available for all; major platforms (though Salmon is currently unsupported on Windows.); ; Installation; ============. After downloading the Salmon source distribution and unpacking it, change into the top-level directory:. ::. > cd salmon. Then, create and out-of-source build directory and change into it:. ::. > mkdir build; > cd build. Salmon makes extensive use of Boost_. We recommend installing the most; recent version (1.55) systemwide if possible. If Boost is not installed on your; system, the build process will fetch, compile and install it locally. However,; if you already have a recent version of Boost available on your system, it make; sense to tell the build system to use that. If you have Boost installed you can tell CMake where to look for it. Likewise,; if you already have `Intel's Threading Building Blocks; <http://threadingbuildingblocks.org/>`_ library installed, you can tell CMake; where it is as well. The flags for CMake are as follows:. * -DFETCH_BOOST=TRUE -- If you don't have Boost installed (or have an older; version of it), you can provide the FETCH_BOOST flag instead of the; BOOST_ROOT variable, which will cause CMake to fetch and build Boost locally. * -DBOOST_ROOT=<boostdir> -- Tells CMake where an existing installtion of Boost; resides, and looks for the appropritate version in <boostdir>. This is the; top-level directory where Boost is installed (e.g. /opt/local). * -DTBB_INSTALL_DIR=<tbbroot> -- Tells CMake where an existing installation of; Intel's TBB is installed (<tbbroot>), and looks for the apropriate headers; and libraries there. This is the top-level directory where TBB is installed; (e.g. /opt/local). * -DCMAKE_INSTALL_PREFIX=<install_dir> -- <install_dir> is the d",MatchSource.DOCS,doc/source/building.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst:1742,Deployability,install,installed,1742," build system to check, fetch and install; dependencies, and to compile and install Salmon. CMake is available for all; major platforms (though Salmon is currently unsupported on Windows.); ; Installation; ============. After downloading the Salmon source distribution and unpacking it, change into the top-level directory:. ::. > cd salmon. Then, create and out-of-source build directory and change into it:. ::. > mkdir build; > cd build. Salmon makes extensive use of Boost_. We recommend installing the most; recent version (1.55) systemwide if possible. If Boost is not installed on your; system, the build process will fetch, compile and install it locally. However,; if you already have a recent version of Boost available on your system, it make; sense to tell the build system to use that. If you have Boost installed you can tell CMake where to look for it. Likewise,; if you already have `Intel's Threading Building Blocks; <http://threadingbuildingblocks.org/>`_ library installed, you can tell CMake; where it is as well. The flags for CMake are as follows:. * -DFETCH_BOOST=TRUE -- If you don't have Boost installed (or have an older; version of it), you can provide the FETCH_BOOST flag instead of the; BOOST_ROOT variable, which will cause CMake to fetch and build Boost locally. * -DBOOST_ROOT=<boostdir> -- Tells CMake where an existing installtion of Boost; resides, and looks for the appropritate version in <boostdir>. This is the; top-level directory where Boost is installed (e.g. /opt/local). * -DTBB_INSTALL_DIR=<tbbroot> -- Tells CMake where an existing installation of; Intel's TBB is installed (<tbbroot>), and looks for the apropriate headers; and libraries there. This is the top-level directory where TBB is installed; (e.g. /opt/local). * -DCMAKE_INSTALL_PREFIX=<install_dir> -- <install_dir> is the directory to; which you wish Salmon to be installed. If you don't specify this option,; it will be installed locally in the top-level directory (i.e. the directory; dire",MatchSource.DOCS,doc/source/building.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst:1879,Deployability,install,installed,1879,"ows.); ; Installation; ============. After downloading the Salmon source distribution and unpacking it, change into the top-level directory:. ::. > cd salmon. Then, create and out-of-source build directory and change into it:. ::. > mkdir build; > cd build. Salmon makes extensive use of Boost_. We recommend installing the most; recent version (1.55) systemwide if possible. If Boost is not installed on your; system, the build process will fetch, compile and install it locally. However,; if you already have a recent version of Boost available on your system, it make; sense to tell the build system to use that. If you have Boost installed you can tell CMake where to look for it. Likewise,; if you already have `Intel's Threading Building Blocks; <http://threadingbuildingblocks.org/>`_ library installed, you can tell CMake; where it is as well. The flags for CMake are as follows:. * -DFETCH_BOOST=TRUE -- If you don't have Boost installed (or have an older; version of it), you can provide the FETCH_BOOST flag instead of the; BOOST_ROOT variable, which will cause CMake to fetch and build Boost locally. * -DBOOST_ROOT=<boostdir> -- Tells CMake where an existing installtion of Boost; resides, and looks for the appropritate version in <boostdir>. This is the; top-level directory where Boost is installed (e.g. /opt/local). * -DTBB_INSTALL_DIR=<tbbroot> -- Tells CMake where an existing installation of; Intel's TBB is installed (<tbbroot>), and looks for the apropriate headers; and libraries there. This is the top-level directory where TBB is installed; (e.g. /opt/local). * -DCMAKE_INSTALL_PREFIX=<install_dir> -- <install_dir> is the directory to; which you wish Salmon to be installed. If you don't specify this option,; it will be installed locally in the top-level directory (i.e. the directory; directly above ""build""). There are a number of other libraries upon which Salmon depends, but CMake ; should fetch these for you automatically. Setting the appropriate flags, you can the",MatchSource.DOCS,doc/source/building.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst:2114,Deployability,install,installtion,2114,"ource build directory and change into it:. ::. > mkdir build; > cd build. Salmon makes extensive use of Boost_. We recommend installing the most; recent version (1.55) systemwide if possible. If Boost is not installed on your; system, the build process will fetch, compile and install it locally. However,; if you already have a recent version of Boost available on your system, it make; sense to tell the build system to use that. If you have Boost installed you can tell CMake where to look for it. Likewise,; if you already have `Intel's Threading Building Blocks; <http://threadingbuildingblocks.org/>`_ library installed, you can tell CMake; where it is as well. The flags for CMake are as follows:. * -DFETCH_BOOST=TRUE -- If you don't have Boost installed (or have an older; version of it), you can provide the FETCH_BOOST flag instead of the; BOOST_ROOT variable, which will cause CMake to fetch and build Boost locally. * -DBOOST_ROOT=<boostdir> -- Tells CMake where an existing installtion of Boost; resides, and looks for the appropritate version in <boostdir>. This is the; top-level directory where Boost is installed (e.g. /opt/local). * -DTBB_INSTALL_DIR=<tbbroot> -- Tells CMake where an existing installation of; Intel's TBB is installed (<tbbroot>), and looks for the apropriate headers; and libraries there. This is the top-level directory where TBB is installed; (e.g. /opt/local). * -DCMAKE_INSTALL_PREFIX=<install_dir> -- <install_dir> is the directory to; which you wish Salmon to be installed. If you don't specify this option,; it will be installed locally in the top-level directory (i.e. the directory; directly above ""build""). There are a number of other libraries upon which Salmon depends, but CMake ; should fetch these for you automatically. Setting the appropriate flags, you can then run the CMake configure step as; follows:. ::; ; > cmake [FLAGS] .. The above command is the cmake configuration step, which *should* complain if; anything goes wrong. Next, you have",MatchSource.DOCS,doc/source/building.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst:2247,Deployability,install,installed,2247," Boost_. We recommend installing the most; recent version (1.55) systemwide if possible. If Boost is not installed on your; system, the build process will fetch, compile and install it locally. However,; if you already have a recent version of Boost available on your system, it make; sense to tell the build system to use that. If you have Boost installed you can tell CMake where to look for it. Likewise,; if you already have `Intel's Threading Building Blocks; <http://threadingbuildingblocks.org/>`_ library installed, you can tell CMake; where it is as well. The flags for CMake are as follows:. * -DFETCH_BOOST=TRUE -- If you don't have Boost installed (or have an older; version of it), you can provide the FETCH_BOOST flag instead of the; BOOST_ROOT variable, which will cause CMake to fetch and build Boost locally. * -DBOOST_ROOT=<boostdir> -- Tells CMake where an existing installtion of Boost; resides, and looks for the appropritate version in <boostdir>. This is the; top-level directory where Boost is installed (e.g. /opt/local). * -DTBB_INSTALL_DIR=<tbbroot> -- Tells CMake where an existing installation of; Intel's TBB is installed (<tbbroot>), and looks for the apropriate headers; and libraries there. This is the top-level directory where TBB is installed; (e.g. /opt/local). * -DCMAKE_INSTALL_PREFIX=<install_dir> -- <install_dir> is the directory to; which you wish Salmon to be installed. If you don't specify this option,; it will be installed locally in the top-level directory (i.e. the directory; directly above ""build""). There are a number of other libraries upon which Salmon depends, but CMake ; should fetch these for you automatically. Setting the appropriate flags, you can then run the CMake configure step as; follows:. ::; ; > cmake [FLAGS] .. The above command is the cmake configuration step, which *should* complain if; anything goes wrong. Next, you have to run the build step. Depending on what; libraries need to be fetched and installed, this could take ",MatchSource.DOCS,doc/source/building.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst:2339,Deployability,install,installation,2339,"e build process will fetch, compile and install it locally. However,; if you already have a recent version of Boost available on your system, it make; sense to tell the build system to use that. If you have Boost installed you can tell CMake where to look for it. Likewise,; if you already have `Intel's Threading Building Blocks; <http://threadingbuildingblocks.org/>`_ library installed, you can tell CMake; where it is as well. The flags for CMake are as follows:. * -DFETCH_BOOST=TRUE -- If you don't have Boost installed (or have an older; version of it), you can provide the FETCH_BOOST flag instead of the; BOOST_ROOT variable, which will cause CMake to fetch and build Boost locally. * -DBOOST_ROOT=<boostdir> -- Tells CMake where an existing installtion of Boost; resides, and looks for the appropritate version in <boostdir>. This is the; top-level directory where Boost is installed (e.g. /opt/local). * -DTBB_INSTALL_DIR=<tbbroot> -- Tells CMake where an existing installation of; Intel's TBB is installed (<tbbroot>), and looks for the apropriate headers; and libraries there. This is the top-level directory where TBB is installed; (e.g. /opt/local). * -DCMAKE_INSTALL_PREFIX=<install_dir> -- <install_dir> is the directory to; which you wish Salmon to be installed. If you don't specify this option,; it will be installed locally in the top-level directory (i.e. the directory; directly above ""build""). There are a number of other libraries upon which Salmon depends, but CMake ; should fetch these for you automatically. Setting the appropriate flags, you can then run the CMake configure step as; follows:. ::; ; > cmake [FLAGS] .. The above command is the cmake configuration step, which *should* complain if; anything goes wrong. Next, you have to run the build step. Depending on what; libraries need to be fetched and installed, this could take a while; (specifically if the installation needs to install Boost). To start the build,; just run make. ::. > make. If the build is suc",MatchSource.DOCS,doc/source/building.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst:2371,Deployability,install,installed,2371,"e build process will fetch, compile and install it locally. However,; if you already have a recent version of Boost available on your system, it make; sense to tell the build system to use that. If you have Boost installed you can tell CMake where to look for it. Likewise,; if you already have `Intel's Threading Building Blocks; <http://threadingbuildingblocks.org/>`_ library installed, you can tell CMake; where it is as well. The flags for CMake are as follows:. * -DFETCH_BOOST=TRUE -- If you don't have Boost installed (or have an older; version of it), you can provide the FETCH_BOOST flag instead of the; BOOST_ROOT variable, which will cause CMake to fetch and build Boost locally. * -DBOOST_ROOT=<boostdir> -- Tells CMake where an existing installtion of Boost; resides, and looks for the appropritate version in <boostdir>. This is the; top-level directory where Boost is installed (e.g. /opt/local). * -DTBB_INSTALL_DIR=<tbbroot> -- Tells CMake where an existing installation of; Intel's TBB is installed (<tbbroot>), and looks for the apropriate headers; and libraries there. This is the top-level directory where TBB is installed; (e.g. /opt/local). * -DCMAKE_INSTALL_PREFIX=<install_dir> -- <install_dir> is the directory to; which you wish Salmon to be installed. If you don't specify this option,; it will be installed locally in the top-level directory (i.e. the directory; directly above ""build""). There are a number of other libraries upon which Salmon depends, but CMake ; should fetch these for you automatically. Setting the appropriate flags, you can then run the CMake configure step as; follows:. ::; ; > cmake [FLAGS] .. The above command is the cmake configuration step, which *should* complain if; anything goes wrong. Next, you have to run the build step. Depending on what; libraries need to be fetched and installed, this could take a while; (specifically if the installation needs to install Boost). To start the build,; just run make. ::. > make. If the build is suc",MatchSource.DOCS,doc/source/building.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst:2498,Deployability,install,installed,2498,"ilable on your system, it make; sense to tell the build system to use that. If you have Boost installed you can tell CMake where to look for it. Likewise,; if you already have `Intel's Threading Building Blocks; <http://threadingbuildingblocks.org/>`_ library installed, you can tell CMake; where it is as well. The flags for CMake are as follows:. * -DFETCH_BOOST=TRUE -- If you don't have Boost installed (or have an older; version of it), you can provide the FETCH_BOOST flag instead of the; BOOST_ROOT variable, which will cause CMake to fetch and build Boost locally. * -DBOOST_ROOT=<boostdir> -- Tells CMake where an existing installtion of Boost; resides, and looks for the appropritate version in <boostdir>. This is the; top-level directory where Boost is installed (e.g. /opt/local). * -DTBB_INSTALL_DIR=<tbbroot> -- Tells CMake where an existing installation of; Intel's TBB is installed (<tbbroot>), and looks for the apropriate headers; and libraries there. This is the top-level directory where TBB is installed; (e.g. /opt/local). * -DCMAKE_INSTALL_PREFIX=<install_dir> -- <install_dir> is the directory to; which you wish Salmon to be installed. If you don't specify this option,; it will be installed locally in the top-level directory (i.e. the directory; directly above ""build""). There are a number of other libraries upon which Salmon depends, but CMake ; should fetch these for you automatically. Setting the appropriate flags, you can then run the CMake configure step as; follows:. ::; ; > cmake [FLAGS] .. The above command is the cmake configuration step, which *should* complain if; anything goes wrong. Next, you have to run the build step. Depending on what; libraries need to be fetched and installed, this could take a while; (specifically if the installation needs to install Boost). To start the build,; just run make. ::. > make. If the build is successful, the appropriate executables and libraries should be; created. There are two points to note about the build pr",MatchSource.DOCS,doc/source/building.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst:2633,Deployability,install,installed,2633," you can tell CMake where to look for it. Likewise,; if you already have `Intel's Threading Building Blocks; <http://threadingbuildingblocks.org/>`_ library installed, you can tell CMake; where it is as well. The flags for CMake are as follows:. * -DFETCH_BOOST=TRUE -- If you don't have Boost installed (or have an older; version of it), you can provide the FETCH_BOOST flag instead of the; BOOST_ROOT variable, which will cause CMake to fetch and build Boost locally. * -DBOOST_ROOT=<boostdir> -- Tells CMake where an existing installtion of Boost; resides, and looks for the appropritate version in <boostdir>. This is the; top-level directory where Boost is installed (e.g. /opt/local). * -DTBB_INSTALL_DIR=<tbbroot> -- Tells CMake where an existing installation of; Intel's TBB is installed (<tbbroot>), and looks for the apropriate headers; and libraries there. This is the top-level directory where TBB is installed; (e.g. /opt/local). * -DCMAKE_INSTALL_PREFIX=<install_dir> -- <install_dir> is the directory to; which you wish Salmon to be installed. If you don't specify this option,; it will be installed locally in the top-level directory (i.e. the directory; directly above ""build""). There are a number of other libraries upon which Salmon depends, but CMake ; should fetch these for you automatically. Setting the appropriate flags, you can then run the CMake configure step as; follows:. ::; ; > cmake [FLAGS] .. The above command is the cmake configuration step, which *should* complain if; anything goes wrong. Next, you have to run the build step. Depending on what; libraries need to be fetched and installed, this could take a while; (specifically if the installation needs to install Boost). To start the build,; just run make. ::. > make. If the build is successful, the appropriate executables and libraries should be; created. There are two points to note about the build process. First, if the; build system is downloading and compiling boost, you may see a large number of; w",MatchSource.DOCS,doc/source/building.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst:2690,Deployability,install,installed,2690,"ks; <http://threadingbuildingblocks.org/>`_ library installed, you can tell CMake; where it is as well. The flags for CMake are as follows:. * -DFETCH_BOOST=TRUE -- If you don't have Boost installed (or have an older; version of it), you can provide the FETCH_BOOST flag instead of the; BOOST_ROOT variable, which will cause CMake to fetch and build Boost locally. * -DBOOST_ROOT=<boostdir> -- Tells CMake where an existing installtion of Boost; resides, and looks for the appropritate version in <boostdir>. This is the; top-level directory where Boost is installed (e.g. /opt/local). * -DTBB_INSTALL_DIR=<tbbroot> -- Tells CMake where an existing installation of; Intel's TBB is installed (<tbbroot>), and looks for the apropriate headers; and libraries there. This is the top-level directory where TBB is installed; (e.g. /opt/local). * -DCMAKE_INSTALL_PREFIX=<install_dir> -- <install_dir> is the directory to; which you wish Salmon to be installed. If you don't specify this option,; it will be installed locally in the top-level directory (i.e. the directory; directly above ""build""). There are a number of other libraries upon which Salmon depends, but CMake ; should fetch these for you automatically. Setting the appropriate flags, you can then run the CMake configure step as; follows:. ::; ; > cmake [FLAGS] .. The above command is the cmake configuration step, which *should* complain if; anything goes wrong. Next, you have to run the build step. Depending on what; libraries need to be fetched and installed, this could take a while; (specifically if the installation needs to install Boost). To start the build,; just run make. ::. > make. If the build is successful, the appropriate executables and libraries should be; created. There are two points to note about the build process. First, if the; build system is downloading and compiling boost, you may see a large number of; warnings during compilation; these are normal. Second, note that CMake has; colored output by default, and ",MatchSource.DOCS,doc/source/building.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst:3043,Deployability,configurat,configuration,3043,"OST_ROOT=<boostdir> -- Tells CMake where an existing installtion of Boost; resides, and looks for the appropritate version in <boostdir>. This is the; top-level directory where Boost is installed (e.g. /opt/local). * -DTBB_INSTALL_DIR=<tbbroot> -- Tells CMake where an existing installation of; Intel's TBB is installed (<tbbroot>), and looks for the apropriate headers; and libraries there. This is the top-level directory where TBB is installed; (e.g. /opt/local). * -DCMAKE_INSTALL_PREFIX=<install_dir> -- <install_dir> is the directory to; which you wish Salmon to be installed. If you don't specify this option,; it will be installed locally in the top-level directory (i.e. the directory; directly above ""build""). There are a number of other libraries upon which Salmon depends, but CMake ; should fetch these for you automatically. Setting the appropriate flags, you can then run the CMake configure step as; follows:. ::; ; > cmake [FLAGS] .. The above command is the cmake configuration step, which *should* complain if; anything goes wrong. Next, you have to run the build step. Depending on what; libraries need to be fetched and installed, this could take a while; (specifically if the installation needs to install Boost). To start the build,; just run make. ::. > make. If the build is successful, the appropriate executables and libraries should be; created. There are two points to note about the build process. First, if the; build system is downloading and compiling boost, you may see a large number of; warnings during compilation; these are normal. Second, note that CMake has; colored output by default, and the steps which create or link libraries are; printed in red. This is the color chosen by CMake for linking messages, and; does not denote an error in the build process. ; ; Finally, after everything is built, the libraries and executable can be; installed with:. ::; ; > make install. You can test the installation by running. ::. > make test. This should run a simple ",MatchSource.DOCS,doc/source/building.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst:3202,Deployability,install,installed,3202,"tate version in <boostdir>. This is the; top-level directory where Boost is installed (e.g. /opt/local). * -DTBB_INSTALL_DIR=<tbbroot> -- Tells CMake where an existing installation of; Intel's TBB is installed (<tbbroot>), and looks for the apropriate headers; and libraries there. This is the top-level directory where TBB is installed; (e.g. /opt/local). * -DCMAKE_INSTALL_PREFIX=<install_dir> -- <install_dir> is the directory to; which you wish Salmon to be installed. If you don't specify this option,; it will be installed locally in the top-level directory (i.e. the directory; directly above ""build""). There are a number of other libraries upon which Salmon depends, but CMake ; should fetch these for you automatically. Setting the appropriate flags, you can then run the CMake configure step as; follows:. ::; ; > cmake [FLAGS] .. The above command is the cmake configuration step, which *should* complain if; anything goes wrong. Next, you have to run the build step. Depending on what; libraries need to be fetched and installed, this could take a while; (specifically if the installation needs to install Boost). To start the build,; just run make. ::. > make. If the build is successful, the appropriate executables and libraries should be; created. There are two points to note about the build process. First, if the; build system is downloading and compiling boost, you may see a large number of; warnings during compilation; these are normal. Second, note that CMake has; colored output by default, and the steps which create or link libraries are; printed in red. This is the color chosen by CMake for linking messages, and; does not denote an error in the build process. ; ; Finally, after everything is built, the libraries and executable can be; installed with:. ::; ; > make install. You can test the installation by running. ::. > make test. This should run a simple test and tell you if it succeeded or not. .. _CMake : http://www.cmake.org ; .. _Boost: http://www.boost.org; ",MatchSource.DOCS,doc/source/building.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst:3259,Deployability,install,installation,3259,"tate version in <boostdir>. This is the; top-level directory where Boost is installed (e.g. /opt/local). * -DTBB_INSTALL_DIR=<tbbroot> -- Tells CMake where an existing installation of; Intel's TBB is installed (<tbbroot>), and looks for the apropriate headers; and libraries there. This is the top-level directory where TBB is installed; (e.g. /opt/local). * -DCMAKE_INSTALL_PREFIX=<install_dir> -- <install_dir> is the directory to; which you wish Salmon to be installed. If you don't specify this option,; it will be installed locally in the top-level directory (i.e. the directory; directly above ""build""). There are a number of other libraries upon which Salmon depends, but CMake ; should fetch these for you automatically. Setting the appropriate flags, you can then run the CMake configure step as; follows:. ::; ; > cmake [FLAGS] .. The above command is the cmake configuration step, which *should* complain if; anything goes wrong. Next, you have to run the build step. Depending on what; libraries need to be fetched and installed, this could take a while; (specifically if the installation needs to install Boost). To start the build,; just run make. ::. > make. If the build is successful, the appropriate executables and libraries should be; created. There are two points to note about the build process. First, if the; build system is downloading and compiling boost, you may see a large number of; warnings during compilation; these are normal. Second, note that CMake has; colored output by default, and the steps which create or link libraries are; printed in red. This is the color chosen by CMake for linking messages, and; does not denote an error in the build process. ; ; Finally, after everything is built, the libraries and executable can be; installed with:. ::; ; > make install. You can test the installation by running. ::. > make test. This should run a simple test and tell you if it succeeded or not. .. _CMake : http://www.cmake.org ; .. _Boost: http://www.boost.org; ",MatchSource.DOCS,doc/source/building.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst:3281,Deployability,install,install,3281,"tate version in <boostdir>. This is the; top-level directory where Boost is installed (e.g. /opt/local). * -DTBB_INSTALL_DIR=<tbbroot> -- Tells CMake where an existing installation of; Intel's TBB is installed (<tbbroot>), and looks for the apropriate headers; and libraries there. This is the top-level directory where TBB is installed; (e.g. /opt/local). * -DCMAKE_INSTALL_PREFIX=<install_dir> -- <install_dir> is the directory to; which you wish Salmon to be installed. If you don't specify this option,; it will be installed locally in the top-level directory (i.e. the directory; directly above ""build""). There are a number of other libraries upon which Salmon depends, but CMake ; should fetch these for you automatically. Setting the appropriate flags, you can then run the CMake configure step as; follows:. ::; ; > cmake [FLAGS] .. The above command is the cmake configuration step, which *should* complain if; anything goes wrong. Next, you have to run the build step. Depending on what; libraries need to be fetched and installed, this could take a while; (specifically if the installation needs to install Boost). To start the build,; just run make. ::. > make. If the build is successful, the appropriate executables and libraries should be; created. There are two points to note about the build process. First, if the; build system is downloading and compiling boost, you may see a large number of; warnings during compilation; these are normal. Second, note that CMake has; colored output by default, and the steps which create or link libraries are; printed in red. This is the color chosen by CMake for linking messages, and; does not denote an error in the build process. ; ; Finally, after everything is built, the libraries and executable can be; installed with:. ::; ; > make install. You can test the installation by running. ::. > make test. This should run a simple test and tell you if it succeeded or not. .. _CMake : http://www.cmake.org ; .. _Boost: http://www.boost.org; ",MatchSource.DOCS,doc/source/building.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst:3938,Deployability,install,installed,3938,"tate version in <boostdir>. This is the; top-level directory where Boost is installed (e.g. /opt/local). * -DTBB_INSTALL_DIR=<tbbroot> -- Tells CMake where an existing installation of; Intel's TBB is installed (<tbbroot>), and looks for the apropriate headers; and libraries there. This is the top-level directory where TBB is installed; (e.g. /opt/local). * -DCMAKE_INSTALL_PREFIX=<install_dir> -- <install_dir> is the directory to; which you wish Salmon to be installed. If you don't specify this option,; it will be installed locally in the top-level directory (i.e. the directory; directly above ""build""). There are a number of other libraries upon which Salmon depends, but CMake ; should fetch these for you automatically. Setting the appropriate flags, you can then run the CMake configure step as; follows:. ::; ; > cmake [FLAGS] .. The above command is the cmake configuration step, which *should* complain if; anything goes wrong. Next, you have to run the build step. Depending on what; libraries need to be fetched and installed, this could take a while; (specifically if the installation needs to install Boost). To start the build,; just run make. ::. > make. If the build is successful, the appropriate executables and libraries should be; created. There are two points to note about the build process. First, if the; build system is downloading and compiling boost, you may see a large number of; warnings during compilation; these are normal. Second, note that CMake has; colored output by default, and the steps which create or link libraries are; printed in red. This is the color chosen by CMake for linking messages, and; does not denote an error in the build process. ; ; Finally, after everything is built, the libraries and executable can be; installed with:. ::; ; > make install. You can test the installation by running. ::. > make test. This should run a simple test and tell you if it succeeded or not. .. _CMake : http://www.cmake.org ; .. _Boost: http://www.boost.org; ",MatchSource.DOCS,doc/source/building.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst:3968,Deployability,install,install,3968,"tate version in <boostdir>. This is the; top-level directory where Boost is installed (e.g. /opt/local). * -DTBB_INSTALL_DIR=<tbbroot> -- Tells CMake where an existing installation of; Intel's TBB is installed (<tbbroot>), and looks for the apropriate headers; and libraries there. This is the top-level directory where TBB is installed; (e.g. /opt/local). * -DCMAKE_INSTALL_PREFIX=<install_dir> -- <install_dir> is the directory to; which you wish Salmon to be installed. If you don't specify this option,; it will be installed locally in the top-level directory (i.e. the directory; directly above ""build""). There are a number of other libraries upon which Salmon depends, but CMake ; should fetch these for you automatically. Setting the appropriate flags, you can then run the CMake configure step as; follows:. ::; ; > cmake [FLAGS] .. The above command is the cmake configuration step, which *should* complain if; anything goes wrong. Next, you have to run the build step. Depending on what; libraries need to be fetched and installed, this could take a while; (specifically if the installation needs to install Boost). To start the build,; just run make. ::. > make. If the build is successful, the appropriate executables and libraries should be; created. There are two points to note about the build process. First, if the; build system is downloading and compiling boost, you may see a large number of; warnings during compilation; these are normal. Second, note that CMake has; colored output by default, and the steps which create or link libraries are; printed in red. This is the color chosen by CMake for linking messages, and; does not denote an error in the build process. ; ; Finally, after everything is built, the libraries and executable can be; installed with:. ::; ; > make install. You can test the installation by running. ::. > make test. This should run a simple test and tell you if it succeeded or not. .. _CMake : http://www.cmake.org ; .. _Boost: http://www.boost.org; ",MatchSource.DOCS,doc/source/building.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst:3994,Deployability,install,installation,3994,"tate version in <boostdir>. This is the; top-level directory where Boost is installed (e.g. /opt/local). * -DTBB_INSTALL_DIR=<tbbroot> -- Tells CMake where an existing installation of; Intel's TBB is installed (<tbbroot>), and looks for the apropriate headers; and libraries there. This is the top-level directory where TBB is installed; (e.g. /opt/local). * -DCMAKE_INSTALL_PREFIX=<install_dir> -- <install_dir> is the directory to; which you wish Salmon to be installed. If you don't specify this option,; it will be installed locally in the top-level directory (i.e. the directory; directly above ""build""). There are a number of other libraries upon which Salmon depends, but CMake ; should fetch these for you automatically. Setting the appropriate flags, you can then run the CMake configure step as; follows:. ::; ; > cmake [FLAGS] .. The above command is the cmake configuration step, which *should* complain if; anything goes wrong. Next, you have to run the build step. Depending on what; libraries need to be fetched and installed, this could take a while; (specifically if the installation needs to install Boost). To start the build,; just run make. ::. > make. If the build is successful, the appropriate executables and libraries should be; created. There are two points to note about the build process. First, if the; build system is downloading and compiling boost, you may see a large number of; warnings during compilation; these are normal. Second, note that CMake has; colored output by default, and the steps which create or link libraries are; printed in red. This is the color chosen by CMake for linking messages, and; does not denote an error in the build process. ; ; Finally, after everything is built, the libraries and executable can be; installed with:. ::; ; > make install. You can test the installation by running. ::. > make test. This should run a simple test and tell you if it succeeded or not. .. _CMake : http://www.cmake.org ; .. _Boost: http://www.boost.org; ",MatchSource.DOCS,doc/source/building.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst:802,Integrability,depend,dependencies,802,"Requirements; ============. Binary Releases; ---------------. Pre-compiled binaries of the latest release of Salmon for a number different; platforms are available available under the `Releases tab; <https://github.com/COMBINE-lab/salmon/releases>`_ of Salmon's `GitHub; repository <https://github.com/COMBINE-lab/salmon>`_. You should be able to; get started quickly by finding a binary from the list that is compatible with; your platform. Additionally, you can obtain a Docker image of the latest version; from DockerHub using:. ::. > docker pull combinelab/salmon; . Requirements for Building from Source; -------------------------------------. * A C++11 conformant compiler (currently tested with GCC>=4.7 and Clang>=3.4); * CMake_. Salmon uses the CMake build system to check, fetch and install; dependencies, and to compile and install Salmon. CMake is available for all; major platforms (though Salmon is currently unsupported on Windows.); ; Installation; ============. After downloading the Salmon source distribution and unpacking it, change into the top-level directory:. ::. > cd salmon. Then, create and out-of-source build directory and change into it:. ::. > mkdir build; > cd build. Salmon makes extensive use of Boost_. We recommend installing the most; recent version (1.55) systemwide if possible. If Boost is not installed on your; system, the build process will fetch, compile and install it locally. However,; if you already have a recent version of Boost available on your system, it make; sense to tell the build system to use that. If you have Boost installed you can tell CMake where to look for it. Likewise,; if you already have `Intel's Threading Building Blocks; <http://threadingbuildingblocks.org/>`_ library installed, you can tell CMake; where it is as well. The flags for CMake are as follows:. * -DFETCH_BOOST=TRUE -- If you don't have Boost installed (or have an older; version of it), you can provide the FETCH_BOOST flag instead of the; BOOST_ROOT variable, whi",MatchSource.DOCS,doc/source/building.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst:2837,Integrability,depend,depends,2837,"H_BOOST=TRUE -- If you don't have Boost installed (or have an older; version of it), you can provide the FETCH_BOOST flag instead of the; BOOST_ROOT variable, which will cause CMake to fetch and build Boost locally. * -DBOOST_ROOT=<boostdir> -- Tells CMake where an existing installtion of Boost; resides, and looks for the appropritate version in <boostdir>. This is the; top-level directory where Boost is installed (e.g. /opt/local). * -DTBB_INSTALL_DIR=<tbbroot> -- Tells CMake where an existing installation of; Intel's TBB is installed (<tbbroot>), and looks for the apropriate headers; and libraries there. This is the top-level directory where TBB is installed; (e.g. /opt/local). * -DCMAKE_INSTALL_PREFIX=<install_dir> -- <install_dir> is the directory to; which you wish Salmon to be installed. If you don't specify this option,; it will be installed locally in the top-level directory (i.e. the directory; directly above ""build""). There are a number of other libraries upon which Salmon depends, but CMake ; should fetch these for you automatically. Setting the appropriate flags, you can then run the CMake configure step as; follows:. ::; ; > cmake [FLAGS] .. The above command is the cmake configuration step, which *should* complain if; anything goes wrong. Next, you have to run the build step. Depending on what; libraries need to be fetched and installed, this could take a while; (specifically if the installation needs to install Boost). To start the build,; just run make. ::. > make. If the build is successful, the appropriate executables and libraries should be; created. There are two points to note about the build process. First, if the; build system is downloading and compiling boost, you may see a large number of; warnings during compilation; these are normal. Second, note that CMake has; colored output by default, and the steps which create or link libraries are; printed in red. This is the color chosen by CMake for linking messages, and; does not denote an error i",MatchSource.DOCS,doc/source/building.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst:3799,Integrability,message,messages,3799,"tate version in <boostdir>. This is the; top-level directory where Boost is installed (e.g. /opt/local). * -DTBB_INSTALL_DIR=<tbbroot> -- Tells CMake where an existing installation of; Intel's TBB is installed (<tbbroot>), and looks for the apropriate headers; and libraries there. This is the top-level directory where TBB is installed; (e.g. /opt/local). * -DCMAKE_INSTALL_PREFIX=<install_dir> -- <install_dir> is the directory to; which you wish Salmon to be installed. If you don't specify this option,; it will be installed locally in the top-level directory (i.e. the directory; directly above ""build""). There are a number of other libraries upon which Salmon depends, but CMake ; should fetch these for you automatically. Setting the appropriate flags, you can then run the CMake configure step as; follows:. ::; ; > cmake [FLAGS] .. The above command is the cmake configuration step, which *should* complain if; anything goes wrong. Next, you have to run the build step. Depending on what; libraries need to be fetched and installed, this could take a while; (specifically if the installation needs to install Boost). To start the build,; just run make. ::. > make. If the build is successful, the appropriate executables and libraries should be; created. There are two points to note about the build process. First, if the; build system is downloading and compiling boost, you may see a large number of; warnings during compilation; these are normal. Second, note that CMake has; colored output by default, and the steps which create or link libraries are; printed in red. This is the color chosen by CMake for linking messages, and; does not denote an error in the build process. ; ; Finally, after everything is built, the libraries and executable can be; installed with:. ::; ; > make install. You can test the installation by running. ::. > make test. This should run a simple test and tell you if it succeeded or not. .. _CMake : http://www.cmake.org ; .. _Boost: http://www.boost.org; ",MatchSource.DOCS,doc/source/building.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst:1988,Modifiability,variab,variable,1988,"ows.); ; Installation; ============. After downloading the Salmon source distribution and unpacking it, change into the top-level directory:. ::. > cd salmon. Then, create and out-of-source build directory and change into it:. ::. > mkdir build; > cd build. Salmon makes extensive use of Boost_. We recommend installing the most; recent version (1.55) systemwide if possible. If Boost is not installed on your; system, the build process will fetch, compile and install it locally. However,; if you already have a recent version of Boost available on your system, it make; sense to tell the build system to use that. If you have Boost installed you can tell CMake where to look for it. Likewise,; if you already have `Intel's Threading Building Blocks; <http://threadingbuildingblocks.org/>`_ library installed, you can tell CMake; where it is as well. The flags for CMake are as follows:. * -DFETCH_BOOST=TRUE -- If you don't have Boost installed (or have an older; version of it), you can provide the FETCH_BOOST flag instead of the; BOOST_ROOT variable, which will cause CMake to fetch and build Boost locally. * -DBOOST_ROOT=<boostdir> -- Tells CMake where an existing installtion of Boost; resides, and looks for the appropritate version in <boostdir>. This is the; top-level directory where Boost is installed (e.g. /opt/local). * -DTBB_INSTALL_DIR=<tbbroot> -- Tells CMake where an existing installation of; Intel's TBB is installed (<tbbroot>), and looks for the apropriate headers; and libraries there. This is the top-level directory where TBB is installed; (e.g. /opt/local). * -DCMAKE_INSTALL_PREFIX=<install_dir> -- <install_dir> is the directory to; which you wish Salmon to be installed. If you don't specify this option,; it will be installed locally in the top-level directory (i.e. the directory; directly above ""build""). There are a number of other libraries upon which Salmon depends, but CMake ; should fetch these for you automatically. Setting the appropriate flags, you can the",MatchSource.DOCS,doc/source/building.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst:2958,Modifiability,config,configure,2958,"e FETCH_BOOST flag instead of the; BOOST_ROOT variable, which will cause CMake to fetch and build Boost locally. * -DBOOST_ROOT=<boostdir> -- Tells CMake where an existing installtion of Boost; resides, and looks for the appropritate version in <boostdir>. This is the; top-level directory where Boost is installed (e.g. /opt/local). * -DTBB_INSTALL_DIR=<tbbroot> -- Tells CMake where an existing installation of; Intel's TBB is installed (<tbbroot>), and looks for the apropriate headers; and libraries there. This is the top-level directory where TBB is installed; (e.g. /opt/local). * -DCMAKE_INSTALL_PREFIX=<install_dir> -- <install_dir> is the directory to; which you wish Salmon to be installed. If you don't specify this option,; it will be installed locally in the top-level directory (i.e. the directory; directly above ""build""). There are a number of other libraries upon which Salmon depends, but CMake ; should fetch these for you automatically. Setting the appropriate flags, you can then run the CMake configure step as; follows:. ::; ; > cmake [FLAGS] .. The above command is the cmake configuration step, which *should* complain if; anything goes wrong. Next, you have to run the build step. Depending on what; libraries need to be fetched and installed, this could take a while; (specifically if the installation needs to install Boost). To start the build,; just run make. ::. > make. If the build is successful, the appropriate executables and libraries should be; created. There are two points to note about the build process. First, if the; build system is downloading and compiling boost, you may see a large number of; warnings during compilation; these are normal. Second, note that CMake has; colored output by default, and the steps which create or link libraries are; printed in red. This is the color chosen by CMake for linking messages, and; does not denote an error in the build process. ; ; Finally, after everything is built, the libraries and executable can be; insta",MatchSource.DOCS,doc/source/building.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst:3043,Modifiability,config,configuration,3043,"OST_ROOT=<boostdir> -- Tells CMake where an existing installtion of Boost; resides, and looks for the appropritate version in <boostdir>. This is the; top-level directory where Boost is installed (e.g. /opt/local). * -DTBB_INSTALL_DIR=<tbbroot> -- Tells CMake where an existing installation of; Intel's TBB is installed (<tbbroot>), and looks for the apropriate headers; and libraries there. This is the top-level directory where TBB is installed; (e.g. /opt/local). * -DCMAKE_INSTALL_PREFIX=<install_dir> -- <install_dir> is the directory to; which you wish Salmon to be installed. If you don't specify this option,; it will be installed locally in the top-level directory (i.e. the directory; directly above ""build""). There are a number of other libraries upon which Salmon depends, but CMake ; should fetch these for you automatically. Setting the appropriate flags, you can then run the CMake configure step as; follows:. ::; ; > cmake [FLAGS] .. The above command is the cmake configuration step, which *should* complain if; anything goes wrong. Next, you have to run the build step. Depending on what; libraries need to be fetched and installed, this could take a while; (specifically if the installation needs to install Boost). To start the build,; just run make. ::. > make. If the build is successful, the appropriate executables and libraries should be; created. There are two points to note about the build process. First, if the; build system is downloading and compiling boost, you may see a large number of; warnings during compilation; these are normal. Second, note that CMake has; colored output by default, and the steps which create or link libraries are; printed in red. This is the color chosen by CMake for linking messages, and; does not denote an error in the build process. ; ; Finally, after everything is built, the libraries and executable can be; installed with:. ::; ; > make install. You can test the installation by running. ::. > make test. This should run a simple ",MatchSource.DOCS,doc/source/building.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst:690,Testability,test,tested,690,"Requirements; ============. Binary Releases; ---------------. Pre-compiled binaries of the latest release of Salmon for a number different; platforms are available available under the `Releases tab; <https://github.com/COMBINE-lab/salmon/releases>`_ of Salmon's `GitHub; repository <https://github.com/COMBINE-lab/salmon>`_. You should be able to; get started quickly by finding a binary from the list that is compatible with; your platform. Additionally, you can obtain a Docker image of the latest version; from DockerHub using:. ::. > docker pull combinelab/salmon; . Requirements for Building from Source; -------------------------------------. * A C++11 conformant compiler (currently tested with GCC>=4.7 and Clang>=3.4); * CMake_. Salmon uses the CMake build system to check, fetch and install; dependencies, and to compile and install Salmon. CMake is available for all; major platforms (though Salmon is currently unsupported on Windows.); ; Installation; ============. After downloading the Salmon source distribution and unpacking it, change into the top-level directory:. ::. > cd salmon. Then, create and out-of-source build directory and change into it:. ::. > mkdir build; > cd build. Salmon makes extensive use of Boost_. We recommend installing the most; recent version (1.55) systemwide if possible. If Boost is not installed on your; system, the build process will fetch, compile and install it locally. However,; if you already have a recent version of Boost available on your system, it make; sense to tell the build system to use that. If you have Boost installed you can tell CMake where to look for it. Likewise,; if you already have `Intel's Threading Building Blocks; <http://threadingbuildingblocks.org/>`_ library installed, you can tell CMake; where it is as well. The flags for CMake are as follows:. * -DFETCH_BOOST=TRUE -- If you don't have Boost installed (or have an older; version of it), you can provide the FETCH_BOOST flag instead of the; BOOST_ROOT variable, whi",MatchSource.DOCS,doc/source/building.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst:3985,Testability,test,test,3985,"tate version in <boostdir>. This is the; top-level directory where Boost is installed (e.g. /opt/local). * -DTBB_INSTALL_DIR=<tbbroot> -- Tells CMake where an existing installation of; Intel's TBB is installed (<tbbroot>), and looks for the apropriate headers; and libraries there. This is the top-level directory where TBB is installed; (e.g. /opt/local). * -DCMAKE_INSTALL_PREFIX=<install_dir> -- <install_dir> is the directory to; which you wish Salmon to be installed. If you don't specify this option,; it will be installed locally in the top-level directory (i.e. the directory; directly above ""build""). There are a number of other libraries upon which Salmon depends, but CMake ; should fetch these for you automatically. Setting the appropriate flags, you can then run the CMake configure step as; follows:. ::; ; > cmake [FLAGS] .. The above command is the cmake configuration step, which *should* complain if; anything goes wrong. Next, you have to run the build step. Depending on what; libraries need to be fetched and installed, this could take a while; (specifically if the installation needs to install Boost). To start the build,; just run make. ::. > make. If the build is successful, the appropriate executables and libraries should be; created. There are two points to note about the build process. First, if the; build system is downloading and compiling boost, you may see a large number of; warnings during compilation; these are normal. Second, note that CMake has; colored output by default, and the steps which create or link libraries are; printed in red. This is the color chosen by CMake for linking messages, and; does not denote an error in the build process. ; ; Finally, after everything is built, the libraries and executable can be; installed with:. ::; ; > make install. You can test the installation by running. ::. > make test. This should run a simple test and tell you if it succeeded or not. .. _CMake : http://www.cmake.org ; .. _Boost: http://www.boost.org; ",MatchSource.DOCS,doc/source/building.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst:4030,Testability,test,test,4030,"tate version in <boostdir>. This is the; top-level directory where Boost is installed (e.g. /opt/local). * -DTBB_INSTALL_DIR=<tbbroot> -- Tells CMake where an existing installation of; Intel's TBB is installed (<tbbroot>), and looks for the apropriate headers; and libraries there. This is the top-level directory where TBB is installed; (e.g. /opt/local). * -DCMAKE_INSTALL_PREFIX=<install_dir> -- <install_dir> is the directory to; which you wish Salmon to be installed. If you don't specify this option,; it will be installed locally in the top-level directory (i.e. the directory; directly above ""build""). There are a number of other libraries upon which Salmon depends, but CMake ; should fetch these for you automatically. Setting the appropriate flags, you can then run the CMake configure step as; follows:. ::; ; > cmake [FLAGS] .. The above command is the cmake configuration step, which *should* complain if; anything goes wrong. Next, you have to run the build step. Depending on what; libraries need to be fetched and installed, this could take a while; (specifically if the installation needs to install Boost). To start the build,; just run make. ::. > make. If the build is successful, the appropriate executables and libraries should be; created. There are two points to note about the build process. First, if the; build system is downloading and compiling boost, you may see a large number of; warnings during compilation; these are normal. Second, note that CMake has; colored output by default, and the steps which create or link libraries are; printed in red. This is the color chosen by CMake for linking messages, and; does not denote an error in the build process. ; ; Finally, after everything is built, the libraries and executable can be; installed with:. ::; ; > make install. You can test the installation by running. ::. > make test. This should run a simple test and tell you if it succeeded or not. .. _CMake : http://www.cmake.org ; .. _Boost: http://www.boost.org; ",MatchSource.DOCS,doc/source/building.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst:4061,Testability,test,test,4061,"tate version in <boostdir>. This is the; top-level directory where Boost is installed (e.g. /opt/local). * -DTBB_INSTALL_DIR=<tbbroot> -- Tells CMake where an existing installation of; Intel's TBB is installed (<tbbroot>), and looks for the apropriate headers; and libraries there. This is the top-level directory where TBB is installed; (e.g. /opt/local). * -DCMAKE_INSTALL_PREFIX=<install_dir> -- <install_dir> is the directory to; which you wish Salmon to be installed. If you don't specify this option,; it will be installed locally in the top-level directory (i.e. the directory; directly above ""build""). There are a number of other libraries upon which Salmon depends, but CMake ; should fetch these for you automatically. Setting the appropriate flags, you can then run the CMake configure step as; follows:. ::; ; > cmake [FLAGS] .. The above command is the cmake configuration step, which *should* complain if; anything goes wrong. Next, you have to run the build step. Depending on what; libraries need to be fetched and installed, this could take a while; (specifically if the installation needs to install Boost). To start the build,; just run make. ::. > make. If the build is successful, the appropriate executables and libraries should be; created. There are two points to note about the build process. First, if the; build system is downloading and compiling boost, you may see a large number of; warnings during compilation; these are normal. Second, note that CMake has; colored output by default, and the steps which create or link libraries are; printed in red. This is the color chosen by CMake for linking messages, and; does not denote an error in the build process. ; ; Finally, after everything is built, the libraries and executable can be; installed with:. ::; ; > make install. You can test the installation by running. ::. > make test. This should run a simple test and tell you if it succeeded or not. .. _CMake : http://www.cmake.org ; .. _Boost: http://www.boost.org; ",MatchSource.DOCS,doc/source/building.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst:4054,Usability,simpl,simple,4054,"tate version in <boostdir>. This is the; top-level directory where Boost is installed (e.g. /opt/local). * -DTBB_INSTALL_DIR=<tbbroot> -- Tells CMake where an existing installation of; Intel's TBB is installed (<tbbroot>), and looks for the apropriate headers; and libraries there. This is the top-level directory where TBB is installed; (e.g. /opt/local). * -DCMAKE_INSTALL_PREFIX=<install_dir> -- <install_dir> is the directory to; which you wish Salmon to be installed. If you don't specify this option,; it will be installed locally in the top-level directory (i.e. the directory; directly above ""build""). There are a number of other libraries upon which Salmon depends, but CMake ; should fetch these for you automatically. Setting the appropriate flags, you can then run the CMake configure step as; follows:. ::; ; > cmake [FLAGS] .. The above command is the cmake configuration step, which *should* complain if; anything goes wrong. Next, you have to run the build step. Depending on what; libraries need to be fetched and installed, this could take a while; (specifically if the installation needs to install Boost). To start the build,; just run make. ::. > make. If the build is successful, the appropriate executables and libraries should be; created. There are two points to note about the build process. First, if the; build system is downloading and compiling boost, you may see a large number of; warnings during compilation; these are normal. Second, note that CMake has; colored output by default, and the steps which create or link libraries are; printed in red. This is the color chosen by CMake for linking messages, and; does not denote an error in the build process. ; ; Finally, after everything is built, the libraries and executable can be; installed with:. ::; ; > make install. You can test the installation by running. ::. > make test. This should run a simple test and tell you if it succeeded or not. .. _CMake : http://www.cmake.org ; .. _Boost: http://www.boost.org; ",MatchSource.DOCS,doc/source/building.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/building.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/file_formats.rst:1401,Availability,down,downstream,1401,"ear in the following order:. +------+--------+-----------------+----+----------+; | Name | Length | EffectiveLength |TPM | NumReads |; +------+--------+-----------------+----+----------+. Each subsequent row describes a single quantification record. The columns have; the following interpretation. * **Name** --- ; This is the name of the target transcript provided in the input transcript database (FASTA file). . * **Length** ---; This is the length of the target transcript in nucleotides. * **EffectiveLength** ---; This is the computed *effective* length of the target transcript. It takes into account ; all factors being modeled that will effect the probability of sampling fragments from; this transcript, including the fragment length distribution and sequence-specific and ; gc-fragment bias (if they are being modeled). * **TPM** ---; This is salmon's estimate of the relative abundance of this transcript in units of Transcripts Per Million (TPM).; TPM is the recommended relative abundance measure to use for downstream analysis. . * **NumReads** --- ; This is salmon's estimate of the number of reads mapping to each transcript that was quantified. It is an ""estimate"" ; insofar as it is the expected number of reads that have originated from each transcript given the structure of the uniquely ; mapping and multi-mapping reads and the relative abundance estimates for each transcript. Command Information File; ------------------------. In the top-level quantification directory, there will be a file called ``cmd_info.json``. This is a; JSON format file that records the main command line parameters with which Salmon was invoked for the ; run that produced the output in this directory. Auxiliary Files; ---------------. The top-level quantification directory will contain an auxiliary directory called ``aux_info`` (unless ; the auxiliary directory name was overridden via the command line). This directory will have a number; of files (and subfolders) depending on how salmon was i",MatchSource.DOCS,doc/source/file_formats.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/file_formats.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/file_formats.rst:2351,Integrability,depend,depending,2351,"; TPM is the recommended relative abundance measure to use for downstream analysis. . * **NumReads** --- ; This is salmon's estimate of the number of reads mapping to each transcript that was quantified. It is an ""estimate"" ; insofar as it is the expected number of reads that have originated from each transcript given the structure of the uniquely ; mapping and multi-mapping reads and the relative abundance estimates for each transcript. Command Information File; ------------------------. In the top-level quantification directory, there will be a file called ``cmd_info.json``. This is a; JSON format file that records the main command line parameters with which Salmon was invoked for the ; run that produced the output in this directory. Auxiliary Files; ---------------. The top-level quantification directory will contain an auxiliary directory called ``aux_info`` (unless ; the auxiliary directory name was overridden via the command line). This directory will have a number; of files (and subfolders) depending on how salmon was invoked. """"""""""""""""""""""""""""""""; Meta information; """""""""""""""""""""""""""""""". The auxiliary directory will contain a JSON format file called; ``meta_info.json`` which contains meta information about the run,; including stats such as the number of observed and mapped fragments,; details of the bias modeling etc. If Salmon was run with automatic; inference of the library type (i.e. ``--libType A``), then one; particularly important piece of information contained in this file is; the inferred library type. Most of the information recorded in this; file should be self-descriptive. """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Unique and ambiguous count file; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""". The auxiliary directory also contains 2-column tab-separated file called; ``ambig_info.tsv``. This file contains information about the number of; uniquely-mapping reads as well as the total number of ambiguously-mapping reads; for each transcript. This file is provided mostly for explorator",MatchSource.DOCS,doc/source/file_formats.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/file_formats.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/file_formats.rst:7565,Testability,log,logarithmic,7565," length of the sub-context exceed the order of the; model at that position) contain a 0. This array can be re-shaped; into a matrix of the appropriate size. Finally, the file contains the marginalized 0:sup:`th`-order; probabilities (i.e. the probability of each nucleotide at each; position in the context). This is stored as a 4-by-context length; matrix. As before, this entry begins with two signed integers that; give the number of rows and columns, followed by an array of doubles; giving the marginal probabilities. The rows are in lexicographic; order. """"""""""""""""""""""""""""""""""""""""""""; Fragment-GC bias files; """""""""""""""""""""""""""""""""""""""""""". If Salmon was run with fragment-GC bias correction enabled, the; auxiliary directory will contain two files named ``expected_gc.gz``; and ``observed_gc.gz``. These are gzipped binary files containing,; respectively, the expected and observed fragment-GC content curves.; These files both have the same form. They consist of a 32-bit signed; int, *dtype* which specifies if the values to follow are in; logarithmic space or not. Then, the file contains two signed integers; of type ``std::ptrdiff`` which give the number of rows and columns of; the matrix to follow. Finally, there is an array of *nrow* by *ncol*; doubles. Each row corresponds to a conditional fragment GC; distribution, and the number of columns is the number of bins in the; learned (or expected) fragment-GC distribution. .. _eq-class-file:. """"""""""""""""""""""""""""""""""""""""""""; Equivalence class file; """""""""""""""""""""""""""""""""""""""""""". If salmon was run with the ``--dumpEq`` option, then a file called ``eq_classes.txt``; will exist in the auxiliary directory. The format of that file is as follows:. ::; ; N (num transcripts); M (num equiv classes); tn_1; tn_2; ...; tn_N; eq_1_size t_11 t_12 ... count; eq_2_size t_21 t_22 ... count. ; That is, the file begins with a line that contains the number of; transcripts (say N) then a line that contains the number of; equivalence classes (say M). It is then followed by N",MatchSource.DOCS,doc/source/file_formats.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/file_formats.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/file_formats.rst:5200,Usability,learn,learned,5200,"criptome in more than one way may contribute to multiple library; type counts. **Note**: This file is currently not generated when Salmon; is run in alignment-based mode. """"""""""""""""""""""""""""""""""""""""""""""""""""""""; Fragment length distribution; """""""""""""""""""""""""""""""""""""""""""""""""""""""". The auxiliary directory will contain a file called ``fld.gz``. This; file contains an approximation of the observed fragment length; distribution. It is a gzipped, binary file containing integer counts.; The number of (signed, 32-bit) integers (with machine-native; endianness) is equal to the number of bins in the fragment length; distribution (1,001 by default --- for fragments ranging in length; from 0 to 1,000 nucleotides). """"""""""""""""""""""""""""""""""""""""""""""""""""""""; Sequence-specific bias files; """""""""""""""""""""""""""""""""""""""""""""""""""""""". If sequence-specific bias modeling was enabled, there will be 4 files; in the auxiliary directory named ``obs5_seq.gz``, ``obs3_seq.gz``,; ``exp5_seq.gz``, ``exp5_seq.gz``. These encode the parameters of the; VLMM that were learned for the 5' and 3' fragment ends. Each file; is a gzipped, binary file with the same format. It begins with 3 32-bit signed integers which record the length of the; context (window around the read start / end) that is modeled, follwed; by the length of the context that is to the left of the read and the; length of the context that is to the right of the read. Next, the file contains 3 arrays of 32-bit signed integers (each of which; have a length of equal to the context length recorded above). The first; records the order of the VLMM used at each position, the second records; the *shifts* and the *widths* required to extract each sub-context --- these; are implementation details. Next, the file contains a matrix that encodes all VLMM probabilities.; This starts with two signed integers of type ``std::ptrdiff_t``. This; is a platform-specific type, but on most 64-bit systems should; correspond to a 64-bit signed integer. These numbers denote the number of; rows (*nrow*) and",MatchSource.DOCS,doc/source/file_formats.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/file_formats.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/file_formats.rst:7907,Usability,learn,learned,7907,"xt length; matrix. As before, this entry begins with two signed integers that; give the number of rows and columns, followed by an array of doubles; giving the marginal probabilities. The rows are in lexicographic; order. """"""""""""""""""""""""""""""""""""""""""""; Fragment-GC bias files; """""""""""""""""""""""""""""""""""""""""""". If Salmon was run with fragment-GC bias correction enabled, the; auxiliary directory will contain two files named ``expected_gc.gz``; and ``observed_gc.gz``. These are gzipped binary files containing,; respectively, the expected and observed fragment-GC content curves.; These files both have the same form. They consist of a 32-bit signed; int, *dtype* which specifies if the values to follow are in; logarithmic space or not. Then, the file contains two signed integers; of type ``std::ptrdiff`` which give the number of rows and columns of; the matrix to follow. Finally, there is an array of *nrow* by *ncol*; doubles. Each row corresponds to a conditional fragment GC; distribution, and the number of columns is the number of bins in the; learned (or expected) fragment-GC distribution. .. _eq-class-file:. """"""""""""""""""""""""""""""""""""""""""""; Equivalence class file; """""""""""""""""""""""""""""""""""""""""""". If salmon was run with the ``--dumpEq`` option, then a file called ``eq_classes.txt``; will exist in the auxiliary directory. The format of that file is as follows:. ::; ; N (num transcripts); M (num equiv classes); tn_1; tn_2; ...; tn_N; eq_1_size t_11 t_12 ... count; eq_2_size t_21 t_22 ... count. ; That is, the file begins with a line that contains the number of; transcripts (say N) then a line that contains the number of; equivalence classes (say M). It is then followed by N lines that list; the transcript names --- the order here is important, because the; labels of the equivalence classes are given in terms of the ID's of; the transcripts. The rank of a transcript in this list is the ID with; which it will be labeled when it appears in the label of an; equivalence class. Finally, the file contains M lines,",MatchSource.DOCS,doc/source/file_formats.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/file_formats.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/file_formats.rst:11377,Usability,simpl,simple,11377,"; tn_N; eq_1_size t_11 t_12 ... p_11 p_12 ... count; eq_2_size t_21 t_22 ... p_21 p_22 ... count. ; That is, the file begins with a line that contains the number of; transcripts (say N) then a line that contains the number of; equivalence classes (say M). It is then followed by N lines that list; the transcript names --- the order here is important, because the; labels of the equivalence classes are given in terms of the ID's of; the transcripts. The rank of a transcript in this list is the ID with; which it will be labeled when it appears in the label of an; equivalence class. Finally, the file contains M lines, each of which; describes a range-factorized equivalence class of fragments. The first entry in this; line is the number of transcripts in the label of this equivalence; class (the number of different transcripts to which fragments in this; class map --- call this k). The line then contains the k transcript; IDs that *partially* define the label of this range-factorized equivalence class; followed by k floating point values which correspond to the conditional probabilities ; of drawing a fragment from each of these k transcripts within this range-factorized ; equivalence class. Finally, the line contains the count of fragments in this; equivalence class (how many fragments mapped to these; transcripts with approximately this conditional probability distribution). ; The values in each such line are tab separated. ; **Note**: The indices for transcripts referenced in this file start at 0.; **Note**: Unlike the *simple* equivalence classes, the same transcript set can ; appear more than once in the set of range-factorized equivalence classes. This is ; because different sets of fragments can induce quite different conditional probability ; distributions among these transcripts. For more details on this representation, please ; check the `paper describing range-factorized equivalence classes <https://academic.oup.com/bioinformatics/article/33/14/i142/3953977>`_.",MatchSource.DOCS,doc/source/file_formats.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/file_formats.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/index.rst:107,Energy Efficiency,adapt,adapt,107,".. Sailfish documentation master file, created by; sphinx-quickstart on Tue Jul 15 17:48:43 2014.; You can adapt this file completely to your liking, but it should at least; contain the root `toctree` directive. Welcome to Salmon's documentation!; =============================================. Contents:. .. toctree::; :maxdepth: 2; ; building.rst; salmon.rst; alevin.rst; file_formats.rst; library_type.rst. Indices and tables; ==================. * :ref:`genindex`; * :ref:`modindex`; * :ref:`search`. ",MatchSource.DOCS,doc/source/index.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/index.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/index.rst:107,Modifiability,adapt,adapt,107,".. Sailfish documentation master file, created by; sphinx-quickstart on Tue Jul 15 17:48:43 2014.; You can adapt this file completely to your liking, but it should at least; contain the root `toctree` directive. Welcome to Salmon's documentation!; =============================================. Contents:. .. toctree::; :maxdepth: 2; ; building.rst; salmon.rst; alevin.rst; file_formats.rst; library_type.rst. Indices and tables; ==================. * :ref:`genindex`; * :ref:`modindex`; * :ref:`search`. ",MatchSource.DOCS,doc/source/index.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/index.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/library_type.rst:105,Integrability,protocol,protocols,105,".. _FragLibType:. Fragment Library Types; ======================. There are numerous library preparation protocols for RNA-seq that result in; sequencing reads with different characteristics. For example, reads can be; single end (only one side of a fragment is recorded as a read) or paired-end; (reads are generated from both ends of a fragment). Further, the sequencing; reads themselves may be unstranded or strand-specific. Finally, paired-end; protocols will have a specified relative orientation. To characterize the; various different typs of sequencing libraries, we've created a miniature; ""language"" that allows for the succinct description of the many different types; of possible fragment libraries. For paired-end reads, the possible; orientations, along with a graphical description of what they mean, are; illustrated below:. .. image:: ReadLibraryIllustration.png. The library type string consists of three parts: the relative orientation of; the reads, the strandedness of the library, and the directionality of the; reads. The first part of the library string (relative orientation) is only provided if; the library is paired-end. The possible options are:. ::. I = inward; O = outward; M = matching. The second part of the read library string specifies whether the protocol is; stranded or unstranded; the options are:. ::. S = stranded; U = unstranded. If the protocol is unstranded, then we're done. The final part of the library; string specifies the strand from which the read originates in a strand-specific; protocol — it is only provided if the library is stranded (i.e. if the; library format string is of the form S). The possible values are:. ::. F = read 1 (or single-end read) comes from the forward strand; R = read 1 (or single-end read) comes from the reverse strand. So, for example, if you wanted to specify a fragment library of strand-specific; paired-end reads, oriented toward each other, where read 1 comes from the; forward strand and read 2 comes from the r",MatchSource.DOCS,doc/source/library_type.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/library_type.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/library_type.rst:450,Integrability,protocol,protocols,450,".. _FragLibType:. Fragment Library Types; ======================. There are numerous library preparation protocols for RNA-seq that result in; sequencing reads with different characteristics. For example, reads can be; single end (only one side of a fragment is recorded as a read) or paired-end; (reads are generated from both ends of a fragment). Further, the sequencing; reads themselves may be unstranded or strand-specific. Finally, paired-end; protocols will have a specified relative orientation. To characterize the; various different typs of sequencing libraries, we've created a miniature; ""language"" that allows for the succinct description of the many different types; of possible fragment libraries. For paired-end reads, the possible; orientations, along with a graphical description of what they mean, are; illustrated below:. .. image:: ReadLibraryIllustration.png. The library type string consists of three parts: the relative orientation of; the reads, the strandedness of the library, and the directionality of the; reads. The first part of the library string (relative orientation) is only provided if; the library is paired-end. The possible options are:. ::. I = inward; O = outward; M = matching. The second part of the read library string specifies whether the protocol is; stranded or unstranded; the options are:. ::. S = stranded; U = unstranded. If the protocol is unstranded, then we're done. The final part of the library; string specifies the strand from which the read originates in a strand-specific; protocol — it is only provided if the library is stranded (i.e. if the; library format string is of the form S). The possible values are:. ::. F = read 1 (or single-end read) comes from the forward strand; R = read 1 (or single-end read) comes from the reverse strand. So, for example, if you wanted to specify a fragment library of strand-specific; paired-end reads, oriented toward each other, where read 1 comes from the; forward strand and read 2 comes from the r",MatchSource.DOCS,doc/source/library_type.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/library_type.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/library_type.rst:1285,Integrability,protocol,protocol,1285,"d) or paired-end; (reads are generated from both ends of a fragment). Further, the sequencing; reads themselves may be unstranded or strand-specific. Finally, paired-end; protocols will have a specified relative orientation. To characterize the; various different typs of sequencing libraries, we've created a miniature; ""language"" that allows for the succinct description of the many different types; of possible fragment libraries. For paired-end reads, the possible; orientations, along with a graphical description of what they mean, are; illustrated below:. .. image:: ReadLibraryIllustration.png. The library type string consists of three parts: the relative orientation of; the reads, the strandedness of the library, and the directionality of the; reads. The first part of the library string (relative orientation) is only provided if; the library is paired-end. The possible options are:. ::. I = inward; O = outward; M = matching. The second part of the read library string specifies whether the protocol is; stranded or unstranded; the options are:. ::. S = stranded; U = unstranded. If the protocol is unstranded, then we're done. The final part of the library; string specifies the strand from which the read originates in a strand-specific; protocol — it is only provided if the library is stranded (i.e. if the; library format string is of the form S). The possible values are:. ::. F = read 1 (or single-end read) comes from the forward strand; R = read 1 (or single-end read) comes from the reverse strand. So, for example, if you wanted to specify a fragment library of strand-specific; paired-end reads, oriented toward each other, where read 1 comes from the; forward strand and read 2 comes from the reverse strand, you would specify ``-l; ISF`` on the command line. This designates that the library being processed has; the type ""ISF"" meaning, **I**\ nward (the relative orientation), **S**\ tranded; (the protocol is strand-specific), **F**\ orward (read 1 comes from the forwa",MatchSource.DOCS,doc/source/library_type.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/library_type.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/library_type.rst:1381,Integrability,protocol,protocol,1381," unstranded or strand-specific. Finally, paired-end; protocols will have a specified relative orientation. To characterize the; various different typs of sequencing libraries, we've created a miniature; ""language"" that allows for the succinct description of the many different types; of possible fragment libraries. For paired-end reads, the possible; orientations, along with a graphical description of what they mean, are; illustrated below:. .. image:: ReadLibraryIllustration.png. The library type string consists of three parts: the relative orientation of; the reads, the strandedness of the library, and the directionality of the; reads. The first part of the library string (relative orientation) is only provided if; the library is paired-end. The possible options are:. ::. I = inward; O = outward; M = matching. The second part of the read library string specifies whether the protocol is; stranded or unstranded; the options are:. ::. S = stranded; U = unstranded. If the protocol is unstranded, then we're done. The final part of the library; string specifies the strand from which the read originates in a strand-specific; protocol — it is only provided if the library is stranded (i.e. if the; library format string is of the form S). The possible values are:. ::. F = read 1 (or single-end read) comes from the forward strand; R = read 1 (or single-end read) comes from the reverse strand. So, for example, if you wanted to specify a fragment library of strand-specific; paired-end reads, oriented toward each other, where read 1 comes from the; forward strand and read 2 comes from the reverse strand, you would specify ``-l; ISF`` on the command line. This designates that the library being processed has; the type ""ISF"" meaning, **I**\ nward (the relative orientation), **S**\ tranded; (the protocol is strand-specific), **F**\ orward (read 1 comes from the forward; strand). The single end library strings are a bit simpler than their pair-end counter; parts, since there is no re",MatchSource.DOCS,doc/source/library_type.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/library_type.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/library_type.rst:1534,Integrability,protocol,protocol,1534,"haracterize the; various different typs of sequencing libraries, we've created a miniature; ""language"" that allows for the succinct description of the many different types; of possible fragment libraries. For paired-end reads, the possible; orientations, along with a graphical description of what they mean, are; illustrated below:. .. image:: ReadLibraryIllustration.png. The library type string consists of three parts: the relative orientation of; the reads, the strandedness of the library, and the directionality of the; reads. The first part of the library string (relative orientation) is only provided if; the library is paired-end. The possible options are:. ::. I = inward; O = outward; M = matching. The second part of the read library string specifies whether the protocol is; stranded or unstranded; the options are:. ::. S = stranded; U = unstranded. If the protocol is unstranded, then we're done. The final part of the library; string specifies the strand from which the read originates in a strand-specific; protocol — it is only provided if the library is stranded (i.e. if the; library format string is of the form S). The possible values are:. ::. F = read 1 (or single-end read) comes from the forward strand; R = read 1 (or single-end read) comes from the reverse strand. So, for example, if you wanted to specify a fragment library of strand-specific; paired-end reads, oriented toward each other, where read 1 comes from the; forward strand and read 2 comes from the reverse strand, you would specify ``-l; ISF`` on the command line. This designates that the library being processed has; the type ""ISF"" meaning, **I**\ nward (the relative orientation), **S**\ tranded; (the protocol is strand-specific), **F**\ orward (read 1 comes from the forward; strand). The single end library strings are a bit simpler than their pair-end counter; parts, since there is no relative orientation of which to speak. Thus, the; only possible library format types for single-end reads are ``",MatchSource.DOCS,doc/source/library_type.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/library_type.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/library_type.rst:2207,Integrability,protocol,protocol,2207,":. I = inward; O = outward; M = matching. The second part of the read library string specifies whether the protocol is; stranded or unstranded; the options are:. ::. S = stranded; U = unstranded. If the protocol is unstranded, then we're done. The final part of the library; string specifies the strand from which the read originates in a strand-specific; protocol — it is only provided if the library is stranded (i.e. if the; library format string is of the form S). The possible values are:. ::. F = read 1 (or single-end read) comes from the forward strand; R = read 1 (or single-end read) comes from the reverse strand. So, for example, if you wanted to specify a fragment library of strand-specific; paired-end reads, oriented toward each other, where read 1 comes from the; forward strand and read 2 comes from the reverse strand, you would specify ``-l; ISF`` on the command line. This designates that the library being processed has; the type ""ISF"" meaning, **I**\ nward (the relative orientation), **S**\ tranded; (the protocol is strand-specific), **F**\ orward (read 1 comes from the forward; strand). The single end library strings are a bit simpler than their pair-end counter; parts, since there is no relative orientation of which to speak. Thus, the; only possible library format types for single-end reads are ``U`` (for; unstranded), ``SF`` (for strand-specific reads coming from the forward strand); and ``SR`` (for strand-specific reads coming from the reverse strand). A few more examples of some library format strings and their interpretations are:. ::. IU (an unstranded paired-end library where the reads face each other). ::. SF (a stranded single-end protocol where the reads come from the forward strand). ::. OSR (a stranded paired-end protocol where the reads face away from each other,; read1 comes from reverse strand and read2 comes from the forward strand). .. note:: Correspondence to TopHat library types . The popular `TopHat <http://ccb.jhu.edu/software/tophat/i",MatchSource.DOCS,doc/source/library_type.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/library_type.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/library_type.rst:2857,Integrability,protocol,protocol,2857,"nd-specific; paired-end reads, oriented toward each other, where read 1 comes from the; forward strand and read 2 comes from the reverse strand, you would specify ``-l; ISF`` on the command line. This designates that the library being processed has; the type ""ISF"" meaning, **I**\ nward (the relative orientation), **S**\ tranded; (the protocol is strand-specific), **F**\ orward (read 1 comes from the forward; strand). The single end library strings are a bit simpler than their pair-end counter; parts, since there is no relative orientation of which to speak. Thus, the; only possible library format types for single-end reads are ``U`` (for; unstranded), ``SF`` (for strand-specific reads coming from the forward strand); and ``SR`` (for strand-specific reads coming from the reverse strand). A few more examples of some library format strings and their interpretations are:. ::. IU (an unstranded paired-end library where the reads face each other). ::. SF (a stranded single-end protocol where the reads come from the forward strand). ::. OSR (a stranded paired-end protocol where the reads face away from each other,; read1 comes from reverse strand and read2 comes from the forward strand). .. note:: Correspondence to TopHat library types . The popular `TopHat <http://ccb.jhu.edu/software/tophat/index.shtml>`_ RNA-seq ; read aligner has a different convention for specifying the format of the library.; Below is a table that provides the corresponding sailfish/salmon library format; string for each of the potential TopHat library types:. +---------------------+-------------------------+ ; | TopHat | Salmon (and Sailfish) |; +=====================+============+============+; | | Paired-end | Single-end | ; +---------------------+------------+------------+; |``-fr-unstranded`` |``-l IU`` |``-l U`` | ; +---------------------+------------+------------+; |``-fr-firststrand`` |``-l ISR`` |``-l SR`` | ; +---------------------+------------+------------+; |``-fr-secondstrand`` |``-l ISF",MatchSource.DOCS,doc/source/library_type.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/library_type.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/library_type.rst:2944,Integrability,protocol,protocol,2944,"om the reverse strand, you would specify ``-l; ISF`` on the command line. This designates that the library being processed has; the type ""ISF"" meaning, **I**\ nward (the relative orientation), **S**\ tranded; (the protocol is strand-specific), **F**\ orward (read 1 comes from the forward; strand). The single end library strings are a bit simpler than their pair-end counter; parts, since there is no relative orientation of which to speak. Thus, the; only possible library format types for single-end reads are ``U`` (for; unstranded), ``SF`` (for strand-specific reads coming from the forward strand); and ``SR`` (for strand-specific reads coming from the reverse strand). A few more examples of some library format strings and their interpretations are:. ::. IU (an unstranded paired-end library where the reads face each other). ::. SF (a stranded single-end protocol where the reads come from the forward strand). ::. OSR (a stranded paired-end protocol where the reads face away from each other,; read1 comes from reverse strand and read2 comes from the forward strand). .. note:: Correspondence to TopHat library types . The popular `TopHat <http://ccb.jhu.edu/software/tophat/index.shtml>`_ RNA-seq ; read aligner has a different convention for specifying the format of the library.; Below is a table that provides the corresponding sailfish/salmon library format; string for each of the potential TopHat library types:. +---------------------+-------------------------+ ; | TopHat | Salmon (and Sailfish) |; +=====================+============+============+; | | Paired-end | Single-end | ; +---------------------+------------+------------+; |``-fr-unstranded`` |``-l IU`` |``-l U`` | ; +---------------------+------------+------------+; |``-fr-firststrand`` |``-l ISR`` |``-l SR`` | ; +---------------------+------------+------------+; |``-fr-secondstrand`` |``-l ISF`` |``-l SF`` | ; +---------------------+------------+------------+. The remaining salmon library format strings are not d",MatchSource.DOCS,doc/source/library_type.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/library_type.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/library_type.rst:2333,Usability,simpl,simpler,2333,"unstranded. If the protocol is unstranded, then we're done. The final part of the library; string specifies the strand from which the read originates in a strand-specific; protocol — it is only provided if the library is stranded (i.e. if the; library format string is of the form S). The possible values are:. ::. F = read 1 (or single-end read) comes from the forward strand; R = read 1 (or single-end read) comes from the reverse strand. So, for example, if you wanted to specify a fragment library of strand-specific; paired-end reads, oriented toward each other, where read 1 comes from the; forward strand and read 2 comes from the reverse strand, you would specify ``-l; ISF`` on the command line. This designates that the library being processed has; the type ""ISF"" meaning, **I**\ nward (the relative orientation), **S**\ tranded; (the protocol is strand-specific), **F**\ orward (read 1 comes from the forward; strand). The single end library strings are a bit simpler than their pair-end counter; parts, since there is no relative orientation of which to speak. Thus, the; only possible library format types for single-end reads are ``U`` (for; unstranded), ``SF`` (for strand-specific reads coming from the forward strand); and ``SR`` (for strand-specific reads coming from the reverse strand). A few more examples of some library format strings and their interpretations are:. ::. IU (an unstranded paired-end library where the reads face each other). ::. SF (a stranded single-end protocol where the reads come from the forward strand). ::. OSR (a stranded paired-end protocol where the reads face away from each other,; read1 comes from reverse strand and read2 comes from the forward strand). .. note:: Correspondence to TopHat library types . The popular `TopHat <http://ccb.jhu.edu/software/tophat/index.shtml>`_ RNA-seq ; read aligner has a different convention for specifying the format of the library.; Below is a table that provides the corresponding sailfish/salmon library form",MatchSource.DOCS,doc/source/library_type.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/library_type.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:852,Availability,avail,available,852,"Salmon; ===============. Salmon is a tool for **wicked-fast** transcript quantification from RNA-seq; data. It requires a set of target transcripts (either from a reference or; *de-novo* assembly) to quantify. All you need to run Salmon is a FASTA file; containing your reference transcripts and a (set of) FASTA/FASTQ file(s); containing your reads. Optionally, Salmon can make use of pre-computed; alignments (in the form of a SAM/BAM file) to the transcripts rather than the; raw reads. The **mapping**-based mode of Salmon runs in two phases; indexing and; quantification. The indexing step is independent of the reads, and only needs to; be run once for a particular set of reference transcripts. The quantification; step, obviously, is specific to the set of RNA-seq reads and is thus run more; frequently. For a more complete description of all available options in Salmon,; see below. .. note:: Selective alignment. Selective alignment, first introduced by the ``--validateMappings`` flag; in salmon, and now the default mapping strategy (in version 1.0.0; forward), is a major feature enhancement introduced in recent versions of; salmon. When salmon is run with selective alignment, it adopts a; considerably more sensitive scheme that we have developed for finding the; potential mapping loci of a read, and score potential mapping loci using; the chaining algorithm introduced in minimap2 [#minimap2]_. It scores and; validates these mappings using the score-only, SIMD, dynamic programming; algorithm of ksw2 [#ksw2]_. Finally, we recommend using selective; alignment with a *decoy-aware* transcriptome, to mitigate potential; spurious mapping of reads that actually arise from some unannotated; genomic locus that is sequence-similar to an annotated transcriptome. The; selective-alignment algorithm, the use of a decoy-aware transcriptome, and; the influence of running salmon with different mapping and alignment; strategies is covered in detail in the paper `Alignment and mapping met",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:5455,Availability,avail,available,5455,"e `Staden IO <http://sourceforge.net/projects/staden/files/io_lib/>`_ ; library for SAM/BAM/CRAM I/O (CRAM is, in theory, supported, but has not been; thoroughly tested). This means that multiple threads can be effectively used; to aid in BAM decompression. However, we find that throwing more than a ; few threads at file decompression does not result in increased processing; speed. Thus, alignment-based Salmon will only ever allocate up to 4 threads; to file decompression, with the rest being allocated to quantification.; If these threads are starved, they will sleep (the quantification threads ; do not busy wait), but there is a point beyond which allocating more threads; will not speed up alignment-based quantification. We find that allocating ; 8 --- 12 threads results in the maximum speed, threads allocated above this; limit will likely spend most of their time idle / sleeping. For quasi-mapping-based Salmon, the story is somewhat different.; Generally, performance continues to improve as more threads are made; available. This is because the determination of the potential mapping; locations of each read is, generally, the slowest step in; quasi-mapping-based quantification. Since this process is; trivially parallelizable (and well-parallelized within Salmon), more; threads generally equates to faster quantification. However, there may; still be a limit to the return on invested threads, when Salmon can begin; to process fragments more quickly than they can be provided via the parser.; ; ; Preparing transcriptome indices (mapping-based mode) ; ----------------------------------------------------------. One of the novel and innovative features of Salmon is its ability to accurately; quantify transcripts without having previously aligned the reads using its fast,; built-in selective-alignment mapping algorithm. Further details about the selective alignment algorithm can be; found `here <https://www.biorxiv.org/content/10.1101/657874v1>`_. If you want to use Salmon ",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:6868,Availability,mask,masked,6868,"ed threads, when Salmon can begin; to process fragments more quickly than they can be provided via the parser.; ; ; Preparing transcriptome indices (mapping-based mode) ; ----------------------------------------------------------. One of the novel and innovative features of Salmon is its ability to accurately; quantify transcripts without having previously aligned the reads using its fast,; built-in selective-alignment mapping algorithm. Further details about the selective alignment algorithm can be; found `here <https://www.biorxiv.org/content/10.1101/657874v1>`_. If you want to use Salmon in mapping-based mode, then you first have to build a; salmon index for your transcriptome. Assume that ``transcripts.fa`` contains the; set of transcripts you wish to quantify. We generally recommend that you build a; *decoy-aware* transcriptome file. . There are two options for generating a decoy-aware transcriptome:. - The first is to compute a set of decoy sequences by mapping the annotated transcripts you wish to index; against a hard-masked version of the organism's genome. This can be done with e.g. ; `MashMap2 <https://github.com/marbl/MashMap>`_, and we provide some simple scripts to ; greatly simplify this whole process. Specifically, you can use the ; `generateDecoyTranscriptome.sh <https://github.com/COMBINE-lab/SalmonTools/blob/master/scripts/generateDecoyTranscriptome.sh>`_; script, whose instructions you can find `in this README <https://github.com/COMBINE-lab/SalmonTools/blob/master/README.md>`_. . - The second is to use the entire genome of the organism as the decoy sequence. This can be ; done by concatenating the genome to the end of the transcriptome you want to index and populating ; the `decoys.txt` file with the chromosome names. Detailed instructions on how to prepare this ; type of decoy sequence is available `here <https://combine-lab.github.io/alevin-tutorial/2019/selective-alignment/>`_.; This scheme provides a more comprehensive set of decoys, but, obv",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:7668,Availability,avail,available,7668,"-aware* transcriptome file. . There are two options for generating a decoy-aware transcriptome:. - The first is to compute a set of decoy sequences by mapping the annotated transcripts you wish to index; against a hard-masked version of the organism's genome. This can be done with e.g. ; `MashMap2 <https://github.com/marbl/MashMap>`_, and we provide some simple scripts to ; greatly simplify this whole process. Specifically, you can use the ; `generateDecoyTranscriptome.sh <https://github.com/COMBINE-lab/SalmonTools/blob/master/scripts/generateDecoyTranscriptome.sh>`_; script, whose instructions you can find `in this README <https://github.com/COMBINE-lab/SalmonTools/blob/master/README.md>`_. . - The second is to use the entire genome of the organism as the decoy sequence. This can be ; done by concatenating the genome to the end of the transcriptome you want to index and populating ; the `decoys.txt` file with the chromosome names. Detailed instructions on how to prepare this ; type of decoy sequence is available `here <https://combine-lab.github.io/alevin-tutorial/2019/selective-alignment/>`_.; This scheme provides a more comprehensive set of decoys, but, obviously, requires considerably more memory to build the index. Finally, pre-built versions of both the *partial* decoy and *full* decoy (i.e. using the whole genome) salmon indices ; for some common organisms are available via refgenie `here <http://refgenomes.databio.org/>`_. If you are not using a pre-computed index, you run the salmon indexer as so:. ::; ; > ./bin/salmon index -t transcripts.fa -i transcripts_index --decoys decoys.txt -k 31; ; This will build the mapping-based index, using an auxiliary k-mer hash; over k-mers of length 31. While the mapping algorithms will make used of arbitrarily ; long matches between the query and reference, the `k` size selected here will ; act as the *minimum* acceptable length for a valid match. Thus, a smaller ; value of `k` may slightly improve sensitivity. We find tha",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:8039,Availability,avail,available,8039,"reatly simplify this whole process. Specifically, you can use the ; `generateDecoyTranscriptome.sh <https://github.com/COMBINE-lab/SalmonTools/blob/master/scripts/generateDecoyTranscriptome.sh>`_; script, whose instructions you can find `in this README <https://github.com/COMBINE-lab/SalmonTools/blob/master/README.md>`_. . - The second is to use the entire genome of the organism as the decoy sequence. This can be ; done by concatenating the genome to the end of the transcriptome you want to index and populating ; the `decoys.txt` file with the chromosome names. Detailed instructions on how to prepare this ; type of decoy sequence is available `here <https://combine-lab.github.io/alevin-tutorial/2019/selective-alignment/>`_.; This scheme provides a more comprehensive set of decoys, but, obviously, requires considerably more memory to build the index. Finally, pre-built versions of both the *partial* decoy and *full* decoy (i.e. using the whole genome) salmon indices ; for some common organisms are available via refgenie `here <http://refgenomes.databio.org/>`_. If you are not using a pre-computed index, you run the salmon indexer as so:. ::; ; > ./bin/salmon index -t transcripts.fa -i transcripts_index --decoys decoys.txt -k 31; ; This will build the mapping-based index, using an auxiliary k-mer hash; over k-mers of length 31. While the mapping algorithms will make used of arbitrarily ; long matches between the query and reference, the `k` size selected here will ; act as the *minimum* acceptable length for a valid match. Thus, a smaller ; value of `k` may slightly improve sensitivity. We find that a `k` of 31 seems; to work well for reads of 75bp or longer, but you might consider a smaller ; `k` if you plan to deal with shorter reads. Also, a shorter value of `k` may; improve sensitivity even more when using selective alignment (enabled via the `--validateMappings` flag). So,; if you are seeing a smaller mapping rate than you might expect, consider building; the ind",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:17778,Availability,recover,recoverOrphans,17778,"a. Specifically, the ``--meta``; flag sets the following options: . * The abundance optimization is initialized from the uniform distribution (compared to the default of using a weighted combination of the uniform intialization and the abundances learned during the online optimization). * Rich equivalence classes are disabled. Using rich equivalence classes with metagenomic data should not be particularly problematic, but since they have been developed and tested most in the context of bulk RNA-seq quantification, they are currently disabled under this flag. * The EM algorithm is used for abundance optimization instead of the default VBEM optimization. Neither is universally better than the other, but the parameters for the VBEM (e.g. the prior size and type) are set based on typical bulk RNA-seq transcriptome samples, and so may be less appropriate in the metagenomic context. Hence the ``--meta`` flags opts for the basic EM algorithm instead. """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""; ``--recoverOrphans``; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""". This flag (which should only be used in conjunction with selective alignment),; performs orphan ""rescue"" for reads. That is, if mappings are discovered for only; one end of a fragment, or if the mappings for the ends of the fragment don't; fall on the same transcript, then this flag will cause salmon to look upstream; or downstream of the discovered mapping (anchor) for a match for the opposite; end of the given fragment. This is done by performing ""infix"" alignment within; the maximum fragment length upstream of downstream of the anchor mapping using; edlib. """"""""""""""""""""""""""""""""""""""""""""""""""""; ``--hardFilter``; """""""""""""""""""""""""""""""""""""""""""""""""""". This flag (which should only be used with selective alignment) turns off soft; filtering and range-factorized equivalence classes, and removes all but the; equally highest scoring mappings from the equivalence class label for each; fragment. While we recommend using soft filtering (the default) for; quantification,",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:18151,Availability,down,downstream,18151," are disabled. Using rich equivalence classes with metagenomic data should not be particularly problematic, but since they have been developed and tested most in the context of bulk RNA-seq quantification, they are currently disabled under this flag. * The EM algorithm is used for abundance optimization instead of the default VBEM optimization. Neither is universally better than the other, but the parameters for the VBEM (e.g. the prior size and type) are set based on typical bulk RNA-seq transcriptome samples, and so may be less appropriate in the metagenomic context. Hence the ``--meta`` flags opts for the basic EM algorithm instead. """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""; ``--recoverOrphans``; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""". This flag (which should only be used in conjunction with selective alignment),; performs orphan ""rescue"" for reads. That is, if mappings are discovered for only; one end of a fragment, or if the mappings for the ends of the fragment don't; fall on the same transcript, then this flag will cause salmon to look upstream; or downstream of the discovered mapping (anchor) for a match for the opposite; end of the given fragment. This is done by performing ""infix"" alignment within; the maximum fragment length upstream of downstream of the anchor mapping using; edlib. """"""""""""""""""""""""""""""""""""""""""""""""""""; ``--hardFilter``; """""""""""""""""""""""""""""""""""""""""""""""""""". This flag (which should only be used with selective alignment) turns off soft; filtering and range-factorized equivalence classes, and removes all but the; equally highest scoring mappings from the equivalence class label for each; fragment. While we recommend using soft filtering (the default) for; quantification, this flag can produce easier-to-understand equivalence classes; if that is the primary object of study. """"""""""""""""""""""""""""""""""""""""""""""""""; ``--skipQuant``; """""""""""""""""""""""""""""""""""""""""""""""""". Related to the above, this flag will stop execution before the actual; quantification algorithm is run. """"""""""""""""""""""""""""""""""""""""""""""""""""""""""; ``-",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:18347,Availability,down,downstream,18347,"disabled under this flag. * The EM algorithm is used for abundance optimization instead of the default VBEM optimization. Neither is universally better than the other, but the parameters for the VBEM (e.g. the prior size and type) are set based on typical bulk RNA-seq transcriptome samples, and so may be less appropriate in the metagenomic context. Hence the ``--meta`` flags opts for the basic EM algorithm instead. """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""; ``--recoverOrphans``; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""". This flag (which should only be used in conjunction with selective alignment),; performs orphan ""rescue"" for reads. That is, if mappings are discovered for only; one end of a fragment, or if the mappings for the ends of the fragment don't; fall on the same transcript, then this flag will cause salmon to look upstream; or downstream of the discovered mapping (anchor) for a match for the opposite; end of the given fragment. This is done by performing ""infix"" alignment within; the maximum fragment length upstream of downstream of the anchor mapping using; edlib. """"""""""""""""""""""""""""""""""""""""""""""""""""; ``--hardFilter``; """""""""""""""""""""""""""""""""""""""""""""""""""". This flag (which should only be used with selective alignment) turns off soft; filtering and range-factorized equivalence classes, and removes all but the; equally highest scoring mappings from the equivalence class label for each; fragment. While we recommend using soft filtering (the default) for; quantification, this flag can produce easier-to-understand equivalence classes; if that is the primary object of study. """"""""""""""""""""""""""""""""""""""""""""""""""; ``--skipQuant``; """""""""""""""""""""""""""""""""""""""""""""""""". Related to the above, this flag will stop execution before the actual; quantification algorithm is run. """"""""""""""""""""""""""""""""""""""""""""""""""""""""""; ``--allowDovetail``; """""""""""""""""""""""""""""""""""""""""""""""""""""""""". Dovetailing mappings and alignments are considered discordant and discarded by; default --- this is the same behavior that is adopted by default in Bowtie2.; This is a change f",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:20205,Availability,avail,available,20205,"cordant and discarded by; default --- this is the same behavior that is adopted by default in Bowtie2.; This is a change from the older behavior of salmon where dovetailing mappings; were considered concordant and counted by default. If you wish to consider; dovetailing mappings as concordant (the previous behavior), you can do so by; passing the flag to salmon quant. Exotic library types (e.g. MU, MSF, MSR) are; no longer supported. If you need support for such a library type, please submit; a feature request describing the use-case. """"""""""""""""""""""""""""""""""""""""""""""""""""; ``-p`` / ``--threads``; """""""""""""""""""""""""""""""""""""""""""""""""""". The number of threads that will be used for quasi-mapping, quantification, and; bootstrapping / posterior sampling (if enabled). Salmon is designed to work; well with many threads, so, if you have a sufficient number of processors, larger; values here can speed up the run substantially. .. note:: Default number of threads. The default behavior is for Salmon to probe the number of available hardware; threads and to use this number. Thus, if you want to use fewer threads (e.g.,; if you are running multiple instances of Salmon simultaneously), you will; likely want to set this option explicitly in accordance with the desired; per-process resource usage. """"""""""""""""""""""""""""""""""""""""""""; ``--dumpEq``; """""""""""""""""""""""""""""""""""""""""""". If Salmon is passed the ``--dumpEq`` option, it will write a file in the auxiliary; directory, called ``eq_classes.txt`` that contains the equivalence classes and corresponding; counts that were computed during quasi-mapping. The file has a format described in; :ref:`eq-class-file`. """"""""""""""""""""""""""""""""""""""""""""""""""""""""""; ``--incompatPrior``; """""""""""""""""""""""""""""""""""""""""""""""""""""""""". This parameter governs the *a priori* probability that a fragment mapping or; aligning to the reference in a manner incompatible with the prescribed library; type is nonetheless the correct mapping. Note that Salmon sets this value, by; default, to a small but *non-zero* probability. This m",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:26674,Availability,error,error,26674," is the gap length. The value of ``go`` should typically; be larger than that of ``ge``. """"""""""""""""""""""""""""""""""""; ``--ge``; """""""""""""""""""""""""""""""""""". This value should be a positive (typically small) integer. It controls the score; penalty attributed to the extension of a gap in an alignment. The; alignment score computed uses an affine gap penalty, so the penalty of a gap is; ``go + l * ge`` where l is the gap length. The value of ``ge`` should typically; be smaller than that of ``go``. """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; ``--rangeFactorizationBins``; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""". The `range-factorization <https://academic.oup.com/bioinformatics/article/33/14/i142/3953977>`_ feature; allows using a data-driven likelihood factorization, which can improve; quantification accuracy on certain classes of ""difficult"" transcripts.; Currently, this feature interacts best (i.e., yields the most considerable; improvements) when either (1) using alignment-based mode and simultaneously; enabling error modeling with ``--useErrorModel`` or (2) when enabling; ``--validateMappings`` in quasi-mapping-based mode. The argument to this option; is a positive integer ``x``, that determines fidelity of the factorization. The larger; ``x``, the closer the factorization to the un-factorized likelihood, but the larger; the resulting number of equivalence classes. A value of 1 corresponds to salmon's; traditional rich equivalence classes. We recommend 4 as a reasonable parameter; for this option (it is what was used in the range-factorization paper). """"""""""""""""""""""""""""; ``--useEM``; """""""""""""""""""""""""""". Use the ""standard"" EM algorithm to optimize abundance estimates; instead of the variational Bayesian EM algorithm. The details of the VBEM; algorithm can be found in [#salmon]_. While both the standard EM and; the VBEM produce accurate abundance estimates, there are some; trade-offs between the approaches. Specifically, the sparsity of; the VBEM algorithm depends on the prior that is chosen. When; t",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:30119,Availability,down,downstream,30119,"d VBEM algorithms. As mentioned above, a thorough comparison of all of the benefits and detriments; of the different algorithms is an ongoing area of research. However, preliminary; testing suggests that the sparsity-inducing effect of running the VBEM with a small; prior may lead, in general, to more accurate estimates (the current testing was; performed mostly through simulation). Hence, the VBEM is the default, and the; standard EM algorithm is accessed via the `--useEM` flag. """"""""""""""""""""""""""""""""""""""""""""""""""""""""""; ``--numBootstraps``; """""""""""""""""""""""""""""""""""""""""""""""""""""""""". Salmon has the ability to optionally compute bootstrapped abundance estimates.; This is done by resampling (with replacement) from the counts assigned to; the fragment equivalence classes, and then re-running the optimization procedure,; either the EM or VBEM, for each such sample. The values of these different; bootstraps allows us to assess technical variance in the main abundance estimates; we produce. Such estimates can be useful for downstream (e.g. differential; expression) tools that can make use of such uncertainty estimates. This option; takes a positive integer that dictates the number of bootstrap samples to compute.; The more samples computed, the better the estimates of variance, but the; more computation (and time) required. """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; ``--numGibbsSamples``; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""". Just as with the bootstrap procedure above, this option produces samples that allow; us to estimate the variance in abundance estimates. However, in this case the; samples are generated using posterior Gibbs sampling over the fragment equivalence; classes rather than bootstrapping. We are currently analyzing these different approaches; to assess the potential trade-offs in time / accuracy. The ``--numBootstraps`` and; ``--numGibbsSamples`` options are mutually exclusive (i.e. in a given run, you must; set at most one of these options to a positive integer.). """"""""""""""""""""""""""""""""""""""""""; ``--se",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:33274,Availability,error,errors,33274,"oblem that was sometimes observed using the previous bias-correction; methodology. """"""""""""""""""""""""""""""""""""""""""; ``--gcBias``; """""""""""""""""""""""""""""""""""""""""". Passing the ``--gcBias`` flag to Salmon will enable it to learn and; correct for fragment-level GC biases in the input data. Specifically,; this model will attempt to correct for biases in how likely a sequence; is to be observed based on its internal GC content. . You can use the FASTQC software followed by ; `MultiQC with transcriptome GC distributions <http://multiqc.info/docs/#theoretical-gc-content>`_; to check if your samples exhibit strong GC bias, i.e.; under-representation of some sub-sequences of the transcriptome. If they do, ; we obviously recommend using the ``--gcBias`` flag. Or you can simply run Salmon with ; ``--gcBias`` in any case, as it does not impair quantification for samples ; without GC bias, it just takes a few more minutes per sample. For samples ; with moderate to high GC bias, correction for this bias at the fragment level ; has been shown to reduce isoform quantification errors [#alpine]_ [#salmon]_. This bias is distinct from the primer biases learned with the ``--seqBias`` option.; Though these biases are distinct, they are not completely independent.; When both ``--seqBias`` and ``--gcBias`` are enabled, Salmon will; learn a conditional fragment-GC bias model. By default, Salmon will; learn 3 different fragment-GC bias models based on the GC content of; the fragment start and end contexts, though this number of conditional; models can be changed with the (*hidden*) option; ``--conditionalGCBins``. Likewise, the number of distinct fragment GC; bins used to model the GC bias can be changed with the (*hidden*); option ``--numGCBins``. *Note* : In order to speed up the evaluation of the GC content of; arbitrary fragments, Salmon pre-computes and stores the cumulative GC; count for each transcript. This requires an extra 4-bytes per; nucleotide. While this extra memory usage should normally be mino",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:44283,Availability,avail,available,44283,"her). If your reads are compressed in a different format, you can; still stream them directly to Salmon by using process substitution.; Say in the *quasi-mapping*-based Salmon example above, the reads were; actually in the files ``reads1.fa.bz2`` and ``reads2.fa.bz2``, then; you'd run the following command to decompress the reads ""on-the-fly"":. ::. > ./bin/salmon quant -i transcripts_index -l <LIBTYPE> -1 <(bunzip2 -c reads1.fa.gz) -2 <(bunzip2 -c reads2.fa.bz2) -o transcripts_quant. and the bzipped files will be decompressed via separate processes and; the raw reads will be fed into Salmon. Actually, you can use this; same process even with gzip compressed reads (replacing ``bunzip2``; with ``gunzip`` or ``pigz -d``). Depending on the number of threads; and the exact configuration, this may actually improve Salmon's; running time, since the reads are decompressed concurrently in a; separate process when you use process substitution. **Finally**, the purpose of making this software available is for; people to use it and provide feedback. The; `paper describing this method is published in Nature Methods <http://rdcu.be/pQsw>`_.; If you have something useful to report or just some interesting ideas; or suggestions, please contact us (`rob.patro@cs.stonybrook.edu`; and/or `carlk@cs.cmu.edu`). If you encounter any bugs, please file a; *detailed* bug report at the `Salmon GitHub repository <https://github.com/COMBINE-lab/salmon>`_. References; ----------. .. [#express] Roberts, Adam, and Lior Pachter. ""Streaming fragment assignment for real-time analysis of sequencing experiments."" Nature Methods 10.1 (2013): 71-73.; ; .. [#roberts] Roberts, Adam, et al. ""Improving RNA-Seq expression estimates by correcting for fragment bias."" Genome Biology 12.3 (2011): 1. .. [#salmon] Patro, Rob, et al. ""Salmon provides fast and bias-aware quantification of transcript expression."" Nature Methods (2017). Advanced Online Publication. doi: 10.1038/nmeth.4197.. .. [#alpine] Love, Michael I",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:45392,Availability,error,errors,45392,"reads1.fa.gz) -2 <(bunzip2 -c reads2.fa.bz2) -o transcripts_quant. and the bzipped files will be decompressed via separate processes and; the raw reads will be fed into Salmon. Actually, you can use this; same process even with gzip compressed reads (replacing ``bunzip2``; with ``gunzip`` or ``pigz -d``). Depending on the number of threads; and the exact configuration, this may actually improve Salmon's; running time, since the reads are decompressed concurrently in a; separate process when you use process substitution. **Finally**, the purpose of making this software available is for; people to use it and provide feedback. The; `paper describing this method is published in Nature Methods <http://rdcu.be/pQsw>`_.; If you have something useful to report or just some interesting ideas; or suggestions, please contact us (`rob.patro@cs.stonybrook.edu`; and/or `carlk@cs.cmu.edu`). If you encounter any bugs, please file a; *detailed* bug report at the `Salmon GitHub repository <https://github.com/COMBINE-lab/salmon>`_. References; ----------. .. [#express] Roberts, Adam, and Lior Pachter. ""Streaming fragment assignment for real-time analysis of sequencing experiments."" Nature Methods 10.1 (2013): 71-73.; ; .. [#roberts] Roberts, Adam, et al. ""Improving RNA-Seq expression estimates by correcting for fragment bias."" Genome Biology 12.3 (2011): 1. .. [#salmon] Patro, Rob, et al. ""Salmon provides fast and bias-aware quantification of transcript expression."" Nature Methods (2017). Advanced Online Publication. doi: 10.1038/nmeth.4197.. .. [#alpine] Love, Michael I., Hogenesch, John B., Irizarry, Rafael A. ""Modeling of RNA-seq fragment sequence bias reduces systematic errors in transcript abundance estimation."" Nature Biotechnology 34.12 (2016). doi: 10.1038/nbt.368.2.. .. [#minimap2] Li, Heng. ""Minimap2: pairwise alignment for nucleotide sequences."" Bioinformatics 34.18 (2018): 3094-3100. . .. [#ksw2] `Global alignment and alignment extension <https://github.com/lh3/ksw2>`_. ; ",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:35170,Deployability,release,release,35170,"4-bytes per; nucleotide. While this extra memory usage should normally be minor,; it can nonetheless be controlled with the ``--reduceGCMemory`` option.; This option replaces the per-nucleotide GC count with a rank-select; capable bit vector, reducing the memory overhead from 4-bytes per; nucleotide to ~1.25 bits, while being only marginally slower). """"""""""""""""""""""""""""""""""""""""""; ``--posBias``; """""""""""""""""""""""""""""""""""""""""". Passing the ``--posBias`` flag to Salmon will enable modeling of a; position-specific fragment start distribution. This is meant to model; non-uniform coverage biases that are sometimes present in RNA-seq data; (e.g. 5' or 3' positional bias). Currently, a small and fixed number; of models are learned for different length classes of transcripts, as; is done in Roberts et al. [#roberts]_. *Note*: The positional bias; model is relatively new, and is still undergoing testing. It replaces; the previous `--useFSPD` option, which is now deprecated. This; feature should be considered as *experimental* in the current release. """"""""""""""""""""""""""""""""""""""""""""""""""""""""""; ``--biasSpeedSamp``; """""""""""""""""""""""""""""""""""""""""""""""""""""""""". When evaluating the bias models (the GC-fragment model specifically),; Salmon must consider the probability of generating a fragment of every; possible length (with a non-trivial probability) from every position; on every transcript. This results in a process that is quadratic in; the length of the transcriptome --- though each evaluation itself is; efficient and the process is highly parallelized. It is possible to speed this process up by a multiplicative factor by; considering only every *i*:sup:`th` fragment length, and interpolating; the intermediate results. The ``--biasSpeedSamp`` option allows the; user to set this sampling factor. Larger values speed up effective; length correction, but may decrease the fidelity of bias modeling.; However, reasonably small values (e.g. 10 or less) should have only a; minor effect on the computed effective lengths, and can c",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:44065,Deployability,configurat,configuration,44065,"pt reads from FASTA/Q; format files, or directly from gzipped FASTA/Q files (the ability to; accept compressed files directly is a feature of Salmon 0.7.0 and; higher). If your reads are compressed in a different format, you can; still stream them directly to Salmon by using process substitution.; Say in the *quasi-mapping*-based Salmon example above, the reads were; actually in the files ``reads1.fa.bz2`` and ``reads2.fa.bz2``, then; you'd run the following command to decompress the reads ""on-the-fly"":. ::. > ./bin/salmon quant -i transcripts_index -l <LIBTYPE> -1 <(bunzip2 -c reads1.fa.gz) -2 <(bunzip2 -c reads2.fa.bz2) -o transcripts_quant. and the bzipped files will be decompressed via separate processes and; the raw reads will be fed into Salmon. Actually, you can use this; same process even with gzip compressed reads (replacing ``bunzip2``; with ``gunzip`` or ``pigz -d``). Depending on the number of threads; and the exact configuration, this may actually improve Salmon's; running time, since the reads are decompressed concurrently in a; separate process when you use process substitution. **Finally**, the purpose of making this software available is for; people to use it and provide feedback. The; `paper describing this method is published in Nature Methods <http://rdcu.be/pQsw>`_.; If you have something useful to report or just some interesting ideas; or suggestions, please contact us (`rob.patro@cs.stonybrook.edu`; and/or `carlk@cs.cmu.edu`). If you encounter any bugs, please file a; *detailed* bug report at the `Salmon GitHub repository <https://github.com/COMBINE-lab/salmon>`_. References; ----------. .. [#express] Roberts, Adam, and Lior Pachter. ""Streaming fragment assignment for real-time analysis of sequencing experiments."" Nature Methods 10.1 (2013): 71-73.; ; .. [#roberts] Roberts, Adam, et al. ""Improving RNA-Seq expression estimates by correcting for fragment bias."" Genome Biology 12.3 (2011): 1. .. [#salmon] Patro, Rob, et al. ""Salmon provides fast a",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:4853,Energy Efficiency,allocate,allocate,4853," ""at random"". This means, for example, that alignments should ; **not** be sorted by target or position. If your reads or alignments ; do not appear in a random order with respect to the target transcripts,; please randomize / shuffle them before performing quantification with ; Salmon. .. note:: Number of Threads. The number of threads that Salmon can effectively make use of depends ; upon the mode in which it is being run. In alignment-based mode, the; main bottleneck is in parsing and decompressing the input BAM file.; We make use of the `Staden IO <http://sourceforge.net/projects/staden/files/io_lib/>`_ ; library for SAM/BAM/CRAM I/O (CRAM is, in theory, supported, but has not been; thoroughly tested). This means that multiple threads can be effectively used; to aid in BAM decompression. However, we find that throwing more than a ; few threads at file decompression does not result in increased processing; speed. Thus, alignment-based Salmon will only ever allocate up to 4 threads; to file decompression, with the rest being allocated to quantification.; If these threads are starved, they will sleep (the quantification threads ; do not busy wait), but there is a point beyond which allocating more threads; will not speed up alignment-based quantification. We find that allocating ; 8 --- 12 threads results in the maximum speed, threads allocated above this; limit will likely spend most of their time idle / sleeping. For quasi-mapping-based Salmon, the story is somewhat different.; Generally, performance continues to improve as more threads are made; available. This is because the determination of the potential mapping; locations of each read is, generally, the slowest step in; quasi-mapping-based quantification. Since this process is; trivially parallelizable (and well-parallelized within Salmon), more; threads generally equates to faster quantification. However, there may; still be a limit to the return on invested threads, when Salmon can begin; to process fragmen",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:4922,Energy Efficiency,allocate,allocated,4922," ""at random"". This means, for example, that alignments should ; **not** be sorted by target or position. If your reads or alignments ; do not appear in a random order with respect to the target transcripts,; please randomize / shuffle them before performing quantification with ; Salmon. .. note:: Number of Threads. The number of threads that Salmon can effectively make use of depends ; upon the mode in which it is being run. In alignment-based mode, the; main bottleneck is in parsing and decompressing the input BAM file.; We make use of the `Staden IO <http://sourceforge.net/projects/staden/files/io_lib/>`_ ; library for SAM/BAM/CRAM I/O (CRAM is, in theory, supported, but has not been; thoroughly tested). This means that multiple threads can be effectively used; to aid in BAM decompression. However, we find that throwing more than a ; few threads at file decompression does not result in increased processing; speed. Thus, alignment-based Salmon will only ever allocate up to 4 threads; to file decompression, with the rest being allocated to quantification.; If these threads are starved, they will sleep (the quantification threads ; do not busy wait), but there is a point beyond which allocating more threads; will not speed up alignment-based quantification. We find that allocating ; 8 --- 12 threads results in the maximum speed, threads allocated above this; limit will likely spend most of their time idle / sleeping. For quasi-mapping-based Salmon, the story is somewhat different.; Generally, performance continues to improve as more threads are made; available. This is because the determination of the potential mapping; locations of each read is, generally, the slowest step in; quasi-mapping-based quantification. Since this process is; trivially parallelizable (and well-parallelized within Salmon), more; threads generally equates to faster quantification. However, there may; still be a limit to the return on invested threads, when Salmon can begin; to process fragmen",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:5237,Energy Efficiency,allocate,allocated,5237,"fectively make use of depends ; upon the mode in which it is being run. In alignment-based mode, the; main bottleneck is in parsing and decompressing the input BAM file.; We make use of the `Staden IO <http://sourceforge.net/projects/staden/files/io_lib/>`_ ; library for SAM/BAM/CRAM I/O (CRAM is, in theory, supported, but has not been; thoroughly tested). This means that multiple threads can be effectively used; to aid in BAM decompression. However, we find that throwing more than a ; few threads at file decompression does not result in increased processing; speed. Thus, alignment-based Salmon will only ever allocate up to 4 threads; to file decompression, with the rest being allocated to quantification.; If these threads are starved, they will sleep (the quantification threads ; do not busy wait), but there is a point beyond which allocating more threads; will not speed up alignment-based quantification. We find that allocating ; 8 --- 12 threads results in the maximum speed, threads allocated above this; limit will likely spend most of their time idle / sleeping. For quasi-mapping-based Salmon, the story is somewhat different.; Generally, performance continues to improve as more threads are made; available. This is because the determination of the potential mapping; locations of each read is, generally, the slowest step in; quasi-mapping-based quantification. Since this process is; trivially parallelizable (and well-parallelized within Salmon), more; threads generally equates to faster quantification. However, there may; still be a limit to the return on invested threads, when Salmon can begin; to process fragments more quickly than they can be provided via the parser.; ; ; Preparing transcriptome indices (mapping-based mode) ; ----------------------------------------------------------. One of the novel and innovative features of Salmon is its ability to accurately; quantify transcripts without having previously aligned the reads using its fast,; built-in selectiv",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:33244,Energy Efficiency,reduce,reduce,33244,"oblem that was sometimes observed using the previous bias-correction; methodology. """"""""""""""""""""""""""""""""""""""""""; ``--gcBias``; """""""""""""""""""""""""""""""""""""""""". Passing the ``--gcBias`` flag to Salmon will enable it to learn and; correct for fragment-level GC biases in the input data. Specifically,; this model will attempt to correct for biases in how likely a sequence; is to be observed based on its internal GC content. . You can use the FASTQC software followed by ; `MultiQC with transcriptome GC distributions <http://multiqc.info/docs/#theoretical-gc-content>`_; to check if your samples exhibit strong GC bias, i.e.; under-representation of some sub-sequences of the transcriptome. If they do, ; we obviously recommend using the ``--gcBias`` flag. Or you can simply run Salmon with ; ``--gcBias`` in any case, as it does not impair quantification for samples ; without GC bias, it just takes a few more minutes per sample. For samples ; with moderate to high GC bias, correction for this bias at the fragment level ; has been shown to reduce isoform quantification errors [#alpine]_ [#salmon]_. This bias is distinct from the primer biases learned with the ``--seqBias`` option.; Though these biases are distinct, they are not completely independent.; When both ``--seqBias`` and ``--gcBias`` are enabled, Salmon will; learn a conditional fragment-GC bias model. By default, Salmon will; learn 3 different fragment-GC bias models based on the GC content of; the fragment start and end contexts, though this number of conditional; models can be changed with the (*hidden*) option; ``--conditionalGCBins``. Likewise, the number of distinct fragment GC; bins used to model the GC bias can be changed with the (*hidden*); option ``--numGCBins``. *Note* : In order to speed up the evaluation of the GC content of; arbitrary fragments, Salmon pre-computes and stores the cumulative GC; count for each transcript. This requires an extra 4-bytes per; nucleotide. While this extra memory usage should normally be mino",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:34267,Energy Efficiency,reduce,reduceGCMemory,34267,"as been shown to reduce isoform quantification errors [#alpine]_ [#salmon]_. This bias is distinct from the primer biases learned with the ``--seqBias`` option.; Though these biases are distinct, they are not completely independent.; When both ``--seqBias`` and ``--gcBias`` are enabled, Salmon will; learn a conditional fragment-GC bias model. By default, Salmon will; learn 3 different fragment-GC bias models based on the GC content of; the fragment start and end contexts, though this number of conditional; models can be changed with the (*hidden*) option; ``--conditionalGCBins``. Likewise, the number of distinct fragment GC; bins used to model the GC bias can be changed with the (*hidden*); option ``--numGCBins``. *Note* : In order to speed up the evaluation of the GC content of; arbitrary fragments, Salmon pre-computes and stores the cumulative GC; count for each transcript. This requires an extra 4-bytes per; nucleotide. While this extra memory usage should normally be minor,; it can nonetheless be controlled with the ``--reduceGCMemory`` option.; This option replaces the per-nucleotide GC count with a rank-select; capable bit vector, reducing the memory overhead from 4-bytes per; nucleotide to ~1.25 bits, while being only marginally slower). """"""""""""""""""""""""""""""""""""""""""; ``--posBias``; """""""""""""""""""""""""""""""""""""""""". Passing the ``--posBias`` flag to Salmon will enable modeling of a; position-specific fragment start distribution. This is meant to model; non-uniform coverage biases that are sometimes present in RNA-seq data; (e.g. 5' or 3' positional bias). Currently, a small and fixed number; of models are learned for different length classes of transcripts, as; is done in Roberts et al. [#roberts]_. *Note*: The positional bias; model is relatively new, and is still undergoing testing. It replaces; the previous `--useFSPD` option, which is now deprecated. This; feature should be considered as *experimental* in the current release. """"""""""""""""""""""""""""""""""""""""""""""""""""""""""; ``--biasSpeedSamp",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:35614,Energy Efficiency,efficient,efficient,35614,"flag to Salmon will enable modeling of a; position-specific fragment start distribution. This is meant to model; non-uniform coverage biases that are sometimes present in RNA-seq data; (e.g. 5' or 3' positional bias). Currently, a small and fixed number; of models are learned for different length classes of transcripts, as; is done in Roberts et al. [#roberts]_. *Note*: The positional bias; model is relatively new, and is still undergoing testing. It replaces; the previous `--useFSPD` option, which is now deprecated. This; feature should be considered as *experimental* in the current release. """"""""""""""""""""""""""""""""""""""""""""""""""""""""""; ``--biasSpeedSamp``; """""""""""""""""""""""""""""""""""""""""""""""""""""""""". When evaluating the bias models (the GC-fragment model specifically),; Salmon must consider the probability of generating a fragment of every; possible length (with a non-trivial probability) from every position; on every transcript. This results in a process that is quadratic in; the length of the transcriptome --- though each evaluation itself is; efficient and the process is highly parallelized. It is possible to speed this process up by a multiplicative factor by; considering only every *i*:sup:`th` fragment length, and interpolating; the intermediate results. The ``--biasSpeedSamp`` option allows the; user to set this sampling factor. Larger values speed up effective; length correction, but may decrease the fidelity of bias modeling.; However, reasonably small values (e.g. 10 or less) should have only a; minor effect on the computed effective lengths, and can considerably; speed up effective length correction on large transcriptomes. The; default value for ``--biasSpeedSamp`` is 5. """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; ``--writeUnmappedNames``; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""". Passing the ``--writeUnmappedNames`` flag to Salmon will tell Salmon to; write out the names of reads (or mates in paired-end reads) that do not; map to the transcriptome. When mapping paired-end reads, the entire; fr",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:45373,Energy Efficiency,reduce,reduces,45373,"reads1.fa.gz) -2 <(bunzip2 -c reads2.fa.bz2) -o transcripts_quant. and the bzipped files will be decompressed via separate processes and; the raw reads will be fed into Salmon. Actually, you can use this; same process even with gzip compressed reads (replacing ``bunzip2``; with ``gunzip`` or ``pigz -d``). Depending on the number of threads; and the exact configuration, this may actually improve Salmon's; running time, since the reads are decompressed concurrently in a; separate process when you use process substitution. **Finally**, the purpose of making this software available is for; people to use it and provide feedback. The; `paper describing this method is published in Nature Methods <http://rdcu.be/pQsw>`_.; If you have something useful to report or just some interesting ideas; or suggestions, please contact us (`rob.patro@cs.stonybrook.edu`; and/or `carlk@cs.cmu.edu`). If you encounter any bugs, please file a; *detailed* bug report at the `Salmon GitHub repository <https://github.com/COMBINE-lab/salmon>`_. References; ----------. .. [#express] Roberts, Adam, and Lior Pachter. ""Streaming fragment assignment for real-time analysis of sequencing experiments."" Nature Methods 10.1 (2013): 71-73.; ; .. [#roberts] Roberts, Adam, et al. ""Improving RNA-Seq expression estimates by correcting for fragment bias."" Genome Biology 12.3 (2011): 1. .. [#salmon] Patro, Rob, et al. ""Salmon provides fast and bias-aware quantification of transcript expression."" Nature Methods (2017). Advanced Online Publication. doi: 10.1038/nmeth.4197.. .. [#alpine] Love, Michael I., Hogenesch, John B., Irizarry, Rafael A. ""Modeling of RNA-seq fragment sequence bias reduces systematic errors in transcript abundance estimation."" Nature Biotechnology 34.12 (2016). doi: 10.1038/nbt.368.2.. .. [#minimap2] Li, Heng. ""Minimap2: pairwise alignment for nucleotide sequences."" Bioinformatics 34.18 (2018): 3094-3100. . .. [#ksw2] `Global alignment and alignment extension <https://github.com/lh3/ksw2>`_. ; ",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:4258,Integrability,depend,depends,4258,"_. Using Salmon; ------------. As mentioned above, there are two ""modes"" of operation for Salmon. The first,; requires you to build an index for the transcriptome, but then subsequently; processes reads directly. The second mode simply requires you to provide a; FASTA file of the transcriptome and a ``.sam`` or ``.bam`` file containing a; set of alignments. .. note:: Read / alignment order. Salmon, like eXpress [#express]_, uses a streaming inference method to perform ; transcript-level quantification. One of the fundamental assumptions ; of such inference methods is that observations (i.e. reads or alignments); are made ""at random"". This means, for example, that alignments should ; **not** be sorted by target or position. If your reads or alignments ; do not appear in a random order with respect to the target transcripts,; please randomize / shuffle them before performing quantification with ; Salmon. .. note:: Number of Threads. The number of threads that Salmon can effectively make use of depends ; upon the mode in which it is being run. In alignment-based mode, the; main bottleneck is in parsing and decompressing the input BAM file.; We make use of the `Staden IO <http://sourceforge.net/projects/staden/files/io_lib/>`_ ; library for SAM/BAM/CRAM I/O (CRAM is, in theory, supported, but has not been; thoroughly tested). This means that multiple threads can be effectively used; to aid in BAM decompression. However, we find that throwing more than a ; few threads at file decompression does not result in increased processing; speed. Thus, alignment-based Salmon will only ever allocate up to 4 threads; to file decompression, with the rest being allocated to quantification.; If these threads are starved, they will sleep (the quantification threads ; do not busy wait), but there is a point beyond which allocating more threads; will not speed up alignment-based quantification. We find that allocating ; 8 --- 12 threads results in the maximum speed, threads allocated abov",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:12788,Integrability,synchroniz,synchronized,12788,"ut. > salmon quant -i index -l IU -1 <(gunzip -c lib_1_1.fq.gz lib_2_1.fq.gz) -2 <(gunzip -c lib_1_2.fq.gz lib_2_2.fq.gz) --validateMappings -o out. In each pair of commands, the first command lets Salmon natively parse the files, while the latter command; creates, on-the-fly, an input stream that consists of the concatenation of both files. Both methods work, and; are acceptable ways to merge the files. The latter method (i.e. process substitution) allows more complex; processing to be done to the reads in the substituted process before they are passed to Salmon as input, and thus,; in some situations, is more versatile. .. note:: Interleaved FASTQ files. Salmon does not currently have built-in support for interleaved FASTQ files (i.e., paired-end; files where both pairs are stored in the same file). We provide a `script <https://github.com/COMBINE-lab/salmon/blob/master/scripts/runner.sh>`_; that can be used to run salmon with interleaved input. However, this script assumes that the; input reads are perfectly synchronized. That is, the input cannot contain any un-paired reads. Quantifying in alignment-based mode; -----------------------------------. Say that you've prepared your alignments using your favorite aligner and the; results are in the file ``aln.bam``, and assume that the sequence of the; transcriptome you want to quantify is in the file ``transcripts.fa``. You; would run Salmon as follows:. ::. > ./bin/salmon quant -t transcripts.fa -l <LIBTYPE> -a aln.bam -o salmon_quant. The ``<LIBTYPE>`` parameter is described below and is shared between both modes; of Salmon. After Salmon has finished running, there will be a directory called; ``salmon_quant``, that contains a file called ``quant.sf``. This contains the; quantification results for the run, and the columns it contains are similar to; those of Sailfish (and self-explanatory where they differ). For the full set of options that can be passed to Salmon in its alignment-based; mode, and a description of ea",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:27628,Integrability,depend,depends,27628,"ing alignment-based mode and simultaneously; enabling error modeling with ``--useErrorModel`` or (2) when enabling; ``--validateMappings`` in quasi-mapping-based mode. The argument to this option; is a positive integer ``x``, that determines fidelity of the factorization. The larger; ``x``, the closer the factorization to the un-factorized likelihood, but the larger; the resulting number of equivalence classes. A value of 1 corresponds to salmon's; traditional rich equivalence classes. We recommend 4 as a reasonable parameter; for this option (it is what was used in the range-factorization paper). """"""""""""""""""""""""""""; ``--useEM``; """""""""""""""""""""""""""". Use the ""standard"" EM algorithm to optimize abundance estimates; instead of the variational Bayesian EM algorithm. The details of the VBEM; algorithm can be found in [#salmon]_. While both the standard EM and; the VBEM produce accurate abundance estimates, there are some; trade-offs between the approaches. Specifically, the sparsity of; the VBEM algorithm depends on the prior that is chosen. When; the prior is small, the VBEM tends to produce a sparser solution; than the EM algorithm, while when the prior is relatively larger, it; tends to estimate more non-zero abundances than the EM algorithm.; It is an active research effort to analyze and understand all the tradeoffs; between these different optimization approaches. Also, the VBEM tends to; converge after fewer iterations, so it may result in a shorter runtime;; especially if you are computing many bootstrap samples. The default prior used in the VB optimization is a *per-nucleotide* prior; of 1e-5 reads per-nucleotide. This means that a transcript of length 100000 will; have a prior count of 1 fragment, while a transcript of length 50000 will have; a prior count of 0.5 fragments, etc. This behavior can be modified in two; ways. First, the prior itself can be modified via Salmon's ``--vbPrior``; option. The argument to this option is the value you wish to place as the; *per-n",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:28938,Integrability,depend,dependent,28938,"ve research effort to analyze and understand all the tradeoffs; between these different optimization approaches. Also, the VBEM tends to; converge after fewer iterations, so it may result in a shorter runtime;; especially if you are computing many bootstrap samples. The default prior used in the VB optimization is a *per-nucleotide* prior; of 1e-5 reads per-nucleotide. This means that a transcript of length 100000 will; have a prior count of 1 fragment, while a transcript of length 50000 will have; a prior count of 0.5 fragments, etc. This behavior can be modified in two; ways. First, the prior itself can be modified via Salmon's ``--vbPrior``; option. The argument to this option is the value you wish to place as the; *per-nucleotide* prior. Additionally, you can modify the behavior to use; a *per-transcript* rather than a *per-nucleotide* prior by passing the flag; ``--perTranscriptPrior`` to Salmon. In this case, whatever value is set; by ``--vbPrior`` will be used as the transcript-level prior, so that the; prior count is no longer dependent on the transcript length. However,; the default behavior of a *per-nucleotide* prior is recommended when; using VB optimization. .. note:: Choosing between EM and VBEM algorithms. As mentioned above, a thorough comparison of all of the benefits and detriments; of the different algorithms is an ongoing area of research. However, preliminary; testing suggests that the sparsity-inducing effect of running the VBEM with a small; prior may lead, in general, to more accurate estimates (the current testing was; performed mostly through simulation). Hence, the VBEM is the default, and the; standard EM algorithm is accessed via the `--useEM` flag. """"""""""""""""""""""""""""""""""""""""""""""""""""""""""; ``--numBootstraps``; """""""""""""""""""""""""""""""""""""""""""""""""""""""""". Salmon has the ability to optionally compute bootstrapped abundance estimates.; This is done by resampling (with replacement) from the counts assigned to; the fragment equivalence classes, and then re-running t",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:41668,Integrability,protocol,protocol,41668," file, everything should; work as expected; otherwise, you should provide the library; type explicitly in alignment-based mode.; ; Also the automatic library type detection is performed *on the; basis of the alignments in the file*. Thus, for example, if the; upstream aligner has been told to perform strand-aware mapping; (i.e. to ignore potential alignments that don't map in the; expected manner), but the actual library is unstranded,; automatic library type detection cannot detect this. It will; attempt to detect the library type that is most consistent *with; the alignment that are provided*. The library type string consists of three parts: the relative orientation of; the reads, the strandedness of the library, and the directionality of the; reads. The first part of the library string (relative orientation) is only provided if; the library is paired-end. The possible options are:. ::. I = inward; O = outward; M = matching. The second part of the read library string specifies whether the protocol is; stranded or unstranded; the options are:. ::. S = stranded; U = unstranded. If the protocol is unstranded, then we're done. The final part of the library; string specifies the strand from which the read originates in a strand-specific; protocol — it is only provided if the library is stranded (i.e. if the; library format string is of the form S). The possible values are:. ::. F = read 1 (or single-end read) comes from the forward strand; R = read 1 (or single-end read) comes from the reverse strand. An example of some library format strings and their interpretations are:. ::. IU (an unstranded paired-end library where the reads face each other). ::. SF (a stranded single-end protocol where the reads come from the forward strand). ::. OSR (a stranded paired-end protocol where the reads face away from each other,; read1 comes from reverse strand and read2 comes from the forward strand). .. note:: Strand Matching. Above, when it is said that the read ""comes from"" a stra",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:41764,Integrability,protocol,protocol,41764,"sed mode.; ; Also the automatic library type detection is performed *on the; basis of the alignments in the file*. Thus, for example, if the; upstream aligner has been told to perform strand-aware mapping; (i.e. to ignore potential alignments that don't map in the; expected manner), but the actual library is unstranded,; automatic library type detection cannot detect this. It will; attempt to detect the library type that is most consistent *with; the alignment that are provided*. The library type string consists of three parts: the relative orientation of; the reads, the strandedness of the library, and the directionality of the; reads. The first part of the library string (relative orientation) is only provided if; the library is paired-end. The possible options are:. ::. I = inward; O = outward; M = matching. The second part of the read library string specifies whether the protocol is; stranded or unstranded; the options are:. ::. S = stranded; U = unstranded. If the protocol is unstranded, then we're done. The final part of the library; string specifies the strand from which the read originates in a strand-specific; protocol — it is only provided if the library is stranded (i.e. if the; library format string is of the form S). The possible values are:. ::. F = read 1 (or single-end read) comes from the forward strand; R = read 1 (or single-end read) comes from the reverse strand. An example of some library format strings and their interpretations are:. ::. IU (an unstranded paired-end library where the reads face each other). ::. SF (a stranded single-end protocol where the reads come from the forward strand). ::. OSR (a stranded paired-end protocol where the reads face away from each other,; read1 comes from reverse strand and read2 comes from the forward strand). .. note:: Strand Matching. Above, when it is said that the read ""comes from"" a strand, we mean that; the read should align with / map to that strand. For example, for; libraries having the ``OSR`` prot",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:41917,Integrability,protocol,protocol,41917,"e*. Thus, for example, if the; upstream aligner has been told to perform strand-aware mapping; (i.e. to ignore potential alignments that don't map in the; expected manner), but the actual library is unstranded,; automatic library type detection cannot detect this. It will; attempt to detect the library type that is most consistent *with; the alignment that are provided*. The library type string consists of three parts: the relative orientation of; the reads, the strandedness of the library, and the directionality of the; reads. The first part of the library string (relative orientation) is only provided if; the library is paired-end. The possible options are:. ::. I = inward; O = outward; M = matching. The second part of the read library string specifies whether the protocol is; stranded or unstranded; the options are:. ::. S = stranded; U = unstranded. If the protocol is unstranded, then we're done. The final part of the library; string specifies the strand from which the read originates in a strand-specific; protocol — it is only provided if the library is stranded (i.e. if the; library format string is of the form S). The possible values are:. ::. F = read 1 (or single-end read) comes from the forward strand; R = read 1 (or single-end read) comes from the reverse strand. An example of some library format strings and their interpretations are:. ::. IU (an unstranded paired-end library where the reads face each other). ::. SF (a stranded single-end protocol where the reads come from the forward strand). ::. OSR (a stranded paired-end protocol where the reads face away from each other,; read1 comes from reverse strand and read2 comes from the forward strand). .. note:: Strand Matching. Above, when it is said that the read ""comes from"" a strand, we mean that; the read should align with / map to that strand. For example, for; libraries having the ``OSR`` protocol as described above, we expect that; read1 maps to the reverse strand, and read2 maps to the forward strand",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:42365,Integrability,protocol,protocol,42365,"ibrary, and the directionality of the; reads. The first part of the library string (relative orientation) is only provided if; the library is paired-end. The possible options are:. ::. I = inward; O = outward; M = matching. The second part of the read library string specifies whether the protocol is; stranded or unstranded; the options are:. ::. S = stranded; U = unstranded. If the protocol is unstranded, then we're done. The final part of the library; string specifies the strand from which the read originates in a strand-specific; protocol — it is only provided if the library is stranded (i.e. if the; library format string is of the form S). The possible values are:. ::. F = read 1 (or single-end read) comes from the forward strand; R = read 1 (or single-end read) comes from the reverse strand. An example of some library format strings and their interpretations are:. ::. IU (an unstranded paired-end library where the reads face each other). ::. SF (a stranded single-end protocol where the reads come from the forward strand). ::. OSR (a stranded paired-end protocol where the reads face away from each other,; read1 comes from reverse strand and read2 comes from the forward strand). .. note:: Strand Matching. Above, when it is said that the read ""comes from"" a strand, we mean that; the read should align with / map to that strand. For example, for; libraries having the ``OSR`` protocol as described above, we expect that; read1 maps to the reverse strand, and read2 maps to the forward strand. . For more details on the library type, see :ref:`FragLibType`. . Output; ------. For details of Salmon's different output files and their formats see :ref:`FileFormats`. Misc; ----. Salmon, in *quasi-mapping*-based mode, can accept reads from FASTA/Q; format files, or directly from gzipped FASTA/Q files (the ability to; accept compressed files directly is a feature of Salmon 0.7.0 and; higher). If your reads are compressed in a different format, you can; still stream them directly",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:42452,Integrability,protocol,protocol,42452," if; the library is paired-end. The possible options are:. ::. I = inward; O = outward; M = matching. The second part of the read library string specifies whether the protocol is; stranded or unstranded; the options are:. ::. S = stranded; U = unstranded. If the protocol is unstranded, then we're done. The final part of the library; string specifies the strand from which the read originates in a strand-specific; protocol — it is only provided if the library is stranded (i.e. if the; library format string is of the form S). The possible values are:. ::. F = read 1 (or single-end read) comes from the forward strand; R = read 1 (or single-end read) comes from the reverse strand. An example of some library format strings and their interpretations are:. ::. IU (an unstranded paired-end library where the reads face each other). ::. SF (a stranded single-end protocol where the reads come from the forward strand). ::. OSR (a stranded paired-end protocol where the reads face away from each other,; read1 comes from reverse strand and read2 comes from the forward strand). .. note:: Strand Matching. Above, when it is said that the read ""comes from"" a strand, we mean that; the read should align with / map to that strand. For example, for; libraries having the ``OSR`` protocol as described above, we expect that; read1 maps to the reverse strand, and read2 maps to the forward strand. . For more details on the library type, see :ref:`FragLibType`. . Output; ------. For details of Salmon's different output files and their formats see :ref:`FileFormats`. Misc; ----. Salmon, in *quasi-mapping*-based mode, can accept reads from FASTA/Q; format files, or directly from gzipped FASTA/Q files (the ability to; accept compressed files directly is a feature of Salmon 0.7.0 and; higher). If your reads are compressed in a different format, you can; still stream them directly to Salmon by using process substitution.; Say in the *quasi-mapping*-based Salmon example above, the reads were; actually",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:42776,Integrability,protocol,protocol,42776,"inal part of the library; string specifies the strand from which the read originates in a strand-specific; protocol — it is only provided if the library is stranded (i.e. if the; library format string is of the form S). The possible values are:. ::. F = read 1 (or single-end read) comes from the forward strand; R = read 1 (or single-end read) comes from the reverse strand. An example of some library format strings and their interpretations are:. ::. IU (an unstranded paired-end library where the reads face each other). ::. SF (a stranded single-end protocol where the reads come from the forward strand). ::. OSR (a stranded paired-end protocol where the reads face away from each other,; read1 comes from reverse strand and read2 comes from the forward strand). .. note:: Strand Matching. Above, when it is said that the read ""comes from"" a strand, we mean that; the read should align with / map to that strand. For example, for; libraries having the ``OSR`` protocol as described above, we expect that; read1 maps to the reverse strand, and read2 maps to the forward strand. . For more details on the library type, see :ref:`FragLibType`. . Output; ------. For details of Salmon's different output files and their formats see :ref:`FileFormats`. Misc; ----. Salmon, in *quasi-mapping*-based mode, can accept reads from FASTA/Q; format files, or directly from gzipped FASTA/Q files (the ability to; accept compressed files directly is a feature of Salmon 0.7.0 and; higher). If your reads are compressed in a different format, you can; still stream them directly to Salmon by using process substitution.; Say in the *quasi-mapping*-based Salmon example above, the reads were; actually in the files ``reads1.fa.bz2`` and ``reads2.fa.bz2``, then; you'd run the following command to decompress the reads ""on-the-fly"":. ::. > ./bin/salmon quant -i transcripts_index -l <LIBTYPE> -1 <(bunzip2 -c reads1.fa.gz) -2 <(bunzip2 -c reads2.fa.bz2) -o transcripts_quant. and the bzipped files will be decom",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:1094,Modifiability,enhance,enhancement,1094,"ta. It requires a set of target transcripts (either from a reference or; *de-novo* assembly) to quantify. All you need to run Salmon is a FASTA file; containing your reference transcripts and a (set of) FASTA/FASTQ file(s); containing your reads. Optionally, Salmon can make use of pre-computed; alignments (in the form of a SAM/BAM file) to the transcripts rather than the; raw reads. The **mapping**-based mode of Salmon runs in two phases; indexing and; quantification. The indexing step is independent of the reads, and only needs to; be run once for a particular set of reference transcripts. The quantification; step, obviously, is specific to the set of RNA-seq reads and is thus run more; frequently. For a more complete description of all available options in Salmon,; see below. .. note:: Selective alignment. Selective alignment, first introduced by the ``--validateMappings`` flag; in salmon, and now the default mapping strategy (in version 1.0.0; forward), is a major feature enhancement introduced in recent versions of; salmon. When salmon is run with selective alignment, it adopts a; considerably more sensitive scheme that we have developed for finding the; potential mapping loci of a read, and score potential mapping loci using; the chaining algorithm introduced in minimap2 [#minimap2]_. It scores and; validates these mappings using the score-only, SIMD, dynamic programming; algorithm of ksw2 [#ksw2]_. Finally, we recommend using selective; alignment with a *decoy-aware* transcriptome, to mitigate potential; spurious mapping of reads that actually arise from some unannotated; genomic locus that is sequence-similar to an annotated transcriptome. The; selective-alignment algorithm, the use of a decoy-aware transcriptome, and; the influence of running salmon with different mapping and alignment; strategies is covered in detail in the paper `Alignment and mapping methodology influence transcript abundance estimation <https://genomebiology.biomedcentral.com/articles/10.",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:24777,Modifiability,extend,extended,24777," minimum score fraction of ``f``, only; mappings with a score > ``f * s`` will be kept. Mappings with lower scores will be considered as low-quality,; and will be discarded. It is worth noting that mapping validation uses extension alignment. This means that the read need not; map end-to-end. Instead, the score of the mapping will be the position along the alignment with the; highest score. This is the score which must reach the fraction threshold for the read to be considered; as valid. """"""""""""""""""""""""""""""""""""""""""""""""""; ``--bandwidth``; """""""""""""""""""""""""""""""""""""""""""""""""". This flag (which is only meaningful in conjunction with selective alignment),; sets the bandwidth parameter of the relevant calls to ksw2's alignment function.; This determines how wide an area around the diagonal in the DP matrix should be; calculated. """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; ``--maxMMPExtension``; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""". This flag (which should only be used with selective alignment) limits the length; that a mappable prefix of a fragment may be extended before another search along; the fragment is started. Smaller values for this flag can improve the; sensitivity of mapping, but could increase run time. """"""""""""""""""""""""""""""""""""; ``--ma``; """""""""""""""""""""""""""""""""""". This value should be a positive (typically small) integer. It controls the score given; to a match in the alignment between the query (read) and the reference. """"""""""""""""""""""""""""""""""""; ``--mp``; """""""""""""""""""""""""""""""""""". This value should be a negative (typically small) integer. It controls the score given; to a mismatch in the alignment between the query (read) and the reference. """"""""""""""""""""""""""""""""""""; ``--go``; """""""""""""""""""""""""""""""""""". This value should be a positive (typically small) integer. It controls the score; penalty attributed to an alignment for each new gap that is opened. The; alignment score computed uses an affine gap penalty, so the penalty of a gap is; ``go + l * ge`` where l is the gap length. The value of ``go`` should typically; be larger than t",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:31713,Modifiability,variab,variable-length,31713,"es rather than bootstrapping. We are currently analyzing these different approaches; to assess the potential trade-offs in time / accuracy. The ``--numBootstraps`` and; ``--numGibbsSamples`` options are mutually exclusive (i.e. in a given run, you must; set at most one of these options to a positive integer.). """"""""""""""""""""""""""""""""""""""""""; ``--seqBias``; """""""""""""""""""""""""""""""""""""""""". Passing the ``--seqBias`` flag to Salmon will enable it to learn and; correct for sequence-specific biases in the input data. Specifically,; this model will attempt to correct for random hexamer priming bias,; which results in the preferential sequencing of fragments starting; with certain nucleotide motifs. By default, Salmon learns the; sequence-specific bias parameters using 1,000,000 reads from the; beginning of the input. If you wish to change the number of samples; from which the model is learned, you can use the ``--numBiasSamples``; parameter. Salmon uses a variable-length Markov Model; (VLMM) to model the sequence specific biases at both the 5' and 3' end; of sequenced fragments. This methodology generally follows that of; Roberts et al. [#roberts]_, though some details of the VLMM differ. *Note*: This sequence-specific bias model is substantially different; from the bias-correction methodology that was used in Salmon versions; prior to 0.6.0. This model specifically accounts for; sequence-specific bias, and should not be prone to the over-fitting; problem that was sometimes observed using the previous bias-correction; methodology. """"""""""""""""""""""""""""""""""""""""""; ``--gcBias``; """""""""""""""""""""""""""""""""""""""""". Passing the ``--gcBias`` flag to Salmon will enable it to learn and; correct for fragment-level GC biases in the input data. Specifically,; this model will attempt to correct for biases in how likely a sequence; is to be observed based on its internal GC content. . You can use the FASTQC software followed by ; `MultiQC with transcriptome GC distributions <http://multiqc.info/docs/#theoretical-gc-content>`",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:44065,Modifiability,config,configuration,44065,"pt reads from FASTA/Q; format files, or directly from gzipped FASTA/Q files (the ability to; accept compressed files directly is a feature of Salmon 0.7.0 and; higher). If your reads are compressed in a different format, you can; still stream them directly to Salmon by using process substitution.; Say in the *quasi-mapping*-based Salmon example above, the reads were; actually in the files ``reads1.fa.bz2`` and ``reads2.fa.bz2``, then; you'd run the following command to decompress the reads ""on-the-fly"":. ::. > ./bin/salmon quant -i transcripts_index -l <LIBTYPE> -1 <(bunzip2 -c reads1.fa.gz) -2 <(bunzip2 -c reads2.fa.bz2) -o transcripts_quant. and the bzipped files will be decompressed via separate processes and; the raw reads will be fed into Salmon. Actually, you can use this; same process even with gzip compressed reads (replacing ``bunzip2``; with ``gunzip`` or ``pigz -d``). Depending on the number of threads; and the exact configuration, this may actually improve Salmon's; running time, since the reads are decompressed concurrently in a; separate process when you use process substitution. **Finally**, the purpose of making this software available is for; people to use it and provide feedback. The; `paper describing this method is published in Nature Methods <http://rdcu.be/pQsw>`_.; If you have something useful to report or just some interesting ideas; or suggestions, please contact us (`rob.patro@cs.stonybrook.edu`; and/or `carlk@cs.cmu.edu`). If you encounter any bugs, please file a; *detailed* bug report at the `Salmon GitHub repository <https://github.com/COMBINE-lab/salmon>`_. References; ----------. .. [#express] Roberts, Adam, and Lior Pachter. ""Streaming fragment assignment for real-time analysis of sequencing experiments."" Nature Methods 10.1 (2013): 71-73.; ; .. [#roberts] Roberts, Adam, et al. ""Improving RNA-Seq expression estimates by correcting for fragment bias."" Genome Biology 12.3 (2011): 1. .. [#salmon] Patro, Rob, et al. ""Salmon provides fast a",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:3716,Performance,perform,perform,3716,"for the; purposes of quantification. . The **alignment**-based mode of Salmon does not require indexing. Rather, you can ; simply provide Salmon with a FASTA file of the transcripts and a SAM/BAM file; containing the alignments you wish to use for quantification. Salmon is, and will continue to be, `freely and actively supported on a best-effort basis <https://oceangenomics.com/about/#open>`_.; If you are in need of industrial-grade technical support, please consider the options at `oceangenomics.com/support <https://oceangenomics.com/support>`_. Using Salmon; ------------. As mentioned above, there are two ""modes"" of operation for Salmon. The first,; requires you to build an index for the transcriptome, but then subsequently; processes reads directly. The second mode simply requires you to provide a; FASTA file of the transcriptome and a ``.sam`` or ``.bam`` file containing a; set of alignments. .. note:: Read / alignment order. Salmon, like eXpress [#express]_, uses a streaming inference method to perform ; transcript-level quantification. One of the fundamental assumptions ; of such inference methods is that observations (i.e. reads or alignments); are made ""at random"". This means, for example, that alignments should ; **not** be sorted by target or position. If your reads or alignments ; do not appear in a random order with respect to the target transcripts,; please randomize / shuffle them before performing quantification with ; Salmon. .. note:: Number of Threads. The number of threads that Salmon can effectively make use of depends ; upon the mode in which it is being run. In alignment-based mode, the; main bottleneck is in parsing and decompressing the input BAM file.; We make use of the `Staden IO <http://sourceforge.net/projects/staden/files/io_lib/>`_ ; library for SAM/BAM/CRAM I/O (CRAM is, in theory, supported, but has not been; thoroughly tested). This means that multiple threads can be effectively used; to aid in BAM decompression. However, we find th",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:4126,Performance,perform,performing,4126,"ics.com/about/#open>`_.; If you are in need of industrial-grade technical support, please consider the options at `oceangenomics.com/support <https://oceangenomics.com/support>`_. Using Salmon; ------------. As mentioned above, there are two ""modes"" of operation for Salmon. The first,; requires you to build an index for the transcriptome, but then subsequently; processes reads directly. The second mode simply requires you to provide a; FASTA file of the transcriptome and a ``.sam`` or ``.bam`` file containing a; set of alignments. .. note:: Read / alignment order. Salmon, like eXpress [#express]_, uses a streaming inference method to perform ; transcript-level quantification. One of the fundamental assumptions ; of such inference methods is that observations (i.e. reads or alignments); are made ""at random"". This means, for example, that alignments should ; **not** be sorted by target or position. If your reads or alignments ; do not appear in a random order with respect to the target transcripts,; please randomize / shuffle them before performing quantification with ; Salmon. .. note:: Number of Threads. The number of threads that Salmon can effectively make use of depends ; upon the mode in which it is being run. In alignment-based mode, the; main bottleneck is in parsing and decompressing the input BAM file.; We make use of the `Staden IO <http://sourceforge.net/projects/staden/files/io_lib/>`_ ; library for SAM/BAM/CRAM I/O (CRAM is, in theory, supported, but has not been; thoroughly tested). This means that multiple threads can be effectively used; to aid in BAM decompression. However, we find that throwing more than a ; few threads at file decompression does not result in increased processing; speed. Thus, alignment-based Salmon will only ever allocate up to 4 threads; to file decompression, with the rest being allocated to quantification.; If these threads are starved, they will sleep (the quantification threads ; do not busy wait), but there is a point beyond ",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:4343,Performance,bottleneck,bottleneck,4343,"st,; requires you to build an index for the transcriptome, but then subsequently; processes reads directly. The second mode simply requires you to provide a; FASTA file of the transcriptome and a ``.sam`` or ``.bam`` file containing a; set of alignments. .. note:: Read / alignment order. Salmon, like eXpress [#express]_, uses a streaming inference method to perform ; transcript-level quantification. One of the fundamental assumptions ; of such inference methods is that observations (i.e. reads or alignments); are made ""at random"". This means, for example, that alignments should ; **not** be sorted by target or position. If your reads or alignments ; do not appear in a random order with respect to the target transcripts,; please randomize / shuffle them before performing quantification with ; Salmon. .. note:: Number of Threads. The number of threads that Salmon can effectively make use of depends ; upon the mode in which it is being run. In alignment-based mode, the; main bottleneck is in parsing and decompressing the input BAM file.; We make use of the `Staden IO <http://sourceforge.net/projects/staden/files/io_lib/>`_ ; library for SAM/BAM/CRAM I/O (CRAM is, in theory, supported, but has not been; thoroughly tested). This means that multiple threads can be effectively used; to aid in BAM decompression. However, we find that throwing more than a ; few threads at file decompression does not result in increased processing; speed. Thus, alignment-based Salmon will only ever allocate up to 4 threads; to file decompression, with the rest being allocated to quantification.; If these threads are starved, they will sleep (the quantification threads ; do not busy wait), but there is a point beyond which allocating more threads; will not speed up alignment-based quantification. We find that allocating ; 8 --- 12 threads results in the maximum speed, threads allocated above this; limit will likely spend most of their time idle / sleeping. For quasi-mapping-based Salmon, the s",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:5396,Performance,perform,performance,5396,"e `Staden IO <http://sourceforge.net/projects/staden/files/io_lib/>`_ ; library for SAM/BAM/CRAM I/O (CRAM is, in theory, supported, but has not been; thoroughly tested). This means that multiple threads can be effectively used; to aid in BAM decompression. However, we find that throwing more than a ; few threads at file decompression does not result in increased processing; speed. Thus, alignment-based Salmon will only ever allocate up to 4 threads; to file decompression, with the rest being allocated to quantification.; If these threads are starved, they will sleep (the quantification threads ; do not busy wait), but there is a point beyond which allocating more threads; will not speed up alignment-based quantification. We find that allocating ; 8 --- 12 threads results in the maximum speed, threads allocated above this; limit will likely spend most of their time idle / sleeping. For quasi-mapping-based Salmon, the story is somewhat different.; Generally, performance continues to improve as more threads are made; available. This is because the determination of the potential mapping; locations of each read is, generally, the slowest step in; quasi-mapping-based quantification. Since this process is; trivially parallelizable (and well-parallelized within Salmon), more; threads generally equates to faster quantification. However, there may; still be a limit to the return on invested threads, when Salmon can begin; to process fragments more quickly than they can be provided via the parser.; ; ; Preparing transcriptome indices (mapping-based mode) ; ----------------------------------------------------------. One of the novel and innovative features of Salmon is its ability to accurately; quantify transcripts without having previously aligned the reads using its fast,; built-in selective-alignment mapping algorithm. Further details about the selective alignment algorithm can be; found `here <https://www.biorxiv.org/content/10.1101/657874v1>`_. If you want to use Salmon ",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:16868,Performance,optimiz,optimization,16868," mimic alignment using Bowtie2 (with the flags; ``--no-discordant`` and ``--no-mixed``), but using the default scoring scheme; and allowing both mismatches and indels in alignments. """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""; ``--mimicStrictBT2``; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""". This flag is a ""meta-flag"" that sets the parameters related to mapping and; selective alignment to mimic alignment using Bowtie2 (with the flags suggested; by RSEM), but using the default scoring scheme and allowing both mismatches and; indels in alignments. These setting essentially disallow indels in the resulting; alignments. """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""; ``--meta``; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""". As with the flags described above, this is a ""meta-flag"" that simply enables some options; that may make more sense when quantifying metagenomic data. Specifically, the ``--meta``; flag sets the following options: . * The abundance optimization is initialized from the uniform distribution (compared to the default of using a weighted combination of the uniform intialization and the abundances learned during the online optimization). * Rich equivalence classes are disabled. Using rich equivalence classes with metagenomic data should not be particularly problematic, but since they have been developed and tested most in the context of bulk RNA-seq quantification, they are currently disabled under this flag. * The EM algorithm is used for abundance optimization instead of the default VBEM optimization. Neither is universally better than the other, but the parameters for the VBEM (e.g. the prior size and type) are set based on typical bulk RNA-seq transcriptome samples, and so may be less appropriate in the metagenomic context. Hence the ``--meta`` flags opts for the basic EM algorithm instead. """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""; ``--recoverOrphans``; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""". This flag (which should only be used in conjunction with selective alignment),; performs orphan ""rescue"" for reads. That is, if mappi",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:17057,Performance,optimiz,optimization,17057," mimic alignment using Bowtie2 (with the flags; ``--no-discordant`` and ``--no-mixed``), but using the default scoring scheme; and allowing both mismatches and indels in alignments. """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""; ``--mimicStrictBT2``; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""". This flag is a ""meta-flag"" that sets the parameters related to mapping and; selective alignment to mimic alignment using Bowtie2 (with the flags suggested; by RSEM), but using the default scoring scheme and allowing both mismatches and; indels in alignments. These setting essentially disallow indels in the resulting; alignments. """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""; ``--meta``; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""". As with the flags described above, this is a ""meta-flag"" that simply enables some options; that may make more sense when quantifying metagenomic data. Specifically, the ``--meta``; flag sets the following options: . * The abundance optimization is initialized from the uniform distribution (compared to the default of using a weighted combination of the uniform intialization and the abundances learned during the online optimization). * Rich equivalence classes are disabled. Using rich equivalence classes with metagenomic data should not be particularly problematic, but since they have been developed and tested most in the context of bulk RNA-seq quantification, they are currently disabled under this flag. * The EM algorithm is used for abundance optimization instead of the default VBEM optimization. Neither is universally better than the other, but the parameters for the VBEM (e.g. the prior size and type) are set based on typical bulk RNA-seq transcriptome samples, and so may be less appropriate in the metagenomic context. Hence the ``--meta`` flags opts for the basic EM algorithm instead. """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""; ``--recoverOrphans``; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""". This flag (which should only be used in conjunction with selective alignment),; performs orphan ""rescue"" for reads. That is, if mappi",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:17390,Performance,optimiz,optimization,17390,"ut using the default scoring scheme and allowing both mismatches and; indels in alignments. These setting essentially disallow indels in the resulting; alignments. """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""; ``--meta``; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""". As with the flags described above, this is a ""meta-flag"" that simply enables some options; that may make more sense when quantifying metagenomic data. Specifically, the ``--meta``; flag sets the following options: . * The abundance optimization is initialized from the uniform distribution (compared to the default of using a weighted combination of the uniform intialization and the abundances learned during the online optimization). * Rich equivalence classes are disabled. Using rich equivalence classes with metagenomic data should not be particularly problematic, but since they have been developed and tested most in the context of bulk RNA-seq quantification, they are currently disabled under this flag. * The EM algorithm is used for abundance optimization instead of the default VBEM optimization. Neither is universally better than the other, but the parameters for the VBEM (e.g. the prior size and type) are set based on typical bulk RNA-seq transcriptome samples, and so may be less appropriate in the metagenomic context. Hence the ``--meta`` flags opts for the basic EM algorithm instead. """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""; ``--recoverOrphans``; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""". This flag (which should only be used in conjunction with selective alignment),; performs orphan ""rescue"" for reads. That is, if mappings are discovered for only; one end of a fragment, or if the mappings for the ends of the fragment don't; fall on the same transcript, then this flag will cause salmon to look upstream; or downstream of the discovered mapping (anchor) for a match for the opposite; end of the given fragment. This is done by performing ""infix"" alignment within; the maximum fragment length upstream of downstream of the anchor mapping using; edlib. """"",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:17431,Performance,optimiz,optimization,17431,"ut using the default scoring scheme and allowing both mismatches and; indels in alignments. These setting essentially disallow indels in the resulting; alignments. """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""; ``--meta``; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""". As with the flags described above, this is a ""meta-flag"" that simply enables some options; that may make more sense when quantifying metagenomic data. Specifically, the ``--meta``; flag sets the following options: . * The abundance optimization is initialized from the uniform distribution (compared to the default of using a weighted combination of the uniform intialization and the abundances learned during the online optimization). * Rich equivalence classes are disabled. Using rich equivalence classes with metagenomic data should not be particularly problematic, but since they have been developed and tested most in the context of bulk RNA-seq quantification, they are currently disabled under this flag. * The EM algorithm is used for abundance optimization instead of the default VBEM optimization. Neither is universally better than the other, but the parameters for the VBEM (e.g. the prior size and type) are set based on typical bulk RNA-seq transcriptome samples, and so may be less appropriate in the metagenomic context. Hence the ``--meta`` flags opts for the basic EM algorithm instead. """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""; ``--recoverOrphans``; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""". This flag (which should only be used in conjunction with selective alignment),; performs orphan ""rescue"" for reads. That is, if mappings are discovered for only; one end of a fragment, or if the mappings for the ends of the fragment don't; fall on the same transcript, then this flag will cause salmon to look upstream; or downstream of the discovered mapping (anchor) for a match for the opposite; end of the given fragment. This is done by performing ""infix"" alignment within; the maximum fragment length upstream of downstream of the anchor mapping using; edlib. """"",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:17908,Performance,perform,performs,17908,"nitialized from the uniform distribution (compared to the default of using a weighted combination of the uniform intialization and the abundances learned during the online optimization). * Rich equivalence classes are disabled. Using rich equivalence classes with metagenomic data should not be particularly problematic, but since they have been developed and tested most in the context of bulk RNA-seq quantification, they are currently disabled under this flag. * The EM algorithm is used for abundance optimization instead of the default VBEM optimization. Neither is universally better than the other, but the parameters for the VBEM (e.g. the prior size and type) are set based on typical bulk RNA-seq transcriptome samples, and so may be less appropriate in the metagenomic context. Hence the ``--meta`` flags opts for the basic EM algorithm instead. """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""; ``--recoverOrphans``; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""". This flag (which should only be used in conjunction with selective alignment),; performs orphan ""rescue"" for reads. That is, if mappings are discovered for only; one end of a fragment, or if the mappings for the ends of the fragment don't; fall on the same transcript, then this flag will cause salmon to look upstream; or downstream of the discovered mapping (anchor) for a match for the opposite; end of the given fragment. This is done by performing ""infix"" alignment within; the maximum fragment length upstream of downstream of the anchor mapping using; edlib. """"""""""""""""""""""""""""""""""""""""""""""""""""; ``--hardFilter``; """""""""""""""""""""""""""""""""""""""""""""""""""". This flag (which should only be used with selective alignment) turns off soft; filtering and range-factorized equivalence classes, and removes all but the; equally highest scoring mappings from the equivalence class label for each; fragment. While we recommend using soft filtering (the default) for; quantification, this flag can produce easier-to-understand equivalence classes; if that is the primary object of stu",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:18270,Performance,perform,performing,18270,"disabled under this flag. * The EM algorithm is used for abundance optimization instead of the default VBEM optimization. Neither is universally better than the other, but the parameters for the VBEM (e.g. the prior size and type) are set based on typical bulk RNA-seq transcriptome samples, and so may be less appropriate in the metagenomic context. Hence the ``--meta`` flags opts for the basic EM algorithm instead. """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""; ``--recoverOrphans``; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""". This flag (which should only be used in conjunction with selective alignment),; performs orphan ""rescue"" for reads. That is, if mappings are discovered for only; one end of a fragment, or if the mappings for the ends of the fragment don't; fall on the same transcript, then this flag will cause salmon to look upstream; or downstream of the discovered mapping (anchor) for a match for the opposite; end of the given fragment. This is done by performing ""infix"" alignment within; the maximum fragment length upstream of downstream of the anchor mapping using; edlib. """"""""""""""""""""""""""""""""""""""""""""""""""""; ``--hardFilter``; """""""""""""""""""""""""""""""""""""""""""""""""""". This flag (which should only be used with selective alignment) turns off soft; filtering and range-factorized equivalence classes, and removes all but the; equally highest scoring mappings from the equivalence class label for each; fragment. While we recommend using soft filtering (the default) for; quantification, this flag can produce easier-to-understand equivalence classes; if that is the primary object of study. """"""""""""""""""""""""""""""""""""""""""""""""""; ``--skipQuant``; """""""""""""""""""""""""""""""""""""""""""""""""". Related to the above, this flag will stop execution before the actual; quantification algorithm is run. """"""""""""""""""""""""""""""""""""""""""""""""""""""""""; ``--allowDovetail``; """""""""""""""""""""""""""""""""""""""""""""""""""""""""". Dovetailing mappings and alignments are considered discordant and discarded by; default --- this is the same behavior that is adopted by default in Bowtie2.; This is a change f",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:27305,Performance,optimiz,optimize,27305,"cs/article/33/14/i142/3953977>`_ feature; allows using a data-driven likelihood factorization, which can improve; quantification accuracy on certain classes of ""difficult"" transcripts.; Currently, this feature interacts best (i.e., yields the most considerable; improvements) when either (1) using alignment-based mode and simultaneously; enabling error modeling with ``--useErrorModel`` or (2) when enabling; ``--validateMappings`` in quasi-mapping-based mode. The argument to this option; is a positive integer ``x``, that determines fidelity of the factorization. The larger; ``x``, the closer the factorization to the un-factorized likelihood, but the larger; the resulting number of equivalence classes. A value of 1 corresponds to salmon's; traditional rich equivalence classes. We recommend 4 as a reasonable parameter; for this option (it is what was used in the range-factorization paper). """"""""""""""""""""""""""""; ``--useEM``; """""""""""""""""""""""""""". Use the ""standard"" EM algorithm to optimize abundance estimates; instead of the variational Bayesian EM algorithm. The details of the VBEM; algorithm can be found in [#salmon]_. While both the standard EM and; the VBEM produce accurate abundance estimates, there are some; trade-offs between the approaches. Specifically, the sparsity of; the VBEM algorithm depends on the prior that is chosen. When; the prior is small, the VBEM tends to produce a sparser solution; than the EM algorithm, while when the prior is relatively larger, it; tends to estimate more non-zero abundances than the EM algorithm.; It is an active research effort to analyze and understand all the tradeoffs; between these different optimization approaches. Also, the VBEM tends to; converge after fewer iterations, so it may result in a shorter runtime;; especially if you are computing many bootstrap samples. The default prior used in the VB optimization is a *per-nucleotide* prior; of 1e-5 reads per-nucleotide. This means that a transcript of length 100000 will; have a prior cou",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:27975,Performance,optimiz,optimization,27975,"ation to the un-factorized likelihood, but the larger; the resulting number of equivalence classes. A value of 1 corresponds to salmon's; traditional rich equivalence classes. We recommend 4 as a reasonable parameter; for this option (it is what was used in the range-factorization paper). """"""""""""""""""""""""""""; ``--useEM``; """""""""""""""""""""""""""". Use the ""standard"" EM algorithm to optimize abundance estimates; instead of the variational Bayesian EM algorithm. The details of the VBEM; algorithm can be found in [#salmon]_. While both the standard EM and; the VBEM produce accurate abundance estimates, there are some; trade-offs between the approaches. Specifically, the sparsity of; the VBEM algorithm depends on the prior that is chosen. When; the prior is small, the VBEM tends to produce a sparser solution; than the EM algorithm, while when the prior is relatively larger, it; tends to estimate more non-zero abundances than the EM algorithm.; It is an active research effort to analyze and understand all the tradeoffs; between these different optimization approaches. Also, the VBEM tends to; converge after fewer iterations, so it may result in a shorter runtime;; especially if you are computing many bootstrap samples. The default prior used in the VB optimization is a *per-nucleotide* prior; of 1e-5 reads per-nucleotide. This means that a transcript of length 100000 will; have a prior count of 1 fragment, while a transcript of length 50000 will have; a prior count of 0.5 fragments, etc. This behavior can be modified in two; ways. First, the prior itself can be modified via Salmon's ``--vbPrior``; option. The argument to this option is the value you wish to place as the; *per-nucleotide* prior. Additionally, you can modify the behavior to use; a *per-transcript* rather than a *per-nucleotide* prior by passing the flag; ``--perTranscriptPrior`` to Salmon. In this case, whatever value is set; by ``--vbPrior`` will be used as the transcript-level prior, so that the; prior count is no longe",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:28187,Performance,optimiz,optimization,28187,"ctorization paper). """"""""""""""""""""""""""""; ``--useEM``; """""""""""""""""""""""""""". Use the ""standard"" EM algorithm to optimize abundance estimates; instead of the variational Bayesian EM algorithm. The details of the VBEM; algorithm can be found in [#salmon]_. While both the standard EM and; the VBEM produce accurate abundance estimates, there are some; trade-offs between the approaches. Specifically, the sparsity of; the VBEM algorithm depends on the prior that is chosen. When; the prior is small, the VBEM tends to produce a sparser solution; than the EM algorithm, while when the prior is relatively larger, it; tends to estimate more non-zero abundances than the EM algorithm.; It is an active research effort to analyze and understand all the tradeoffs; between these different optimization approaches. Also, the VBEM tends to; converge after fewer iterations, so it may result in a shorter runtime;; especially if you are computing many bootstrap samples. The default prior used in the VB optimization is a *per-nucleotide* prior; of 1e-5 reads per-nucleotide. This means that a transcript of length 100000 will; have a prior count of 1 fragment, while a transcript of length 50000 will have; a prior count of 0.5 fragments, etc. This behavior can be modified in two; ways. First, the prior itself can be modified via Salmon's ``--vbPrior``; option. The argument to this option is the value you wish to place as the; *per-nucleotide* prior. Additionally, you can modify the behavior to use; a *per-transcript* rather than a *per-nucleotide* prior by passing the flag; ``--perTranscriptPrior`` to Salmon. In this case, whatever value is set; by ``--vbPrior`` will be used as the transcript-level prior, so that the; prior count is no longer dependent on the transcript length. However,; the default behavior of a *per-nucleotide* prior is recommended when; using VB optimization. .. note:: Choosing between EM and VBEM algorithms. As mentioned above, a thorough comparison of all of the benefits and detriment",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:29063,Performance,optimiz,optimization,29063," converge after fewer iterations, so it may result in a shorter runtime;; especially if you are computing many bootstrap samples. The default prior used in the VB optimization is a *per-nucleotide* prior; of 1e-5 reads per-nucleotide. This means that a transcript of length 100000 will; have a prior count of 1 fragment, while a transcript of length 50000 will have; a prior count of 0.5 fragments, etc. This behavior can be modified in two; ways. First, the prior itself can be modified via Salmon's ``--vbPrior``; option. The argument to this option is the value you wish to place as the; *per-nucleotide* prior. Additionally, you can modify the behavior to use; a *per-transcript* rather than a *per-nucleotide* prior by passing the flag; ``--perTranscriptPrior`` to Salmon. In this case, whatever value is set; by ``--vbPrior`` will be used as the transcript-level prior, so that the; prior count is no longer dependent on the transcript length. However,; the default behavior of a *per-nucleotide* prior is recommended when; using VB optimization. .. note:: Choosing between EM and VBEM algorithms. As mentioned above, a thorough comparison of all of the benefits and detriments; of the different algorithms is an ongoing area of research. However, preliminary; testing suggests that the sparsity-inducing effect of running the VBEM with a small; prior may lead, in general, to more accurate estimates (the current testing was; performed mostly through simulation). Hence, the VBEM is the default, and the; standard EM algorithm is accessed via the `--useEM` flag. """"""""""""""""""""""""""""""""""""""""""""""""""""""""""; ``--numBootstraps``; """""""""""""""""""""""""""""""""""""""""""""""""""""""""". Salmon has the ability to optionally compute bootstrapped abundance estimates.; This is done by resampling (with replacement) from the counts assigned to; the fragment equivalence classes, and then re-running the optimization procedure,; either the EM or VBEM, for each such sample. The values of these different; bootstraps allows us to assess tec",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:29457,Performance,perform,performed,29457,"ill have; a prior count of 0.5 fragments, etc. This behavior can be modified in two; ways. First, the prior itself can be modified via Salmon's ``--vbPrior``; option. The argument to this option is the value you wish to place as the; *per-nucleotide* prior. Additionally, you can modify the behavior to use; a *per-transcript* rather than a *per-nucleotide* prior by passing the flag; ``--perTranscriptPrior`` to Salmon. In this case, whatever value is set; by ``--vbPrior`` will be used as the transcript-level prior, so that the; prior count is no longer dependent on the transcript length. However,; the default behavior of a *per-nucleotide* prior is recommended when; using VB optimization. .. note:: Choosing between EM and VBEM algorithms. As mentioned above, a thorough comparison of all of the benefits and detriments; of the different algorithms is an ongoing area of research. However, preliminary; testing suggests that the sparsity-inducing effect of running the VBEM with a small; prior may lead, in general, to more accurate estimates (the current testing was; performed mostly through simulation). Hence, the VBEM is the default, and the; standard EM algorithm is accessed via the `--useEM` flag. """"""""""""""""""""""""""""""""""""""""""""""""""""""""""; ``--numBootstraps``; """""""""""""""""""""""""""""""""""""""""""""""""""""""""". Salmon has the ability to optionally compute bootstrapped abundance estimates.; This is done by resampling (with replacement) from the counts assigned to; the fragment equivalence classes, and then re-running the optimization procedure,; either the EM or VBEM, for each such sample. The values of these different; bootstraps allows us to assess technical variance in the main abundance estimates; we produce. Such estimates can be useful for downstream (e.g. differential; expression) tools that can make use of such uncertainty estimates. This option; takes a positive integer that dictates the number of bootstrap samples to compute.; The more samples computed, the better the estimates of variance, bu",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:29890,Performance,optimiz,optimization,29890,"ill be used as the transcript-level prior, so that the; prior count is no longer dependent on the transcript length. However,; the default behavior of a *per-nucleotide* prior is recommended when; using VB optimization. .. note:: Choosing between EM and VBEM algorithms. As mentioned above, a thorough comparison of all of the benefits and detriments; of the different algorithms is an ongoing area of research. However, preliminary; testing suggests that the sparsity-inducing effect of running the VBEM with a small; prior may lead, in general, to more accurate estimates (the current testing was; performed mostly through simulation). Hence, the VBEM is the default, and the; standard EM algorithm is accessed via the `--useEM` flag. """"""""""""""""""""""""""""""""""""""""""""""""""""""""""; ``--numBootstraps``; """""""""""""""""""""""""""""""""""""""""""""""""""""""""". Salmon has the ability to optionally compute bootstrapped abundance estimates.; This is done by resampling (with replacement) from the counts assigned to; the fragment equivalence classes, and then re-running the optimization procedure,; either the EM or VBEM, for each such sample. The values of these different; bootstraps allows us to assess technical variance in the main abundance estimates; we produce. Such estimates can be useful for downstream (e.g. differential; expression) tools that can make use of such uncertainty estimates. This option; takes a positive integer that dictates the number of bootstrap samples to compute.; The more samples computed, the better the estimates of variance, but the; more computation (and time) required. """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; ``--numGibbsSamples``; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""". Just as with the bootstrap procedure above, this option produces samples that allow; us to estimate the variance in abundance estimates. However, in this case the; samples are generated using posterior Gibbs sampling over the fragment equivalence; classes rather than bootstrapping. We are currently analyzing these different approaches; to a",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:40838,Performance,perform,performed,40838,"has the ability to automatically infer (i.e. guess); the library type based on how the first few thousand reads map to the; transcriptome. To allow Salmon to automatically infer the library; type, simply provide ``-l A`` or ``--libType A`` to Salmon. Even if you; allow Salmon to infer the library type for you, you should still read; the section below, so that you can interpret how Salmon reports the; library type it discovers. .. note:: Automatic library type detection in alignment-based mode. The implementation of this feature involves opening the BAM; file, peaking at the first record, and then closing it to; determine if the library should be treated as single-end or; paired-end. Thus, *in alignment-based mode* automatic; library type detection will not work with an input; stream. If your input is a regular file, everything should; work as expected; otherwise, you should provide the library; type explicitly in alignment-based mode.; ; Also the automatic library type detection is performed *on the; basis of the alignments in the file*. Thus, for example, if the; upstream aligner has been told to perform strand-aware mapping; (i.e. to ignore potential alignments that don't map in the; expected manner), but the actual library is unstranded,; automatic library type detection cannot detect this. It will; attempt to detect the library type that is most consistent *with; the alignment that are provided*. The library type string consists of three parts: the relative orientation of; the reads, the strandedness of the library, and the directionality of the; reads. The first part of the library string (relative orientation) is only provided if; the library is paired-end. The possible options are:. ::. I = inward; O = outward; M = matching. The second part of the read library string specifies whether the protocol is; stranded or unstranded; the options are:. ::. S = stranded; U = unstranded. If the protocol is unstranded, then we're done. The final part of the library; string",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:40956,Performance,perform,perform,40956,"usand reads map to the; transcriptome. To allow Salmon to automatically infer the library; type, simply provide ``-l A`` or ``--libType A`` to Salmon. Even if you; allow Salmon to infer the library type for you, you should still read; the section below, so that you can interpret how Salmon reports the; library type it discovers. .. note:: Automatic library type detection in alignment-based mode. The implementation of this feature involves opening the BAM; file, peaking at the first record, and then closing it to; determine if the library should be treated as single-end or; paired-end. Thus, *in alignment-based mode* automatic; library type detection will not work with an input; stream. If your input is a regular file, everything should; work as expected; otherwise, you should provide the library; type explicitly in alignment-based mode.; ; Also the automatic library type detection is performed *on the; basis of the alignments in the file*. Thus, for example, if the; upstream aligner has been told to perform strand-aware mapping; (i.e. to ignore potential alignments that don't map in the; expected manner), but the actual library is unstranded,; automatic library type detection cannot detect this. It will; attempt to detect the library type that is most consistent *with; the alignment that are provided*. The library type string consists of three parts: the relative orientation of; the reads, the strandedness of the library, and the directionality of the; reads. The first part of the library string (relative orientation) is only provided if; the library is paired-end. The possible options are:. ::. I = inward; O = outward; M = matching. The second part of the read library string specifies whether the protocol is; stranded or unstranded; the options are:. ::. S = stranded; U = unstranded. If the protocol is unstranded, then we're done. The final part of the library; string specifies the strand from which the read originates in a strand-specific; protocol — it is only pro",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:44163,Performance,concurren,concurrently,44163,"pt reads from FASTA/Q; format files, or directly from gzipped FASTA/Q files (the ability to; accept compressed files directly is a feature of Salmon 0.7.0 and; higher). If your reads are compressed in a different format, you can; still stream them directly to Salmon by using process substitution.; Say in the *quasi-mapping*-based Salmon example above, the reads were; actually in the files ``reads1.fa.bz2`` and ``reads2.fa.bz2``, then; you'd run the following command to decompress the reads ""on-the-fly"":. ::. > ./bin/salmon quant -i transcripts_index -l <LIBTYPE> -1 <(bunzip2 -c reads1.fa.gz) -2 <(bunzip2 -c reads2.fa.bz2) -o transcripts_quant. and the bzipped files will be decompressed via separate processes and; the raw reads will be fed into Salmon. Actually, you can use this; same process even with gzip compressed reads (replacing ``bunzip2``; with ``gunzip`` or ``pigz -d``). Depending on the number of threads; and the exact configuration, this may actually improve Salmon's; running time, since the reads are decompressed concurrently in a; separate process when you use process substitution. **Finally**, the purpose of making this software available is for; people to use it and provide feedback. The; `paper describing this method is published in Nature Methods <http://rdcu.be/pQsw>`_.; If you have something useful to report or just some interesting ideas; or suggestions, please contact us (`rob.patro@cs.stonybrook.edu`; and/or `carlk@cs.cmu.edu`). If you encounter any bugs, please file a; *detailed* bug report at the `Salmon GitHub repository <https://github.com/COMBINE-lab/salmon>`_. References; ----------. .. [#express] Roberts, Adam, and Lior Pachter. ""Streaming fragment assignment for real-time analysis of sequencing experiments."" Nature Methods 10.1 (2013): 71-73.; ; .. [#roberts] Roberts, Adam, et al. ""Improving RNA-Seq expression estimates by correcting for fragment bias."" Genome Biology 12.3 (2011): 1. .. [#salmon] Patro, Rob, et al. ""Salmon provides fast a",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:14809,Safety,avoid,avoids,14809,"scriptomic alignments. Salmon expects that the alignment files provided are with respect to the; transcripts given in the corresponding FASTA file. That is, Salmon expects; that the reads have been aligned directly to the transcriptome (like RSEM,; eXpress, etc.) rather than to the genome (as does, e.g. Cufflinks). If you; have reads that have already been aligned to the genome, there are; currently 3 options for converting them for use with Salmon. First, you; could convert the SAM/BAM file to a FAST{A/Q} file and then use the; lightweight-alignment-based mode of Salmon described below. Second, given the converted; FASTA{A/Q} file, you could re-align these converted reads directly to the; transcripts with your favorite aligner and run Salmon in alignment-based; mode as described above. Third, you could use a tool like `sam-xlate <https://github.com/mozack/ubu/wiki>`_; to try and convert the genome-coordinate BAM files directly into transcript ; coordinates. This avoids the necessity of having to re-map the reads. However,; we have very limited experience with this tool so far. .. topic:: Multiple alignment files; ; If your alignments for the sample you want to quantify appear in multiple ; .bam/.sam files, then you can simply provide the Salmon ``-a`` parameter ; with a (space-separated) list of these files. Salmon will automatically ; read through these one after the other quantifying transcripts using the ; alignments contained therein. However, it is currently the case that these; separate files must (1) all be of the same library type and (2) all be; aligned with respect to the same reference (i.e. the @SQ records in the ; header sections must be identical). Description of some important options; -------------------------------------. Salmon exposes a number of useful optional command-line parameters to the user.; The particularly important ones are explained here, but you can always run; ``salmon quant -h`` to see them all. """"""""""""""""""""""""""""""""""""""""""""""""; ``--mimicBT",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:17778,Safety,recover,recoverOrphans,17778,"a. Specifically, the ``--meta``; flag sets the following options: . * The abundance optimization is initialized from the uniform distribution (compared to the default of using a weighted combination of the uniform intialization and the abundances learned during the online optimization). * Rich equivalence classes are disabled. Using rich equivalence classes with metagenomic data should not be particularly problematic, but since they have been developed and tested most in the context of bulk RNA-seq quantification, they are currently disabled under this flag. * The EM algorithm is used for abundance optimization instead of the default VBEM optimization. Neither is universally better than the other, but the parameters for the VBEM (e.g. the prior size and type) are set based on typical bulk RNA-seq transcriptome samples, and so may be less appropriate in the metagenomic context. Hence the ``--meta`` flags opts for the basic EM algorithm instead. """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""; ``--recoverOrphans``; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""". This flag (which should only be used in conjunction with selective alignment),; performs orphan ""rescue"" for reads. That is, if mappings are discovered for only; one end of a fragment, or if the mappings for the ends of the fragment don't; fall on the same transcript, then this flag will cause salmon to look upstream; or downstream of the discovered mapping (anchor) for a match for the opposite; end of the given fragment. This is done by performing ""infix"" alignment within; the maximum fragment length upstream of downstream of the anchor mapping using; edlib. """"""""""""""""""""""""""""""""""""""""""""""""""""; ``--hardFilter``; """""""""""""""""""""""""""""""""""""""""""""""""""". This flag (which should only be used with selective alignment) turns off soft; filtering and range-factorized equivalence classes, and removes all but the; equally highest scoring mappings from the equivalence class label for each; fragment. While we recommend using soft filtering (the default) for; quantification,",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:40305,Safety,detect,detection,40305,"tten *before* library; type compatibility checks take place, thus the mapping file will; contain information about all mappings of the reads considered by; Salmon, even those that may later be filtered out due to; incompatibility with the library type.; ; What's this ``LIBTYPE``?; ------------------------. Salmon, has the user provide a description of the type of sequencing; library from which the reads come, and this contains information about; e.g. the relative orientation of paired-end reads. As of version; 0.7.0, Salmon also has the ability to automatically infer (i.e. guess); the library type based on how the first few thousand reads map to the; transcriptome. To allow Salmon to automatically infer the library; type, simply provide ``-l A`` or ``--libType A`` to Salmon. Even if you; allow Salmon to infer the library type for you, you should still read; the section below, so that you can interpret how Salmon reports the; library type it discovers. .. note:: Automatic library type detection in alignment-based mode. The implementation of this feature involves opening the BAM; file, peaking at the first record, and then closing it to; determine if the library should be treated as single-end or; paired-end. Thus, *in alignment-based mode* automatic; library type detection will not work with an input; stream. If your input is a regular file, everything should; work as expected; otherwise, you should provide the library; type explicitly in alignment-based mode.; ; Also the automatic library type detection is performed *on the; basis of the alignments in the file*. Thus, for example, if the; upstream aligner has been told to perform strand-aware mapping; (i.e. to ignore potential alignments that don't map in the; expected manner), but the actual library is unstranded,; automatic library type detection cannot detect this. It will; attempt to detect the library type that is most consistent *with; the alignment that are provided*. The library type string consists of three ",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:40589,Safety,detect,detection,40589,"``?; ------------------------. Salmon, has the user provide a description of the type of sequencing; library from which the reads come, and this contains information about; e.g. the relative orientation of paired-end reads. As of version; 0.7.0, Salmon also has the ability to automatically infer (i.e. guess); the library type based on how the first few thousand reads map to the; transcriptome. To allow Salmon to automatically infer the library; type, simply provide ``-l A`` or ``--libType A`` to Salmon. Even if you; allow Salmon to infer the library type for you, you should still read; the section below, so that you can interpret how Salmon reports the; library type it discovers. .. note:: Automatic library type detection in alignment-based mode. The implementation of this feature involves opening the BAM; file, peaking at the first record, and then closing it to; determine if the library should be treated as single-end or; paired-end. Thus, *in alignment-based mode* automatic; library type detection will not work with an input; stream. If your input is a regular file, everything should; work as expected; otherwise, you should provide the library; type explicitly in alignment-based mode.; ; Also the automatic library type detection is performed *on the; basis of the alignments in the file*. Thus, for example, if the; upstream aligner has been told to perform strand-aware mapping; (i.e. to ignore potential alignments that don't map in the; expected manner), but the actual library is unstranded,; automatic library type detection cannot detect this. It will; attempt to detect the library type that is most consistent *with; the alignment that are provided*. The library type string consists of three parts: the relative orientation of; the reads, the strandedness of the library, and the directionality of the; reads. The first part of the library string (relative orientation) is only provided if; the library is paired-end. The possible options are:. ::. I = inward; O = outw",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:40825,Safety,detect,detection,40825,"has the ability to automatically infer (i.e. guess); the library type based on how the first few thousand reads map to the; transcriptome. To allow Salmon to automatically infer the library; type, simply provide ``-l A`` or ``--libType A`` to Salmon. Even if you; allow Salmon to infer the library type for you, you should still read; the section below, so that you can interpret how Salmon reports the; library type it discovers. .. note:: Automatic library type detection in alignment-based mode. The implementation of this feature involves opening the BAM; file, peaking at the first record, and then closing it to; determine if the library should be treated as single-end or; paired-end. Thus, *in alignment-based mode* automatic; library type detection will not work with an input; stream. If your input is a regular file, everything should; work as expected; otherwise, you should provide the library; type explicitly in alignment-based mode.; ; Also the automatic library type detection is performed *on the; basis of the alignments in the file*. Thus, for example, if the; upstream aligner has been told to perform strand-aware mapping; (i.e. to ignore potential alignments that don't map in the; expected manner), but the actual library is unstranded,; automatic library type detection cannot detect this. It will; attempt to detect the library type that is most consistent *with; the alignment that are provided*. The library type string consists of three parts: the relative orientation of; the reads, the strandedness of the library, and the directionality of the; reads. The first part of the library string (relative orientation) is only provided if; the library is paired-end. The possible options are:. ::. I = inward; O = outward; M = matching. The second part of the read library string specifies whether the protocol is; stranded or unstranded; the options are:. ::. S = stranded; U = unstranded. If the protocol is unstranded, then we're done. The final part of the library; string",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:41126,Safety,detect,detection,41126,"ype A`` to Salmon. Even if you; allow Salmon to infer the library type for you, you should still read; the section below, so that you can interpret how Salmon reports the; library type it discovers. .. note:: Automatic library type detection in alignment-based mode. The implementation of this feature involves opening the BAM; file, peaking at the first record, and then closing it to; determine if the library should be treated as single-end or; paired-end. Thus, *in alignment-based mode* automatic; library type detection will not work with an input; stream. If your input is a regular file, everything should; work as expected; otherwise, you should provide the library; type explicitly in alignment-based mode.; ; Also the automatic library type detection is performed *on the; basis of the alignments in the file*. Thus, for example, if the; upstream aligner has been told to perform strand-aware mapping; (i.e. to ignore potential alignments that don't map in the; expected manner), but the actual library is unstranded,; automatic library type detection cannot detect this. It will; attempt to detect the library type that is most consistent *with; the alignment that are provided*. The library type string consists of three parts: the relative orientation of; the reads, the strandedness of the library, and the directionality of the; reads. The first part of the library string (relative orientation) is only provided if; the library is paired-end. The possible options are:. ::. I = inward; O = outward; M = matching. The second part of the read library string specifies whether the protocol is; stranded or unstranded; the options are:. ::. S = stranded; U = unstranded. If the protocol is unstranded, then we're done. The final part of the library; string specifies the strand from which the read originates in a strand-specific; protocol — it is only provided if the library is stranded (i.e. if the; library format string is of the form S). The possible values are:. ::. F = read 1 (o",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:41143,Safety,detect,detect,41143,"ype A`` to Salmon. Even if you; allow Salmon to infer the library type for you, you should still read; the section below, so that you can interpret how Salmon reports the; library type it discovers. .. note:: Automatic library type detection in alignment-based mode. The implementation of this feature involves opening the BAM; file, peaking at the first record, and then closing it to; determine if the library should be treated as single-end or; paired-end. Thus, *in alignment-based mode* automatic; library type detection will not work with an input; stream. If your input is a regular file, everything should; work as expected; otherwise, you should provide the library; type explicitly in alignment-based mode.; ; Also the automatic library type detection is performed *on the; basis of the alignments in the file*. Thus, for example, if the; upstream aligner has been told to perform strand-aware mapping; (i.e. to ignore potential alignments that don't map in the; expected manner), but the actual library is unstranded,; automatic library type detection cannot detect this. It will; attempt to detect the library type that is most consistent *with; the alignment that are provided*. The library type string consists of three parts: the relative orientation of; the reads, the strandedness of the library, and the directionality of the; reads. The first part of the library string (relative orientation) is only provided if; the library is paired-end. The possible options are:. ::. I = inward; O = outward; M = matching. The second part of the read library string specifies whether the protocol is; stranded or unstranded; the options are:. ::. S = stranded; U = unstranded. If the protocol is unstranded, then we're done. The final part of the library; string specifies the strand from which the read originates in a strand-specific; protocol — it is only provided if the library is stranded (i.e. if the; library format string is of the form S). The possible values are:. ::. F = read 1 (o",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:41176,Safety,detect,detect,41176,"n interpret how Salmon reports the; library type it discovers. .. note:: Automatic library type detection in alignment-based mode. The implementation of this feature involves opening the BAM; file, peaking at the first record, and then closing it to; determine if the library should be treated as single-end or; paired-end. Thus, *in alignment-based mode* automatic; library type detection will not work with an input; stream. If your input is a regular file, everything should; work as expected; otherwise, you should provide the library; type explicitly in alignment-based mode.; ; Also the automatic library type detection is performed *on the; basis of the alignments in the file*. Thus, for example, if the; upstream aligner has been told to perform strand-aware mapping; (i.e. to ignore potential alignments that don't map in the; expected manner), but the actual library is unstranded,; automatic library type detection cannot detect this. It will; attempt to detect the library type that is most consistent *with; the alignment that are provided*. The library type string consists of three parts: the relative orientation of; the reads, the strandedness of the library, and the directionality of the; reads. The first part of the library string (relative orientation) is only provided if; the library is paired-end. The possible options are:. ::. I = inward; O = outward; M = matching. The second part of the read library string specifies whether the protocol is; stranded or unstranded; the options are:. ::. S = stranded; U = unstranded. If the protocol is unstranded, then we're done. The final part of the library; string specifies the strand from which the read originates in a strand-specific; protocol — it is only provided if the library is stranded (i.e. if the; library format string is of the form S). The possible values are:. ::. F = read 1 (or single-end read) comes from the forward strand; R = read 1 (or single-end read) comes from the reverse strand. An example of some libra",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:973,Security,validat,validateMappings,973,"Salmon; ===============. Salmon is a tool for **wicked-fast** transcript quantification from RNA-seq; data. It requires a set of target transcripts (either from a reference or; *de-novo* assembly) to quantify. All you need to run Salmon is a FASTA file; containing your reference transcripts and a (set of) FASTA/FASTQ file(s); containing your reads. Optionally, Salmon can make use of pre-computed; alignments (in the form of a SAM/BAM file) to the transcripts rather than the; raw reads. The **mapping**-based mode of Salmon runs in two phases; indexing and; quantification. The indexing step is independent of the reads, and only needs to; be run once for a particular set of reference transcripts. The quantification; step, obviously, is specific to the set of RNA-seq reads and is thus run more; frequently. For a more complete description of all available options in Salmon,; see below. .. note:: Selective alignment. Selective alignment, first introduced by the ``--validateMappings`` flag; in salmon, and now the default mapping strategy (in version 1.0.0; forward), is a major feature enhancement introduced in recent versions of; salmon. When salmon is run with selective alignment, it adopts a; considerably more sensitive scheme that we have developed for finding the; potential mapping loci of a read, and score potential mapping loci using; the chaining algorithm introduced in minimap2 [#minimap2]_. It scores and; validates these mappings using the score-only, SIMD, dynamic programming; algorithm of ksw2 [#ksw2]_. Finally, we recommend using selective; alignment with a *decoy-aware* transcriptome, to mitigate potential; spurious mapping of reads that actually arise from some unannotated; genomic locus that is sequence-similar to an annotated transcriptome. The; selective-alignment algorithm, the use of a decoy-aware transcriptome, and; the influence of running salmon with different mapping and alignment; strategies is covered in detail in the paper `Alignment and mapping met",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:1430,Security,validat,validates,1430,"n the; raw reads. The **mapping**-based mode of Salmon runs in two phases; indexing and; quantification. The indexing step is independent of the reads, and only needs to; be run once for a particular set of reference transcripts. The quantification; step, obviously, is specific to the set of RNA-seq reads and is thus run more; frequently. For a more complete description of all available options in Salmon,; see below. .. note:: Selective alignment. Selective alignment, first introduced by the ``--validateMappings`` flag; in salmon, and now the default mapping strategy (in version 1.0.0; forward), is a major feature enhancement introduced in recent versions of; salmon. When salmon is run with selective alignment, it adopts a; considerably more sensitive scheme that we have developed for finding the; potential mapping loci of a read, and score potential mapping loci using; the chaining algorithm introduced in minimap2 [#minimap2]_. It scores and; validates these mappings using the score-only, SIMD, dynamic programming; algorithm of ksw2 [#ksw2]_. Finally, we recommend using selective; alignment with a *decoy-aware* transcriptome, to mitigate potential; spurious mapping of reads that actually arise from some unannotated; genomic locus that is sequence-similar to an annotated transcriptome. The; selective-alignment algorithm, the use of a decoy-aware transcriptome, and; the influence of running salmon with different mapping and alignment; strategies is covered in detail in the paper `Alignment and mapping methodology influence transcript abundance estimation <https://genomebiology.biomedcentral.com/articles/10.1186/s13059-020-02151-8>`_. The use of selective alignment implies the use of range factorization, as mapping; scores become very meaningful with this option. Selective alignment can; improve the accuracy, sometimes considerably, over the faster, but; less-precise mapping algorithm that was previously used. Also, there are a number of ; options and flags that allow ",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:8343,Security,hash,hash,8343,"ools/blob/master/README.md>`_. . - The second is to use the entire genome of the organism as the decoy sequence. This can be ; done by concatenating the genome to the end of the transcriptome you want to index and populating ; the `decoys.txt` file with the chromosome names. Detailed instructions on how to prepare this ; type of decoy sequence is available `here <https://combine-lab.github.io/alevin-tutorial/2019/selective-alignment/>`_.; This scheme provides a more comprehensive set of decoys, but, obviously, requires considerably more memory to build the index. Finally, pre-built versions of both the *partial* decoy and *full* decoy (i.e. using the whole genome) salmon indices ; for some common organisms are available via refgenie `here <http://refgenomes.databio.org/>`_. If you are not using a pre-computed index, you run the salmon indexer as so:. ::; ; > ./bin/salmon index -t transcripts.fa -i transcripts_index --decoys decoys.txt -k 31; ; This will build the mapping-based index, using an auxiliary k-mer hash; over k-mers of length 31. While the mapping algorithms will make used of arbitrarily ; long matches between the query and reference, the `k` size selected here will ; act as the *minimum* acceptable length for a valid match. Thus, a smaller ; value of `k` may slightly improve sensitivity. We find that a `k` of 31 seems; to work well for reads of 75bp or longer, but you might consider a smaller ; `k` if you plan to deal with shorter reads. Also, a shorter value of `k` may; improve sensitivity even more when using selective alignment (enabled via the `--validateMappings` flag). So,; if you are seeing a smaller mapping rate than you might expect, consider building; the index with a slightly smaller `k`. . Quantifying in mapping-based mode; ---------------------------------------. Then, you can quantify any set of reads (say, paired-end reads in files; `reads1.fq` and `reads2.fq`) directly against this index using the Salmon; ``quant`` command as follows:. ::.",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:8907,Security,validat,validateMappings,8907," memory to build the index. Finally, pre-built versions of both the *partial* decoy and *full* decoy (i.e. using the whole genome) salmon indices ; for some common organisms are available via refgenie `here <http://refgenomes.databio.org/>`_. If you are not using a pre-computed index, you run the salmon indexer as so:. ::; ; > ./bin/salmon index -t transcripts.fa -i transcripts_index --decoys decoys.txt -k 31; ; This will build the mapping-based index, using an auxiliary k-mer hash; over k-mers of length 31. While the mapping algorithms will make used of arbitrarily ; long matches between the query and reference, the `k` size selected here will ; act as the *minimum* acceptable length for a valid match. Thus, a smaller ; value of `k` may slightly improve sensitivity. We find that a `k` of 31 seems; to work well for reads of 75bp or longer, but you might consider a smaller ; `k` if you plan to deal with shorter reads. Also, a shorter value of `k` may; improve sensitivity even more when using selective alignment (enabled via the `--validateMappings` flag). So,; if you are seeing a smaller mapping rate than you might expect, consider building; the index with a slightly smaller `k`. . Quantifying in mapping-based mode; ---------------------------------------. Then, you can quantify any set of reads (say, paired-end reads in files; `reads1.fq` and `reads2.fq`) directly against this index using the Salmon; ``quant`` command as follows:. ::. > ./bin/salmon quant -i transcripts_index -l <LIBTYPE> -1 reads1.fq -2 reads2.fq --validateMappings -o transcripts_quant. If you are using single-end reads, then you pass them to Salmon with ; the ``-r`` flag like:. ::. > ./bin/salmon quant -i transcripts_index -l <LIBTYPE> -r reads.fq --validateMappings -o transcripts_quant. .. note:: Order of command-line parameters. The library type ``-l`` should be specified on the command line **before** the ; read files (i.e. the parameters to ``-1`` and ``-2``, or ``-r``). This is because; the c",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:9403,Security,validat,validateMappings,9403,"of arbitrarily ; long matches between the query and reference, the `k` size selected here will ; act as the *minimum* acceptable length for a valid match. Thus, a smaller ; value of `k` may slightly improve sensitivity. We find that a `k` of 31 seems; to work well for reads of 75bp or longer, but you might consider a smaller ; `k` if you plan to deal with shorter reads. Also, a shorter value of `k` may; improve sensitivity even more when using selective alignment (enabled via the `--validateMappings` flag). So,; if you are seeing a smaller mapping rate than you might expect, consider building; the index with a slightly smaller `k`. . Quantifying in mapping-based mode; ---------------------------------------. Then, you can quantify any set of reads (say, paired-end reads in files; `reads1.fq` and `reads2.fq`) directly against this index using the Salmon; ``quant`` command as follows:. ::. > ./bin/salmon quant -i transcripts_index -l <LIBTYPE> -1 reads1.fq -2 reads2.fq --validateMappings -o transcripts_quant. If you are using single-end reads, then you pass them to Salmon with ; the ``-r`` flag like:. ::. > ./bin/salmon quant -i transcripts_index -l <LIBTYPE> -r reads.fq --validateMappings -o transcripts_quant. .. note:: Order of command-line parameters. The library type ``-l`` should be specified on the command line **before** the ; read files (i.e. the parameters to ``-1`` and ``-2``, or ``-r``). This is because; the contents of the library type flag is used to determine how the reads should ; be interpreted.; ; You can, of course, pass a number of options to control things such as the; number of threads used or the different cutoffs used for counting reads.; Just as with the alignment-based mode, after Salmon has finished running, there; will be a directory called ``salmon_quant``, that contains a file called; ``quant.sf`` containing the quantification results. """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Providing multiple read files to Salmon; """"""""""""""""""""""""""""""""""""""""""""""""",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:9609,Security,validat,validateMappings,9609," sensitivity. We find that a `k` of 31 seems; to work well for reads of 75bp or longer, but you might consider a smaller ; `k` if you plan to deal with shorter reads. Also, a shorter value of `k` may; improve sensitivity even more when using selective alignment (enabled via the `--validateMappings` flag). So,; if you are seeing a smaller mapping rate than you might expect, consider building; the index with a slightly smaller `k`. . Quantifying in mapping-based mode; ---------------------------------------. Then, you can quantify any set of reads (say, paired-end reads in files; `reads1.fq` and `reads2.fq`) directly against this index using the Salmon; ``quant`` command as follows:. ::. > ./bin/salmon quant -i transcripts_index -l <LIBTYPE> -1 reads1.fq -2 reads2.fq --validateMappings -o transcripts_quant. If you are using single-end reads, then you pass them to Salmon with ; the ``-r`` flag like:. ::. > ./bin/salmon quant -i transcripts_index -l <LIBTYPE> -r reads.fq --validateMappings -o transcripts_quant. .. note:: Order of command-line parameters. The library type ``-l`` should be specified on the command line **before** the ; read files (i.e. the parameters to ``-1`` and ``-2``, or ``-r``). This is because; the contents of the library type flag is used to determine how the reads should ; be interpreted.; ; You can, of course, pass a number of options to control things such as the; number of threads used or the different cutoffs used for counting reads.; Just as with the alignment-based mode, after Salmon has finished running, there; will be a directory called ``salmon_quant``, that contains a file called; ``quant.sf`` containing the quantification results. """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; Providing multiple read files to Salmon; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""". Often, a single library may be split into multiple FASTA/Q files. Also, sometimes one may wish; to quantify multiple replicates or samples together, treating them as if they are one library",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:11413,Security,validat,validateMappings,11413,""""""""""""""""""""""""""". Often, a single library may be split into multiple FASTA/Q files. Also, sometimes one may wish; to quantify multiple replicates or samples together, treating them as if they are one library.; Salmon allows the user to provide a *space-separated* list of read files to all of it's options; that expect input files (i.e. ``-r``, ``-1``, ``-2``). When the input is paired-end reads, the; order of the files in the left and right lists must be the same. There are a number of ways to; provide salmon with multiple read files, and treat these as a single library. For the examples; below, assume we have two replicates ``lib_1`` and ``lib_2``. The left and right reads for; ``lib_1`` are ``lib_1_1.fq`` and ``lib_1_2.fq``, respectively. The left and right reads for; ``lib_2`` are ``lib_2_1.fq`` and ``lib_2_2.fq``, respectively. The following are both valid; ways to input these reads to Salmon::. > salmon quant -i index -l IU -1 lib_1_1.fq lib_2_1.fq -2 lib_1_2.fq lib_2_2.fq --validateMappings -o out. > salmon quant -i index -l IU -1 <(cat lib_1_1.fq lib_2_1.fq) -2 <(cat lib_1_2.fq lib_2_2.fq) --validateMappings -o out. Similarly, both of these approaches can be adopted if the files are gzipped as well::. > salmon quant -i index -l IU -1 lib_1_1.fq.gz lib_2_1.fq.gz -2 lib_1_2.fq.gz lib_2_2.fq.gz --validateMappings -o out. > salmon quant -i index -l IU -1 <(gunzip -c lib_1_1.fq.gz lib_2_1.fq.gz) -2 <(gunzip -c lib_1_2.fq.gz lib_2_2.fq.gz) --validateMappings -o out. In each pair of commands, the first command lets Salmon natively parse the files, while the latter command; creates, on-the-fly, an input stream that consists of the concatenation of both files. Both methods work, and; are acceptable ways to merge the files. The latter method (i.e. process substitution) allows more complex; processing to be done to the reads in the substituted process before they are passed to Salmon as input, and thus,; in some situations, is more versatile. .. note:: Interleaved FASTQ file",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:11534,Security,validat,validateMappings,11534,"y multiple replicates or samples together, treating them as if they are one library.; Salmon allows the user to provide a *space-separated* list of read files to all of it's options; that expect input files (i.e. ``-r``, ``-1``, ``-2``). When the input is paired-end reads, the; order of the files in the left and right lists must be the same. There are a number of ways to; provide salmon with multiple read files, and treat these as a single library. For the examples; below, assume we have two replicates ``lib_1`` and ``lib_2``. The left and right reads for; ``lib_1`` are ``lib_1_1.fq`` and ``lib_1_2.fq``, respectively. The left and right reads for; ``lib_2`` are ``lib_2_1.fq`` and ``lib_2_2.fq``, respectively. The following are both valid; ways to input these reads to Salmon::. > salmon quant -i index -l IU -1 lib_1_1.fq lib_2_1.fq -2 lib_1_2.fq lib_2_2.fq --validateMappings -o out. > salmon quant -i index -l IU -1 <(cat lib_1_1.fq lib_2_1.fq) -2 <(cat lib_1_2.fq lib_2_2.fq) --validateMappings -o out. Similarly, both of these approaches can be adopted if the files are gzipped as well::. > salmon quant -i index -l IU -1 lib_1_1.fq.gz lib_2_1.fq.gz -2 lib_1_2.fq.gz lib_2_2.fq.gz --validateMappings -o out. > salmon quant -i index -l IU -1 <(gunzip -c lib_1_1.fq.gz lib_2_1.fq.gz) -2 <(gunzip -c lib_1_2.fq.gz lib_2_2.fq.gz) --validateMappings -o out. In each pair of commands, the first command lets Salmon natively parse the files, while the latter command; creates, on-the-fly, an input stream that consists of the concatenation of both files. Both methods work, and; are acceptable ways to merge the files. The latter method (i.e. process substitution) allows more complex; processing to be done to the reads in the substituted process before they are passed to Salmon as input, and thus,; in some situations, is more versatile. .. note:: Interleaved FASTQ files. Salmon does not currently have built-in support for interleaved FASTQ files (i.e., paired-end; files where both pairs",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:11740,Security,validat,validateMappings,11740," (i.e. ``-r``, ``-1``, ``-2``). When the input is paired-end reads, the; order of the files in the left and right lists must be the same. There are a number of ways to; provide salmon with multiple read files, and treat these as a single library. For the examples; below, assume we have two replicates ``lib_1`` and ``lib_2``. The left and right reads for; ``lib_1`` are ``lib_1_1.fq`` and ``lib_1_2.fq``, respectively. The left and right reads for; ``lib_2`` are ``lib_2_1.fq`` and ``lib_2_2.fq``, respectively. The following are both valid; ways to input these reads to Salmon::. > salmon quant -i index -l IU -1 lib_1_1.fq lib_2_1.fq -2 lib_1_2.fq lib_2_2.fq --validateMappings -o out. > salmon quant -i index -l IU -1 <(cat lib_1_1.fq lib_2_1.fq) -2 <(cat lib_1_2.fq lib_2_2.fq) --validateMappings -o out. Similarly, both of these approaches can be adopted if the files are gzipped as well::. > salmon quant -i index -l IU -1 lib_1_1.fq.gz lib_2_1.fq.gz -2 lib_1_2.fq.gz lib_2_2.fq.gz --validateMappings -o out. > salmon quant -i index -l IU -1 <(gunzip -c lib_1_1.fq.gz lib_2_1.fq.gz) -2 <(gunzip -c lib_1_2.fq.gz lib_2_2.fq.gz) --validateMappings -o out. In each pair of commands, the first command lets Salmon natively parse the files, while the latter command; creates, on-the-fly, an input stream that consists of the concatenation of both files. Both methods work, and; are acceptable ways to merge the files. The latter method (i.e. process substitution) allows more complex; processing to be done to the reads in the substituted process before they are passed to Salmon as input, and thus,; in some situations, is more versatile. .. note:: Interleaved FASTQ files. Salmon does not currently have built-in support for interleaved FASTQ files (i.e., paired-end; files where both pairs are stored in the same file). We provide a `script <https://github.com/COMBINE-lab/salmon/blob/master/scripts/runner.sh>`_; that can be used to run salmon with interleaved input. However, this script assume",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:11885,Security,validat,validateMappings,11885,"re a number of ways to; provide salmon with multiple read files, and treat these as a single library. For the examples; below, assume we have two replicates ``lib_1`` and ``lib_2``. The left and right reads for; ``lib_1`` are ``lib_1_1.fq`` and ``lib_1_2.fq``, respectively. The left and right reads for; ``lib_2`` are ``lib_2_1.fq`` and ``lib_2_2.fq``, respectively. The following are both valid; ways to input these reads to Salmon::. > salmon quant -i index -l IU -1 lib_1_1.fq lib_2_1.fq -2 lib_1_2.fq lib_2_2.fq --validateMappings -o out. > salmon quant -i index -l IU -1 <(cat lib_1_1.fq lib_2_1.fq) -2 <(cat lib_1_2.fq lib_2_2.fq) --validateMappings -o out. Similarly, both of these approaches can be adopted if the files are gzipped as well::. > salmon quant -i index -l IU -1 lib_1_1.fq.gz lib_2_1.fq.gz -2 lib_1_2.fq.gz lib_2_2.fq.gz --validateMappings -o out. > salmon quant -i index -l IU -1 <(gunzip -c lib_1_1.fq.gz lib_2_1.fq.gz) -2 <(gunzip -c lib_1_2.fq.gz lib_2_2.fq.gz) --validateMappings -o out. In each pair of commands, the first command lets Salmon natively parse the files, while the latter command; creates, on-the-fly, an input stream that consists of the concatenation of both files. Both methods work, and; are acceptable ways to merge the files. The latter method (i.e. process substitution) allows more complex; processing to be done to the reads in the substituted process before they are passed to Salmon as input, and thus,; in some situations, is more versatile. .. note:: Interleaved FASTQ files. Salmon does not currently have built-in support for interleaved FASTQ files (i.e., paired-end; files where both pairs are stored in the same file). We provide a `script <https://github.com/COMBINE-lab/salmon/blob/master/scripts/runner.sh>`_; that can be used to run salmon with interleaved input. However, this script assumes that the; input reads are perfectly synchronized. That is, the input cannot contain any un-paired reads. Quantifying in alignment-based mode; ",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:15608,Security,expose,exposes,15608,"could use a tool like `sam-xlate <https://github.com/mozack/ubu/wiki>`_; to try and convert the genome-coordinate BAM files directly into transcript ; coordinates. This avoids the necessity of having to re-map the reads. However,; we have very limited experience with this tool so far. .. topic:: Multiple alignment files; ; If your alignments for the sample you want to quantify appear in multiple ; .bam/.sam files, then you can simply provide the Salmon ``-a`` parameter ; with a (space-separated) list of these files. Salmon will automatically ; read through these one after the other quantifying transcripts using the ; alignments contained therein. However, it is currently the case that these; separate files must (1) all be of the same library type and (2) all be; aligned with respect to the same reference (i.e. the @SQ records in the ; header sections must be identical). Description of some important options; -------------------------------------. Salmon exposes a number of useful optional command-line parameters to the user.; The particularly important ones are explained here, but you can always run; ``salmon quant -h`` to see them all. """"""""""""""""""""""""""""""""""""""""""""""""; ``--mimicBT2``; """""""""""""""""""""""""""""""""""""""""""""""". This flag is a ""meta-flag"" that sets the parameters related to mapping and; selective alignment to mimic alignment using Bowtie2 (with the flags; ``--no-discordant`` and ``--no-mixed``), but using the default scoring scheme; and allowing both mismatches and indels in alignments. """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""; ``--mimicStrictBT2``; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""". This flag is a ""meta-flag"" that sets the parameters related to mapping and; selective alignment to mimic alignment using Bowtie2 (with the flags suggested; by RSEM), but using the default scoring scheme and allowing both mismatches and; indels in alignments. These setting essentially disallow indels in the resulting; alignments. """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""; ``--meta``; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""". As w",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:23406,Security,validat,validateMappings,23406,"s a truncated Gaussian with; a standard deviation given by ``--fldSD``). """"""""""""""""""""""""""""""""""""""""""; ``--fldSD``; """""""""""""""""""""""""""""""""""""""""". *Note* : This option is only important when running Salmon with single-end reads. Since the empirical fragment length distribution cannot be estimated; from the mappings of single-end reads, the ``--fldSD`` allows the user; to set the expected standard deviation of the fragment length; distribution of the sequencing library. This value will affect the; effective length correction, and hence the estimated effective lengths; of the transcripts and the TPMs. The value passed to ``--fldSD`` will; be used as the standard deviation of the assumed fragment length; distribution (which is modeled as a truncated Gaussian with a mean; given by ``--fldMean``). """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; ``--minScoreFraction``; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""". This value controls the minimum allowed score for a mapping to be considered valid.; It matters only when ``--validateMappings`` has been passed to Salmon. The maximum; possible score for a fragment is ``ms = read_len * ma`` (or ``ms = (left_read_len + right_read_len) * ma``; for paired-end reads). The argument to ``--minScoreFraction`` determines what fraction of the maximum; score ``s`` a mapping must achieve to be potentially retained. For a minimum score fraction of ``f``, only; mappings with a score > ``f * s`` will be kept. Mappings with lower scores will be considered as low-quality,; and will be discarded. It is worth noting that mapping validation uses extension alignment. This means that the read need not; map end-to-end. Instead, the score of the mapping will be the position along the alignment with the; highest score. This is the score which must reach the fraction threshold for the read to be considered; as valid. """"""""""""""""""""""""""""""""""""""""""""""""""; ``--bandwidth``; """""""""""""""""""""""""""""""""""""""""""""""""". This flag (which is only meaningful in conjunction with selective alignment),; sets the bandwidth parameter",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:23950,Security,validat,validation,23950,"ted effective lengths; of the transcripts and the TPMs. The value passed to ``--fldSD`` will; be used as the standard deviation of the assumed fragment length; distribution (which is modeled as a truncated Gaussian with a mean; given by ``--fldMean``). """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; ``--minScoreFraction``; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""". This value controls the minimum allowed score for a mapping to be considered valid.; It matters only when ``--validateMappings`` has been passed to Salmon. The maximum; possible score for a fragment is ``ms = read_len * ma`` (or ``ms = (left_read_len + right_read_len) * ma``; for paired-end reads). The argument to ``--minScoreFraction`` determines what fraction of the maximum; score ``s`` a mapping must achieve to be potentially retained. For a minimum score fraction of ``f``, only; mappings with a score > ``f * s`` will be kept. Mappings with lower scores will be considered as low-quality,; and will be discarded. It is worth noting that mapping validation uses extension alignment. This means that the read need not; map end-to-end. Instead, the score of the mapping will be the position along the alignment with the; highest score. This is the score which must reach the fraction threshold for the read to be considered; as valid. """"""""""""""""""""""""""""""""""""""""""""""""""; ``--bandwidth``; """""""""""""""""""""""""""""""""""""""""""""""""". This flag (which is only meaningful in conjunction with selective alignment),; sets the bandwidth parameter of the relevant calls to ksw2's alignment function.; This determines how wide an area around the diagonal in the DP matrix should be; calculated. """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; ``--maxMMPExtension``; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""". This flag (which should only be used with selective alignment) limits the length; that a mappable prefix of a fragment may be extended before another search along; the fragment is started. Smaller values for this flag can improve the; sensitivity of mapping, but could increase run time. """"""""""""""""""""""""""",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:26740,Security,validat,validateMappings,26740," is the gap length. The value of ``go`` should typically; be larger than that of ``ge``. """"""""""""""""""""""""""""""""""""; ``--ge``; """""""""""""""""""""""""""""""""""". This value should be a positive (typically small) integer. It controls the score; penalty attributed to the extension of a gap in an alignment. The; alignment score computed uses an affine gap penalty, so the penalty of a gap is; ``go + l * ge`` where l is the gap length. The value of ``ge`` should typically; be smaller than that of ``go``. """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; ``--rangeFactorizationBins``; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""". The `range-factorization <https://academic.oup.com/bioinformatics/article/33/14/i142/3953977>`_ feature; allows using a data-driven likelihood factorization, which can improve; quantification accuracy on certain classes of ""difficult"" transcripts.; Currently, this feature interacts best (i.e., yields the most considerable; improvements) when either (1) using alignment-based mode and simultaneously; enabling error modeling with ``--useErrorModel`` or (2) when enabling; ``--validateMappings`` in quasi-mapping-based mode. The argument to this option; is a positive integer ``x``, that determines fidelity of the factorization. The larger; ``x``, the closer the factorization to the un-factorized likelihood, but the larger; the resulting number of equivalence classes. A value of 1 corresponds to salmon's; traditional rich equivalence classes. We recommend 4 as a reasonable parameter; for this option (it is what was used in the range-factorization paper). """"""""""""""""""""""""""""; ``--useEM``; """""""""""""""""""""""""""". Use the ""standard"" EM algorithm to optimize abundance estimates; instead of the variational Bayesian EM algorithm. The details of the VBEM; algorithm can be found in [#salmon]_. While both the standard EM and; the VBEM produce accurate abundance estimates, there are some; trade-offs between the approaches. Specifically, the sparsity of; the VBEM algorithm depends on the prior that is chosen. When; t",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:29561,Security,access,accessed,29561,"ion. The argument to this option is the value you wish to place as the; *per-nucleotide* prior. Additionally, you can modify the behavior to use; a *per-transcript* rather than a *per-nucleotide* prior by passing the flag; ``--perTranscriptPrior`` to Salmon. In this case, whatever value is set; by ``--vbPrior`` will be used as the transcript-level prior, so that the; prior count is no longer dependent on the transcript length. However,; the default behavior of a *per-nucleotide* prior is recommended when; using VB optimization. .. note:: Choosing between EM and VBEM algorithms. As mentioned above, a thorough comparison of all of the benefits and detriments; of the different algorithms is an ongoing area of research. However, preliminary; testing suggests that the sparsity-inducing effect of running the VBEM with a small; prior may lead, in general, to more accurate estimates (the current testing was; performed mostly through simulation). Hence, the VBEM is the default, and the; standard EM algorithm is accessed via the `--useEM` flag. """"""""""""""""""""""""""""""""""""""""""""""""""""""""""; ``--numBootstraps``; """""""""""""""""""""""""""""""""""""""""""""""""""""""""". Salmon has the ability to optionally compute bootstrapped abundance estimates.; This is done by resampling (with replacement) from the counts assigned to; the fragment equivalence classes, and then re-running the optimization procedure,; either the EM or VBEM, for each such sample. The values of these different; bootstraps allows us to assess technical variance in the main abundance estimates; we produce. Such estimates can be useful for downstream (e.g. differential; expression) tools that can make use of such uncertainty estimates. This option; takes a positive integer that dictates the number of bootstrap samples to compute.; The more samples computed, the better the estimates of variance, but the; more computation (and time) required. """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; ``--numGibbsSamples``; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""". Just as with the bootstrap pr",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:4586,Testability,test,tested,4586,"of the transcriptome and a ``.sam`` or ``.bam`` file containing a; set of alignments. .. note:: Read / alignment order. Salmon, like eXpress [#express]_, uses a streaming inference method to perform ; transcript-level quantification. One of the fundamental assumptions ; of such inference methods is that observations (i.e. reads or alignments); are made ""at random"". This means, for example, that alignments should ; **not** be sorted by target or position. If your reads or alignments ; do not appear in a random order with respect to the target transcripts,; please randomize / shuffle them before performing quantification with ; Salmon. .. note:: Number of Threads. The number of threads that Salmon can effectively make use of depends ; upon the mode in which it is being run. In alignment-based mode, the; main bottleneck is in parsing and decompressing the input BAM file.; We make use of the `Staden IO <http://sourceforge.net/projects/staden/files/io_lib/>`_ ; library for SAM/BAM/CRAM I/O (CRAM is, in theory, supported, but has not been; thoroughly tested). This means that multiple threads can be effectively used; to aid in BAM decompression. However, we find that throwing more than a ; few threads at file decompression does not result in increased processing; speed. Thus, alignment-based Salmon will only ever allocate up to 4 threads; to file decompression, with the rest being allocated to quantification.; If these threads are starved, they will sleep (the quantification threads ; do not busy wait), but there is a point beyond which allocating more threads; will not speed up alignment-based quantification. We find that allocating ; 8 --- 12 threads results in the maximum speed, threads allocated above this; limit will likely spend most of their time idle / sleeping. For quasi-mapping-based Salmon, the story is somewhat different.; Generally, performance continues to improve as more threads are made; available. This is because the determination of the potential mapping; ",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:17245,Testability,test,tested,17245,"his flag is a ""meta-flag"" that sets the parameters related to mapping and; selective alignment to mimic alignment using Bowtie2 (with the flags suggested; by RSEM), but using the default scoring scheme and allowing both mismatches and; indels in alignments. These setting essentially disallow indels in the resulting; alignments. """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""; ``--meta``; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""". As with the flags described above, this is a ""meta-flag"" that simply enables some options; that may make more sense when quantifying metagenomic data. Specifically, the ``--meta``; flag sets the following options: . * The abundance optimization is initialized from the uniform distribution (compared to the default of using a weighted combination of the uniform intialization and the abundances learned during the online optimization). * Rich equivalence classes are disabled. Using rich equivalence classes with metagenomic data should not be particularly problematic, but since they have been developed and tested most in the context of bulk RNA-seq quantification, they are currently disabled under this flag. * The EM algorithm is used for abundance optimization instead of the default VBEM optimization. Neither is universally better than the other, but the parameters for the VBEM (e.g. the prior size and type) are set based on typical bulk RNA-seq transcriptome samples, and so may be less appropriate in the metagenomic context. Hence the ``--meta`` flags opts for the basic EM algorithm instead. """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""; ``--recoverOrphans``; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""". This flag (which should only be used in conjunction with selective alignment),; performs orphan ""rescue"" for reads. That is, if mappings are discovered for only; one end of a fragment, or if the mappings for the ends of the fragment don't; fall on the same transcript, then this flag will cause salmon to look upstream; or downstream of the discovered mapping (anchor) for a match for the opposite; end",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:29291,Testability,test,testing,29291,"ill have; a prior count of 0.5 fragments, etc. This behavior can be modified in two; ways. First, the prior itself can be modified via Salmon's ``--vbPrior``; option. The argument to this option is the value you wish to place as the; *per-nucleotide* prior. Additionally, you can modify the behavior to use; a *per-transcript* rather than a *per-nucleotide* prior by passing the flag; ``--perTranscriptPrior`` to Salmon. In this case, whatever value is set; by ``--vbPrior`` will be used as the transcript-level prior, so that the; prior count is no longer dependent on the transcript length. However,; the default behavior of a *per-nucleotide* prior is recommended when; using VB optimization. .. note:: Choosing between EM and VBEM algorithms. As mentioned above, a thorough comparison of all of the benefits and detriments; of the different algorithms is an ongoing area of research. However, preliminary; testing suggests that the sparsity-inducing effect of running the VBEM with a small; prior may lead, in general, to more accurate estimates (the current testing was; performed mostly through simulation). Hence, the VBEM is the default, and the; standard EM algorithm is accessed via the `--useEM` flag. """"""""""""""""""""""""""""""""""""""""""""""""""""""""""; ``--numBootstraps``; """""""""""""""""""""""""""""""""""""""""""""""""""""""""". Salmon has the ability to optionally compute bootstrapped abundance estimates.; This is done by resampling (with replacement) from the counts assigned to; the fragment equivalence classes, and then re-running the optimization procedure,; either the EM or VBEM, for each such sample. The values of these different; bootstraps allows us to assess technical variance in the main abundance estimates; we produce. Such estimates can be useful for downstream (e.g. differential; expression) tools that can make use of such uncertainty estimates. This option; takes a positive integer that dictates the number of bootstrap samples to compute.; The more samples computed, the better the estimates of variance, bu",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:29444,Testability,test,testing,29444,"ill have; a prior count of 0.5 fragments, etc. This behavior can be modified in two; ways. First, the prior itself can be modified via Salmon's ``--vbPrior``; option. The argument to this option is the value you wish to place as the; *per-nucleotide* prior. Additionally, you can modify the behavior to use; a *per-transcript* rather than a *per-nucleotide* prior by passing the flag; ``--perTranscriptPrior`` to Salmon. In this case, whatever value is set; by ``--vbPrior`` will be used as the transcript-level prior, so that the; prior count is no longer dependent on the transcript length. However,; the default behavior of a *per-nucleotide* prior is recommended when; using VB optimization. .. note:: Choosing between EM and VBEM algorithms. As mentioned above, a thorough comparison of all of the benefits and detriments; of the different algorithms is an ongoing area of research. However, preliminary; testing suggests that the sparsity-inducing effect of running the VBEM with a small; prior may lead, in general, to more accurate estimates (the current testing was; performed mostly through simulation). Hence, the VBEM is the default, and the; standard EM algorithm is accessed via the `--useEM` flag. """"""""""""""""""""""""""""""""""""""""""""""""""""""""""; ``--numBootstraps``; """""""""""""""""""""""""""""""""""""""""""""""""""""""""". Salmon has the ability to optionally compute bootstrapped abundance estimates.; This is done by resampling (with replacement) from the counts assigned to; the fragment equivalence classes, and then re-running the optimization procedure,; either the EM or VBEM, for each such sample. The values of these different; bootstraps allows us to assess technical variance in the main abundance estimates; we produce. Such estimates can be useful for downstream (e.g. differential; expression) tools that can make use of such uncertainty estimates. This option; takes a positive integer that dictates the number of bootstrap samples to compute.; The more samples computed, the better the estimates of variance, bu",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:35022,Testability,test,testing,35022,"valuation of the GC content of; arbitrary fragments, Salmon pre-computes and stores the cumulative GC; count for each transcript. This requires an extra 4-bytes per; nucleotide. While this extra memory usage should normally be minor,; it can nonetheless be controlled with the ``--reduceGCMemory`` option.; This option replaces the per-nucleotide GC count with a rank-select; capable bit vector, reducing the memory overhead from 4-bytes per; nucleotide to ~1.25 bits, while being only marginally slower). """"""""""""""""""""""""""""""""""""""""""; ``--posBias``; """""""""""""""""""""""""""""""""""""""""". Passing the ``--posBias`` flag to Salmon will enable modeling of a; position-specific fragment start distribution. This is meant to model; non-uniform coverage biases that are sometimes present in RNA-seq data; (e.g. 5' or 3' positional bias). Currently, a small and fixed number; of models are learned for different length classes of transcripts, as; is done in Roberts et al. [#roberts]_. *Note*: The positional bias; model is relatively new, and is still undergoing testing. It replaces; the previous `--useFSPD` option, which is now deprecated. This; feature should be considered as *experimental* in the current release. """"""""""""""""""""""""""""""""""""""""""""""""""""""""""; ``--biasSpeedSamp``; """""""""""""""""""""""""""""""""""""""""""""""""""""""""". When evaluating the bias models (the GC-fragment model specifically),; Salmon must consider the probability of generating a fragment of every; possible length (with a non-trivial probability) from every position; on every transcript. This results in a process that is quadratic in; the length of the transcriptome --- though each evaluation itself is; efficient and the process is highly parallelized. It is possible to speed this process up by a multiplicative factor by; considering only every *i*:sup:`th` fragment length, and interpolating; the intermediate results. The ``--biasSpeedSamp`` option allows the; user to set this sampling factor. Larger values speed up effective; length correction, but may decrease the fid",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:2824,Usability,simpl,simply,2824," salmon with different mapping and alignment; strategies is covered in detail in the paper `Alignment and mapping methodology influence transcript abundance estimation <https://genomebiology.biomedcentral.com/articles/10.1186/s13059-020-02151-8>`_. The use of selective alignment implies the use of range factorization, as mapping; scores become very meaningful with this option. Selective alignment can; improve the accuracy, sometimes considerably, over the faster, but; less-precise mapping algorithm that was previously used. Also, there are a number of ; options and flags that allow the user to control details about how the scoring is ; carried out, including setting match, mismatch, and gap scores, and choosing the minimum ; score below which an alignment will be considered invalid, and therefore not used for the; purposes of quantification. . The **alignment**-based mode of Salmon does not require indexing. Rather, you can ; simply provide Salmon with a FASTA file of the transcripts and a SAM/BAM file; containing the alignments you wish to use for quantification. Salmon is, and will continue to be, `freely and actively supported on a best-effort basis <https://oceangenomics.com/about/#open>`_.; If you are in need of industrial-grade technical support, please consider the options at `oceangenomics.com/support <https://oceangenomics.com/support>`_. Using Salmon; ------------. As mentioned above, there are two ""modes"" of operation for Salmon. The first,; requires you to build an index for the transcriptome, but then subsequently; processes reads directly. The second mode simply requires you to provide a; FASTA file of the transcriptome and a ``.sam`` or ``.bam`` file containing a; set of alignments. .. note:: Read / alignment order. Salmon, like eXpress [#express]_, uses a streaming inference method to perform ; transcript-level quantification. One of the fundamental assumptions ; of such inference methods is that observations (i.e. reads or alignments); are made ""at r",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:3480,Usability,simpl,simply,3480,"w the scoring is ; carried out, including setting match, mismatch, and gap scores, and choosing the minimum ; score below which an alignment will be considered invalid, and therefore not used for the; purposes of quantification. . The **alignment**-based mode of Salmon does not require indexing. Rather, you can ; simply provide Salmon with a FASTA file of the transcripts and a SAM/BAM file; containing the alignments you wish to use for quantification. Salmon is, and will continue to be, `freely and actively supported on a best-effort basis <https://oceangenomics.com/about/#open>`_.; If you are in need of industrial-grade technical support, please consider the options at `oceangenomics.com/support <https://oceangenomics.com/support>`_. Using Salmon; ------------. As mentioned above, there are two ""modes"" of operation for Salmon. The first,; requires you to build an index for the transcriptome, but then subsequently; processes reads directly. The second mode simply requires you to provide a; FASTA file of the transcriptome and a ``.sam`` or ``.bam`` file containing a; set of alignments. .. note:: Read / alignment order. Salmon, like eXpress [#express]_, uses a streaming inference method to perform ; transcript-level quantification. One of the fundamental assumptions ; of such inference methods is that observations (i.e. reads or alignments); are made ""at random"". This means, for example, that alignments should ; **not** be sorted by target or position. If your reads or alignments ; do not appear in a random order with respect to the target transcripts,; please randomize / shuffle them before performing quantification with ; Salmon. .. note:: Number of Threads. The number of threads that Salmon can effectively make use of depends ; upon the mode in which it is being run. In alignment-based mode, the; main bottleneck is in parsing and decompressing the input BAM file.; We make use of the `Staden IO <http://sourceforge.net/projects/staden/files/io_lib/>`_ ; library for S",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:7006,Usability,simpl,simple,7006,"------------------------------------------. One of the novel and innovative features of Salmon is its ability to accurately; quantify transcripts without having previously aligned the reads using its fast,; built-in selective-alignment mapping algorithm. Further details about the selective alignment algorithm can be; found `here <https://www.biorxiv.org/content/10.1101/657874v1>`_. If you want to use Salmon in mapping-based mode, then you first have to build a; salmon index for your transcriptome. Assume that ``transcripts.fa`` contains the; set of transcripts you wish to quantify. We generally recommend that you build a; *decoy-aware* transcriptome file. . There are two options for generating a decoy-aware transcriptome:. - The first is to compute a set of decoy sequences by mapping the annotated transcripts you wish to index; against a hard-masked version of the organism's genome. This can be done with e.g. ; `MashMap2 <https://github.com/marbl/MashMap>`_, and we provide some simple scripts to ; greatly simplify this whole process. Specifically, you can use the ; `generateDecoyTranscriptome.sh <https://github.com/COMBINE-lab/SalmonTools/blob/master/scripts/generateDecoyTranscriptome.sh>`_; script, whose instructions you can find `in this README <https://github.com/COMBINE-lab/SalmonTools/blob/master/README.md>`_. . - The second is to use the entire genome of the organism as the decoy sequence. This can be ; done by concatenating the genome to the end of the transcriptome you want to index and populating ; the `decoys.txt` file with the chromosome names. Detailed instructions on how to prepare this ; type of decoy sequence is available `here <https://combine-lab.github.io/alevin-tutorial/2019/selective-alignment/>`_.; This scheme provides a more comprehensive set of decoys, but, obviously, requires considerably more memory to build the index. Finally, pre-built versions of both the *partial* decoy and *full* decoy (i.e. using the whole genome) salmon indices ; for ",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:7034,Usability,simpl,simplify,7034,"------------------------------------------. One of the novel and innovative features of Salmon is its ability to accurately; quantify transcripts without having previously aligned the reads using its fast,; built-in selective-alignment mapping algorithm. Further details about the selective alignment algorithm can be; found `here <https://www.biorxiv.org/content/10.1101/657874v1>`_. If you want to use Salmon in mapping-based mode, then you first have to build a; salmon index for your transcriptome. Assume that ``transcripts.fa`` contains the; set of transcripts you wish to quantify. We generally recommend that you build a; *decoy-aware* transcriptome file. . There are two options for generating a decoy-aware transcriptome:. - The first is to compute a set of decoy sequences by mapping the annotated transcripts you wish to index; against a hard-masked version of the organism's genome. This can be done with e.g. ; `MashMap2 <https://github.com/marbl/MashMap>`_, and we provide some simple scripts to ; greatly simplify this whole process. Specifically, you can use the ; `generateDecoyTranscriptome.sh <https://github.com/COMBINE-lab/SalmonTools/blob/master/scripts/generateDecoyTranscriptome.sh>`_; script, whose instructions you can find `in this README <https://github.com/COMBINE-lab/SalmonTools/blob/master/README.md>`_. . - The second is to use the entire genome of the organism as the decoy sequence. This can be ; done by concatenating the genome to the end of the transcriptome you want to index and populating ; the `decoys.txt` file with the chromosome names. Detailed instructions on how to prepare this ; type of decoy sequence is available `here <https://combine-lab.github.io/alevin-tutorial/2019/selective-alignment/>`_.; This scheme provides a more comprehensive set of decoys, but, obviously, requires considerably more memory to build the index. Finally, pre-built versions of both the *partial* decoy and *full* decoy (i.e. using the whole genome) salmon indices ; for ",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:15071,Usability,simpl,simply,15071,"an to the genome (as does, e.g. Cufflinks). If you; have reads that have already been aligned to the genome, there are; currently 3 options for converting them for use with Salmon. First, you; could convert the SAM/BAM file to a FAST{A/Q} file and then use the; lightweight-alignment-based mode of Salmon described below. Second, given the converted; FASTA{A/Q} file, you could re-align these converted reads directly to the; transcripts with your favorite aligner and run Salmon in alignment-based; mode as described above. Third, you could use a tool like `sam-xlate <https://github.com/mozack/ubu/wiki>`_; to try and convert the genome-coordinate BAM files directly into transcript ; coordinates. This avoids the necessity of having to re-map the reads. However,; we have very limited experience with this tool so far. .. topic:: Multiple alignment files; ; If your alignments for the sample you want to quantify appear in multiple ; .bam/.sam files, then you can simply provide the Salmon ``-a`` parameter ; with a (space-separated) list of these files. Salmon will automatically ; read through these one after the other quantifying transcripts using the ; alignments contained therein. However, it is currently the case that these; separate files must (1) all be of the same library type and (2) all be; aligned with respect to the same reference (i.e. the @SQ records in the ; header sections must be identical). Description of some important options; -------------------------------------. Salmon exposes a number of useful optional command-line parameters to the user.; The particularly important ones are explained here, but you can always run; ``salmon quant -h`` to see them all. """"""""""""""""""""""""""""""""""""""""""""""""; ``--mimicBT2``; """""""""""""""""""""""""""""""""""""""""""""""". This flag is a ""meta-flag"" that sets the parameters related to mapping and; selective alignment to mimic alignment using Bowtie2 (with the flags; ``--no-discordant`` and ``--no-mixed``), but using the default scoring scheme; and allowing bot",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:16698,Usability,simpl,simply,16698,"nes are explained here, but you can always run; ``salmon quant -h`` to see them all. """"""""""""""""""""""""""""""""""""""""""""""""; ``--mimicBT2``; """""""""""""""""""""""""""""""""""""""""""""""". This flag is a ""meta-flag"" that sets the parameters related to mapping and; selective alignment to mimic alignment using Bowtie2 (with the flags; ``--no-discordant`` and ``--no-mixed``), but using the default scoring scheme; and allowing both mismatches and indels in alignments. """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""; ``--mimicStrictBT2``; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""". This flag is a ""meta-flag"" that sets the parameters related to mapping and; selective alignment to mimic alignment using Bowtie2 (with the flags suggested; by RSEM), but using the default scoring scheme and allowing both mismatches and; indels in alignments. These setting essentially disallow indels in the resulting; alignments. """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""; ``--meta``; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""". As with the flags described above, this is a ""meta-flag"" that simply enables some options; that may make more sense when quantifying metagenomic data. Specifically, the ``--meta``; flag sets the following options: . * The abundance optimization is initialized from the uniform distribution (compared to the default of using a weighted combination of the uniform intialization and the abundances learned during the online optimization). * Rich equivalence classes are disabled. Using rich equivalence classes with metagenomic data should not be particularly problematic, but since they have been developed and tested most in the context of bulk RNA-seq quantification, they are currently disabled under this flag. * The EM algorithm is used for abundance optimization instead of the default VBEM optimization. Neither is universally better than the other, but the parameters for the VBEM (e.g. the prior size and type) are set based on typical bulk RNA-seq transcriptome samples, and so may be less appropriate in the metagenomic context. Hence the ``--meta`` flags opts for t",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:17031,Usability,learn,learned,17031," mimic alignment using Bowtie2 (with the flags; ``--no-discordant`` and ``--no-mixed``), but using the default scoring scheme; and allowing both mismatches and indels in alignments. """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""; ``--mimicStrictBT2``; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""". This flag is a ""meta-flag"" that sets the parameters related to mapping and; selective alignment to mimic alignment using Bowtie2 (with the flags suggested; by RSEM), but using the default scoring scheme and allowing both mismatches and; indels in alignments. These setting essentially disallow indels in the resulting; alignments. """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""; ``--meta``; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""". As with the flags described above, this is a ""meta-flag"" that simply enables some options; that may make more sense when quantifying metagenomic data. Specifically, the ``--meta``; flag sets the following options: . * The abundance optimization is initialized from the uniform distribution (compared to the default of using a weighted combination of the uniform intialization and the abundances learned during the online optimization). * Rich equivalence classes are disabled. Using rich equivalence classes with metagenomic data should not be particularly problematic, but since they have been developed and tested most in the context of bulk RNA-seq quantification, they are currently disabled under this flag. * The EM algorithm is used for abundance optimization instead of the default VBEM optimization. Neither is universally better than the other, but the parameters for the VBEM (e.g. the prior size and type) are set based on typical bulk RNA-seq transcriptome samples, and so may be less appropriate in the metagenomic context. Hence the ``--meta`` flags opts for the basic EM algorithm instead. """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""; ``--recoverOrphans``; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""". This flag (which should only be used in conjunction with selective alignment),; performs orphan ""rescue"" for reads. That is, if mappi",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:31200,Usability,learn,learn,31200,"ty estimates. This option; takes a positive integer that dictates the number of bootstrap samples to compute.; The more samples computed, the better the estimates of variance, but the; more computation (and time) required. """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; ``--numGibbsSamples``; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""". Just as with the bootstrap procedure above, this option produces samples that allow; us to estimate the variance in abundance estimates. However, in this case the; samples are generated using posterior Gibbs sampling over the fragment equivalence; classes rather than bootstrapping. We are currently analyzing these different approaches; to assess the potential trade-offs in time / accuracy. The ``--numBootstraps`` and; ``--numGibbsSamples`` options are mutually exclusive (i.e. in a given run, you must; set at most one of these options to a positive integer.). """"""""""""""""""""""""""""""""""""""""""; ``--seqBias``; """""""""""""""""""""""""""""""""""""""""". Passing the ``--seqBias`` flag to Salmon will enable it to learn and; correct for sequence-specific biases in the input data. Specifically,; this model will attempt to correct for random hexamer priming bias,; which results in the preferential sequencing of fragments starting; with certain nucleotide motifs. By default, Salmon learns the; sequence-specific bias parameters using 1,000,000 reads from the; beginning of the input. If you wish to change the number of samples; from which the model is learned, you can use the ``--numBiasSamples``; parameter. Salmon uses a variable-length Markov Model; (VLMM) to model the sequence specific biases at both the 5' and 3' end; of sequenced fragments. This methodology generally follows that of; Roberts et al. [#roberts]_, though some details of the VLMM differ. *Note*: This sequence-specific bias model is substantially different; from the bias-correction methodology that was used in Salmon versions; prior to 0.6.0. This model specifically accounts for; sequence-specific bias, and should not be prone to the ov",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:31470,Usability,learn,learns,31470,""""""". Just as with the bootstrap procedure above, this option produces samples that allow; us to estimate the variance in abundance estimates. However, in this case the; samples are generated using posterior Gibbs sampling over the fragment equivalence; classes rather than bootstrapping. We are currently analyzing these different approaches; to assess the potential trade-offs in time / accuracy. The ``--numBootstraps`` and; ``--numGibbsSamples`` options are mutually exclusive (i.e. in a given run, you must; set at most one of these options to a positive integer.). """"""""""""""""""""""""""""""""""""""""""; ``--seqBias``; """""""""""""""""""""""""""""""""""""""""". Passing the ``--seqBias`` flag to Salmon will enable it to learn and; correct for sequence-specific biases in the input data. Specifically,; this model will attempt to correct for random hexamer priming bias,; which results in the preferential sequencing of fragments starting; with certain nucleotide motifs. By default, Salmon learns the; sequence-specific bias parameters using 1,000,000 reads from the; beginning of the input. If you wish to change the number of samples; from which the model is learned, you can use the ``--numBiasSamples``; parameter. Salmon uses a variable-length Markov Model; (VLMM) to model the sequence specific biases at both the 5' and 3' end; of sequenced fragments. This methodology generally follows that of; Roberts et al. [#roberts]_, though some details of the VLMM differ. *Note*: This sequence-specific bias model is substantially different; from the bias-correction methodology that was used in Salmon versions; prior to 0.6.0. This model specifically accounts for; sequence-specific bias, and should not be prone to the over-fitting; problem that was sometimes observed using the previous bias-correction; methodology. """"""""""""""""""""""""""""""""""""""""""; ``--gcBias``; """""""""""""""""""""""""""""""""""""""""". Passing the ``--gcBias`` flag to Salmon will enable it to learn and; correct for fragment-level GC biases in the input data. Specifically,; this model ",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:31641,Usability,learn,learned,31641,"ndance estimates. However, in this case the; samples are generated using posterior Gibbs sampling over the fragment equivalence; classes rather than bootstrapping. We are currently analyzing these different approaches; to assess the potential trade-offs in time / accuracy. The ``--numBootstraps`` and; ``--numGibbsSamples`` options are mutually exclusive (i.e. in a given run, you must; set at most one of these options to a positive integer.). """"""""""""""""""""""""""""""""""""""""""; ``--seqBias``; """""""""""""""""""""""""""""""""""""""""". Passing the ``--seqBias`` flag to Salmon will enable it to learn and; correct for sequence-specific biases in the input data. Specifically,; this model will attempt to correct for random hexamer priming bias,; which results in the preferential sequencing of fragments starting; with certain nucleotide motifs. By default, Salmon learns the; sequence-specific bias parameters using 1,000,000 reads from the; beginning of the input. If you wish to change the number of samples; from which the model is learned, you can use the ``--numBiasSamples``; parameter. Salmon uses a variable-length Markov Model; (VLMM) to model the sequence specific biases at both the 5' and 3' end; of sequenced fragments. This methodology generally follows that of; Roberts et al. [#roberts]_, though some details of the VLMM differ. *Note*: This sequence-specific bias model is substantially different; from the bias-correction methodology that was used in Salmon versions; prior to 0.6.0. This model specifically accounts for; sequence-specific bias, and should not be prone to the over-fitting; problem that was sometimes observed using the previous bias-correction; methodology. """"""""""""""""""""""""""""""""""""""""""; ``--gcBias``; """""""""""""""""""""""""""""""""""""""""". Passing the ``--gcBias`` flag to Salmon will enable it to learn and; correct for fragment-level GC biases in the input data. Specifically,; this model will attempt to correct for biases in how likely a sequence; is to be observed based on its internal GC content. . You can u",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:32418,Usability,learn,learn,32418,"th certain nucleotide motifs. By default, Salmon learns the; sequence-specific bias parameters using 1,000,000 reads from the; beginning of the input. If you wish to change the number of samples; from which the model is learned, you can use the ``--numBiasSamples``; parameter. Salmon uses a variable-length Markov Model; (VLMM) to model the sequence specific biases at both the 5' and 3' end; of sequenced fragments. This methodology generally follows that of; Roberts et al. [#roberts]_, though some details of the VLMM differ. *Note*: This sequence-specific bias model is substantially different; from the bias-correction methodology that was used in Salmon versions; prior to 0.6.0. This model specifically accounts for; sequence-specific bias, and should not be prone to the over-fitting; problem that was sometimes observed using the previous bias-correction; methodology. """"""""""""""""""""""""""""""""""""""""""; ``--gcBias``; """""""""""""""""""""""""""""""""""""""""". Passing the ``--gcBias`` flag to Salmon will enable it to learn and; correct for fragment-level GC biases in the input data. Specifically,; this model will attempt to correct for biases in how likely a sequence; is to be observed based on its internal GC content. . You can use the FASTQC software followed by ; `MultiQC with transcriptome GC distributions <http://multiqc.info/docs/#theoretical-gc-content>`_; to check if your samples exhibit strong GC bias, i.e.; under-representation of some sub-sequences of the transcriptome. If they do, ; we obviously recommend using the ``--gcBias`` flag. Or you can simply run Salmon with ; ``--gcBias`` in any case, as it does not impair quantification for samples ; without GC bias, it just takes a few more minutes per sample. For samples ; with moderate to high GC bias, correction for this bias at the fragment level ; has been shown to reduce isoform quantification errors [#alpine]_ [#salmon]_. This bias is distinct from the primer biases learned with the ``--seqBias`` option.; Though these biases are distinct,",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:32968,Usability,simpl,simply,32968,"on methodology that was used in Salmon versions; prior to 0.6.0. This model specifically accounts for; sequence-specific bias, and should not be prone to the over-fitting; problem that was sometimes observed using the previous bias-correction; methodology. """"""""""""""""""""""""""""""""""""""""""; ``--gcBias``; """""""""""""""""""""""""""""""""""""""""". Passing the ``--gcBias`` flag to Salmon will enable it to learn and; correct for fragment-level GC biases in the input data. Specifically,; this model will attempt to correct for biases in how likely a sequence; is to be observed based on its internal GC content. . You can use the FASTQC software followed by ; `MultiQC with transcriptome GC distributions <http://multiqc.info/docs/#theoretical-gc-content>`_; to check if your samples exhibit strong GC bias, i.e.; under-representation of some sub-sequences of the transcriptome. If they do, ; we obviously recommend using the ``--gcBias`` flag. Or you can simply run Salmon with ; ``--gcBias`` in any case, as it does not impair quantification for samples ; without GC bias, it just takes a few more minutes per sample. For samples ; with moderate to high GC bias, correction for this bias at the fragment level ; has been shown to reduce isoform quantification errors [#alpine]_ [#salmon]_. This bias is distinct from the primer biases learned with the ``--seqBias`` option.; Though these biases are distinct, they are not completely independent.; When both ``--seqBias`` and ``--gcBias`` are enabled, Salmon will; learn a conditional fragment-GC bias model. By default, Salmon will; learn 3 different fragment-GC bias models based on the GC content of; the fragment start and end contexts, though this number of conditional; models can be changed with the (*hidden*) option; ``--conditionalGCBins``. Likewise, the number of distinct fragment GC; bins used to model the GC bias can be changed with the (*hidden*); option ``--numGCBins``. *Note* : In order to speed up the evaluation of the GC content of; arbitrary fragments, Salmo",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:33349,Usability,learn,learned,33349,""""""""""""""""""""""""""". Passing the ``--gcBias`` flag to Salmon will enable it to learn and; correct for fragment-level GC biases in the input data. Specifically,; this model will attempt to correct for biases in how likely a sequence; is to be observed based on its internal GC content. . You can use the FASTQC software followed by ; `MultiQC with transcriptome GC distributions <http://multiqc.info/docs/#theoretical-gc-content>`_; to check if your samples exhibit strong GC bias, i.e.; under-representation of some sub-sequences of the transcriptome. If they do, ; we obviously recommend using the ``--gcBias`` flag. Or you can simply run Salmon with ; ``--gcBias`` in any case, as it does not impair quantification for samples ; without GC bias, it just takes a few more minutes per sample. For samples ; with moderate to high GC bias, correction for this bias at the fragment level ; has been shown to reduce isoform quantification errors [#alpine]_ [#salmon]_. This bias is distinct from the primer biases learned with the ``--seqBias`` option.; Though these biases are distinct, they are not completely independent.; When both ``--seqBias`` and ``--gcBias`` are enabled, Salmon will; learn a conditional fragment-GC bias model. By default, Salmon will; learn 3 different fragment-GC bias models based on the GC content of; the fragment start and end contexts, though this number of conditional; models can be changed with the (*hidden*) option; ``--conditionalGCBins``. Likewise, the number of distinct fragment GC; bins used to model the GC bias can be changed with the (*hidden*); option ``--numGCBins``. *Note* : In order to speed up the evaluation of the GC content of; arbitrary fragments, Salmon pre-computes and stores the cumulative GC; count for each transcript. This requires an extra 4-bytes per; nucleotide. While this extra memory usage should normally be minor,; it can nonetheless be controlled with the ``--reduceGCMemory`` option.; This option replaces the per-nucleotide GC count wit",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:33528,Usability,learn,learn,33528," attempt to correct for biases in how likely a sequence; is to be observed based on its internal GC content. . You can use the FASTQC software followed by ; `MultiQC with transcriptome GC distributions <http://multiqc.info/docs/#theoretical-gc-content>`_; to check if your samples exhibit strong GC bias, i.e.; under-representation of some sub-sequences of the transcriptome. If they do, ; we obviously recommend using the ``--gcBias`` flag. Or you can simply run Salmon with ; ``--gcBias`` in any case, as it does not impair quantification for samples ; without GC bias, it just takes a few more minutes per sample. For samples ; with moderate to high GC bias, correction for this bias at the fragment level ; has been shown to reduce isoform quantification errors [#alpine]_ [#salmon]_. This bias is distinct from the primer biases learned with the ``--seqBias`` option.; Though these biases are distinct, they are not completely independent.; When both ``--seqBias`` and ``--gcBias`` are enabled, Salmon will; learn a conditional fragment-GC bias model. By default, Salmon will; learn 3 different fragment-GC bias models based on the GC content of; the fragment start and end contexts, though this number of conditional; models can be changed with the (*hidden*) option; ``--conditionalGCBins``. Likewise, the number of distinct fragment GC; bins used to model the GC bias can be changed with the (*hidden*); option ``--numGCBins``. *Note* : In order to speed up the evaluation of the GC content of; arbitrary fragments, Salmon pre-computes and stores the cumulative GC; count for each transcript. This requires an extra 4-bytes per; nucleotide. While this extra memory usage should normally be minor,; it can nonetheless be controlled with the ``--reduceGCMemory`` option.; This option replaces the per-nucleotide GC count with a rank-select; capable bit vector, reducing the memory overhead from 4-bytes per; nucleotide to ~1.25 bits, while being only marginally slower). """"""""""""""""""""""""""""""""""""""""""; ",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:33597,Usability,learn,learn,33597,"riptome GC distributions <http://multiqc.info/docs/#theoretical-gc-content>`_; to check if your samples exhibit strong GC bias, i.e.; under-representation of some sub-sequences of the transcriptome. If they do, ; we obviously recommend using the ``--gcBias`` flag. Or you can simply run Salmon with ; ``--gcBias`` in any case, as it does not impair quantification for samples ; without GC bias, it just takes a few more minutes per sample. For samples ; with moderate to high GC bias, correction for this bias at the fragment level ; has been shown to reduce isoform quantification errors [#alpine]_ [#salmon]_. This bias is distinct from the primer biases learned with the ``--seqBias`` option.; Though these biases are distinct, they are not completely independent.; When both ``--seqBias`` and ``--gcBias`` are enabled, Salmon will; learn a conditional fragment-GC bias model. By default, Salmon will; learn 3 different fragment-GC bias models based on the GC content of; the fragment start and end contexts, though this number of conditional; models can be changed with the (*hidden*) option; ``--conditionalGCBins``. Likewise, the number of distinct fragment GC; bins used to model the GC bias can be changed with the (*hidden*); option ``--numGCBins``. *Note* : In order to speed up the evaluation of the GC content of; arbitrary fragments, Salmon pre-computes and stores the cumulative GC; count for each transcript. This requires an extra 4-bytes per; nucleotide. While this extra memory usage should normally be minor,; it can nonetheless be controlled with the ``--reduceGCMemory`` option.; This option replaces the per-nucleotide GC count with a rank-select; capable bit vector, reducing the memory overhead from 4-bytes per; nucleotide to ~1.25 bits, while being only marginally slower). """"""""""""""""""""""""""""""""""""""""""; ``--posBias``; """""""""""""""""""""""""""""""""""""""""". Passing the ``--posBias`` flag to Salmon will enable modeling of a; position-specific fragment start distribution. This is meant to model; ",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:34848,Usability,learn,learned,34848,"s used to model the GC bias can be changed with the (*hidden*); option ``--numGCBins``. *Note* : In order to speed up the evaluation of the GC content of; arbitrary fragments, Salmon pre-computes and stores the cumulative GC; count for each transcript. This requires an extra 4-bytes per; nucleotide. While this extra memory usage should normally be minor,; it can nonetheless be controlled with the ``--reduceGCMemory`` option.; This option replaces the per-nucleotide GC count with a rank-select; capable bit vector, reducing the memory overhead from 4-bytes per; nucleotide to ~1.25 bits, while being only marginally slower). """"""""""""""""""""""""""""""""""""""""""; ``--posBias``; """""""""""""""""""""""""""""""""""""""""". Passing the ``--posBias`` flag to Salmon will enable modeling of a; position-specific fragment start distribution. This is meant to model; non-uniform coverage biases that are sometimes present in RNA-seq data; (e.g. 5' or 3' positional bias). Currently, a small and fixed number; of models are learned for different length classes of transcripts, as; is done in Roberts et al. [#roberts]_. *Note*: The positional bias; model is relatively new, and is still undergoing testing. It replaces; the previous `--useFSPD` option, which is now deprecated. This; feature should be considered as *experimental* in the current release. """"""""""""""""""""""""""""""""""""""""""""""""""""""""""; ``--biasSpeedSamp``; """""""""""""""""""""""""""""""""""""""""""""""""""""""""". When evaluating the bias models (the GC-fragment model specifically),; Salmon must consider the probability of generating a fragment of every; possible length (with a non-trivial probability) from every position; on every transcript. This results in a process that is quadratic in; the length of the transcriptome --- though each evaluation itself is; efficient and the process is highly parallelized. It is possible to speed this process up by a multiplicative factor by; considering only every *i*:sup:`th` fragment length, and interpolating; the intermediate results. The ``--biasSpeedSamp`` option",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:36793,Usability,simpl,simple,36793,"ength, and interpolating; the intermediate results. The ``--biasSpeedSamp`` option allows the; user to set this sampling factor. Larger values speed up effective; length correction, but may decrease the fidelity of bias modeling.; However, reasonably small values (e.g. 10 or less) should have only a; minor effect on the computed effective lengths, and can considerably; speed up effective length correction on large transcriptomes. The; default value for ``--biasSpeedSamp`` is 5. """"""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""; ``--writeUnmappedNames``; """""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""""". Passing the ``--writeUnmappedNames`` flag to Salmon will tell Salmon to; write out the names of reads (or mates in paired-end reads) that do not; map to the transcriptome. When mapping paired-end reads, the entire; fragment (both ends of the pair) are identified by the name of the first; read (i.e. the read appearing in the ``_1`` file). Each line of the unmapped; reads file contains the name of the unmapped read followed by a simple flag; that designates *how* the read failed to map completely. If fragments are ; aligned against a decoy-aware index, then fragments that are confidently ; assigned as decoys are written in this file followed by the ``d`` (decoy); flag. Apart from the decoy flag, for single-end; reads, the only valid flag is ``u`` (unmapped). However, for paired-end; reads, there are a number of different possibilities, outlined below:. ::; ; u = The entire pair was unmapped. No mappings were found for either the left or right read.; m1 = Left orphan (mappings were found for the left (i.e. first) read, but not the right).; m2 = Right orphan (mappings were found for the right read, but not the left).; m12 = Left and right orphans. Both the left and right read mapped, but never to the same transcript. . By reading through the file of unmapped reads and selecting the appropriate; sequences from the input FASTA/Q files, you can build an ""unmapped"" file that; can then be used to investiga",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:40038,Usability,simpl,simply,40038,"st do so ; with the syntax ``--writeMappings=<outfile>`` rather than the synatx ; ``--writeMappings <outfile>``. This is due to a limitation of the ; parser in how the latter could be interpreted. .. note:: Compatible mappings. The mapping information is computed and written *before* library; type compatibility checks take place, thus the mapping file will; contain information about all mappings of the reads considered by; Salmon, even those that may later be filtered out due to; incompatibility with the library type.; ; What's this ``LIBTYPE``?; ------------------------. Salmon, has the user provide a description of the type of sequencing; library from which the reads come, and this contains information about; e.g. the relative orientation of paired-end reads. As of version; 0.7.0, Salmon also has the ability to automatically infer (i.e. guess); the library type based on how the first few thousand reads map to the; transcriptome. To allow Salmon to automatically infer the library; type, simply provide ``-l A`` or ``--libType A`` to Salmon. Even if you; allow Salmon to infer the library type for you, you should still read; the section below, so that you can interpret how Salmon reports the; library type it discovers. .. note:: Automatic library type detection in alignment-based mode. The implementation of this feature involves opening the BAM; file, peaking at the first record, and then closing it to; determine if the library should be treated as single-end or; paired-end. Thus, *in alignment-based mode* automatic; library type detection will not work with an input; stream. If your input is a regular file, everything should; work as expected; otherwise, you should provide the library; type explicitly in alignment-based mode.; ; Also the automatic library type detection is performed *on the; basis of the alignments in the file*. Thus, for example, if the; upstream aligner has been told to perform strand-aware mapping; (i.e. to ignore potential alignments that don't m",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst:44330,Usability,feedback,feedback,44330,"her). If your reads are compressed in a different format, you can; still stream them directly to Salmon by using process substitution.; Say in the *quasi-mapping*-based Salmon example above, the reads were; actually in the files ``reads1.fa.bz2`` and ``reads2.fa.bz2``, then; you'd run the following command to decompress the reads ""on-the-fly"":. ::. > ./bin/salmon quant -i transcripts_index -l <LIBTYPE> -1 <(bunzip2 -c reads1.fa.gz) -2 <(bunzip2 -c reads2.fa.bz2) -o transcripts_quant. and the bzipped files will be decompressed via separate processes and; the raw reads will be fed into Salmon. Actually, you can use this; same process even with gzip compressed reads (replacing ``bunzip2``; with ``gunzip`` or ``pigz -d``). Depending on the number of threads; and the exact configuration, this may actually improve Salmon's; running time, since the reads are decompressed concurrently in a; separate process when you use process substitution. **Finally**, the purpose of making this software available is for; people to use it and provide feedback. The; `paper describing this method is published in Nature Methods <http://rdcu.be/pQsw>`_.; If you have something useful to report or just some interesting ideas; or suggestions, please contact us (`rob.patro@cs.stonybrook.edu`; and/or `carlk@cs.cmu.edu`). If you encounter any bugs, please file a; *detailed* bug report at the `Salmon GitHub repository <https://github.com/COMBINE-lab/salmon>`_. References; ----------. .. [#express] Roberts, Adam, and Lior Pachter. ""Streaming fragment assignment for real-time analysis of sequencing experiments."" Nature Methods 10.1 (2013): 71-73.; ; .. [#roberts] Roberts, Adam, et al. ""Improving RNA-Seq expression estimates by correcting for fragment bias."" Genome Biology 12.3 (2011): 1. .. [#salmon] Patro, Rob, et al. ""Salmon provides fast and bias-aware quantification of transcript expression."" Nature Methods (2017). Advanced Online Publication. doi: 10.1038/nmeth.4197.. .. [#alpine] Love, Michael I",MatchSource.DOCS,doc/source/salmon.rst,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/doc/source/salmon.rst
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:7813,Availability,avail,available,7813,"1""); list(APPEND TGT_WARN_FLAGS ""-Wno-deprecated-copy""); endif(). set(GCC TRUE). # Put complete static linking on hold for the time-being; # If we're not on OSX, make an attempt to compile everything statically; #if(NOT APPLE); #set(CMAKE_EXE_LINK_FLAGS ""-static""); set(PTHREAD_LIB ""pthread""); #endif(). # If we're on Linux (i.e. not OSX) and we're using; # gcc, then set the -static-libstdc++ flag; if(NOT APPLE); list(APPEND TGT_COMPILE_FLAGS -static-libstdc++); endif(). set(WARNING_IGNORE_FLAGS ""${WARNING_IGNORE_FLAGS} -Wno-unused-local-typedefs""); set(BOOST_TOOLSET ""gcc""); set(BOOST_CONFIGURE_TOOLSET ""--with-toolset=gcc""); set(BCXX_FLAGS ""${CXXSTDFLAG} ${SCHAR_FLAG}""); set(BOOST_EXTRA_FLAGS toolset=gcc cxxflags=${BCXX_FLAGS}); # Tentatively, we support clang now; elseif(""${CMAKE_CXX_COMPILER_ID}"" MATCHES ""Clang""); set(CLANG TRUE); # If we have libc++, then try and use it; include(CheckCXXCompilerFlag); check_cxx_compiler_flag(-stdlib=libc++ HAVE_LIBCPP); if(HAVE_LIBCPP); message(""It appears that you're compiling with clang and that libc++ is available, so I'll use that""); list(APPEND TGT_COMPILE_FLAGS -stdlib=libc++); set(BOOST_TOOLSET ""clang""); set(BOOST_CONFIGURE_TOOLSET ""--with-toolset=clang""); set(BCXX_FLAGS ""-stdlib=libc++ -DBOOST_HAS_INT128 ${SCHAR_FLAG}""); set(BOOST_EXTRA_FLAGS toolset=clang cxxflags=${BCXX_FLAGS} linkflags=""-stdlib=libc++""); # Otherwise, use libstdc++ (and make it static); else(); list(APPEND TGT_COMPILE_FLAGS -static-libstdc++); endif(); # There's currently a bug with clang-3.4 & Boost 1.55 -- this hack fixes it; # but we should do something better (does this break things if CPU doesn't; # have 128-bit support)?; list(APPEND TGT_COMPILE_FLAGS -DBOOST_HAS_INT128). if(APPLE); set(NON_APPLECLANG_LIBS """"); else(); set(PTHREAD_LIB ""pthread""); endif(); else(); message(FATAL_ERROR ""Your C++ compiler does not support C++14.""); endif(). if(DO_QUIET_MAKE); set(QUIET_MAKE ""--silent""); else(); set(QUIET_MAKE """"); endif(). ## TODO: Figure out how to det",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:16278,Availability,down,download,16278,"OST_ROOT CACHE); unset(CMAKE_PREFIX_PATH CACHE); unset(Boost::diagnostic_definitions CACHE); unset(Boost::disable_autolinking CACHE); unset(Boost::dynamic_linking CACHE); set(BOOST_ROOT ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(CMAKE_PREFIX_PATH ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(Boost_INCLUDE_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/include); set(Boost_LIBRARY_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/lib); find_package(Boost 1.59.0 COMPONENTS iostreams system filesystem timer chrono program_options locale REQUIRED); set(FETCH_BOOST FALSE); endif(). ##; # Either inform the user of how to obtain Boost, or, if they passed in the FETCH_BOOST; # option, go and grab it for them.; ##; if((NOT Boost_FOUND) AND (NOT FETCH_BOOST)); message(FATAL_ERROR; ""Salmon cannot be compiled without Boost.\n""; ""It is recommended to visit http://www.boost.org/ and install Boost according to those instructions.\n""; ""This build system can also download and install a local version of boost for you (this takes a lot of time).\n""; ""To fetch and build boost locally, call cmake with -DFETCH_BOOST=TRUE""; ); elseif(FETCH_BOOST); if(NOT DEFINED BOOST_BUILD_THREADS); set(BOOST_BUILD_THREADS 2); endif(). ## Let the rest of the build process know we're going to be fetching boost; set(BOOST_LIB_SUBSET --with-iostreams --with-atomic --with-chrono --with-container --with-date_time --with-exception; --with-filesystem --with-graph --with-graph_parallel --with-math; --with-program_options --with-system --with-locale; --with-timer); set(BOOST_WILL_RECONFIGURE TRUE); set(FETCH_BOOST FALSE); set(BOOST_FETCHED_VERSION ""1_72_0""); message(""Build system will fetch and build Boost""); message(""==================================================================""); externalproject_add(libboost; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://sourceforge.net/projects/boost/files/boost/1.72.0/boost_1_72_0.tar.gz/download -o boost_1_72_0.tar",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:17274,Availability,down,download,17274,"d and install a local version of boost for you (this takes a lot of time).\n""; ""To fetch and build boost locally, call cmake with -DFETCH_BOOST=TRUE""; ); elseif(FETCH_BOOST); if(NOT DEFINED BOOST_BUILD_THREADS); set(BOOST_BUILD_THREADS 2); endif(). ## Let the rest of the build process know we're going to be fetching boost; set(BOOST_LIB_SUBSET --with-iostreams --with-atomic --with-chrono --with-container --with-date_time --with-exception; --with-filesystem --with-graph --with-graph_parallel --with-math; --with-program_options --with-system --with-locale; --with-timer); set(BOOST_WILL_RECONFIGURE TRUE); set(FETCH_BOOST FALSE); set(BOOST_FETCHED_VERSION ""1_72_0""); message(""Build system will fetch and build Boost""); message(""==================================================================""); externalproject_add(libboost; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://sourceforge.net/projects/boost/files/boost/1.72.0/boost_1_72_0.tar.gz/download -o boost_1_72_0.tar.gz &&; #${SHASUM} 96b34f7468f26a141f6020efb813f1a2f3dfb9797ecf76a7d7cbd843cc95f5bd boost_1_71_0.tar.gz &&; ${SHASUM} c66e88d5786f2ca4dbebb14e06b566fb642a1a6947ad8cc9091f9f445134143f boost_${BOOST_FETCHED_VERSION}.tar.gz &&; tar xzf boost_${BOOST_FETCHED_VERSION}.tar.gz ; SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/boost_${BOOST_FETCHED_VERSION}; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; #PATCH_COMMAND patch -p2 < ${CMAKE_CURRENT_SOURCE_DIR}/external/boost156.patch; CONFIGURE_COMMAND CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER} ${CMAKE_CURRENT_SOURCE_DIR}/external/boost_${BOOST_FETCHED_VERSION}/bootstrap.sh ${BOOST_CONFIGURE_TOOLSET} ${BOOST_BUILD_LIBS} --prefix=<INSTALL_DIR>; add_custom_command(; OUTPUT ${CMAKE_CURRENT_SOURCE_DIR}/external/boost_${BOOST_FETCHED_VERSION}/tools/build/src/user-config.jam; PRE_BUILD; COMMAND echo ""using gcc : ${CC_VERSION} : ${CMAKE_CXX_COMPILER} ;""; ); BUILD_COMMAND CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER}",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:18160,Availability,echo,echo,18160,"6020efb813f1a2f3dfb9797ecf76a7d7cbd843cc95f5bd boost_1_71_0.tar.gz &&; ${SHASUM} c66e88d5786f2ca4dbebb14e06b566fb642a1a6947ad8cc9091f9f445134143f boost_${BOOST_FETCHED_VERSION}.tar.gz &&; tar xzf boost_${BOOST_FETCHED_VERSION}.tar.gz ; SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/boost_${BOOST_FETCHED_VERSION}; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; #PATCH_COMMAND patch -p2 < ${CMAKE_CURRENT_SOURCE_DIR}/external/boost156.patch; CONFIGURE_COMMAND CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER} ${CMAKE_CURRENT_SOURCE_DIR}/external/boost_${BOOST_FETCHED_VERSION}/bootstrap.sh ${BOOST_CONFIGURE_TOOLSET} ${BOOST_BUILD_LIBS} --prefix=<INSTALL_DIR>; add_custom_command(; OUTPUT ${CMAKE_CURRENT_SOURCE_DIR}/external/boost_${BOOST_FETCHED_VERSION}/tools/build/src/user-config.jam; PRE_BUILD; COMMAND echo ""using gcc : ${CC_VERSION} : ${CMAKE_CXX_COMPILER} ;""; ); BUILD_COMMAND CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER} ${CMAKE_CURRENT_SOURCE_DIR}/external/boost_${BOOST_FETCHED_VERSION}/b2 -d0 -j${BOOST_BUILD_THREADS} ${BOOST_LIB_SUBSET} toolset=${BOOST_TOOLSET} ${BOOST_EXTRA_FLAGS} cxxflags=${BOOST_CXX_FLAGS} link=static install; BUILD_IN_SOURCE 1; INSTALL_COMMAND """"; ). externalproject_add_step(libboost makedir; COMMAND mkdir -p <SOURCE_DIR>/build; COMMENT ""Make build directory""; DEPENDEES download; DEPENDERS configure). ##; # After we've installed boost,; ##; set(RECONFIG_FLAGS ${RECONFIG_FLAGS} -DBOOST_WILL_RECONFIGURE=FALSE -DBOOST_RECONFIGURE=TRUE -DFETCH_BOOST=FALSE); externalproject_add_step(libboost reconfigure; COMMAND ${CMAKE_COMMAND} ${CMAKE_CURRENT_SOURCE_DIR} ${RECONFIG_FLAGS}; DEPENDEES install; ); set(FETCHED_BOOST TRUE); endif(). ##; # If we're fetching boost and we need to have dummy paths for these variables; # so that CMake won't complain; ##; if(BOOST_WILL_RECONFIGURE); message(""Setting Temporary Boost paths""); set(Boost_INCLUDE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install/include); set(Boost_INCLUDE_DIRS ${CMAKE_CURRENT_SOURCE_",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:18665,Availability,down,download,18665,"nal/boost_${BOOST_FETCHED_VERSION}; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; #PATCH_COMMAND patch -p2 < ${CMAKE_CURRENT_SOURCE_DIR}/external/boost156.patch; CONFIGURE_COMMAND CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER} ${CMAKE_CURRENT_SOURCE_DIR}/external/boost_${BOOST_FETCHED_VERSION}/bootstrap.sh ${BOOST_CONFIGURE_TOOLSET} ${BOOST_BUILD_LIBS} --prefix=<INSTALL_DIR>; add_custom_command(; OUTPUT ${CMAKE_CURRENT_SOURCE_DIR}/external/boost_${BOOST_FETCHED_VERSION}/tools/build/src/user-config.jam; PRE_BUILD; COMMAND echo ""using gcc : ${CC_VERSION} : ${CMAKE_CXX_COMPILER} ;""; ); BUILD_COMMAND CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER} ${CMAKE_CURRENT_SOURCE_DIR}/external/boost_${BOOST_FETCHED_VERSION}/b2 -d0 -j${BOOST_BUILD_THREADS} ${BOOST_LIB_SUBSET} toolset=${BOOST_TOOLSET} ${BOOST_EXTRA_FLAGS} cxxflags=${BOOST_CXX_FLAGS} link=static install; BUILD_IN_SOURCE 1; INSTALL_COMMAND """"; ). externalproject_add_step(libboost makedir; COMMAND mkdir -p <SOURCE_DIR>/build; COMMENT ""Make build directory""; DEPENDEES download; DEPENDERS configure). ##; # After we've installed boost,; ##; set(RECONFIG_FLAGS ${RECONFIG_FLAGS} -DBOOST_WILL_RECONFIGURE=FALSE -DBOOST_RECONFIGURE=TRUE -DFETCH_BOOST=FALSE); externalproject_add_step(libboost reconfigure; COMMAND ${CMAKE_COMMAND} ${CMAKE_CURRENT_SOURCE_DIR} ${RECONFIG_FLAGS}; DEPENDEES install; ); set(FETCHED_BOOST TRUE); endif(). ##; # If we're fetching boost and we need to have dummy paths for these variables; # so that CMake won't complain; ##; if(BOOST_WILL_RECONFIGURE); message(""Setting Temporary Boost paths""); set(Boost_INCLUDE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install/include); set(Boost_INCLUDE_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/include); set(Boost_LIBRARY_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/lib); set(Boost_FOUND TRUE); endif(). message(""BOOST ROOT = ${BOOST_ROOT}""); message(""BOOST INCLUDE DIR = ${Boost_INCLUDE_DIR}""); message(""BOOST INCLUDE DIRS = ${Boost_INCLUDE_DIRS",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:20814,Availability,down,download,20814,"ENT_SOURCE_DIR/lib). #find_package(libdivsufsort); #if(NOT LIBDIVSUFSORT_FOUND); # message(""Build system will build libdivsufsort""); # message(""==================================================================""); # include(ExternalProject); # externalproject_add(libdivsufsort; # DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; # URL ${CMAKE_CURRENT_SOURCE_DIR}/external/libdivsufsort.zip; # # Note: This zip comes from the fetched rapmap.zip, whose SHA we check; # # so we souldn't need to check this one separately.; # SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/libdivsufsort-master; # INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; # #UPDATE_COMMAND sh -c ""mkdir -p <SOURCE_DIR>/build""; # BINARY_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/libdivsufsort-master/build; # CMAKE_ARGS -DCMAKE_INSTALL_PREFIX:PATH=<INSTALL_DIR> -DBUILD_DIVSUFSORT64=TRUE -DUSE_OPENMP=TRUE -DBUILD_SHARED_LIBS=FALSE; # ); # externalproject_add_step(libdivsufsort makedir; # COMMAND mkdir -p <SOURCE_DIR>/build; # COMMENT ""Make build directory""; # DEPENDEES download; # DEPENDERS configure); #; # set(SUFFARRAY_INCLUDE_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/include); # set(FETCHED_LIBDIVSUFSORT TRUE); #else(); # message(""SUFFARRAY_LIB = ${SUFFARRAY_LIBRARY}""); # set(SUFFARRAY_LIB ${SUFFARRAY_LIBRARY}); # message(""SUFFARRAY_LIB64 = ${SUFFARRAY_LIBRARY64}""); # set(SUFFARRAY_LIB64 ${SUFFARRAY_LIBRARY64}); # set(SUFFARRAY_INCLUDE_DIRS ${SUFFARRAY_INCLUDE_DIR}); #endif(). find_package(cereal ""1.3.2""); if (NOT CEREAL_FOUND); message(""Build system will fetch and build the cereal serialization library""); message(""==================================================================""); include(ExternalProject); externalproject_add(libcereal; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://github.com/USCiLab/cereal/archive/refs/tags/v1.3.2.tar.gz -o cereal-v1.3.2.tar.gz &&; ${SHASUM} 16a7ad9b31ba5880dac55d62b5d6f243c3ebc8d46a3514149e56b5e7ea81f85f cere",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:22336,Availability,down,download,22336,"SUFFARRAY_INCLUDE_DIR}); #endif(). find_package(cereal ""1.3.2""); if (NOT CEREAL_FOUND); message(""Build system will fetch and build the cereal serialization library""); message(""==================================================================""); include(ExternalProject); externalproject_add(libcereal; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://github.com/USCiLab/cereal/archive/refs/tags/v1.3.2.tar.gz -o cereal-v1.3.2.tar.gz &&; ${SHASUM} 16a7ad9b31ba5880dac55d62b5d6f243c3ebc8d46a3514149e56b5e7ea81f85f cereal-v1.3.2.tar.gz &&; tar -xzvf cereal-v1.3.2.tar.gz. SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/cereal-1.3.2; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; #UPDATE_COMMAND sh -c ""mkdir -p <SOURCE_DIR>/build""; BINARY_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/cereal-1.3.2/build; CONFIGURE_COMMAND """"; BUILD_COMMAND """"; INSTALL_COMMAND sh -c ""mkdir -p <INSTALL_DIR>/include && cp -r <SOURCE_DIR>/include/cereal <INSTALL_DIR>/include""; ); externalproject_add_step(libcereal makedir; COMMAND mkdir -p <SOURCE_DIR>/build; COMMENT ""Make build directory""; DEPENDEES download; DEPENDERS configure). set(FETCHED_CEREAL TRUE); endif(). ## Try and find TBB first; find_package(TBB 2021.4; HINTS ${TBB_ROOT_SEARCH}; COMPONENTS tbb tbbmalloc tbbmalloc_proxy). if (${TBB_FOUND}); if (${TBB_VERSION} VERSION_GREATER_EQUAL 2021.4); message(""FOUND SUITABLE TBB VERSION : ${TBB_VERSION}""); set(TBB_TARGET_EXISTED TRUE); else(); set(TBB_TARGET_EXISTED FALSE); endif(); else(); set(TBB_TARGET_EXISTED FALSE); endif(). ##; #; # Fetch and build Intel's Threading Building Blocks library.; #; ##; if(NOT ${TBB_TARGET_EXISTED}). set(TBB_WILL_RECONFIGURE TRUE); # Set the appropriate compiler; if(CLANG); set(TBB_COMPILER ""clang""); else(); set(TBB_COMPILER ""gcc""); endif(). message(""Build system will fetch and build Intel Threading Building Blocks""); message(""==================================================================""); # These are useful for t",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:28111,Availability,down,download,28111,"bgff_FOUND); message(STATUS ""libgff ver. ${LIB_GFF_VERSION} found.""); message(STATUS "" include: ${LIB_GFF_INCLUDE_DIR}""); message(STATUS "" lib : ${LIB_GFF_LIBRARY_DIR}""); endif(). if(NOT libgff_FOUND); message(""Build system will compile libgff""); message(""==================================================================""); externalproject_add(libgff; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://github.com/COMBINE-lab/libgff/archive/v2.0.0.tar.gz -o libgff.tgz &&; ${SHASUM} 7656b19459a7ca7d2fd0fcec4f2e0fd0deec1b4f39c703a114e8f4c22d82a99c libgff.tgz &&; tar -xzvf libgff.tgz; SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/libgff-2.0.0; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; BINARY_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/libgff-2.0.0/build; CMAKE_ARGS -DCMAKE_INSTALL_PREFIX:PATH=<INSTALL_DIR> -DCMAKE_CXX_COMPILER=${CMAKE_CXX_COMPILER} -DCMAKE_C_COMPILER=${CMAKE_C_COMPILER} ; ); externalproject_add_step(libgff makedir; COMMAND mkdir -p <SOURCE_DIR>/build; COMMENT ""Make build directory""; DEPENDEES download; DEPENDERS configure); set(FETCHED_GFF TRUE); set(LIB_GFF_PATH ${CMAKE_CURRENT_SOURCE_DIR}/external/install); endif(). # Because of the way that Apple has changed SIP; # in el capitan, some headers may be in a new location; if(APPLE); set(STADEN_INC ""-I/usr/local/include""); set(STADEN_LIB ""-L/usr/local/lib""); endif(). if(CONDA_BUILD); set(LZFLAG ""-lz""); else(); set(LZFLAG """"); endif(). find_package(CURL). if (FETCH_STADEN); set(LIBSTADEN_FOUND FALSE); else (); find_package(libstadenio 1.14.15); endif(). if (NOT LIBSTADENIO_FOUND); message(""Build system will compile Staden IOLib""); message(""==================================================================""); externalproject_add(libstadenio; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://github.com/jkbonfield/io_lib/releases/download/io_lib-1-14-15/io_lib-1.14.15.tar.gz -o staden-io_lib-v1.14.15.tar.gz &&; ${SHASUM} 20",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:28945,Availability,down,download,28945," -DCMAKE_C_COMPILER=${CMAKE_C_COMPILER} ; ); externalproject_add_step(libgff makedir; COMMAND mkdir -p <SOURCE_DIR>/build; COMMENT ""Make build directory""; DEPENDEES download; DEPENDERS configure); set(FETCHED_GFF TRUE); set(LIB_GFF_PATH ${CMAKE_CURRENT_SOURCE_DIR}/external/install); endif(). # Because of the way that Apple has changed SIP; # in el capitan, some headers may be in a new location; if(APPLE); set(STADEN_INC ""-I/usr/local/include""); set(STADEN_LIB ""-L/usr/local/lib""); endif(). if(CONDA_BUILD); set(LZFLAG ""-lz""); else(); set(LZFLAG """"); endif(). find_package(CURL). if (FETCH_STADEN); set(LIBSTADEN_FOUND FALSE); else (); find_package(libstadenio 1.14.15); endif(). if (NOT LIBSTADENIO_FOUND); message(""Build system will compile Staden IOLib""); message(""==================================================================""); externalproject_add(libstadenio; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://github.com/jkbonfield/io_lib/releases/download/io_lib-1-14-15/io_lib-1.14.15.tar.gz -o staden-io_lib-v1.14.15.tar.gz &&; ${SHASUM} 20814c4365e1e2fe6630fb11d0df370dec4c5688af3871de7f1cb0129671401e staden-io_lib-v1.14.15.tar.gz &&; mkdir -p staden-io_lib-1.14.15 &&; tar -xzf staden-io_lib-v1.14.15.tar.gz --strip-components=1 -C staden-io_lib-1.14.15 &&; rm -fr staden-io_lib &&; mv -f staden-io_lib-1.14.15 staden-io_lib; SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/staden-io_lib; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; CONFIGURE_COMMAND ./configure --enable-shared=no --without-libcurl --prefix=<INSTALL_DIR> LDFLAGS=${LIBSTADEN_LDFLAGS} CFLAGS=${LIBSTADEN_CFLAGS} CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER}; BUILD_COMMAND make ${QUIET_MAKE} CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER} CFLAGS+=${STADEN_INC} CFLAGS+=${STADEN_LIB} LDFLAGS+=${EXTRA_CMAKE_LIBRARY_FLAGS} CFLAGS+=${EXTRA_CMAKE_INCLUDE_FLAGS} CFLAGS+=${LZFLAG} CFLAGS+=${SCHAR_FLAG}. BUILD_IN_SOURCE 1; INSTALL_COMMAND make install; ); if(NOT",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:4773,Deployability,install,install,4773,"dif(). ## Prefer static to dynamic libraries; if(NOT USE_SHARED_LIBS); set(CMAKE_FIND_LIBRARY_SUFFIXES .a ${CMAKE_FIND_LIBRARY_SUFFIXES}); set(MALLOC_STATIC_BUILD_FLAG ""--enable-static""); endif(). include(CheckIPOSupported). set(THREADS_PREFER_PTHREAD_FLAG ON); find_package(Threads REQUIRED). set(ICU_LIBS """"); set(ICU_INC_DIRS """"). set(CMAKE_CXX_STANDARD 14); set(CMAKE_CXX_STANDARD_REQUIRED ON); set(CMAKE_CXX_EXTENSIONS OFF); set(CXXSTDFLAG ""-std=c++14""); set(GCCVERSION ""5.2""). if(CONDA_BUILD); message(""Building with CONDA_BUILD flag""); if(APPLE); # Do we require all these components? Any others?; find_package(ICU COMPONENTS data i18n io uc REQUIRED); if(ICU_FOUND); message(STATUS ""ICU_INCLUDE_DIRS = ${ICU_INCLUDE_DIRS}""); message(STATUS ""ICU_LIBRARIES = ${ICU_LIBRARIES}""); endif(); set(ICU_INC_DIRS ${ICU_INCLUDE_DIRS}); set(ICU_LIBS ${ICU_LIBRARIES}); endif(); endif(). set(BOOST_CXX_FLAGS ""${WARNING_IGNORE_FLAGS} ${CXXSTDFLAG}""); if(FETCH_BOOST); set(BOOST_CXX_FLAGS ""${BOOST_CXX_FLAGS} -I${CMAKE_CURRENT_SOURCE_DIR}/external/install/include -L${CMAKE_CURRENT_SOURCE_DIR}/external/install/lib""); endif(). ##; # OSX is strange (some might say, stupid in this regard). Deal with it's quirkines here.; ##; if(APPLE); # To allow ourselves to build a dynamic library, we have to tell the compiler; # that, yes, the symbols will be around at runtime.; list(APPEND TGT_COMPILE_FLAGS ""-undefined dynamic_lookup;-Wno-unused-command-line-argument""); # set(LIBSALMON_LINKER_FLAGS ""-all_load""); # In order to ""think different"", we also have to use non-standard suffixes; # for our shared libraries; set(SHARED_LIB_EXTENSION ""dylib""); else(); # We're in sane linux world; set(SHARED_LIB_EXTENSION ""so""); set(LIBSALMON_LINKER_FLAGS """"); endif(). set( BOOST_EXTRA_FLAGS ""--layout=tagged"" ); ## this get's set differently below if we; ## are on clang & apple; set(NON_APPLECLANG_LIBS gomp). if(UNIX AND NOT APPLE); set(LIBRT rt); endif(). set(PTHREAD_LIB). ##; # Let us check the sha sum of our pacakge",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:4828,Deployability,install,install,4828,"dif(). ## Prefer static to dynamic libraries; if(NOT USE_SHARED_LIBS); set(CMAKE_FIND_LIBRARY_SUFFIXES .a ${CMAKE_FIND_LIBRARY_SUFFIXES}); set(MALLOC_STATIC_BUILD_FLAG ""--enable-static""); endif(). include(CheckIPOSupported). set(THREADS_PREFER_PTHREAD_FLAG ON); find_package(Threads REQUIRED). set(ICU_LIBS """"); set(ICU_INC_DIRS """"). set(CMAKE_CXX_STANDARD 14); set(CMAKE_CXX_STANDARD_REQUIRED ON); set(CMAKE_CXX_EXTENSIONS OFF); set(CXXSTDFLAG ""-std=c++14""); set(GCCVERSION ""5.2""). if(CONDA_BUILD); message(""Building with CONDA_BUILD flag""); if(APPLE); # Do we require all these components? Any others?; find_package(ICU COMPONENTS data i18n io uc REQUIRED); if(ICU_FOUND); message(STATUS ""ICU_INCLUDE_DIRS = ${ICU_INCLUDE_DIRS}""); message(STATUS ""ICU_LIBRARIES = ${ICU_LIBRARIES}""); endif(); set(ICU_INC_DIRS ${ICU_INCLUDE_DIRS}); set(ICU_LIBS ${ICU_LIBRARIES}); endif(); endif(). set(BOOST_CXX_FLAGS ""${WARNING_IGNORE_FLAGS} ${CXXSTDFLAG}""); if(FETCH_BOOST); set(BOOST_CXX_FLAGS ""${BOOST_CXX_FLAGS} -I${CMAKE_CURRENT_SOURCE_DIR}/external/install/include -L${CMAKE_CURRENT_SOURCE_DIR}/external/install/lib""); endif(). ##; # OSX is strange (some might say, stupid in this regard). Deal with it's quirkines here.; ##; if(APPLE); # To allow ourselves to build a dynamic library, we have to tell the compiler; # that, yes, the symbols will be around at runtime.; list(APPEND TGT_COMPILE_FLAGS ""-undefined dynamic_lookup;-Wno-unused-command-line-argument""); # set(LIBSALMON_LINKER_FLAGS ""-all_load""); # In order to ""think different"", we also have to use non-standard suffixes; # for our shared libraries; set(SHARED_LIB_EXTENSION ""dylib""); else(); # We're in sane linux world; set(SHARED_LIB_EXTENSION ""so""); set(LIBSALMON_LINKER_FLAGS """"); endif(). set( BOOST_EXTRA_FLAGS ""--layout=tagged"" ); ## this get's set differently below if we; ## are on clang & apple; set(NON_APPLECLANG_LIBS gomp). if(UNIX AND NOT APPLE); set(LIBRT rt); endif(). set(PTHREAD_LIB). ##; # Let us check the sha sum of our pacakge",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:10907,Deployability,install,installed,10907,"VALUE FETCH_PF_SCRIPT_RET); message(STATUS ""fetch PUFFERFISH exit code ${FETCH_PF_SCRIPT_RET}""); if(NOT (FETCH_PF_SCRIPT_RET EQUAL 0)); message(FATAL_ERROR ""Could not fetch pufferfish source [fetchPufferfish.sh returned exit code ${FETCH_PF_SCRIPT_RET}].""); endif(); set(FETCHED_PUFFERFISH TRUE CACHE BOOL ""Has pufferfish been fetched?"" FORCE); endif(). ##; # Super-secret override; ##; if( DEFINED CUSTOM_BOOST_PATH ); set(CMAKE_INCLUDE_PATH ${CUSTOM_BOOST_PATH} ${CMAKE_INCLUDE_PATH}); set(CMAKE_LIBRARY_PATH ${CUSTOM_BOOST_PATH}/lib ${CMAKE_LIBRARY_PATH}); endif(). ##; # We want static, multithreaded boost libraries; ##; if(CONDA_BUILD); set(Boost_USE_STATIC_LIBS OFF); elseif(USE_SHARED_LIBS) # CI failed when using an OR statement above...; set(Boost_USE_STATIC_LIBS OFF); else(); set(Boost_USE_STATIC_LIBS ON); endif(). set(Boost_USE_MULTITHREADED ON); #set(Boost_USE_STATIC_RUNTIME OFF); set(Boost_USE_DEBUG_RUNTIME OFF). find_package(ZLIB); if(NOT ZLIB_FOUND); message(FATAL_ERROR ""zlib must be installed before configuration & building can proceed""); endif(). if(""${CMAKE_INCLUDE_PATH}"" STREQUAL """"); set(EXTRA_CMAKE_INCLUDE_FLAGS """"); else(); set(EXTRA_CMAKE_INCLUDE_FLAGS ""-I${CMAKE_INCLUDE_PATH}""); endif(). if(""${CMAKE_LIBRARY_PATH}"" STREQUAL """"); set(EXTRA_CMAKE_LIBRARY_FLAGS """"); else(); set(EXTRA_CMAKE_LIBRARY_FLAGS ""-L${CMAKE_LIBRARY_PATH}""); endif(). find_package(Iconv REQUIRED); if(NOT Iconv_IS_BUILT_IN); set(ICONV_LIB Iconv::Iconv); endif(). find_package(LibLZMA); if(NOT LIBLZMA_FOUND); message(""Will attempt to fetch and build liblzma""); message(""=======================================""); externalproject_add(liblzma; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; ##; DOWNLOAD_COMMAND curl -k -L http://tukaani.org/xz/xz-5.2.2.tar.gz -o xz-5.2.2.tar.gz &&; ${SHASUM} 73df4d5d34f0468bd57d09f2d8af363e95ed6cc3a4a86129d2f2c366259902a2 xz-5.2.2.tar.gz &&; tar -xzvf xz-5.2.2.tar.gz; #URL http://tukaani.org/xz/xz-5.2.2.tar.gz; #URL_HASH SHA1=14663612422ab61386673be78fbb",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:10924,Deployability,configurat,configuration,10924,"VALUE FETCH_PF_SCRIPT_RET); message(STATUS ""fetch PUFFERFISH exit code ${FETCH_PF_SCRIPT_RET}""); if(NOT (FETCH_PF_SCRIPT_RET EQUAL 0)); message(FATAL_ERROR ""Could not fetch pufferfish source [fetchPufferfish.sh returned exit code ${FETCH_PF_SCRIPT_RET}].""); endif(); set(FETCHED_PUFFERFISH TRUE CACHE BOOL ""Has pufferfish been fetched?"" FORCE); endif(). ##; # Super-secret override; ##; if( DEFINED CUSTOM_BOOST_PATH ); set(CMAKE_INCLUDE_PATH ${CUSTOM_BOOST_PATH} ${CMAKE_INCLUDE_PATH}); set(CMAKE_LIBRARY_PATH ${CUSTOM_BOOST_PATH}/lib ${CMAKE_LIBRARY_PATH}); endif(). ##; # We want static, multithreaded boost libraries; ##; if(CONDA_BUILD); set(Boost_USE_STATIC_LIBS OFF); elseif(USE_SHARED_LIBS) # CI failed when using an OR statement above...; set(Boost_USE_STATIC_LIBS OFF); else(); set(Boost_USE_STATIC_LIBS ON); endif(). set(Boost_USE_MULTITHREADED ON); #set(Boost_USE_STATIC_RUNTIME OFF); set(Boost_USE_DEBUG_RUNTIME OFF). find_package(ZLIB); if(NOT ZLIB_FOUND); message(FATAL_ERROR ""zlib must be installed before configuration & building can proceed""); endif(). if(""${CMAKE_INCLUDE_PATH}"" STREQUAL """"); set(EXTRA_CMAKE_INCLUDE_FLAGS """"); else(); set(EXTRA_CMAKE_INCLUDE_FLAGS ""-I${CMAKE_INCLUDE_PATH}""); endif(). if(""${CMAKE_LIBRARY_PATH}"" STREQUAL """"); set(EXTRA_CMAKE_LIBRARY_FLAGS """"); else(); set(EXTRA_CMAKE_LIBRARY_FLAGS ""-L${CMAKE_LIBRARY_PATH}""); endif(). find_package(Iconv REQUIRED); if(NOT Iconv_IS_BUILT_IN); set(ICONV_LIB Iconv::Iconv); endif(). find_package(LibLZMA); if(NOT LIBLZMA_FOUND); message(""Will attempt to fetch and build liblzma""); message(""=======================================""); externalproject_add(liblzma; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; ##; DOWNLOAD_COMMAND curl -k -L http://tukaani.org/xz/xz-5.2.2.tar.gz -o xz-5.2.2.tar.gz &&; ${SHASUM} 73df4d5d34f0468bd57d09f2d8af363e95ed6cc3a4a86129d2f2c366259902a2 xz-5.2.2.tar.gz &&; tar -xzvf xz-5.2.2.tar.gz; #URL http://tukaani.org/xz/xz-5.2.2.tar.gz; #URL_HASH SHA1=14663612422ab61386673be78fbb",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:12027,Deployability,install,install,12027,"); else(); set(EXTRA_CMAKE_INCLUDE_FLAGS ""-I${CMAKE_INCLUDE_PATH}""); endif(). if(""${CMAKE_LIBRARY_PATH}"" STREQUAL """"); set(EXTRA_CMAKE_LIBRARY_FLAGS """"); else(); set(EXTRA_CMAKE_LIBRARY_FLAGS ""-L${CMAKE_LIBRARY_PATH}""); endif(). find_package(Iconv REQUIRED); if(NOT Iconv_IS_BUILT_IN); set(ICONV_LIB Iconv::Iconv); endif(). find_package(LibLZMA); if(NOT LIBLZMA_FOUND); message(""Will attempt to fetch and build liblzma""); message(""=======================================""); externalproject_add(liblzma; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; ##; DOWNLOAD_COMMAND curl -k -L http://tukaani.org/xz/xz-5.2.2.tar.gz -o xz-5.2.2.tar.gz &&; ${SHASUM} 73df4d5d34f0468bd57d09f2d8af363e95ed6cc3a4a86129d2f2c366259902a2 xz-5.2.2.tar.gz &&; tar -xzvf xz-5.2.2.tar.gz; #URL http://tukaani.org/xz/xz-5.2.2.tar.gz; #URL_HASH SHA1=14663612422ab61386673be78fbb2556f50a1f08; ##; SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/xz-5.2.2; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; BUILD_IN_SOURCE TRUE; CONFIGURE_COMMAND ${CMAKE_CURRENT_SOURCE_DIR}/external/xz-5.2.2/configure --prefix=<INSTALL_DIR> CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER} CFLAGS=${EXTRA_CMAKE_INCLUDE_FLAGS} CPPFLAGS=${EXTRA_CMAKE_INCLUDE_FLAGS} LDFLAGS=${EXTRA_CMAKE_LIBRARY_FLAGS}; BUILD_COMMAND make ${QUIET_MAKE}; INSTALL_COMMAND make ${QUIET_MAKE} install; ). # Tell cmake that the external project generated a library so we can; # add dependencies here instead of later; set(LIBLZMA_LIBRARIES ${GAT_SOURCE_DIR}/external/install/lib/liblzma.a); set(LIBSTADEN_LDFLAGS ""-L${GAT_SOURCE_DIR}/external/install/lib""); set(LIBSTADEN_CFLAGS ""-I${GAT_SOURCE_DIR}/external/install/include""); set(FETCHED_LIBLZMA TRUE); else(); message(""Found liblzma library: ${LIBLZMA_LIBRARIES}""); message(""===========================================""); endif(). find_package(BZip2); if(NOT BZIP2_FOUND); message(""Will attempt to fetch and build libbz2""); message(""=======================================""); externalproject_add(libbz2;",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:12385,Deployability,install,install,12385,"ATH}""); endif(). find_package(Iconv REQUIRED); if(NOT Iconv_IS_BUILT_IN); set(ICONV_LIB Iconv::Iconv); endif(). find_package(LibLZMA); if(NOT LIBLZMA_FOUND); message(""Will attempt to fetch and build liblzma""); message(""=======================================""); externalproject_add(liblzma; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; ##; DOWNLOAD_COMMAND curl -k -L http://tukaani.org/xz/xz-5.2.2.tar.gz -o xz-5.2.2.tar.gz &&; ${SHASUM} 73df4d5d34f0468bd57d09f2d8af363e95ed6cc3a4a86129d2f2c366259902a2 xz-5.2.2.tar.gz &&; tar -xzvf xz-5.2.2.tar.gz; #URL http://tukaani.org/xz/xz-5.2.2.tar.gz; #URL_HASH SHA1=14663612422ab61386673be78fbb2556f50a1f08; ##; SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/xz-5.2.2; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; BUILD_IN_SOURCE TRUE; CONFIGURE_COMMAND ${CMAKE_CURRENT_SOURCE_DIR}/external/xz-5.2.2/configure --prefix=<INSTALL_DIR> CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER} CFLAGS=${EXTRA_CMAKE_INCLUDE_FLAGS} CPPFLAGS=${EXTRA_CMAKE_INCLUDE_FLAGS} LDFLAGS=${EXTRA_CMAKE_LIBRARY_FLAGS}; BUILD_COMMAND make ${QUIET_MAKE}; INSTALL_COMMAND make ${QUIET_MAKE} install; ). # Tell cmake that the external project generated a library so we can; # add dependencies here instead of later; set(LIBLZMA_LIBRARIES ${GAT_SOURCE_DIR}/external/install/lib/liblzma.a); set(LIBSTADEN_LDFLAGS ""-L${GAT_SOURCE_DIR}/external/install/lib""); set(LIBSTADEN_CFLAGS ""-I${GAT_SOURCE_DIR}/external/install/include""); set(FETCHED_LIBLZMA TRUE); else(); message(""Found liblzma library: ${LIBLZMA_LIBRARIES}""); message(""===========================================""); endif(). find_package(BZip2); if(NOT BZIP2_FOUND); message(""Will attempt to fetch and build libbz2""); message(""=======================================""); externalproject_add(libbz2; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://sourceware.org/pub/bzip2/bzip2-1.0.6.tar.gz -o bzip2-1.0.6.tar.gz &&; ${SHASUM} a2848f34fcd5d6cf47def00461fcb528a0484d8edef",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:12558,Deployability,install,install,12558,"=============================""); externalproject_add(liblzma; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; ##; DOWNLOAD_COMMAND curl -k -L http://tukaani.org/xz/xz-5.2.2.tar.gz -o xz-5.2.2.tar.gz &&; ${SHASUM} 73df4d5d34f0468bd57d09f2d8af363e95ed6cc3a4a86129d2f2c366259902a2 xz-5.2.2.tar.gz &&; tar -xzvf xz-5.2.2.tar.gz; #URL http://tukaani.org/xz/xz-5.2.2.tar.gz; #URL_HASH SHA1=14663612422ab61386673be78fbb2556f50a1f08; ##; SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/xz-5.2.2; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; BUILD_IN_SOURCE TRUE; CONFIGURE_COMMAND ${CMAKE_CURRENT_SOURCE_DIR}/external/xz-5.2.2/configure --prefix=<INSTALL_DIR> CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER} CFLAGS=${EXTRA_CMAKE_INCLUDE_FLAGS} CPPFLAGS=${EXTRA_CMAKE_INCLUDE_FLAGS} LDFLAGS=${EXTRA_CMAKE_LIBRARY_FLAGS}; BUILD_COMMAND make ${QUIET_MAKE}; INSTALL_COMMAND make ${QUIET_MAKE} install; ). # Tell cmake that the external project generated a library so we can; # add dependencies here instead of later; set(LIBLZMA_LIBRARIES ${GAT_SOURCE_DIR}/external/install/lib/liblzma.a); set(LIBSTADEN_LDFLAGS ""-L${GAT_SOURCE_DIR}/external/install/lib""); set(LIBSTADEN_CFLAGS ""-I${GAT_SOURCE_DIR}/external/install/include""); set(FETCHED_LIBLZMA TRUE); else(); message(""Found liblzma library: ${LIBLZMA_LIBRARIES}""); message(""===========================================""); endif(). find_package(BZip2); if(NOT BZIP2_FOUND); message(""Will attempt to fetch and build libbz2""); message(""=======================================""); externalproject_add(libbz2; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://sourceware.org/pub/bzip2/bzip2-1.0.6.tar.gz -o bzip2-1.0.6.tar.gz &&; ${SHASUM} a2848f34fcd5d6cf47def00461fcb528a0484d8edef8208d6d2e2909dc61d9cd bzip2-1.0.6.tar.gz &&; tar -xzvf bzip2-1.0.6.tar.gz; #URL http://www.bzip.org/1.0.6/bzip2-1.0.6.tar.gz; #URL_HASH SHA1=3f89f861209ce81a6bab1fd1998c0ef311712002; SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/externa",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:12634,Deployability,install,install,12634,"2d8af363e95ed6cc3a4a86129d2f2c366259902a2 xz-5.2.2.tar.gz &&; tar -xzvf xz-5.2.2.tar.gz; #URL http://tukaani.org/xz/xz-5.2.2.tar.gz; #URL_HASH SHA1=14663612422ab61386673be78fbb2556f50a1f08; ##; SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/xz-5.2.2; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; BUILD_IN_SOURCE TRUE; CONFIGURE_COMMAND ${CMAKE_CURRENT_SOURCE_DIR}/external/xz-5.2.2/configure --prefix=<INSTALL_DIR> CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER} CFLAGS=${EXTRA_CMAKE_INCLUDE_FLAGS} CPPFLAGS=${EXTRA_CMAKE_INCLUDE_FLAGS} LDFLAGS=${EXTRA_CMAKE_LIBRARY_FLAGS}; BUILD_COMMAND make ${QUIET_MAKE}; INSTALL_COMMAND make ${QUIET_MAKE} install; ). # Tell cmake that the external project generated a library so we can; # add dependencies here instead of later; set(LIBLZMA_LIBRARIES ${GAT_SOURCE_DIR}/external/install/lib/liblzma.a); set(LIBSTADEN_LDFLAGS ""-L${GAT_SOURCE_DIR}/external/install/lib""); set(LIBSTADEN_CFLAGS ""-I${GAT_SOURCE_DIR}/external/install/include""); set(FETCHED_LIBLZMA TRUE); else(); message(""Found liblzma library: ${LIBLZMA_LIBRARIES}""); message(""===========================================""); endif(). find_package(BZip2); if(NOT BZIP2_FOUND); message(""Will attempt to fetch and build libbz2""); message(""=======================================""); externalproject_add(libbz2; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://sourceware.org/pub/bzip2/bzip2-1.0.6.tar.gz -o bzip2-1.0.6.tar.gz &&; ${SHASUM} a2848f34fcd5d6cf47def00461fcb528a0484d8edef8208d6d2e2909dc61d9cd bzip2-1.0.6.tar.gz &&; tar -xzvf bzip2-1.0.6.tar.gz; #URL http://www.bzip.org/1.0.6/bzip2-1.0.6.tar.gz; #URL_HASH SHA1=3f89f861209ce81a6bab1fd1998c0ef311712002; SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/bzip2-1.0.6; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; BUILD_IN_SOURCE TRUE; CONFIGURE_COMMAND """"; BUILD_COMMAND make ${QUIET_MAKE} CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER}; INSTALL_COMMAND make ${QUIET_MAKE} inst",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:12700,Deployability,install,install,12700,"2d8af363e95ed6cc3a4a86129d2f2c366259902a2 xz-5.2.2.tar.gz &&; tar -xzvf xz-5.2.2.tar.gz; #URL http://tukaani.org/xz/xz-5.2.2.tar.gz; #URL_HASH SHA1=14663612422ab61386673be78fbb2556f50a1f08; ##; SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/xz-5.2.2; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; BUILD_IN_SOURCE TRUE; CONFIGURE_COMMAND ${CMAKE_CURRENT_SOURCE_DIR}/external/xz-5.2.2/configure --prefix=<INSTALL_DIR> CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER} CFLAGS=${EXTRA_CMAKE_INCLUDE_FLAGS} CPPFLAGS=${EXTRA_CMAKE_INCLUDE_FLAGS} LDFLAGS=${EXTRA_CMAKE_LIBRARY_FLAGS}; BUILD_COMMAND make ${QUIET_MAKE}; INSTALL_COMMAND make ${QUIET_MAKE} install; ). # Tell cmake that the external project generated a library so we can; # add dependencies here instead of later; set(LIBLZMA_LIBRARIES ${GAT_SOURCE_DIR}/external/install/lib/liblzma.a); set(LIBSTADEN_LDFLAGS ""-L${GAT_SOURCE_DIR}/external/install/lib""); set(LIBSTADEN_CFLAGS ""-I${GAT_SOURCE_DIR}/external/install/include""); set(FETCHED_LIBLZMA TRUE); else(); message(""Found liblzma library: ${LIBLZMA_LIBRARIES}""); message(""===========================================""); endif(). find_package(BZip2); if(NOT BZIP2_FOUND); message(""Will attempt to fetch and build libbz2""); message(""=======================================""); externalproject_add(libbz2; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://sourceware.org/pub/bzip2/bzip2-1.0.6.tar.gz -o bzip2-1.0.6.tar.gz &&; ${SHASUM} a2848f34fcd5d6cf47def00461fcb528a0484d8edef8208d6d2e2909dc61d9cd bzip2-1.0.6.tar.gz &&; tar -xzvf bzip2-1.0.6.tar.gz; #URL http://www.bzip.org/1.0.6/bzip2-1.0.6.tar.gz; #URL_HASH SHA1=3f89f861209ce81a6bab1fd1998c0ef311712002; SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/bzip2-1.0.6; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; BUILD_IN_SOURCE TRUE; CONFIGURE_COMMAND """"; BUILD_COMMAND make ${QUIET_MAKE} CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER}; INSTALL_COMMAND make ${QUIET_MAKE} inst",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:13551,Deployability,install,install,13551,"); set(FETCHED_LIBLZMA TRUE); else(); message(""Found liblzma library: ${LIBLZMA_LIBRARIES}""); message(""===========================================""); endif(). find_package(BZip2); if(NOT BZIP2_FOUND); message(""Will attempt to fetch and build libbz2""); message(""=======================================""); externalproject_add(libbz2; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://sourceware.org/pub/bzip2/bzip2-1.0.6.tar.gz -o bzip2-1.0.6.tar.gz &&; ${SHASUM} a2848f34fcd5d6cf47def00461fcb528a0484d8edef8208d6d2e2909dc61d9cd bzip2-1.0.6.tar.gz &&; tar -xzvf bzip2-1.0.6.tar.gz; #URL http://www.bzip.org/1.0.6/bzip2-1.0.6.tar.gz; #URL_HASH SHA1=3f89f861209ce81a6bab1fd1998c0ef311712002; SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/bzip2-1.0.6; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; BUILD_IN_SOURCE TRUE; CONFIGURE_COMMAND """"; BUILD_COMMAND make ${QUIET_MAKE} CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER}; INSTALL_COMMAND make ${QUIET_MAKE} install PREFIX=<INSTALL_DIR>; ); # Tell cmake that the external project generated a library so we can; # add dependencies here instead of later; set(BZIP2_LIBRARIES ${GAT_SOURCE_DIR}/external/install/lib/libbz2.a); set(LIBSTADEN_LDFLAGS ""-L${GAT_SOURCE_DIR}/external/install/lib -I${GAT_SOURCE_DIR}/external/install/include""); set(LIBSTADEN_CFLAGS ""-I${GAT_SOURCE_DIR}/external/install/include""); set(FETCHED_LIBBZ2 TRUE); else(); message(""Found libbz2 library: ${BZIP2_LIBRARIES}""); message(""===========================================""); endif(). ##; # Set the latest version and look for what we need; ##; set(Boost_ADDITIONAL_VERSIONS ""1.59.0"" ""1.60.0"" ""1.61.0"" ""1.62.0"" ""1.63.0"" ""1.64.0"" ""1.65.0"" ""1.66.0"" ""1.67.0"" ""1.68.0"" ""1.69.0"" ""1.70.0"" ""1.71.0"" ""1.72.0"" ""1.73.0"" ""1.74.0"" ""1.75.0"" ""1.76.0"" ""1.77.0"" ""1.78.0""); if (NOT BOOST_RECONFIGURE); find_package(Boost 1.59.0 COMPONENTS iostreams system filesystem timer chrono program_options); message(""BOOST_INCLUDEDIR = ${BOOST_INCLUDEDIR}"")",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:13722,Deployability,install,install,13722,"); set(FETCHED_LIBLZMA TRUE); else(); message(""Found liblzma library: ${LIBLZMA_LIBRARIES}""); message(""===========================================""); endif(). find_package(BZip2); if(NOT BZIP2_FOUND); message(""Will attempt to fetch and build libbz2""); message(""=======================================""); externalproject_add(libbz2; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://sourceware.org/pub/bzip2/bzip2-1.0.6.tar.gz -o bzip2-1.0.6.tar.gz &&; ${SHASUM} a2848f34fcd5d6cf47def00461fcb528a0484d8edef8208d6d2e2909dc61d9cd bzip2-1.0.6.tar.gz &&; tar -xzvf bzip2-1.0.6.tar.gz; #URL http://www.bzip.org/1.0.6/bzip2-1.0.6.tar.gz; #URL_HASH SHA1=3f89f861209ce81a6bab1fd1998c0ef311712002; SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/bzip2-1.0.6; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; BUILD_IN_SOURCE TRUE; CONFIGURE_COMMAND """"; BUILD_COMMAND make ${QUIET_MAKE} CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER}; INSTALL_COMMAND make ${QUIET_MAKE} install PREFIX=<INSTALL_DIR>; ); # Tell cmake that the external project generated a library so we can; # add dependencies here instead of later; set(BZIP2_LIBRARIES ${GAT_SOURCE_DIR}/external/install/lib/libbz2.a); set(LIBSTADEN_LDFLAGS ""-L${GAT_SOURCE_DIR}/external/install/lib -I${GAT_SOURCE_DIR}/external/install/include""); set(LIBSTADEN_CFLAGS ""-I${GAT_SOURCE_DIR}/external/install/include""); set(FETCHED_LIBBZ2 TRUE); else(); message(""Found libbz2 library: ${BZIP2_LIBRARIES}""); message(""===========================================""); endif(). ##; # Set the latest version and look for what we need; ##; set(Boost_ADDITIONAL_VERSIONS ""1.59.0"" ""1.60.0"" ""1.61.0"" ""1.62.0"" ""1.63.0"" ""1.64.0"" ""1.65.0"" ""1.66.0"" ""1.67.0"" ""1.68.0"" ""1.69.0"" ""1.70.0"" ""1.71.0"" ""1.72.0"" ""1.73.0"" ""1.74.0"" ""1.75.0"" ""1.76.0"" ""1.77.0"" ""1.78.0""); if (NOT BOOST_RECONFIGURE); find_package(Boost 1.59.0 COMPONENTS iostreams system filesystem timer chrono program_options); message(""BOOST_INCLUDEDIR = ${BOOST_INCLUDEDIR}"")",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:13914,Deployability,install,install,13914,"); set(FETCHED_LIBLZMA TRUE); else(); message(""Found liblzma library: ${LIBLZMA_LIBRARIES}""); message(""===========================================""); endif(). find_package(BZip2); if(NOT BZIP2_FOUND); message(""Will attempt to fetch and build libbz2""); message(""=======================================""); externalproject_add(libbz2; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://sourceware.org/pub/bzip2/bzip2-1.0.6.tar.gz -o bzip2-1.0.6.tar.gz &&; ${SHASUM} a2848f34fcd5d6cf47def00461fcb528a0484d8edef8208d6d2e2909dc61d9cd bzip2-1.0.6.tar.gz &&; tar -xzvf bzip2-1.0.6.tar.gz; #URL http://www.bzip.org/1.0.6/bzip2-1.0.6.tar.gz; #URL_HASH SHA1=3f89f861209ce81a6bab1fd1998c0ef311712002; SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/bzip2-1.0.6; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; BUILD_IN_SOURCE TRUE; CONFIGURE_COMMAND """"; BUILD_COMMAND make ${QUIET_MAKE} CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER}; INSTALL_COMMAND make ${QUIET_MAKE} install PREFIX=<INSTALL_DIR>; ); # Tell cmake that the external project generated a library so we can; # add dependencies here instead of later; set(BZIP2_LIBRARIES ${GAT_SOURCE_DIR}/external/install/lib/libbz2.a); set(LIBSTADEN_LDFLAGS ""-L${GAT_SOURCE_DIR}/external/install/lib -I${GAT_SOURCE_DIR}/external/install/include""); set(LIBSTADEN_CFLAGS ""-I${GAT_SOURCE_DIR}/external/install/include""); set(FETCHED_LIBBZ2 TRUE); else(); message(""Found libbz2 library: ${BZIP2_LIBRARIES}""); message(""===========================================""); endif(). ##; # Set the latest version and look for what we need; ##; set(Boost_ADDITIONAL_VERSIONS ""1.59.0"" ""1.60.0"" ""1.61.0"" ""1.62.0"" ""1.63.0"" ""1.64.0"" ""1.65.0"" ""1.66.0"" ""1.67.0"" ""1.68.0"" ""1.69.0"" ""1.70.0"" ""1.71.0"" ""1.72.0"" ""1.73.0"" ""1.74.0"" ""1.75.0"" ""1.76.0"" ""1.77.0"" ""1.78.0""); if (NOT BOOST_RECONFIGURE); find_package(Boost 1.59.0 COMPONENTS iostreams system filesystem timer chrono program_options); message(""BOOST_INCLUDEDIR = ${BOOST_INCLUDEDIR}"")",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:13989,Deployability,install,install,13989,"WNLOAD_COMMAND curl -k -L https://sourceware.org/pub/bzip2/bzip2-1.0.6.tar.gz -o bzip2-1.0.6.tar.gz &&; ${SHASUM} a2848f34fcd5d6cf47def00461fcb528a0484d8edef8208d6d2e2909dc61d9cd bzip2-1.0.6.tar.gz &&; tar -xzvf bzip2-1.0.6.tar.gz; #URL http://www.bzip.org/1.0.6/bzip2-1.0.6.tar.gz; #URL_HASH SHA1=3f89f861209ce81a6bab1fd1998c0ef311712002; SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/bzip2-1.0.6; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; BUILD_IN_SOURCE TRUE; CONFIGURE_COMMAND """"; BUILD_COMMAND make ${QUIET_MAKE} CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER}; INSTALL_COMMAND make ${QUIET_MAKE} install PREFIX=<INSTALL_DIR>; ); # Tell cmake that the external project generated a library so we can; # add dependencies here instead of later; set(BZIP2_LIBRARIES ${GAT_SOURCE_DIR}/external/install/lib/libbz2.a); set(LIBSTADEN_LDFLAGS ""-L${GAT_SOURCE_DIR}/external/install/lib -I${GAT_SOURCE_DIR}/external/install/include""); set(LIBSTADEN_CFLAGS ""-I${GAT_SOURCE_DIR}/external/install/include""); set(FETCHED_LIBBZ2 TRUE); else(); message(""Found libbz2 library: ${BZIP2_LIBRARIES}""); message(""===========================================""); endif(). ##; # Set the latest version and look for what we need; ##; set(Boost_ADDITIONAL_VERSIONS ""1.59.0"" ""1.60.0"" ""1.61.0"" ""1.62.0"" ""1.63.0"" ""1.64.0"" ""1.65.0"" ""1.66.0"" ""1.67.0"" ""1.68.0"" ""1.69.0"" ""1.70.0"" ""1.71.0"" ""1.72.0"" ""1.73.0"" ""1.74.0"" ""1.75.0"" ""1.76.0"" ""1.77.0"" ""1.78.0""); if (NOT BOOST_RECONFIGURE); find_package(Boost 1.59.0 COMPONENTS iostreams system filesystem timer chrono program_options); message(""BOOST_INCLUDEDIR = ${BOOST_INCLUDEDIR}""); message(""BOOST_LIBRARYDIR = ${BOOST_LIBRARYDIR}""); message(""Boost_FOUND = ${Boost_FOUND}""); endif(). include(ExternalProject). ##; # If we had to fetch Boost, the reconfigure step will re-run cmake. The second configuration; # pass is executed with the BOOST_RECONFIGURE flag set. This should allow our newly; # installed Boost to be found by CMake.; ##; if(BOOST_RECONFIGURE); messag",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:14030,Deployability,install,install,14030,"WNLOAD_COMMAND curl -k -L https://sourceware.org/pub/bzip2/bzip2-1.0.6.tar.gz -o bzip2-1.0.6.tar.gz &&; ${SHASUM} a2848f34fcd5d6cf47def00461fcb528a0484d8edef8208d6d2e2909dc61d9cd bzip2-1.0.6.tar.gz &&; tar -xzvf bzip2-1.0.6.tar.gz; #URL http://www.bzip.org/1.0.6/bzip2-1.0.6.tar.gz; #URL_HASH SHA1=3f89f861209ce81a6bab1fd1998c0ef311712002; SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/bzip2-1.0.6; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; BUILD_IN_SOURCE TRUE; CONFIGURE_COMMAND """"; BUILD_COMMAND make ${QUIET_MAKE} CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER}; INSTALL_COMMAND make ${QUIET_MAKE} install PREFIX=<INSTALL_DIR>; ); # Tell cmake that the external project generated a library so we can; # add dependencies here instead of later; set(BZIP2_LIBRARIES ${GAT_SOURCE_DIR}/external/install/lib/libbz2.a); set(LIBSTADEN_LDFLAGS ""-L${GAT_SOURCE_DIR}/external/install/lib -I${GAT_SOURCE_DIR}/external/install/include""); set(LIBSTADEN_CFLAGS ""-I${GAT_SOURCE_DIR}/external/install/include""); set(FETCHED_LIBBZ2 TRUE); else(); message(""Found libbz2 library: ${BZIP2_LIBRARIES}""); message(""===========================================""); endif(). ##; # Set the latest version and look for what we need; ##; set(Boost_ADDITIONAL_VERSIONS ""1.59.0"" ""1.60.0"" ""1.61.0"" ""1.62.0"" ""1.63.0"" ""1.64.0"" ""1.65.0"" ""1.66.0"" ""1.67.0"" ""1.68.0"" ""1.69.0"" ""1.70.0"" ""1.71.0"" ""1.72.0"" ""1.73.0"" ""1.74.0"" ""1.75.0"" ""1.76.0"" ""1.77.0"" ""1.78.0""); if (NOT BOOST_RECONFIGURE); find_package(Boost 1.59.0 COMPONENTS iostreams system filesystem timer chrono program_options); message(""BOOST_INCLUDEDIR = ${BOOST_INCLUDEDIR}""); message(""BOOST_LIBRARYDIR = ${BOOST_LIBRARYDIR}""); message(""Boost_FOUND = ${Boost_FOUND}""); endif(). include(ExternalProject). ##; # If we had to fetch Boost, the reconfigure step will re-run cmake. The second configuration; # pass is executed with the BOOST_RECONFIGURE flag set. This should allow our newly; # installed Boost to be found by CMake.; ##; if(BOOST_RECONFIGURE); messag",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:14100,Deployability,install,install,14100,"WNLOAD_COMMAND curl -k -L https://sourceware.org/pub/bzip2/bzip2-1.0.6.tar.gz -o bzip2-1.0.6.tar.gz &&; ${SHASUM} a2848f34fcd5d6cf47def00461fcb528a0484d8edef8208d6d2e2909dc61d9cd bzip2-1.0.6.tar.gz &&; tar -xzvf bzip2-1.0.6.tar.gz; #URL http://www.bzip.org/1.0.6/bzip2-1.0.6.tar.gz; #URL_HASH SHA1=3f89f861209ce81a6bab1fd1998c0ef311712002; SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/bzip2-1.0.6; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; BUILD_IN_SOURCE TRUE; CONFIGURE_COMMAND """"; BUILD_COMMAND make ${QUIET_MAKE} CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER}; INSTALL_COMMAND make ${QUIET_MAKE} install PREFIX=<INSTALL_DIR>; ); # Tell cmake that the external project generated a library so we can; # add dependencies here instead of later; set(BZIP2_LIBRARIES ${GAT_SOURCE_DIR}/external/install/lib/libbz2.a); set(LIBSTADEN_LDFLAGS ""-L${GAT_SOURCE_DIR}/external/install/lib -I${GAT_SOURCE_DIR}/external/install/include""); set(LIBSTADEN_CFLAGS ""-I${GAT_SOURCE_DIR}/external/install/include""); set(FETCHED_LIBBZ2 TRUE); else(); message(""Found libbz2 library: ${BZIP2_LIBRARIES}""); message(""===========================================""); endif(). ##; # Set the latest version and look for what we need; ##; set(Boost_ADDITIONAL_VERSIONS ""1.59.0"" ""1.60.0"" ""1.61.0"" ""1.62.0"" ""1.63.0"" ""1.64.0"" ""1.65.0"" ""1.66.0"" ""1.67.0"" ""1.68.0"" ""1.69.0"" ""1.70.0"" ""1.71.0"" ""1.72.0"" ""1.73.0"" ""1.74.0"" ""1.75.0"" ""1.76.0"" ""1.77.0"" ""1.78.0""); if (NOT BOOST_RECONFIGURE); find_package(Boost 1.59.0 COMPONENTS iostreams system filesystem timer chrono program_options); message(""BOOST_INCLUDEDIR = ${BOOST_INCLUDEDIR}""); message(""BOOST_LIBRARYDIR = ${BOOST_LIBRARYDIR}""); message(""Boost_FOUND = ${Boost_FOUND}""); endif(). include(ExternalProject). ##; # If we had to fetch Boost, the reconfigure step will re-run cmake. The second configuration; # pass is executed with the BOOST_RECONFIGURE flag set. This should allow our newly; # installed Boost to be found by CMake.; ##; if(BOOST_RECONFIGURE); messag",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:14928,Deployability,configurat,configuration,14928,"S ""-L${GAT_SOURCE_DIR}/external/install/lib -I${GAT_SOURCE_DIR}/external/install/include""); set(LIBSTADEN_CFLAGS ""-I${GAT_SOURCE_DIR}/external/install/include""); set(FETCHED_LIBBZ2 TRUE); else(); message(""Found libbz2 library: ${BZIP2_LIBRARIES}""); message(""===========================================""); endif(). ##; # Set the latest version and look for what we need; ##; set(Boost_ADDITIONAL_VERSIONS ""1.59.0"" ""1.60.0"" ""1.61.0"" ""1.62.0"" ""1.63.0"" ""1.64.0"" ""1.65.0"" ""1.66.0"" ""1.67.0"" ""1.68.0"" ""1.69.0"" ""1.70.0"" ""1.71.0"" ""1.72.0"" ""1.73.0"" ""1.74.0"" ""1.75.0"" ""1.76.0"" ""1.77.0"" ""1.78.0""); if (NOT BOOST_RECONFIGURE); find_package(Boost 1.59.0 COMPONENTS iostreams system filesystem timer chrono program_options); message(""BOOST_INCLUDEDIR = ${BOOST_INCLUDEDIR}""); message(""BOOST_LIBRARYDIR = ${BOOST_LIBRARYDIR}""); message(""Boost_FOUND = ${Boost_FOUND}""); endif(). include(ExternalProject). ##; # If we had to fetch Boost, the reconfigure step will re-run cmake. The second configuration; # pass is executed with the BOOST_RECONFIGURE flag set. This should allow our newly; # installed Boost to be found by CMake.; ##; if(BOOST_RECONFIGURE); message(""Executing Boost Reconfiguration""); unset(Boost_FOUND CACHE); unset(Boost_INCLUDE_DIR CACHE); unset(Boost_INCLUDE_DIRS CACHE); unset(Boost_LIBRARY_DIRS CACHE); unset(Boost_LIBRARIES CACHE); unset(BOOST_ROOT CACHE); unset(CMAKE_PREFIX_PATH CACHE); unset(Boost::diagnostic_definitions CACHE); unset(Boost::disable_autolinking CACHE); unset(Boost::dynamic_linking CACHE); set(BOOST_ROOT ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(CMAKE_PREFIX_PATH ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(Boost_INCLUDE_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/include); set(Boost_LIBRARY_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/lib); find_package(Boost 1.59.0 COMPONENTS iostreams system filesystem timer chrono program_options locale REQUIRED); set(FETCH_BOOST FALSE); endif(). ##; # Either inform the user of how to obtain Boost, or,",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:15030,Deployability,install,installed,15030,"stall/include""); set(LIBSTADEN_CFLAGS ""-I${GAT_SOURCE_DIR}/external/install/include""); set(FETCHED_LIBBZ2 TRUE); else(); message(""Found libbz2 library: ${BZIP2_LIBRARIES}""); message(""===========================================""); endif(). ##; # Set the latest version and look for what we need; ##; set(Boost_ADDITIONAL_VERSIONS ""1.59.0"" ""1.60.0"" ""1.61.0"" ""1.62.0"" ""1.63.0"" ""1.64.0"" ""1.65.0"" ""1.66.0"" ""1.67.0"" ""1.68.0"" ""1.69.0"" ""1.70.0"" ""1.71.0"" ""1.72.0"" ""1.73.0"" ""1.74.0"" ""1.75.0"" ""1.76.0"" ""1.77.0"" ""1.78.0""); if (NOT BOOST_RECONFIGURE); find_package(Boost 1.59.0 COMPONENTS iostreams system filesystem timer chrono program_options); message(""BOOST_INCLUDEDIR = ${BOOST_INCLUDEDIR}""); message(""BOOST_LIBRARYDIR = ${BOOST_LIBRARYDIR}""); message(""Boost_FOUND = ${Boost_FOUND}""); endif(). include(ExternalProject). ##; # If we had to fetch Boost, the reconfigure step will re-run cmake. The second configuration; # pass is executed with the BOOST_RECONFIGURE flag set. This should allow our newly; # installed Boost to be found by CMake.; ##; if(BOOST_RECONFIGURE); message(""Executing Boost Reconfiguration""); unset(Boost_FOUND CACHE); unset(Boost_INCLUDE_DIR CACHE); unset(Boost_INCLUDE_DIRS CACHE); unset(Boost_LIBRARY_DIRS CACHE); unset(Boost_LIBRARIES CACHE); unset(BOOST_ROOT CACHE); unset(CMAKE_PREFIX_PATH CACHE); unset(Boost::diagnostic_definitions CACHE); unset(Boost::disable_autolinking CACHE); unset(Boost::dynamic_linking CACHE); set(BOOST_ROOT ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(CMAKE_PREFIX_PATH ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(Boost_INCLUDE_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/include); set(Boost_LIBRARY_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/lib); find_package(Boost 1.59.0 COMPONENTS iostreams system filesystem timer chrono program_options locale REQUIRED); set(FETCH_BOOST FALSE); endif(). ##; # Either inform the user of how to obtain Boost, or, if they passed in the FETCH_BOOST; # option, go and grab it for them.; ##; ",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:15525,Deployability,install,install,15525,""" ""1.66.0"" ""1.67.0"" ""1.68.0"" ""1.69.0"" ""1.70.0"" ""1.71.0"" ""1.72.0"" ""1.73.0"" ""1.74.0"" ""1.75.0"" ""1.76.0"" ""1.77.0"" ""1.78.0""); if (NOT BOOST_RECONFIGURE); find_package(Boost 1.59.0 COMPONENTS iostreams system filesystem timer chrono program_options); message(""BOOST_INCLUDEDIR = ${BOOST_INCLUDEDIR}""); message(""BOOST_LIBRARYDIR = ${BOOST_LIBRARYDIR}""); message(""Boost_FOUND = ${Boost_FOUND}""); endif(). include(ExternalProject). ##; # If we had to fetch Boost, the reconfigure step will re-run cmake. The second configuration; # pass is executed with the BOOST_RECONFIGURE flag set. This should allow our newly; # installed Boost to be found by CMake.; ##; if(BOOST_RECONFIGURE); message(""Executing Boost Reconfiguration""); unset(Boost_FOUND CACHE); unset(Boost_INCLUDE_DIR CACHE); unset(Boost_INCLUDE_DIRS CACHE); unset(Boost_LIBRARY_DIRS CACHE); unset(Boost_LIBRARIES CACHE); unset(BOOST_ROOT CACHE); unset(CMAKE_PREFIX_PATH CACHE); unset(Boost::diagnostic_definitions CACHE); unset(Boost::disable_autolinking CACHE); unset(Boost::dynamic_linking CACHE); set(BOOST_ROOT ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(CMAKE_PREFIX_PATH ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(Boost_INCLUDE_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/include); set(Boost_LIBRARY_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/lib); find_package(Boost 1.59.0 COMPONENTS iostreams system filesystem timer chrono program_options locale REQUIRED); set(FETCH_BOOST FALSE); endif(). ##; # Either inform the user of how to obtain Boost, or, if they passed in the FETCH_BOOST; # option, go and grab it for them.; ##; if((NOT Boost_FOUND) AND (NOT FETCH_BOOST)); message(FATAL_ERROR; ""Salmon cannot be compiled without Boost.\n""; ""It is recommended to visit http://www.boost.org/ and install Boost according to those instructions.\n""; ""This build system can also download and install a local version of boost for you (this takes a lot of time).\n""; ""To fetch and build boost locally, call cmake with -DFETCH",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:15594,Deployability,install,install,15594,""" ""1.66.0"" ""1.67.0"" ""1.68.0"" ""1.69.0"" ""1.70.0"" ""1.71.0"" ""1.72.0"" ""1.73.0"" ""1.74.0"" ""1.75.0"" ""1.76.0"" ""1.77.0"" ""1.78.0""); if (NOT BOOST_RECONFIGURE); find_package(Boost 1.59.0 COMPONENTS iostreams system filesystem timer chrono program_options); message(""BOOST_INCLUDEDIR = ${BOOST_INCLUDEDIR}""); message(""BOOST_LIBRARYDIR = ${BOOST_LIBRARYDIR}""); message(""Boost_FOUND = ${Boost_FOUND}""); endif(). include(ExternalProject). ##; # If we had to fetch Boost, the reconfigure step will re-run cmake. The second configuration; # pass is executed with the BOOST_RECONFIGURE flag set. This should allow our newly; # installed Boost to be found by CMake.; ##; if(BOOST_RECONFIGURE); message(""Executing Boost Reconfiguration""); unset(Boost_FOUND CACHE); unset(Boost_INCLUDE_DIR CACHE); unset(Boost_INCLUDE_DIRS CACHE); unset(Boost_LIBRARY_DIRS CACHE); unset(Boost_LIBRARIES CACHE); unset(BOOST_ROOT CACHE); unset(CMAKE_PREFIX_PATH CACHE); unset(Boost::diagnostic_definitions CACHE); unset(Boost::disable_autolinking CACHE); unset(Boost::dynamic_linking CACHE); set(BOOST_ROOT ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(CMAKE_PREFIX_PATH ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(Boost_INCLUDE_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/include); set(Boost_LIBRARY_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/lib); find_package(Boost 1.59.0 COMPONENTS iostreams system filesystem timer chrono program_options locale REQUIRED); set(FETCH_BOOST FALSE); endif(). ##; # Either inform the user of how to obtain Boost, or, if they passed in the FETCH_BOOST; # option, go and grab it for them.; ##; if((NOT Boost_FOUND) AND (NOT FETCH_BOOST)); message(FATAL_ERROR; ""Salmon cannot be compiled without Boost.\n""; ""It is recommended to visit http://www.boost.org/ and install Boost according to those instructions.\n""; ""This build system can also download and install a local version of boost for you (this takes a lot of time).\n""; ""To fetch and build boost locally, call cmake with -DFETCH",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:15664,Deployability,install,install,15664,""" ""1.66.0"" ""1.67.0"" ""1.68.0"" ""1.69.0"" ""1.70.0"" ""1.71.0"" ""1.72.0"" ""1.73.0"" ""1.74.0"" ""1.75.0"" ""1.76.0"" ""1.77.0"" ""1.78.0""); if (NOT BOOST_RECONFIGURE); find_package(Boost 1.59.0 COMPONENTS iostreams system filesystem timer chrono program_options); message(""BOOST_INCLUDEDIR = ${BOOST_INCLUDEDIR}""); message(""BOOST_LIBRARYDIR = ${BOOST_LIBRARYDIR}""); message(""Boost_FOUND = ${Boost_FOUND}""); endif(). include(ExternalProject). ##; # If we had to fetch Boost, the reconfigure step will re-run cmake. The second configuration; # pass is executed with the BOOST_RECONFIGURE flag set. This should allow our newly; # installed Boost to be found by CMake.; ##; if(BOOST_RECONFIGURE); message(""Executing Boost Reconfiguration""); unset(Boost_FOUND CACHE); unset(Boost_INCLUDE_DIR CACHE); unset(Boost_INCLUDE_DIRS CACHE); unset(Boost_LIBRARY_DIRS CACHE); unset(Boost_LIBRARIES CACHE); unset(BOOST_ROOT CACHE); unset(CMAKE_PREFIX_PATH CACHE); unset(Boost::diagnostic_definitions CACHE); unset(Boost::disable_autolinking CACHE); unset(Boost::dynamic_linking CACHE); set(BOOST_ROOT ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(CMAKE_PREFIX_PATH ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(Boost_INCLUDE_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/include); set(Boost_LIBRARY_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/lib); find_package(Boost 1.59.0 COMPONENTS iostreams system filesystem timer chrono program_options locale REQUIRED); set(FETCH_BOOST FALSE); endif(). ##; # Either inform the user of how to obtain Boost, or, if they passed in the FETCH_BOOST; # option, go and grab it for them.; ##; if((NOT Boost_FOUND) AND (NOT FETCH_BOOST)); message(FATAL_ERROR; ""Salmon cannot be compiled without Boost.\n""; ""It is recommended to visit http://www.boost.org/ and install Boost according to those instructions.\n""; ""This build system can also download and install a local version of boost for you (this takes a lot of time).\n""; ""To fetch and build boost locally, call cmake with -DFETCH",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:15742,Deployability,install,install,15742,""" ""1.66.0"" ""1.67.0"" ""1.68.0"" ""1.69.0"" ""1.70.0"" ""1.71.0"" ""1.72.0"" ""1.73.0"" ""1.74.0"" ""1.75.0"" ""1.76.0"" ""1.77.0"" ""1.78.0""); if (NOT BOOST_RECONFIGURE); find_package(Boost 1.59.0 COMPONENTS iostreams system filesystem timer chrono program_options); message(""BOOST_INCLUDEDIR = ${BOOST_INCLUDEDIR}""); message(""BOOST_LIBRARYDIR = ${BOOST_LIBRARYDIR}""); message(""Boost_FOUND = ${Boost_FOUND}""); endif(). include(ExternalProject). ##; # If we had to fetch Boost, the reconfigure step will re-run cmake. The second configuration; # pass is executed with the BOOST_RECONFIGURE flag set. This should allow our newly; # installed Boost to be found by CMake.; ##; if(BOOST_RECONFIGURE); message(""Executing Boost Reconfiguration""); unset(Boost_FOUND CACHE); unset(Boost_INCLUDE_DIR CACHE); unset(Boost_INCLUDE_DIRS CACHE); unset(Boost_LIBRARY_DIRS CACHE); unset(Boost_LIBRARIES CACHE); unset(BOOST_ROOT CACHE); unset(CMAKE_PREFIX_PATH CACHE); unset(Boost::diagnostic_definitions CACHE); unset(Boost::disable_autolinking CACHE); unset(Boost::dynamic_linking CACHE); set(BOOST_ROOT ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(CMAKE_PREFIX_PATH ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(Boost_INCLUDE_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/include); set(Boost_LIBRARY_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/lib); find_package(Boost 1.59.0 COMPONENTS iostreams system filesystem timer chrono program_options locale REQUIRED); set(FETCH_BOOST FALSE); endif(). ##; # Either inform the user of how to obtain Boost, or, if they passed in the FETCH_BOOST; # option, go and grab it for them.; ##; if((NOT Boost_FOUND) AND (NOT FETCH_BOOST)); message(FATAL_ERROR; ""Salmon cannot be compiled without Boost.\n""; ""It is recommended to visit http://www.boost.org/ and install Boost according to those instructions.\n""; ""This build system can also download and install a local version of boost for you (this takes a lot of time).\n""; ""To fetch and build boost locally, call cmake with -DFETCH",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:16199,Deployability,install,install,16199,"_DIRS CACHE); unset(Boost_LIBRARY_DIRS CACHE); unset(Boost_LIBRARIES CACHE); unset(BOOST_ROOT CACHE); unset(CMAKE_PREFIX_PATH CACHE); unset(Boost::diagnostic_definitions CACHE); unset(Boost::disable_autolinking CACHE); unset(Boost::dynamic_linking CACHE); set(BOOST_ROOT ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(CMAKE_PREFIX_PATH ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(Boost_INCLUDE_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/include); set(Boost_LIBRARY_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/lib); find_package(Boost 1.59.0 COMPONENTS iostreams system filesystem timer chrono program_options locale REQUIRED); set(FETCH_BOOST FALSE); endif(). ##; # Either inform the user of how to obtain Boost, or, if they passed in the FETCH_BOOST; # option, go and grab it for them.; ##; if((NOT Boost_FOUND) AND (NOT FETCH_BOOST)); message(FATAL_ERROR; ""Salmon cannot be compiled without Boost.\n""; ""It is recommended to visit http://www.boost.org/ and install Boost according to those instructions.\n""; ""This build system can also download and install a local version of boost for you (this takes a lot of time).\n""; ""To fetch and build boost locally, call cmake with -DFETCH_BOOST=TRUE""; ); elseif(FETCH_BOOST); if(NOT DEFINED BOOST_BUILD_THREADS); set(BOOST_BUILD_THREADS 2); endif(). ## Let the rest of the build process know we're going to be fetching boost; set(BOOST_LIB_SUBSET --with-iostreams --with-atomic --with-chrono --with-container --with-date_time --with-exception; --with-filesystem --with-graph --with-graph_parallel --with-math; --with-program_options --with-system --with-locale; --with-timer); set(BOOST_WILL_RECONFIGURE TRUE); set(FETCH_BOOST FALSE); set(BOOST_FETCHED_VERSION ""1_72_0""); message(""Build system will fetch and build Boost""); message(""==================================================================""); externalproject_add(libboost; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://sourceforge.ne",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:16291,Deployability,install,install,16291,"OST_ROOT CACHE); unset(CMAKE_PREFIX_PATH CACHE); unset(Boost::diagnostic_definitions CACHE); unset(Boost::disable_autolinking CACHE); unset(Boost::dynamic_linking CACHE); set(BOOST_ROOT ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(CMAKE_PREFIX_PATH ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(Boost_INCLUDE_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/include); set(Boost_LIBRARY_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/lib); find_package(Boost 1.59.0 COMPONENTS iostreams system filesystem timer chrono program_options locale REQUIRED); set(FETCH_BOOST FALSE); endif(). ##; # Either inform the user of how to obtain Boost, or, if they passed in the FETCH_BOOST; # option, go and grab it for them.; ##; if((NOT Boost_FOUND) AND (NOT FETCH_BOOST)); message(FATAL_ERROR; ""Salmon cannot be compiled without Boost.\n""; ""It is recommended to visit http://www.boost.org/ and install Boost according to those instructions.\n""; ""This build system can also download and install a local version of boost for you (this takes a lot of time).\n""; ""To fetch and build boost locally, call cmake with -DFETCH_BOOST=TRUE""; ); elseif(FETCH_BOOST); if(NOT DEFINED BOOST_BUILD_THREADS); set(BOOST_BUILD_THREADS 2); endif(). ## Let the rest of the build process know we're going to be fetching boost; set(BOOST_LIB_SUBSET --with-iostreams --with-atomic --with-chrono --with-container --with-date_time --with-exception; --with-filesystem --with-graph --with-graph_parallel --with-math; --with-program_options --with-system --with-locale; --with-timer); set(BOOST_WILL_RECONFIGURE TRUE); set(FETCH_BOOST FALSE); set(BOOST_FETCHED_VERSION ""1_72_0""); message(""Build system will fetch and build Boost""); message(""==================================================================""); externalproject_add(libboost; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://sourceforge.net/projects/boost/files/boost/1.72.0/boost_1_72_0.tar.gz/download -o boost_1_72_0.tar",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:17704,Deployability,install,install,17704,"with-container --with-date_time --with-exception; --with-filesystem --with-graph --with-graph_parallel --with-math; --with-program_options --with-system --with-locale; --with-timer); set(BOOST_WILL_RECONFIGURE TRUE); set(FETCH_BOOST FALSE); set(BOOST_FETCHED_VERSION ""1_72_0""); message(""Build system will fetch and build Boost""); message(""==================================================================""); externalproject_add(libboost; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://sourceforge.net/projects/boost/files/boost/1.72.0/boost_1_72_0.tar.gz/download -o boost_1_72_0.tar.gz &&; #${SHASUM} 96b34f7468f26a141f6020efb813f1a2f3dfb9797ecf76a7d7cbd843cc95f5bd boost_1_71_0.tar.gz &&; ${SHASUM} c66e88d5786f2ca4dbebb14e06b566fb642a1a6947ad8cc9091f9f445134143f boost_${BOOST_FETCHED_VERSION}.tar.gz &&; tar xzf boost_${BOOST_FETCHED_VERSION}.tar.gz ; SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/boost_${BOOST_FETCHED_VERSION}; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; #PATCH_COMMAND patch -p2 < ${CMAKE_CURRENT_SOURCE_DIR}/external/boost156.patch; CONFIGURE_COMMAND CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER} ${CMAKE_CURRENT_SOURCE_DIR}/external/boost_${BOOST_FETCHED_VERSION}/bootstrap.sh ${BOOST_CONFIGURE_TOOLSET} ${BOOST_BUILD_LIBS} --prefix=<INSTALL_DIR>; add_custom_command(; OUTPUT ${CMAKE_CURRENT_SOURCE_DIR}/external/boost_${BOOST_FETCHED_VERSION}/tools/build/src/user-config.jam; PRE_BUILD; COMMAND echo ""using gcc : ${CC_VERSION} : ${CMAKE_CXX_COMPILER} ;""; ); BUILD_COMMAND CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER} ${CMAKE_CURRENT_SOURCE_DIR}/external/boost_${BOOST_FETCHED_VERSION}/b2 -d0 -j${BOOST_BUILD_THREADS} ${BOOST_LIB_SUBSET} toolset=${BOOST_TOOLSET} ${BOOST_EXTRA_FLAGS} cxxflags=${BOOST_CXX_FLAGS} link=static install; BUILD_IN_SOURCE 1; INSTALL_COMMAND """"; ). externalproject_add_step(libboost makedir; COMMAND mkdir -p <SOURCE_DIR>/build; COMMENT ""Make build directory""; DEPENDEES download; DEP",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:17728,Deployability,patch,patch,17728,"with-container --with-date_time --with-exception; --with-filesystem --with-graph --with-graph_parallel --with-math; --with-program_options --with-system --with-locale; --with-timer); set(BOOST_WILL_RECONFIGURE TRUE); set(FETCH_BOOST FALSE); set(BOOST_FETCHED_VERSION ""1_72_0""); message(""Build system will fetch and build Boost""); message(""==================================================================""); externalproject_add(libboost; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://sourceforge.net/projects/boost/files/boost/1.72.0/boost_1_72_0.tar.gz/download -o boost_1_72_0.tar.gz &&; #${SHASUM} 96b34f7468f26a141f6020efb813f1a2f3dfb9797ecf76a7d7cbd843cc95f5bd boost_1_71_0.tar.gz &&; ${SHASUM} c66e88d5786f2ca4dbebb14e06b566fb642a1a6947ad8cc9091f9f445134143f boost_${BOOST_FETCHED_VERSION}.tar.gz &&; tar xzf boost_${BOOST_FETCHED_VERSION}.tar.gz ; SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/boost_${BOOST_FETCHED_VERSION}; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; #PATCH_COMMAND patch -p2 < ${CMAKE_CURRENT_SOURCE_DIR}/external/boost156.patch; CONFIGURE_COMMAND CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER} ${CMAKE_CURRENT_SOURCE_DIR}/external/boost_${BOOST_FETCHED_VERSION}/bootstrap.sh ${BOOST_CONFIGURE_TOOLSET} ${BOOST_BUILD_LIBS} --prefix=<INSTALL_DIR>; add_custom_command(; OUTPUT ${CMAKE_CURRENT_SOURCE_DIR}/external/boost_${BOOST_FETCHED_VERSION}/tools/build/src/user-config.jam; PRE_BUILD; COMMAND echo ""using gcc : ${CC_VERSION} : ${CMAKE_CXX_COMPILER} ;""; ); BUILD_COMMAND CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER} ${CMAKE_CURRENT_SOURCE_DIR}/external/boost_${BOOST_FETCHED_VERSION}/b2 -d0 -j${BOOST_BUILD_THREADS} ${BOOST_LIB_SUBSET} toolset=${BOOST_TOOLSET} ${BOOST_EXTRA_FLAGS} cxxflags=${BOOST_CXX_FLAGS} link=static install; BUILD_IN_SOURCE 1; INSTALL_COMMAND """"; ). externalproject_add_step(libboost makedir; COMMAND mkdir -p <SOURCE_DIR>/build; COMMENT ""Make build directory""; DEPENDEES download; DEP",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:17786,Deployability,patch,patch,17786,"et(BOOST_WILL_RECONFIGURE TRUE); set(FETCH_BOOST FALSE); set(BOOST_FETCHED_VERSION ""1_72_0""); message(""Build system will fetch and build Boost""); message(""==================================================================""); externalproject_add(libboost; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://sourceforge.net/projects/boost/files/boost/1.72.0/boost_1_72_0.tar.gz/download -o boost_1_72_0.tar.gz &&; #${SHASUM} 96b34f7468f26a141f6020efb813f1a2f3dfb9797ecf76a7d7cbd843cc95f5bd boost_1_71_0.tar.gz &&; ${SHASUM} c66e88d5786f2ca4dbebb14e06b566fb642a1a6947ad8cc9091f9f445134143f boost_${BOOST_FETCHED_VERSION}.tar.gz &&; tar xzf boost_${BOOST_FETCHED_VERSION}.tar.gz ; SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/boost_${BOOST_FETCHED_VERSION}; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; #PATCH_COMMAND patch -p2 < ${CMAKE_CURRENT_SOURCE_DIR}/external/boost156.patch; CONFIGURE_COMMAND CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER} ${CMAKE_CURRENT_SOURCE_DIR}/external/boost_${BOOST_FETCHED_VERSION}/bootstrap.sh ${BOOST_CONFIGURE_TOOLSET} ${BOOST_BUILD_LIBS} --prefix=<INSTALL_DIR>; add_custom_command(; OUTPUT ${CMAKE_CURRENT_SOURCE_DIR}/external/boost_${BOOST_FETCHED_VERSION}/tools/build/src/user-config.jam; PRE_BUILD; COMMAND echo ""using gcc : ${CC_VERSION} : ${CMAKE_CXX_COMPILER} ;""; ); BUILD_COMMAND CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER} ${CMAKE_CURRENT_SOURCE_DIR}/external/boost_${BOOST_FETCHED_VERSION}/b2 -d0 -j${BOOST_BUILD_THREADS} ${BOOST_LIB_SUBSET} toolset=${BOOST_TOOLSET} ${BOOST_EXTRA_FLAGS} cxxflags=${BOOST_CXX_FLAGS} link=static install; BUILD_IN_SOURCE 1; INSTALL_COMMAND """"; ). externalproject_add_step(libboost makedir; COMMAND mkdir -p <SOURCE_DIR>/build; COMMENT ""Make build directory""; DEPENDEES download; DEPENDERS configure). ##; # After we've installed boost,; ##; set(RECONFIG_FLAGS ${RECONFIG_FLAGS} -DBOOST_WILL_RECONFIGURE=FALSE -DBOOST_RECONFIGURE=TRUE -DFETCH_BOOST=FALSE); externalpr",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:18492,Deployability,install,install,18492,"6020efb813f1a2f3dfb9797ecf76a7d7cbd843cc95f5bd boost_1_71_0.tar.gz &&; ${SHASUM} c66e88d5786f2ca4dbebb14e06b566fb642a1a6947ad8cc9091f9f445134143f boost_${BOOST_FETCHED_VERSION}.tar.gz &&; tar xzf boost_${BOOST_FETCHED_VERSION}.tar.gz ; SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/boost_${BOOST_FETCHED_VERSION}; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; #PATCH_COMMAND patch -p2 < ${CMAKE_CURRENT_SOURCE_DIR}/external/boost156.patch; CONFIGURE_COMMAND CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER} ${CMAKE_CURRENT_SOURCE_DIR}/external/boost_${BOOST_FETCHED_VERSION}/bootstrap.sh ${BOOST_CONFIGURE_TOOLSET} ${BOOST_BUILD_LIBS} --prefix=<INSTALL_DIR>; add_custom_command(; OUTPUT ${CMAKE_CURRENT_SOURCE_DIR}/external/boost_${BOOST_FETCHED_VERSION}/tools/build/src/user-config.jam; PRE_BUILD; COMMAND echo ""using gcc : ${CC_VERSION} : ${CMAKE_CXX_COMPILER} ;""; ); BUILD_COMMAND CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER} ${CMAKE_CURRENT_SOURCE_DIR}/external/boost_${BOOST_FETCHED_VERSION}/b2 -d0 -j${BOOST_BUILD_THREADS} ${BOOST_LIB_SUBSET} toolset=${BOOST_TOOLSET} ${BOOST_EXTRA_FLAGS} cxxflags=${BOOST_CXX_FLAGS} link=static install; BUILD_IN_SOURCE 1; INSTALL_COMMAND """"; ). externalproject_add_step(libboost makedir; COMMAND mkdir -p <SOURCE_DIR>/build; COMMENT ""Make build directory""; DEPENDEES download; DEPENDERS configure). ##; # After we've installed boost,; ##; set(RECONFIG_FLAGS ${RECONFIG_FLAGS} -DBOOST_WILL_RECONFIGURE=FALSE -DBOOST_RECONFIGURE=TRUE -DFETCH_BOOST=FALSE); externalproject_add_step(libboost reconfigure; COMMAND ${CMAKE_COMMAND} ${CMAKE_CURRENT_SOURCE_DIR} ${RECONFIG_FLAGS}; DEPENDEES install; ); set(FETCHED_BOOST TRUE); endif(). ##; # If we're fetching boost and we need to have dummy paths for these variables; # so that CMake won't complain; ##; if(BOOST_WILL_RECONFIGURE); message(""Setting Temporary Boost paths""); set(Boost_INCLUDE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install/include); set(Boost_INCLUDE_DIRS ${CMAKE_CURRENT_SOURCE_",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:18715,Deployability,install,installed,18715,"{CMAKE_CURRENT_SOURCE_DIR}/external/boost_${BOOST_FETCHED_VERSION}/bootstrap.sh ${BOOST_CONFIGURE_TOOLSET} ${BOOST_BUILD_LIBS} --prefix=<INSTALL_DIR>; add_custom_command(; OUTPUT ${CMAKE_CURRENT_SOURCE_DIR}/external/boost_${BOOST_FETCHED_VERSION}/tools/build/src/user-config.jam; PRE_BUILD; COMMAND echo ""using gcc : ${CC_VERSION} : ${CMAKE_CXX_COMPILER} ;""; ); BUILD_COMMAND CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER} ${CMAKE_CURRENT_SOURCE_DIR}/external/boost_${BOOST_FETCHED_VERSION}/b2 -d0 -j${BOOST_BUILD_THREADS} ${BOOST_LIB_SUBSET} toolset=${BOOST_TOOLSET} ${BOOST_EXTRA_FLAGS} cxxflags=${BOOST_CXX_FLAGS} link=static install; BUILD_IN_SOURCE 1; INSTALL_COMMAND """"; ). externalproject_add_step(libboost makedir; COMMAND mkdir -p <SOURCE_DIR>/build; COMMENT ""Make build directory""; DEPENDEES download; DEPENDERS configure). ##; # After we've installed boost,; ##; set(RECONFIG_FLAGS ${RECONFIG_FLAGS} -DBOOST_WILL_RECONFIGURE=FALSE -DBOOST_RECONFIGURE=TRUE -DFETCH_BOOST=FALSE); externalproject_add_step(libboost reconfigure; COMMAND ${CMAKE_COMMAND} ${CMAKE_CURRENT_SOURCE_DIR} ${RECONFIG_FLAGS}; DEPENDEES install; ); set(FETCHED_BOOST TRUE); endif(). ##; # If we're fetching boost and we need to have dummy paths for these variables; # so that CMake won't complain; ##; if(BOOST_WILL_RECONFIGURE); message(""Setting Temporary Boost paths""); set(Boost_INCLUDE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install/include); set(Boost_INCLUDE_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/include); set(Boost_LIBRARY_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/lib); set(Boost_FOUND TRUE); endif(). message(""BOOST ROOT = ${BOOST_ROOT}""); message(""BOOST INCLUDE DIR = ${Boost_INCLUDE_DIR}""); message(""BOOST INCLUDE DIRS = ${Boost_INCLUDE_DIRS}""); message(""BOOST LIB DIR = ${Boost_LIBRARY_DIRS}""); message(""BOOST LIBRARIES = ${Boost_LIBRARIES}""). set(EXTERNAL_LIBRARY_PATH $CMAKE_CURRENT_SOURCE_DIR/lib). #find_package(libdivsufsort); #if(NOT LIBDIVSUFSORT_FOUND); # message(""Build sys",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:18981,Deployability,install,install,18981,"{CMAKE_CURRENT_SOURCE_DIR}/external/boost_${BOOST_FETCHED_VERSION}/bootstrap.sh ${BOOST_CONFIGURE_TOOLSET} ${BOOST_BUILD_LIBS} --prefix=<INSTALL_DIR>; add_custom_command(; OUTPUT ${CMAKE_CURRENT_SOURCE_DIR}/external/boost_${BOOST_FETCHED_VERSION}/tools/build/src/user-config.jam; PRE_BUILD; COMMAND echo ""using gcc : ${CC_VERSION} : ${CMAKE_CXX_COMPILER} ;""; ); BUILD_COMMAND CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER} ${CMAKE_CURRENT_SOURCE_DIR}/external/boost_${BOOST_FETCHED_VERSION}/b2 -d0 -j${BOOST_BUILD_THREADS} ${BOOST_LIB_SUBSET} toolset=${BOOST_TOOLSET} ${BOOST_EXTRA_FLAGS} cxxflags=${BOOST_CXX_FLAGS} link=static install; BUILD_IN_SOURCE 1; INSTALL_COMMAND """"; ). externalproject_add_step(libboost makedir; COMMAND mkdir -p <SOURCE_DIR>/build; COMMENT ""Make build directory""; DEPENDEES download; DEPENDERS configure). ##; # After we've installed boost,; ##; set(RECONFIG_FLAGS ${RECONFIG_FLAGS} -DBOOST_WILL_RECONFIGURE=FALSE -DBOOST_RECONFIGURE=TRUE -DFETCH_BOOST=FALSE); externalproject_add_step(libboost reconfigure; COMMAND ${CMAKE_COMMAND} ${CMAKE_CURRENT_SOURCE_DIR} ${RECONFIG_FLAGS}; DEPENDEES install; ); set(FETCHED_BOOST TRUE); endif(). ##; # If we're fetching boost and we need to have dummy paths for these variables; # so that CMake won't complain; ##; if(BOOST_WILL_RECONFIGURE); message(""Setting Temporary Boost paths""); set(Boost_INCLUDE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install/include); set(Boost_INCLUDE_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/include); set(Boost_LIBRARY_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/lib); set(Boost_FOUND TRUE); endif(). message(""BOOST ROOT = ${BOOST_ROOT}""); message(""BOOST INCLUDE DIR = ${Boost_INCLUDE_DIR}""); message(""BOOST INCLUDE DIRS = ${Boost_INCLUDE_DIRS}""); message(""BOOST LIB DIR = ${Boost_LIBRARY_DIRS}""); message(""BOOST LIBRARIES = ${Boost_LIBRARIES}""). set(EXTERNAL_LIBRARY_PATH $CMAKE_CURRENT_SOURCE_DIR/lib). #find_package(libdivsufsort); #if(NOT LIBDIVSUFSORT_FOUND); # message(""Build sys",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:19275,Deployability,install,install,19275,"OMPILER} CXX=${CMAKE_CXX_COMPILER} ${CMAKE_CURRENT_SOURCE_DIR}/external/boost_${BOOST_FETCHED_VERSION}/b2 -d0 -j${BOOST_BUILD_THREADS} ${BOOST_LIB_SUBSET} toolset=${BOOST_TOOLSET} ${BOOST_EXTRA_FLAGS} cxxflags=${BOOST_CXX_FLAGS} link=static install; BUILD_IN_SOURCE 1; INSTALL_COMMAND """"; ). externalproject_add_step(libboost makedir; COMMAND mkdir -p <SOURCE_DIR>/build; COMMENT ""Make build directory""; DEPENDEES download; DEPENDERS configure). ##; # After we've installed boost,; ##; set(RECONFIG_FLAGS ${RECONFIG_FLAGS} -DBOOST_WILL_RECONFIGURE=FALSE -DBOOST_RECONFIGURE=TRUE -DFETCH_BOOST=FALSE); externalproject_add_step(libboost reconfigure; COMMAND ${CMAKE_COMMAND} ${CMAKE_CURRENT_SOURCE_DIR} ${RECONFIG_FLAGS}; DEPENDEES install; ); set(FETCHED_BOOST TRUE); endif(). ##; # If we're fetching boost and we need to have dummy paths for these variables; # so that CMake won't complain; ##; if(BOOST_WILL_RECONFIGURE); message(""Setting Temporary Boost paths""); set(Boost_INCLUDE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install/include); set(Boost_INCLUDE_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/include); set(Boost_LIBRARY_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/lib); set(Boost_FOUND TRUE); endif(). message(""BOOST ROOT = ${BOOST_ROOT}""); message(""BOOST INCLUDE DIR = ${Boost_INCLUDE_DIR}""); message(""BOOST INCLUDE DIRS = ${Boost_INCLUDE_DIRS}""); message(""BOOST LIB DIR = ${Boost_LIBRARY_DIRS}""); message(""BOOST LIBRARIES = ${Boost_LIBRARIES}""). set(EXTERNAL_LIBRARY_PATH $CMAKE_CURRENT_SOURCE_DIR/lib). #find_package(libdivsufsort); #if(NOT LIBDIVSUFSORT_FOUND); # message(""Build system will build libdivsufsort""); # message(""==================================================================""); # include(ExternalProject); # externalproject_add(libdivsufsort; # DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; # URL ${CMAKE_CURRENT_SOURCE_DIR}/external/libdivsufsort.zip; # # Note: This zip comes from the fetched rapmap.zip, whose SHA we check; # # so we souldn't need",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:19353,Deployability,install,install,19353,"OMPILER} CXX=${CMAKE_CXX_COMPILER} ${CMAKE_CURRENT_SOURCE_DIR}/external/boost_${BOOST_FETCHED_VERSION}/b2 -d0 -j${BOOST_BUILD_THREADS} ${BOOST_LIB_SUBSET} toolset=${BOOST_TOOLSET} ${BOOST_EXTRA_FLAGS} cxxflags=${BOOST_CXX_FLAGS} link=static install; BUILD_IN_SOURCE 1; INSTALL_COMMAND """"; ). externalproject_add_step(libboost makedir; COMMAND mkdir -p <SOURCE_DIR>/build; COMMENT ""Make build directory""; DEPENDEES download; DEPENDERS configure). ##; # After we've installed boost,; ##; set(RECONFIG_FLAGS ${RECONFIG_FLAGS} -DBOOST_WILL_RECONFIGURE=FALSE -DBOOST_RECONFIGURE=TRUE -DFETCH_BOOST=FALSE); externalproject_add_step(libboost reconfigure; COMMAND ${CMAKE_COMMAND} ${CMAKE_CURRENT_SOURCE_DIR} ${RECONFIG_FLAGS}; DEPENDEES install; ); set(FETCHED_BOOST TRUE); endif(). ##; # If we're fetching boost and we need to have dummy paths for these variables; # so that CMake won't complain; ##; if(BOOST_WILL_RECONFIGURE); message(""Setting Temporary Boost paths""); set(Boost_INCLUDE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install/include); set(Boost_INCLUDE_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/include); set(Boost_LIBRARY_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/lib); set(Boost_FOUND TRUE); endif(). message(""BOOST ROOT = ${BOOST_ROOT}""); message(""BOOST INCLUDE DIR = ${Boost_INCLUDE_DIR}""); message(""BOOST INCLUDE DIRS = ${Boost_INCLUDE_DIRS}""); message(""BOOST LIB DIR = ${Boost_LIBRARY_DIRS}""); message(""BOOST LIBRARIES = ${Boost_LIBRARIES}""). set(EXTERNAL_LIBRARY_PATH $CMAKE_CURRENT_SOURCE_DIR/lib). #find_package(libdivsufsort); #if(NOT LIBDIVSUFSORT_FOUND); # message(""Build system will build libdivsufsort""); # message(""==================================================================""); # include(ExternalProject); # externalproject_add(libdivsufsort; # DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; # URL ${CMAKE_CURRENT_SOURCE_DIR}/external/libdivsufsort.zip; # # Note: This zip comes from the fetched rapmap.zip, whose SHA we check; # # so we souldn't need",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:19431,Deployability,install,install,19431,"OMPILER} CXX=${CMAKE_CXX_COMPILER} ${CMAKE_CURRENT_SOURCE_DIR}/external/boost_${BOOST_FETCHED_VERSION}/b2 -d0 -j${BOOST_BUILD_THREADS} ${BOOST_LIB_SUBSET} toolset=${BOOST_TOOLSET} ${BOOST_EXTRA_FLAGS} cxxflags=${BOOST_CXX_FLAGS} link=static install; BUILD_IN_SOURCE 1; INSTALL_COMMAND """"; ). externalproject_add_step(libboost makedir; COMMAND mkdir -p <SOURCE_DIR>/build; COMMENT ""Make build directory""; DEPENDEES download; DEPENDERS configure). ##; # After we've installed boost,; ##; set(RECONFIG_FLAGS ${RECONFIG_FLAGS} -DBOOST_WILL_RECONFIGURE=FALSE -DBOOST_RECONFIGURE=TRUE -DFETCH_BOOST=FALSE); externalproject_add_step(libboost reconfigure; COMMAND ${CMAKE_COMMAND} ${CMAKE_CURRENT_SOURCE_DIR} ${RECONFIG_FLAGS}; DEPENDEES install; ); set(FETCHED_BOOST TRUE); endif(). ##; # If we're fetching boost and we need to have dummy paths for these variables; # so that CMake won't complain; ##; if(BOOST_WILL_RECONFIGURE); message(""Setting Temporary Boost paths""); set(Boost_INCLUDE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install/include); set(Boost_INCLUDE_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/include); set(Boost_LIBRARY_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/lib); set(Boost_FOUND TRUE); endif(). message(""BOOST ROOT = ${BOOST_ROOT}""); message(""BOOST INCLUDE DIR = ${Boost_INCLUDE_DIR}""); message(""BOOST INCLUDE DIRS = ${Boost_INCLUDE_DIRS}""); message(""BOOST LIB DIR = ${Boost_LIBRARY_DIRS}""); message(""BOOST LIBRARIES = ${Boost_LIBRARIES}""). set(EXTERNAL_LIBRARY_PATH $CMAKE_CURRENT_SOURCE_DIR/lib). #find_package(libdivsufsort); #if(NOT LIBDIVSUFSORT_FOUND); # message(""Build system will build libdivsufsort""); # message(""==================================================================""); # include(ExternalProject); # externalproject_add(libdivsufsort; # DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; # URL ${CMAKE_CURRENT_SOURCE_DIR}/external/libdivsufsort.zip; # # Note: This zip comes from the fetched rapmap.zip, whose SHA we check; # # so we souldn't need",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:20406,Deployability,install,install,20406,"ENT_SOURCE_DIR/lib). #find_package(libdivsufsort); #if(NOT LIBDIVSUFSORT_FOUND); # message(""Build system will build libdivsufsort""); # message(""==================================================================""); # include(ExternalProject); # externalproject_add(libdivsufsort; # DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; # URL ${CMAKE_CURRENT_SOURCE_DIR}/external/libdivsufsort.zip; # # Note: This zip comes from the fetched rapmap.zip, whose SHA we check; # # so we souldn't need to check this one separately.; # SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/libdivsufsort-master; # INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; # #UPDATE_COMMAND sh -c ""mkdir -p <SOURCE_DIR>/build""; # BINARY_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/libdivsufsort-master/build; # CMAKE_ARGS -DCMAKE_INSTALL_PREFIX:PATH=<INSTALL_DIR> -DBUILD_DIVSUFSORT64=TRUE -DUSE_OPENMP=TRUE -DBUILD_SHARED_LIBS=FALSE; # ); # externalproject_add_step(libdivsufsort makedir; # COMMAND mkdir -p <SOURCE_DIR>/build; # COMMENT ""Make build directory""; # DEPENDEES download; # DEPENDERS configure); #; # set(SUFFARRAY_INCLUDE_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/include); # set(FETCHED_LIBDIVSUFSORT TRUE); #else(); # message(""SUFFARRAY_LIB = ${SUFFARRAY_LIBRARY}""); # set(SUFFARRAY_LIB ${SUFFARRAY_LIBRARY}); # message(""SUFFARRAY_LIB64 = ${SUFFARRAY_LIBRARY64}""); # set(SUFFARRAY_LIB64 ${SUFFARRAY_LIBRARY64}); # set(SUFFARRAY_INCLUDE_DIRS ${SUFFARRAY_INCLUDE_DIR}); #endif(). find_package(cereal ""1.3.2""); if (NOT CEREAL_FOUND); message(""Build system will fetch and build the cereal serialization library""); message(""==================================================================""); include(ExternalProject); externalproject_add(libcereal; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://github.com/USCiLab/cereal/archive/refs/tags/v1.3.2.tar.gz -o cereal-v1.3.2.tar.gz &&; ${SHASUM} 16a7ad9b31ba5880dac55d62b5d6f243c3ebc8d46a3514149e56b5e7ea81f85f cere",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:20917,Deployability,install,install,20917,"ENT_SOURCE_DIR/lib). #find_package(libdivsufsort); #if(NOT LIBDIVSUFSORT_FOUND); # message(""Build system will build libdivsufsort""); # message(""==================================================================""); # include(ExternalProject); # externalproject_add(libdivsufsort; # DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; # URL ${CMAKE_CURRENT_SOURCE_DIR}/external/libdivsufsort.zip; # # Note: This zip comes from the fetched rapmap.zip, whose SHA we check; # # so we souldn't need to check this one separately.; # SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/libdivsufsort-master; # INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; # #UPDATE_COMMAND sh -c ""mkdir -p <SOURCE_DIR>/build""; # BINARY_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/libdivsufsort-master/build; # CMAKE_ARGS -DCMAKE_INSTALL_PREFIX:PATH=<INSTALL_DIR> -DBUILD_DIVSUFSORT64=TRUE -DUSE_OPENMP=TRUE -DBUILD_SHARED_LIBS=FALSE; # ); # externalproject_add_step(libdivsufsort makedir; # COMMAND mkdir -p <SOURCE_DIR>/build; # COMMENT ""Make build directory""; # DEPENDEES download; # DEPENDERS configure); #; # set(SUFFARRAY_INCLUDE_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/include); # set(FETCHED_LIBDIVSUFSORT TRUE); #else(); # message(""SUFFARRAY_LIB = ${SUFFARRAY_LIBRARY}""); # set(SUFFARRAY_LIB ${SUFFARRAY_LIBRARY}); # message(""SUFFARRAY_LIB64 = ${SUFFARRAY_LIBRARY64}""); # set(SUFFARRAY_LIB64 ${SUFFARRAY_LIBRARY64}); # set(SUFFARRAY_INCLUDE_DIRS ${SUFFARRAY_INCLUDE_DIR}); #endif(). find_package(cereal ""1.3.2""); if (NOT CEREAL_FOUND); message(""Build system will fetch and build the cereal serialization library""); message(""==================================================================""); include(ExternalProject); externalproject_add(libcereal; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://github.com/USCiLab/cereal/archive/refs/tags/v1.3.2.tar.gz -o cereal-v1.3.2.tar.gz &&; ${SHASUM} 16a7ad9b31ba5880dac55d62b5d6f243c3ebc8d46a3514149e56b5e7ea81f85f cere",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:21925,Deployability,install,install,21925,"SORT TRUE); #else(); # message(""SUFFARRAY_LIB = ${SUFFARRAY_LIBRARY}""); # set(SUFFARRAY_LIB ${SUFFARRAY_LIBRARY}); # message(""SUFFARRAY_LIB64 = ${SUFFARRAY_LIBRARY64}""); # set(SUFFARRAY_LIB64 ${SUFFARRAY_LIBRARY64}); # set(SUFFARRAY_INCLUDE_DIRS ${SUFFARRAY_INCLUDE_DIR}); #endif(). find_package(cereal ""1.3.2""); if (NOT CEREAL_FOUND); message(""Build system will fetch and build the cereal serialization library""); message(""==================================================================""); include(ExternalProject); externalproject_add(libcereal; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://github.com/USCiLab/cereal/archive/refs/tags/v1.3.2.tar.gz -o cereal-v1.3.2.tar.gz &&; ${SHASUM} 16a7ad9b31ba5880dac55d62b5d6f243c3ebc8d46a3514149e56b5e7ea81f85f cereal-v1.3.2.tar.gz &&; tar -xzvf cereal-v1.3.2.tar.gz. SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/cereal-1.3.2; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; #UPDATE_COMMAND sh -c ""mkdir -p <SOURCE_DIR>/build""; BINARY_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/cereal-1.3.2/build; CONFIGURE_COMMAND """"; BUILD_COMMAND """"; INSTALL_COMMAND sh -c ""mkdir -p <INSTALL_DIR>/include && cp -r <SOURCE_DIR>/include/cereal <INSTALL_DIR>/include""; ); externalproject_add_step(libcereal makedir; COMMAND mkdir -p <SOURCE_DIR>/build; COMMENT ""Make build directory""; DEPENDEES download; DEPENDERS configure). set(FETCHED_CEREAL TRUE); endif(). ## Try and find TBB first; find_package(TBB 2021.4; HINTS ${TBB_ROOT_SEARCH}; COMPONENTS tbb tbbmalloc tbbmalloc_proxy). if (${TBB_FOUND}); if (${TBB_VERSION} VERSION_GREATER_EQUAL 2021.4); message(""FOUND SUITABLE TBB VERSION : ${TBB_VERSION}""); set(TBB_TARGET_EXISTED TRUE); else(); set(TBB_TARGET_EXISTED FALSE); endif(); else(); set(TBB_TARGET_EXISTED FALSE); endif(). ##; #; # Fetch and build Intel's Threading Building Blocks library.; #; ##; if(NOT ${TBB_TARGET_EXISTED}). set(TBB_WILL_RECONFIGURE TRUE); # Set the appropriate compiler; if(CLANG); se",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:23217,Deployability,install,install,23217,"E_DIR>/include/cereal <INSTALL_DIR>/include""; ); externalproject_add_step(libcereal makedir; COMMAND mkdir -p <SOURCE_DIR>/build; COMMENT ""Make build directory""; DEPENDEES download; DEPENDERS configure). set(FETCHED_CEREAL TRUE); endif(). ## Try and find TBB first; find_package(TBB 2021.4; HINTS ${TBB_ROOT_SEARCH}; COMPONENTS tbb tbbmalloc tbbmalloc_proxy). if (${TBB_FOUND}); if (${TBB_VERSION} VERSION_GREATER_EQUAL 2021.4); message(""FOUND SUITABLE TBB VERSION : ${TBB_VERSION}""); set(TBB_TARGET_EXISTED TRUE); else(); set(TBB_TARGET_EXISTED FALSE); endif(); else(); set(TBB_TARGET_EXISTED FALSE); endif(). ##; #; # Fetch and build Intel's Threading Building Blocks library.; #; ##; if(NOT ${TBB_TARGET_EXISTED}). set(TBB_WILL_RECONFIGURE TRUE); # Set the appropriate compiler; if(CLANG); set(TBB_COMPILER ""clang""); else(); set(TBB_COMPILER ""gcc""); endif(). message(""Build system will fetch and build Intel Threading Building Blocks""); message(""==================================================================""); # These are useful for the custom install step we'll do later; set(TBB_SOURCE_DIR ${GAT_SOURCE_DIR}/external/oneTBB-2021.5.0); set(TBB_INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install). if(""${TBB_COMPILER}"" STREQUAL ""gcc""); ## Don't know why it's a problem yet, but if we're using; ## GCC, get rid of the DO_ITT_NOTIFY flag; # set(TBB_CXXFLAGS ""${TBB_CXXFLAGS} -UDO_ITT_NOTIFY""); endif(). set(TBB_CXXFLAGS ""${TBB_CXXFLAGS} ${CXXSTDFLAG} ${SCHAR_FLAG}""). ExternalProject_Add(libtbb; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://github.com/oneapi-src/oneTBB/archive/refs/tags/v2021.5.0.tar.gz -o v2021.5.tar.gz &&; ${SHASUM} e5b57537c741400cf6134b428fc1689a649d7d38d9bb9c1b6d64f092ea28178a v2021.5.tar.gz &&; tar -xzvf v2021.5.tar.gz; SOURCE_DIR ${TBB_SOURCE_DIR}; INSTALL_DIR ${TBB_INSTALL_DIR}; PATCH_COMMAND ""${TBB_PATCH_STEP}""; CMAKE_ARGS -DCMAKE_CXX_FLAGS=${TBB_CXXFLAGS} -DCMAKE_INSTALL_PREFIX=<INSTALL_DIR> -DTBB_TEST=OFF -DTBB",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:23367,Deployability,install,install,23367,"oad; DEPENDERS configure). set(FETCHED_CEREAL TRUE); endif(). ## Try and find TBB first; find_package(TBB 2021.4; HINTS ${TBB_ROOT_SEARCH}; COMPONENTS tbb tbbmalloc tbbmalloc_proxy). if (${TBB_FOUND}); if (${TBB_VERSION} VERSION_GREATER_EQUAL 2021.4); message(""FOUND SUITABLE TBB VERSION : ${TBB_VERSION}""); set(TBB_TARGET_EXISTED TRUE); else(); set(TBB_TARGET_EXISTED FALSE); endif(); else(); set(TBB_TARGET_EXISTED FALSE); endif(). ##; #; # Fetch and build Intel's Threading Building Blocks library.; #; ##; if(NOT ${TBB_TARGET_EXISTED}). set(TBB_WILL_RECONFIGURE TRUE); # Set the appropriate compiler; if(CLANG); set(TBB_COMPILER ""clang""); else(); set(TBB_COMPILER ""gcc""); endif(). message(""Build system will fetch and build Intel Threading Building Blocks""); message(""==================================================================""); # These are useful for the custom install step we'll do later; set(TBB_SOURCE_DIR ${GAT_SOURCE_DIR}/external/oneTBB-2021.5.0); set(TBB_INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install). if(""${TBB_COMPILER}"" STREQUAL ""gcc""); ## Don't know why it's a problem yet, but if we're using; ## GCC, get rid of the DO_ITT_NOTIFY flag; # set(TBB_CXXFLAGS ""${TBB_CXXFLAGS} -UDO_ITT_NOTIFY""); endif(). set(TBB_CXXFLAGS ""${TBB_CXXFLAGS} ${CXXSTDFLAG} ${SCHAR_FLAG}""). ExternalProject_Add(libtbb; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://github.com/oneapi-src/oneTBB/archive/refs/tags/v2021.5.0.tar.gz -o v2021.5.tar.gz &&; ${SHASUM} e5b57537c741400cf6134b428fc1689a649d7d38d9bb9c1b6d64f092ea28178a v2021.5.tar.gz &&; tar -xzvf v2021.5.tar.gz; SOURCE_DIR ${TBB_SOURCE_DIR}; INSTALL_DIR ${TBB_INSTALL_DIR}; PATCH_COMMAND ""${TBB_PATCH_STEP}""; CMAKE_ARGS -DCMAKE_CXX_FLAGS=${TBB_CXXFLAGS} -DCMAKE_INSTALL_PREFIX=<INSTALL_DIR> -DTBB_TEST=OFF -DTBB_EXAMPLES=OFF -DCMAKE_BUILD_TYPE=Release -DCMAKE_CXX_STANDARD=${CMAKE_CXX_STANDARD} -DCMAKE_CXX_COMPILER=${CMAKE_CXX_COMPILER} -DCMAKE_C_COMPILER=${CMAKE_C_COMPILER}; BUILD_IN_",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:24575,Deployability,install,install,24575,"g; # set(TBB_CXXFLAGS ""${TBB_CXXFLAGS} -UDO_ITT_NOTIFY""); endif(). set(TBB_CXXFLAGS ""${TBB_CXXFLAGS} ${CXXSTDFLAG} ${SCHAR_FLAG}""). ExternalProject_Add(libtbb; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://github.com/oneapi-src/oneTBB/archive/refs/tags/v2021.5.0.tar.gz -o v2021.5.tar.gz &&; ${SHASUM} e5b57537c741400cf6134b428fc1689a649d7d38d9bb9c1b6d64f092ea28178a v2021.5.tar.gz &&; tar -xzvf v2021.5.tar.gz; SOURCE_DIR ${TBB_SOURCE_DIR}; INSTALL_DIR ${TBB_INSTALL_DIR}; PATCH_COMMAND ""${TBB_PATCH_STEP}""; CMAKE_ARGS -DCMAKE_CXX_FLAGS=${TBB_CXXFLAGS} -DCMAKE_INSTALL_PREFIX=<INSTALL_DIR> -DTBB_TEST=OFF -DTBB_EXAMPLES=OFF -DCMAKE_BUILD_TYPE=Release -DCMAKE_CXX_STANDARD=${CMAKE_CXX_STANDARD} -DCMAKE_CXX_COMPILER=${CMAKE_CXX_COMPILER} -DCMAKE_C_COMPILER=${CMAKE_C_COMPILER}; BUILD_IN_SOURCE TRUE; ). set(RECONFIG_FLAGS ${RECONFIG_FLAGS} -DTBB_WILL_RECONFIGURE=FALSE -DTBB_RECONFIGURE=TRUE); ExternalProject_Add_Step(libtbb reconfigure; COMMAND ${CMAKE_COMMAND} ${CMAKE_CURRENT_SOURCE_DIR} ${RECONFIG_FLAGS}; DEPENDEES install ; ); set(FETCHED_TBB TRUE); set(TBB_ROOT_SEARCH ${CMAKE_SOURCE_DIR}/external/install) . if(${FETCHED_BOOST}); add_dependencies(libtbb libboost); endif(). endif() # end of fetch tbb. ##; # If we're fetching tbb, we need to have dummy paths for these variables; # so that CMake won't complain; ##; if(TBB_WILL_RECONFIGURE); set(TBB_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(TBB_INCLUDE_DIRS ${TBB_INSTALL_DIR}/include); set(TBB_INCLUDE_DIR ${TBB_INSTALL_DIR}/include); set(TBB_LIBRARY_DIRS ${TBB_INSTALL_DIR}/lib); set(TBB_LIBRARY ${TBB_INSTALL_DIR}/lib); set(TBB_LIB_DIR ${TBB_INSTALL_DIR}/lib); #set(TBB_LIBRARIES tbb tbbmalloc); set(TBB_LIBRARIES ${TBB_INSTALL_DIR}/lib/libtbb.${SHARED_LIB_EXTENSION}; 			${TBB_INSTALL_DIR}/lib/libtbbmalloc.${SHARED_LIB_EXTENSION}; ${TBB_INSTALL_DIR}/lib/libtbbmalloc_proxy.${SHARED_LIB_EXTENSION}; 	 ); message(""TBB_INCLUDE_DIRS = ${TBB_INCLUDE_DIRS}""); message(""TBB_LIBRARY_DIRS =",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:24660,Deployability,install,install,24660,"g; # set(TBB_CXXFLAGS ""${TBB_CXXFLAGS} -UDO_ITT_NOTIFY""); endif(). set(TBB_CXXFLAGS ""${TBB_CXXFLAGS} ${CXXSTDFLAG} ${SCHAR_FLAG}""). ExternalProject_Add(libtbb; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://github.com/oneapi-src/oneTBB/archive/refs/tags/v2021.5.0.tar.gz -o v2021.5.tar.gz &&; ${SHASUM} e5b57537c741400cf6134b428fc1689a649d7d38d9bb9c1b6d64f092ea28178a v2021.5.tar.gz &&; tar -xzvf v2021.5.tar.gz; SOURCE_DIR ${TBB_SOURCE_DIR}; INSTALL_DIR ${TBB_INSTALL_DIR}; PATCH_COMMAND ""${TBB_PATCH_STEP}""; CMAKE_ARGS -DCMAKE_CXX_FLAGS=${TBB_CXXFLAGS} -DCMAKE_INSTALL_PREFIX=<INSTALL_DIR> -DTBB_TEST=OFF -DTBB_EXAMPLES=OFF -DCMAKE_BUILD_TYPE=Release -DCMAKE_CXX_STANDARD=${CMAKE_CXX_STANDARD} -DCMAKE_CXX_COMPILER=${CMAKE_CXX_COMPILER} -DCMAKE_C_COMPILER=${CMAKE_C_COMPILER}; BUILD_IN_SOURCE TRUE; ). set(RECONFIG_FLAGS ${RECONFIG_FLAGS} -DTBB_WILL_RECONFIGURE=FALSE -DTBB_RECONFIGURE=TRUE); ExternalProject_Add_Step(libtbb reconfigure; COMMAND ${CMAKE_COMMAND} ${CMAKE_CURRENT_SOURCE_DIR} ${RECONFIG_FLAGS}; DEPENDEES install ; ); set(FETCHED_TBB TRUE); set(TBB_ROOT_SEARCH ${CMAKE_SOURCE_DIR}/external/install) . if(${FETCHED_BOOST}); add_dependencies(libtbb libboost); endif(). endif() # end of fetch tbb. ##; # If we're fetching tbb, we need to have dummy paths for these variables; # so that CMake won't complain; ##; if(TBB_WILL_RECONFIGURE); set(TBB_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(TBB_INCLUDE_DIRS ${TBB_INSTALL_DIR}/include); set(TBB_INCLUDE_DIR ${TBB_INSTALL_DIR}/include); set(TBB_LIBRARY_DIRS ${TBB_INSTALL_DIR}/lib); set(TBB_LIBRARY ${TBB_INSTALL_DIR}/lib); set(TBB_LIB_DIR ${TBB_INSTALL_DIR}/lib); #set(TBB_LIBRARIES tbb tbbmalloc); set(TBB_LIBRARIES ${TBB_INSTALL_DIR}/lib/libtbb.${SHARED_LIB_EXTENSION}; 			${TBB_INSTALL_DIR}/lib/libtbbmalloc.${SHARED_LIB_EXTENSION}; ${TBB_INSTALL_DIR}/lib/libtbbmalloc_proxy.${SHARED_LIB_EXTENSION}; 	 ); message(""TBB_INCLUDE_DIRS = ${TBB_INCLUDE_DIRS}""); message(""TBB_LIBRARY_DIRS =",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:24954,Deployability,install,install,24954,"LL_DIR}; PATCH_COMMAND ""${TBB_PATCH_STEP}""; CMAKE_ARGS -DCMAKE_CXX_FLAGS=${TBB_CXXFLAGS} -DCMAKE_INSTALL_PREFIX=<INSTALL_DIR> -DTBB_TEST=OFF -DTBB_EXAMPLES=OFF -DCMAKE_BUILD_TYPE=Release -DCMAKE_CXX_STANDARD=${CMAKE_CXX_STANDARD} -DCMAKE_CXX_COMPILER=${CMAKE_CXX_COMPILER} -DCMAKE_C_COMPILER=${CMAKE_C_COMPILER}; BUILD_IN_SOURCE TRUE; ). set(RECONFIG_FLAGS ${RECONFIG_FLAGS} -DTBB_WILL_RECONFIGURE=FALSE -DTBB_RECONFIGURE=TRUE); ExternalProject_Add_Step(libtbb reconfigure; COMMAND ${CMAKE_COMMAND} ${CMAKE_CURRENT_SOURCE_DIR} ${RECONFIG_FLAGS}; DEPENDEES install ; ); set(FETCHED_TBB TRUE); set(TBB_ROOT_SEARCH ${CMAKE_SOURCE_DIR}/external/install) . if(${FETCHED_BOOST}); add_dependencies(libtbb libboost); endif(). endif() # end of fetch tbb. ##; # If we're fetching tbb, we need to have dummy paths for these variables; # so that CMake won't complain; ##; if(TBB_WILL_RECONFIGURE); set(TBB_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(TBB_INCLUDE_DIRS ${TBB_INSTALL_DIR}/include); set(TBB_INCLUDE_DIR ${TBB_INSTALL_DIR}/include); set(TBB_LIBRARY_DIRS ${TBB_INSTALL_DIR}/lib); set(TBB_LIBRARY ${TBB_INSTALL_DIR}/lib); set(TBB_LIB_DIR ${TBB_INSTALL_DIR}/lib); #set(TBB_LIBRARIES tbb tbbmalloc); set(TBB_LIBRARIES ${TBB_INSTALL_DIR}/lib/libtbb.${SHARED_LIB_EXTENSION}; 			${TBB_INSTALL_DIR}/lib/libtbbmalloc.${SHARED_LIB_EXTENSION}; ${TBB_INSTALL_DIR}/lib/libtbbmalloc_proxy.${SHARED_LIB_EXTENSION}; 	 ); message(""TBB_INCLUDE_DIRS = ${TBB_INCLUDE_DIRS}""); message(""TBB_LIBRARY_DIRS = ${TBB_LIBRARY_DIRS}""); endif(). ##; # Similar to the Boost trick above, the libtbb reconfigure should force this code; # to be run on the second configuration pass, where it should appropriately set the; # TBB_INSTALL_DIR variable.; ##; if(TBB_RECONFIGURE); unset(TBB_FOUND CACHE); unset(TBB_INSTALL_DIR CACHE); unset(CMAKE_PREFIX_PATH CACHE); unset(TBB_INCLUDE_DIRS CACHE); unset(TBB_INCLUDE_DIR CACHE); unset(TBB_LIBRARY_DIRS CACHE); unset(TBB_LIBRARY CACHE); unset(TBB_LIBRARIES CACHE); set(CMAKE_PREFI",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:25659,Deployability,configurat,configuration,25659,"_DIR}/external/install) . if(${FETCHED_BOOST}); add_dependencies(libtbb libboost); endif(). endif() # end of fetch tbb. ##; # If we're fetching tbb, we need to have dummy paths for these variables; # so that CMake won't complain; ##; if(TBB_WILL_RECONFIGURE); set(TBB_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(TBB_INCLUDE_DIRS ${TBB_INSTALL_DIR}/include); set(TBB_INCLUDE_DIR ${TBB_INSTALL_DIR}/include); set(TBB_LIBRARY_DIRS ${TBB_INSTALL_DIR}/lib); set(TBB_LIBRARY ${TBB_INSTALL_DIR}/lib); set(TBB_LIB_DIR ${TBB_INSTALL_DIR}/lib); #set(TBB_LIBRARIES tbb tbbmalloc); set(TBB_LIBRARIES ${TBB_INSTALL_DIR}/lib/libtbb.${SHARED_LIB_EXTENSION}; 			${TBB_INSTALL_DIR}/lib/libtbbmalloc.${SHARED_LIB_EXTENSION}; ${TBB_INSTALL_DIR}/lib/libtbbmalloc_proxy.${SHARED_LIB_EXTENSION}; 	 ); message(""TBB_INCLUDE_DIRS = ${TBB_INCLUDE_DIRS}""); message(""TBB_LIBRARY_DIRS = ${TBB_LIBRARY_DIRS}""); endif(). ##; # Similar to the Boost trick above, the libtbb reconfigure should force this code; # to be run on the second configuration pass, where it should appropriately set the; # TBB_INSTALL_DIR variable.; ##; if(TBB_RECONFIGURE); unset(TBB_FOUND CACHE); unset(TBB_INSTALL_DIR CACHE); unset(CMAKE_PREFIX_PATH CACHE); unset(TBB_INCLUDE_DIRS CACHE); unset(TBB_INCLUDE_DIR CACHE); unset(TBB_LIBRARY_DIRS CACHE); unset(TBB_LIBRARY CACHE); unset(TBB_LIBRARIES CACHE); set(CMAKE_PREFIX_PATH ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(TBB_INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(TBB_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(TBB_INCLUDE_DIRS ${TBB_INSTALL_DIR}/include); set(TBB_INCLUDE_DIR ${TBB_INSTALL_DIR}/include); set(TBB_LIBRARY_DIRS ${TBB_INSTALL_DIR}/lib); set(TBB_LIBRARY ${TBB_INSTALL_DIR}/lib); set(TBB_LIB_DIR ${TBB_INSTALL_DIR}/lib); message(""TBB_INSTALL_DIR = ${TBB_INSTALL_DIR}""); find_package(TBB 2021.4; HINTS ${TBB_ROOT_SEARCH}; COMPONENTS tbb tbbmalloc tbbmalloc_proxy); message(""[in TBB_RECONFIGURE] TBB_LIBRARIES = ${TBB_LIBRARIES}""); endif(). #",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:26063,Deployability,install,install,26063,"ARY ${TBB_INSTALL_DIR}/lib); set(TBB_LIB_DIR ${TBB_INSTALL_DIR}/lib); #set(TBB_LIBRARIES tbb tbbmalloc); set(TBB_LIBRARIES ${TBB_INSTALL_DIR}/lib/libtbb.${SHARED_LIB_EXTENSION}; 			${TBB_INSTALL_DIR}/lib/libtbbmalloc.${SHARED_LIB_EXTENSION}; ${TBB_INSTALL_DIR}/lib/libtbbmalloc_proxy.${SHARED_LIB_EXTENSION}; 	 ); message(""TBB_INCLUDE_DIRS = ${TBB_INCLUDE_DIRS}""); message(""TBB_LIBRARY_DIRS = ${TBB_LIBRARY_DIRS}""); endif(). ##; # Similar to the Boost trick above, the libtbb reconfigure should force this code; # to be run on the second configuration pass, where it should appropriately set the; # TBB_INSTALL_DIR variable.; ##; if(TBB_RECONFIGURE); unset(TBB_FOUND CACHE); unset(TBB_INSTALL_DIR CACHE); unset(CMAKE_PREFIX_PATH CACHE); unset(TBB_INCLUDE_DIRS CACHE); unset(TBB_INCLUDE_DIR CACHE); unset(TBB_LIBRARY_DIRS CACHE); unset(TBB_LIBRARY CACHE); unset(TBB_LIBRARIES CACHE); set(CMAKE_PREFIX_PATH ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(TBB_INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(TBB_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(TBB_INCLUDE_DIRS ${TBB_INSTALL_DIR}/include); set(TBB_INCLUDE_DIR ${TBB_INSTALL_DIR}/include); set(TBB_LIBRARY_DIRS ${TBB_INSTALL_DIR}/lib); set(TBB_LIBRARY ${TBB_INSTALL_DIR}/lib); set(TBB_LIB_DIR ${TBB_INSTALL_DIR}/lib); message(""TBB_INSTALL_DIR = ${TBB_INSTALL_DIR}""); find_package(TBB 2021.4; HINTS ${TBB_ROOT_SEARCH}; COMPONENTS tbb tbbmalloc tbbmalloc_proxy); message(""[in TBB_RECONFIGURE] TBB_LIBRARIES = ${TBB_LIBRARIES}""); endif(). #message(""TBB_LIBRARIES = ${TBB_LIBRARIES}""); #message(""TBB_FOUND ${TBB_FOUND} ""); #message(""TBB_INSTALL_DIR ${TBB_INSTALL_DIR}""); #message(""TBB_INCLUDE_DIRS ${TBB_INCLUDE_DIRS}""); #message(""TBB_INCLUDE_DIR ${TBB_INCLUDE_DIR} ""); #message(""TBB_LIBRARY_DIRS ${TBB_LIBRARY_DIRS}""); #message(""TBB_LIBRARIES ${TBB_LIBRARIES} ""). find_package(libgff 2.0.0 ; HINTS ${LIB_GFF_PATH} ${GFF_ROOT}; ); if(libgff_FOUND); message(STATUS ""libgff ver. ${LIB_GFF_VERSION} found.""); message(STA",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:26130,Deployability,install,install,26130,"ARY ${TBB_INSTALL_DIR}/lib); set(TBB_LIB_DIR ${TBB_INSTALL_DIR}/lib); #set(TBB_LIBRARIES tbb tbbmalloc); set(TBB_LIBRARIES ${TBB_INSTALL_DIR}/lib/libtbb.${SHARED_LIB_EXTENSION}; 			${TBB_INSTALL_DIR}/lib/libtbbmalloc.${SHARED_LIB_EXTENSION}; ${TBB_INSTALL_DIR}/lib/libtbbmalloc_proxy.${SHARED_LIB_EXTENSION}; 	 ); message(""TBB_INCLUDE_DIRS = ${TBB_INCLUDE_DIRS}""); message(""TBB_LIBRARY_DIRS = ${TBB_LIBRARY_DIRS}""); endif(). ##; # Similar to the Boost trick above, the libtbb reconfigure should force this code; # to be run on the second configuration pass, where it should appropriately set the; # TBB_INSTALL_DIR variable.; ##; if(TBB_RECONFIGURE); unset(TBB_FOUND CACHE); unset(TBB_INSTALL_DIR CACHE); unset(CMAKE_PREFIX_PATH CACHE); unset(TBB_INCLUDE_DIRS CACHE); unset(TBB_INCLUDE_DIR CACHE); unset(TBB_LIBRARY_DIRS CACHE); unset(TBB_LIBRARY CACHE); unset(TBB_LIBRARIES CACHE); set(CMAKE_PREFIX_PATH ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(TBB_INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(TBB_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(TBB_INCLUDE_DIRS ${TBB_INSTALL_DIR}/include); set(TBB_INCLUDE_DIR ${TBB_INSTALL_DIR}/include); set(TBB_LIBRARY_DIRS ${TBB_INSTALL_DIR}/lib); set(TBB_LIBRARY ${TBB_INSTALL_DIR}/lib); set(TBB_LIB_DIR ${TBB_INSTALL_DIR}/lib); message(""TBB_INSTALL_DIR = ${TBB_INSTALL_DIR}""); find_package(TBB 2021.4; HINTS ${TBB_ROOT_SEARCH}; COMPONENTS tbb tbbmalloc tbbmalloc_proxy); message(""[in TBB_RECONFIGURE] TBB_LIBRARIES = ${TBB_LIBRARIES}""); endif(). #message(""TBB_LIBRARIES = ${TBB_LIBRARIES}""); #message(""TBB_FOUND ${TBB_FOUND} ""); #message(""TBB_INSTALL_DIR ${TBB_INSTALL_DIR}""); #message(""TBB_INCLUDE_DIRS ${TBB_INCLUDE_DIRS}""); #message(""TBB_INCLUDE_DIR ${TBB_INCLUDE_DIR} ""); #message(""TBB_LIBRARY_DIRS ${TBB_LIBRARY_DIRS}""); #message(""TBB_LIBRARIES ${TBB_LIBRARIES} ""). find_package(libgff 2.0.0 ; HINTS ${LIB_GFF_PATH} ${GFF_ROOT}; ); if(libgff_FOUND); message(STATUS ""libgff ver. ${LIB_GFF_VERSION} found.""); message(STA",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:26189,Deployability,install,install,26189,"ARY ${TBB_INSTALL_DIR}/lib); set(TBB_LIB_DIR ${TBB_INSTALL_DIR}/lib); #set(TBB_LIBRARIES tbb tbbmalloc); set(TBB_LIBRARIES ${TBB_INSTALL_DIR}/lib/libtbb.${SHARED_LIB_EXTENSION}; 			${TBB_INSTALL_DIR}/lib/libtbbmalloc.${SHARED_LIB_EXTENSION}; ${TBB_INSTALL_DIR}/lib/libtbbmalloc_proxy.${SHARED_LIB_EXTENSION}; 	 ); message(""TBB_INCLUDE_DIRS = ${TBB_INCLUDE_DIRS}""); message(""TBB_LIBRARY_DIRS = ${TBB_LIBRARY_DIRS}""); endif(). ##; # Similar to the Boost trick above, the libtbb reconfigure should force this code; # to be run on the second configuration pass, where it should appropriately set the; # TBB_INSTALL_DIR variable.; ##; if(TBB_RECONFIGURE); unset(TBB_FOUND CACHE); unset(TBB_INSTALL_DIR CACHE); unset(CMAKE_PREFIX_PATH CACHE); unset(TBB_INCLUDE_DIRS CACHE); unset(TBB_INCLUDE_DIR CACHE); unset(TBB_LIBRARY_DIRS CACHE); unset(TBB_LIBRARY CACHE); unset(TBB_LIBRARIES CACHE); set(CMAKE_PREFIX_PATH ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(TBB_INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(TBB_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(TBB_INCLUDE_DIRS ${TBB_INSTALL_DIR}/include); set(TBB_INCLUDE_DIR ${TBB_INSTALL_DIR}/include); set(TBB_LIBRARY_DIRS ${TBB_INSTALL_DIR}/lib); set(TBB_LIBRARY ${TBB_INSTALL_DIR}/lib); set(TBB_LIB_DIR ${TBB_INSTALL_DIR}/lib); message(""TBB_INSTALL_DIR = ${TBB_INSTALL_DIR}""); find_package(TBB 2021.4; HINTS ${TBB_ROOT_SEARCH}; COMPONENTS tbb tbbmalloc tbbmalloc_proxy); message(""[in TBB_RECONFIGURE] TBB_LIBRARIES = ${TBB_LIBRARIES}""); endif(). #message(""TBB_LIBRARIES = ${TBB_LIBRARIES}""); #message(""TBB_FOUND ${TBB_FOUND} ""); #message(""TBB_INSTALL_DIR ${TBB_INSTALL_DIR}""); #message(""TBB_INCLUDE_DIRS ${TBB_INCLUDE_DIRS}""); #message(""TBB_INCLUDE_DIR ${TBB_INCLUDE_DIR} ""); #message(""TBB_LIBRARY_DIRS ${TBB_LIBRARY_DIRS}""); #message(""TBB_LIBRARIES ${TBB_LIBRARIES} ""). find_package(libgff 2.0.0 ; HINTS ${LIB_GFF_PATH} ${GFF_ROOT}; ); if(libgff_FOUND); message(STATUS ""libgff ver. ${LIB_GFF_VERSION} found.""); message(STA",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:27774,Deployability,install,install,27774,"ge(""TBB_INCLUDE_DIRS ${TBB_INCLUDE_DIRS}""); #message(""TBB_INCLUDE_DIR ${TBB_INCLUDE_DIR} ""); #message(""TBB_LIBRARY_DIRS ${TBB_LIBRARY_DIRS}""); #message(""TBB_LIBRARIES ${TBB_LIBRARIES} ""). find_package(libgff 2.0.0 ; HINTS ${LIB_GFF_PATH} ${GFF_ROOT}; ); if(libgff_FOUND); message(STATUS ""libgff ver. ${LIB_GFF_VERSION} found.""); message(STATUS "" include: ${LIB_GFF_INCLUDE_DIR}""); message(STATUS "" lib : ${LIB_GFF_LIBRARY_DIR}""); endif(). if(NOT libgff_FOUND); message(""Build system will compile libgff""); message(""==================================================================""); externalproject_add(libgff; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://github.com/COMBINE-lab/libgff/archive/v2.0.0.tar.gz -o libgff.tgz &&; ${SHASUM} 7656b19459a7ca7d2fd0fcec4f2e0fd0deec1b4f39c703a114e8f4c22d82a99c libgff.tgz &&; tar -xzvf libgff.tgz; SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/libgff-2.0.0; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; BINARY_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/libgff-2.0.0/build; CMAKE_ARGS -DCMAKE_INSTALL_PREFIX:PATH=<INSTALL_DIR> -DCMAKE_CXX_COMPILER=${CMAKE_CXX_COMPILER} -DCMAKE_C_COMPILER=${CMAKE_C_COMPILER} ; ); externalproject_add_step(libgff makedir; COMMAND mkdir -p <SOURCE_DIR>/build; COMMENT ""Make build directory""; DEPENDEES download; DEPENDERS configure); set(FETCHED_GFF TRUE); set(LIB_GFF_PATH ${CMAKE_CURRENT_SOURCE_DIR}/external/install); endif(). # Because of the way that Apple has changed SIP; # in el capitan, some headers may be in a new location; if(APPLE); set(STADEN_INC ""-I/usr/local/include""); set(STADEN_LIB ""-L/usr/local/lib""); endif(). if(CONDA_BUILD); set(LZFLAG ""-lz""); else(); set(LZFLAG """"); endif(). find_package(CURL). if (FETCH_STADEN); set(LIBSTADEN_FOUND FALSE); else (); find_package(libstadenio 1.14.15); endif(). if (NOT LIBSTADENIO_FOUND); message(""Build system will compile Staden IOLib""); message(""================================================================",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:28220,Deployability,install,install,28220,"bgff_FOUND); message(STATUS ""libgff ver. ${LIB_GFF_VERSION} found.""); message(STATUS "" include: ${LIB_GFF_INCLUDE_DIR}""); message(STATUS "" lib : ${LIB_GFF_LIBRARY_DIR}""); endif(). if(NOT libgff_FOUND); message(""Build system will compile libgff""); message(""==================================================================""); externalproject_add(libgff; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://github.com/COMBINE-lab/libgff/archive/v2.0.0.tar.gz -o libgff.tgz &&; ${SHASUM} 7656b19459a7ca7d2fd0fcec4f2e0fd0deec1b4f39c703a114e8f4c22d82a99c libgff.tgz &&; tar -xzvf libgff.tgz; SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/libgff-2.0.0; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; BINARY_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/libgff-2.0.0/build; CMAKE_ARGS -DCMAKE_INSTALL_PREFIX:PATH=<INSTALL_DIR> -DCMAKE_CXX_COMPILER=${CMAKE_CXX_COMPILER} -DCMAKE_C_COMPILER=${CMAKE_C_COMPILER} ; ); externalproject_add_step(libgff makedir; COMMAND mkdir -p <SOURCE_DIR>/build; COMMENT ""Make build directory""; DEPENDEES download; DEPENDERS configure); set(FETCHED_GFF TRUE); set(LIB_GFF_PATH ${CMAKE_CURRENT_SOURCE_DIR}/external/install); endif(). # Because of the way that Apple has changed SIP; # in el capitan, some headers may be in a new location; if(APPLE); set(STADEN_INC ""-I/usr/local/include""); set(STADEN_LIB ""-L/usr/local/lib""); endif(). if(CONDA_BUILD); set(LZFLAG ""-lz""); else(); set(LZFLAG """"); endif(). find_package(CURL). if (FETCH_STADEN); set(LIBSTADEN_FOUND FALSE); else (); find_package(libstadenio 1.14.15); endif(). if (NOT LIBSTADENIO_FOUND); message(""Build system will compile Staden IOLib""); message(""==================================================================""); externalproject_add(libstadenio; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://github.com/jkbonfield/io_lib/releases/download/io_lib-1-14-15/io_lib-1.14.15.tar.gz -o staden-io_lib-v1.14.15.tar.gz &&; ${SHASUM} 20",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:28936,Deployability,release,releases,28936," -DCMAKE_C_COMPILER=${CMAKE_C_COMPILER} ; ); externalproject_add_step(libgff makedir; COMMAND mkdir -p <SOURCE_DIR>/build; COMMENT ""Make build directory""; DEPENDEES download; DEPENDERS configure); set(FETCHED_GFF TRUE); set(LIB_GFF_PATH ${CMAKE_CURRENT_SOURCE_DIR}/external/install); endif(). # Because of the way that Apple has changed SIP; # in el capitan, some headers may be in a new location; if(APPLE); set(STADEN_INC ""-I/usr/local/include""); set(STADEN_LIB ""-L/usr/local/lib""); endif(). if(CONDA_BUILD); set(LZFLAG ""-lz""); else(); set(LZFLAG """"); endif(). find_package(CURL). if (FETCH_STADEN); set(LIBSTADEN_FOUND FALSE); else (); find_package(libstadenio 1.14.15); endif(). if (NOT LIBSTADENIO_FOUND); message(""Build system will compile Staden IOLib""); message(""==================================================================""); externalproject_add(libstadenio; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://github.com/jkbonfield/io_lib/releases/download/io_lib-1-14-15/io_lib-1.14.15.tar.gz -o staden-io_lib-v1.14.15.tar.gz &&; ${SHASUM} 20814c4365e1e2fe6630fb11d0df370dec4c5688af3871de7f1cb0129671401e staden-io_lib-v1.14.15.tar.gz &&; mkdir -p staden-io_lib-1.14.15 &&; tar -xzf staden-io_lib-v1.14.15.tar.gz --strip-components=1 -C staden-io_lib-1.14.15 &&; rm -fr staden-io_lib &&; mv -f staden-io_lib-1.14.15 staden-io_lib; SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/staden-io_lib; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; CONFIGURE_COMMAND ./configure --enable-shared=no --without-libcurl --prefix=<INSTALL_DIR> LDFLAGS=${LIBSTADEN_LDFLAGS} CFLAGS=${LIBSTADEN_CFLAGS} CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER}; BUILD_COMMAND make ${QUIET_MAKE} CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER} CFLAGS+=${STADEN_INC} CFLAGS+=${STADEN_LIB} LDFLAGS+=${EXTRA_CMAKE_LIBRARY_FLAGS} CFLAGS+=${EXTRA_CMAKE_INCLUDE_FLAGS} CFLAGS+=${LZFLAG} CFLAGS+=${SCHAR_FLAG}. BUILD_IN_SOURCE 1; INSTALL_COMMAND make install; ); if(NOT",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:29441,Deployability,install,install,29441,"e""); set(STADEN_LIB ""-L/usr/local/lib""); endif(). if(CONDA_BUILD); set(LZFLAG ""-lz""); else(); set(LZFLAG """"); endif(). find_package(CURL). if (FETCH_STADEN); set(LIBSTADEN_FOUND FALSE); else (); find_package(libstadenio 1.14.15); endif(). if (NOT LIBSTADENIO_FOUND); message(""Build system will compile Staden IOLib""); message(""==================================================================""); externalproject_add(libstadenio; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://github.com/jkbonfield/io_lib/releases/download/io_lib-1-14-15/io_lib-1.14.15.tar.gz -o staden-io_lib-v1.14.15.tar.gz &&; ${SHASUM} 20814c4365e1e2fe6630fb11d0df370dec4c5688af3871de7f1cb0129671401e staden-io_lib-v1.14.15.tar.gz &&; mkdir -p staden-io_lib-1.14.15 &&; tar -xzf staden-io_lib-v1.14.15.tar.gz --strip-components=1 -C staden-io_lib-1.14.15 &&; rm -fr staden-io_lib &&; mv -f staden-io_lib-1.14.15 staden-io_lib; SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/staden-io_lib; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; CONFIGURE_COMMAND ./configure --enable-shared=no --without-libcurl --prefix=<INSTALL_DIR> LDFLAGS=${LIBSTADEN_LDFLAGS} CFLAGS=${LIBSTADEN_CFLAGS} CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER}; BUILD_COMMAND make ${QUIET_MAKE} CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER} CFLAGS+=${STADEN_INC} CFLAGS+=${STADEN_LIB} LDFLAGS+=${EXTRA_CMAKE_LIBRARY_FLAGS} CFLAGS+=${EXTRA_CMAKE_INCLUDE_FLAGS} CFLAGS+=${LZFLAG} CFLAGS+=${SCHAR_FLAG}. BUILD_IN_SOURCE 1; INSTALL_COMMAND make install; ); if(NOT LIBLZMA_FOUND); 	ExternalProject_Add_StepDependencies(libstadenio build liblzma); endif(). set(FETCHED_STADEN TRUE); set(STADEN_LIBRARIES ""${GAT_SOURCE_DIR}/external/install/lib/libstaden-read.a;${GAT_SOURCE_DIR}/external/install/lib/libhtscodecs.a""); endif(). if (ASAN_BUILD); set(FAST_MALLOC_LIB """"); set(HAVE_FAST_MALLOC TRUE); else(); set(FAST_MALLOC_LIB """"); set(HAVE_FAST_MALLOC FALSE). # See if we have Jemalloc; find_package(Jemalloc);",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:29928,Deployability,install,install,29928,"-14-15/io_lib-1.14.15.tar.gz -o staden-io_lib-v1.14.15.tar.gz &&; ${SHASUM} 20814c4365e1e2fe6630fb11d0df370dec4c5688af3871de7f1cb0129671401e staden-io_lib-v1.14.15.tar.gz &&; mkdir -p staden-io_lib-1.14.15 &&; tar -xzf staden-io_lib-v1.14.15.tar.gz --strip-components=1 -C staden-io_lib-1.14.15 &&; rm -fr staden-io_lib &&; mv -f staden-io_lib-1.14.15 staden-io_lib; SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/staden-io_lib; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; CONFIGURE_COMMAND ./configure --enable-shared=no --without-libcurl --prefix=<INSTALL_DIR> LDFLAGS=${LIBSTADEN_LDFLAGS} CFLAGS=${LIBSTADEN_CFLAGS} CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER}; BUILD_COMMAND make ${QUIET_MAKE} CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER} CFLAGS+=${STADEN_INC} CFLAGS+=${STADEN_LIB} LDFLAGS+=${EXTRA_CMAKE_LIBRARY_FLAGS} CFLAGS+=${EXTRA_CMAKE_INCLUDE_FLAGS} CFLAGS+=${LZFLAG} CFLAGS+=${SCHAR_FLAG}. BUILD_IN_SOURCE 1; INSTALL_COMMAND make install; ); if(NOT LIBLZMA_FOUND); 	ExternalProject_Add_StepDependencies(libstadenio build liblzma); endif(). set(FETCHED_STADEN TRUE); set(STADEN_LIBRARIES ""${GAT_SOURCE_DIR}/external/install/lib/libstaden-read.a;${GAT_SOURCE_DIR}/external/install/lib/libhtscodecs.a""); endif(). if (ASAN_BUILD); set(FAST_MALLOC_LIB """"); set(HAVE_FAST_MALLOC TRUE); else(); set(FAST_MALLOC_LIB """"); set(HAVE_FAST_MALLOC FALSE). # See if we have Jemalloc; find_package(Jemalloc); if(Jemalloc_FOUND); ##; # Don't be so stringent about the version yet; ##; #if (NOT (${JEMALLOC_VERSION} VERSION_LESS 5.2.1)); message(""Found Jemalloc library --- using this memory allocator""); set(FAST_MALLOC_LIB ${JEMALLOC_LIBRARIES}); set(HAVE_FAST_MALLOC TRUE); #else(); # message(""Fond Jemalloc version ${JEMALLOC_VERSION}, but require >= 5.2.1. Downloading newer version""); #endif(); endif(); endif(). if(CONDA_BUILD); set(JEMALLOC_FLAGS ""CC=${CMAKE_C_COMPILER} CFLAGS=\\\""-fPIC ${SCHAR_FLAG}\\\"" CPPFLAGS=\\\""-fPIC ${SCHAR_FLAG}\\\""""); else(); set(JEMALLOC_FLAGS """,MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:30113,Deployability,install,install,30113,"1cb0129671401e staden-io_lib-v1.14.15.tar.gz &&; mkdir -p staden-io_lib-1.14.15 &&; tar -xzf staden-io_lib-v1.14.15.tar.gz --strip-components=1 -C staden-io_lib-1.14.15 &&; rm -fr staden-io_lib &&; mv -f staden-io_lib-1.14.15 staden-io_lib; SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/staden-io_lib; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; CONFIGURE_COMMAND ./configure --enable-shared=no --without-libcurl --prefix=<INSTALL_DIR> LDFLAGS=${LIBSTADEN_LDFLAGS} CFLAGS=${LIBSTADEN_CFLAGS} CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER}; BUILD_COMMAND make ${QUIET_MAKE} CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER} CFLAGS+=${STADEN_INC} CFLAGS+=${STADEN_LIB} LDFLAGS+=${EXTRA_CMAKE_LIBRARY_FLAGS} CFLAGS+=${EXTRA_CMAKE_INCLUDE_FLAGS} CFLAGS+=${LZFLAG} CFLAGS+=${SCHAR_FLAG}. BUILD_IN_SOURCE 1; INSTALL_COMMAND make install; ); if(NOT LIBLZMA_FOUND); 	ExternalProject_Add_StepDependencies(libstadenio build liblzma); endif(). set(FETCHED_STADEN TRUE); set(STADEN_LIBRARIES ""${GAT_SOURCE_DIR}/external/install/lib/libstaden-read.a;${GAT_SOURCE_DIR}/external/install/lib/libhtscodecs.a""); endif(). if (ASAN_BUILD); set(FAST_MALLOC_LIB """"); set(HAVE_FAST_MALLOC TRUE); else(); set(FAST_MALLOC_LIB """"); set(HAVE_FAST_MALLOC FALSE). # See if we have Jemalloc; find_package(Jemalloc); if(Jemalloc_FOUND); ##; # Don't be so stringent about the version yet; ##; #if (NOT (${JEMALLOC_VERSION} VERSION_LESS 5.2.1)); message(""Found Jemalloc library --- using this memory allocator""); set(FAST_MALLOC_LIB ${JEMALLOC_LIBRARIES}); set(HAVE_FAST_MALLOC TRUE); #else(); # message(""Fond Jemalloc version ${JEMALLOC_VERSION}, but require >= 5.2.1. Downloading newer version""); #endif(); endif(); endif(). if(CONDA_BUILD); set(JEMALLOC_FLAGS ""CC=${CMAKE_C_COMPILER} CFLAGS=\\\""-fPIC ${SCHAR_FLAG}\\\"" CPPFLAGS=\\\""-fPIC ${SCHAR_FLAG}\\\""""); else(); set(JEMALLOC_FLAGS ""CC=${CMAKE_C_COMPILER} CFLAGS=${SCHAR_FLAG} CPPFLAGS=${SCHAR_FLAG}""); endif(). if(NOT HAVE_FAST_MALLOC); message(""Build system ",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:30169,Deployability,install,install,30169," &&; tar -xzf staden-io_lib-v1.14.15.tar.gz --strip-components=1 -C staden-io_lib-1.14.15 &&; rm -fr staden-io_lib &&; mv -f staden-io_lib-1.14.15 staden-io_lib; SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/staden-io_lib; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; CONFIGURE_COMMAND ./configure --enable-shared=no --without-libcurl --prefix=<INSTALL_DIR> LDFLAGS=${LIBSTADEN_LDFLAGS} CFLAGS=${LIBSTADEN_CFLAGS} CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER}; BUILD_COMMAND make ${QUIET_MAKE} CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER} CFLAGS+=${STADEN_INC} CFLAGS+=${STADEN_LIB} LDFLAGS+=${EXTRA_CMAKE_LIBRARY_FLAGS} CFLAGS+=${EXTRA_CMAKE_INCLUDE_FLAGS} CFLAGS+=${LZFLAG} CFLAGS+=${SCHAR_FLAG}. BUILD_IN_SOURCE 1; INSTALL_COMMAND make install; ); if(NOT LIBLZMA_FOUND); 	ExternalProject_Add_StepDependencies(libstadenio build liblzma); endif(). set(FETCHED_STADEN TRUE); set(STADEN_LIBRARIES ""${GAT_SOURCE_DIR}/external/install/lib/libstaden-read.a;${GAT_SOURCE_DIR}/external/install/lib/libhtscodecs.a""); endif(). if (ASAN_BUILD); set(FAST_MALLOC_LIB """"); set(HAVE_FAST_MALLOC TRUE); else(); set(FAST_MALLOC_LIB """"); set(HAVE_FAST_MALLOC FALSE). # See if we have Jemalloc; find_package(Jemalloc); if(Jemalloc_FOUND); ##; # Don't be so stringent about the version yet; ##; #if (NOT (${JEMALLOC_VERSION} VERSION_LESS 5.2.1)); message(""Found Jemalloc library --- using this memory allocator""); set(FAST_MALLOC_LIB ${JEMALLOC_LIBRARIES}); set(HAVE_FAST_MALLOC TRUE); #else(); # message(""Fond Jemalloc version ${JEMALLOC_VERSION}, but require >= 5.2.1. Downloading newer version""); #endif(); endif(); endif(). if(CONDA_BUILD); set(JEMALLOC_FLAGS ""CC=${CMAKE_C_COMPILER} CFLAGS=\\\""-fPIC ${SCHAR_FLAG}\\\"" CPPFLAGS=\\\""-fPIC ${SCHAR_FLAG}\\\""""); else(); set(JEMALLOC_FLAGS ""CC=${CMAKE_C_COMPILER} CFLAGS=${SCHAR_FLAG} CPPFLAGS=${SCHAR_FLAG}""); endif(). if(NOT HAVE_FAST_MALLOC); message(""Build system will fetch and use JEMalloc""); message(""======================================",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:31666,Deployability,install,install,31666,"; #else(); # message(""Fond Jemalloc version ${JEMALLOC_VERSION}, but require >= 5.2.1. Downloading newer version""); #endif(); endif(); endif(). if(CONDA_BUILD); set(JEMALLOC_FLAGS ""CC=${CMAKE_C_COMPILER} CFLAGS=\\\""-fPIC ${SCHAR_FLAG}\\\"" CPPFLAGS=\\\""-fPIC ${SCHAR_FLAG}\\\""""); else(); set(JEMALLOC_FLAGS ""CC=${CMAKE_C_COMPILER} CFLAGS=${SCHAR_FLAG} CPPFLAGS=${SCHAR_FLAG}""); endif(). if(NOT HAVE_FAST_MALLOC); message(""Build system will fetch and use JEMalloc""); message(""==================================================================""); externalproject_add(libjemalloc; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://github.com/jemalloc/jemalloc/archive/5.2.1.tar.gz -o jemalloc-5.2.1.tar.gz &&; ${SHASUM} ed51b0b37098af4ca6ed31c22324635263f8ad6471889e0592a9c0dba9136aea jemalloc-5.2.1.tar.gz &&; tar -xzf jemalloc-5.2.1.tar.gz. SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/jemalloc-5.2.1; BUILD_IN_SOURCE TRUE; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; CONFIGURE_COMMAND sh -c ""${JEMALLOC_FLAGS} ./autogen.sh --disable-debug ${MALLOC_STATIC_BUILD_FLAG} --prefix=<INSTALL_DIR>""; #CONFIGURE_COMMAND sh -c ""${JEMALLOC_FLAGS} ./autogen.sh ${MALLOC_STATIC_BUILD_FLAG} --prefix=<INSTALL_DIR>""; INSTALL_COMMAND cp -r lib <INSTALL_DIR>/ && cp -r include <INSTALL_DIR>/; ). set(FAST_MALLOC_LIB ${CMAKE_CURRENT_SOURCE_DIR}/external/install/lib/libjemalloc.a); set(HAVE_FAST_MALLOC TRUE); set(FETCHED_JEMALLOC TRUE); if(FETCHED_LIBBZ2); add_dependencies(libjemalloc libbz2); endif(). if(FETCHED_LIBLZMA); add_dependencies(libjemalloc liblzma); endif(); endif(). ###; #; # Done building external dependencies.; #; ###. set(CPACK_SOURCE_IGNORE_FILES; ""/src/PCA.cpp""; ""/src/PCAUtils.cpp""; ""/build/""; ""/scripts/AggregateToGeneLevel.py""; ""/scripts/ExpressionTools.py""; ""/scripts/GenerateExpressionFiles.sh""; ""/scripts/ParseSoftFile.py""; ""/scripts/PlotCorrelation.py""; ""/scripts/junk""; ""/scripts/sfstrace.log""; ""/scripts/SFPipeline.py""; ""/bin/""; ""/lib",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:32044,Deployability,install,install,32044,"}""); endif(). if(NOT HAVE_FAST_MALLOC); message(""Build system will fetch and use JEMalloc""); message(""==================================================================""); externalproject_add(libjemalloc; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://github.com/jemalloc/jemalloc/archive/5.2.1.tar.gz -o jemalloc-5.2.1.tar.gz &&; ${SHASUM} ed51b0b37098af4ca6ed31c22324635263f8ad6471889e0592a9c0dba9136aea jemalloc-5.2.1.tar.gz &&; tar -xzf jemalloc-5.2.1.tar.gz. SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/jemalloc-5.2.1; BUILD_IN_SOURCE TRUE; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; CONFIGURE_COMMAND sh -c ""${JEMALLOC_FLAGS} ./autogen.sh --disable-debug ${MALLOC_STATIC_BUILD_FLAG} --prefix=<INSTALL_DIR>""; #CONFIGURE_COMMAND sh -c ""${JEMALLOC_FLAGS} ./autogen.sh ${MALLOC_STATIC_BUILD_FLAG} --prefix=<INSTALL_DIR>""; INSTALL_COMMAND cp -r lib <INSTALL_DIR>/ && cp -r include <INSTALL_DIR>/; ). set(FAST_MALLOC_LIB ${CMAKE_CURRENT_SOURCE_DIR}/external/install/lib/libjemalloc.a); set(HAVE_FAST_MALLOC TRUE); set(FETCHED_JEMALLOC TRUE); if(FETCHED_LIBBZ2); add_dependencies(libjemalloc libbz2); endif(). if(FETCHED_LIBLZMA); add_dependencies(libjemalloc liblzma); endif(); endif(). ###; #; # Done building external dependencies.; #; ###. set(CPACK_SOURCE_IGNORE_FILES; ""/src/PCA.cpp""; ""/src/PCAUtils.cpp""; ""/build/""; ""/scripts/AggregateToGeneLevel.py""; ""/scripts/ExpressionTools.py""; ""/scripts/GenerateExpressionFiles.sh""; ""/scripts/ParseSoftFile.py""; ""/scripts/PlotCorrelation.py""; ""/scripts/junk""; ""/scripts/sfstrace.log""; ""/scripts/SFPipeline.py""; ""/bin/""; ""/lib/""; ""/sample_data/""; ""PublishREADMEToWebsite.sh""; ""/external/""; ""/src/obsolete/""; ""/include/obsolete/""; ""WebsiteHeader.txt""; ""/experimental_configs/""; "".git/""). message(""CPACK_SOURCE_IGNORE_FILES = ${CPACK_SOURCE_IGNORE_FILES}""). # we will use this property later; define_property(TARGET PROPERTY COMPACT_VECTOR_DIR INHERITED ; BRIEF_DOCS ""the path to the directory conta",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:33634,Deployability,install,installer,33634,"TALL_DIR>""; INSTALL_COMMAND cp -r lib <INSTALL_DIR>/ && cp -r include <INSTALL_DIR>/; ). set(FAST_MALLOC_LIB ${CMAKE_CURRENT_SOURCE_DIR}/external/install/lib/libjemalloc.a); set(HAVE_FAST_MALLOC TRUE); set(FETCHED_JEMALLOC TRUE); if(FETCHED_LIBBZ2); add_dependencies(libjemalloc libbz2); endif(). if(FETCHED_LIBLZMA); add_dependencies(libjemalloc liblzma); endif(); endif(). ###; #; # Done building external dependencies.; #; ###. set(CPACK_SOURCE_IGNORE_FILES; ""/src/PCA.cpp""; ""/src/PCAUtils.cpp""; ""/build/""; ""/scripts/AggregateToGeneLevel.py""; ""/scripts/ExpressionTools.py""; ""/scripts/GenerateExpressionFiles.sh""; ""/scripts/ParseSoftFile.py""; ""/scripts/PlotCorrelation.py""; ""/scripts/junk""; ""/scripts/sfstrace.log""; ""/scripts/SFPipeline.py""; ""/bin/""; ""/lib/""; ""/sample_data/""; ""PublishREADMEToWebsite.sh""; ""/external/""; ""/src/obsolete/""; ""/include/obsolete/""; ""WebsiteHeader.txt""; ""/experimental_configs/""; "".git/""). message(""CPACK_SOURCE_IGNORE_FILES = ${CPACK_SOURCE_IGNORE_FILES}""). # we will use this property later; define_property(TARGET PROPERTY COMPACT_VECTOR_DIR INHERITED ; BRIEF_DOCS ""the path to the directory containing the compact_vector include tree""; FULL_DOCS ""the path to the directory containing the compact_vector include tree""). # Recurse into pufferfish source directory ; # and build the library ; set(BUILD_PUFF_FOR_SALMON TRUE); add_subdirectory(external/pufferfish). # make sure we know the path to compact_vector; get_property(COMPACT_VECTOR_INCLUDE_PATH TARGET graphdump PROPERTY COMPACT_VECTOR_DIR); message(""fetched path for compact_vector as [${COMPACT_VECTOR_INCLUDE_PATH}]""). # and then the main salmon source directory; add_subdirectory(src). #add_dependencies(salmon RapMap); # build a CPack driven installer package; include(CPack). set(ARCHIVE_NAME ${CMAKE_PROJECT_NAME}-${PROJECT_VERSION}); add_custom_target(dist; COMMAND git archive --prefix=${ARCHIVE_NAME}/ HEAD; | gzip > ${CMAKE_BINARY_DIR}/${ARCHIVE_NAME}.tar.gz; WORKING_DIRECTORY ${CMAKE_SOURCE_DIR}); ",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:107,Integrability,message,message,107,"cmake_minimum_required(VERSION 3.15). if(DEFINED ENV{CC}); set(CC $ENV{CC}); else(); set(CC gcc); endif(); message(""CC: ${CC}""). set(CC_VERSION """"); if(${CC} MATCHES ^gcc-); string(REGEX REPLACE ""gcc-"" """" CC_VERSION ${CC}); endif(); message(""CC version: ${CC_VERSION}""). enable_testing(). project(Salmon). # detect host architecture ; if(NOT DEFINED USE_ARM); if(CMAKE_SYSTEM_PROCESSOR MATCHES ""^(aarch64.*|AARCH64.*|arm64.*|ARM64.*)""); message(""Detected 64-bit ARM host. Setting USE_ARM to true.""); set(USE_ARM TRUE); # set char to be signed; add_compile_options(-fsigned-char); set(SCHAR_FLAG ""-fsigned-char""); else(); message(""Detected non-ARM host. Setting USE_ARM to false.""); set(USE_ARM FALSE); set(SCHAR_FLAG """"); endif(); endif(). option(USE_SHARED_LIBS ""Use shared instead of static libraries"" OFF). # auto-populate version:; # from https://stackoverflow.com/questions/47066115/cmake-get-version-from-multi-line-text-file; file(READ ""current_version.txt"" ver). string(REGEX MATCH ""VERSION_MAJOR ([0-9]*)"" _ ${ver}); set(ver_major ${CMAKE_MATCH_1}). string(REGEX MATCH ""VERSION_MINOR ([0-9]*)"" _ ${ver}); set(ver_minor ${CMAKE_MATCH_1}). string(REGEX MATCH ""VERSION_PATCH ([0-9]*)"" _ ${ver}); set(ver_patch ${CMAKE_MATCH_1}). set(CPACK_PACKAGE_VERSION_MAJOR ${ver_major}); set(CPACK_PACKAGE_VERSION_MINOR ${ver_minor}); set(CPACK_PACKAGE_VERSION_PATCH ${ver_patch}). set(CPACK_PACKAGE_VERSION ""${ver_major}.${ver_minor}.${ver_patch}""); message(""version: ${CPACK_PACKAGE_VERSION}""). set(PROJECT_VERSION ${CPACK_PACKAGE_VERSION}); set(CPACK_GENERATOR ""TGZ""); set(CPACK_SOURCE_GENERATOR ""TGZ""); set(CPACK_PACKAGE_VENDOR ""University of Maryland""); set(CPACK_PACKAGE_DESCRIPTION_SUMMARY ""Salmon - Wicked-fast RNA-seq isoform quantification using selective alignment""); set(CPACK_PACKAGE_NAME; ""${CMAKE_PROJECT_NAME}-${CPACK_PACKAGE_VERSION_MAJOR}.${CPACK_PACKAGE_VERSION_MINOR}.${CPACK_PACKAGE_VERSION_PATCH}""); set(CPACK_SOURCE_PACKAGE_FILE_NAME; ""${CMAKE_PROJECT_NAME}-${CPACK_PACKAGE_VERSION_MA",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:233,Integrability,message,message,233,"cmake_minimum_required(VERSION 3.15). if(DEFINED ENV{CC}); set(CC $ENV{CC}); else(); set(CC gcc); endif(); message(""CC: ${CC}""). set(CC_VERSION """"); if(${CC} MATCHES ^gcc-); string(REGEX REPLACE ""gcc-"" """" CC_VERSION ${CC}); endif(); message(""CC version: ${CC_VERSION}""). enable_testing(). project(Salmon). # detect host architecture ; if(NOT DEFINED USE_ARM); if(CMAKE_SYSTEM_PROCESSOR MATCHES ""^(aarch64.*|AARCH64.*|arm64.*|ARM64.*)""); message(""Detected 64-bit ARM host. Setting USE_ARM to true.""); set(USE_ARM TRUE); # set char to be signed; add_compile_options(-fsigned-char); set(SCHAR_FLAG ""-fsigned-char""); else(); message(""Detected non-ARM host. Setting USE_ARM to false.""); set(USE_ARM FALSE); set(SCHAR_FLAG """"); endif(); endif(). option(USE_SHARED_LIBS ""Use shared instead of static libraries"" OFF). # auto-populate version:; # from https://stackoverflow.com/questions/47066115/cmake-get-version-from-multi-line-text-file; file(READ ""current_version.txt"" ver). string(REGEX MATCH ""VERSION_MAJOR ([0-9]*)"" _ ${ver}); set(ver_major ${CMAKE_MATCH_1}). string(REGEX MATCH ""VERSION_MINOR ([0-9]*)"" _ ${ver}); set(ver_minor ${CMAKE_MATCH_1}). string(REGEX MATCH ""VERSION_PATCH ([0-9]*)"" _ ${ver}); set(ver_patch ${CMAKE_MATCH_1}). set(CPACK_PACKAGE_VERSION_MAJOR ${ver_major}); set(CPACK_PACKAGE_VERSION_MINOR ${ver_minor}); set(CPACK_PACKAGE_VERSION_PATCH ${ver_patch}). set(CPACK_PACKAGE_VERSION ""${ver_major}.${ver_minor}.${ver_patch}""); message(""version: ${CPACK_PACKAGE_VERSION}""). set(PROJECT_VERSION ${CPACK_PACKAGE_VERSION}); set(CPACK_GENERATOR ""TGZ""); set(CPACK_SOURCE_GENERATOR ""TGZ""); set(CPACK_PACKAGE_VENDOR ""University of Maryland""); set(CPACK_PACKAGE_DESCRIPTION_SUMMARY ""Salmon - Wicked-fast RNA-seq isoform quantification using selective alignment""); set(CPACK_PACKAGE_NAME; ""${CMAKE_PROJECT_NAME}-${CPACK_PACKAGE_VERSION_MAJOR}.${CPACK_PACKAGE_VERSION_MINOR}.${CPACK_PACKAGE_VERSION_PATCH}""); set(CPACK_SOURCE_PACKAGE_FILE_NAME; ""${CMAKE_PROJECT_NAME}-${CPACK_PACKAGE_VERSION_MA",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:437,Integrability,message,message,437,"cmake_minimum_required(VERSION 3.15). if(DEFINED ENV{CC}); set(CC $ENV{CC}); else(); set(CC gcc); endif(); message(""CC: ${CC}""). set(CC_VERSION """"); if(${CC} MATCHES ^gcc-); string(REGEX REPLACE ""gcc-"" """" CC_VERSION ${CC}); endif(); message(""CC version: ${CC_VERSION}""). enable_testing(). project(Salmon). # detect host architecture ; if(NOT DEFINED USE_ARM); if(CMAKE_SYSTEM_PROCESSOR MATCHES ""^(aarch64.*|AARCH64.*|arm64.*|ARM64.*)""); message(""Detected 64-bit ARM host. Setting USE_ARM to true.""); set(USE_ARM TRUE); # set char to be signed; add_compile_options(-fsigned-char); set(SCHAR_FLAG ""-fsigned-char""); else(); message(""Detected non-ARM host. Setting USE_ARM to false.""); set(USE_ARM FALSE); set(SCHAR_FLAG """"); endif(); endif(). option(USE_SHARED_LIBS ""Use shared instead of static libraries"" OFF). # auto-populate version:; # from https://stackoverflow.com/questions/47066115/cmake-get-version-from-multi-line-text-file; file(READ ""current_version.txt"" ver). string(REGEX MATCH ""VERSION_MAJOR ([0-9]*)"" _ ${ver}); set(ver_major ${CMAKE_MATCH_1}). string(REGEX MATCH ""VERSION_MINOR ([0-9]*)"" _ ${ver}); set(ver_minor ${CMAKE_MATCH_1}). string(REGEX MATCH ""VERSION_PATCH ([0-9]*)"" _ ${ver}); set(ver_patch ${CMAKE_MATCH_1}). set(CPACK_PACKAGE_VERSION_MAJOR ${ver_major}); set(CPACK_PACKAGE_VERSION_MINOR ${ver_minor}); set(CPACK_PACKAGE_VERSION_PATCH ${ver_patch}). set(CPACK_PACKAGE_VERSION ""${ver_major}.${ver_minor}.${ver_patch}""); message(""version: ${CPACK_PACKAGE_VERSION}""). set(PROJECT_VERSION ${CPACK_PACKAGE_VERSION}); set(CPACK_GENERATOR ""TGZ""); set(CPACK_SOURCE_GENERATOR ""TGZ""); set(CPACK_PACKAGE_VENDOR ""University of Maryland""); set(CPACK_PACKAGE_DESCRIPTION_SUMMARY ""Salmon - Wicked-fast RNA-seq isoform quantification using selective alignment""); set(CPACK_PACKAGE_NAME; ""${CMAKE_PROJECT_NAME}-${CPACK_PACKAGE_VERSION_MAJOR}.${CPACK_PACKAGE_VERSION_MINOR}.${CPACK_PACKAGE_VERSION_PATCH}""); set(CPACK_SOURCE_PACKAGE_FILE_NAME; ""${CMAKE_PROJECT_NAME}-${CPACK_PACKAGE_VERSION_MA",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:621,Integrability,message,message,621,"cmake_minimum_required(VERSION 3.15). if(DEFINED ENV{CC}); set(CC $ENV{CC}); else(); set(CC gcc); endif(); message(""CC: ${CC}""). set(CC_VERSION """"); if(${CC} MATCHES ^gcc-); string(REGEX REPLACE ""gcc-"" """" CC_VERSION ${CC}); endif(); message(""CC version: ${CC_VERSION}""). enable_testing(). project(Salmon). # detect host architecture ; if(NOT DEFINED USE_ARM); if(CMAKE_SYSTEM_PROCESSOR MATCHES ""^(aarch64.*|AARCH64.*|arm64.*|ARM64.*)""); message(""Detected 64-bit ARM host. Setting USE_ARM to true.""); set(USE_ARM TRUE); # set char to be signed; add_compile_options(-fsigned-char); set(SCHAR_FLAG ""-fsigned-char""); else(); message(""Detected non-ARM host. Setting USE_ARM to false.""); set(USE_ARM FALSE); set(SCHAR_FLAG """"); endif(); endif(). option(USE_SHARED_LIBS ""Use shared instead of static libraries"" OFF). # auto-populate version:; # from https://stackoverflow.com/questions/47066115/cmake-get-version-from-multi-line-text-file; file(READ ""current_version.txt"" ver). string(REGEX MATCH ""VERSION_MAJOR ([0-9]*)"" _ ${ver}); set(ver_major ${CMAKE_MATCH_1}). string(REGEX MATCH ""VERSION_MINOR ([0-9]*)"" _ ${ver}); set(ver_minor ${CMAKE_MATCH_1}). string(REGEX MATCH ""VERSION_PATCH ([0-9]*)"" _ ${ver}); set(ver_patch ${CMAKE_MATCH_1}). set(CPACK_PACKAGE_VERSION_MAJOR ${ver_major}); set(CPACK_PACKAGE_VERSION_MINOR ${ver_minor}); set(CPACK_PACKAGE_VERSION_PATCH ${ver_patch}). set(CPACK_PACKAGE_VERSION ""${ver_major}.${ver_minor}.${ver_patch}""); message(""version: ${CPACK_PACKAGE_VERSION}""). set(PROJECT_VERSION ${CPACK_PACKAGE_VERSION}); set(CPACK_GENERATOR ""TGZ""); set(CPACK_SOURCE_GENERATOR ""TGZ""); set(CPACK_PACKAGE_VENDOR ""University of Maryland""); set(CPACK_PACKAGE_DESCRIPTION_SUMMARY ""Salmon - Wicked-fast RNA-seq isoform quantification using selective alignment""); set(CPACK_PACKAGE_NAME; ""${CMAKE_PROJECT_NAME}-${CPACK_PACKAGE_VERSION_MAJOR}.${CPACK_PACKAGE_VERSION_MINOR}.${CPACK_PACKAGE_VERSION_PATCH}""); set(CPACK_SOURCE_PACKAGE_FILE_NAME; ""${CMAKE_PROJECT_NAME}-${CPACK_PACKAGE_VERSION_MA",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:1445,Integrability,message,message,1445,"it ARM host. Setting USE_ARM to true.""); set(USE_ARM TRUE); # set char to be signed; add_compile_options(-fsigned-char); set(SCHAR_FLAG ""-fsigned-char""); else(); message(""Detected non-ARM host. Setting USE_ARM to false.""); set(USE_ARM FALSE); set(SCHAR_FLAG """"); endif(); endif(). option(USE_SHARED_LIBS ""Use shared instead of static libraries"" OFF). # auto-populate version:; # from https://stackoverflow.com/questions/47066115/cmake-get-version-from-multi-line-text-file; file(READ ""current_version.txt"" ver). string(REGEX MATCH ""VERSION_MAJOR ([0-9]*)"" _ ${ver}); set(ver_major ${CMAKE_MATCH_1}). string(REGEX MATCH ""VERSION_MINOR ([0-9]*)"" _ ${ver}); set(ver_minor ${CMAKE_MATCH_1}). string(REGEX MATCH ""VERSION_PATCH ([0-9]*)"" _ ${ver}); set(ver_patch ${CMAKE_MATCH_1}). set(CPACK_PACKAGE_VERSION_MAJOR ${ver_major}); set(CPACK_PACKAGE_VERSION_MINOR ${ver_minor}); set(CPACK_PACKAGE_VERSION_PATCH ${ver_patch}). set(CPACK_PACKAGE_VERSION ""${ver_major}.${ver_minor}.${ver_patch}""); message(""version: ${CPACK_PACKAGE_VERSION}""). set(PROJECT_VERSION ${CPACK_PACKAGE_VERSION}); set(CPACK_GENERATOR ""TGZ""); set(CPACK_SOURCE_GENERATOR ""TGZ""); set(CPACK_PACKAGE_VENDOR ""University of Maryland""); set(CPACK_PACKAGE_DESCRIPTION_SUMMARY ""Salmon - Wicked-fast RNA-seq isoform quantification using selective alignment""); set(CPACK_PACKAGE_NAME; ""${CMAKE_PROJECT_NAME}-${CPACK_PACKAGE_VERSION_MAJOR}.${CPACK_PACKAGE_VERSION_MINOR}.${CPACK_PACKAGE_VERSION_PATCH}""); set(CPACK_SOURCE_PACKAGE_FILE_NAME; ""${CMAKE_PROJECT_NAME}-${CPACK_PACKAGE_VERSION_MAJOR}.${CPACK_PACKAGE_VERSION_MINOR}.${CPACK_PACKAGE_VERSION_PATCH}-Source""). set(CMAKE_MODULE_PATH ${CMAKE_MODULE_PATH} ""${CMAKE_SOURCE_DIR}/cmake/Modules/""). # Set a default build type if none was specified; set(default_build_type ""Release""). if(NOT CMAKE_BUILD_TYPE AND NOT CMAKE_CONFIGURATION_TYPES); message(STATUS ""Setting build type to '${default_build_type}' as none was specified.""); set(CMAKE_BUILD_TYPE ""${default_build_type}"" CACHE; STRING ""Choose ",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:2305,Integrability,message,message,2305,"ver_minor}); set(CPACK_PACKAGE_VERSION_PATCH ${ver_patch}). set(CPACK_PACKAGE_VERSION ""${ver_major}.${ver_minor}.${ver_patch}""); message(""version: ${CPACK_PACKAGE_VERSION}""). set(PROJECT_VERSION ${CPACK_PACKAGE_VERSION}); set(CPACK_GENERATOR ""TGZ""); set(CPACK_SOURCE_GENERATOR ""TGZ""); set(CPACK_PACKAGE_VENDOR ""University of Maryland""); set(CPACK_PACKAGE_DESCRIPTION_SUMMARY ""Salmon - Wicked-fast RNA-seq isoform quantification using selective alignment""); set(CPACK_PACKAGE_NAME; ""${CMAKE_PROJECT_NAME}-${CPACK_PACKAGE_VERSION_MAJOR}.${CPACK_PACKAGE_VERSION_MINOR}.${CPACK_PACKAGE_VERSION_PATCH}""); set(CPACK_SOURCE_PACKAGE_FILE_NAME; ""${CMAKE_PROJECT_NAME}-${CPACK_PACKAGE_VERSION_MAJOR}.${CPACK_PACKAGE_VERSION_MINOR}.${CPACK_PACKAGE_VERSION_PATCH}-Source""). set(CMAKE_MODULE_PATH ${CMAKE_MODULE_PATH} ""${CMAKE_SOURCE_DIR}/cmake/Modules/""). # Set a default build type if none was specified; set(default_build_type ""Release""). if(NOT CMAKE_BUILD_TYPE AND NOT CMAKE_CONFIGURATION_TYPES); message(STATUS ""Setting build type to '${default_build_type}' as none was specified.""); set(CMAKE_BUILD_TYPE ""${default_build_type}"" CACHE; STRING ""Choose the type of build."" FORCE); # Set the possible values of build type for cmake-gui; #set_property(CACHE CMAKE_BUILD_TYPE PROPERTY STRINGS; # ""Debug"" ""Release""); endif(). message(STATUS ""CMAKE_BUILD_TYPE = ${CMAKE_BUILD_TYPE}""). ## Set the standard required compile flags; set(REMOVE_WARNING_FLAGS ""-Wno-unused-function;-Wno-unused-local-typedefs""); set(TGT_COMPILE_FLAGS ""${SCHAR_FLAG};-ftree-vectorize;-funroll-loops;-fPIC;-fomit-frame-pointer;-O3;-DNDEBUG;-DSTX_NO_STD_STRING_VIEW;-D__STDC_FORMAT_MACROS""); set(TGT_WARN_FLAGS ""-Wall;-Wno-unknown-pragmas;-Wno-reorder;-Wno-unused-variable;-Wreturn-type;-Werror=return-type;${REMOVE_WARNING_FLAGS}""); #set(CMAKE_C_FLAGS ""${CMAKE_C_FLAGS} -fsanitize=address""); #set(CMAKE_CXX_FLAGS ""${CMAKE_CXX_FLAGS} -fsanitize=address""). ###; # Sanitizers BEGIN; ###; if (ASAN_BUILD); list(APPEND TGT_COMPILE_FLAGS ""-fsanit",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:2629,Integrability,message,message,2629,"CPACK_PACKAGE_DESCRIPTION_SUMMARY ""Salmon - Wicked-fast RNA-seq isoform quantification using selective alignment""); set(CPACK_PACKAGE_NAME; ""${CMAKE_PROJECT_NAME}-${CPACK_PACKAGE_VERSION_MAJOR}.${CPACK_PACKAGE_VERSION_MINOR}.${CPACK_PACKAGE_VERSION_PATCH}""); set(CPACK_SOURCE_PACKAGE_FILE_NAME; ""${CMAKE_PROJECT_NAME}-${CPACK_PACKAGE_VERSION_MAJOR}.${CPACK_PACKAGE_VERSION_MINOR}.${CPACK_PACKAGE_VERSION_PATCH}-Source""). set(CMAKE_MODULE_PATH ${CMAKE_MODULE_PATH} ""${CMAKE_SOURCE_DIR}/cmake/Modules/""). # Set a default build type if none was specified; set(default_build_type ""Release""). if(NOT CMAKE_BUILD_TYPE AND NOT CMAKE_CONFIGURATION_TYPES); message(STATUS ""Setting build type to '${default_build_type}' as none was specified.""); set(CMAKE_BUILD_TYPE ""${default_build_type}"" CACHE; STRING ""Choose the type of build."" FORCE); # Set the possible values of build type for cmake-gui; #set_property(CACHE CMAKE_BUILD_TYPE PROPERTY STRINGS; # ""Debug"" ""Release""); endif(). message(STATUS ""CMAKE_BUILD_TYPE = ${CMAKE_BUILD_TYPE}""). ## Set the standard required compile flags; set(REMOVE_WARNING_FLAGS ""-Wno-unused-function;-Wno-unused-local-typedefs""); set(TGT_COMPILE_FLAGS ""${SCHAR_FLAG};-ftree-vectorize;-funroll-loops;-fPIC;-fomit-frame-pointer;-O3;-DNDEBUG;-DSTX_NO_STD_STRING_VIEW;-D__STDC_FORMAT_MACROS""); set(TGT_WARN_FLAGS ""-Wall;-Wno-unknown-pragmas;-Wno-reorder;-Wno-unused-variable;-Wreturn-type;-Werror=return-type;${REMOVE_WARNING_FLAGS}""); #set(CMAKE_C_FLAGS ""${CMAKE_C_FLAGS} -fsanitize=address""); #set(CMAKE_CXX_FLAGS ""${CMAKE_CXX_FLAGS} -fsanitize=address""). ###; # Sanitizers BEGIN; ###; if (ASAN_BUILD); list(APPEND TGT_COMPILE_FLAGS ""-fsanitize=address""); #list(APPEND TGT_COMPILE_FLAGS ""-fsanitize=undefined""); #set(CMAKE_LINK_FLAGS ""-fsanitize=address""); #list(APPEND CMAKE_LINK_FLAGS ""-fsanitize=undefined""); set(ASAN_LIB ""asan""); else(); set(ASAN_LIB """"); endif(); ###; # Sanitizers END; ###. if(APPLE); set(WARNING_IGNORE_FLAGS ""-Wno-deprecated-register""); list(APPEND TGT_WAR",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:4232,Integrability,message,message,4232,"anitize=address""); #list(APPEND CMAKE_LINK_FLAGS ""-fsanitize=undefined""); set(ASAN_LIB ""asan""); else(); set(ASAN_LIB """"); endif(); ###; # Sanitizers END; ###. if(APPLE); set(WARNING_IGNORE_FLAGS ""-Wno-deprecated-register""); list(APPEND TGT_WARN_FLAGS -Wno-deprecated-register); else(); set(WARNING_IGNORE_FLAGS """"); endif(). ## Prefer static to dynamic libraries; if(NOT USE_SHARED_LIBS); set(CMAKE_FIND_LIBRARY_SUFFIXES .a ${CMAKE_FIND_LIBRARY_SUFFIXES}); set(MALLOC_STATIC_BUILD_FLAG ""--enable-static""); endif(). include(CheckIPOSupported). set(THREADS_PREFER_PTHREAD_FLAG ON); find_package(Threads REQUIRED). set(ICU_LIBS """"); set(ICU_INC_DIRS """"). set(CMAKE_CXX_STANDARD 14); set(CMAKE_CXX_STANDARD_REQUIRED ON); set(CMAKE_CXX_EXTENSIONS OFF); set(CXXSTDFLAG ""-std=c++14""); set(GCCVERSION ""5.2""). if(CONDA_BUILD); message(""Building with CONDA_BUILD flag""); if(APPLE); # Do we require all these components? Any others?; find_package(ICU COMPONENTS data i18n io uc REQUIRED); if(ICU_FOUND); message(STATUS ""ICU_INCLUDE_DIRS = ${ICU_INCLUDE_DIRS}""); message(STATUS ""ICU_LIBRARIES = ${ICU_LIBRARIES}""); endif(); set(ICU_INC_DIRS ${ICU_INCLUDE_DIRS}); set(ICU_LIBS ${ICU_LIBRARIES}); endif(); endif(). set(BOOST_CXX_FLAGS ""${WARNING_IGNORE_FLAGS} ${CXXSTDFLAG}""); if(FETCH_BOOST); set(BOOST_CXX_FLAGS ""${BOOST_CXX_FLAGS} -I${CMAKE_CURRENT_SOURCE_DIR}/external/install/include -L${CMAKE_CURRENT_SOURCE_DIR}/external/install/lib""); endif(). ##; # OSX is strange (some might say, stupid in this regard). Deal with it's quirkines here.; ##; if(APPLE); # To allow ourselves to build a dynamic library, we have to tell the compiler; # that, yes, the symbols will be around at runtime.; list(APPEND TGT_COMPILE_FLAGS ""-undefined dynamic_lookup;-Wno-unused-command-line-argument""); # set(LIBSALMON_LINKER_FLAGS ""-all_load""); # In order to ""think different"", we also have to use non-standard suffixes; # for our shared libraries; set(SHARED_LIB_EXTENSION ""dylib""); else(); # We're in sane linux world; set(SHAR",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:4407,Integrability,message,message,4407,"anitize=address""); #list(APPEND CMAKE_LINK_FLAGS ""-fsanitize=undefined""); set(ASAN_LIB ""asan""); else(); set(ASAN_LIB """"); endif(); ###; # Sanitizers END; ###. if(APPLE); set(WARNING_IGNORE_FLAGS ""-Wno-deprecated-register""); list(APPEND TGT_WARN_FLAGS -Wno-deprecated-register); else(); set(WARNING_IGNORE_FLAGS """"); endif(). ## Prefer static to dynamic libraries; if(NOT USE_SHARED_LIBS); set(CMAKE_FIND_LIBRARY_SUFFIXES .a ${CMAKE_FIND_LIBRARY_SUFFIXES}); set(MALLOC_STATIC_BUILD_FLAG ""--enable-static""); endif(). include(CheckIPOSupported). set(THREADS_PREFER_PTHREAD_FLAG ON); find_package(Threads REQUIRED). set(ICU_LIBS """"); set(ICU_INC_DIRS """"). set(CMAKE_CXX_STANDARD 14); set(CMAKE_CXX_STANDARD_REQUIRED ON); set(CMAKE_CXX_EXTENSIONS OFF); set(CXXSTDFLAG ""-std=c++14""); set(GCCVERSION ""5.2""). if(CONDA_BUILD); message(""Building with CONDA_BUILD flag""); if(APPLE); # Do we require all these components? Any others?; find_package(ICU COMPONENTS data i18n io uc REQUIRED); if(ICU_FOUND); message(STATUS ""ICU_INCLUDE_DIRS = ${ICU_INCLUDE_DIRS}""); message(STATUS ""ICU_LIBRARIES = ${ICU_LIBRARIES}""); endif(); set(ICU_INC_DIRS ${ICU_INCLUDE_DIRS}); set(ICU_LIBS ${ICU_LIBRARIES}); endif(); endif(). set(BOOST_CXX_FLAGS ""${WARNING_IGNORE_FLAGS} ${CXXSTDFLAG}""); if(FETCH_BOOST); set(BOOST_CXX_FLAGS ""${BOOST_CXX_FLAGS} -I${CMAKE_CURRENT_SOURCE_DIR}/external/install/include -L${CMAKE_CURRENT_SOURCE_DIR}/external/install/lib""); endif(). ##; # OSX is strange (some might say, stupid in this regard). Deal with it's quirkines here.; ##; if(APPLE); # To allow ourselves to build a dynamic library, we have to tell the compiler; # that, yes, the symbols will be around at runtime.; list(APPEND TGT_COMPILE_FLAGS ""-undefined dynamic_lookup;-Wno-unused-command-line-argument""); # set(LIBSALMON_LINKER_FLAGS ""-all_load""); # In order to ""think different"", we also have to use non-standard suffixes; # for our shared libraries; set(SHARED_LIB_EXTENSION ""dylib""); else(); # We're in sane linux world; set(SHAR",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:4465,Integrability,message,message,4465,"anitize=address""); #list(APPEND CMAKE_LINK_FLAGS ""-fsanitize=undefined""); set(ASAN_LIB ""asan""); else(); set(ASAN_LIB """"); endif(); ###; # Sanitizers END; ###. if(APPLE); set(WARNING_IGNORE_FLAGS ""-Wno-deprecated-register""); list(APPEND TGT_WARN_FLAGS -Wno-deprecated-register); else(); set(WARNING_IGNORE_FLAGS """"); endif(). ## Prefer static to dynamic libraries; if(NOT USE_SHARED_LIBS); set(CMAKE_FIND_LIBRARY_SUFFIXES .a ${CMAKE_FIND_LIBRARY_SUFFIXES}); set(MALLOC_STATIC_BUILD_FLAG ""--enable-static""); endif(). include(CheckIPOSupported). set(THREADS_PREFER_PTHREAD_FLAG ON); find_package(Threads REQUIRED). set(ICU_LIBS """"); set(ICU_INC_DIRS """"). set(CMAKE_CXX_STANDARD 14); set(CMAKE_CXX_STANDARD_REQUIRED ON); set(CMAKE_CXX_EXTENSIONS OFF); set(CXXSTDFLAG ""-std=c++14""); set(GCCVERSION ""5.2""). if(CONDA_BUILD); message(""Building with CONDA_BUILD flag""); if(APPLE); # Do we require all these components? Any others?; find_package(ICU COMPONENTS data i18n io uc REQUIRED); if(ICU_FOUND); message(STATUS ""ICU_INCLUDE_DIRS = ${ICU_INCLUDE_DIRS}""); message(STATUS ""ICU_LIBRARIES = ${ICU_LIBRARIES}""); endif(); set(ICU_INC_DIRS ${ICU_INCLUDE_DIRS}); set(ICU_LIBS ${ICU_LIBRARIES}); endif(); endif(). set(BOOST_CXX_FLAGS ""${WARNING_IGNORE_FLAGS} ${CXXSTDFLAG}""); if(FETCH_BOOST); set(BOOST_CXX_FLAGS ""${BOOST_CXX_FLAGS} -I${CMAKE_CURRENT_SOURCE_DIR}/external/install/include -L${CMAKE_CURRENT_SOURCE_DIR}/external/install/lib""); endif(). ##; # OSX is strange (some might say, stupid in this regard). Deal with it's quirkines here.; ##; if(APPLE); # To allow ourselves to build a dynamic library, we have to tell the compiler; # that, yes, the symbols will be around at runtime.; list(APPEND TGT_COMPILE_FLAGS ""-undefined dynamic_lookup;-Wno-unused-command-line-argument""); # set(LIBSALMON_LINKER_FLAGS ""-all_load""); # In order to ""think different"", we also have to use non-standard suffixes; # for our shared libraries; set(SHARED_LIB_EXTENSION ""dylib""); else(); # We're in sane linux world; set(SHAR",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:6298,Integrability,message,message,6298,"""think different"", we also have to use non-standard suffixes; # for our shared libraries; set(SHARED_LIB_EXTENSION ""dylib""); else(); # We're in sane linux world; set(SHARED_LIB_EXTENSION ""so""); set(LIBSALMON_LINKER_FLAGS """"); endif(). set( BOOST_EXTRA_FLAGS ""--layout=tagged"" ); ## this get's set differently below if we; ## are on clang & apple; set(NON_APPLECLANG_LIBS gomp). if(UNIX AND NOT APPLE); set(LIBRT rt); endif(). set(PTHREAD_LIB). ##; # Let us check the sha sum of our pacakges if we have the right tools; ##; set(SHASUM ${CMAKE_CURRENT_SOURCE_DIR}/scripts/check_shasum.sh). ##; # Compiler-specific C++11/14 activation.; # http://stackoverflow.com/questions/10984442/how-to-detect-c11-support-of-a-compiler-with-cmake; ##; ##; # First take care of what to do if we have gcc; ##; if(""${CMAKE_CXX_COMPILER_ID}"" MATCHES ""GNU""); execute_process(; COMMAND ${CMAKE_CXX_COMPILER} -dumpversion OUTPUT_VARIABLE GCC_VERSION); # If we're on OSX; if(APPLE AND NOT (GCC_VERSION VERSION_GREATER ${GCCVERSION} OR GCC_VERSION VERSION_EQUAL ${GCCVERSION})); message(FATAL_ERROR ""When building under OSX, ${PROJECT_NAME} requires ""; ""either clang or g++ >= ${GCCVERSION}""); elseif(NOT (GCC_VERSION VERSION_GREATER ${GCCVERSION} OR GCC_VERSION VERSION_EQUAL ${GCCVERSION})); message(FATAL_ERROR ""${PROJECT_NAME} requires g++ ${GCCVERSION} or greater.""); endif(); ; if(GCC_VERSION VERSION_GREATER_EQUAL ""7.1""); list(APPEND TGT_WARN_FLAGS ""-Wno-int-in-bool-context""); endif(); ; if(GCC_VERSION VERSION_GREATER_EQUAL ""9.1""); list(APPEND TGT_WARN_FLAGS ""-Wno-deprecated-copy""); endif(). set(GCC TRUE). # Put complete static linking on hold for the time-being; # If we're not on OSX, make an attempt to compile everything statically; #if(NOT APPLE); #set(CMAKE_EXE_LINK_FLAGS ""-static""); set(PTHREAD_LIB ""pthread""); #endif(). # If we're on Linux (i.e. not OSX) and we're using; # gcc, then set the -static-libstdc++ flag; if(NOT APPLE); list(APPEND TGT_COMPILE_FLAGS -static-libstdc++); endif(). set(WARNING_IGNO",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:6513,Integrability,message,message,6513,"""think different"", we also have to use non-standard suffixes; # for our shared libraries; set(SHARED_LIB_EXTENSION ""dylib""); else(); # We're in sane linux world; set(SHARED_LIB_EXTENSION ""so""); set(LIBSALMON_LINKER_FLAGS """"); endif(). set( BOOST_EXTRA_FLAGS ""--layout=tagged"" ); ## this get's set differently below if we; ## are on clang & apple; set(NON_APPLECLANG_LIBS gomp). if(UNIX AND NOT APPLE); set(LIBRT rt); endif(). set(PTHREAD_LIB). ##; # Let us check the sha sum of our pacakges if we have the right tools; ##; set(SHASUM ${CMAKE_CURRENT_SOURCE_DIR}/scripts/check_shasum.sh). ##; # Compiler-specific C++11/14 activation.; # http://stackoverflow.com/questions/10984442/how-to-detect-c11-support-of-a-compiler-with-cmake; ##; ##; # First take care of what to do if we have gcc; ##; if(""${CMAKE_CXX_COMPILER_ID}"" MATCHES ""GNU""); execute_process(; COMMAND ${CMAKE_CXX_COMPILER} -dumpversion OUTPUT_VARIABLE GCC_VERSION); # If we're on OSX; if(APPLE AND NOT (GCC_VERSION VERSION_GREATER ${GCCVERSION} OR GCC_VERSION VERSION_EQUAL ${GCCVERSION})); message(FATAL_ERROR ""When building under OSX, ${PROJECT_NAME} requires ""; ""either clang or g++ >= ${GCCVERSION}""); elseif(NOT (GCC_VERSION VERSION_GREATER ${GCCVERSION} OR GCC_VERSION VERSION_EQUAL ${GCCVERSION})); message(FATAL_ERROR ""${PROJECT_NAME} requires g++ ${GCCVERSION} or greater.""); endif(); ; if(GCC_VERSION VERSION_GREATER_EQUAL ""7.1""); list(APPEND TGT_WARN_FLAGS ""-Wno-int-in-bool-context""); endif(); ; if(GCC_VERSION VERSION_GREATER_EQUAL ""9.1""); list(APPEND TGT_WARN_FLAGS ""-Wno-deprecated-copy""); endif(). set(GCC TRUE). # Put complete static linking on hold for the time-being; # If we're not on OSX, make an attempt to compile everything statically; #if(NOT APPLE); #set(CMAKE_EXE_LINK_FLAGS ""-static""); set(PTHREAD_LIB ""pthread""); #endif(). # If we're on Linux (i.e. not OSX) and we're using; # gcc, then set the -static-libstdc++ flag; if(NOT APPLE); list(APPEND TGT_COMPILE_FLAGS -static-libstdc++); endif(). set(WARNING_IGNO",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:7741,Integrability,message,message,7741,"1""); list(APPEND TGT_WARN_FLAGS ""-Wno-deprecated-copy""); endif(). set(GCC TRUE). # Put complete static linking on hold for the time-being; # If we're not on OSX, make an attempt to compile everything statically; #if(NOT APPLE); #set(CMAKE_EXE_LINK_FLAGS ""-static""); set(PTHREAD_LIB ""pthread""); #endif(). # If we're on Linux (i.e. not OSX) and we're using; # gcc, then set the -static-libstdc++ flag; if(NOT APPLE); list(APPEND TGT_COMPILE_FLAGS -static-libstdc++); endif(). set(WARNING_IGNORE_FLAGS ""${WARNING_IGNORE_FLAGS} -Wno-unused-local-typedefs""); set(BOOST_TOOLSET ""gcc""); set(BOOST_CONFIGURE_TOOLSET ""--with-toolset=gcc""); set(BCXX_FLAGS ""${CXXSTDFLAG} ${SCHAR_FLAG}""); set(BOOST_EXTRA_FLAGS toolset=gcc cxxflags=${BCXX_FLAGS}); # Tentatively, we support clang now; elseif(""${CMAKE_CXX_COMPILER_ID}"" MATCHES ""Clang""); set(CLANG TRUE); # If we have libc++, then try and use it; include(CheckCXXCompilerFlag); check_cxx_compiler_flag(-stdlib=libc++ HAVE_LIBCPP); if(HAVE_LIBCPP); message(""It appears that you're compiling with clang and that libc++ is available, so I'll use that""); list(APPEND TGT_COMPILE_FLAGS -stdlib=libc++); set(BOOST_TOOLSET ""clang""); set(BOOST_CONFIGURE_TOOLSET ""--with-toolset=clang""); set(BCXX_FLAGS ""-stdlib=libc++ -DBOOST_HAS_INT128 ${SCHAR_FLAG}""); set(BOOST_EXTRA_FLAGS toolset=clang cxxflags=${BCXX_FLAGS} linkflags=""-stdlib=libc++""); # Otherwise, use libstdc++ (and make it static); else(); list(APPEND TGT_COMPILE_FLAGS -static-libstdc++); endif(); # There's currently a bug with clang-3.4 & Boost 1.55 -- this hack fixes it; # but we should do something better (does this break things if CPU doesn't; # have 128-bit support)?; list(APPEND TGT_COMPILE_FLAGS -DBOOST_HAS_INT128). if(APPLE); set(NON_APPLECLANG_LIBS """"); else(); set(PTHREAD_LIB ""pthread""); endif(); else(); message(FATAL_ERROR ""Your C++ compiler does not support C++14.""); endif(). if(DO_QUIET_MAKE); set(QUIET_MAKE ""--silent""); else(); set(QUIET_MAKE """"); endif(). ## TODO: Figure out how to det",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:8566,Integrability,message,message,8566,"OMPILER_ID}"" MATCHES ""Clang""); set(CLANG TRUE); # If we have libc++, then try and use it; include(CheckCXXCompilerFlag); check_cxx_compiler_flag(-stdlib=libc++ HAVE_LIBCPP); if(HAVE_LIBCPP); message(""It appears that you're compiling with clang and that libc++ is available, so I'll use that""); list(APPEND TGT_COMPILE_FLAGS -stdlib=libc++); set(BOOST_TOOLSET ""clang""); set(BOOST_CONFIGURE_TOOLSET ""--with-toolset=clang""); set(BCXX_FLAGS ""-stdlib=libc++ -DBOOST_HAS_INT128 ${SCHAR_FLAG}""); set(BOOST_EXTRA_FLAGS toolset=clang cxxflags=${BCXX_FLAGS} linkflags=""-stdlib=libc++""); # Otherwise, use libstdc++ (and make it static); else(); list(APPEND TGT_COMPILE_FLAGS -static-libstdc++); endif(); # There's currently a bug with clang-3.4 & Boost 1.55 -- this hack fixes it; # but we should do something better (does this break things if CPU doesn't; # have 128-bit support)?; list(APPEND TGT_COMPILE_FLAGS -DBOOST_HAS_INT128). if(APPLE); set(NON_APPLECLANG_LIBS """"); else(); set(PTHREAD_LIB ""pthread""); endif(); else(); message(FATAL_ERROR ""Your C++ compiler does not support C++14.""); endif(). if(DO_QUIET_MAKE); set(QUIET_MAKE ""--silent""); else(); set(QUIET_MAKE """"); endif(). ## TODO: Figure out how to detect this automatically; # If the ""assembler"" is too old, tell TBB not to compile; # with -mrtm; if(NO_RTM); set(TBB_CXXFLAGS ""-mno-rtm""); endif(). include(ExternalProject). if(CMAKE_BUILD_TYPE MATCHES Debug); message(""Making Debug build""); elseif(CMAKE_BUILD_TYPE MATCHES Release); message(""Making Release build""); else(); message(""Making Default build type""); endif(). ##; # Record this top-level path; ##; set(GAT_SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}). # Have CMake tell us what it's doing; # set(CMAKE_VERBOSE_MAKEFILE true). ###; # check if numeric_limits<__int128_t> is defined; ###; try_compile(HAVE_INT128_NUMERIC_LIMITS ${CMAKE_BINARY_DIR} ; SOURCES ${GAT_SOURCE_DIR}/tests/compile_tests/int128_numeric_limits.cpp; CXX_STANDARD 14; CXX_STANDARD_REQUIRED ON ; ); if(HAVE_INT128_NUMERIC_",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:8964,Integrability,message,message,8964,"CHAR_FLAG}""); set(BOOST_EXTRA_FLAGS toolset=clang cxxflags=${BCXX_FLAGS} linkflags=""-stdlib=libc++""); # Otherwise, use libstdc++ (and make it static); else(); list(APPEND TGT_COMPILE_FLAGS -static-libstdc++); endif(); # There's currently a bug with clang-3.4 & Boost 1.55 -- this hack fixes it; # but we should do something better (does this break things if CPU doesn't; # have 128-bit support)?; list(APPEND TGT_COMPILE_FLAGS -DBOOST_HAS_INT128). if(APPLE); set(NON_APPLECLANG_LIBS """"); else(); set(PTHREAD_LIB ""pthread""); endif(); else(); message(FATAL_ERROR ""Your C++ compiler does not support C++14.""); endif(). if(DO_QUIET_MAKE); set(QUIET_MAKE ""--silent""); else(); set(QUIET_MAKE """"); endif(). ## TODO: Figure out how to detect this automatically; # If the ""assembler"" is too old, tell TBB not to compile; # with -mrtm; if(NO_RTM); set(TBB_CXXFLAGS ""-mno-rtm""); endif(). include(ExternalProject). if(CMAKE_BUILD_TYPE MATCHES Debug); message(""Making Debug build""); elseif(CMAKE_BUILD_TYPE MATCHES Release); message(""Making Release build""); else(); message(""Making Default build type""); endif(). ##; # Record this top-level path; ##; set(GAT_SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}). # Have CMake tell us what it's doing; # set(CMAKE_VERBOSE_MAKEFILE true). ###; # check if numeric_limits<__int128_t> is defined; ###; try_compile(HAVE_INT128_NUMERIC_LIMITS ${CMAKE_BINARY_DIR} ; SOURCES ${GAT_SOURCE_DIR}/tests/compile_tests/int128_numeric_limits.cpp; CXX_STANDARD 14; CXX_STANDARD_REQUIRED ON ; ); if(HAVE_INT128_NUMERIC_LIMITS); message(""setting -DHAVE_NUMERIC_LIMITS128""); list(APPEND TGT_COMPILE_FLAGS ""-DHAVE_NUMERIC_LIMITS128""); else(); message(""not setting -DHAVE_NUMERIC_LIMITS128""); endif(). ###; #; # Grab pufferfish source --- DURING CONFIGURE TIME!; #; ####; if(NOT FETCHED_PUFFERFISH); exec_program(${CMAKE_CURRENT_SOURCE_DIR}/scripts/fetchPufferfish.sh RETURN_VALUE FETCH_PF_SCRIPT_RET); message(STATUS ""fetch PUFFERFISH exit code ${FETCH_PF_SCRIPT_RET}""); if(NOT (FETCH_PF_SCRIPT_RET",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:9037,Integrability,message,message,9037,"CHAR_FLAG}""); set(BOOST_EXTRA_FLAGS toolset=clang cxxflags=${BCXX_FLAGS} linkflags=""-stdlib=libc++""); # Otherwise, use libstdc++ (and make it static); else(); list(APPEND TGT_COMPILE_FLAGS -static-libstdc++); endif(); # There's currently a bug with clang-3.4 & Boost 1.55 -- this hack fixes it; # but we should do something better (does this break things if CPU doesn't; # have 128-bit support)?; list(APPEND TGT_COMPILE_FLAGS -DBOOST_HAS_INT128). if(APPLE); set(NON_APPLECLANG_LIBS """"); else(); set(PTHREAD_LIB ""pthread""); endif(); else(); message(FATAL_ERROR ""Your C++ compiler does not support C++14.""); endif(). if(DO_QUIET_MAKE); set(QUIET_MAKE ""--silent""); else(); set(QUIET_MAKE """"); endif(). ## TODO: Figure out how to detect this automatically; # If the ""assembler"" is too old, tell TBB not to compile; # with -mrtm; if(NO_RTM); set(TBB_CXXFLAGS ""-mno-rtm""); endif(). include(ExternalProject). if(CMAKE_BUILD_TYPE MATCHES Debug); message(""Making Debug build""); elseif(CMAKE_BUILD_TYPE MATCHES Release); message(""Making Release build""); else(); message(""Making Default build type""); endif(). ##; # Record this top-level path; ##; set(GAT_SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}). # Have CMake tell us what it's doing; # set(CMAKE_VERBOSE_MAKEFILE true). ###; # check if numeric_limits<__int128_t> is defined; ###; try_compile(HAVE_INT128_NUMERIC_LIMITS ${CMAKE_BINARY_DIR} ; SOURCES ${GAT_SOURCE_DIR}/tests/compile_tests/int128_numeric_limits.cpp; CXX_STANDARD 14; CXX_STANDARD_REQUIRED ON ; ); if(HAVE_INT128_NUMERIC_LIMITS); message(""setting -DHAVE_NUMERIC_LIMITS128""); list(APPEND TGT_COMPILE_FLAGS ""-DHAVE_NUMERIC_LIMITS128""); else(); message(""not setting -DHAVE_NUMERIC_LIMITS128""); endif(). ###; #; # Grab pufferfish source --- DURING CONFIGURE TIME!; #; ####; if(NOT FETCHED_PUFFERFISH); exec_program(${CMAKE_CURRENT_SOURCE_DIR}/scripts/fetchPufferfish.sh RETURN_VALUE FETCH_PF_SCRIPT_RET); message(STATUS ""fetch PUFFERFISH exit code ${FETCH_PF_SCRIPT_RET}""); if(NOT (FETCH_PF_SCRIPT_RET",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:9078,Integrability,message,message,9078,"CHAR_FLAG}""); set(BOOST_EXTRA_FLAGS toolset=clang cxxflags=${BCXX_FLAGS} linkflags=""-stdlib=libc++""); # Otherwise, use libstdc++ (and make it static); else(); list(APPEND TGT_COMPILE_FLAGS -static-libstdc++); endif(); # There's currently a bug with clang-3.4 & Boost 1.55 -- this hack fixes it; # but we should do something better (does this break things if CPU doesn't; # have 128-bit support)?; list(APPEND TGT_COMPILE_FLAGS -DBOOST_HAS_INT128). if(APPLE); set(NON_APPLECLANG_LIBS """"); else(); set(PTHREAD_LIB ""pthread""); endif(); else(); message(FATAL_ERROR ""Your C++ compiler does not support C++14.""); endif(). if(DO_QUIET_MAKE); set(QUIET_MAKE ""--silent""); else(); set(QUIET_MAKE """"); endif(). ## TODO: Figure out how to detect this automatically; # If the ""assembler"" is too old, tell TBB not to compile; # with -mrtm; if(NO_RTM); set(TBB_CXXFLAGS ""-mno-rtm""); endif(). include(ExternalProject). if(CMAKE_BUILD_TYPE MATCHES Debug); message(""Making Debug build""); elseif(CMAKE_BUILD_TYPE MATCHES Release); message(""Making Release build""); else(); message(""Making Default build type""); endif(). ##; # Record this top-level path; ##; set(GAT_SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}). # Have CMake tell us what it's doing; # set(CMAKE_VERBOSE_MAKEFILE true). ###; # check if numeric_limits<__int128_t> is defined; ###; try_compile(HAVE_INT128_NUMERIC_LIMITS ${CMAKE_BINARY_DIR} ; SOURCES ${GAT_SOURCE_DIR}/tests/compile_tests/int128_numeric_limits.cpp; CXX_STANDARD 14; CXX_STANDARD_REQUIRED ON ; ); if(HAVE_INT128_NUMERIC_LIMITS); message(""setting -DHAVE_NUMERIC_LIMITS128""); list(APPEND TGT_COMPILE_FLAGS ""-DHAVE_NUMERIC_LIMITS128""); else(); message(""not setting -DHAVE_NUMERIC_LIMITS128""); endif(). ###; #; # Grab pufferfish source --- DURING CONFIGURE TIME!; #; ####; if(NOT FETCHED_PUFFERFISH); exec_program(${CMAKE_CURRENT_SOURCE_DIR}/scripts/fetchPufferfish.sh RETURN_VALUE FETCH_PF_SCRIPT_RET); message(STATUS ""fetch PUFFERFISH exit code ${FETCH_PF_SCRIPT_RET}""); if(NOT (FETCH_PF_SCRIPT_RET",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:9559,Integrability,message,message,9559,"ler does not support C++14.""); endif(). if(DO_QUIET_MAKE); set(QUIET_MAKE ""--silent""); else(); set(QUIET_MAKE """"); endif(). ## TODO: Figure out how to detect this automatically; # If the ""assembler"" is too old, tell TBB not to compile; # with -mrtm; if(NO_RTM); set(TBB_CXXFLAGS ""-mno-rtm""); endif(). include(ExternalProject). if(CMAKE_BUILD_TYPE MATCHES Debug); message(""Making Debug build""); elseif(CMAKE_BUILD_TYPE MATCHES Release); message(""Making Release build""); else(); message(""Making Default build type""); endif(). ##; # Record this top-level path; ##; set(GAT_SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}). # Have CMake tell us what it's doing; # set(CMAKE_VERBOSE_MAKEFILE true). ###; # check if numeric_limits<__int128_t> is defined; ###; try_compile(HAVE_INT128_NUMERIC_LIMITS ${CMAKE_BINARY_DIR} ; SOURCES ${GAT_SOURCE_DIR}/tests/compile_tests/int128_numeric_limits.cpp; CXX_STANDARD 14; CXX_STANDARD_REQUIRED ON ; ); if(HAVE_INT128_NUMERIC_LIMITS); message(""setting -DHAVE_NUMERIC_LIMITS128""); list(APPEND TGT_COMPILE_FLAGS ""-DHAVE_NUMERIC_LIMITS128""); else(); message(""not setting -DHAVE_NUMERIC_LIMITS128""); endif(). ###; #; # Grab pufferfish source --- DURING CONFIGURE TIME!; #; ####; if(NOT FETCHED_PUFFERFISH); exec_program(${CMAKE_CURRENT_SOURCE_DIR}/scripts/fetchPufferfish.sh RETURN_VALUE FETCH_PF_SCRIPT_RET); message(STATUS ""fetch PUFFERFISH exit code ${FETCH_PF_SCRIPT_RET}""); if(NOT (FETCH_PF_SCRIPT_RET EQUAL 0)); message(FATAL_ERROR ""Could not fetch pufferfish source [fetchPufferfish.sh returned exit code ${FETCH_PF_SCRIPT_RET}].""); endif(); set(FETCHED_PUFFERFISH TRUE CACHE BOOL ""Has pufferfish been fetched?"" FORCE); endif(). ##; # Super-secret override; ##; if( DEFINED CUSTOM_BOOST_PATH ); set(CMAKE_INCLUDE_PATH ${CUSTOM_BOOST_PATH} ${CMAKE_INCLUDE_PATH}); set(CMAKE_LIBRARY_PATH ${CUSTOM_BOOST_PATH}/lib ${CMAKE_LIBRARY_PATH}); endif(). ##; # We want static, multithreaded boost libraries; ##; if(CONDA_BUILD); set(Boost_USE_STATIC_LIBS OFF); elseif(USE_SHARED_LIBS) #",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:9671,Integrability,message,message,9671,"ler does not support C++14.""); endif(). if(DO_QUIET_MAKE); set(QUIET_MAKE ""--silent""); else(); set(QUIET_MAKE """"); endif(). ## TODO: Figure out how to detect this automatically; # If the ""assembler"" is too old, tell TBB not to compile; # with -mrtm; if(NO_RTM); set(TBB_CXXFLAGS ""-mno-rtm""); endif(). include(ExternalProject). if(CMAKE_BUILD_TYPE MATCHES Debug); message(""Making Debug build""); elseif(CMAKE_BUILD_TYPE MATCHES Release); message(""Making Release build""); else(); message(""Making Default build type""); endif(). ##; # Record this top-level path; ##; set(GAT_SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}). # Have CMake tell us what it's doing; # set(CMAKE_VERBOSE_MAKEFILE true). ###; # check if numeric_limits<__int128_t> is defined; ###; try_compile(HAVE_INT128_NUMERIC_LIMITS ${CMAKE_BINARY_DIR} ; SOURCES ${GAT_SOURCE_DIR}/tests/compile_tests/int128_numeric_limits.cpp; CXX_STANDARD 14; CXX_STANDARD_REQUIRED ON ; ); if(HAVE_INT128_NUMERIC_LIMITS); message(""setting -DHAVE_NUMERIC_LIMITS128""); list(APPEND TGT_COMPILE_FLAGS ""-DHAVE_NUMERIC_LIMITS128""); else(); message(""not setting -DHAVE_NUMERIC_LIMITS128""); endif(). ###; #; # Grab pufferfish source --- DURING CONFIGURE TIME!; #; ####; if(NOT FETCHED_PUFFERFISH); exec_program(${CMAKE_CURRENT_SOURCE_DIR}/scripts/fetchPufferfish.sh RETURN_VALUE FETCH_PF_SCRIPT_RET); message(STATUS ""fetch PUFFERFISH exit code ${FETCH_PF_SCRIPT_RET}""); if(NOT (FETCH_PF_SCRIPT_RET EQUAL 0)); message(FATAL_ERROR ""Could not fetch pufferfish source [fetchPufferfish.sh returned exit code ${FETCH_PF_SCRIPT_RET}].""); endif(); set(FETCHED_PUFFERFISH TRUE CACHE BOOL ""Has pufferfish been fetched?"" FORCE); endif(). ##; # Super-secret override; ##; if( DEFINED CUSTOM_BOOST_PATH ); set(CMAKE_INCLUDE_PATH ${CUSTOM_BOOST_PATH} ${CMAKE_INCLUDE_PATH}); set(CMAKE_LIBRARY_PATH ${CUSTOM_BOOST_PATH}/lib ${CMAKE_LIBRARY_PATH}); endif(). ##; # We want static, multithreaded boost libraries; ##; if(CONDA_BUILD); set(Boost_USE_STATIC_LIBS OFF); elseif(USE_SHARED_LIBS) #",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:9930,Integrability,message,message,9930,"(CMAKE_BUILD_TYPE MATCHES Release); message(""Making Release build""); else(); message(""Making Default build type""); endif(). ##; # Record this top-level path; ##; set(GAT_SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}). # Have CMake tell us what it's doing; # set(CMAKE_VERBOSE_MAKEFILE true). ###; # check if numeric_limits<__int128_t> is defined; ###; try_compile(HAVE_INT128_NUMERIC_LIMITS ${CMAKE_BINARY_DIR} ; SOURCES ${GAT_SOURCE_DIR}/tests/compile_tests/int128_numeric_limits.cpp; CXX_STANDARD 14; CXX_STANDARD_REQUIRED ON ; ); if(HAVE_INT128_NUMERIC_LIMITS); message(""setting -DHAVE_NUMERIC_LIMITS128""); list(APPEND TGT_COMPILE_FLAGS ""-DHAVE_NUMERIC_LIMITS128""); else(); message(""not setting -DHAVE_NUMERIC_LIMITS128""); endif(). ###; #; # Grab pufferfish source --- DURING CONFIGURE TIME!; #; ####; if(NOT FETCHED_PUFFERFISH); exec_program(${CMAKE_CURRENT_SOURCE_DIR}/scripts/fetchPufferfish.sh RETURN_VALUE FETCH_PF_SCRIPT_RET); message(STATUS ""fetch PUFFERFISH exit code ${FETCH_PF_SCRIPT_RET}""); if(NOT (FETCH_PF_SCRIPT_RET EQUAL 0)); message(FATAL_ERROR ""Could not fetch pufferfish source [fetchPufferfish.sh returned exit code ${FETCH_PF_SCRIPT_RET}].""); endif(); set(FETCHED_PUFFERFISH TRUE CACHE BOOL ""Has pufferfish been fetched?"" FORCE); endif(). ##; # Super-secret override; ##; if( DEFINED CUSTOM_BOOST_PATH ); set(CMAKE_INCLUDE_PATH ${CUSTOM_BOOST_PATH} ${CMAKE_INCLUDE_PATH}); set(CMAKE_LIBRARY_PATH ${CUSTOM_BOOST_PATH}/lib ${CMAKE_LIBRARY_PATH}); endif(). ##; # We want static, multithreaded boost libraries; ##; if(CONDA_BUILD); set(Boost_USE_STATIC_LIBS OFF); elseif(USE_SHARED_LIBS) # CI failed when using an OR statement above...; set(Boost_USE_STATIC_LIBS OFF); else(); set(Boost_USE_STATIC_LIBS ON); endif(). set(Boost_USE_MULTITHREADED ON); #set(Boost_USE_STATIC_RUNTIME OFF); set(Boost_USE_DEBUG_RUNTIME OFF). find_package(ZLIB); if(NOT ZLIB_FOUND); message(FATAL_ERROR ""zlib must be installed before configuration & building can proceed""); endif(). if(""${CMAKE_INCLUDE_PATH}"" S",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:10038,Integrability,message,message,10038,"(CMAKE_BUILD_TYPE MATCHES Release); message(""Making Release build""); else(); message(""Making Default build type""); endif(). ##; # Record this top-level path; ##; set(GAT_SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}). # Have CMake tell us what it's doing; # set(CMAKE_VERBOSE_MAKEFILE true). ###; # check if numeric_limits<__int128_t> is defined; ###; try_compile(HAVE_INT128_NUMERIC_LIMITS ${CMAKE_BINARY_DIR} ; SOURCES ${GAT_SOURCE_DIR}/tests/compile_tests/int128_numeric_limits.cpp; CXX_STANDARD 14; CXX_STANDARD_REQUIRED ON ; ); if(HAVE_INT128_NUMERIC_LIMITS); message(""setting -DHAVE_NUMERIC_LIMITS128""); list(APPEND TGT_COMPILE_FLAGS ""-DHAVE_NUMERIC_LIMITS128""); else(); message(""not setting -DHAVE_NUMERIC_LIMITS128""); endif(). ###; #; # Grab pufferfish source --- DURING CONFIGURE TIME!; #; ####; if(NOT FETCHED_PUFFERFISH); exec_program(${CMAKE_CURRENT_SOURCE_DIR}/scripts/fetchPufferfish.sh RETURN_VALUE FETCH_PF_SCRIPT_RET); message(STATUS ""fetch PUFFERFISH exit code ${FETCH_PF_SCRIPT_RET}""); if(NOT (FETCH_PF_SCRIPT_RET EQUAL 0)); message(FATAL_ERROR ""Could not fetch pufferfish source [fetchPufferfish.sh returned exit code ${FETCH_PF_SCRIPT_RET}].""); endif(); set(FETCHED_PUFFERFISH TRUE CACHE BOOL ""Has pufferfish been fetched?"" FORCE); endif(). ##; # Super-secret override; ##; if( DEFINED CUSTOM_BOOST_PATH ); set(CMAKE_INCLUDE_PATH ${CUSTOM_BOOST_PATH} ${CMAKE_INCLUDE_PATH}); set(CMAKE_LIBRARY_PATH ${CUSTOM_BOOST_PATH}/lib ${CMAKE_LIBRARY_PATH}); endif(). ##; # We want static, multithreaded boost libraries; ##; if(CONDA_BUILD); set(Boost_USE_STATIC_LIBS OFF); elseif(USE_SHARED_LIBS) # CI failed when using an OR statement above...; set(Boost_USE_STATIC_LIBS OFF); else(); set(Boost_USE_STATIC_LIBS ON); endif(). set(Boost_USE_MULTITHREADED ON); #set(Boost_USE_STATIC_RUNTIME OFF); set(Boost_USE_DEBUG_RUNTIME OFF). find_package(ZLIB); if(NOT ZLIB_FOUND); message(FATAL_ERROR ""zlib must be installed before configuration & building can proceed""); endif(). if(""${CMAKE_INCLUDE_PATH}"" S",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:10873,Integrability,message,message,10873,"VALUE FETCH_PF_SCRIPT_RET); message(STATUS ""fetch PUFFERFISH exit code ${FETCH_PF_SCRIPT_RET}""); if(NOT (FETCH_PF_SCRIPT_RET EQUAL 0)); message(FATAL_ERROR ""Could not fetch pufferfish source [fetchPufferfish.sh returned exit code ${FETCH_PF_SCRIPT_RET}].""); endif(); set(FETCHED_PUFFERFISH TRUE CACHE BOOL ""Has pufferfish been fetched?"" FORCE); endif(). ##; # Super-secret override; ##; if( DEFINED CUSTOM_BOOST_PATH ); set(CMAKE_INCLUDE_PATH ${CUSTOM_BOOST_PATH} ${CMAKE_INCLUDE_PATH}); set(CMAKE_LIBRARY_PATH ${CUSTOM_BOOST_PATH}/lib ${CMAKE_LIBRARY_PATH}); endif(). ##; # We want static, multithreaded boost libraries; ##; if(CONDA_BUILD); set(Boost_USE_STATIC_LIBS OFF); elseif(USE_SHARED_LIBS) # CI failed when using an OR statement above...; set(Boost_USE_STATIC_LIBS OFF); else(); set(Boost_USE_STATIC_LIBS ON); endif(). set(Boost_USE_MULTITHREADED ON); #set(Boost_USE_STATIC_RUNTIME OFF); set(Boost_USE_DEBUG_RUNTIME OFF). find_package(ZLIB); if(NOT ZLIB_FOUND); message(FATAL_ERROR ""zlib must be installed before configuration & building can proceed""); endif(). if(""${CMAKE_INCLUDE_PATH}"" STREQUAL """"); set(EXTRA_CMAKE_INCLUDE_FLAGS """"); else(); set(EXTRA_CMAKE_INCLUDE_FLAGS ""-I${CMAKE_INCLUDE_PATH}""); endif(). if(""${CMAKE_LIBRARY_PATH}"" STREQUAL """"); set(EXTRA_CMAKE_LIBRARY_FLAGS """"); else(); set(EXTRA_CMAKE_LIBRARY_FLAGS ""-L${CMAKE_LIBRARY_PATH}""); endif(). find_package(Iconv REQUIRED); if(NOT Iconv_IS_BUILT_IN); set(ICONV_LIB Iconv::Iconv); endif(). find_package(LibLZMA); if(NOT LIBLZMA_FOUND); message(""Will attempt to fetch and build liblzma""); message(""=======================================""); externalproject_add(liblzma; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; ##; DOWNLOAD_COMMAND curl -k -L http://tukaani.org/xz/xz-5.2.2.tar.gz -o xz-5.2.2.tar.gz &&; ${SHASUM} 73df4d5d34f0468bd57d09f2d8af363e95ed6cc3a4a86129d2f2c366259902a2 xz-5.2.2.tar.gz &&; tar -xzvf xz-5.2.2.tar.gz; #URL http://tukaani.org/xz/xz-5.2.2.tar.gz; #URL_HASH SHA1=14663612422ab61386673be78fbb",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:11416,Integrability,message,message,11416,"oost libraries; ##; if(CONDA_BUILD); set(Boost_USE_STATIC_LIBS OFF); elseif(USE_SHARED_LIBS) # CI failed when using an OR statement above...; set(Boost_USE_STATIC_LIBS OFF); else(); set(Boost_USE_STATIC_LIBS ON); endif(). set(Boost_USE_MULTITHREADED ON); #set(Boost_USE_STATIC_RUNTIME OFF); set(Boost_USE_DEBUG_RUNTIME OFF). find_package(ZLIB); if(NOT ZLIB_FOUND); message(FATAL_ERROR ""zlib must be installed before configuration & building can proceed""); endif(). if(""${CMAKE_INCLUDE_PATH}"" STREQUAL """"); set(EXTRA_CMAKE_INCLUDE_FLAGS """"); else(); set(EXTRA_CMAKE_INCLUDE_FLAGS ""-I${CMAKE_INCLUDE_PATH}""); endif(). if(""${CMAKE_LIBRARY_PATH}"" STREQUAL """"); set(EXTRA_CMAKE_LIBRARY_FLAGS """"); else(); set(EXTRA_CMAKE_LIBRARY_FLAGS ""-L${CMAKE_LIBRARY_PATH}""); endif(). find_package(Iconv REQUIRED); if(NOT Iconv_IS_BUILT_IN); set(ICONV_LIB Iconv::Iconv); endif(). find_package(LibLZMA); if(NOT LIBLZMA_FOUND); message(""Will attempt to fetch and build liblzma""); message(""=======================================""); externalproject_add(liblzma; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; ##; DOWNLOAD_COMMAND curl -k -L http://tukaani.org/xz/xz-5.2.2.tar.gz -o xz-5.2.2.tar.gz &&; ${SHASUM} 73df4d5d34f0468bd57d09f2d8af363e95ed6cc3a4a86129d2f2c366259902a2 xz-5.2.2.tar.gz &&; tar -xzvf xz-5.2.2.tar.gz; #URL http://tukaani.org/xz/xz-5.2.2.tar.gz; #URL_HASH SHA1=14663612422ab61386673be78fbb2556f50a1f08; ##; SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/xz-5.2.2; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; BUILD_IN_SOURCE TRUE; CONFIGURE_COMMAND ${CMAKE_CURRENT_SOURCE_DIR}/external/xz-5.2.2/configure --prefix=<INSTALL_DIR> CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER} CFLAGS=${EXTRA_CMAKE_INCLUDE_FLAGS} CPPFLAGS=${EXTRA_CMAKE_INCLUDE_FLAGS} LDFLAGS=${EXTRA_CMAKE_LIBRARY_FLAGS}; BUILD_COMMAND make ${QUIET_MAKE}; INSTALL_COMMAND make ${QUIET_MAKE} install; ). # Tell cmake that the external project generated a library so we can; # add dependencies here instead of later;",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:11468,Integrability,message,message,11468,"oost libraries; ##; if(CONDA_BUILD); set(Boost_USE_STATIC_LIBS OFF); elseif(USE_SHARED_LIBS) # CI failed when using an OR statement above...; set(Boost_USE_STATIC_LIBS OFF); else(); set(Boost_USE_STATIC_LIBS ON); endif(). set(Boost_USE_MULTITHREADED ON); #set(Boost_USE_STATIC_RUNTIME OFF); set(Boost_USE_DEBUG_RUNTIME OFF). find_package(ZLIB); if(NOT ZLIB_FOUND); message(FATAL_ERROR ""zlib must be installed before configuration & building can proceed""); endif(). if(""${CMAKE_INCLUDE_PATH}"" STREQUAL """"); set(EXTRA_CMAKE_INCLUDE_FLAGS """"); else(); set(EXTRA_CMAKE_INCLUDE_FLAGS ""-I${CMAKE_INCLUDE_PATH}""); endif(). if(""${CMAKE_LIBRARY_PATH}"" STREQUAL """"); set(EXTRA_CMAKE_LIBRARY_FLAGS """"); else(); set(EXTRA_CMAKE_LIBRARY_FLAGS ""-L${CMAKE_LIBRARY_PATH}""); endif(). find_package(Iconv REQUIRED); if(NOT Iconv_IS_BUILT_IN); set(ICONV_LIB Iconv::Iconv); endif(). find_package(LibLZMA); if(NOT LIBLZMA_FOUND); message(""Will attempt to fetch and build liblzma""); message(""=======================================""); externalproject_add(liblzma; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; ##; DOWNLOAD_COMMAND curl -k -L http://tukaani.org/xz/xz-5.2.2.tar.gz -o xz-5.2.2.tar.gz &&; ${SHASUM} 73df4d5d34f0468bd57d09f2d8af363e95ed6cc3a4a86129d2f2c366259902a2 xz-5.2.2.tar.gz &&; tar -xzvf xz-5.2.2.tar.gz; #URL http://tukaani.org/xz/xz-5.2.2.tar.gz; #URL_HASH SHA1=14663612422ab61386673be78fbb2556f50a1f08; ##; SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/xz-5.2.2; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; BUILD_IN_SOURCE TRUE; CONFIGURE_COMMAND ${CMAKE_CURRENT_SOURCE_DIR}/external/xz-5.2.2/configure --prefix=<INSTALL_DIR> CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER} CFLAGS=${EXTRA_CMAKE_INCLUDE_FLAGS} CPPFLAGS=${EXTRA_CMAKE_INCLUDE_FLAGS} LDFLAGS=${EXTRA_CMAKE_LIBRARY_FLAGS}; BUILD_COMMAND make ${QUIET_MAKE}; INSTALL_COMMAND make ${QUIET_MAKE} install; ). # Tell cmake that the external project generated a library so we can; # add dependencies here instead of later;",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:12473,Integrability,depend,dependencies,12473,"=============================""); externalproject_add(liblzma; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; ##; DOWNLOAD_COMMAND curl -k -L http://tukaani.org/xz/xz-5.2.2.tar.gz -o xz-5.2.2.tar.gz &&; ${SHASUM} 73df4d5d34f0468bd57d09f2d8af363e95ed6cc3a4a86129d2f2c366259902a2 xz-5.2.2.tar.gz &&; tar -xzvf xz-5.2.2.tar.gz; #URL http://tukaani.org/xz/xz-5.2.2.tar.gz; #URL_HASH SHA1=14663612422ab61386673be78fbb2556f50a1f08; ##; SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/xz-5.2.2; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; BUILD_IN_SOURCE TRUE; CONFIGURE_COMMAND ${CMAKE_CURRENT_SOURCE_DIR}/external/xz-5.2.2/configure --prefix=<INSTALL_DIR> CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER} CFLAGS=${EXTRA_CMAKE_INCLUDE_FLAGS} CPPFLAGS=${EXTRA_CMAKE_INCLUDE_FLAGS} LDFLAGS=${EXTRA_CMAKE_LIBRARY_FLAGS}; BUILD_COMMAND make ${QUIET_MAKE}; INSTALL_COMMAND make ${QUIET_MAKE} install; ). # Tell cmake that the external project generated a library so we can; # add dependencies here instead of later; set(LIBLZMA_LIBRARIES ${GAT_SOURCE_DIR}/external/install/lib/liblzma.a); set(LIBSTADEN_LDFLAGS ""-L${GAT_SOURCE_DIR}/external/install/lib""); set(LIBSTADEN_CFLAGS ""-I${GAT_SOURCE_DIR}/external/install/include""); set(FETCHED_LIBLZMA TRUE); else(); message(""Found liblzma library: ${LIBLZMA_LIBRARIES}""); message(""===========================================""); endif(). find_package(BZip2); if(NOT BZIP2_FOUND); message(""Will attempt to fetch and build libbz2""); message(""=======================================""); externalproject_add(libbz2; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://sourceware.org/pub/bzip2/bzip2-1.0.6.tar.gz -o bzip2-1.0.6.tar.gz &&; ${SHASUM} a2848f34fcd5d6cf47def00461fcb528a0484d8edef8208d6d2e2909dc61d9cd bzip2-1.0.6.tar.gz &&; tar -xzvf bzip2-1.0.6.tar.gz; #URL http://www.bzip.org/1.0.6/bzip2-1.0.6.tar.gz; #URL_HASH SHA1=3f89f861209ce81a6bab1fd1998c0ef311712002; SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/externa",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:12754,Integrability,message,message,12754,"2d8af363e95ed6cc3a4a86129d2f2c366259902a2 xz-5.2.2.tar.gz &&; tar -xzvf xz-5.2.2.tar.gz; #URL http://tukaani.org/xz/xz-5.2.2.tar.gz; #URL_HASH SHA1=14663612422ab61386673be78fbb2556f50a1f08; ##; SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/xz-5.2.2; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; BUILD_IN_SOURCE TRUE; CONFIGURE_COMMAND ${CMAKE_CURRENT_SOURCE_DIR}/external/xz-5.2.2/configure --prefix=<INSTALL_DIR> CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER} CFLAGS=${EXTRA_CMAKE_INCLUDE_FLAGS} CPPFLAGS=${EXTRA_CMAKE_INCLUDE_FLAGS} LDFLAGS=${EXTRA_CMAKE_LIBRARY_FLAGS}; BUILD_COMMAND make ${QUIET_MAKE}; INSTALL_COMMAND make ${QUIET_MAKE} install; ). # Tell cmake that the external project generated a library so we can; # add dependencies here instead of later; set(LIBLZMA_LIBRARIES ${GAT_SOURCE_DIR}/external/install/lib/liblzma.a); set(LIBSTADEN_LDFLAGS ""-L${GAT_SOURCE_DIR}/external/install/lib""); set(LIBSTADEN_CFLAGS ""-I${GAT_SOURCE_DIR}/external/install/include""); set(FETCHED_LIBLZMA TRUE); else(); message(""Found liblzma library: ${LIBLZMA_LIBRARIES}""); message(""===========================================""); endif(). find_package(BZip2); if(NOT BZIP2_FOUND); message(""Will attempt to fetch and build libbz2""); message(""=======================================""); externalproject_add(libbz2; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://sourceware.org/pub/bzip2/bzip2-1.0.6.tar.gz -o bzip2-1.0.6.tar.gz &&; ${SHASUM} a2848f34fcd5d6cf47def00461fcb528a0484d8edef8208d6d2e2909dc61d9cd bzip2-1.0.6.tar.gz &&; tar -xzvf bzip2-1.0.6.tar.gz; #URL http://www.bzip.org/1.0.6/bzip2-1.0.6.tar.gz; #URL_HASH SHA1=3f89f861209ce81a6bab1fd1998c0ef311712002; SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/bzip2-1.0.6; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; BUILD_IN_SOURCE TRUE; CONFIGURE_COMMAND """"; BUILD_COMMAND make ${QUIET_MAKE} CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER}; INSTALL_COMMAND make ${QUIET_MAKE} inst",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:12810,Integrability,message,message,12810,"2d8af363e95ed6cc3a4a86129d2f2c366259902a2 xz-5.2.2.tar.gz &&; tar -xzvf xz-5.2.2.tar.gz; #URL http://tukaani.org/xz/xz-5.2.2.tar.gz; #URL_HASH SHA1=14663612422ab61386673be78fbb2556f50a1f08; ##; SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/xz-5.2.2; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; BUILD_IN_SOURCE TRUE; CONFIGURE_COMMAND ${CMAKE_CURRENT_SOURCE_DIR}/external/xz-5.2.2/configure --prefix=<INSTALL_DIR> CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER} CFLAGS=${EXTRA_CMAKE_INCLUDE_FLAGS} CPPFLAGS=${EXTRA_CMAKE_INCLUDE_FLAGS} LDFLAGS=${EXTRA_CMAKE_LIBRARY_FLAGS}; BUILD_COMMAND make ${QUIET_MAKE}; INSTALL_COMMAND make ${QUIET_MAKE} install; ). # Tell cmake that the external project generated a library so we can; # add dependencies here instead of later; set(LIBLZMA_LIBRARIES ${GAT_SOURCE_DIR}/external/install/lib/liblzma.a); set(LIBSTADEN_LDFLAGS ""-L${GAT_SOURCE_DIR}/external/install/lib""); set(LIBSTADEN_CFLAGS ""-I${GAT_SOURCE_DIR}/external/install/include""); set(FETCHED_LIBLZMA TRUE); else(); message(""Found liblzma library: ${LIBLZMA_LIBRARIES}""); message(""===========================================""); endif(). find_package(BZip2); if(NOT BZIP2_FOUND); message(""Will attempt to fetch and build libbz2""); message(""=======================================""); externalproject_add(libbz2; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://sourceware.org/pub/bzip2/bzip2-1.0.6.tar.gz -o bzip2-1.0.6.tar.gz &&; ${SHASUM} a2848f34fcd5d6cf47def00461fcb528a0484d8edef8208d6d2e2909dc61d9cd bzip2-1.0.6.tar.gz &&; tar -xzvf bzip2-1.0.6.tar.gz; #URL http://www.bzip.org/1.0.6/bzip2-1.0.6.tar.gz; #URL_HASH SHA1=3f89f861209ce81a6bab1fd1998c0ef311712002; SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/bzip2-1.0.6; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; BUILD_IN_SOURCE TRUE; CONFIGURE_COMMAND """"; BUILD_COMMAND make ${QUIET_MAKE} CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER}; INSTALL_COMMAND make ${QUIET_MAKE} inst",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:12917,Integrability,message,message,12917,"CE_DIR}/external/install; BUILD_IN_SOURCE TRUE; CONFIGURE_COMMAND ${CMAKE_CURRENT_SOURCE_DIR}/external/xz-5.2.2/configure --prefix=<INSTALL_DIR> CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER} CFLAGS=${EXTRA_CMAKE_INCLUDE_FLAGS} CPPFLAGS=${EXTRA_CMAKE_INCLUDE_FLAGS} LDFLAGS=${EXTRA_CMAKE_LIBRARY_FLAGS}; BUILD_COMMAND make ${QUIET_MAKE}; INSTALL_COMMAND make ${QUIET_MAKE} install; ). # Tell cmake that the external project generated a library so we can; # add dependencies here instead of later; set(LIBLZMA_LIBRARIES ${GAT_SOURCE_DIR}/external/install/lib/liblzma.a); set(LIBSTADEN_LDFLAGS ""-L${GAT_SOURCE_DIR}/external/install/lib""); set(LIBSTADEN_CFLAGS ""-I${GAT_SOURCE_DIR}/external/install/include""); set(FETCHED_LIBLZMA TRUE); else(); message(""Found liblzma library: ${LIBLZMA_LIBRARIES}""); message(""===========================================""); endif(). find_package(BZip2); if(NOT BZIP2_FOUND); message(""Will attempt to fetch and build libbz2""); message(""=======================================""); externalproject_add(libbz2; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://sourceware.org/pub/bzip2/bzip2-1.0.6.tar.gz -o bzip2-1.0.6.tar.gz &&; ${SHASUM} a2848f34fcd5d6cf47def00461fcb528a0484d8edef8208d6d2e2909dc61d9cd bzip2-1.0.6.tar.gz &&; tar -xzvf bzip2-1.0.6.tar.gz; #URL http://www.bzip.org/1.0.6/bzip2-1.0.6.tar.gz; #URL_HASH SHA1=3f89f861209ce81a6bab1fd1998c0ef311712002; SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/bzip2-1.0.6; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; BUILD_IN_SOURCE TRUE; CONFIGURE_COMMAND """"; BUILD_COMMAND make ${QUIET_MAKE} CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER}; INSTALL_COMMAND make ${QUIET_MAKE} install PREFIX=<INSTALL_DIR>; ); # Tell cmake that the external project generated a library so we can; # add dependencies here instead of later; set(BZIP2_LIBRARIES ${GAT_SOURCE_DIR}/external/install/lib/libbz2.a); set(LIBSTADEN_LDFLAGS ""-L${GAT_SOURCE_DIR}/external/install/lib -I${GAT_S",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:12968,Integrability,message,message,12968,"CE_DIR}/external/install; BUILD_IN_SOURCE TRUE; CONFIGURE_COMMAND ${CMAKE_CURRENT_SOURCE_DIR}/external/xz-5.2.2/configure --prefix=<INSTALL_DIR> CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER} CFLAGS=${EXTRA_CMAKE_INCLUDE_FLAGS} CPPFLAGS=${EXTRA_CMAKE_INCLUDE_FLAGS} LDFLAGS=${EXTRA_CMAKE_LIBRARY_FLAGS}; BUILD_COMMAND make ${QUIET_MAKE}; INSTALL_COMMAND make ${QUIET_MAKE} install; ). # Tell cmake that the external project generated a library so we can; # add dependencies here instead of later; set(LIBLZMA_LIBRARIES ${GAT_SOURCE_DIR}/external/install/lib/liblzma.a); set(LIBSTADEN_LDFLAGS ""-L${GAT_SOURCE_DIR}/external/install/lib""); set(LIBSTADEN_CFLAGS ""-I${GAT_SOURCE_DIR}/external/install/include""); set(FETCHED_LIBLZMA TRUE); else(); message(""Found liblzma library: ${LIBLZMA_LIBRARIES}""); message(""===========================================""); endif(). find_package(BZip2); if(NOT BZIP2_FOUND); message(""Will attempt to fetch and build libbz2""); message(""=======================================""); externalproject_add(libbz2; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://sourceware.org/pub/bzip2/bzip2-1.0.6.tar.gz -o bzip2-1.0.6.tar.gz &&; ${SHASUM} a2848f34fcd5d6cf47def00461fcb528a0484d8edef8208d6d2e2909dc61d9cd bzip2-1.0.6.tar.gz &&; tar -xzvf bzip2-1.0.6.tar.gz; #URL http://www.bzip.org/1.0.6/bzip2-1.0.6.tar.gz; #URL_HASH SHA1=3f89f861209ce81a6bab1fd1998c0ef311712002; SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/bzip2-1.0.6; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; BUILD_IN_SOURCE TRUE; CONFIGURE_COMMAND """"; BUILD_COMMAND make ${QUIET_MAKE} CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER}; INSTALL_COMMAND make ${QUIET_MAKE} install PREFIX=<INSTALL_DIR>; ); # Tell cmake that the external project generated a library so we can; # add dependencies here instead of later; set(BZIP2_LIBRARIES ${GAT_SOURCE_DIR}/external/install/lib/libbz2.a); set(LIBSTADEN_LDFLAGS ""-L${GAT_SOURCE_DIR}/external/install/lib -I${GAT_S",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:13831,Integrability,depend,dependencies,13831,"); set(FETCHED_LIBLZMA TRUE); else(); message(""Found liblzma library: ${LIBLZMA_LIBRARIES}""); message(""===========================================""); endif(). find_package(BZip2); if(NOT BZIP2_FOUND); message(""Will attempt to fetch and build libbz2""); message(""=======================================""); externalproject_add(libbz2; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://sourceware.org/pub/bzip2/bzip2-1.0.6.tar.gz -o bzip2-1.0.6.tar.gz &&; ${SHASUM} a2848f34fcd5d6cf47def00461fcb528a0484d8edef8208d6d2e2909dc61d9cd bzip2-1.0.6.tar.gz &&; tar -xzvf bzip2-1.0.6.tar.gz; #URL http://www.bzip.org/1.0.6/bzip2-1.0.6.tar.gz; #URL_HASH SHA1=3f89f861209ce81a6bab1fd1998c0ef311712002; SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/bzip2-1.0.6; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; BUILD_IN_SOURCE TRUE; CONFIGURE_COMMAND """"; BUILD_COMMAND make ${QUIET_MAKE} CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER}; INSTALL_COMMAND make ${QUIET_MAKE} install PREFIX=<INSTALL_DIR>; ); # Tell cmake that the external project generated a library so we can; # add dependencies here instead of later; set(BZIP2_LIBRARIES ${GAT_SOURCE_DIR}/external/install/lib/libbz2.a); set(LIBSTADEN_LDFLAGS ""-L${GAT_SOURCE_DIR}/external/install/lib -I${GAT_SOURCE_DIR}/external/install/include""); set(LIBSTADEN_CFLAGS ""-I${GAT_SOURCE_DIR}/external/install/include""); set(FETCHED_LIBBZ2 TRUE); else(); message(""Found libbz2 library: ${BZIP2_LIBRARIES}""); message(""===========================================""); endif(). ##; # Set the latest version and look for what we need; ##; set(Boost_ADDITIONAL_VERSIONS ""1.59.0"" ""1.60.0"" ""1.61.0"" ""1.62.0"" ""1.63.0"" ""1.64.0"" ""1.65.0"" ""1.66.0"" ""1.67.0"" ""1.68.0"" ""1.69.0"" ""1.70.0"" ""1.71.0"" ""1.72.0"" ""1.73.0"" ""1.74.0"" ""1.75.0"" ""1.76.0"" ""1.77.0"" ""1.78.0""); if (NOT BOOST_RECONFIGURE); find_package(Boost 1.59.0 COMPONENTS iostreams system filesystem timer chrono program_options); message(""BOOST_INCLUDEDIR = ${BOOST_INCLUDEDIR}"")",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:14153,Integrability,message,message,14153,"WNLOAD_COMMAND curl -k -L https://sourceware.org/pub/bzip2/bzip2-1.0.6.tar.gz -o bzip2-1.0.6.tar.gz &&; ${SHASUM} a2848f34fcd5d6cf47def00461fcb528a0484d8edef8208d6d2e2909dc61d9cd bzip2-1.0.6.tar.gz &&; tar -xzvf bzip2-1.0.6.tar.gz; #URL http://www.bzip.org/1.0.6/bzip2-1.0.6.tar.gz; #URL_HASH SHA1=3f89f861209ce81a6bab1fd1998c0ef311712002; SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/bzip2-1.0.6; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; BUILD_IN_SOURCE TRUE; CONFIGURE_COMMAND """"; BUILD_COMMAND make ${QUIET_MAKE} CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER}; INSTALL_COMMAND make ${QUIET_MAKE} install PREFIX=<INSTALL_DIR>; ); # Tell cmake that the external project generated a library so we can; # add dependencies here instead of later; set(BZIP2_LIBRARIES ${GAT_SOURCE_DIR}/external/install/lib/libbz2.a); set(LIBSTADEN_LDFLAGS ""-L${GAT_SOURCE_DIR}/external/install/lib -I${GAT_SOURCE_DIR}/external/install/include""); set(LIBSTADEN_CFLAGS ""-I${GAT_SOURCE_DIR}/external/install/include""); set(FETCHED_LIBBZ2 TRUE); else(); message(""Found libbz2 library: ${BZIP2_LIBRARIES}""); message(""===========================================""); endif(). ##; # Set the latest version and look for what we need; ##; set(Boost_ADDITIONAL_VERSIONS ""1.59.0"" ""1.60.0"" ""1.61.0"" ""1.62.0"" ""1.63.0"" ""1.64.0"" ""1.65.0"" ""1.66.0"" ""1.67.0"" ""1.68.0"" ""1.69.0"" ""1.70.0"" ""1.71.0"" ""1.72.0"" ""1.73.0"" ""1.74.0"" ""1.75.0"" ""1.76.0"" ""1.77.0"" ""1.78.0""); if (NOT BOOST_RECONFIGURE); find_package(Boost 1.59.0 COMPONENTS iostreams system filesystem timer chrono program_options); message(""BOOST_INCLUDEDIR = ${BOOST_INCLUDEDIR}""); message(""BOOST_LIBRARYDIR = ${BOOST_LIBRARYDIR}""); message(""Boost_FOUND = ${Boost_FOUND}""); endif(). include(ExternalProject). ##; # If we had to fetch Boost, the reconfigure step will re-run cmake. The second configuration; # pass is executed with the BOOST_RECONFIGURE flag set. This should allow our newly; # installed Boost to be found by CMake.; ##; if(BOOST_RECONFIGURE); messag",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:14206,Integrability,message,message,14206,"WNLOAD_COMMAND curl -k -L https://sourceware.org/pub/bzip2/bzip2-1.0.6.tar.gz -o bzip2-1.0.6.tar.gz &&; ${SHASUM} a2848f34fcd5d6cf47def00461fcb528a0484d8edef8208d6d2e2909dc61d9cd bzip2-1.0.6.tar.gz &&; tar -xzvf bzip2-1.0.6.tar.gz; #URL http://www.bzip.org/1.0.6/bzip2-1.0.6.tar.gz; #URL_HASH SHA1=3f89f861209ce81a6bab1fd1998c0ef311712002; SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/bzip2-1.0.6; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; BUILD_IN_SOURCE TRUE; CONFIGURE_COMMAND """"; BUILD_COMMAND make ${QUIET_MAKE} CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER}; INSTALL_COMMAND make ${QUIET_MAKE} install PREFIX=<INSTALL_DIR>; ); # Tell cmake that the external project generated a library so we can; # add dependencies here instead of later; set(BZIP2_LIBRARIES ${GAT_SOURCE_DIR}/external/install/lib/libbz2.a); set(LIBSTADEN_LDFLAGS ""-L${GAT_SOURCE_DIR}/external/install/lib -I${GAT_SOURCE_DIR}/external/install/include""); set(LIBSTADEN_CFLAGS ""-I${GAT_SOURCE_DIR}/external/install/include""); set(FETCHED_LIBBZ2 TRUE); else(); message(""Found libbz2 library: ${BZIP2_LIBRARIES}""); message(""===========================================""); endif(). ##; # Set the latest version and look for what we need; ##; set(Boost_ADDITIONAL_VERSIONS ""1.59.0"" ""1.60.0"" ""1.61.0"" ""1.62.0"" ""1.63.0"" ""1.64.0"" ""1.65.0"" ""1.66.0"" ""1.67.0"" ""1.68.0"" ""1.69.0"" ""1.70.0"" ""1.71.0"" ""1.72.0"" ""1.73.0"" ""1.74.0"" ""1.75.0"" ""1.76.0"" ""1.77.0"" ""1.78.0""); if (NOT BOOST_RECONFIGURE); find_package(Boost 1.59.0 COMPONENTS iostreams system filesystem timer chrono program_options); message(""BOOST_INCLUDEDIR = ${BOOST_INCLUDEDIR}""); message(""BOOST_LIBRARYDIR = ${BOOST_LIBRARYDIR}""); message(""Boost_FOUND = ${Boost_FOUND}""); endif(). include(ExternalProject). ##; # If we had to fetch Boost, the reconfigure step will re-run cmake. The second configuration; # pass is executed with the BOOST_RECONFIGURE flag set. This should allow our newly; # installed Boost to be found by CMake.; ##; if(BOOST_RECONFIGURE); messag",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:14667,Integrability,message,message,14667,"e ${QUIET_MAKE} install PREFIX=<INSTALL_DIR>; ); # Tell cmake that the external project generated a library so we can; # add dependencies here instead of later; set(BZIP2_LIBRARIES ${GAT_SOURCE_DIR}/external/install/lib/libbz2.a); set(LIBSTADEN_LDFLAGS ""-L${GAT_SOURCE_DIR}/external/install/lib -I${GAT_SOURCE_DIR}/external/install/include""); set(LIBSTADEN_CFLAGS ""-I${GAT_SOURCE_DIR}/external/install/include""); set(FETCHED_LIBBZ2 TRUE); else(); message(""Found libbz2 library: ${BZIP2_LIBRARIES}""); message(""===========================================""); endif(). ##; # Set the latest version and look for what we need; ##; set(Boost_ADDITIONAL_VERSIONS ""1.59.0"" ""1.60.0"" ""1.61.0"" ""1.62.0"" ""1.63.0"" ""1.64.0"" ""1.65.0"" ""1.66.0"" ""1.67.0"" ""1.68.0"" ""1.69.0"" ""1.70.0"" ""1.71.0"" ""1.72.0"" ""1.73.0"" ""1.74.0"" ""1.75.0"" ""1.76.0"" ""1.77.0"" ""1.78.0""); if (NOT BOOST_RECONFIGURE); find_package(Boost 1.59.0 COMPONENTS iostreams system filesystem timer chrono program_options); message(""BOOST_INCLUDEDIR = ${BOOST_INCLUDEDIR}""); message(""BOOST_LIBRARYDIR = ${BOOST_LIBRARYDIR}""); message(""Boost_FOUND = ${Boost_FOUND}""); endif(). include(ExternalProject). ##; # If we had to fetch Boost, the reconfigure step will re-run cmake. The second configuration; # pass is executed with the BOOST_RECONFIGURE flag set. This should allow our newly; # installed Boost to be found by CMake.; ##; if(BOOST_RECONFIGURE); message(""Executing Boost Reconfiguration""); unset(Boost_FOUND CACHE); unset(Boost_INCLUDE_DIR CACHE); unset(Boost_INCLUDE_DIRS CACHE); unset(Boost_LIBRARY_DIRS CACHE); unset(Boost_LIBRARIES CACHE); unset(BOOST_ROOT CACHE); unset(CMAKE_PREFIX_PATH CACHE); unset(Boost::diagnostic_definitions CACHE); unset(Boost::disable_autolinking CACHE); unset(Boost::dynamic_linking CACHE); set(BOOST_ROOT ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(CMAKE_PREFIX_PATH ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(Boost_INCLUDE_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/include); set(Boost_LIBRARY_DIRS ${",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:14718,Integrability,message,message,14718,"e ${QUIET_MAKE} install PREFIX=<INSTALL_DIR>; ); # Tell cmake that the external project generated a library so we can; # add dependencies here instead of later; set(BZIP2_LIBRARIES ${GAT_SOURCE_DIR}/external/install/lib/libbz2.a); set(LIBSTADEN_LDFLAGS ""-L${GAT_SOURCE_DIR}/external/install/lib -I${GAT_SOURCE_DIR}/external/install/include""); set(LIBSTADEN_CFLAGS ""-I${GAT_SOURCE_DIR}/external/install/include""); set(FETCHED_LIBBZ2 TRUE); else(); message(""Found libbz2 library: ${BZIP2_LIBRARIES}""); message(""===========================================""); endif(). ##; # Set the latest version and look for what we need; ##; set(Boost_ADDITIONAL_VERSIONS ""1.59.0"" ""1.60.0"" ""1.61.0"" ""1.62.0"" ""1.63.0"" ""1.64.0"" ""1.65.0"" ""1.66.0"" ""1.67.0"" ""1.68.0"" ""1.69.0"" ""1.70.0"" ""1.71.0"" ""1.72.0"" ""1.73.0"" ""1.74.0"" ""1.75.0"" ""1.76.0"" ""1.77.0"" ""1.78.0""); if (NOT BOOST_RECONFIGURE); find_package(Boost 1.59.0 COMPONENTS iostreams system filesystem timer chrono program_options); message(""BOOST_INCLUDEDIR = ${BOOST_INCLUDEDIR}""); message(""BOOST_LIBRARYDIR = ${BOOST_LIBRARYDIR}""); message(""Boost_FOUND = ${Boost_FOUND}""); endif(). include(ExternalProject). ##; # If we had to fetch Boost, the reconfigure step will re-run cmake. The second configuration; # pass is executed with the BOOST_RECONFIGURE flag set. This should allow our newly; # installed Boost to be found by CMake.; ##; if(BOOST_RECONFIGURE); message(""Executing Boost Reconfiguration""); unset(Boost_FOUND CACHE); unset(Boost_INCLUDE_DIR CACHE); unset(Boost_INCLUDE_DIRS CACHE); unset(Boost_LIBRARY_DIRS CACHE); unset(Boost_LIBRARIES CACHE); unset(BOOST_ROOT CACHE); unset(CMAKE_PREFIX_PATH CACHE); unset(Boost::diagnostic_definitions CACHE); unset(Boost::disable_autolinking CACHE); unset(Boost::dynamic_linking CACHE); set(BOOST_ROOT ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(CMAKE_PREFIX_PATH ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(Boost_INCLUDE_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/include); set(Boost_LIBRARY_DIRS ${",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:14769,Integrability,message,message,14769,"e ${QUIET_MAKE} install PREFIX=<INSTALL_DIR>; ); # Tell cmake that the external project generated a library so we can; # add dependencies here instead of later; set(BZIP2_LIBRARIES ${GAT_SOURCE_DIR}/external/install/lib/libbz2.a); set(LIBSTADEN_LDFLAGS ""-L${GAT_SOURCE_DIR}/external/install/lib -I${GAT_SOURCE_DIR}/external/install/include""); set(LIBSTADEN_CFLAGS ""-I${GAT_SOURCE_DIR}/external/install/include""); set(FETCHED_LIBBZ2 TRUE); else(); message(""Found libbz2 library: ${BZIP2_LIBRARIES}""); message(""===========================================""); endif(). ##; # Set the latest version and look for what we need; ##; set(Boost_ADDITIONAL_VERSIONS ""1.59.0"" ""1.60.0"" ""1.61.0"" ""1.62.0"" ""1.63.0"" ""1.64.0"" ""1.65.0"" ""1.66.0"" ""1.67.0"" ""1.68.0"" ""1.69.0"" ""1.70.0"" ""1.71.0"" ""1.72.0"" ""1.73.0"" ""1.74.0"" ""1.75.0"" ""1.76.0"" ""1.77.0"" ""1.78.0""); if (NOT BOOST_RECONFIGURE); find_package(Boost 1.59.0 COMPONENTS iostreams system filesystem timer chrono program_options); message(""BOOST_INCLUDEDIR = ${BOOST_INCLUDEDIR}""); message(""BOOST_LIBRARYDIR = ${BOOST_LIBRARYDIR}""); message(""Boost_FOUND = ${Boost_FOUND}""); endif(). include(ExternalProject). ##; # If we had to fetch Boost, the reconfigure step will re-run cmake. The second configuration; # pass is executed with the BOOST_RECONFIGURE flag set. This should allow our newly; # installed Boost to be found by CMake.; ##; if(BOOST_RECONFIGURE); message(""Executing Boost Reconfiguration""); unset(Boost_FOUND CACHE); unset(Boost_INCLUDE_DIR CACHE); unset(Boost_INCLUDE_DIRS CACHE); unset(Boost_LIBRARY_DIRS CACHE); unset(Boost_LIBRARIES CACHE); unset(BOOST_ROOT CACHE); unset(CMAKE_PREFIX_PATH CACHE); unset(Boost::diagnostic_definitions CACHE); unset(Boost::disable_autolinking CACHE); unset(Boost::dynamic_linking CACHE); set(BOOST_ROOT ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(CMAKE_PREFIX_PATH ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(Boost_INCLUDE_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/include); set(Boost_LIBRARY_DIRS ${",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:15096,Integrability,message,message,15096,""" ""1.66.0"" ""1.67.0"" ""1.68.0"" ""1.69.0"" ""1.70.0"" ""1.71.0"" ""1.72.0"" ""1.73.0"" ""1.74.0"" ""1.75.0"" ""1.76.0"" ""1.77.0"" ""1.78.0""); if (NOT BOOST_RECONFIGURE); find_package(Boost 1.59.0 COMPONENTS iostreams system filesystem timer chrono program_options); message(""BOOST_INCLUDEDIR = ${BOOST_INCLUDEDIR}""); message(""BOOST_LIBRARYDIR = ${BOOST_LIBRARYDIR}""); message(""Boost_FOUND = ${Boost_FOUND}""); endif(). include(ExternalProject). ##; # If we had to fetch Boost, the reconfigure step will re-run cmake. The second configuration; # pass is executed with the BOOST_RECONFIGURE flag set. This should allow our newly; # installed Boost to be found by CMake.; ##; if(BOOST_RECONFIGURE); message(""Executing Boost Reconfiguration""); unset(Boost_FOUND CACHE); unset(Boost_INCLUDE_DIR CACHE); unset(Boost_INCLUDE_DIRS CACHE); unset(Boost_LIBRARY_DIRS CACHE); unset(Boost_LIBRARIES CACHE); unset(BOOST_ROOT CACHE); unset(CMAKE_PREFIX_PATH CACHE); unset(Boost::diagnostic_definitions CACHE); unset(Boost::disable_autolinking CACHE); unset(Boost::dynamic_linking CACHE); set(BOOST_ROOT ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(CMAKE_PREFIX_PATH ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(Boost_INCLUDE_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/include); set(Boost_LIBRARY_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/lib); find_package(Boost 1.59.0 COMPONENTS iostreams system filesystem timer chrono program_options locale REQUIRED); set(FETCH_BOOST FALSE); endif(). ##; # Either inform the user of how to obtain Boost, or, if they passed in the FETCH_BOOST; # option, go and grab it for them.; ##; if((NOT Boost_FOUND) AND (NOT FETCH_BOOST)); message(FATAL_ERROR; ""Salmon cannot be compiled without Boost.\n""; ""It is recommended to visit http://www.boost.org/ and install Boost according to those instructions.\n""; ""This build system can also download and install a local version of boost for you (this takes a lot of time).\n""; ""To fetch and build boost locally, call cmake with -DFETCH",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:16078,Integrability,message,message,16078,"ECONFIGURE); message(""Executing Boost Reconfiguration""); unset(Boost_FOUND CACHE); unset(Boost_INCLUDE_DIR CACHE); unset(Boost_INCLUDE_DIRS CACHE); unset(Boost_LIBRARY_DIRS CACHE); unset(Boost_LIBRARIES CACHE); unset(BOOST_ROOT CACHE); unset(CMAKE_PREFIX_PATH CACHE); unset(Boost::diagnostic_definitions CACHE); unset(Boost::disable_autolinking CACHE); unset(Boost::dynamic_linking CACHE); set(BOOST_ROOT ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(CMAKE_PREFIX_PATH ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(Boost_INCLUDE_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/include); set(Boost_LIBRARY_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/lib); find_package(Boost 1.59.0 COMPONENTS iostreams system filesystem timer chrono program_options locale REQUIRED); set(FETCH_BOOST FALSE); endif(). ##; # Either inform the user of how to obtain Boost, or, if they passed in the FETCH_BOOST; # option, go and grab it for them.; ##; if((NOT Boost_FOUND) AND (NOT FETCH_BOOST)); message(FATAL_ERROR; ""Salmon cannot be compiled without Boost.\n""; ""It is recommended to visit http://www.boost.org/ and install Boost according to those instructions.\n""; ""This build system can also download and install a local version of boost for you (this takes a lot of time).\n""; ""To fetch and build boost locally, call cmake with -DFETCH_BOOST=TRUE""; ); elseif(FETCH_BOOST); if(NOT DEFINED BOOST_BUILD_THREADS); set(BOOST_BUILD_THREADS 2); endif(). ## Let the rest of the build process know we're going to be fetching boost; set(BOOST_LIB_SUBSET --with-iostreams --with-atomic --with-chrono --with-container --with-date_time --with-exception; --with-filesystem --with-graph --with-graph_parallel --with-math; --with-program_options --with-system --with-locale; --with-timer); set(BOOST_WILL_RECONFIGURE TRUE); set(FETCH_BOOST FALSE); set(BOOST_FETCHED_VERSION ""1_72_0""); message(""Build system will fetch and build Boost""); message(""==================================================================""",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:16956,Integrability,message,message,16956,"TCH_BOOST FALSE); endif(). ##; # Either inform the user of how to obtain Boost, or, if they passed in the FETCH_BOOST; # option, go and grab it for them.; ##; if((NOT Boost_FOUND) AND (NOT FETCH_BOOST)); message(FATAL_ERROR; ""Salmon cannot be compiled without Boost.\n""; ""It is recommended to visit http://www.boost.org/ and install Boost according to those instructions.\n""; ""This build system can also download and install a local version of boost for you (this takes a lot of time).\n""; ""To fetch and build boost locally, call cmake with -DFETCH_BOOST=TRUE""; ); elseif(FETCH_BOOST); if(NOT DEFINED BOOST_BUILD_THREADS); set(BOOST_BUILD_THREADS 2); endif(). ## Let the rest of the build process know we're going to be fetching boost; set(BOOST_LIB_SUBSET --with-iostreams --with-atomic --with-chrono --with-container --with-date_time --with-exception; --with-filesystem --with-graph --with-graph_parallel --with-math; --with-program_options --with-system --with-locale; --with-timer); set(BOOST_WILL_RECONFIGURE TRUE); set(FETCH_BOOST FALSE); set(BOOST_FETCHED_VERSION ""1_72_0""); message(""Build system will fetch and build Boost""); message(""==================================================================""); externalproject_add(libboost; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://sourceforge.net/projects/boost/files/boost/1.72.0/boost_1_72_0.tar.gz/download -o boost_1_72_0.tar.gz &&; #${SHASUM} 96b34f7468f26a141f6020efb813f1a2f3dfb9797ecf76a7d7cbd843cc95f5bd boost_1_71_0.tar.gz &&; ${SHASUM} c66e88d5786f2ca4dbebb14e06b566fb642a1a6947ad8cc9091f9f445134143f boost_${BOOST_FETCHED_VERSION}.tar.gz &&; tar xzf boost_${BOOST_FETCHED_VERSION}.tar.gz ; SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/boost_${BOOST_FETCHED_VERSION}; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; #PATCH_COMMAND patch -p2 < ${CMAKE_CURRENT_SOURCE_DIR}/external/boost156.patch; CONFIGURE_COMMAND CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER} ${CMAKE_CURRENT",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:17008,Integrability,message,message,17008,"TCH_BOOST FALSE); endif(). ##; # Either inform the user of how to obtain Boost, or, if they passed in the FETCH_BOOST; # option, go and grab it for them.; ##; if((NOT Boost_FOUND) AND (NOT FETCH_BOOST)); message(FATAL_ERROR; ""Salmon cannot be compiled without Boost.\n""; ""It is recommended to visit http://www.boost.org/ and install Boost according to those instructions.\n""; ""This build system can also download and install a local version of boost for you (this takes a lot of time).\n""; ""To fetch and build boost locally, call cmake with -DFETCH_BOOST=TRUE""; ); elseif(FETCH_BOOST); if(NOT DEFINED BOOST_BUILD_THREADS); set(BOOST_BUILD_THREADS 2); endif(). ## Let the rest of the build process know we're going to be fetching boost; set(BOOST_LIB_SUBSET --with-iostreams --with-atomic --with-chrono --with-container --with-date_time --with-exception; --with-filesystem --with-graph --with-graph_parallel --with-math; --with-program_options --with-system --with-locale; --with-timer); set(BOOST_WILL_RECONFIGURE TRUE); set(FETCH_BOOST FALSE); set(BOOST_FETCHED_VERSION ""1_72_0""); message(""Build system will fetch and build Boost""); message(""==================================================================""); externalproject_add(libboost; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://sourceforge.net/projects/boost/files/boost/1.72.0/boost_1_72_0.tar.gz/download -o boost_1_72_0.tar.gz &&; #${SHASUM} 96b34f7468f26a141f6020efb813f1a2f3dfb9797ecf76a7d7cbd843cc95f5bd boost_1_71_0.tar.gz &&; ${SHASUM} c66e88d5786f2ca4dbebb14e06b566fb642a1a6947ad8cc9091f9f445134143f boost_${BOOST_FETCHED_VERSION}.tar.gz &&; tar xzf boost_${BOOST_FETCHED_VERSION}.tar.gz ; SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/boost_${BOOST_FETCHED_VERSION}; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; #PATCH_COMMAND patch -p2 < ${CMAKE_CURRENT_SOURCE_DIR}/external/boost156.patch; CONFIGURE_COMMAND CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER} ${CMAKE_CURRENT",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:19174,Integrability,message,message,19174,"OMPILER} CXX=${CMAKE_CXX_COMPILER} ${CMAKE_CURRENT_SOURCE_DIR}/external/boost_${BOOST_FETCHED_VERSION}/b2 -d0 -j${BOOST_BUILD_THREADS} ${BOOST_LIB_SUBSET} toolset=${BOOST_TOOLSET} ${BOOST_EXTRA_FLAGS} cxxflags=${BOOST_CXX_FLAGS} link=static install; BUILD_IN_SOURCE 1; INSTALL_COMMAND """"; ). externalproject_add_step(libboost makedir; COMMAND mkdir -p <SOURCE_DIR>/build; COMMENT ""Make build directory""; DEPENDEES download; DEPENDERS configure). ##; # After we've installed boost,; ##; set(RECONFIG_FLAGS ${RECONFIG_FLAGS} -DBOOST_WILL_RECONFIGURE=FALSE -DBOOST_RECONFIGURE=TRUE -DFETCH_BOOST=FALSE); externalproject_add_step(libboost reconfigure; COMMAND ${CMAKE_COMMAND} ${CMAKE_CURRENT_SOURCE_DIR} ${RECONFIG_FLAGS}; DEPENDEES install; ); set(FETCHED_BOOST TRUE); endif(). ##; # If we're fetching boost and we need to have dummy paths for these variables; # so that CMake won't complain; ##; if(BOOST_WILL_RECONFIGURE); message(""Setting Temporary Boost paths""); set(Boost_INCLUDE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install/include); set(Boost_INCLUDE_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/include); set(Boost_LIBRARY_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/lib); set(Boost_FOUND TRUE); endif(). message(""BOOST ROOT = ${BOOST_ROOT}""); message(""BOOST INCLUDE DIR = ${Boost_INCLUDE_DIR}""); message(""BOOST INCLUDE DIRS = ${Boost_INCLUDE_DIRS}""); message(""BOOST LIB DIR = ${Boost_LIBRARY_DIRS}""); message(""BOOST LIBRARIES = ${Boost_LIBRARIES}""). set(EXTERNAL_LIBRARY_PATH $CMAKE_CURRENT_SOURCE_DIR/lib). #find_package(libdivsufsort); #if(NOT LIBDIVSUFSORT_FOUND); # message(""Build system will build libdivsufsort""); # message(""==================================================================""); # include(ExternalProject); # externalproject_add(libdivsufsort; # DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; # URL ${CMAKE_CURRENT_SOURCE_DIR}/external/libdivsufsort.zip; # # Note: This zip comes from the fetched rapmap.zip, whose SHA we check; # # so we souldn't need",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:19477,Integrability,message,message,19477," -p <SOURCE_DIR>/build; COMMENT ""Make build directory""; DEPENDEES download; DEPENDERS configure). ##; # After we've installed boost,; ##; set(RECONFIG_FLAGS ${RECONFIG_FLAGS} -DBOOST_WILL_RECONFIGURE=FALSE -DBOOST_RECONFIGURE=TRUE -DFETCH_BOOST=FALSE); externalproject_add_step(libboost reconfigure; COMMAND ${CMAKE_COMMAND} ${CMAKE_CURRENT_SOURCE_DIR} ${RECONFIG_FLAGS}; DEPENDEES install; ); set(FETCHED_BOOST TRUE); endif(). ##; # If we're fetching boost and we need to have dummy paths for these variables; # so that CMake won't complain; ##; if(BOOST_WILL_RECONFIGURE); message(""Setting Temporary Boost paths""); set(Boost_INCLUDE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install/include); set(Boost_INCLUDE_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/include); set(Boost_LIBRARY_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/lib); set(Boost_FOUND TRUE); endif(). message(""BOOST ROOT = ${BOOST_ROOT}""); message(""BOOST INCLUDE DIR = ${Boost_INCLUDE_DIR}""); message(""BOOST INCLUDE DIRS = ${Boost_INCLUDE_DIRS}""); message(""BOOST LIB DIR = ${Boost_LIBRARY_DIRS}""); message(""BOOST LIBRARIES = ${Boost_LIBRARIES}""). set(EXTERNAL_LIBRARY_PATH $CMAKE_CURRENT_SOURCE_DIR/lib). #find_package(libdivsufsort); #if(NOT LIBDIVSUFSORT_FOUND); # message(""Build system will build libdivsufsort""); # message(""==================================================================""); # include(ExternalProject); # externalproject_add(libdivsufsort; # DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; # URL ${CMAKE_CURRENT_SOURCE_DIR}/external/libdivsufsort.zip; # # Note: This zip comes from the fetched rapmap.zip, whose SHA we check; # # so we souldn't need to check this one separately.; # SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/libdivsufsort-master; # INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; # #UPDATE_COMMAND sh -c ""mkdir -p <SOURCE_DIR>/build""; # BINARY_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/libdivsufsort-master/build; # CMAKE_ARGS -DCMAKE_INSTALL_PREFIX:PATH=<INSTALL_D",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:19516,Integrability,message,message,19516," -p <SOURCE_DIR>/build; COMMENT ""Make build directory""; DEPENDEES download; DEPENDERS configure). ##; # After we've installed boost,; ##; set(RECONFIG_FLAGS ${RECONFIG_FLAGS} -DBOOST_WILL_RECONFIGURE=FALSE -DBOOST_RECONFIGURE=TRUE -DFETCH_BOOST=FALSE); externalproject_add_step(libboost reconfigure; COMMAND ${CMAKE_COMMAND} ${CMAKE_CURRENT_SOURCE_DIR} ${RECONFIG_FLAGS}; DEPENDEES install; ); set(FETCHED_BOOST TRUE); endif(). ##; # If we're fetching boost and we need to have dummy paths for these variables; # so that CMake won't complain; ##; if(BOOST_WILL_RECONFIGURE); message(""Setting Temporary Boost paths""); set(Boost_INCLUDE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install/include); set(Boost_INCLUDE_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/include); set(Boost_LIBRARY_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/lib); set(Boost_FOUND TRUE); endif(). message(""BOOST ROOT = ${BOOST_ROOT}""); message(""BOOST INCLUDE DIR = ${Boost_INCLUDE_DIR}""); message(""BOOST INCLUDE DIRS = ${Boost_INCLUDE_DIRS}""); message(""BOOST LIB DIR = ${Boost_LIBRARY_DIRS}""); message(""BOOST LIBRARIES = ${Boost_LIBRARIES}""). set(EXTERNAL_LIBRARY_PATH $CMAKE_CURRENT_SOURCE_DIR/lib). #find_package(libdivsufsort); #if(NOT LIBDIVSUFSORT_FOUND); # message(""Build system will build libdivsufsort""); # message(""==================================================================""); # include(ExternalProject); # externalproject_add(libdivsufsort; # DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; # URL ${CMAKE_CURRENT_SOURCE_DIR}/external/libdivsufsort.zip; # # Note: This zip comes from the fetched rapmap.zip, whose SHA we check; # # so we souldn't need to check this one separately.; # SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/libdivsufsort-master; # INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; # #UPDATE_COMMAND sh -c ""mkdir -p <SOURCE_DIR>/build""; # BINARY_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/libdivsufsort-master/build; # CMAKE_ARGS -DCMAKE_INSTALL_PREFIX:PATH=<INSTALL_D",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:19569,Integrability,message,message,19569," -p <SOURCE_DIR>/build; COMMENT ""Make build directory""; DEPENDEES download; DEPENDERS configure). ##; # After we've installed boost,; ##; set(RECONFIG_FLAGS ${RECONFIG_FLAGS} -DBOOST_WILL_RECONFIGURE=FALSE -DBOOST_RECONFIGURE=TRUE -DFETCH_BOOST=FALSE); externalproject_add_step(libboost reconfigure; COMMAND ${CMAKE_COMMAND} ${CMAKE_CURRENT_SOURCE_DIR} ${RECONFIG_FLAGS}; DEPENDEES install; ); set(FETCHED_BOOST TRUE); endif(). ##; # If we're fetching boost and we need to have dummy paths for these variables; # so that CMake won't complain; ##; if(BOOST_WILL_RECONFIGURE); message(""Setting Temporary Boost paths""); set(Boost_INCLUDE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install/include); set(Boost_INCLUDE_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/include); set(Boost_LIBRARY_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/lib); set(Boost_FOUND TRUE); endif(). message(""BOOST ROOT = ${BOOST_ROOT}""); message(""BOOST INCLUDE DIR = ${Boost_INCLUDE_DIR}""); message(""BOOST INCLUDE DIRS = ${Boost_INCLUDE_DIRS}""); message(""BOOST LIB DIR = ${Boost_LIBRARY_DIRS}""); message(""BOOST LIBRARIES = ${Boost_LIBRARIES}""). set(EXTERNAL_LIBRARY_PATH $CMAKE_CURRENT_SOURCE_DIR/lib). #find_package(libdivsufsort); #if(NOT LIBDIVSUFSORT_FOUND); # message(""Build system will build libdivsufsort""); # message(""==================================================================""); # include(ExternalProject); # externalproject_add(libdivsufsort; # DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; # URL ${CMAKE_CURRENT_SOURCE_DIR}/external/libdivsufsort.zip; # # Note: This zip comes from the fetched rapmap.zip, whose SHA we check; # # so we souldn't need to check this one separately.; # SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/libdivsufsort-master; # INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; # #UPDATE_COMMAND sh -c ""mkdir -p <SOURCE_DIR>/build""; # BINARY_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/libdivsufsort-master/build; # CMAKE_ARGS -DCMAKE_INSTALL_PREFIX:PATH=<INSTALL_D",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:19624,Integrability,message,message,19624," -p <SOURCE_DIR>/build; COMMENT ""Make build directory""; DEPENDEES download; DEPENDERS configure). ##; # After we've installed boost,; ##; set(RECONFIG_FLAGS ${RECONFIG_FLAGS} -DBOOST_WILL_RECONFIGURE=FALSE -DBOOST_RECONFIGURE=TRUE -DFETCH_BOOST=FALSE); externalproject_add_step(libboost reconfigure; COMMAND ${CMAKE_COMMAND} ${CMAKE_CURRENT_SOURCE_DIR} ${RECONFIG_FLAGS}; DEPENDEES install; ); set(FETCHED_BOOST TRUE); endif(). ##; # If we're fetching boost and we need to have dummy paths for these variables; # so that CMake won't complain; ##; if(BOOST_WILL_RECONFIGURE); message(""Setting Temporary Boost paths""); set(Boost_INCLUDE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install/include); set(Boost_INCLUDE_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/include); set(Boost_LIBRARY_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/lib); set(Boost_FOUND TRUE); endif(). message(""BOOST ROOT = ${BOOST_ROOT}""); message(""BOOST INCLUDE DIR = ${Boost_INCLUDE_DIR}""); message(""BOOST INCLUDE DIRS = ${Boost_INCLUDE_DIRS}""); message(""BOOST LIB DIR = ${Boost_LIBRARY_DIRS}""); message(""BOOST LIBRARIES = ${Boost_LIBRARIES}""). set(EXTERNAL_LIBRARY_PATH $CMAKE_CURRENT_SOURCE_DIR/lib). #find_package(libdivsufsort); #if(NOT LIBDIVSUFSORT_FOUND); # message(""Build system will build libdivsufsort""); # message(""==================================================================""); # include(ExternalProject); # externalproject_add(libdivsufsort; # DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; # URL ${CMAKE_CURRENT_SOURCE_DIR}/external/libdivsufsort.zip; # # Note: This zip comes from the fetched rapmap.zip, whose SHA we check; # # so we souldn't need to check this one separately.; # SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/libdivsufsort-master; # INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; # #UPDATE_COMMAND sh -c ""mkdir -p <SOURCE_DIR>/build""; # BINARY_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/libdivsufsort-master/build; # CMAKE_ARGS -DCMAKE_INSTALL_PREFIX:PATH=<INSTALL_D",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:19674,Integrability,message,message,19674," -p <SOURCE_DIR>/build; COMMENT ""Make build directory""; DEPENDEES download; DEPENDERS configure). ##; # After we've installed boost,; ##; set(RECONFIG_FLAGS ${RECONFIG_FLAGS} -DBOOST_WILL_RECONFIGURE=FALSE -DBOOST_RECONFIGURE=TRUE -DFETCH_BOOST=FALSE); externalproject_add_step(libboost reconfigure; COMMAND ${CMAKE_COMMAND} ${CMAKE_CURRENT_SOURCE_DIR} ${RECONFIG_FLAGS}; DEPENDEES install; ); set(FETCHED_BOOST TRUE); endif(). ##; # If we're fetching boost and we need to have dummy paths for these variables; # so that CMake won't complain; ##; if(BOOST_WILL_RECONFIGURE); message(""Setting Temporary Boost paths""); set(Boost_INCLUDE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install/include); set(Boost_INCLUDE_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/include); set(Boost_LIBRARY_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/lib); set(Boost_FOUND TRUE); endif(). message(""BOOST ROOT = ${BOOST_ROOT}""); message(""BOOST INCLUDE DIR = ${Boost_INCLUDE_DIR}""); message(""BOOST INCLUDE DIRS = ${Boost_INCLUDE_DIRS}""); message(""BOOST LIB DIR = ${Boost_LIBRARY_DIRS}""); message(""BOOST LIBRARIES = ${Boost_LIBRARIES}""). set(EXTERNAL_LIBRARY_PATH $CMAKE_CURRENT_SOURCE_DIR/lib). #find_package(libdivsufsort); #if(NOT LIBDIVSUFSORT_FOUND); # message(""Build system will build libdivsufsort""); # message(""==================================================================""); # include(ExternalProject); # externalproject_add(libdivsufsort; # DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; # URL ${CMAKE_CURRENT_SOURCE_DIR}/external/libdivsufsort.zip; # # Note: This zip comes from the fetched rapmap.zip, whose SHA we check; # # so we souldn't need to check this one separately.; # SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/libdivsufsort-master; # INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; # #UPDATE_COMMAND sh -c ""mkdir -p <SOURCE_DIR>/build""; # BINARY_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/libdivsufsort-master/build; # CMAKE_ARGS -DCMAKE_INSTALL_PREFIX:PATH=<INSTALL_D",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:19843,Integrability,message,message,19843,"LAGS}; DEPENDEES install; ); set(FETCHED_BOOST TRUE); endif(). ##; # If we're fetching boost and we need to have dummy paths for these variables; # so that CMake won't complain; ##; if(BOOST_WILL_RECONFIGURE); message(""Setting Temporary Boost paths""); set(Boost_INCLUDE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install/include); set(Boost_INCLUDE_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/include); set(Boost_LIBRARY_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/lib); set(Boost_FOUND TRUE); endif(). message(""BOOST ROOT = ${BOOST_ROOT}""); message(""BOOST INCLUDE DIR = ${Boost_INCLUDE_DIR}""); message(""BOOST INCLUDE DIRS = ${Boost_INCLUDE_DIRS}""); message(""BOOST LIB DIR = ${Boost_LIBRARY_DIRS}""); message(""BOOST LIBRARIES = ${Boost_LIBRARIES}""). set(EXTERNAL_LIBRARY_PATH $CMAKE_CURRENT_SOURCE_DIR/lib). #find_package(libdivsufsort); #if(NOT LIBDIVSUFSORT_FOUND); # message(""Build system will build libdivsufsort""); # message(""==================================================================""); # include(ExternalProject); # externalproject_add(libdivsufsort; # DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; # URL ${CMAKE_CURRENT_SOURCE_DIR}/external/libdivsufsort.zip; # # Note: This zip comes from the fetched rapmap.zip, whose SHA we check; # # so we souldn't need to check this one separately.; # SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/libdivsufsort-master; # INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; # #UPDATE_COMMAND sh -c ""mkdir -p <SOURCE_DIR>/build""; # BINARY_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/libdivsufsort-master/build; # CMAKE_ARGS -DCMAKE_INSTALL_PREFIX:PATH=<INSTALL_DIR> -DBUILD_DIVSUFSORT64=TRUE -DUSE_OPENMP=TRUE -DBUILD_SHARED_LIBS=FALSE; # ); # externalproject_add_step(libdivsufsort makedir; # COMMAND mkdir -p <SOURCE_DIR>/build; # COMMENT ""Make build directory""; # DEPENDEES download; # DEPENDERS configure); #; # set(SUFFARRAY_INCLUDE_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/include); # set(FETCHED_LIBDIVSUFSORT TR",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:19895,Integrability,message,message,19895,"LAGS}; DEPENDEES install; ); set(FETCHED_BOOST TRUE); endif(). ##; # If we're fetching boost and we need to have dummy paths for these variables; # so that CMake won't complain; ##; if(BOOST_WILL_RECONFIGURE); message(""Setting Temporary Boost paths""); set(Boost_INCLUDE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install/include); set(Boost_INCLUDE_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/include); set(Boost_LIBRARY_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/lib); set(Boost_FOUND TRUE); endif(). message(""BOOST ROOT = ${BOOST_ROOT}""); message(""BOOST INCLUDE DIR = ${Boost_INCLUDE_DIR}""); message(""BOOST INCLUDE DIRS = ${Boost_INCLUDE_DIRS}""); message(""BOOST LIB DIR = ${Boost_LIBRARY_DIRS}""); message(""BOOST LIBRARIES = ${Boost_LIBRARIES}""). set(EXTERNAL_LIBRARY_PATH $CMAKE_CURRENT_SOURCE_DIR/lib). #find_package(libdivsufsort); #if(NOT LIBDIVSUFSORT_FOUND); # message(""Build system will build libdivsufsort""); # message(""==================================================================""); # include(ExternalProject); # externalproject_add(libdivsufsort; # DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; # URL ${CMAKE_CURRENT_SOURCE_DIR}/external/libdivsufsort.zip; # # Note: This zip comes from the fetched rapmap.zip, whose SHA we check; # # so we souldn't need to check this one separately.; # SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/libdivsufsort-master; # INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; # #UPDATE_COMMAND sh -c ""mkdir -p <SOURCE_DIR>/build""; # BINARY_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/libdivsufsort-master/build; # CMAKE_ARGS -DCMAKE_INSTALL_PREFIX:PATH=<INSTALL_DIR> -DBUILD_DIVSUFSORT64=TRUE -DUSE_OPENMP=TRUE -DBUILD_SHARED_LIBS=FALSE; # ); # externalproject_add_step(libdivsufsort makedir; # COMMAND mkdir -p <SOURCE_DIR>/build; # COMMENT ""Make build directory""; # DEPENDEES download; # DEPENDERS configure); #; # set(SUFFARRAY_INCLUDE_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/include); # set(FETCHED_LIBDIVSUFSORT TR",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:20981,Integrability,message,message,20981,"ENT_SOURCE_DIR/lib). #find_package(libdivsufsort); #if(NOT LIBDIVSUFSORT_FOUND); # message(""Build system will build libdivsufsort""); # message(""==================================================================""); # include(ExternalProject); # externalproject_add(libdivsufsort; # DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; # URL ${CMAKE_CURRENT_SOURCE_DIR}/external/libdivsufsort.zip; # # Note: This zip comes from the fetched rapmap.zip, whose SHA we check; # # so we souldn't need to check this one separately.; # SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/libdivsufsort-master; # INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; # #UPDATE_COMMAND sh -c ""mkdir -p <SOURCE_DIR>/build""; # BINARY_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/libdivsufsort-master/build; # CMAKE_ARGS -DCMAKE_INSTALL_PREFIX:PATH=<INSTALL_DIR> -DBUILD_DIVSUFSORT64=TRUE -DUSE_OPENMP=TRUE -DBUILD_SHARED_LIBS=FALSE; # ); # externalproject_add_step(libdivsufsort makedir; # COMMAND mkdir -p <SOURCE_DIR>/build; # COMMENT ""Make build directory""; # DEPENDEES download; # DEPENDERS configure); #; # set(SUFFARRAY_INCLUDE_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/include); # set(FETCHED_LIBDIVSUFSORT TRUE); #else(); # message(""SUFFARRAY_LIB = ${SUFFARRAY_LIBRARY}""); # set(SUFFARRAY_LIB ${SUFFARRAY_LIBRARY}); # message(""SUFFARRAY_LIB64 = ${SUFFARRAY_LIBRARY64}""); # set(SUFFARRAY_LIB64 ${SUFFARRAY_LIBRARY64}); # set(SUFFARRAY_INCLUDE_DIRS ${SUFFARRAY_INCLUDE_DIR}); #endif(). find_package(cereal ""1.3.2""); if (NOT CEREAL_FOUND); message(""Build system will fetch and build the cereal serialization library""); message(""==================================================================""); include(ExternalProject); externalproject_add(libcereal; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://github.com/USCiLab/cereal/archive/refs/tags/v1.3.2.tar.gz -o cereal-v1.3.2.tar.gz &&; ${SHASUM} 16a7ad9b31ba5880dac55d62b5d6f243c3ebc8d46a3514149e56b5e7ea81f85f cere",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:21075,Integrability,message,message,21075,"ENT_SOURCE_DIR/lib). #find_package(libdivsufsort); #if(NOT LIBDIVSUFSORT_FOUND); # message(""Build system will build libdivsufsort""); # message(""==================================================================""); # include(ExternalProject); # externalproject_add(libdivsufsort; # DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; # URL ${CMAKE_CURRENT_SOURCE_DIR}/external/libdivsufsort.zip; # # Note: This zip comes from the fetched rapmap.zip, whose SHA we check; # # so we souldn't need to check this one separately.; # SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/libdivsufsort-master; # INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; # #UPDATE_COMMAND sh -c ""mkdir -p <SOURCE_DIR>/build""; # BINARY_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/libdivsufsort-master/build; # CMAKE_ARGS -DCMAKE_INSTALL_PREFIX:PATH=<INSTALL_DIR> -DBUILD_DIVSUFSORT64=TRUE -DUSE_OPENMP=TRUE -DBUILD_SHARED_LIBS=FALSE; # ); # externalproject_add_step(libdivsufsort makedir; # COMMAND mkdir -p <SOURCE_DIR>/build; # COMMENT ""Make build directory""; # DEPENDEES download; # DEPENDERS configure); #; # set(SUFFARRAY_INCLUDE_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/include); # set(FETCHED_LIBDIVSUFSORT TRUE); #else(); # message(""SUFFARRAY_LIB = ${SUFFARRAY_LIBRARY}""); # set(SUFFARRAY_LIB ${SUFFARRAY_LIBRARY}); # message(""SUFFARRAY_LIB64 = ${SUFFARRAY_LIBRARY64}""); # set(SUFFARRAY_LIB64 ${SUFFARRAY_LIBRARY64}); # set(SUFFARRAY_INCLUDE_DIRS ${SUFFARRAY_INCLUDE_DIR}); #endif(). find_package(cereal ""1.3.2""); if (NOT CEREAL_FOUND); message(""Build system will fetch and build the cereal serialization library""); message(""==================================================================""); include(ExternalProject); externalproject_add(libcereal; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://github.com/USCiLab/cereal/archive/refs/tags/v1.3.2.tar.gz -o cereal-v1.3.2.tar.gz &&; ${SHASUM} 16a7ad9b31ba5880dac55d62b5d6f243c3ebc8d46a3514149e56b5e7ea81f85f cere",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:21294,Integrability,message,message,21294,"h -c ""mkdir -p <SOURCE_DIR>/build""; # BINARY_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/libdivsufsort-master/build; # CMAKE_ARGS -DCMAKE_INSTALL_PREFIX:PATH=<INSTALL_DIR> -DBUILD_DIVSUFSORT64=TRUE -DUSE_OPENMP=TRUE -DBUILD_SHARED_LIBS=FALSE; # ); # externalproject_add_step(libdivsufsort makedir; # COMMAND mkdir -p <SOURCE_DIR>/build; # COMMENT ""Make build directory""; # DEPENDEES download; # DEPENDERS configure); #; # set(SUFFARRAY_INCLUDE_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/include); # set(FETCHED_LIBDIVSUFSORT TRUE); #else(); # message(""SUFFARRAY_LIB = ${SUFFARRAY_LIBRARY}""); # set(SUFFARRAY_LIB ${SUFFARRAY_LIBRARY}); # message(""SUFFARRAY_LIB64 = ${SUFFARRAY_LIBRARY64}""); # set(SUFFARRAY_LIB64 ${SUFFARRAY_LIBRARY64}); # set(SUFFARRAY_INCLUDE_DIRS ${SUFFARRAY_INCLUDE_DIR}); #endif(). find_package(cereal ""1.3.2""); if (NOT CEREAL_FOUND); message(""Build system will fetch and build the cereal serialization library""); message(""==================================================================""); include(ExternalProject); externalproject_add(libcereal; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://github.com/USCiLab/cereal/archive/refs/tags/v1.3.2.tar.gz -o cereal-v1.3.2.tar.gz &&; ${SHASUM} 16a7ad9b31ba5880dac55d62b5d6f243c3ebc8d46a3514149e56b5e7ea81f85f cereal-v1.3.2.tar.gz &&; tar -xzvf cereal-v1.3.2.tar.gz. SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/cereal-1.3.2; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; #UPDATE_COMMAND sh -c ""mkdir -p <SOURCE_DIR>/build""; BINARY_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/cereal-1.3.2/build; CONFIGURE_COMMAND """"; BUILD_COMMAND """"; INSTALL_COMMAND sh -c ""mkdir -p <INSTALL_DIR>/include && cp -r <SOURCE_DIR>/include/cereal <INSTALL_DIR>/include""; ); externalproject_add_step(libcereal makedir; COMMAND mkdir -p <SOURCE_DIR>/build; COMMENT ""Make build directory""; DEPENDEES download; DEPENDERS configure). set(FETCHED_CEREAL TRUE); endif(). ## Try and find TBB first; find_",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:21373,Integrability,message,message,21373,"h -c ""mkdir -p <SOURCE_DIR>/build""; # BINARY_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/libdivsufsort-master/build; # CMAKE_ARGS -DCMAKE_INSTALL_PREFIX:PATH=<INSTALL_DIR> -DBUILD_DIVSUFSORT64=TRUE -DUSE_OPENMP=TRUE -DBUILD_SHARED_LIBS=FALSE; # ); # externalproject_add_step(libdivsufsort makedir; # COMMAND mkdir -p <SOURCE_DIR>/build; # COMMENT ""Make build directory""; # DEPENDEES download; # DEPENDERS configure); #; # set(SUFFARRAY_INCLUDE_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/include); # set(FETCHED_LIBDIVSUFSORT TRUE); #else(); # message(""SUFFARRAY_LIB = ${SUFFARRAY_LIBRARY}""); # set(SUFFARRAY_LIB ${SUFFARRAY_LIBRARY}); # message(""SUFFARRAY_LIB64 = ${SUFFARRAY_LIBRARY64}""); # set(SUFFARRAY_LIB64 ${SUFFARRAY_LIBRARY64}); # set(SUFFARRAY_INCLUDE_DIRS ${SUFFARRAY_INCLUDE_DIR}); #endif(). find_package(cereal ""1.3.2""); if (NOT CEREAL_FOUND); message(""Build system will fetch and build the cereal serialization library""); message(""==================================================================""); include(ExternalProject); externalproject_add(libcereal; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://github.com/USCiLab/cereal/archive/refs/tags/v1.3.2.tar.gz -o cereal-v1.3.2.tar.gz &&; ${SHASUM} 16a7ad9b31ba5880dac55d62b5d6f243c3ebc8d46a3514149e56b5e7ea81f85f cereal-v1.3.2.tar.gz &&; tar -xzvf cereal-v1.3.2.tar.gz. SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/cereal-1.3.2; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; #UPDATE_COMMAND sh -c ""mkdir -p <SOURCE_DIR>/build""; BINARY_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/cereal-1.3.2/build; CONFIGURE_COMMAND """"; BUILD_COMMAND """"; INSTALL_COMMAND sh -c ""mkdir -p <INSTALL_DIR>/include && cp -r <SOURCE_DIR>/include/cereal <INSTALL_DIR>/include""; ); externalproject_add_step(libcereal makedir; COMMAND mkdir -p <SOURCE_DIR>/build; COMMENT ""Make build directory""; DEPENDEES download; DEPENDERS configure). set(FETCHED_CEREAL TRUE); endif(). ## Try and find TBB first; find_",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:22593,Integrability,message,message,22593," ${SHASUM} 16a7ad9b31ba5880dac55d62b5d6f243c3ebc8d46a3514149e56b5e7ea81f85f cereal-v1.3.2.tar.gz &&; tar -xzvf cereal-v1.3.2.tar.gz. SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/cereal-1.3.2; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; #UPDATE_COMMAND sh -c ""mkdir -p <SOURCE_DIR>/build""; BINARY_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/cereal-1.3.2/build; CONFIGURE_COMMAND """"; BUILD_COMMAND """"; INSTALL_COMMAND sh -c ""mkdir -p <INSTALL_DIR>/include && cp -r <SOURCE_DIR>/include/cereal <INSTALL_DIR>/include""; ); externalproject_add_step(libcereal makedir; COMMAND mkdir -p <SOURCE_DIR>/build; COMMENT ""Make build directory""; DEPENDEES download; DEPENDERS configure). set(FETCHED_CEREAL TRUE); endif(). ## Try and find TBB first; find_package(TBB 2021.4; HINTS ${TBB_ROOT_SEARCH}; COMPONENTS tbb tbbmalloc tbbmalloc_proxy). if (${TBB_FOUND}); if (${TBB_VERSION} VERSION_GREATER_EQUAL 2021.4); message(""FOUND SUITABLE TBB VERSION : ${TBB_VERSION}""); set(TBB_TARGET_EXISTED TRUE); else(); set(TBB_TARGET_EXISTED FALSE); endif(); else(); set(TBB_TARGET_EXISTED FALSE); endif(). ##; #; # Fetch and build Intel's Threading Building Blocks library.; #; ##; if(NOT ${TBB_TARGET_EXISTED}). set(TBB_WILL_RECONFIGURE TRUE); # Set the appropriate compiler; if(CLANG); set(TBB_COMPILER ""clang""); else(); set(TBB_COMPILER ""gcc""); endif(). message(""Build system will fetch and build Intel Threading Building Blocks""); message(""==================================================================""); # These are useful for the custom install step we'll do later; set(TBB_SOURCE_DIR ${GAT_SOURCE_DIR}/external/oneTBB-2021.5.0); set(TBB_INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install). if(""${TBB_COMPILER}"" STREQUAL ""gcc""); ## Don't know why it's a problem yet, but if we're using; ## GCC, get rid of the DO_ITT_NOTIFY flag; # set(TBB_CXXFLAGS ""${TBB_CXXFLAGS} -UDO_ITT_NOTIFY""); endif(). set(TBB_CXXFLAGS ""${TBB_CXXFLAGS} ${CXXSTDFLAG} ${SCHAR_FLAG}""). ExternalProject_Add(libtbb; DOWNLOAD_",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:23026,Integrability,message,message,23026,"E_DIR>/include/cereal <INSTALL_DIR>/include""; ); externalproject_add_step(libcereal makedir; COMMAND mkdir -p <SOURCE_DIR>/build; COMMENT ""Make build directory""; DEPENDEES download; DEPENDERS configure). set(FETCHED_CEREAL TRUE); endif(). ## Try and find TBB first; find_package(TBB 2021.4; HINTS ${TBB_ROOT_SEARCH}; COMPONENTS tbb tbbmalloc tbbmalloc_proxy). if (${TBB_FOUND}); if (${TBB_VERSION} VERSION_GREATER_EQUAL 2021.4); message(""FOUND SUITABLE TBB VERSION : ${TBB_VERSION}""); set(TBB_TARGET_EXISTED TRUE); else(); set(TBB_TARGET_EXISTED FALSE); endif(); else(); set(TBB_TARGET_EXISTED FALSE); endif(). ##; #; # Fetch and build Intel's Threading Building Blocks library.; #; ##; if(NOT ${TBB_TARGET_EXISTED}). set(TBB_WILL_RECONFIGURE TRUE); # Set the appropriate compiler; if(CLANG); set(TBB_COMPILER ""clang""); else(); set(TBB_COMPILER ""gcc""); endif(). message(""Build system will fetch and build Intel Threading Building Blocks""); message(""==================================================================""); # These are useful for the custom install step we'll do later; set(TBB_SOURCE_DIR ${GAT_SOURCE_DIR}/external/oneTBB-2021.5.0); set(TBB_INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install). if(""${TBB_COMPILER}"" STREQUAL ""gcc""); ## Don't know why it's a problem yet, but if we're using; ## GCC, get rid of the DO_ITT_NOTIFY flag; # set(TBB_CXXFLAGS ""${TBB_CXXFLAGS} -UDO_ITT_NOTIFY""); endif(). set(TBB_CXXFLAGS ""${TBB_CXXFLAGS} ${CXXSTDFLAG} ${SCHAR_FLAG}""). ExternalProject_Add(libtbb; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://github.com/oneapi-src/oneTBB/archive/refs/tags/v2021.5.0.tar.gz -o v2021.5.tar.gz &&; ${SHASUM} e5b57537c741400cf6134b428fc1689a649d7d38d9bb9c1b6d64f092ea28178a v2021.5.tar.gz &&; tar -xzvf v2021.5.tar.gz; SOURCE_DIR ${TBB_SOURCE_DIR}; INSTALL_DIR ${TBB_INSTALL_DIR}; PATCH_COMMAND ""${TBB_PATCH_STEP}""; CMAKE_ARGS -DCMAKE_CXX_FLAGS=${TBB_CXXFLAGS} -DCMAKE_INSTALL_PREFIX=<INSTALL_DIR> -DTBB_TEST=OFF -DTBB",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:23104,Integrability,message,message,23104,"E_DIR>/include/cereal <INSTALL_DIR>/include""; ); externalproject_add_step(libcereal makedir; COMMAND mkdir -p <SOURCE_DIR>/build; COMMENT ""Make build directory""; DEPENDEES download; DEPENDERS configure). set(FETCHED_CEREAL TRUE); endif(). ## Try and find TBB first; find_package(TBB 2021.4; HINTS ${TBB_ROOT_SEARCH}; COMPONENTS tbb tbbmalloc tbbmalloc_proxy). if (${TBB_FOUND}); if (${TBB_VERSION} VERSION_GREATER_EQUAL 2021.4); message(""FOUND SUITABLE TBB VERSION : ${TBB_VERSION}""); set(TBB_TARGET_EXISTED TRUE); else(); set(TBB_TARGET_EXISTED FALSE); endif(); else(); set(TBB_TARGET_EXISTED FALSE); endif(). ##; #; # Fetch and build Intel's Threading Building Blocks library.; #; ##; if(NOT ${TBB_TARGET_EXISTED}). set(TBB_WILL_RECONFIGURE TRUE); # Set the appropriate compiler; if(CLANG); set(TBB_COMPILER ""clang""); else(); set(TBB_COMPILER ""gcc""); endif(). message(""Build system will fetch and build Intel Threading Building Blocks""); message(""==================================================================""); # These are useful for the custom install step we'll do later; set(TBB_SOURCE_DIR ${GAT_SOURCE_DIR}/external/oneTBB-2021.5.0); set(TBB_INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install). if(""${TBB_COMPILER}"" STREQUAL ""gcc""); ## Don't know why it's a problem yet, but if we're using; ## GCC, get rid of the DO_ITT_NOTIFY flag; # set(TBB_CXXFLAGS ""${TBB_CXXFLAGS} -UDO_ITT_NOTIFY""); endif(). set(TBB_CXXFLAGS ""${TBB_CXXFLAGS} ${CXXSTDFLAG} ${SCHAR_FLAG}""). ExternalProject_Add(libtbb; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://github.com/oneapi-src/oneTBB/archive/refs/tags/v2021.5.0.tar.gz -o v2021.5.tar.gz &&; ${SHASUM} e5b57537c741400cf6134b428fc1689a649d7d38d9bb9c1b6d64f092ea28178a v2021.5.tar.gz &&; tar -xzvf v2021.5.tar.gz; SOURCE_DIR ${TBB_SOURCE_DIR}; INSTALL_DIR ${TBB_INSTALL_DIR}; PATCH_COMMAND ""${TBB_PATCH_STEP}""; CMAKE_ARGS -DCMAKE_CXX_FLAGS=${TBB_CXXFLAGS} -DCMAKE_INSTALL_PREFIX=<INSTALL_DIR> -DTBB_TEST=OFF -DTBB",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:25435,Integrability,message,message,25435,"btbb reconfigure; COMMAND ${CMAKE_COMMAND} ${CMAKE_CURRENT_SOURCE_DIR} ${RECONFIG_FLAGS}; DEPENDEES install ; ); set(FETCHED_TBB TRUE); set(TBB_ROOT_SEARCH ${CMAKE_SOURCE_DIR}/external/install) . if(${FETCHED_BOOST}); add_dependencies(libtbb libboost); endif(). endif() # end of fetch tbb. ##; # If we're fetching tbb, we need to have dummy paths for these variables; # so that CMake won't complain; ##; if(TBB_WILL_RECONFIGURE); set(TBB_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(TBB_INCLUDE_DIRS ${TBB_INSTALL_DIR}/include); set(TBB_INCLUDE_DIR ${TBB_INSTALL_DIR}/include); set(TBB_LIBRARY_DIRS ${TBB_INSTALL_DIR}/lib); set(TBB_LIBRARY ${TBB_INSTALL_DIR}/lib); set(TBB_LIB_DIR ${TBB_INSTALL_DIR}/lib); #set(TBB_LIBRARIES tbb tbbmalloc); set(TBB_LIBRARIES ${TBB_INSTALL_DIR}/lib/libtbb.${SHARED_LIB_EXTENSION}; 			${TBB_INSTALL_DIR}/lib/libtbbmalloc.${SHARED_LIB_EXTENSION}; ${TBB_INSTALL_DIR}/lib/libtbbmalloc_proxy.${SHARED_LIB_EXTENSION}; 	 ); message(""TBB_INCLUDE_DIRS = ${TBB_INCLUDE_DIRS}""); message(""TBB_LIBRARY_DIRS = ${TBB_LIBRARY_DIRS}""); endif(). ##; # Similar to the Boost trick above, the libtbb reconfigure should force this code; # to be run on the second configuration pass, where it should appropriately set the; # TBB_INSTALL_DIR variable.; ##; if(TBB_RECONFIGURE); unset(TBB_FOUND CACHE); unset(TBB_INSTALL_DIR CACHE); unset(CMAKE_PREFIX_PATH CACHE); unset(TBB_INCLUDE_DIRS CACHE); unset(TBB_INCLUDE_DIR CACHE); unset(TBB_LIBRARY_DIRS CACHE); unset(TBB_LIBRARY CACHE); unset(TBB_LIBRARIES CACHE); set(CMAKE_PREFIX_PATH ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(TBB_INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(TBB_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(TBB_INCLUDE_DIRS ${TBB_INSTALL_DIR}/include); set(TBB_INCLUDE_DIR ${TBB_INSTALL_DIR}/include); set(TBB_LIBRARY_DIRS ${TBB_INSTALL_DIR}/lib); set(TBB_LIBRARY ${TBB_INSTALL_DIR}/lib); set(TBB_LIB_DIR ${TBB_INSTALL_DIR}/lib); message(""TBB_INSTALL_DIR = ${TBB_INSTALL_DIR}""); ",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:25486,Integrability,message,message,25486,"btbb reconfigure; COMMAND ${CMAKE_COMMAND} ${CMAKE_CURRENT_SOURCE_DIR} ${RECONFIG_FLAGS}; DEPENDEES install ; ); set(FETCHED_TBB TRUE); set(TBB_ROOT_SEARCH ${CMAKE_SOURCE_DIR}/external/install) . if(${FETCHED_BOOST}); add_dependencies(libtbb libboost); endif(). endif() # end of fetch tbb. ##; # If we're fetching tbb, we need to have dummy paths for these variables; # so that CMake won't complain; ##; if(TBB_WILL_RECONFIGURE); set(TBB_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(TBB_INCLUDE_DIRS ${TBB_INSTALL_DIR}/include); set(TBB_INCLUDE_DIR ${TBB_INSTALL_DIR}/include); set(TBB_LIBRARY_DIRS ${TBB_INSTALL_DIR}/lib); set(TBB_LIBRARY ${TBB_INSTALL_DIR}/lib); set(TBB_LIB_DIR ${TBB_INSTALL_DIR}/lib); #set(TBB_LIBRARIES tbb tbbmalloc); set(TBB_LIBRARIES ${TBB_INSTALL_DIR}/lib/libtbb.${SHARED_LIB_EXTENSION}; 			${TBB_INSTALL_DIR}/lib/libtbbmalloc.${SHARED_LIB_EXTENSION}; ${TBB_INSTALL_DIR}/lib/libtbbmalloc_proxy.${SHARED_LIB_EXTENSION}; 	 ); message(""TBB_INCLUDE_DIRS = ${TBB_INCLUDE_DIRS}""); message(""TBB_LIBRARY_DIRS = ${TBB_LIBRARY_DIRS}""); endif(). ##; # Similar to the Boost trick above, the libtbb reconfigure should force this code; # to be run on the second configuration pass, where it should appropriately set the; # TBB_INSTALL_DIR variable.; ##; if(TBB_RECONFIGURE); unset(TBB_FOUND CACHE); unset(TBB_INSTALL_DIR CACHE); unset(CMAKE_PREFIX_PATH CACHE); unset(TBB_INCLUDE_DIRS CACHE); unset(TBB_INCLUDE_DIR CACHE); unset(TBB_LIBRARY_DIRS CACHE); unset(TBB_LIBRARY CACHE); unset(TBB_LIBRARIES CACHE); set(CMAKE_PREFIX_PATH ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(TBB_INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(TBB_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(TBB_INCLUDE_DIRS ${TBB_INSTALL_DIR}/include); set(TBB_INCLUDE_DIR ${TBB_INSTALL_DIR}/include); set(TBB_LIBRARY_DIRS ${TBB_INSTALL_DIR}/lib); set(TBB_LIBRARY ${TBB_INSTALL_DIR}/lib); set(TBB_LIB_DIR ${TBB_INSTALL_DIR}/lib); message(""TBB_INSTALL_DIR = ${TBB_INSTALL_DIR}""); ",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:26426,Integrability,message,message,26426,"ARY ${TBB_INSTALL_DIR}/lib); set(TBB_LIB_DIR ${TBB_INSTALL_DIR}/lib); #set(TBB_LIBRARIES tbb tbbmalloc); set(TBB_LIBRARIES ${TBB_INSTALL_DIR}/lib/libtbb.${SHARED_LIB_EXTENSION}; 			${TBB_INSTALL_DIR}/lib/libtbbmalloc.${SHARED_LIB_EXTENSION}; ${TBB_INSTALL_DIR}/lib/libtbbmalloc_proxy.${SHARED_LIB_EXTENSION}; 	 ); message(""TBB_INCLUDE_DIRS = ${TBB_INCLUDE_DIRS}""); message(""TBB_LIBRARY_DIRS = ${TBB_LIBRARY_DIRS}""); endif(). ##; # Similar to the Boost trick above, the libtbb reconfigure should force this code; # to be run on the second configuration pass, where it should appropriately set the; # TBB_INSTALL_DIR variable.; ##; if(TBB_RECONFIGURE); unset(TBB_FOUND CACHE); unset(TBB_INSTALL_DIR CACHE); unset(CMAKE_PREFIX_PATH CACHE); unset(TBB_INCLUDE_DIRS CACHE); unset(TBB_INCLUDE_DIR CACHE); unset(TBB_LIBRARY_DIRS CACHE); unset(TBB_LIBRARY CACHE); unset(TBB_LIBRARIES CACHE); set(CMAKE_PREFIX_PATH ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(TBB_INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(TBB_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(TBB_INCLUDE_DIRS ${TBB_INSTALL_DIR}/include); set(TBB_INCLUDE_DIR ${TBB_INSTALL_DIR}/include); set(TBB_LIBRARY_DIRS ${TBB_INSTALL_DIR}/lib); set(TBB_LIBRARY ${TBB_INSTALL_DIR}/lib); set(TBB_LIB_DIR ${TBB_INSTALL_DIR}/lib); message(""TBB_INSTALL_DIR = ${TBB_INSTALL_DIR}""); find_package(TBB 2021.4; HINTS ${TBB_ROOT_SEARCH}; COMPONENTS tbb tbbmalloc tbbmalloc_proxy); message(""[in TBB_RECONFIGURE] TBB_LIBRARIES = ${TBB_LIBRARIES}""); endif(). #message(""TBB_LIBRARIES = ${TBB_LIBRARIES}""); #message(""TBB_FOUND ${TBB_FOUND} ""); #message(""TBB_INSTALL_DIR ${TBB_INSTALL_DIR}""); #message(""TBB_INCLUDE_DIRS ${TBB_INCLUDE_DIRS}""); #message(""TBB_INCLUDE_DIR ${TBB_INCLUDE_DIR} ""); #message(""TBB_LIBRARY_DIRS ${TBB_LIBRARY_DIRS}""); #message(""TBB_LIBRARIES ${TBB_LIBRARIES} ""). find_package(libgff 2.0.0 ; HINTS ${LIB_GFF_PATH} ${GFF_ROOT}; ); if(libgff_FOUND); message(STATUS ""libgff ver. ${LIB_GFF_VERSION} found.""); message(STA",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:26569,Integrability,message,message,26569,"st trick above, the libtbb reconfigure should force this code; # to be run on the second configuration pass, where it should appropriately set the; # TBB_INSTALL_DIR variable.; ##; if(TBB_RECONFIGURE); unset(TBB_FOUND CACHE); unset(TBB_INSTALL_DIR CACHE); unset(CMAKE_PREFIX_PATH CACHE); unset(TBB_INCLUDE_DIRS CACHE); unset(TBB_INCLUDE_DIR CACHE); unset(TBB_LIBRARY_DIRS CACHE); unset(TBB_LIBRARY CACHE); unset(TBB_LIBRARIES CACHE); set(CMAKE_PREFIX_PATH ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(TBB_INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(TBB_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(TBB_INCLUDE_DIRS ${TBB_INSTALL_DIR}/include); set(TBB_INCLUDE_DIR ${TBB_INSTALL_DIR}/include); set(TBB_LIBRARY_DIRS ${TBB_INSTALL_DIR}/lib); set(TBB_LIBRARY ${TBB_INSTALL_DIR}/lib); set(TBB_LIB_DIR ${TBB_INSTALL_DIR}/lib); message(""TBB_INSTALL_DIR = ${TBB_INSTALL_DIR}""); find_package(TBB 2021.4; HINTS ${TBB_ROOT_SEARCH}; COMPONENTS tbb tbbmalloc tbbmalloc_proxy); message(""[in TBB_RECONFIGURE] TBB_LIBRARIES = ${TBB_LIBRARIES}""); endif(). #message(""TBB_LIBRARIES = ${TBB_LIBRARIES}""); #message(""TBB_FOUND ${TBB_FOUND} ""); #message(""TBB_INSTALL_DIR ${TBB_INSTALL_DIR}""); #message(""TBB_INCLUDE_DIRS ${TBB_INCLUDE_DIRS}""); #message(""TBB_INCLUDE_DIR ${TBB_INCLUDE_DIR} ""); #message(""TBB_LIBRARY_DIRS ${TBB_LIBRARY_DIRS}""); #message(""TBB_LIBRARIES ${TBB_LIBRARIES} ""). find_package(libgff 2.0.0 ; HINTS ${LIB_GFF_PATH} ${GFF_ROOT}; ); if(libgff_FOUND); message(STATUS ""libgff ver. ${LIB_GFF_VERSION} found.""); message(STATUS "" include: ${LIB_GFF_INCLUDE_DIR}""); message(STATUS "" lib : ${LIB_GFF_LIBRARY_DIR}""); endif(). if(NOT libgff_FOUND); message(""Build system will compile libgff""); message(""==================================================================""); externalproject_add(libgff; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://github.com/COMBINE-lab/libgff/archive/v2.0.0.tar.gz -o libgff.tgz &&; ${SHASUM} 7656b1945",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:26645,Integrability,message,message,26645,"_INSTALL_DIR CACHE); unset(CMAKE_PREFIX_PATH CACHE); unset(TBB_INCLUDE_DIRS CACHE); unset(TBB_INCLUDE_DIR CACHE); unset(TBB_LIBRARY_DIRS CACHE); unset(TBB_LIBRARY CACHE); unset(TBB_LIBRARIES CACHE); set(CMAKE_PREFIX_PATH ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(TBB_INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(TBB_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(TBB_INCLUDE_DIRS ${TBB_INSTALL_DIR}/include); set(TBB_INCLUDE_DIR ${TBB_INSTALL_DIR}/include); set(TBB_LIBRARY_DIRS ${TBB_INSTALL_DIR}/lib); set(TBB_LIBRARY ${TBB_INSTALL_DIR}/lib); set(TBB_LIB_DIR ${TBB_INSTALL_DIR}/lib); message(""TBB_INSTALL_DIR = ${TBB_INSTALL_DIR}""); find_package(TBB 2021.4; HINTS ${TBB_ROOT_SEARCH}; COMPONENTS tbb tbbmalloc tbbmalloc_proxy); message(""[in TBB_RECONFIGURE] TBB_LIBRARIES = ${TBB_LIBRARIES}""); endif(). #message(""TBB_LIBRARIES = ${TBB_LIBRARIES}""); #message(""TBB_FOUND ${TBB_FOUND} ""); #message(""TBB_INSTALL_DIR ${TBB_INSTALL_DIR}""); #message(""TBB_INCLUDE_DIRS ${TBB_INCLUDE_DIRS}""); #message(""TBB_INCLUDE_DIR ${TBB_INCLUDE_DIR} ""); #message(""TBB_LIBRARY_DIRS ${TBB_LIBRARY_DIRS}""); #message(""TBB_LIBRARIES ${TBB_LIBRARIES} ""). find_package(libgff 2.0.0 ; HINTS ${LIB_GFF_PATH} ${GFF_ROOT}; ); if(libgff_FOUND); message(STATUS ""libgff ver. ${LIB_GFF_VERSION} found.""); message(STATUS "" include: ${LIB_GFF_INCLUDE_DIR}""); message(STATUS "" lib : ${LIB_GFF_LIBRARY_DIR}""); endif(). if(NOT libgff_FOUND); message(""Build system will compile libgff""); message(""==================================================================""); externalproject_add(libgff; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://github.com/COMBINE-lab/libgff/archive/v2.0.0.tar.gz -o libgff.tgz &&; ${SHASUM} 7656b19459a7ca7d2fd0fcec4f2e0fd0deec1b4f39c703a114e8f4c22d82a99c libgff.tgz &&; tar -xzvf libgff.tgz; SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/libgff-2.0.0; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; BINARY_DIR ${CMAKE_CURR",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:26691,Integrability,message,message,26691,"_INSTALL_DIR CACHE); unset(CMAKE_PREFIX_PATH CACHE); unset(TBB_INCLUDE_DIRS CACHE); unset(TBB_INCLUDE_DIR CACHE); unset(TBB_LIBRARY_DIRS CACHE); unset(TBB_LIBRARY CACHE); unset(TBB_LIBRARIES CACHE); set(CMAKE_PREFIX_PATH ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(TBB_INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(TBB_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(TBB_INCLUDE_DIRS ${TBB_INSTALL_DIR}/include); set(TBB_INCLUDE_DIR ${TBB_INSTALL_DIR}/include); set(TBB_LIBRARY_DIRS ${TBB_INSTALL_DIR}/lib); set(TBB_LIBRARY ${TBB_INSTALL_DIR}/lib); set(TBB_LIB_DIR ${TBB_INSTALL_DIR}/lib); message(""TBB_INSTALL_DIR = ${TBB_INSTALL_DIR}""); find_package(TBB 2021.4; HINTS ${TBB_ROOT_SEARCH}; COMPONENTS tbb tbbmalloc tbbmalloc_proxy); message(""[in TBB_RECONFIGURE] TBB_LIBRARIES = ${TBB_LIBRARIES}""); endif(). #message(""TBB_LIBRARIES = ${TBB_LIBRARIES}""); #message(""TBB_FOUND ${TBB_FOUND} ""); #message(""TBB_INSTALL_DIR ${TBB_INSTALL_DIR}""); #message(""TBB_INCLUDE_DIRS ${TBB_INCLUDE_DIRS}""); #message(""TBB_INCLUDE_DIR ${TBB_INCLUDE_DIR} ""); #message(""TBB_LIBRARY_DIRS ${TBB_LIBRARY_DIRS}""); #message(""TBB_LIBRARIES ${TBB_LIBRARIES} ""). find_package(libgff 2.0.0 ; HINTS ${LIB_GFF_PATH} ${GFF_ROOT}; ); if(libgff_FOUND); message(STATUS ""libgff ver. ${LIB_GFF_VERSION} found.""); message(STATUS "" include: ${LIB_GFF_INCLUDE_DIR}""); message(STATUS "" lib : ${LIB_GFF_LIBRARY_DIR}""); endif(). if(NOT libgff_FOUND); message(""Build system will compile libgff""); message(""==================================================================""); externalproject_add(libgff; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://github.com/COMBINE-lab/libgff/archive/v2.0.0.tar.gz -o libgff.tgz &&; ${SHASUM} 7656b19459a7ca7d2fd0fcec4f2e0fd0deec1b4f39c703a114e8f4c22d82a99c libgff.tgz &&; tar -xzvf libgff.tgz; SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/libgff-2.0.0; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; BINARY_DIR ${CMAKE_CURR",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:26728,Integrability,message,message,26728,"_INSTALL_DIR CACHE); unset(CMAKE_PREFIX_PATH CACHE); unset(TBB_INCLUDE_DIRS CACHE); unset(TBB_INCLUDE_DIR CACHE); unset(TBB_LIBRARY_DIRS CACHE); unset(TBB_LIBRARY CACHE); unset(TBB_LIBRARIES CACHE); set(CMAKE_PREFIX_PATH ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(TBB_INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(TBB_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(TBB_INCLUDE_DIRS ${TBB_INSTALL_DIR}/include); set(TBB_INCLUDE_DIR ${TBB_INSTALL_DIR}/include); set(TBB_LIBRARY_DIRS ${TBB_INSTALL_DIR}/lib); set(TBB_LIBRARY ${TBB_INSTALL_DIR}/lib); set(TBB_LIB_DIR ${TBB_INSTALL_DIR}/lib); message(""TBB_INSTALL_DIR = ${TBB_INSTALL_DIR}""); find_package(TBB 2021.4; HINTS ${TBB_ROOT_SEARCH}; COMPONENTS tbb tbbmalloc tbbmalloc_proxy); message(""[in TBB_RECONFIGURE] TBB_LIBRARIES = ${TBB_LIBRARIES}""); endif(). #message(""TBB_LIBRARIES = ${TBB_LIBRARIES}""); #message(""TBB_FOUND ${TBB_FOUND} ""); #message(""TBB_INSTALL_DIR ${TBB_INSTALL_DIR}""); #message(""TBB_INCLUDE_DIRS ${TBB_INCLUDE_DIRS}""); #message(""TBB_INCLUDE_DIR ${TBB_INCLUDE_DIR} ""); #message(""TBB_LIBRARY_DIRS ${TBB_LIBRARY_DIRS}""); #message(""TBB_LIBRARIES ${TBB_LIBRARIES} ""). find_package(libgff 2.0.0 ; HINTS ${LIB_GFF_PATH} ${GFF_ROOT}; ); if(libgff_FOUND); message(STATUS ""libgff ver. ${LIB_GFF_VERSION} found.""); message(STATUS "" include: ${LIB_GFF_INCLUDE_DIR}""); message(STATUS "" lib : ${LIB_GFF_LIBRARY_DIR}""); endif(). if(NOT libgff_FOUND); message(""Build system will compile libgff""); message(""==================================================================""); externalproject_add(libgff; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://github.com/COMBINE-lab/libgff/archive/v2.0.0.tar.gz -o libgff.tgz &&; ${SHASUM} 7656b19459a7ca7d2fd0fcec4f2e0fd0deec1b4f39c703a114e8f4c22d82a99c libgff.tgz &&; tar -xzvf libgff.tgz; SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/libgff-2.0.0; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; BINARY_DIR ${CMAKE_CURR",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:26776,Integrability,message,message,26776,"_INSTALL_DIR CACHE); unset(CMAKE_PREFIX_PATH CACHE); unset(TBB_INCLUDE_DIRS CACHE); unset(TBB_INCLUDE_DIR CACHE); unset(TBB_LIBRARY_DIRS CACHE); unset(TBB_LIBRARY CACHE); unset(TBB_LIBRARIES CACHE); set(CMAKE_PREFIX_PATH ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(TBB_INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(TBB_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(TBB_INCLUDE_DIRS ${TBB_INSTALL_DIR}/include); set(TBB_INCLUDE_DIR ${TBB_INSTALL_DIR}/include); set(TBB_LIBRARY_DIRS ${TBB_INSTALL_DIR}/lib); set(TBB_LIBRARY ${TBB_INSTALL_DIR}/lib); set(TBB_LIB_DIR ${TBB_INSTALL_DIR}/lib); message(""TBB_INSTALL_DIR = ${TBB_INSTALL_DIR}""); find_package(TBB 2021.4; HINTS ${TBB_ROOT_SEARCH}; COMPONENTS tbb tbbmalloc tbbmalloc_proxy); message(""[in TBB_RECONFIGURE] TBB_LIBRARIES = ${TBB_LIBRARIES}""); endif(). #message(""TBB_LIBRARIES = ${TBB_LIBRARIES}""); #message(""TBB_FOUND ${TBB_FOUND} ""); #message(""TBB_INSTALL_DIR ${TBB_INSTALL_DIR}""); #message(""TBB_INCLUDE_DIRS ${TBB_INCLUDE_DIRS}""); #message(""TBB_INCLUDE_DIR ${TBB_INCLUDE_DIR} ""); #message(""TBB_LIBRARY_DIRS ${TBB_LIBRARY_DIRS}""); #message(""TBB_LIBRARIES ${TBB_LIBRARIES} ""). find_package(libgff 2.0.0 ; HINTS ${LIB_GFF_PATH} ${GFF_ROOT}; ); if(libgff_FOUND); message(STATUS ""libgff ver. ${LIB_GFF_VERSION} found.""); message(STATUS "" include: ${LIB_GFF_INCLUDE_DIR}""); message(STATUS "" lib : ${LIB_GFF_LIBRARY_DIR}""); endif(). if(NOT libgff_FOUND); message(""Build system will compile libgff""); message(""==================================================================""); externalproject_add(libgff; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://github.com/COMBINE-lab/libgff/archive/v2.0.0.tar.gz -o libgff.tgz &&; ${SHASUM} 7656b19459a7ca7d2fd0fcec4f2e0fd0deec1b4f39c703a114e8f4c22d82a99c libgff.tgz &&; tar -xzvf libgff.tgz; SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/libgff-2.0.0; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; BINARY_DIR ${CMAKE_CURR",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:26826,Integrability,message,message,26826,"_INSTALL_DIR CACHE); unset(CMAKE_PREFIX_PATH CACHE); unset(TBB_INCLUDE_DIRS CACHE); unset(TBB_INCLUDE_DIR CACHE); unset(TBB_LIBRARY_DIRS CACHE); unset(TBB_LIBRARY CACHE); unset(TBB_LIBRARIES CACHE); set(CMAKE_PREFIX_PATH ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(TBB_INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(TBB_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(TBB_INCLUDE_DIRS ${TBB_INSTALL_DIR}/include); set(TBB_INCLUDE_DIR ${TBB_INSTALL_DIR}/include); set(TBB_LIBRARY_DIRS ${TBB_INSTALL_DIR}/lib); set(TBB_LIBRARY ${TBB_INSTALL_DIR}/lib); set(TBB_LIB_DIR ${TBB_INSTALL_DIR}/lib); message(""TBB_INSTALL_DIR = ${TBB_INSTALL_DIR}""); find_package(TBB 2021.4; HINTS ${TBB_ROOT_SEARCH}; COMPONENTS tbb tbbmalloc tbbmalloc_proxy); message(""[in TBB_RECONFIGURE] TBB_LIBRARIES = ${TBB_LIBRARIES}""); endif(). #message(""TBB_LIBRARIES = ${TBB_LIBRARIES}""); #message(""TBB_FOUND ${TBB_FOUND} ""); #message(""TBB_INSTALL_DIR ${TBB_INSTALL_DIR}""); #message(""TBB_INCLUDE_DIRS ${TBB_INCLUDE_DIRS}""); #message(""TBB_INCLUDE_DIR ${TBB_INCLUDE_DIR} ""); #message(""TBB_LIBRARY_DIRS ${TBB_LIBRARY_DIRS}""); #message(""TBB_LIBRARIES ${TBB_LIBRARIES} ""). find_package(libgff 2.0.0 ; HINTS ${LIB_GFF_PATH} ${GFF_ROOT}; ); if(libgff_FOUND); message(STATUS ""libgff ver. ${LIB_GFF_VERSION} found.""); message(STATUS "" include: ${LIB_GFF_INCLUDE_DIR}""); message(STATUS "" lib : ${LIB_GFF_LIBRARY_DIR}""); endif(). if(NOT libgff_FOUND); message(""Build system will compile libgff""); message(""==================================================================""); externalproject_add(libgff; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://github.com/COMBINE-lab/libgff/archive/v2.0.0.tar.gz -o libgff.tgz &&; ${SHASUM} 7656b19459a7ca7d2fd0fcec4f2e0fd0deec1b4f39c703a114e8f4c22d82a99c libgff.tgz &&; tar -xzvf libgff.tgz; SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/libgff-2.0.0; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; BINARY_DIR ${CMAKE_CURR",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:26875,Integrability,message,message,26875,"_INSTALL_DIR CACHE); unset(CMAKE_PREFIX_PATH CACHE); unset(TBB_INCLUDE_DIRS CACHE); unset(TBB_INCLUDE_DIR CACHE); unset(TBB_LIBRARY_DIRS CACHE); unset(TBB_LIBRARY CACHE); unset(TBB_LIBRARIES CACHE); set(CMAKE_PREFIX_PATH ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(TBB_INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(TBB_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(TBB_INCLUDE_DIRS ${TBB_INSTALL_DIR}/include); set(TBB_INCLUDE_DIR ${TBB_INSTALL_DIR}/include); set(TBB_LIBRARY_DIRS ${TBB_INSTALL_DIR}/lib); set(TBB_LIBRARY ${TBB_INSTALL_DIR}/lib); set(TBB_LIB_DIR ${TBB_INSTALL_DIR}/lib); message(""TBB_INSTALL_DIR = ${TBB_INSTALL_DIR}""); find_package(TBB 2021.4; HINTS ${TBB_ROOT_SEARCH}; COMPONENTS tbb tbbmalloc tbbmalloc_proxy); message(""[in TBB_RECONFIGURE] TBB_LIBRARIES = ${TBB_LIBRARIES}""); endif(). #message(""TBB_LIBRARIES = ${TBB_LIBRARIES}""); #message(""TBB_FOUND ${TBB_FOUND} ""); #message(""TBB_INSTALL_DIR ${TBB_INSTALL_DIR}""); #message(""TBB_INCLUDE_DIRS ${TBB_INCLUDE_DIRS}""); #message(""TBB_INCLUDE_DIR ${TBB_INCLUDE_DIR} ""); #message(""TBB_LIBRARY_DIRS ${TBB_LIBRARY_DIRS}""); #message(""TBB_LIBRARIES ${TBB_LIBRARIES} ""). find_package(libgff 2.0.0 ; HINTS ${LIB_GFF_PATH} ${GFF_ROOT}; ); if(libgff_FOUND); message(STATUS ""libgff ver. ${LIB_GFF_VERSION} found.""); message(STATUS "" include: ${LIB_GFF_INCLUDE_DIR}""); message(STATUS "" lib : ${LIB_GFF_LIBRARY_DIR}""); endif(). if(NOT libgff_FOUND); message(""Build system will compile libgff""); message(""==================================================================""); externalproject_add(libgff; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://github.com/COMBINE-lab/libgff/archive/v2.0.0.tar.gz -o libgff.tgz &&; ${SHASUM} 7656b19459a7ca7d2fd0fcec4f2e0fd0deec1b4f39c703a114e8f4c22d82a99c libgff.tgz &&; tar -xzvf libgff.tgz; SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/libgff-2.0.0; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; BINARY_DIR ${CMAKE_CURR",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:26925,Integrability,message,message,26925,"_INSTALL_DIR CACHE); unset(CMAKE_PREFIX_PATH CACHE); unset(TBB_INCLUDE_DIRS CACHE); unset(TBB_INCLUDE_DIR CACHE); unset(TBB_LIBRARY_DIRS CACHE); unset(TBB_LIBRARY CACHE); unset(TBB_LIBRARIES CACHE); set(CMAKE_PREFIX_PATH ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(TBB_INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(TBB_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(TBB_INCLUDE_DIRS ${TBB_INSTALL_DIR}/include); set(TBB_INCLUDE_DIR ${TBB_INSTALL_DIR}/include); set(TBB_LIBRARY_DIRS ${TBB_INSTALL_DIR}/lib); set(TBB_LIBRARY ${TBB_INSTALL_DIR}/lib); set(TBB_LIB_DIR ${TBB_INSTALL_DIR}/lib); message(""TBB_INSTALL_DIR = ${TBB_INSTALL_DIR}""); find_package(TBB 2021.4; HINTS ${TBB_ROOT_SEARCH}; COMPONENTS tbb tbbmalloc tbbmalloc_proxy); message(""[in TBB_RECONFIGURE] TBB_LIBRARIES = ${TBB_LIBRARIES}""); endif(). #message(""TBB_LIBRARIES = ${TBB_LIBRARIES}""); #message(""TBB_FOUND ${TBB_FOUND} ""); #message(""TBB_INSTALL_DIR ${TBB_INSTALL_DIR}""); #message(""TBB_INCLUDE_DIRS ${TBB_INCLUDE_DIRS}""); #message(""TBB_INCLUDE_DIR ${TBB_INCLUDE_DIR} ""); #message(""TBB_LIBRARY_DIRS ${TBB_LIBRARY_DIRS}""); #message(""TBB_LIBRARIES ${TBB_LIBRARIES} ""). find_package(libgff 2.0.0 ; HINTS ${LIB_GFF_PATH} ${GFF_ROOT}; ); if(libgff_FOUND); message(STATUS ""libgff ver. ${LIB_GFF_VERSION} found.""); message(STATUS "" include: ${LIB_GFF_INCLUDE_DIR}""); message(STATUS "" lib : ${LIB_GFF_LIBRARY_DIR}""); endif(). if(NOT libgff_FOUND); message(""Build system will compile libgff""); message(""==================================================================""); externalproject_add(libgff; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://github.com/COMBINE-lab/libgff/archive/v2.0.0.tar.gz -o libgff.tgz &&; ${SHASUM} 7656b19459a7ca7d2fd0fcec4f2e0fd0deec1b4f39c703a114e8f4c22d82a99c libgff.tgz &&; tar -xzvf libgff.tgz; SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/libgff-2.0.0; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; BINARY_DIR ${CMAKE_CURR",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:27053,Integrability,message,message,27053,"RRENT_SOURCE_DIR}/external/install); set(TBB_INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(TBB_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(TBB_INCLUDE_DIRS ${TBB_INSTALL_DIR}/include); set(TBB_INCLUDE_DIR ${TBB_INSTALL_DIR}/include); set(TBB_LIBRARY_DIRS ${TBB_INSTALL_DIR}/lib); set(TBB_LIBRARY ${TBB_INSTALL_DIR}/lib); set(TBB_LIB_DIR ${TBB_INSTALL_DIR}/lib); message(""TBB_INSTALL_DIR = ${TBB_INSTALL_DIR}""); find_package(TBB 2021.4; HINTS ${TBB_ROOT_SEARCH}; COMPONENTS tbb tbbmalloc tbbmalloc_proxy); message(""[in TBB_RECONFIGURE] TBB_LIBRARIES = ${TBB_LIBRARIES}""); endif(). #message(""TBB_LIBRARIES = ${TBB_LIBRARIES}""); #message(""TBB_FOUND ${TBB_FOUND} ""); #message(""TBB_INSTALL_DIR ${TBB_INSTALL_DIR}""); #message(""TBB_INCLUDE_DIRS ${TBB_INCLUDE_DIRS}""); #message(""TBB_INCLUDE_DIR ${TBB_INCLUDE_DIR} ""); #message(""TBB_LIBRARY_DIRS ${TBB_LIBRARY_DIRS}""); #message(""TBB_LIBRARIES ${TBB_LIBRARIES} ""). find_package(libgff 2.0.0 ; HINTS ${LIB_GFF_PATH} ${GFF_ROOT}; ); if(libgff_FOUND); message(STATUS ""libgff ver. ${LIB_GFF_VERSION} found.""); message(STATUS "" include: ${LIB_GFF_INCLUDE_DIR}""); message(STATUS "" lib : ${LIB_GFF_LIBRARY_DIR}""); endif(). if(NOT libgff_FOUND); message(""Build system will compile libgff""); message(""==================================================================""); externalproject_add(libgff; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://github.com/COMBINE-lab/libgff/archive/v2.0.0.tar.gz -o libgff.tgz &&; ${SHASUM} 7656b19459a7ca7d2fd0fcec4f2e0fd0deec1b4f39c703a114e8f4c22d82a99c libgff.tgz &&; tar -xzvf libgff.tgz; SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/libgff-2.0.0; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; BINARY_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/libgff-2.0.0/build; CMAKE_ARGS -DCMAKE_INSTALL_PREFIX:PATH=<INSTALL_DIR> -DCMAKE_CXX_COMPILER=${CMAKE_CXX_COMPILER} -DCMAKE_C_COMPILER=${CMAKE_C_COMPILER} ; ); externalproject_add_step(libgff makedir; COMMA",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:27110,Integrability,message,message,27110,"RRENT_SOURCE_DIR}/external/install); set(TBB_INCLUDE_DIRS ${TBB_INSTALL_DIR}/include); set(TBB_INCLUDE_DIR ${TBB_INSTALL_DIR}/include); set(TBB_LIBRARY_DIRS ${TBB_INSTALL_DIR}/lib); set(TBB_LIBRARY ${TBB_INSTALL_DIR}/lib); set(TBB_LIB_DIR ${TBB_INSTALL_DIR}/lib); message(""TBB_INSTALL_DIR = ${TBB_INSTALL_DIR}""); find_package(TBB 2021.4; HINTS ${TBB_ROOT_SEARCH}; COMPONENTS tbb tbbmalloc tbbmalloc_proxy); message(""[in TBB_RECONFIGURE] TBB_LIBRARIES = ${TBB_LIBRARIES}""); endif(). #message(""TBB_LIBRARIES = ${TBB_LIBRARIES}""); #message(""TBB_FOUND ${TBB_FOUND} ""); #message(""TBB_INSTALL_DIR ${TBB_INSTALL_DIR}""); #message(""TBB_INCLUDE_DIRS ${TBB_INCLUDE_DIRS}""); #message(""TBB_INCLUDE_DIR ${TBB_INCLUDE_DIR} ""); #message(""TBB_LIBRARY_DIRS ${TBB_LIBRARY_DIRS}""); #message(""TBB_LIBRARIES ${TBB_LIBRARIES} ""). find_package(libgff 2.0.0 ; HINTS ${LIB_GFF_PATH} ${GFF_ROOT}; ); if(libgff_FOUND); message(STATUS ""libgff ver. ${LIB_GFF_VERSION} found.""); message(STATUS "" include: ${LIB_GFF_INCLUDE_DIR}""); message(STATUS "" lib : ${LIB_GFF_LIBRARY_DIR}""); endif(). if(NOT libgff_FOUND); message(""Build system will compile libgff""); message(""==================================================================""); externalproject_add(libgff; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://github.com/COMBINE-lab/libgff/archive/v2.0.0.tar.gz -o libgff.tgz &&; ${SHASUM} 7656b19459a7ca7d2fd0fcec4f2e0fd0deec1b4f39c703a114e8f4c22d82a99c libgff.tgz &&; tar -xzvf libgff.tgz; SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/libgff-2.0.0; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; BINARY_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/libgff-2.0.0/build; CMAKE_ARGS -DCMAKE_INSTALL_PREFIX:PATH=<INSTALL_DIR> -DCMAKE_CXX_COMPILER=${CMAKE_CXX_COMPILER} -DCMAKE_C_COMPILER=${CMAKE_C_COMPILER} ; ); externalproject_add_step(libgff makedir; COMMAND mkdir -p <SOURCE_DIR>/build; COMMENT ""Make build directory""; DEPENDEES download; DEPENDERS configure); set(FETCHED_GFF TRUE",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:27162,Integrability,message,message,27162,"RRENT_SOURCE_DIR}/external/install); set(TBB_INCLUDE_DIRS ${TBB_INSTALL_DIR}/include); set(TBB_INCLUDE_DIR ${TBB_INSTALL_DIR}/include); set(TBB_LIBRARY_DIRS ${TBB_INSTALL_DIR}/lib); set(TBB_LIBRARY ${TBB_INSTALL_DIR}/lib); set(TBB_LIB_DIR ${TBB_INSTALL_DIR}/lib); message(""TBB_INSTALL_DIR = ${TBB_INSTALL_DIR}""); find_package(TBB 2021.4; HINTS ${TBB_ROOT_SEARCH}; COMPONENTS tbb tbbmalloc tbbmalloc_proxy); message(""[in TBB_RECONFIGURE] TBB_LIBRARIES = ${TBB_LIBRARIES}""); endif(). #message(""TBB_LIBRARIES = ${TBB_LIBRARIES}""); #message(""TBB_FOUND ${TBB_FOUND} ""); #message(""TBB_INSTALL_DIR ${TBB_INSTALL_DIR}""); #message(""TBB_INCLUDE_DIRS ${TBB_INCLUDE_DIRS}""); #message(""TBB_INCLUDE_DIR ${TBB_INCLUDE_DIR} ""); #message(""TBB_LIBRARY_DIRS ${TBB_LIBRARY_DIRS}""); #message(""TBB_LIBRARIES ${TBB_LIBRARIES} ""). find_package(libgff 2.0.0 ; HINTS ${LIB_GFF_PATH} ${GFF_ROOT}; ); if(libgff_FOUND); message(STATUS ""libgff ver. ${LIB_GFF_VERSION} found.""); message(STATUS "" include: ${LIB_GFF_INCLUDE_DIR}""); message(STATUS "" lib : ${LIB_GFF_LIBRARY_DIR}""); endif(). if(NOT libgff_FOUND); message(""Build system will compile libgff""); message(""==================================================================""); externalproject_add(libgff; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://github.com/COMBINE-lab/libgff/archive/v2.0.0.tar.gz -o libgff.tgz &&; ${SHASUM} 7656b19459a7ca7d2fd0fcec4f2e0fd0deec1b4f39c703a114e8f4c22d82a99c libgff.tgz &&; tar -xzvf libgff.tgz; SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/libgff-2.0.0; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; BINARY_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/libgff-2.0.0/build; CMAKE_ARGS -DCMAKE_INSTALL_PREFIX:PATH=<INSTALL_DIR> -DCMAKE_CXX_COMPILER=${CMAKE_CXX_COMPILER} -DCMAKE_C_COMPILER=${CMAKE_C_COMPILER} ; ); externalproject_add_step(libgff makedir; COMMAND mkdir -p <SOURCE_DIR>/build; COMMENT ""Make build directory""; DEPENDEES download; DEPENDERS configure); set(FETCHED_GFF TRUE",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:27242,Integrability,message,message,27242,"IBRARY ${TBB_INSTALL_DIR}/lib); set(TBB_LIB_DIR ${TBB_INSTALL_DIR}/lib); message(""TBB_INSTALL_DIR = ${TBB_INSTALL_DIR}""); find_package(TBB 2021.4; HINTS ${TBB_ROOT_SEARCH}; COMPONENTS tbb tbbmalloc tbbmalloc_proxy); message(""[in TBB_RECONFIGURE] TBB_LIBRARIES = ${TBB_LIBRARIES}""); endif(). #message(""TBB_LIBRARIES = ${TBB_LIBRARIES}""); #message(""TBB_FOUND ${TBB_FOUND} ""); #message(""TBB_INSTALL_DIR ${TBB_INSTALL_DIR}""); #message(""TBB_INCLUDE_DIRS ${TBB_INCLUDE_DIRS}""); #message(""TBB_INCLUDE_DIR ${TBB_INCLUDE_DIR} ""); #message(""TBB_LIBRARY_DIRS ${TBB_LIBRARY_DIRS}""); #message(""TBB_LIBRARIES ${TBB_LIBRARIES} ""). find_package(libgff 2.0.0 ; HINTS ${LIB_GFF_PATH} ${GFF_ROOT}; ); if(libgff_FOUND); message(STATUS ""libgff ver. ${LIB_GFF_VERSION} found.""); message(STATUS "" include: ${LIB_GFF_INCLUDE_DIR}""); message(STATUS "" lib : ${LIB_GFF_LIBRARY_DIR}""); endif(). if(NOT libgff_FOUND); message(""Build system will compile libgff""); message(""==================================================================""); externalproject_add(libgff; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://github.com/COMBINE-lab/libgff/archive/v2.0.0.tar.gz -o libgff.tgz &&; ${SHASUM} 7656b19459a7ca7d2fd0fcec4f2e0fd0deec1b4f39c703a114e8f4c22d82a99c libgff.tgz &&; tar -xzvf libgff.tgz; SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/libgff-2.0.0; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; BINARY_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/libgff-2.0.0/build; CMAKE_ARGS -DCMAKE_INSTALL_PREFIX:PATH=<INSTALL_DIR> -DCMAKE_CXX_COMPILER=${CMAKE_CXX_COMPILER} -DCMAKE_C_COMPILER=${CMAKE_C_COMPILER} ; ); externalproject_add_step(libgff makedir; COMMAND mkdir -p <SOURCE_DIR>/build; COMMENT ""Make build directory""; DEPENDEES download; DEPENDERS configure); set(FETCHED_GFF TRUE); set(LIB_GFF_PATH ${CMAKE_CURRENT_SOURCE_DIR}/external/install); endif(). # Because of the way that Apple has changed SIP; # in el capitan, some headers may be in a new location; if(APPLE);",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:27287,Integrability,message,message,27287,"IBRARY ${TBB_INSTALL_DIR}/lib); set(TBB_LIB_DIR ${TBB_INSTALL_DIR}/lib); message(""TBB_INSTALL_DIR = ${TBB_INSTALL_DIR}""); find_package(TBB 2021.4; HINTS ${TBB_ROOT_SEARCH}; COMPONENTS tbb tbbmalloc tbbmalloc_proxy); message(""[in TBB_RECONFIGURE] TBB_LIBRARIES = ${TBB_LIBRARIES}""); endif(). #message(""TBB_LIBRARIES = ${TBB_LIBRARIES}""); #message(""TBB_FOUND ${TBB_FOUND} ""); #message(""TBB_INSTALL_DIR ${TBB_INSTALL_DIR}""); #message(""TBB_INCLUDE_DIRS ${TBB_INCLUDE_DIRS}""); #message(""TBB_INCLUDE_DIR ${TBB_INCLUDE_DIR} ""); #message(""TBB_LIBRARY_DIRS ${TBB_LIBRARY_DIRS}""); #message(""TBB_LIBRARIES ${TBB_LIBRARIES} ""). find_package(libgff 2.0.0 ; HINTS ${LIB_GFF_PATH} ${GFF_ROOT}; ); if(libgff_FOUND); message(STATUS ""libgff ver. ${LIB_GFF_VERSION} found.""); message(STATUS "" include: ${LIB_GFF_INCLUDE_DIR}""); message(STATUS "" lib : ${LIB_GFF_LIBRARY_DIR}""); endif(). if(NOT libgff_FOUND); message(""Build system will compile libgff""); message(""==================================================================""); externalproject_add(libgff; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://github.com/COMBINE-lab/libgff/archive/v2.0.0.tar.gz -o libgff.tgz &&; ${SHASUM} 7656b19459a7ca7d2fd0fcec4f2e0fd0deec1b4f39c703a114e8f4c22d82a99c libgff.tgz &&; tar -xzvf libgff.tgz; SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/libgff-2.0.0; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; BINARY_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/libgff-2.0.0/build; CMAKE_ARGS -DCMAKE_INSTALL_PREFIX:PATH=<INSTALL_DIR> -DCMAKE_CXX_COMPILER=${CMAKE_CXX_COMPILER} -DCMAKE_C_COMPILER=${CMAKE_C_COMPILER} ; ); externalproject_add_step(libgff makedir; COMMAND mkdir -p <SOURCE_DIR>/build; COMMENT ""Make build directory""; DEPENDEES download; DEPENDERS configure); set(FETCHED_GFF TRUE); set(LIB_GFF_PATH ${CMAKE_CURRENT_SOURCE_DIR}/external/install); endif(). # Because of the way that Apple has changed SIP; # in el capitan, some headers may be in a new location; if(APPLE);",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:28657,Integrability,message,message,28657,"al/install; BINARY_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/libgff-2.0.0/build; CMAKE_ARGS -DCMAKE_INSTALL_PREFIX:PATH=<INSTALL_DIR> -DCMAKE_CXX_COMPILER=${CMAKE_CXX_COMPILER} -DCMAKE_C_COMPILER=${CMAKE_C_COMPILER} ; ); externalproject_add_step(libgff makedir; COMMAND mkdir -p <SOURCE_DIR>/build; COMMENT ""Make build directory""; DEPENDEES download; DEPENDERS configure); set(FETCHED_GFF TRUE); set(LIB_GFF_PATH ${CMAKE_CURRENT_SOURCE_DIR}/external/install); endif(). # Because of the way that Apple has changed SIP; # in el capitan, some headers may be in a new location; if(APPLE); set(STADEN_INC ""-I/usr/local/include""); set(STADEN_LIB ""-L/usr/local/lib""); endif(). if(CONDA_BUILD); set(LZFLAG ""-lz""); else(); set(LZFLAG """"); endif(). find_package(CURL). if (FETCH_STADEN); set(LIBSTADEN_FOUND FALSE); else (); find_package(libstadenio 1.14.15); endif(). if (NOT LIBSTADENIO_FOUND); message(""Build system will compile Staden IOLib""); message(""==================================================================""); externalproject_add(libstadenio; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://github.com/jkbonfield/io_lib/releases/download/io_lib-1-14-15/io_lib-1.14.15.tar.gz -o staden-io_lib-v1.14.15.tar.gz &&; ${SHASUM} 20814c4365e1e2fe6630fb11d0df370dec4c5688af3871de7f1cb0129671401e staden-io_lib-v1.14.15.tar.gz &&; mkdir -p staden-io_lib-1.14.15 &&; tar -xzf staden-io_lib-v1.14.15.tar.gz --strip-components=1 -C staden-io_lib-1.14.15 &&; rm -fr staden-io_lib &&; mv -f staden-io_lib-1.14.15 staden-io_lib; SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/staden-io_lib; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; CONFIGURE_COMMAND ./configure --enable-shared=no --without-libcurl --prefix=<INSTALL_DIR> LDFLAGS=${LIBSTADEN_LDFLAGS} CFLAGS=${LIBSTADEN_CFLAGS} CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER}; BUILD_COMMAND make ${QUIET_MAKE} CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER} CFLAGS+=${STADEN_INC} CFLAGS+=${STADEN_LIB}",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:28708,Integrability,message,message,28708,"al/install; BINARY_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/libgff-2.0.0/build; CMAKE_ARGS -DCMAKE_INSTALL_PREFIX:PATH=<INSTALL_DIR> -DCMAKE_CXX_COMPILER=${CMAKE_CXX_COMPILER} -DCMAKE_C_COMPILER=${CMAKE_C_COMPILER} ; ); externalproject_add_step(libgff makedir; COMMAND mkdir -p <SOURCE_DIR>/build; COMMENT ""Make build directory""; DEPENDEES download; DEPENDERS configure); set(FETCHED_GFF TRUE); set(LIB_GFF_PATH ${CMAKE_CURRENT_SOURCE_DIR}/external/install); endif(). # Because of the way that Apple has changed SIP; # in el capitan, some headers may be in a new location; if(APPLE); set(STADEN_INC ""-I/usr/local/include""); set(STADEN_LIB ""-L/usr/local/lib""); endif(). if(CONDA_BUILD); set(LZFLAG ""-lz""); else(); set(LZFLAG """"); endif(). find_package(CURL). if (FETCH_STADEN); set(LIBSTADEN_FOUND FALSE); else (); find_package(libstadenio 1.14.15); endif(). if (NOT LIBSTADENIO_FOUND); message(""Build system will compile Staden IOLib""); message(""==================================================================""); externalproject_add(libstadenio; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://github.com/jkbonfield/io_lib/releases/download/io_lib-1-14-15/io_lib-1.14.15.tar.gz -o staden-io_lib-v1.14.15.tar.gz &&; ${SHASUM} 20814c4365e1e2fe6630fb11d0df370dec4c5688af3871de7f1cb0129671401e staden-io_lib-v1.14.15.tar.gz &&; mkdir -p staden-io_lib-1.14.15 &&; tar -xzf staden-io_lib-v1.14.15.tar.gz --strip-components=1 -C staden-io_lib-1.14.15 &&; rm -fr staden-io_lib &&; mv -f staden-io_lib-1.14.15 staden-io_lib; SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/staden-io_lib; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; CONFIGURE_COMMAND ./configure --enable-shared=no --without-libcurl --prefix=<INSTALL_DIR> LDFLAGS=${LIBSTADEN_LDFLAGS} CFLAGS=${LIBSTADEN_CFLAGS} CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER}; BUILD_COMMAND make ${QUIET_MAKE} CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER} CFLAGS+=${STADEN_INC} CFLAGS+=${STADEN_LIB}",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:30518,Integrability,message,message,30518,"CMAKE_CXX_COMPILER}; BUILD_COMMAND make ${QUIET_MAKE} CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER} CFLAGS+=${STADEN_INC} CFLAGS+=${STADEN_LIB} LDFLAGS+=${EXTRA_CMAKE_LIBRARY_FLAGS} CFLAGS+=${EXTRA_CMAKE_INCLUDE_FLAGS} CFLAGS+=${LZFLAG} CFLAGS+=${SCHAR_FLAG}. BUILD_IN_SOURCE 1; INSTALL_COMMAND make install; ); if(NOT LIBLZMA_FOUND); 	ExternalProject_Add_StepDependencies(libstadenio build liblzma); endif(). set(FETCHED_STADEN TRUE); set(STADEN_LIBRARIES ""${GAT_SOURCE_DIR}/external/install/lib/libstaden-read.a;${GAT_SOURCE_DIR}/external/install/lib/libhtscodecs.a""); endif(). if (ASAN_BUILD); set(FAST_MALLOC_LIB """"); set(HAVE_FAST_MALLOC TRUE); else(); set(FAST_MALLOC_LIB """"); set(HAVE_FAST_MALLOC FALSE). # See if we have Jemalloc; find_package(Jemalloc); if(Jemalloc_FOUND); ##; # Don't be so stringent about the version yet; ##; #if (NOT (${JEMALLOC_VERSION} VERSION_LESS 5.2.1)); message(""Found Jemalloc library --- using this memory allocator""); set(FAST_MALLOC_LIB ${JEMALLOC_LIBRARIES}); set(HAVE_FAST_MALLOC TRUE); #else(); # message(""Fond Jemalloc version ${JEMALLOC_VERSION}, but require >= 5.2.1. Downloading newer version""); #endif(); endif(); endif(). if(CONDA_BUILD); set(JEMALLOC_FLAGS ""CC=${CMAKE_C_COMPILER} CFLAGS=\\\""-fPIC ${SCHAR_FLAG}\\\"" CPPFLAGS=\\\""-fPIC ${SCHAR_FLAG}\\\""""); else(); set(JEMALLOC_FLAGS ""CC=${CMAKE_C_COMPILER} CFLAGS=${SCHAR_FLAG} CPPFLAGS=${SCHAR_FLAG}""); endif(). if(NOT HAVE_FAST_MALLOC); message(""Build system will fetch and use JEMalloc""); message(""==================================================================""); externalproject_add(libjemalloc; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://github.com/jemalloc/jemalloc/archive/5.2.1.tar.gz -o jemalloc-5.2.1.tar.gz &&; ${SHASUM} ed51b0b37098af4ca6ed31c22324635263f8ad6471889e0592a9c0dba9136aea jemalloc-5.2.1.tar.gz &&; tar -xzf jemalloc-5.2.1.tar.gz. SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/jemalloc-5.2.1; BUILD_IN_SOURCE TRUE; INSTALL_",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:30668,Integrability,message,message,30668,"CMAKE_CXX_COMPILER}; BUILD_COMMAND make ${QUIET_MAKE} CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER} CFLAGS+=${STADEN_INC} CFLAGS+=${STADEN_LIB} LDFLAGS+=${EXTRA_CMAKE_LIBRARY_FLAGS} CFLAGS+=${EXTRA_CMAKE_INCLUDE_FLAGS} CFLAGS+=${LZFLAG} CFLAGS+=${SCHAR_FLAG}. BUILD_IN_SOURCE 1; INSTALL_COMMAND make install; ); if(NOT LIBLZMA_FOUND); 	ExternalProject_Add_StepDependencies(libstadenio build liblzma); endif(). set(FETCHED_STADEN TRUE); set(STADEN_LIBRARIES ""${GAT_SOURCE_DIR}/external/install/lib/libstaden-read.a;${GAT_SOURCE_DIR}/external/install/lib/libhtscodecs.a""); endif(). if (ASAN_BUILD); set(FAST_MALLOC_LIB """"); set(HAVE_FAST_MALLOC TRUE); else(); set(FAST_MALLOC_LIB """"); set(HAVE_FAST_MALLOC FALSE). # See if we have Jemalloc; find_package(Jemalloc); if(Jemalloc_FOUND); ##; # Don't be so stringent about the version yet; ##; #if (NOT (${JEMALLOC_VERSION} VERSION_LESS 5.2.1)); message(""Found Jemalloc library --- using this memory allocator""); set(FAST_MALLOC_LIB ${JEMALLOC_LIBRARIES}); set(HAVE_FAST_MALLOC TRUE); #else(); # message(""Fond Jemalloc version ${JEMALLOC_VERSION}, but require >= 5.2.1. Downloading newer version""); #endif(); endif(); endif(). if(CONDA_BUILD); set(JEMALLOC_FLAGS ""CC=${CMAKE_C_COMPILER} CFLAGS=\\\""-fPIC ${SCHAR_FLAG}\\\"" CPPFLAGS=\\\""-fPIC ${SCHAR_FLAG}\\\""""); else(); set(JEMALLOC_FLAGS ""CC=${CMAKE_C_COMPILER} CFLAGS=${SCHAR_FLAG} CPPFLAGS=${SCHAR_FLAG}""); endif(). if(NOT HAVE_FAST_MALLOC); message(""Build system will fetch and use JEMalloc""); message(""==================================================================""); externalproject_add(libjemalloc; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://github.com/jemalloc/jemalloc/archive/5.2.1.tar.gz -o jemalloc-5.2.1.tar.gz &&; ${SHASUM} ed51b0b37098af4ca6ed31c22324635263f8ad6471889e0592a9c0dba9136aea jemalloc-5.2.1.tar.gz &&; tar -xzf jemalloc-5.2.1.tar.gz. SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/jemalloc-5.2.1; BUILD_IN_SOURCE TRUE; INSTALL_",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:31067,Integrability,message,message,31067,"bhtscodecs.a""); endif(). if (ASAN_BUILD); set(FAST_MALLOC_LIB """"); set(HAVE_FAST_MALLOC TRUE); else(); set(FAST_MALLOC_LIB """"); set(HAVE_FAST_MALLOC FALSE). # See if we have Jemalloc; find_package(Jemalloc); if(Jemalloc_FOUND); ##; # Don't be so stringent about the version yet; ##; #if (NOT (${JEMALLOC_VERSION} VERSION_LESS 5.2.1)); message(""Found Jemalloc library --- using this memory allocator""); set(FAST_MALLOC_LIB ${JEMALLOC_LIBRARIES}); set(HAVE_FAST_MALLOC TRUE); #else(); # message(""Fond Jemalloc version ${JEMALLOC_VERSION}, but require >= 5.2.1. Downloading newer version""); #endif(); endif(); endif(). if(CONDA_BUILD); set(JEMALLOC_FLAGS ""CC=${CMAKE_C_COMPILER} CFLAGS=\\\""-fPIC ${SCHAR_FLAG}\\\"" CPPFLAGS=\\\""-fPIC ${SCHAR_FLAG}\\\""""); else(); set(JEMALLOC_FLAGS ""CC=${CMAKE_C_COMPILER} CFLAGS=${SCHAR_FLAG} CPPFLAGS=${SCHAR_FLAG}""); endif(). if(NOT HAVE_FAST_MALLOC); message(""Build system will fetch and use JEMalloc""); message(""==================================================================""); externalproject_add(libjemalloc; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://github.com/jemalloc/jemalloc/archive/5.2.1.tar.gz -o jemalloc-5.2.1.tar.gz &&; ${SHASUM} ed51b0b37098af4ca6ed31c22324635263f8ad6471889e0592a9c0dba9136aea jemalloc-5.2.1.tar.gz &&; tar -xzf jemalloc-5.2.1.tar.gz. SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/jemalloc-5.2.1; BUILD_IN_SOURCE TRUE; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; CONFIGURE_COMMAND sh -c ""${JEMALLOC_FLAGS} ./autogen.sh --disable-debug ${MALLOC_STATIC_BUILD_FLAG} --prefix=<INSTALL_DIR>""; #CONFIGURE_COMMAND sh -c ""${JEMALLOC_FLAGS} ./autogen.sh ${MALLOC_STATIC_BUILD_FLAG} --prefix=<INSTALL_DIR>""; INSTALL_COMMAND cp -r lib <INSTALL_DIR>/ && cp -r include <INSTALL_DIR>/; ). set(FAST_MALLOC_LIB ${CMAKE_CURRENT_SOURCE_DIR}/external/install/lib/libjemalloc.a); set(HAVE_FAST_MALLOC TRUE); set(FETCHED_JEMALLOC TRUE); if(FETCHED_LIBBZ2); add_dependencies(libjemalloc libbz2",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:31120,Integrability,message,message,31120,"bhtscodecs.a""); endif(). if (ASAN_BUILD); set(FAST_MALLOC_LIB """"); set(HAVE_FAST_MALLOC TRUE); else(); set(FAST_MALLOC_LIB """"); set(HAVE_FAST_MALLOC FALSE). # See if we have Jemalloc; find_package(Jemalloc); if(Jemalloc_FOUND); ##; # Don't be so stringent about the version yet; ##; #if (NOT (${JEMALLOC_VERSION} VERSION_LESS 5.2.1)); message(""Found Jemalloc library --- using this memory allocator""); set(FAST_MALLOC_LIB ${JEMALLOC_LIBRARIES}); set(HAVE_FAST_MALLOC TRUE); #else(); # message(""Fond Jemalloc version ${JEMALLOC_VERSION}, but require >= 5.2.1. Downloading newer version""); #endif(); endif(); endif(). if(CONDA_BUILD); set(JEMALLOC_FLAGS ""CC=${CMAKE_C_COMPILER} CFLAGS=\\\""-fPIC ${SCHAR_FLAG}\\\"" CPPFLAGS=\\\""-fPIC ${SCHAR_FLAG}\\\""""); else(); set(JEMALLOC_FLAGS ""CC=${CMAKE_C_COMPILER} CFLAGS=${SCHAR_FLAG} CPPFLAGS=${SCHAR_FLAG}""); endif(). if(NOT HAVE_FAST_MALLOC); message(""Build system will fetch and use JEMalloc""); message(""==================================================================""); externalproject_add(libjemalloc; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://github.com/jemalloc/jemalloc/archive/5.2.1.tar.gz -o jemalloc-5.2.1.tar.gz &&; ${SHASUM} ed51b0b37098af4ca6ed31c22324635263f8ad6471889e0592a9c0dba9136aea jemalloc-5.2.1.tar.gz &&; tar -xzf jemalloc-5.2.1.tar.gz. SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/jemalloc-5.2.1; BUILD_IN_SOURCE TRUE; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; CONFIGURE_COMMAND sh -c ""${JEMALLOC_FLAGS} ./autogen.sh --disable-debug ${MALLOC_STATIC_BUILD_FLAG} --prefix=<INSTALL_DIR>""; #CONFIGURE_COMMAND sh -c ""${JEMALLOC_FLAGS} ./autogen.sh ${MALLOC_STATIC_BUILD_FLAG} --prefix=<INSTALL_DIR>""; INSTALL_COMMAND cp -r lib <INSTALL_DIR>/ && cp -r include <INSTALL_DIR>/; ). set(FAST_MALLOC_LIB ${CMAKE_CURRENT_SOURCE_DIR}/external/install/lib/libjemalloc.a); set(HAVE_FAST_MALLOC TRUE); set(FETCHED_JEMALLOC TRUE); if(FETCHED_LIBBZ2); add_dependencies(libjemalloc libbz2",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:32306,Integrability,depend,dependencies,32306,"MAND curl -k -L https://github.com/jemalloc/jemalloc/archive/5.2.1.tar.gz -o jemalloc-5.2.1.tar.gz &&; ${SHASUM} ed51b0b37098af4ca6ed31c22324635263f8ad6471889e0592a9c0dba9136aea jemalloc-5.2.1.tar.gz &&; tar -xzf jemalloc-5.2.1.tar.gz. SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/jemalloc-5.2.1; BUILD_IN_SOURCE TRUE; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; CONFIGURE_COMMAND sh -c ""${JEMALLOC_FLAGS} ./autogen.sh --disable-debug ${MALLOC_STATIC_BUILD_FLAG} --prefix=<INSTALL_DIR>""; #CONFIGURE_COMMAND sh -c ""${JEMALLOC_FLAGS} ./autogen.sh ${MALLOC_STATIC_BUILD_FLAG} --prefix=<INSTALL_DIR>""; INSTALL_COMMAND cp -r lib <INSTALL_DIR>/ && cp -r include <INSTALL_DIR>/; ). set(FAST_MALLOC_LIB ${CMAKE_CURRENT_SOURCE_DIR}/external/install/lib/libjemalloc.a); set(HAVE_FAST_MALLOC TRUE); set(FETCHED_JEMALLOC TRUE); if(FETCHED_LIBBZ2); add_dependencies(libjemalloc libbz2); endif(). if(FETCHED_LIBLZMA); add_dependencies(libjemalloc liblzma); endif(); endif(). ###; #; # Done building external dependencies.; #; ###. set(CPACK_SOURCE_IGNORE_FILES; ""/src/PCA.cpp""; ""/src/PCAUtils.cpp""; ""/build/""; ""/scripts/AggregateToGeneLevel.py""; ""/scripts/ExpressionTools.py""; ""/scripts/GenerateExpressionFiles.sh""; ""/scripts/ParseSoftFile.py""; ""/scripts/PlotCorrelation.py""; ""/scripts/junk""; ""/scripts/sfstrace.log""; ""/scripts/SFPipeline.py""; ""/bin/""; ""/lib/""; ""/sample_data/""; ""PublishREADMEToWebsite.sh""; ""/external/""; ""/src/obsolete/""; ""/include/obsolete/""; ""WebsiteHeader.txt""; ""/experimental_configs/""; "".git/""). message(""CPACK_SOURCE_IGNORE_FILES = ${CPACK_SOURCE_IGNORE_FILES}""). # we will use this property later; define_property(TARGET PROPERTY COMPACT_VECTOR_DIR INHERITED ; BRIEF_DOCS ""the path to the directory containing the compact_vector include tree""; FULL_DOCS ""the path to the directory containing the compact_vector include tree""). # Recurse into pufferfish source directory ; # and build the library ; set(BUILD_PUFF_FOR_SALMON TRUE); add_subdirectory(external/pufferfish). # m",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:32817,Integrability,message,message,32817,"gen.sh ${MALLOC_STATIC_BUILD_FLAG} --prefix=<INSTALL_DIR>""; INSTALL_COMMAND cp -r lib <INSTALL_DIR>/ && cp -r include <INSTALL_DIR>/; ). set(FAST_MALLOC_LIB ${CMAKE_CURRENT_SOURCE_DIR}/external/install/lib/libjemalloc.a); set(HAVE_FAST_MALLOC TRUE); set(FETCHED_JEMALLOC TRUE); if(FETCHED_LIBBZ2); add_dependencies(libjemalloc libbz2); endif(). if(FETCHED_LIBLZMA); add_dependencies(libjemalloc liblzma); endif(); endif(). ###; #; # Done building external dependencies.; #; ###. set(CPACK_SOURCE_IGNORE_FILES; ""/src/PCA.cpp""; ""/src/PCAUtils.cpp""; ""/build/""; ""/scripts/AggregateToGeneLevel.py""; ""/scripts/ExpressionTools.py""; ""/scripts/GenerateExpressionFiles.sh""; ""/scripts/ParseSoftFile.py""; ""/scripts/PlotCorrelation.py""; ""/scripts/junk""; ""/scripts/sfstrace.log""; ""/scripts/SFPipeline.py""; ""/bin/""; ""/lib/""; ""/sample_data/""; ""PublishREADMEToWebsite.sh""; ""/external/""; ""/src/obsolete/""; ""/include/obsolete/""; ""WebsiteHeader.txt""; ""/experimental_configs/""; "".git/""). message(""CPACK_SOURCE_IGNORE_FILES = ${CPACK_SOURCE_IGNORE_FILES}""). # we will use this property later; define_property(TARGET PROPERTY COMPACT_VECTOR_DIR INHERITED ; BRIEF_DOCS ""the path to the directory containing the compact_vector include tree""; FULL_DOCS ""the path to the directory containing the compact_vector include tree""). # Recurse into pufferfish source directory ; # and build the library ; set(BUILD_PUFF_FOR_SALMON TRUE); add_subdirectory(external/pufferfish). # make sure we know the path to compact_vector; get_property(COMPACT_VECTOR_INCLUDE_PATH TARGET graphdump PROPERTY COMPACT_VECTOR_DIR); message(""fetched path for compact_vector as [${COMPACT_VECTOR_INCLUDE_PATH}]""). # and then the main salmon source directory; add_subdirectory(src). #add_dependencies(salmon RapMap); # build a CPack driven installer package; include(CPack). set(ARCHIVE_NAME ${CMAKE_PROJECT_NAME}-${PROJECT_VERSION}); add_custom_target(dist; COMMAND git archive --prefix=${ARCHIVE_NAME}/ HEAD; | gzip > ${CMAKE_BINARY_DIR}/${ARCHIVE_NAME}.t",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:33429,Integrability,message,message,33429,"TALL_DIR>""; INSTALL_COMMAND cp -r lib <INSTALL_DIR>/ && cp -r include <INSTALL_DIR>/; ). set(FAST_MALLOC_LIB ${CMAKE_CURRENT_SOURCE_DIR}/external/install/lib/libjemalloc.a); set(HAVE_FAST_MALLOC TRUE); set(FETCHED_JEMALLOC TRUE); if(FETCHED_LIBBZ2); add_dependencies(libjemalloc libbz2); endif(). if(FETCHED_LIBLZMA); add_dependencies(libjemalloc liblzma); endif(); endif(). ###; #; # Done building external dependencies.; #; ###. set(CPACK_SOURCE_IGNORE_FILES; ""/src/PCA.cpp""; ""/src/PCAUtils.cpp""; ""/build/""; ""/scripts/AggregateToGeneLevel.py""; ""/scripts/ExpressionTools.py""; ""/scripts/GenerateExpressionFiles.sh""; ""/scripts/ParseSoftFile.py""; ""/scripts/PlotCorrelation.py""; ""/scripts/junk""; ""/scripts/sfstrace.log""; ""/scripts/SFPipeline.py""; ""/bin/""; ""/lib/""; ""/sample_data/""; ""PublishREADMEToWebsite.sh""; ""/external/""; ""/src/obsolete/""; ""/include/obsolete/""; ""WebsiteHeader.txt""; ""/experimental_configs/""; "".git/""). message(""CPACK_SOURCE_IGNORE_FILES = ${CPACK_SOURCE_IGNORE_FILES}""). # we will use this property later; define_property(TARGET PROPERTY COMPACT_VECTOR_DIR INHERITED ; BRIEF_DOCS ""the path to the directory containing the compact_vector include tree""; FULL_DOCS ""the path to the directory containing the compact_vector include tree""). # Recurse into pufferfish source directory ; # and build the library ; set(BUILD_PUFF_FOR_SALMON TRUE); add_subdirectory(external/pufferfish). # make sure we know the path to compact_vector; get_property(COMPACT_VECTOR_INCLUDE_PATH TARGET graphdump PROPERTY COMPACT_VECTOR_DIR); message(""fetched path for compact_vector as [${COMPACT_VECTOR_INCLUDE_PATH}]""). # and then the main salmon source directory; add_subdirectory(src). #add_dependencies(salmon RapMap); # build a CPack driven installer package; include(CPack). set(ARCHIVE_NAME ${CMAKE_PROJECT_NAME}-${PROJECT_VERSION}); add_custom_target(dist; COMMAND git archive --prefix=${ARCHIVE_NAME}/ HEAD; | gzip > ${CMAKE_BINARY_DIR}/${ARCHIVE_NAME}.tar.gz; WORKING_DIRECTORY ${CMAKE_SOURCE_DIR}); ",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:3040,Modifiability,variab,variable,3040,"KE_PROJECT_NAME}-${CPACK_PACKAGE_VERSION_MAJOR}.${CPACK_PACKAGE_VERSION_MINOR}.${CPACK_PACKAGE_VERSION_PATCH}-Source""). set(CMAKE_MODULE_PATH ${CMAKE_MODULE_PATH} ""${CMAKE_SOURCE_DIR}/cmake/Modules/""). # Set a default build type if none was specified; set(default_build_type ""Release""). if(NOT CMAKE_BUILD_TYPE AND NOT CMAKE_CONFIGURATION_TYPES); message(STATUS ""Setting build type to '${default_build_type}' as none was specified.""); set(CMAKE_BUILD_TYPE ""${default_build_type}"" CACHE; STRING ""Choose the type of build."" FORCE); # Set the possible values of build type for cmake-gui; #set_property(CACHE CMAKE_BUILD_TYPE PROPERTY STRINGS; # ""Debug"" ""Release""); endif(). message(STATUS ""CMAKE_BUILD_TYPE = ${CMAKE_BUILD_TYPE}""). ## Set the standard required compile flags; set(REMOVE_WARNING_FLAGS ""-Wno-unused-function;-Wno-unused-local-typedefs""); set(TGT_COMPILE_FLAGS ""${SCHAR_FLAG};-ftree-vectorize;-funroll-loops;-fPIC;-fomit-frame-pointer;-O3;-DNDEBUG;-DSTX_NO_STD_STRING_VIEW;-D__STDC_FORMAT_MACROS""); set(TGT_WARN_FLAGS ""-Wall;-Wno-unknown-pragmas;-Wno-reorder;-Wno-unused-variable;-Wreturn-type;-Werror=return-type;${REMOVE_WARNING_FLAGS}""); #set(CMAKE_C_FLAGS ""${CMAKE_C_FLAGS} -fsanitize=address""); #set(CMAKE_CXX_FLAGS ""${CMAKE_CXX_FLAGS} -fsanitize=address""). ###; # Sanitizers BEGIN; ###; if (ASAN_BUILD); list(APPEND TGT_COMPILE_FLAGS ""-fsanitize=address""); #list(APPEND TGT_COMPILE_FLAGS ""-fsanitize=undefined""); #set(CMAKE_LINK_FLAGS ""-fsanitize=address""); #list(APPEND CMAKE_LINK_FLAGS ""-fsanitize=undefined""); set(ASAN_LIB ""asan""); else(); set(ASAN_LIB """"); endif(); ###; # Sanitizers END; ###. if(APPLE); set(WARNING_IGNORE_FLAGS ""-Wno-deprecated-register""); list(APPEND TGT_WARN_FLAGS -Wno-deprecated-register); else(); set(WARNING_IGNORE_FLAGS """"); endif(). ## Prefer static to dynamic libraries; if(NOT USE_SHARED_LIBS); set(CMAKE_FIND_LIBRARY_SUFFIXES .a ${CMAKE_FIND_LIBRARY_SUFFIXES}); set(MALLOC_STATIC_BUILD_FLAG ""--enable-static""); endif(). include(CheckIPOSupported). se",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:10924,Modifiability,config,configuration,10924,"VALUE FETCH_PF_SCRIPT_RET); message(STATUS ""fetch PUFFERFISH exit code ${FETCH_PF_SCRIPT_RET}""); if(NOT (FETCH_PF_SCRIPT_RET EQUAL 0)); message(FATAL_ERROR ""Could not fetch pufferfish source [fetchPufferfish.sh returned exit code ${FETCH_PF_SCRIPT_RET}].""); endif(); set(FETCHED_PUFFERFISH TRUE CACHE BOOL ""Has pufferfish been fetched?"" FORCE); endif(). ##; # Super-secret override; ##; if( DEFINED CUSTOM_BOOST_PATH ); set(CMAKE_INCLUDE_PATH ${CUSTOM_BOOST_PATH} ${CMAKE_INCLUDE_PATH}); set(CMAKE_LIBRARY_PATH ${CUSTOM_BOOST_PATH}/lib ${CMAKE_LIBRARY_PATH}); endif(). ##; # We want static, multithreaded boost libraries; ##; if(CONDA_BUILD); set(Boost_USE_STATIC_LIBS OFF); elseif(USE_SHARED_LIBS) # CI failed when using an OR statement above...; set(Boost_USE_STATIC_LIBS OFF); else(); set(Boost_USE_STATIC_LIBS ON); endif(). set(Boost_USE_MULTITHREADED ON); #set(Boost_USE_STATIC_RUNTIME OFF); set(Boost_USE_DEBUG_RUNTIME OFF). find_package(ZLIB); if(NOT ZLIB_FOUND); message(FATAL_ERROR ""zlib must be installed before configuration & building can proceed""); endif(). if(""${CMAKE_INCLUDE_PATH}"" STREQUAL """"); set(EXTRA_CMAKE_INCLUDE_FLAGS """"); else(); set(EXTRA_CMAKE_INCLUDE_FLAGS ""-I${CMAKE_INCLUDE_PATH}""); endif(). if(""${CMAKE_LIBRARY_PATH}"" STREQUAL """"); set(EXTRA_CMAKE_LIBRARY_FLAGS """"); else(); set(EXTRA_CMAKE_LIBRARY_FLAGS ""-L${CMAKE_LIBRARY_PATH}""); endif(). find_package(Iconv REQUIRED); if(NOT Iconv_IS_BUILT_IN); set(ICONV_LIB Iconv::Iconv); endif(). find_package(LibLZMA); if(NOT LIBLZMA_FOUND); message(""Will attempt to fetch and build liblzma""); message(""=======================================""); externalproject_add(liblzma; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; ##; DOWNLOAD_COMMAND curl -k -L http://tukaani.org/xz/xz-5.2.2.tar.gz -o xz-5.2.2.tar.gz &&; ${SHASUM} 73df4d5d34f0468bd57d09f2d8af363e95ed6cc3a4a86129d2f2c366259902a2 xz-5.2.2.tar.gz &&; tar -xzvf xz-5.2.2.tar.gz; #URL http://tukaani.org/xz/xz-5.2.2.tar.gz; #URL_HASH SHA1=14663612422ab61386673be78fbb",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:12122,Modifiability,config,configure,12122,"ATH}""); endif(). find_package(Iconv REQUIRED); if(NOT Iconv_IS_BUILT_IN); set(ICONV_LIB Iconv::Iconv); endif(). find_package(LibLZMA); if(NOT LIBLZMA_FOUND); message(""Will attempt to fetch and build liblzma""); message(""=======================================""); externalproject_add(liblzma; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; ##; DOWNLOAD_COMMAND curl -k -L http://tukaani.org/xz/xz-5.2.2.tar.gz -o xz-5.2.2.tar.gz &&; ${SHASUM} 73df4d5d34f0468bd57d09f2d8af363e95ed6cc3a4a86129d2f2c366259902a2 xz-5.2.2.tar.gz &&; tar -xzvf xz-5.2.2.tar.gz; #URL http://tukaani.org/xz/xz-5.2.2.tar.gz; #URL_HASH SHA1=14663612422ab61386673be78fbb2556f50a1f08; ##; SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/xz-5.2.2; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; BUILD_IN_SOURCE TRUE; CONFIGURE_COMMAND ${CMAKE_CURRENT_SOURCE_DIR}/external/xz-5.2.2/configure --prefix=<INSTALL_DIR> CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER} CFLAGS=${EXTRA_CMAKE_INCLUDE_FLAGS} CPPFLAGS=${EXTRA_CMAKE_INCLUDE_FLAGS} LDFLAGS=${EXTRA_CMAKE_LIBRARY_FLAGS}; BUILD_COMMAND make ${QUIET_MAKE}; INSTALL_COMMAND make ${QUIET_MAKE} install; ). # Tell cmake that the external project generated a library so we can; # add dependencies here instead of later; set(LIBLZMA_LIBRARIES ${GAT_SOURCE_DIR}/external/install/lib/liblzma.a); set(LIBSTADEN_LDFLAGS ""-L${GAT_SOURCE_DIR}/external/install/lib""); set(LIBSTADEN_CFLAGS ""-I${GAT_SOURCE_DIR}/external/install/include""); set(FETCHED_LIBLZMA TRUE); else(); message(""Found liblzma library: ${LIBLZMA_LIBRARIES}""); message(""===========================================""); endif(). find_package(BZip2); if(NOT BZIP2_FOUND); message(""Will attempt to fetch and build libbz2""); message(""=======================================""); externalproject_add(libbz2; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://sourceware.org/pub/bzip2/bzip2-1.0.6.tar.gz -o bzip2-1.0.6.tar.gz &&; ${SHASUM} a2848f34fcd5d6cf47def00461fcb528a0484d8edef",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:14928,Modifiability,config,configuration,14928,"S ""-L${GAT_SOURCE_DIR}/external/install/lib -I${GAT_SOURCE_DIR}/external/install/include""); set(LIBSTADEN_CFLAGS ""-I${GAT_SOURCE_DIR}/external/install/include""); set(FETCHED_LIBBZ2 TRUE); else(); message(""Found libbz2 library: ${BZIP2_LIBRARIES}""); message(""===========================================""); endif(). ##; # Set the latest version and look for what we need; ##; set(Boost_ADDITIONAL_VERSIONS ""1.59.0"" ""1.60.0"" ""1.61.0"" ""1.62.0"" ""1.63.0"" ""1.64.0"" ""1.65.0"" ""1.66.0"" ""1.67.0"" ""1.68.0"" ""1.69.0"" ""1.70.0"" ""1.71.0"" ""1.72.0"" ""1.73.0"" ""1.74.0"" ""1.75.0"" ""1.76.0"" ""1.77.0"" ""1.78.0""); if (NOT BOOST_RECONFIGURE); find_package(Boost 1.59.0 COMPONENTS iostreams system filesystem timer chrono program_options); message(""BOOST_INCLUDEDIR = ${BOOST_INCLUDEDIR}""); message(""BOOST_LIBRARYDIR = ${BOOST_LIBRARYDIR}""); message(""Boost_FOUND = ${Boost_FOUND}""); endif(). include(ExternalProject). ##; # If we had to fetch Boost, the reconfigure step will re-run cmake. The second configuration; # pass is executed with the BOOST_RECONFIGURE flag set. This should allow our newly; # installed Boost to be found by CMake.; ##; if(BOOST_RECONFIGURE); message(""Executing Boost Reconfiguration""); unset(Boost_FOUND CACHE); unset(Boost_INCLUDE_DIR CACHE); unset(Boost_INCLUDE_DIRS CACHE); unset(Boost_LIBRARY_DIRS CACHE); unset(Boost_LIBRARIES CACHE); unset(BOOST_ROOT CACHE); unset(CMAKE_PREFIX_PATH CACHE); unset(Boost::diagnostic_definitions CACHE); unset(Boost::disable_autolinking CACHE); unset(Boost::dynamic_linking CACHE); set(BOOST_ROOT ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(CMAKE_PREFIX_PATH ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(Boost_INCLUDE_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/include); set(Boost_LIBRARY_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/lib); find_package(Boost 1.59.0 COMPONENTS iostreams system filesystem timer chrono program_options locale REQUIRED); set(FETCH_BOOST FALSE); endif(). ##; # Either inform the user of how to obtain Boost, or,",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:18129,Modifiability,config,config,18129,"==============================================""); externalproject_add(libboost; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://sourceforge.net/projects/boost/files/boost/1.72.0/boost_1_72_0.tar.gz/download -o boost_1_72_0.tar.gz &&; #${SHASUM} 96b34f7468f26a141f6020efb813f1a2f3dfb9797ecf76a7d7cbd843cc95f5bd boost_1_71_0.tar.gz &&; ${SHASUM} c66e88d5786f2ca4dbebb14e06b566fb642a1a6947ad8cc9091f9f445134143f boost_${BOOST_FETCHED_VERSION}.tar.gz &&; tar xzf boost_${BOOST_FETCHED_VERSION}.tar.gz ; SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/boost_${BOOST_FETCHED_VERSION}; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; #PATCH_COMMAND patch -p2 < ${CMAKE_CURRENT_SOURCE_DIR}/external/boost156.patch; CONFIGURE_COMMAND CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER} ${CMAKE_CURRENT_SOURCE_DIR}/external/boost_${BOOST_FETCHED_VERSION}/bootstrap.sh ${BOOST_CONFIGURE_TOOLSET} ${BOOST_BUILD_LIBS} --prefix=<INSTALL_DIR>; add_custom_command(; OUTPUT ${CMAKE_CURRENT_SOURCE_DIR}/external/boost_${BOOST_FETCHED_VERSION}/tools/build/src/user-config.jam; PRE_BUILD; COMMAND echo ""using gcc : ${CC_VERSION} : ${CMAKE_CXX_COMPILER} ;""; ); BUILD_COMMAND CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER} ${CMAKE_CURRENT_SOURCE_DIR}/external/boost_${BOOST_FETCHED_VERSION}/b2 -d0 -j${BOOST_BUILD_THREADS} ${BOOST_LIB_SUBSET} toolset=${BOOST_TOOLSET} ${BOOST_EXTRA_FLAGS} cxxflags=${BOOST_CXX_FLAGS} link=static install; BUILD_IN_SOURCE 1; INSTALL_COMMAND """"; ). externalproject_add_step(libboost makedir; COMMAND mkdir -p <SOURCE_DIR>/build; COMMENT ""Make build directory""; DEPENDEES download; DEPENDERS configure). ##; # After we've installed boost,; ##; set(RECONFIG_FLAGS ${RECONFIG_FLAGS} -DBOOST_WILL_RECONFIGURE=FALSE -DBOOST_RECONFIGURE=TRUE -DFETCH_BOOST=FALSE); externalproject_add_step(libboost reconfigure; COMMAND ${CMAKE_COMMAND} ${CMAKE_CURRENT_SOURCE_DIR} ${RECONFIG_FLAGS}; DEPENDEES install; ); set(FETCHED_BOOST TRUE); endif(). ##; # If w",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:18685,Modifiability,config,configure,18685,"nal/boost_${BOOST_FETCHED_VERSION}; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; #PATCH_COMMAND patch -p2 < ${CMAKE_CURRENT_SOURCE_DIR}/external/boost156.patch; CONFIGURE_COMMAND CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER} ${CMAKE_CURRENT_SOURCE_DIR}/external/boost_${BOOST_FETCHED_VERSION}/bootstrap.sh ${BOOST_CONFIGURE_TOOLSET} ${BOOST_BUILD_LIBS} --prefix=<INSTALL_DIR>; add_custom_command(; OUTPUT ${CMAKE_CURRENT_SOURCE_DIR}/external/boost_${BOOST_FETCHED_VERSION}/tools/build/src/user-config.jam; PRE_BUILD; COMMAND echo ""using gcc : ${CC_VERSION} : ${CMAKE_CXX_COMPILER} ;""; ); BUILD_COMMAND CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER} ${CMAKE_CURRENT_SOURCE_DIR}/external/boost_${BOOST_FETCHED_VERSION}/b2 -d0 -j${BOOST_BUILD_THREADS} ${BOOST_LIB_SUBSET} toolset=${BOOST_TOOLSET} ${BOOST_EXTRA_FLAGS} cxxflags=${BOOST_CXX_FLAGS} link=static install; BUILD_IN_SOURCE 1; INSTALL_COMMAND """"; ). externalproject_add_step(libboost makedir; COMMAND mkdir -p <SOURCE_DIR>/build; COMMENT ""Make build directory""; DEPENDEES download; DEPENDERS configure). ##; # After we've installed boost,; ##; set(RECONFIG_FLAGS ${RECONFIG_FLAGS} -DBOOST_WILL_RECONFIGURE=FALSE -DBOOST_RECONFIGURE=TRUE -DFETCH_BOOST=FALSE); externalproject_add_step(libboost reconfigure; COMMAND ${CMAKE_COMMAND} ${CMAKE_CURRENT_SOURCE_DIR} ${RECONFIG_FLAGS}; DEPENDEES install; ); set(FETCHED_BOOST TRUE); endif(). ##; # If we're fetching boost and we need to have dummy paths for these variables; # so that CMake won't complain; ##; if(BOOST_WILL_RECONFIGURE); message(""Setting Temporary Boost paths""); set(Boost_INCLUDE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install/include); set(Boost_INCLUDE_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/include); set(Boost_LIBRARY_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/lib); set(Boost_FOUND TRUE); endif(). message(""BOOST ROOT = ${BOOST_ROOT}""); message(""BOOST INCLUDE DIR = ${Boost_INCLUDE_DIR}""); message(""BOOST INCLUDE DIRS = ${Boost_INCLUDE_DIRS",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:19099,Modifiability,variab,variables,19099,"OMPILER} CXX=${CMAKE_CXX_COMPILER} ${CMAKE_CURRENT_SOURCE_DIR}/external/boost_${BOOST_FETCHED_VERSION}/b2 -d0 -j${BOOST_BUILD_THREADS} ${BOOST_LIB_SUBSET} toolset=${BOOST_TOOLSET} ${BOOST_EXTRA_FLAGS} cxxflags=${BOOST_CXX_FLAGS} link=static install; BUILD_IN_SOURCE 1; INSTALL_COMMAND """"; ). externalproject_add_step(libboost makedir; COMMAND mkdir -p <SOURCE_DIR>/build; COMMENT ""Make build directory""; DEPENDEES download; DEPENDERS configure). ##; # After we've installed boost,; ##; set(RECONFIG_FLAGS ${RECONFIG_FLAGS} -DBOOST_WILL_RECONFIGURE=FALSE -DBOOST_RECONFIGURE=TRUE -DFETCH_BOOST=FALSE); externalproject_add_step(libboost reconfigure; COMMAND ${CMAKE_COMMAND} ${CMAKE_CURRENT_SOURCE_DIR} ${RECONFIG_FLAGS}; DEPENDEES install; ); set(FETCHED_BOOST TRUE); endif(). ##; # If we're fetching boost and we need to have dummy paths for these variables; # so that CMake won't complain; ##; if(BOOST_WILL_RECONFIGURE); message(""Setting Temporary Boost paths""); set(Boost_INCLUDE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install/include); set(Boost_INCLUDE_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/include); set(Boost_LIBRARY_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/lib); set(Boost_FOUND TRUE); endif(). message(""BOOST ROOT = ${BOOST_ROOT}""); message(""BOOST INCLUDE DIR = ${Boost_INCLUDE_DIR}""); message(""BOOST INCLUDE DIRS = ${Boost_INCLUDE_DIRS}""); message(""BOOST LIB DIR = ${Boost_LIBRARY_DIRS}""); message(""BOOST LIBRARIES = ${Boost_LIBRARIES}""). set(EXTERNAL_LIBRARY_PATH $CMAKE_CURRENT_SOURCE_DIR/lib). #find_package(libdivsufsort); #if(NOT LIBDIVSUFSORT_FOUND); # message(""Build system will build libdivsufsort""); # message(""==================================================================""); # include(ExternalProject); # externalproject_add(libdivsufsort; # DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; # URL ${CMAKE_CURRENT_SOURCE_DIR}/external/libdivsufsort.zip; # # Note: This zip comes from the fetched rapmap.zip, whose SHA we check; # # so we souldn't need",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:20836,Modifiability,config,configure,20836,"ENT_SOURCE_DIR/lib). #find_package(libdivsufsort); #if(NOT LIBDIVSUFSORT_FOUND); # message(""Build system will build libdivsufsort""); # message(""==================================================================""); # include(ExternalProject); # externalproject_add(libdivsufsort; # DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; # URL ${CMAKE_CURRENT_SOURCE_DIR}/external/libdivsufsort.zip; # # Note: This zip comes from the fetched rapmap.zip, whose SHA we check; # # so we souldn't need to check this one separately.; # SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/libdivsufsort-master; # INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; # #UPDATE_COMMAND sh -c ""mkdir -p <SOURCE_DIR>/build""; # BINARY_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/libdivsufsort-master/build; # CMAKE_ARGS -DCMAKE_INSTALL_PREFIX:PATH=<INSTALL_DIR> -DBUILD_DIVSUFSORT64=TRUE -DUSE_OPENMP=TRUE -DBUILD_SHARED_LIBS=FALSE; # ); # externalproject_add_step(libdivsufsort makedir; # COMMAND mkdir -p <SOURCE_DIR>/build; # COMMENT ""Make build directory""; # DEPENDEES download; # DEPENDERS configure); #; # set(SUFFARRAY_INCLUDE_DIRS ${CMAKE_CURRENT_SOURCE_DIR}/external/install/include); # set(FETCHED_LIBDIVSUFSORT TRUE); #else(); # message(""SUFFARRAY_LIB = ${SUFFARRAY_LIBRARY}""); # set(SUFFARRAY_LIB ${SUFFARRAY_LIBRARY}); # message(""SUFFARRAY_LIB64 = ${SUFFARRAY_LIBRARY64}""); # set(SUFFARRAY_LIB64 ${SUFFARRAY_LIBRARY64}); # set(SUFFARRAY_INCLUDE_DIRS ${SUFFARRAY_INCLUDE_DIR}); #endif(). find_package(cereal ""1.3.2""); if (NOT CEREAL_FOUND); message(""Build system will fetch and build the cereal serialization library""); message(""==================================================================""); include(ExternalProject); externalproject_add(libcereal; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://github.com/USCiLab/cereal/archive/refs/tags/v1.3.2.tar.gz -o cereal-v1.3.2.tar.gz &&; ${SHASUM} 16a7ad9b31ba5880dac55d62b5d6f243c3ebc8d46a3514149e56b5e7ea81f85f cere",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:22356,Modifiability,config,configure,22356,"SUFFARRAY_INCLUDE_DIR}); #endif(). find_package(cereal ""1.3.2""); if (NOT CEREAL_FOUND); message(""Build system will fetch and build the cereal serialization library""); message(""==================================================================""); include(ExternalProject); externalproject_add(libcereal; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://github.com/USCiLab/cereal/archive/refs/tags/v1.3.2.tar.gz -o cereal-v1.3.2.tar.gz &&; ${SHASUM} 16a7ad9b31ba5880dac55d62b5d6f243c3ebc8d46a3514149e56b5e7ea81f85f cereal-v1.3.2.tar.gz &&; tar -xzvf cereal-v1.3.2.tar.gz. SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/cereal-1.3.2; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; #UPDATE_COMMAND sh -c ""mkdir -p <SOURCE_DIR>/build""; BINARY_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/cereal-1.3.2/build; CONFIGURE_COMMAND """"; BUILD_COMMAND """"; INSTALL_COMMAND sh -c ""mkdir -p <INSTALL_DIR>/include && cp -r <SOURCE_DIR>/include/cereal <INSTALL_DIR>/include""; ); externalproject_add_step(libcereal makedir; COMMAND mkdir -p <SOURCE_DIR>/build; COMMENT ""Make build directory""; DEPENDEES download; DEPENDERS configure). set(FETCHED_CEREAL TRUE); endif(). ## Try and find TBB first; find_package(TBB 2021.4; HINTS ${TBB_ROOT_SEARCH}; COMPONENTS tbb tbbmalloc tbbmalloc_proxy). if (${TBB_FOUND}); if (${TBB_VERSION} VERSION_GREATER_EQUAL 2021.4); message(""FOUND SUITABLE TBB VERSION : ${TBB_VERSION}""); set(TBB_TARGET_EXISTED TRUE); else(); set(TBB_TARGET_EXISTED FALSE); endif(); else(); set(TBB_TARGET_EXISTED FALSE); endif(). ##; #; # Fetch and build Intel's Threading Building Blocks library.; #; ##; if(NOT ${TBB_TARGET_EXISTED}). set(TBB_WILL_RECONFIGURE TRUE); # Set the appropriate compiler; if(CLANG); set(TBB_COMPILER ""clang""); else(); set(TBB_COMPILER ""gcc""); endif(). message(""Build system will fetch and build Intel Threading Building Blocks""); message(""==================================================================""); # These are useful for t",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:24832,Modifiability,variab,variables,24832,"LL_DIR}; PATCH_COMMAND ""${TBB_PATCH_STEP}""; CMAKE_ARGS -DCMAKE_CXX_FLAGS=${TBB_CXXFLAGS} -DCMAKE_INSTALL_PREFIX=<INSTALL_DIR> -DTBB_TEST=OFF -DTBB_EXAMPLES=OFF -DCMAKE_BUILD_TYPE=Release -DCMAKE_CXX_STANDARD=${CMAKE_CXX_STANDARD} -DCMAKE_CXX_COMPILER=${CMAKE_CXX_COMPILER} -DCMAKE_C_COMPILER=${CMAKE_C_COMPILER}; BUILD_IN_SOURCE TRUE; ). set(RECONFIG_FLAGS ${RECONFIG_FLAGS} -DTBB_WILL_RECONFIGURE=FALSE -DTBB_RECONFIGURE=TRUE); ExternalProject_Add_Step(libtbb reconfigure; COMMAND ${CMAKE_COMMAND} ${CMAKE_CURRENT_SOURCE_DIR} ${RECONFIG_FLAGS}; DEPENDEES install ; ); set(FETCHED_TBB TRUE); set(TBB_ROOT_SEARCH ${CMAKE_SOURCE_DIR}/external/install) . if(${FETCHED_BOOST}); add_dependencies(libtbb libboost); endif(). endif() # end of fetch tbb. ##; # If we're fetching tbb, we need to have dummy paths for these variables; # so that CMake won't complain; ##; if(TBB_WILL_RECONFIGURE); set(TBB_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(TBB_INCLUDE_DIRS ${TBB_INSTALL_DIR}/include); set(TBB_INCLUDE_DIR ${TBB_INSTALL_DIR}/include); set(TBB_LIBRARY_DIRS ${TBB_INSTALL_DIR}/lib); set(TBB_LIBRARY ${TBB_INSTALL_DIR}/lib); set(TBB_LIB_DIR ${TBB_INSTALL_DIR}/lib); #set(TBB_LIBRARIES tbb tbbmalloc); set(TBB_LIBRARIES ${TBB_INSTALL_DIR}/lib/libtbb.${SHARED_LIB_EXTENSION}; 			${TBB_INSTALL_DIR}/lib/libtbbmalloc.${SHARED_LIB_EXTENSION}; ${TBB_INSTALL_DIR}/lib/libtbbmalloc_proxy.${SHARED_LIB_EXTENSION}; 	 ); message(""TBB_INCLUDE_DIRS = ${TBB_INCLUDE_DIRS}""); message(""TBB_LIBRARY_DIRS = ${TBB_LIBRARY_DIRS}""); endif(). ##; # Similar to the Boost trick above, the libtbb reconfigure should force this code; # to be run on the second configuration pass, where it should appropriately set the; # TBB_INSTALL_DIR variable.; ##; if(TBB_RECONFIGURE); unset(TBB_FOUND CACHE); unset(TBB_INSTALL_DIR CACHE); unset(CMAKE_PREFIX_PATH CACHE); unset(TBB_INCLUDE_DIRS CACHE); unset(TBB_INCLUDE_DIR CACHE); unset(TBB_LIBRARY_DIRS CACHE); unset(TBB_LIBRARY CACHE); unset(TBB_LIBRARIES CACHE); set(CMAKE_PREFI",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:25659,Modifiability,config,configuration,25659,"_DIR}/external/install) . if(${FETCHED_BOOST}); add_dependencies(libtbb libboost); endif(). endif() # end of fetch tbb. ##; # If we're fetching tbb, we need to have dummy paths for these variables; # so that CMake won't complain; ##; if(TBB_WILL_RECONFIGURE); set(TBB_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(TBB_INCLUDE_DIRS ${TBB_INSTALL_DIR}/include); set(TBB_INCLUDE_DIR ${TBB_INSTALL_DIR}/include); set(TBB_LIBRARY_DIRS ${TBB_INSTALL_DIR}/lib); set(TBB_LIBRARY ${TBB_INSTALL_DIR}/lib); set(TBB_LIB_DIR ${TBB_INSTALL_DIR}/lib); #set(TBB_LIBRARIES tbb tbbmalloc); set(TBB_LIBRARIES ${TBB_INSTALL_DIR}/lib/libtbb.${SHARED_LIB_EXTENSION}; 			${TBB_INSTALL_DIR}/lib/libtbbmalloc.${SHARED_LIB_EXTENSION}; ${TBB_INSTALL_DIR}/lib/libtbbmalloc_proxy.${SHARED_LIB_EXTENSION}; 	 ); message(""TBB_INCLUDE_DIRS = ${TBB_INCLUDE_DIRS}""); message(""TBB_LIBRARY_DIRS = ${TBB_LIBRARY_DIRS}""); endif(). ##; # Similar to the Boost trick above, the libtbb reconfigure should force this code; # to be run on the second configuration pass, where it should appropriately set the; # TBB_INSTALL_DIR variable.; ##; if(TBB_RECONFIGURE); unset(TBB_FOUND CACHE); unset(TBB_INSTALL_DIR CACHE); unset(CMAKE_PREFIX_PATH CACHE); unset(TBB_INCLUDE_DIRS CACHE); unset(TBB_INCLUDE_DIR CACHE); unset(TBB_LIBRARY_DIRS CACHE); unset(TBB_LIBRARY CACHE); unset(TBB_LIBRARIES CACHE); set(CMAKE_PREFIX_PATH ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(TBB_INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(TBB_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(TBB_INCLUDE_DIRS ${TBB_INSTALL_DIR}/include); set(TBB_INCLUDE_DIR ${TBB_INSTALL_DIR}/include); set(TBB_LIBRARY_DIRS ${TBB_INSTALL_DIR}/lib); set(TBB_LIBRARY ${TBB_INSTALL_DIR}/lib); set(TBB_LIB_DIR ${TBB_INSTALL_DIR}/lib); message(""TBB_INSTALL_DIR = ${TBB_INSTALL_DIR}""); find_package(TBB 2021.4; HINTS ${TBB_ROOT_SEARCH}; COMPONENTS tbb tbbmalloc tbbmalloc_proxy); message(""[in TBB_RECONFIGURE] TBB_LIBRARIES = ${TBB_LIBRARIES}""); endif(). #",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:25736,Modifiability,variab,variable,25736,"_DIR}/external/install) . if(${FETCHED_BOOST}); add_dependencies(libtbb libboost); endif(). endif() # end of fetch tbb. ##; # If we're fetching tbb, we need to have dummy paths for these variables; # so that CMake won't complain; ##; if(TBB_WILL_RECONFIGURE); set(TBB_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(TBB_INCLUDE_DIRS ${TBB_INSTALL_DIR}/include); set(TBB_INCLUDE_DIR ${TBB_INSTALL_DIR}/include); set(TBB_LIBRARY_DIRS ${TBB_INSTALL_DIR}/lib); set(TBB_LIBRARY ${TBB_INSTALL_DIR}/lib); set(TBB_LIB_DIR ${TBB_INSTALL_DIR}/lib); #set(TBB_LIBRARIES tbb tbbmalloc); set(TBB_LIBRARIES ${TBB_INSTALL_DIR}/lib/libtbb.${SHARED_LIB_EXTENSION}; 			${TBB_INSTALL_DIR}/lib/libtbbmalloc.${SHARED_LIB_EXTENSION}; ${TBB_INSTALL_DIR}/lib/libtbbmalloc_proxy.${SHARED_LIB_EXTENSION}; 	 ); message(""TBB_INCLUDE_DIRS = ${TBB_INCLUDE_DIRS}""); message(""TBB_LIBRARY_DIRS = ${TBB_LIBRARY_DIRS}""); endif(). ##; # Similar to the Boost trick above, the libtbb reconfigure should force this code; # to be run on the second configuration pass, where it should appropriately set the; # TBB_INSTALL_DIR variable.; ##; if(TBB_RECONFIGURE); unset(TBB_FOUND CACHE); unset(TBB_INSTALL_DIR CACHE); unset(CMAKE_PREFIX_PATH CACHE); unset(TBB_INCLUDE_DIRS CACHE); unset(TBB_INCLUDE_DIR CACHE); unset(TBB_LIBRARY_DIRS CACHE); unset(TBB_LIBRARY CACHE); unset(TBB_LIBRARIES CACHE); set(CMAKE_PREFIX_PATH ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(TBB_INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(TBB_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install); set(TBB_INCLUDE_DIRS ${TBB_INSTALL_DIR}/include); set(TBB_INCLUDE_DIR ${TBB_INSTALL_DIR}/include); set(TBB_LIBRARY_DIRS ${TBB_INSTALL_DIR}/lib); set(TBB_LIBRARY ${TBB_INSTALL_DIR}/lib); set(TBB_LIB_DIR ${TBB_INSTALL_DIR}/lib); message(""TBB_INSTALL_DIR = ${TBB_INSTALL_DIR}""); find_package(TBB 2021.4; HINTS ${TBB_ROOT_SEARCH}; COMPONENTS tbb tbbmalloc tbbmalloc_proxy); message(""[in TBB_RECONFIGURE] TBB_LIBRARIES = ${TBB_LIBRARIES}""); endif(). #",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:28131,Modifiability,config,configure,28131,"bgff_FOUND); message(STATUS ""libgff ver. ${LIB_GFF_VERSION} found.""); message(STATUS "" include: ${LIB_GFF_INCLUDE_DIR}""); message(STATUS "" lib : ${LIB_GFF_LIBRARY_DIR}""); endif(). if(NOT libgff_FOUND); message(""Build system will compile libgff""); message(""==================================================================""); externalproject_add(libgff; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://github.com/COMBINE-lab/libgff/archive/v2.0.0.tar.gz -o libgff.tgz &&; ${SHASUM} 7656b19459a7ca7d2fd0fcec4f2e0fd0deec1b4f39c703a114e8f4c22d82a99c libgff.tgz &&; tar -xzvf libgff.tgz; SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/libgff-2.0.0; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; BINARY_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/libgff-2.0.0/build; CMAKE_ARGS -DCMAKE_INSTALL_PREFIX:PATH=<INSTALL_DIR> -DCMAKE_CXX_COMPILER=${CMAKE_CXX_COMPILER} -DCMAKE_C_COMPILER=${CMAKE_C_COMPILER} ; ); externalproject_add_step(libgff makedir; COMMAND mkdir -p <SOURCE_DIR>/build; COMMENT ""Make build directory""; DEPENDEES download; DEPENDERS configure); set(FETCHED_GFF TRUE); set(LIB_GFF_PATH ${CMAKE_CURRENT_SOURCE_DIR}/external/install); endif(). # Because of the way that Apple has changed SIP; # in el capitan, some headers may be in a new location; if(APPLE); set(STADEN_INC ""-I/usr/local/include""); set(STADEN_LIB ""-L/usr/local/lib""); endif(). if(CONDA_BUILD); set(LZFLAG ""-lz""); else(); set(LZFLAG """"); endif(). find_package(CURL). if (FETCH_STADEN); set(LIBSTADEN_FOUND FALSE); else (); find_package(libstadenio 1.14.15); endif(). if (NOT LIBSTADENIO_FOUND); message(""Build system will compile Staden IOLib""); message(""==================================================================""); externalproject_add(libstadenio; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://github.com/jkbonfield/io_lib/releases/download/io_lib-1-14-15/io_lib-1.14.15.tar.gz -o staden-io_lib-v1.14.15.tar.gz &&; ${SHASUM} 20",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:29470,Modifiability,config,configure,29470," will compile Staden IOLib""); message(""==================================================================""); externalproject_add(libstadenio; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://github.com/jkbonfield/io_lib/releases/download/io_lib-1-14-15/io_lib-1.14.15.tar.gz -o staden-io_lib-v1.14.15.tar.gz &&; ${SHASUM} 20814c4365e1e2fe6630fb11d0df370dec4c5688af3871de7f1cb0129671401e staden-io_lib-v1.14.15.tar.gz &&; mkdir -p staden-io_lib-1.14.15 &&; tar -xzf staden-io_lib-v1.14.15.tar.gz --strip-components=1 -C staden-io_lib-1.14.15 &&; rm -fr staden-io_lib &&; mv -f staden-io_lib-1.14.15 staden-io_lib; SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/staden-io_lib; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; CONFIGURE_COMMAND ./configure --enable-shared=no --without-libcurl --prefix=<INSTALL_DIR> LDFLAGS=${LIBSTADEN_LDFLAGS} CFLAGS=${LIBSTADEN_CFLAGS} CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER}; BUILD_COMMAND make ${QUIET_MAKE} CC=${CMAKE_C_COMPILER} CXX=${CMAKE_CXX_COMPILER} CFLAGS+=${STADEN_INC} CFLAGS+=${STADEN_LIB} LDFLAGS+=${EXTRA_CMAKE_LIBRARY_FLAGS} CFLAGS+=${EXTRA_CMAKE_INCLUDE_FLAGS} CFLAGS+=${LZFLAG} CFLAGS+=${SCHAR_FLAG}. BUILD_IN_SOURCE 1; INSTALL_COMMAND make install; ); if(NOT LIBLZMA_FOUND); 	ExternalProject_Add_StepDependencies(libstadenio build liblzma); endif(). set(FETCHED_STADEN TRUE); set(STADEN_LIBRARIES ""${GAT_SOURCE_DIR}/external/install/lib/libstaden-read.a;${GAT_SOURCE_DIR}/external/install/lib/libhtscodecs.a""); endif(). if (ASAN_BUILD); set(FAST_MALLOC_LIB """"); set(HAVE_FAST_MALLOC TRUE); else(); set(FAST_MALLOC_LIB """"); set(HAVE_FAST_MALLOC FALSE). # See if we have Jemalloc; find_package(Jemalloc); if(Jemalloc_FOUND); ##; # Don't be so stringent about the version yet; ##; #if (NOT (${JEMALLOC_VERSION} VERSION_LESS 5.2.1)); message(""Found Jemalloc library --- using this memory allocator""); set(FAST_MALLOC_LIB ${JEMALLOC_LIBRARIES}); set(HAVE_FAST_MALLOC TRUE); #else(); # message(""F",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:308,Safety,detect,detect,308,"cmake_minimum_required(VERSION 3.15). if(DEFINED ENV{CC}); set(CC $ENV{CC}); else(); set(CC gcc); endif(); message(""CC: ${CC}""). set(CC_VERSION """"); if(${CC} MATCHES ^gcc-); string(REGEX REPLACE ""gcc-"" """" CC_VERSION ${CC}); endif(); message(""CC version: ${CC_VERSION}""). enable_testing(). project(Salmon). # detect host architecture ; if(NOT DEFINED USE_ARM); if(CMAKE_SYSTEM_PROCESSOR MATCHES ""^(aarch64.*|AARCH64.*|arm64.*|ARM64.*)""); message(""Detected 64-bit ARM host. Setting USE_ARM to true.""); set(USE_ARM TRUE); # set char to be signed; add_compile_options(-fsigned-char); set(SCHAR_FLAG ""-fsigned-char""); else(); message(""Detected non-ARM host. Setting USE_ARM to false.""); set(USE_ARM FALSE); set(SCHAR_FLAG """"); endif(); endif(). option(USE_SHARED_LIBS ""Use shared instead of static libraries"" OFF). # auto-populate version:; # from https://stackoverflow.com/questions/47066115/cmake-get-version-from-multi-line-text-file; file(READ ""current_version.txt"" ver). string(REGEX MATCH ""VERSION_MAJOR ([0-9]*)"" _ ${ver}); set(ver_major ${CMAKE_MATCH_1}). string(REGEX MATCH ""VERSION_MINOR ([0-9]*)"" _ ${ver}); set(ver_minor ${CMAKE_MATCH_1}). string(REGEX MATCH ""VERSION_PATCH ([0-9]*)"" _ ${ver}); set(ver_patch ${CMAKE_MATCH_1}). set(CPACK_PACKAGE_VERSION_MAJOR ${ver_major}); set(CPACK_PACKAGE_VERSION_MINOR ${ver_minor}); set(CPACK_PACKAGE_VERSION_PATCH ${ver_patch}). set(CPACK_PACKAGE_VERSION ""${ver_major}.${ver_minor}.${ver_patch}""); message(""version: ${CPACK_PACKAGE_VERSION}""). set(PROJECT_VERSION ${CPACK_PACKAGE_VERSION}); set(CPACK_GENERATOR ""TGZ""); set(CPACK_SOURCE_GENERATOR ""TGZ""); set(CPACK_PACKAGE_VENDOR ""University of Maryland""); set(CPACK_PACKAGE_DESCRIPTION_SUMMARY ""Salmon - Wicked-fast RNA-seq isoform quantification using selective alignment""); set(CPACK_PACKAGE_NAME; ""${CMAKE_PROJECT_NAME}-${CPACK_PACKAGE_VERSION_MAJOR}.${CPACK_PACKAGE_VERSION_MINOR}.${CPACK_PACKAGE_VERSION_PATCH}""); set(CPACK_SOURCE_PACKAGE_FILE_NAME; ""${CMAKE_PROJECT_NAME}-${CPACK_PACKAGE_VERSION_MA",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:5931,Safety,detect,detect-,5931,"""think different"", we also have to use non-standard suffixes; # for our shared libraries; set(SHARED_LIB_EXTENSION ""dylib""); else(); # We're in sane linux world; set(SHARED_LIB_EXTENSION ""so""); set(LIBSALMON_LINKER_FLAGS """"); endif(). set( BOOST_EXTRA_FLAGS ""--layout=tagged"" ); ## this get's set differently below if we; ## are on clang & apple; set(NON_APPLECLANG_LIBS gomp). if(UNIX AND NOT APPLE); set(LIBRT rt); endif(). set(PTHREAD_LIB). ##; # Let us check the sha sum of our pacakges if we have the right tools; ##; set(SHASUM ${CMAKE_CURRENT_SOURCE_DIR}/scripts/check_shasum.sh). ##; # Compiler-specific C++11/14 activation.; # http://stackoverflow.com/questions/10984442/how-to-detect-c11-support-of-a-compiler-with-cmake; ##; ##; # First take care of what to do if we have gcc; ##; if(""${CMAKE_CXX_COMPILER_ID}"" MATCHES ""GNU""); execute_process(; COMMAND ${CMAKE_CXX_COMPILER} -dumpversion OUTPUT_VARIABLE GCC_VERSION); # If we're on OSX; if(APPLE AND NOT (GCC_VERSION VERSION_GREATER ${GCCVERSION} OR GCC_VERSION VERSION_EQUAL ${GCCVERSION})); message(FATAL_ERROR ""When building under OSX, ${PROJECT_NAME} requires ""; ""either clang or g++ >= ${GCCVERSION}""); elseif(NOT (GCC_VERSION VERSION_GREATER ${GCCVERSION} OR GCC_VERSION VERSION_EQUAL ${GCCVERSION})); message(FATAL_ERROR ""${PROJECT_NAME} requires g++ ${GCCVERSION} or greater.""); endif(); ; if(GCC_VERSION VERSION_GREATER_EQUAL ""7.1""); list(APPEND TGT_WARN_FLAGS ""-Wno-int-in-bool-context""); endif(); ; if(GCC_VERSION VERSION_GREATER_EQUAL ""9.1""); list(APPEND TGT_WARN_FLAGS ""-Wno-deprecated-copy""); endif(). set(GCC TRUE). # Put complete static linking on hold for the time-being; # If we're not on OSX, make an attempt to compile everything statically; #if(NOT APPLE); #set(CMAKE_EXE_LINK_FLAGS ""-static""); set(PTHREAD_LIB ""pthread""); #endif(). # If we're on Linux (i.e. not OSX) and we're using; # gcc, then set the -static-libstdc++ flag; if(NOT APPLE); list(APPEND TGT_COMPILE_FLAGS -static-libstdc++); endif(). set(WARNING_IGNO",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:8752,Safety,detect,detect,8752," available, so I'll use that""); list(APPEND TGT_COMPILE_FLAGS -stdlib=libc++); set(BOOST_TOOLSET ""clang""); set(BOOST_CONFIGURE_TOOLSET ""--with-toolset=clang""); set(BCXX_FLAGS ""-stdlib=libc++ -DBOOST_HAS_INT128 ${SCHAR_FLAG}""); set(BOOST_EXTRA_FLAGS toolset=clang cxxflags=${BCXX_FLAGS} linkflags=""-stdlib=libc++""); # Otherwise, use libstdc++ (and make it static); else(); list(APPEND TGT_COMPILE_FLAGS -static-libstdc++); endif(); # There's currently a bug with clang-3.4 & Boost 1.55 -- this hack fixes it; # but we should do something better (does this break things if CPU doesn't; # have 128-bit support)?; list(APPEND TGT_COMPILE_FLAGS -DBOOST_HAS_INT128). if(APPLE); set(NON_APPLECLANG_LIBS """"); else(); set(PTHREAD_LIB ""pthread""); endif(); else(); message(FATAL_ERROR ""Your C++ compiler does not support C++14.""); endif(). if(DO_QUIET_MAKE); set(QUIET_MAKE ""--silent""); else(); set(QUIET_MAKE """"); endif(). ## TODO: Figure out how to detect this automatically; # If the ""assembler"" is too old, tell TBB not to compile; # with -mrtm; if(NO_RTM); set(TBB_CXXFLAGS ""-mno-rtm""); endif(). include(ExternalProject). if(CMAKE_BUILD_TYPE MATCHES Debug); message(""Making Debug build""); elseif(CMAKE_BUILD_TYPE MATCHES Release); message(""Making Release build""); else(); message(""Making Default build type""); endif(). ##; # Record this top-level path; ##; set(GAT_SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}). # Have CMake tell us what it's doing; # set(CMAKE_VERBOSE_MAKEFILE true). ###; # check if numeric_limits<__int128_t> is defined; ###; try_compile(HAVE_INT128_NUMERIC_LIMITS ${CMAKE_BINARY_DIR} ; SOURCES ${GAT_SOURCE_DIR}/tests/compile_tests/int128_numeric_limits.cpp; CXX_STANDARD 14; CXX_STANDARD_REQUIRED ON ; ); if(HAVE_INT128_NUMERIC_LIMITS); message(""setting -DHAVE_NUMERIC_LIMITS128""); list(APPEND TGT_COMPILE_FLAGS ""-DHAVE_NUMERIC_LIMITS128""); else(); message(""not setting -DHAVE_NUMERIC_LIMITS128""); endif(). ###; #; # Grab pufferfish source --- DURING CONFIGURE TIME!; #; ####; if(NOT FETCHED",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:9433,Testability,test,tests,9433,"if CPU doesn't; # have 128-bit support)?; list(APPEND TGT_COMPILE_FLAGS -DBOOST_HAS_INT128). if(APPLE); set(NON_APPLECLANG_LIBS """"); else(); set(PTHREAD_LIB ""pthread""); endif(); else(); message(FATAL_ERROR ""Your C++ compiler does not support C++14.""); endif(). if(DO_QUIET_MAKE); set(QUIET_MAKE ""--silent""); else(); set(QUIET_MAKE """"); endif(). ## TODO: Figure out how to detect this automatically; # If the ""assembler"" is too old, tell TBB not to compile; # with -mrtm; if(NO_RTM); set(TBB_CXXFLAGS ""-mno-rtm""); endif(). include(ExternalProject). if(CMAKE_BUILD_TYPE MATCHES Debug); message(""Making Debug build""); elseif(CMAKE_BUILD_TYPE MATCHES Release); message(""Making Release build""); else(); message(""Making Default build type""); endif(). ##; # Record this top-level path; ##; set(GAT_SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}). # Have CMake tell us what it's doing; # set(CMAKE_VERBOSE_MAKEFILE true). ###; # check if numeric_limits<__int128_t> is defined; ###; try_compile(HAVE_INT128_NUMERIC_LIMITS ${CMAKE_BINARY_DIR} ; SOURCES ${GAT_SOURCE_DIR}/tests/compile_tests/int128_numeric_limits.cpp; CXX_STANDARD 14; CXX_STANDARD_REQUIRED ON ; ); if(HAVE_INT128_NUMERIC_LIMITS); message(""setting -DHAVE_NUMERIC_LIMITS128""); list(APPEND TGT_COMPILE_FLAGS ""-DHAVE_NUMERIC_LIMITS128""); else(); message(""not setting -DHAVE_NUMERIC_LIMITS128""); endif(). ###; #; # Grab pufferfish source --- DURING CONFIGURE TIME!; #; ####; if(NOT FETCHED_PUFFERFISH); exec_program(${CMAKE_CURRENT_SOURCE_DIR}/scripts/fetchPufferfish.sh RETURN_VALUE FETCH_PF_SCRIPT_RET); message(STATUS ""fetch PUFFERFISH exit code ${FETCH_PF_SCRIPT_RET}""); if(NOT (FETCH_PF_SCRIPT_RET EQUAL 0)); message(FATAL_ERROR ""Could not fetch pufferfish source [fetchPufferfish.sh returned exit code ${FETCH_PF_SCRIPT_RET}].""); endif(); set(FETCHED_PUFFERFISH TRUE CACHE BOOL ""Has pufferfish been fetched?"" FORCE); endif(). ##; # Super-secret override; ##; if( DEFINED CUSTOM_BOOST_PATH ); set(CMAKE_INCLUDE_PATH ${CUSTOM_BOOST_PATH} ${CMAKE_INCLUD",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt:32610,Testability,log,log,32610,"L_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; CONFIGURE_COMMAND sh -c ""${JEMALLOC_FLAGS} ./autogen.sh --disable-debug ${MALLOC_STATIC_BUILD_FLAG} --prefix=<INSTALL_DIR>""; #CONFIGURE_COMMAND sh -c ""${JEMALLOC_FLAGS} ./autogen.sh ${MALLOC_STATIC_BUILD_FLAG} --prefix=<INSTALL_DIR>""; INSTALL_COMMAND cp -r lib <INSTALL_DIR>/ && cp -r include <INSTALL_DIR>/; ). set(FAST_MALLOC_LIB ${CMAKE_CURRENT_SOURCE_DIR}/external/install/lib/libjemalloc.a); set(HAVE_FAST_MALLOC TRUE); set(FETCHED_JEMALLOC TRUE); if(FETCHED_LIBBZ2); add_dependencies(libjemalloc libbz2); endif(). if(FETCHED_LIBLZMA); add_dependencies(libjemalloc liblzma); endif(); endif(). ###; #; # Done building external dependencies.; #; ###. set(CPACK_SOURCE_IGNORE_FILES; ""/src/PCA.cpp""; ""/src/PCAUtils.cpp""; ""/build/""; ""/scripts/AggregateToGeneLevel.py""; ""/scripts/ExpressionTools.py""; ""/scripts/GenerateExpressionFiles.sh""; ""/scripts/ParseSoftFile.py""; ""/scripts/PlotCorrelation.py""; ""/scripts/junk""; ""/scripts/sfstrace.log""; ""/scripts/SFPipeline.py""; ""/bin/""; ""/lib/""; ""/sample_data/""; ""PublishREADMEToWebsite.sh""; ""/external/""; ""/src/obsolete/""; ""/include/obsolete/""; ""WebsiteHeader.txt""; ""/experimental_configs/""; "".git/""). message(""CPACK_SOURCE_IGNORE_FILES = ${CPACK_SOURCE_IGNORE_FILES}""). # we will use this property later; define_property(TARGET PROPERTY COMPACT_VECTOR_DIR INHERITED ; BRIEF_DOCS ""the path to the directory containing the compact_vector include tree""; FULL_DOCS ""the path to the directory containing the compact_vector include tree""). # Recurse into pufferfish source directory ; # and build the library ; set(BUILD_PUFF_FOR_SALMON TRUE); add_subdirectory(external/pufferfish). # make sure we know the path to compact_vector; get_property(COMPACT_VECTOR_INCLUDE_PATH TARGET graphdump PROPERTY COMPACT_VECTOR_DIR); message(""fetched path for compact_vector as [${COMPACT_VECTOR_INCLUDE_PATH}]""). # and then the main salmon source directory; add_subdirectory(src). #add_dependencies(salmon RapMap); # build a CPa",MatchSource.DOCS,CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt:11644,Availability,echo,echo,11644,"l -add_rpath ${GAT_SOURCE_DIR}/external/install/lib ${GAT_SOURCE_DIR}/build/src/unitTests; # ); # endif(); #else(); # # related to complete static linking --- on hold ; # set (BOOST_THREAD_LIBRARY); #endif(). #if (APPLE); #	add_custom_command(TARGET salmon; #		POST_BUILD; #		COMMAND install_name_tool -add_rpath ${GAT_SOURCE_DIR}/external/install/lib salmon; #	COMMAND install_name_tool -add_rpath @executable_path/../lib salmon; #		); #endif(). ##### ======================================. IF(CMAKE_INSTALL_PREFIX_INITIALIZED_TO_DEFAULT); SET(CMAKE_INSTALL_PREFIX; ""${GAT_SOURCE_DIR}"" CACHE PATH ""Default install prefix"" FORCE; ); ENDIF(CMAKE_INSTALL_PREFIX_INITIALIZED_TO_DEFAULT). set(INSTALL_LIB_DIR lib ); set(INSTALL_BIN_DIR bin ); set(INSTALL_INCLUDE_DIR include ). if(TBB_RECONFIGURE OR TBB_TARGET_EXISTED); #set(TBB_SOURCE_DIR $<TARGET_FILE:TBB::tbb>); #add_custom_target(genexdebug COMMAND ${CMAKE_COMMAND} -E echo ""$<TARGET_LINKER_FILE:TBB::tbb>""); get_target_property(TBB_LIB_INSTALL_NAME TBB::tbb IMPORTED_LOCATION_RELEASE); get_filename_component(TBB_LIB_INSTALL_DIR ${TBB_LIB_INSTALL_NAME} DIRECTORY); message(""TBB_LIB_INSTALL_DIR = ${TBB_LIB_INSTALL_DIR}""); file(GLOB TBB_FILES ${TBB_LIB_INSTALL_DIR}/libtbb*.${SHARED_LIB_EXTENSION}*); message(""TBBGLOBS = ${TBB_FILES}""). install(FILES ; ${TBB_FILES}; DESTINATION ${INSTALL_LIB_DIR}; ) ; #install(FILES ; # $<TARGET_FILE:TBB::tbbmalloc>; # DESTINATION ${INSTALL_LIB_DIR}; #); #install(DIRECTORY; # ${TBB_SOURCE_DIR}; # DESTINATION ${INSTALL_LIB_DIR}; #	 FILES_MATCHING PATTERN ""libtbb*.${SHARED_LIB_EXTENSION}*""; #); endif(). #install(DIRECTORY; # ${GAT_SOURCE_DIR}/external/install/lib/; # DESTINATION ${INSTALL_LIB_DIR}; #	 FILES_MATCHING PATTERN ""libtbb*.${SHARED_LIB_EXTENSION}*""; # ). # install(FILES ${Boost_LIBRARIES}; # 	 DESTINATION ${INSTALL_LIB_DIR}). install(TARGETS salmon salmon_core; RUNTIME DESTINATION bin; LIBRARY DESTINATION lib; ARCHIVE DESTINATION lib; ). add_custom_command(TARGET unitTests POST_BUILD; COMMAND ",MatchSource.DOCS,src/CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt:286,Deployability,install,install,286,"if(${TBB_FOUND}); get_target_property(TBB_INCLUDE_DIRS TBB::tbb INTERFACE_INCLUDE_DIRECTORIES); endif(). include_directories(; ${GAT_SOURCE_DIR}/include; ${GAT_SOURCE_DIR}/include/eigen3; ${GAT_SOURCE_DIR}/external; ${GAT_SOURCE_DIR}/external/cereal/include; ${GAT_SOURCE_DIR}/external/install/include; ${ZLIB_INCLUDE_DIR}; ${TBB_INCLUDE_DIRS}; ${Boost_INCLUDE_DIRS}; ${GAT_SOURCE_DIR}/external/install/include; ${GAT_SOURCE_DIR}/external/install/include/pufferfish; ${GAT_SOURCE_DIR}/external/install/include/pufferfish/digestpp; ${LIB_GFF_INCLUDE_DIR}; #${GAT_SOURCE_DIR}/external/install/include/rapmap; #${GAT_SOURCE_DIR}/external/install/include/rapmap/digestpp; ${ICU_INC_DIRS}; ). set ( SALMON_MAIN_SRCS; EMUtils.cpp; CollapsedEMOptimizer.cpp; ## PUFF_INTEGRATION; CollapsedCellOptimizer.cpp; ##; CollapsedGibbsSampler.cpp; Salmon.cpp; BuildSalmonIndex.cpp; Graph.cpp; ## PUFF_INTEGRATION; DedupUMI.cpp; Alevin.cpp; AlevinHash.cpp; SalmonAlevin.cpp; WhiteList.cpp; ##; SalmonQuantify.cpp; FragmentLengthDistribution.cpp; FragmentStartPositionDistribution.cpp; # SequenceBiasModel.cpp; GZipWriter.cpp; SalmonQuantMerge.cpp; ProgramOptionsGenerator.cpp; ). set (SALMON_ALIGN_SRCS; FASTAParser.cpp; AlignmentModel.cpp; ONTAlignmentModel.cpp; AlignmentCommon.cpp; FragmentLengthDistribution.cpp; SalmonQuantifyAlignments.cpp; BAMUtils.cpp; ). set (ALEVIN_LIB_SRCS; edlib.cpp; SingleCellProtocols.cpp; AlevinUtils.cpp; ). set (SALMON_LIB_SRCS; ${GAT_SOURCE_DIR}/src/jellyfish/mer_dna.cc; backtrace.cc; xxhash.c; TranscriptGroup.cpp; EffectiveLengthStats.cpp; LibraryFormat.cpp; GenomicFeature.cpp; VersionChecker.cpp; SBModel.cpp; FastxParser.cpp; StadenUtils.cpp; SalmonUtils.cpp; DistributionUtils.cpp; SalmonExceptions.cpp; SalmonStringUtils.cpp; SimplePosBias.cpp; SGSmooth.cpp; ${GAT_SOURCE_DIR}/external/install/src/pufferfish/metro/metrohash64.cpp; ). # check if we know how to do IPO; check_ipo_supported(RESULT HAS_IPO). if (DEFINED NO_IPO); message(""NO_IPO = ${NO_IPO}""); else(); message(""",MatchSource.DOCS,src/CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt:395,Deployability,install,install,395,"if(${TBB_FOUND}); get_target_property(TBB_INCLUDE_DIRS TBB::tbb INTERFACE_INCLUDE_DIRECTORIES); endif(). include_directories(; ${GAT_SOURCE_DIR}/include; ${GAT_SOURCE_DIR}/include/eigen3; ${GAT_SOURCE_DIR}/external; ${GAT_SOURCE_DIR}/external/cereal/include; ${GAT_SOURCE_DIR}/external/install/include; ${ZLIB_INCLUDE_DIR}; ${TBB_INCLUDE_DIRS}; ${Boost_INCLUDE_DIRS}; ${GAT_SOURCE_DIR}/external/install/include; ${GAT_SOURCE_DIR}/external/install/include/pufferfish; ${GAT_SOURCE_DIR}/external/install/include/pufferfish/digestpp; ${LIB_GFF_INCLUDE_DIR}; #${GAT_SOURCE_DIR}/external/install/include/rapmap; #${GAT_SOURCE_DIR}/external/install/include/rapmap/digestpp; ${ICU_INC_DIRS}; ). set ( SALMON_MAIN_SRCS; EMUtils.cpp; CollapsedEMOptimizer.cpp; ## PUFF_INTEGRATION; CollapsedCellOptimizer.cpp; ##; CollapsedGibbsSampler.cpp; Salmon.cpp; BuildSalmonIndex.cpp; Graph.cpp; ## PUFF_INTEGRATION; DedupUMI.cpp; Alevin.cpp; AlevinHash.cpp; SalmonAlevin.cpp; WhiteList.cpp; ##; SalmonQuantify.cpp; FragmentLengthDistribution.cpp; FragmentStartPositionDistribution.cpp; # SequenceBiasModel.cpp; GZipWriter.cpp; SalmonQuantMerge.cpp; ProgramOptionsGenerator.cpp; ). set (SALMON_ALIGN_SRCS; FASTAParser.cpp; AlignmentModel.cpp; ONTAlignmentModel.cpp; AlignmentCommon.cpp; FragmentLengthDistribution.cpp; SalmonQuantifyAlignments.cpp; BAMUtils.cpp; ). set (ALEVIN_LIB_SRCS; edlib.cpp; SingleCellProtocols.cpp; AlevinUtils.cpp; ). set (SALMON_LIB_SRCS; ${GAT_SOURCE_DIR}/src/jellyfish/mer_dna.cc; backtrace.cc; xxhash.c; TranscriptGroup.cpp; EffectiveLengthStats.cpp; LibraryFormat.cpp; GenomicFeature.cpp; VersionChecker.cpp; SBModel.cpp; FastxParser.cpp; StadenUtils.cpp; SalmonUtils.cpp; DistributionUtils.cpp; SalmonExceptions.cpp; SalmonStringUtils.cpp; SimplePosBias.cpp; SGSmooth.cpp; ${GAT_SOURCE_DIR}/external/install/src/pufferfish/metro/metrohash64.cpp; ). # check if we know how to do IPO; check_ipo_supported(RESULT HAS_IPO). if (DEFINED NO_IPO); message(""NO_IPO = ${NO_IPO}""); else(); message(""",MatchSource.DOCS,src/CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt:439,Deployability,install,install,439,"if(${TBB_FOUND}); get_target_property(TBB_INCLUDE_DIRS TBB::tbb INTERFACE_INCLUDE_DIRECTORIES); endif(). include_directories(; ${GAT_SOURCE_DIR}/include; ${GAT_SOURCE_DIR}/include/eigen3; ${GAT_SOURCE_DIR}/external; ${GAT_SOURCE_DIR}/external/cereal/include; ${GAT_SOURCE_DIR}/external/install/include; ${ZLIB_INCLUDE_DIR}; ${TBB_INCLUDE_DIRS}; ${Boost_INCLUDE_DIRS}; ${GAT_SOURCE_DIR}/external/install/include; ${GAT_SOURCE_DIR}/external/install/include/pufferfish; ${GAT_SOURCE_DIR}/external/install/include/pufferfish/digestpp; ${LIB_GFF_INCLUDE_DIR}; #${GAT_SOURCE_DIR}/external/install/include/rapmap; #${GAT_SOURCE_DIR}/external/install/include/rapmap/digestpp; ${ICU_INC_DIRS}; ). set ( SALMON_MAIN_SRCS; EMUtils.cpp; CollapsedEMOptimizer.cpp; ## PUFF_INTEGRATION; CollapsedCellOptimizer.cpp; ##; CollapsedGibbsSampler.cpp; Salmon.cpp; BuildSalmonIndex.cpp; Graph.cpp; ## PUFF_INTEGRATION; DedupUMI.cpp; Alevin.cpp; AlevinHash.cpp; SalmonAlevin.cpp; WhiteList.cpp; ##; SalmonQuantify.cpp; FragmentLengthDistribution.cpp; FragmentStartPositionDistribution.cpp; # SequenceBiasModel.cpp; GZipWriter.cpp; SalmonQuantMerge.cpp; ProgramOptionsGenerator.cpp; ). set (SALMON_ALIGN_SRCS; FASTAParser.cpp; AlignmentModel.cpp; ONTAlignmentModel.cpp; AlignmentCommon.cpp; FragmentLengthDistribution.cpp; SalmonQuantifyAlignments.cpp; BAMUtils.cpp; ). set (ALEVIN_LIB_SRCS; edlib.cpp; SingleCellProtocols.cpp; AlevinUtils.cpp; ). set (SALMON_LIB_SRCS; ${GAT_SOURCE_DIR}/src/jellyfish/mer_dna.cc; backtrace.cc; xxhash.c; TranscriptGroup.cpp; EffectiveLengthStats.cpp; LibraryFormat.cpp; GenomicFeature.cpp; VersionChecker.cpp; SBModel.cpp; FastxParser.cpp; StadenUtils.cpp; SalmonUtils.cpp; DistributionUtils.cpp; SalmonExceptions.cpp; SalmonStringUtils.cpp; SimplePosBias.cpp; SGSmooth.cpp; ${GAT_SOURCE_DIR}/external/install/src/pufferfish/metro/metrohash64.cpp; ). # check if we know how to do IPO; check_ipo_supported(RESULT HAS_IPO). if (DEFINED NO_IPO); message(""NO_IPO = ${NO_IPO}""); else(); message(""",MatchSource.DOCS,src/CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt:494,Deployability,install,install,494,"if(${TBB_FOUND}); get_target_property(TBB_INCLUDE_DIRS TBB::tbb INTERFACE_INCLUDE_DIRECTORIES); endif(). include_directories(; ${GAT_SOURCE_DIR}/include; ${GAT_SOURCE_DIR}/include/eigen3; ${GAT_SOURCE_DIR}/external; ${GAT_SOURCE_DIR}/external/cereal/include; ${GAT_SOURCE_DIR}/external/install/include; ${ZLIB_INCLUDE_DIR}; ${TBB_INCLUDE_DIRS}; ${Boost_INCLUDE_DIRS}; ${GAT_SOURCE_DIR}/external/install/include; ${GAT_SOURCE_DIR}/external/install/include/pufferfish; ${GAT_SOURCE_DIR}/external/install/include/pufferfish/digestpp; ${LIB_GFF_INCLUDE_DIR}; #${GAT_SOURCE_DIR}/external/install/include/rapmap; #${GAT_SOURCE_DIR}/external/install/include/rapmap/digestpp; ${ICU_INC_DIRS}; ). set ( SALMON_MAIN_SRCS; EMUtils.cpp; CollapsedEMOptimizer.cpp; ## PUFF_INTEGRATION; CollapsedCellOptimizer.cpp; ##; CollapsedGibbsSampler.cpp; Salmon.cpp; BuildSalmonIndex.cpp; Graph.cpp; ## PUFF_INTEGRATION; DedupUMI.cpp; Alevin.cpp; AlevinHash.cpp; SalmonAlevin.cpp; WhiteList.cpp; ##; SalmonQuantify.cpp; FragmentLengthDistribution.cpp; FragmentStartPositionDistribution.cpp; # SequenceBiasModel.cpp; GZipWriter.cpp; SalmonQuantMerge.cpp; ProgramOptionsGenerator.cpp; ). set (SALMON_ALIGN_SRCS; FASTAParser.cpp; AlignmentModel.cpp; ONTAlignmentModel.cpp; AlignmentCommon.cpp; FragmentLengthDistribution.cpp; SalmonQuantifyAlignments.cpp; BAMUtils.cpp; ). set (ALEVIN_LIB_SRCS; edlib.cpp; SingleCellProtocols.cpp; AlevinUtils.cpp; ). set (SALMON_LIB_SRCS; ${GAT_SOURCE_DIR}/src/jellyfish/mer_dna.cc; backtrace.cc; xxhash.c; TranscriptGroup.cpp; EffectiveLengthStats.cpp; LibraryFormat.cpp; GenomicFeature.cpp; VersionChecker.cpp; SBModel.cpp; FastxParser.cpp; StadenUtils.cpp; SalmonUtils.cpp; DistributionUtils.cpp; SalmonExceptions.cpp; SalmonStringUtils.cpp; SimplePosBias.cpp; SGSmooth.cpp; ${GAT_SOURCE_DIR}/external/install/src/pufferfish/metro/metrohash64.cpp; ). # check if we know how to do IPO; check_ipo_supported(RESULT HAS_IPO). if (DEFINED NO_IPO); message(""NO_IPO = ${NO_IPO}""); else(); message(""",MatchSource.DOCS,src/CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt:583,Deployability,install,install,583,"if(${TBB_FOUND}); get_target_property(TBB_INCLUDE_DIRS TBB::tbb INTERFACE_INCLUDE_DIRECTORIES); endif(). include_directories(; ${GAT_SOURCE_DIR}/include; ${GAT_SOURCE_DIR}/include/eigen3; ${GAT_SOURCE_DIR}/external; ${GAT_SOURCE_DIR}/external/cereal/include; ${GAT_SOURCE_DIR}/external/install/include; ${ZLIB_INCLUDE_DIR}; ${TBB_INCLUDE_DIRS}; ${Boost_INCLUDE_DIRS}; ${GAT_SOURCE_DIR}/external/install/include; ${GAT_SOURCE_DIR}/external/install/include/pufferfish; ${GAT_SOURCE_DIR}/external/install/include/pufferfish/digestpp; ${LIB_GFF_INCLUDE_DIR}; #${GAT_SOURCE_DIR}/external/install/include/rapmap; #${GAT_SOURCE_DIR}/external/install/include/rapmap/digestpp; ${ICU_INC_DIRS}; ). set ( SALMON_MAIN_SRCS; EMUtils.cpp; CollapsedEMOptimizer.cpp; ## PUFF_INTEGRATION; CollapsedCellOptimizer.cpp; ##; CollapsedGibbsSampler.cpp; Salmon.cpp; BuildSalmonIndex.cpp; Graph.cpp; ## PUFF_INTEGRATION; DedupUMI.cpp; Alevin.cpp; AlevinHash.cpp; SalmonAlevin.cpp; WhiteList.cpp; ##; SalmonQuantify.cpp; FragmentLengthDistribution.cpp; FragmentStartPositionDistribution.cpp; # SequenceBiasModel.cpp; GZipWriter.cpp; SalmonQuantMerge.cpp; ProgramOptionsGenerator.cpp; ). set (SALMON_ALIGN_SRCS; FASTAParser.cpp; AlignmentModel.cpp; ONTAlignmentModel.cpp; AlignmentCommon.cpp; FragmentLengthDistribution.cpp; SalmonQuantifyAlignments.cpp; BAMUtils.cpp; ). set (ALEVIN_LIB_SRCS; edlib.cpp; SingleCellProtocols.cpp; AlevinUtils.cpp; ). set (SALMON_LIB_SRCS; ${GAT_SOURCE_DIR}/src/jellyfish/mer_dna.cc; backtrace.cc; xxhash.c; TranscriptGroup.cpp; EffectiveLengthStats.cpp; LibraryFormat.cpp; GenomicFeature.cpp; VersionChecker.cpp; SBModel.cpp; FastxParser.cpp; StadenUtils.cpp; SalmonUtils.cpp; DistributionUtils.cpp; SalmonExceptions.cpp; SalmonStringUtils.cpp; SimplePosBias.cpp; SGSmooth.cpp; ${GAT_SOURCE_DIR}/external/install/src/pufferfish/metro/metrohash64.cpp; ). # check if we know how to do IPO; check_ipo_supported(RESULT HAS_IPO). if (DEFINED NO_IPO); message(""NO_IPO = ${NO_IPO}""); else(); message(""",MatchSource.DOCS,src/CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt:635,Deployability,install,install,635,"if(${TBB_FOUND}); get_target_property(TBB_INCLUDE_DIRS TBB::tbb INTERFACE_INCLUDE_DIRECTORIES); endif(). include_directories(; ${GAT_SOURCE_DIR}/include; ${GAT_SOURCE_DIR}/include/eigen3; ${GAT_SOURCE_DIR}/external; ${GAT_SOURCE_DIR}/external/cereal/include; ${GAT_SOURCE_DIR}/external/install/include; ${ZLIB_INCLUDE_DIR}; ${TBB_INCLUDE_DIRS}; ${Boost_INCLUDE_DIRS}; ${GAT_SOURCE_DIR}/external/install/include; ${GAT_SOURCE_DIR}/external/install/include/pufferfish; ${GAT_SOURCE_DIR}/external/install/include/pufferfish/digestpp; ${LIB_GFF_INCLUDE_DIR}; #${GAT_SOURCE_DIR}/external/install/include/rapmap; #${GAT_SOURCE_DIR}/external/install/include/rapmap/digestpp; ${ICU_INC_DIRS}; ). set ( SALMON_MAIN_SRCS; EMUtils.cpp; CollapsedEMOptimizer.cpp; ## PUFF_INTEGRATION; CollapsedCellOptimizer.cpp; ##; CollapsedGibbsSampler.cpp; Salmon.cpp; BuildSalmonIndex.cpp; Graph.cpp; ## PUFF_INTEGRATION; DedupUMI.cpp; Alevin.cpp; AlevinHash.cpp; SalmonAlevin.cpp; WhiteList.cpp; ##; SalmonQuantify.cpp; FragmentLengthDistribution.cpp; FragmentStartPositionDistribution.cpp; # SequenceBiasModel.cpp; GZipWriter.cpp; SalmonQuantMerge.cpp; ProgramOptionsGenerator.cpp; ). set (SALMON_ALIGN_SRCS; FASTAParser.cpp; AlignmentModel.cpp; ONTAlignmentModel.cpp; AlignmentCommon.cpp; FragmentLengthDistribution.cpp; SalmonQuantifyAlignments.cpp; BAMUtils.cpp; ). set (ALEVIN_LIB_SRCS; edlib.cpp; SingleCellProtocols.cpp; AlevinUtils.cpp; ). set (SALMON_LIB_SRCS; ${GAT_SOURCE_DIR}/src/jellyfish/mer_dna.cc; backtrace.cc; xxhash.c; TranscriptGroup.cpp; EffectiveLengthStats.cpp; LibraryFormat.cpp; GenomicFeature.cpp; VersionChecker.cpp; SBModel.cpp; FastxParser.cpp; StadenUtils.cpp; SalmonUtils.cpp; DistributionUtils.cpp; SalmonExceptions.cpp; SalmonStringUtils.cpp; SimplePosBias.cpp; SGSmooth.cpp; ${GAT_SOURCE_DIR}/external/install/src/pufferfish/metro/metrohash64.cpp; ). # check if we know how to do IPO; check_ipo_supported(RESULT HAS_IPO). if (DEFINED NO_IPO); message(""NO_IPO = ${NO_IPO}""); else(); message(""",MatchSource.DOCS,src/CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt:1812,Deployability,install,install,1812,"bsSampler.cpp; Salmon.cpp; BuildSalmonIndex.cpp; Graph.cpp; ## PUFF_INTEGRATION; DedupUMI.cpp; Alevin.cpp; AlevinHash.cpp; SalmonAlevin.cpp; WhiteList.cpp; ##; SalmonQuantify.cpp; FragmentLengthDistribution.cpp; FragmentStartPositionDistribution.cpp; # SequenceBiasModel.cpp; GZipWriter.cpp; SalmonQuantMerge.cpp; ProgramOptionsGenerator.cpp; ). set (SALMON_ALIGN_SRCS; FASTAParser.cpp; AlignmentModel.cpp; ONTAlignmentModel.cpp; AlignmentCommon.cpp; FragmentLengthDistribution.cpp; SalmonQuantifyAlignments.cpp; BAMUtils.cpp; ). set (ALEVIN_LIB_SRCS; edlib.cpp; SingleCellProtocols.cpp; AlevinUtils.cpp; ). set (SALMON_LIB_SRCS; ${GAT_SOURCE_DIR}/src/jellyfish/mer_dna.cc; backtrace.cc; xxhash.c; TranscriptGroup.cpp; EffectiveLengthStats.cpp; LibraryFormat.cpp; GenomicFeature.cpp; VersionChecker.cpp; SBModel.cpp; FastxParser.cpp; StadenUtils.cpp; SalmonUtils.cpp; DistributionUtils.cpp; SalmonExceptions.cpp; SalmonStringUtils.cpp; SimplePosBias.cpp; SGSmooth.cpp; ${GAT_SOURCE_DIR}/external/install/src/pufferfish/metro/metrohash64.cpp; ). # check if we know how to do IPO; check_ipo_supported(RESULT HAS_IPO). if (DEFINED NO_IPO); message(""NO_IPO = ${NO_IPO}""); else(); message(""NO_IPO = FALSE""); set(NO_IPO FALSE); endif(). if(HAS_IPO AND (NOT NO_IPO)); set_property(TARGET ksw2pp PROPERTY INTERPROCEDURAL_OPTIMIZATION True); endif(). set (UNIT_TESTS_ENTRY_SRCS; ${GAT_SOURCE_DIR}/tests/UnitTests.cpp; ). set (UNIT_TESTS_INDIVIDUAL_SRCS; ${GAT_SOURCE_DIR}/src/FragmentLengthDistribution.cpp; ${GAT_SOURCE_DIR}/external/install/src/pufferfish/rank9b.cpp; ${GAT_SOURCE_DIR}/tests/GCSampleTests.cpp; ${GAT_SOURCE_DIR}/tests/LibraryTypeTests.cpp; ). link_directories(; ${GAT_SOURCE_DIR}/lib; ${GAT_SOURCE_DIR}/external/install/lib; ${Boost_LIBRARY_DIRS}; ${TBB_LIBRARY_DIRS}; ${LAPACK_LIBRARY_DIR}; ${BLAS_LIBRARY_DIR}; ${LIB_GFF_LIBRARY_DIR}; ). message(""TBB_LIBRARIES = ${TBB_LIBRARIES}""). # Set the RPATH; if (NOT APPLE); set(CMAKE_INSTALL_RPATH ""$ORIGIN/../lib:$ORIGIN/../../lib:$ORIGIN/:$ORIGI",MatchSource.DOCS,src/CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt:2342,Deployability,install,install,2342,"; ). set (ALEVIN_LIB_SRCS; edlib.cpp; SingleCellProtocols.cpp; AlevinUtils.cpp; ). set (SALMON_LIB_SRCS; ${GAT_SOURCE_DIR}/src/jellyfish/mer_dna.cc; backtrace.cc; xxhash.c; TranscriptGroup.cpp; EffectiveLengthStats.cpp; LibraryFormat.cpp; GenomicFeature.cpp; VersionChecker.cpp; SBModel.cpp; FastxParser.cpp; StadenUtils.cpp; SalmonUtils.cpp; DistributionUtils.cpp; SalmonExceptions.cpp; SalmonStringUtils.cpp; SimplePosBias.cpp; SGSmooth.cpp; ${GAT_SOURCE_DIR}/external/install/src/pufferfish/metro/metrohash64.cpp; ). # check if we know how to do IPO; check_ipo_supported(RESULT HAS_IPO). if (DEFINED NO_IPO); message(""NO_IPO = ${NO_IPO}""); else(); message(""NO_IPO = FALSE""); set(NO_IPO FALSE); endif(). if(HAS_IPO AND (NOT NO_IPO)); set_property(TARGET ksw2pp PROPERTY INTERPROCEDURAL_OPTIMIZATION True); endif(). set (UNIT_TESTS_ENTRY_SRCS; ${GAT_SOURCE_DIR}/tests/UnitTests.cpp; ). set (UNIT_TESTS_INDIVIDUAL_SRCS; ${GAT_SOURCE_DIR}/src/FragmentLengthDistribution.cpp; ${GAT_SOURCE_DIR}/external/install/src/pufferfish/rank9b.cpp; ${GAT_SOURCE_DIR}/tests/GCSampleTests.cpp; ${GAT_SOURCE_DIR}/tests/LibraryTypeTests.cpp; ). link_directories(; ${GAT_SOURCE_DIR}/lib; ${GAT_SOURCE_DIR}/external/install/lib; ${Boost_LIBRARY_DIRS}; ${TBB_LIBRARY_DIRS}; ${LAPACK_LIBRARY_DIR}; ${BLAS_LIBRARY_DIR}; ${LIB_GFF_LIBRARY_DIR}; ). message(""TBB_LIBRARIES = ${TBB_LIBRARIES}""). # Set the RPATH; if (NOT APPLE); set(CMAKE_INSTALL_RPATH ""$ORIGIN/../lib:$ORIGIN/../../lib:$ORIGIN/:$ORIGIN/../../external/install/lib""); set(CMAKE_BUILD_WITH_INSTALL_RPATH TRUE); else(); # use, i.e. do not skip the full RPATH for the build tree; set(CMAKE_SKIP_BUILD_RPATH FALSE). # when building, don't use the install RPATH already; # (but later on when installing); set(CMAKE_BUILD_WITH_INSTALL_RPATH FALSE) . # the RPATH to be used when installing; set(CMAKE_INSTALL_RPATH """"). # don't add the automatically determined parts of the RPATH; # which point to directories outside the build tree to the install RPATH; set(CMAKE_IN",MatchSource.DOCS,src/CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt:2538,Deployability,install,install,2538,"ryFormat.cpp; GenomicFeature.cpp; VersionChecker.cpp; SBModel.cpp; FastxParser.cpp; StadenUtils.cpp; SalmonUtils.cpp; DistributionUtils.cpp; SalmonExceptions.cpp; SalmonStringUtils.cpp; SimplePosBias.cpp; SGSmooth.cpp; ${GAT_SOURCE_DIR}/external/install/src/pufferfish/metro/metrohash64.cpp; ). # check if we know how to do IPO; check_ipo_supported(RESULT HAS_IPO). if (DEFINED NO_IPO); message(""NO_IPO = ${NO_IPO}""); else(); message(""NO_IPO = FALSE""); set(NO_IPO FALSE); endif(). if(HAS_IPO AND (NOT NO_IPO)); set_property(TARGET ksw2pp PROPERTY INTERPROCEDURAL_OPTIMIZATION True); endif(). set (UNIT_TESTS_ENTRY_SRCS; ${GAT_SOURCE_DIR}/tests/UnitTests.cpp; ). set (UNIT_TESTS_INDIVIDUAL_SRCS; ${GAT_SOURCE_DIR}/src/FragmentLengthDistribution.cpp; ${GAT_SOURCE_DIR}/external/install/src/pufferfish/rank9b.cpp; ${GAT_SOURCE_DIR}/tests/GCSampleTests.cpp; ${GAT_SOURCE_DIR}/tests/LibraryTypeTests.cpp; ). link_directories(; ${GAT_SOURCE_DIR}/lib; ${GAT_SOURCE_DIR}/external/install/lib; ${Boost_LIBRARY_DIRS}; ${TBB_LIBRARY_DIRS}; ${LAPACK_LIBRARY_DIR}; ${BLAS_LIBRARY_DIR}; ${LIB_GFF_LIBRARY_DIR}; ). message(""TBB_LIBRARIES = ${TBB_LIBRARIES}""). # Set the RPATH; if (NOT APPLE); set(CMAKE_INSTALL_RPATH ""$ORIGIN/../lib:$ORIGIN/../../lib:$ORIGIN/:$ORIGIN/../../external/install/lib""); set(CMAKE_BUILD_WITH_INSTALL_RPATH TRUE); else(); # use, i.e. do not skip the full RPATH for the build tree; set(CMAKE_SKIP_BUILD_RPATH FALSE). # when building, don't use the install RPATH already; # (but later on when installing); set(CMAKE_BUILD_WITH_INSTALL_RPATH FALSE) . # the RPATH to be used when installing; set(CMAKE_INSTALL_RPATH """"). # don't add the automatically determined parts of the RPATH; # which point to directories outside the build tree to the install RPATH; set(CMAKE_INSTALL_RPATH_USE_LINK_PATH FALSE); endif(). set (TGT_RELEASE_FLAGS ""${TGT_COMPILE_FLAGS};${TGT_WARN_FLAGS}""); set (TGT_DEBUG_FLAGS ""-g;${TGT_COMPILE_FLAGS};${TGT_WARN_FLAGS}""). # Build the Salmon library; add_library(salmon_cor",MatchSource.DOCS,src/CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt:2834,Deployability,install,install,2834,"ck if we know how to do IPO; check_ipo_supported(RESULT HAS_IPO). if (DEFINED NO_IPO); message(""NO_IPO = ${NO_IPO}""); else(); message(""NO_IPO = FALSE""); set(NO_IPO FALSE); endif(). if(HAS_IPO AND (NOT NO_IPO)); set_property(TARGET ksw2pp PROPERTY INTERPROCEDURAL_OPTIMIZATION True); endif(). set (UNIT_TESTS_ENTRY_SRCS; ${GAT_SOURCE_DIR}/tests/UnitTests.cpp; ). set (UNIT_TESTS_INDIVIDUAL_SRCS; ${GAT_SOURCE_DIR}/src/FragmentLengthDistribution.cpp; ${GAT_SOURCE_DIR}/external/install/src/pufferfish/rank9b.cpp; ${GAT_SOURCE_DIR}/tests/GCSampleTests.cpp; ${GAT_SOURCE_DIR}/tests/LibraryTypeTests.cpp; ). link_directories(; ${GAT_SOURCE_DIR}/lib; ${GAT_SOURCE_DIR}/external/install/lib; ${Boost_LIBRARY_DIRS}; ${TBB_LIBRARY_DIRS}; ${LAPACK_LIBRARY_DIR}; ${BLAS_LIBRARY_DIR}; ${LIB_GFF_LIBRARY_DIR}; ). message(""TBB_LIBRARIES = ${TBB_LIBRARIES}""). # Set the RPATH; if (NOT APPLE); set(CMAKE_INSTALL_RPATH ""$ORIGIN/../lib:$ORIGIN/../../lib:$ORIGIN/:$ORIGIN/../../external/install/lib""); set(CMAKE_BUILD_WITH_INSTALL_RPATH TRUE); else(); # use, i.e. do not skip the full RPATH for the build tree; set(CMAKE_SKIP_BUILD_RPATH FALSE). # when building, don't use the install RPATH already; # (but later on when installing); set(CMAKE_BUILD_WITH_INSTALL_RPATH FALSE) . # the RPATH to be used when installing; set(CMAKE_INSTALL_RPATH """"). # don't add the automatically determined parts of the RPATH; # which point to directories outside the build tree to the install RPATH; set(CMAKE_INSTALL_RPATH_USE_LINK_PATH FALSE); endif(). set (TGT_RELEASE_FLAGS ""${TGT_COMPILE_FLAGS};${TGT_WARN_FLAGS}""); set (TGT_DEBUG_FLAGS ""-g;${TGT_COMPILE_FLAGS};${TGT_WARN_FLAGS}""). # Build the Salmon library; add_library(salmon_core STATIC ${SALMON_LIB_SRCS} ); target_compile_definitions(salmon_core PUBLIC; RAPMAP_SALMON_SUPPORT=1; PUFFERFISH_SALMON_SUPPORT=1; HAVE_ANSI_TERM=1; HAVE_SSTREAM=1; STX_NO_STD_STRING_VIEW=1; span_FEATURE_MAKE_SPAN_TO_STD=14; ); target_include_directories(salmon_core PUBLIC ${COMPACT_VECTOR_INCLUDE",MatchSource.DOCS,src/CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt:3024,Deployability,install,install,3024,"AND (NOT NO_IPO)); set_property(TARGET ksw2pp PROPERTY INTERPROCEDURAL_OPTIMIZATION True); endif(). set (UNIT_TESTS_ENTRY_SRCS; ${GAT_SOURCE_DIR}/tests/UnitTests.cpp; ). set (UNIT_TESTS_INDIVIDUAL_SRCS; ${GAT_SOURCE_DIR}/src/FragmentLengthDistribution.cpp; ${GAT_SOURCE_DIR}/external/install/src/pufferfish/rank9b.cpp; ${GAT_SOURCE_DIR}/tests/GCSampleTests.cpp; ${GAT_SOURCE_DIR}/tests/LibraryTypeTests.cpp; ). link_directories(; ${GAT_SOURCE_DIR}/lib; ${GAT_SOURCE_DIR}/external/install/lib; ${Boost_LIBRARY_DIRS}; ${TBB_LIBRARY_DIRS}; ${LAPACK_LIBRARY_DIR}; ${BLAS_LIBRARY_DIR}; ${LIB_GFF_LIBRARY_DIR}; ). message(""TBB_LIBRARIES = ${TBB_LIBRARIES}""). # Set the RPATH; if (NOT APPLE); set(CMAKE_INSTALL_RPATH ""$ORIGIN/../lib:$ORIGIN/../../lib:$ORIGIN/:$ORIGIN/../../external/install/lib""); set(CMAKE_BUILD_WITH_INSTALL_RPATH TRUE); else(); # use, i.e. do not skip the full RPATH for the build tree; set(CMAKE_SKIP_BUILD_RPATH FALSE). # when building, don't use the install RPATH already; # (but later on when installing); set(CMAKE_BUILD_WITH_INSTALL_RPATH FALSE) . # the RPATH to be used when installing; set(CMAKE_INSTALL_RPATH """"). # don't add the automatically determined parts of the RPATH; # which point to directories outside the build tree to the install RPATH; set(CMAKE_INSTALL_RPATH_USE_LINK_PATH FALSE); endif(). set (TGT_RELEASE_FLAGS ""${TGT_COMPILE_FLAGS};${TGT_WARN_FLAGS}""); set (TGT_DEBUG_FLAGS ""-g;${TGT_COMPILE_FLAGS};${TGT_WARN_FLAGS}""). # Build the Salmon library; add_library(salmon_core STATIC ${SALMON_LIB_SRCS} ); target_compile_definitions(salmon_core PUBLIC; RAPMAP_SALMON_SUPPORT=1; PUFFERFISH_SALMON_SUPPORT=1; HAVE_ANSI_TERM=1; HAVE_SSTREAM=1; STX_NO_STD_STRING_VIEW=1; span_FEATURE_MAKE_SPAN_TO_STD=14; ); target_include_directories(salmon_core PUBLIC ${COMPACT_VECTOR_INCLUDE_PATH}). if (USE_ARM); target_compile_definitions(salmon_core PUBLIC KSW_USE_ARM=1); endif(). target_compile_options(salmon_core PUBLIC ""$<$<CONFIG:DEBUG>:${TGT_DEBUG_FLAGS}>""); target_compile",MatchSource.DOCS,src/CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt:3068,Deployability,install,installing,3068,"AND (NOT NO_IPO)); set_property(TARGET ksw2pp PROPERTY INTERPROCEDURAL_OPTIMIZATION True); endif(). set (UNIT_TESTS_ENTRY_SRCS; ${GAT_SOURCE_DIR}/tests/UnitTests.cpp; ). set (UNIT_TESTS_INDIVIDUAL_SRCS; ${GAT_SOURCE_DIR}/src/FragmentLengthDistribution.cpp; ${GAT_SOURCE_DIR}/external/install/src/pufferfish/rank9b.cpp; ${GAT_SOURCE_DIR}/tests/GCSampleTests.cpp; ${GAT_SOURCE_DIR}/tests/LibraryTypeTests.cpp; ). link_directories(; ${GAT_SOURCE_DIR}/lib; ${GAT_SOURCE_DIR}/external/install/lib; ${Boost_LIBRARY_DIRS}; ${TBB_LIBRARY_DIRS}; ${LAPACK_LIBRARY_DIR}; ${BLAS_LIBRARY_DIR}; ${LIB_GFF_LIBRARY_DIR}; ). message(""TBB_LIBRARIES = ${TBB_LIBRARIES}""). # Set the RPATH; if (NOT APPLE); set(CMAKE_INSTALL_RPATH ""$ORIGIN/../lib:$ORIGIN/../../lib:$ORIGIN/:$ORIGIN/../../external/install/lib""); set(CMAKE_BUILD_WITH_INSTALL_RPATH TRUE); else(); # use, i.e. do not skip the full RPATH for the build tree; set(CMAKE_SKIP_BUILD_RPATH FALSE). # when building, don't use the install RPATH already; # (but later on when installing); set(CMAKE_BUILD_WITH_INSTALL_RPATH FALSE) . # the RPATH to be used when installing; set(CMAKE_INSTALL_RPATH """"). # don't add the automatically determined parts of the RPATH; # which point to directories outside the build tree to the install RPATH; set(CMAKE_INSTALL_RPATH_USE_LINK_PATH FALSE); endif(). set (TGT_RELEASE_FLAGS ""${TGT_COMPILE_FLAGS};${TGT_WARN_FLAGS}""); set (TGT_DEBUG_FLAGS ""-g;${TGT_COMPILE_FLAGS};${TGT_WARN_FLAGS}""). # Build the Salmon library; add_library(salmon_core STATIC ${SALMON_LIB_SRCS} ); target_compile_definitions(salmon_core PUBLIC; RAPMAP_SALMON_SUPPORT=1; PUFFERFISH_SALMON_SUPPORT=1; HAVE_ANSI_TERM=1; HAVE_SSTREAM=1; STX_NO_STD_STRING_VIEW=1; span_FEATURE_MAKE_SPAN_TO_STD=14; ); target_include_directories(salmon_core PUBLIC ${COMPACT_VECTOR_INCLUDE_PATH}). if (USE_ARM); target_compile_definitions(salmon_core PUBLIC KSW_USE_ARM=1); endif(). target_compile_options(salmon_core PUBLIC ""$<$<CONFIG:DEBUG>:${TGT_DEBUG_FLAGS}>""); target_compile",MatchSource.DOCS,src/CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt:3153,Deployability,install,installing,3153,"set (UNIT_TESTS_ENTRY_SRCS; ${GAT_SOURCE_DIR}/tests/UnitTests.cpp; ). set (UNIT_TESTS_INDIVIDUAL_SRCS; ${GAT_SOURCE_DIR}/src/FragmentLengthDistribution.cpp; ${GAT_SOURCE_DIR}/external/install/src/pufferfish/rank9b.cpp; ${GAT_SOURCE_DIR}/tests/GCSampleTests.cpp; ${GAT_SOURCE_DIR}/tests/LibraryTypeTests.cpp; ). link_directories(; ${GAT_SOURCE_DIR}/lib; ${GAT_SOURCE_DIR}/external/install/lib; ${Boost_LIBRARY_DIRS}; ${TBB_LIBRARY_DIRS}; ${LAPACK_LIBRARY_DIR}; ${BLAS_LIBRARY_DIR}; ${LIB_GFF_LIBRARY_DIR}; ). message(""TBB_LIBRARIES = ${TBB_LIBRARIES}""). # Set the RPATH; if (NOT APPLE); set(CMAKE_INSTALL_RPATH ""$ORIGIN/../lib:$ORIGIN/../../lib:$ORIGIN/:$ORIGIN/../../external/install/lib""); set(CMAKE_BUILD_WITH_INSTALL_RPATH TRUE); else(); # use, i.e. do not skip the full RPATH for the build tree; set(CMAKE_SKIP_BUILD_RPATH FALSE). # when building, don't use the install RPATH already; # (but later on when installing); set(CMAKE_BUILD_WITH_INSTALL_RPATH FALSE) . # the RPATH to be used when installing; set(CMAKE_INSTALL_RPATH """"). # don't add the automatically determined parts of the RPATH; # which point to directories outside the build tree to the install RPATH; set(CMAKE_INSTALL_RPATH_USE_LINK_PATH FALSE); endif(). set (TGT_RELEASE_FLAGS ""${TGT_COMPILE_FLAGS};${TGT_WARN_FLAGS}""); set (TGT_DEBUG_FLAGS ""-g;${TGT_COMPILE_FLAGS};${TGT_WARN_FLAGS}""). # Build the Salmon library; add_library(salmon_core STATIC ${SALMON_LIB_SRCS} ); target_compile_definitions(salmon_core PUBLIC; RAPMAP_SALMON_SUPPORT=1; PUFFERFISH_SALMON_SUPPORT=1; HAVE_ANSI_TERM=1; HAVE_SSTREAM=1; STX_NO_STD_STRING_VIEW=1; span_FEATURE_MAKE_SPAN_TO_STD=14; ); target_include_directories(salmon_core PUBLIC ${COMPACT_VECTOR_INCLUDE_PATH}). if (USE_ARM); target_compile_definitions(salmon_core PUBLIC KSW_USE_ARM=1); endif(). target_compile_options(salmon_core PUBLIC ""$<$<CONFIG:DEBUG>:${TGT_DEBUG_FLAGS}>""); target_compile_options(salmon_core PUBLIC ""$<$<CONFIG:RELEASE>:${TGT_RELEASE_FLAGS}>""); if(HAS_IPO AND (NOT NO_IPO)",MatchSource.DOCS,src/CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt:3314,Deployability,install,install,3314,"entLengthDistribution.cpp; ${GAT_SOURCE_DIR}/external/install/src/pufferfish/rank9b.cpp; ${GAT_SOURCE_DIR}/tests/GCSampleTests.cpp; ${GAT_SOURCE_DIR}/tests/LibraryTypeTests.cpp; ). link_directories(; ${GAT_SOURCE_DIR}/lib; ${GAT_SOURCE_DIR}/external/install/lib; ${Boost_LIBRARY_DIRS}; ${TBB_LIBRARY_DIRS}; ${LAPACK_LIBRARY_DIR}; ${BLAS_LIBRARY_DIR}; ${LIB_GFF_LIBRARY_DIR}; ). message(""TBB_LIBRARIES = ${TBB_LIBRARIES}""). # Set the RPATH; if (NOT APPLE); set(CMAKE_INSTALL_RPATH ""$ORIGIN/../lib:$ORIGIN/../../lib:$ORIGIN/:$ORIGIN/../../external/install/lib""); set(CMAKE_BUILD_WITH_INSTALL_RPATH TRUE); else(); # use, i.e. do not skip the full RPATH for the build tree; set(CMAKE_SKIP_BUILD_RPATH FALSE). # when building, don't use the install RPATH already; # (but later on when installing); set(CMAKE_BUILD_WITH_INSTALL_RPATH FALSE) . # the RPATH to be used when installing; set(CMAKE_INSTALL_RPATH """"). # don't add the automatically determined parts of the RPATH; # which point to directories outside the build tree to the install RPATH; set(CMAKE_INSTALL_RPATH_USE_LINK_PATH FALSE); endif(). set (TGT_RELEASE_FLAGS ""${TGT_COMPILE_FLAGS};${TGT_WARN_FLAGS}""); set (TGT_DEBUG_FLAGS ""-g;${TGT_COMPILE_FLAGS};${TGT_WARN_FLAGS}""). # Build the Salmon library; add_library(salmon_core STATIC ${SALMON_LIB_SRCS} ); target_compile_definitions(salmon_core PUBLIC; RAPMAP_SALMON_SUPPORT=1; PUFFERFISH_SALMON_SUPPORT=1; HAVE_ANSI_TERM=1; HAVE_SSTREAM=1; STX_NO_STD_STRING_VIEW=1; span_FEATURE_MAKE_SPAN_TO_STD=14; ); target_include_directories(salmon_core PUBLIC ${COMPACT_VECTOR_INCLUDE_PATH}). if (USE_ARM); target_compile_definitions(salmon_core PUBLIC KSW_USE_ARM=1); endif(). target_compile_options(salmon_core PUBLIC ""$<$<CONFIG:DEBUG>:${TGT_DEBUG_FLAGS}>""); target_compile_options(salmon_core PUBLIC ""$<$<CONFIG:RELEASE>:${TGT_RELEASE_FLAGS}>""); if(HAS_IPO AND (NOT NO_IPO)); set_property(TARGET salmon_core PROPERTY INTERPROCEDURAL_OPTIMIZATION True); endif(). # Build the Alevin library; # PUFF_INTEG",MatchSource.DOCS,src/CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt:6258,Deployability,install,install,6258,"TERPROCEDURAL_OPTIMIZATION True); endif(). add_library(UnitTestsMain STATIC ${UNIT_TESTS_ENTRY_SRCS}); target_compile_options(UnitTestsMain PUBLIC ""$<$<CONFIG:DEBUG>:${TGT_DEBUG_FLAGS}>""); target_compile_options(UnitTestsMain PUBLIC ""$<$<CONFIG:RELEASE>:${TGT_RELEASE_FLAGS}>""). add_executable(unitTests ${UNIT_TESTS_INDIVIDUAL_SRCS} ${GAT_SOURCE_DIR}/tests/catch.hpp); target_compile_options(unitTests PUBLIC ""$<$<CONFIG:DEBUG>:${TGT_DEBUG_FLAGS}>""); target_compile_options(unitTests PUBLIC ""$<$<CONFIG:RELEASE>:${TGT_RELEASE_FLAGS}>""); target_include_directories(unitTests PUBLIC ${COMPACT_VECTOR_INCLUDE_PATH}). #add_executable(salmon-read ${SALMON_READ_SRCS}); #set_target_properties(salmon-read PROPERTIES COMPILE_FLAGS ""${CMAKE_CXX_FLAGS} -DHAVE_LIBPTHREAD -D_PBGZF_USE -fopenmp""; # LINK_FLAGS ""-DHAVE_LIBPTHREAD -D_PBGZF_USE -fopenmp""). #set_target_properties(salmon_core salmon PROPERTIES LINK_SEARCH_END_STATIC TRUE). # our suffix array construction libraries; #if(NOT LIBDIVSUFSORT_FOUND); # set (SUFFARRAY_LIB ${GAT_SOURCE_DIR}/external/install/lib/libdivsufsort.a); # set (SUFFARRAY_LIB64 ${GAT_SOURCE_DIR}/external/install/lib/libdivsufsort64.a); # message (""Setting libdivsufsort = ${SUFFARRAY_LIB}"") ; # message (""Setting libdivsufsort64 = ${SUFFARRAY_LIB64}"") ; #endif(). add_dependencies(salmon puffer); add_dependencies(salmon twopaco); add_dependencies(salmon graphdump); add_dependencies(salmon ntcard); add_dependencies(salmon ksw2pp); add_dependencies(salmon salmon_core); add_dependencies(salmon alevin_core); if(TBB_RECONFIGURE OR TBB_TARGET_EXISTED). # Link the executable; target_link_libraries(salmon; Threads::Threads ; puffer ; salmon_core; twopaco; graphdump; ntcard; gff; ${Boost_LIBRARIES}; ${ICU_LIBS}; ${CURL_LIBRARIES}; ${ZLIB_LIBRARY}; m; ${STADEN_LIBRARIES} ; ${LIBLZMA_LIBRARIES}; ${BZIP2_LIBRARIES}; ${LIBSALMON_LINKER_FLAGS}; ${NON_APPLECLANG_LIBS}; ksw2pp; alevin_core; ${ASAN_LIB}; ${FAST_MALLOC_LIB}; TBB::tbb; TBB::tbbmalloc; ${LIBRT}; ${CMAKE_DL_LIBS}; );",MatchSource.DOCS,src/CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt:6338,Deployability,install,install,6338,"le_options(UnitTestsMain PUBLIC ""$<$<CONFIG:DEBUG>:${TGT_DEBUG_FLAGS}>""); target_compile_options(UnitTestsMain PUBLIC ""$<$<CONFIG:RELEASE>:${TGT_RELEASE_FLAGS}>""). add_executable(unitTests ${UNIT_TESTS_INDIVIDUAL_SRCS} ${GAT_SOURCE_DIR}/tests/catch.hpp); target_compile_options(unitTests PUBLIC ""$<$<CONFIG:DEBUG>:${TGT_DEBUG_FLAGS}>""); target_compile_options(unitTests PUBLIC ""$<$<CONFIG:RELEASE>:${TGT_RELEASE_FLAGS}>""); target_include_directories(unitTests PUBLIC ${COMPACT_VECTOR_INCLUDE_PATH}). #add_executable(salmon-read ${SALMON_READ_SRCS}); #set_target_properties(salmon-read PROPERTIES COMPILE_FLAGS ""${CMAKE_CXX_FLAGS} -DHAVE_LIBPTHREAD -D_PBGZF_USE -fopenmp""; # LINK_FLAGS ""-DHAVE_LIBPTHREAD -D_PBGZF_USE -fopenmp""). #set_target_properties(salmon_core salmon PROPERTIES LINK_SEARCH_END_STATIC TRUE). # our suffix array construction libraries; #if(NOT LIBDIVSUFSORT_FOUND); # set (SUFFARRAY_LIB ${GAT_SOURCE_DIR}/external/install/lib/libdivsufsort.a); # set (SUFFARRAY_LIB64 ${GAT_SOURCE_DIR}/external/install/lib/libdivsufsort64.a); # message (""Setting libdivsufsort = ${SUFFARRAY_LIB}"") ; # message (""Setting libdivsufsort64 = ${SUFFARRAY_LIB64}"") ; #endif(). add_dependencies(salmon puffer); add_dependencies(salmon twopaco); add_dependencies(salmon graphdump); add_dependencies(salmon ntcard); add_dependencies(salmon ksw2pp); add_dependencies(salmon salmon_core); add_dependencies(salmon alevin_core); if(TBB_RECONFIGURE OR TBB_TARGET_EXISTED). # Link the executable; target_link_libraries(salmon; Threads::Threads ; puffer ; salmon_core; twopaco; graphdump; ntcard; gff; ${Boost_LIBRARIES}; ${ICU_LIBS}; ${CURL_LIBRARIES}; ${ZLIB_LIBRARY}; m; ${STADEN_LIBRARIES} ; ${LIBLZMA_LIBRARIES}; ${BZIP2_LIBRARIES}; ${LIBSALMON_LINKER_FLAGS}; ${NON_APPLECLANG_LIBS}; ksw2pp; alevin_core; ${ASAN_LIB}; ${FAST_MALLOC_LIB}; TBB::tbb; TBB::tbbmalloc; ${LIBRT}; ${CMAKE_DL_LIBS}; ); endif(). # dependencies for unitTests; add_dependencies(salmon salmon_core); add_dependencies(salmon alevin_core);",MatchSource.DOCS,src/CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt:9567,Deployability,install,install,9567,"e libboost); add_dependencies(salmon_core libboost); add_dependencies(salmon libboost); endif(). if (${FETCHED_TBB}); message(""Fetched oneTBB, so libtbb must be a dependency for targets""); add_dependencies(alevin_core libtbb); add_dependencies(salmon_core libtbb); add_dependencies(unitTests libtbb); add_dependencies(salmon libtbb); endif(). if (${FETCHED_CEREAL}); add_dependencies(alevin_core libcereal); add_dependencies(salmon_core libcereal); add_dependencies(salmon libcereal); endif(). if (${FETCHED_STADEN}); ## PUFF_INTEGRATION; # add_dependencies(alevin_core libstadenio); add_dependencies(alevin_core libstadenio); add_dependencies(salmon_core libstadenio); add_dependencies(salmon libstadenio); endif(). #add_dependencies(salmon_core libbwa); #add_dependencies(salmon libbwa). if (${FETCHED_GFF}); add_dependencies(alevin_core libgff); add_dependencies(salmon_core libgff); add_dependencies(salmon libgff); endif(). ### No need for this, I think; ## This ensures that the salmon executable should work with or without `make install`; ###; ## Grumble grumble . . . OSX; #if (APPLE); # # only attempt install_name_tool for tbb if we installed it; # if (${TBB_LIBRARY_DIRS} MATCHES ${GAT_SOURCE_DIR}/external/install/lib); # add_custom_command(TARGET salmon; # POST_BUILD; # COMMAND install_name_tool -change libtbb.dylib @rpath/libtbb.dylib ${GAT_SOURCE_DIR}/build/src/salmon; # COMMAND install_name_tool -change libtbbmalloc.dylib @rpath/libtbbmalloc.dylib ${GAT_SOURCE_DIR}/build/src/salmon; # COMMAND install_name_tool -change libtbbmalloc_proxy.dylib @rpath/libtbbmalloc_proxy.dylib ${GAT_SOURCE_DIR}/build/src/salmon; # COMMAND install_name_tool -add_rpath ${GAT_SOURCE_DIR}/external/install/lib ${GAT_SOURCE_DIR}/build/src/salmon; # ); # add_custom_command(TARGET unitTests; # POST_BUILD; # COMMAND install_name_tool -change libtbb.dylib @rpath/libtbb.dylib ${GAT_SOURCE_DIR}/build/src/unitTests; # COMMAND install_name_tool -change libtbbmalloc.dylib @rpath/libtbbmalloc.dylib ${GAT",MatchSource.DOCS,src/CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt:9674,Deployability,install,installed,9674,"cies(alevin_core libtbb); add_dependencies(salmon_core libtbb); add_dependencies(unitTests libtbb); add_dependencies(salmon libtbb); endif(). if (${FETCHED_CEREAL}); add_dependencies(alevin_core libcereal); add_dependencies(salmon_core libcereal); add_dependencies(salmon libcereal); endif(). if (${FETCHED_STADEN}); ## PUFF_INTEGRATION; # add_dependencies(alevin_core libstadenio); add_dependencies(alevin_core libstadenio); add_dependencies(salmon_core libstadenio); add_dependencies(salmon libstadenio); endif(). #add_dependencies(salmon_core libbwa); #add_dependencies(salmon libbwa). if (${FETCHED_GFF}); add_dependencies(alevin_core libgff); add_dependencies(salmon_core libgff); add_dependencies(salmon libgff); endif(). ### No need for this, I think; ## This ensures that the salmon executable should work with or without `make install`; ###; ## Grumble grumble . . . OSX; #if (APPLE); # # only attempt install_name_tool for tbb if we installed it; # if (${TBB_LIBRARY_DIRS} MATCHES ${GAT_SOURCE_DIR}/external/install/lib); # add_custom_command(TARGET salmon; # POST_BUILD; # COMMAND install_name_tool -change libtbb.dylib @rpath/libtbb.dylib ${GAT_SOURCE_DIR}/build/src/salmon; # COMMAND install_name_tool -change libtbbmalloc.dylib @rpath/libtbbmalloc.dylib ${GAT_SOURCE_DIR}/build/src/salmon; # COMMAND install_name_tool -change libtbbmalloc_proxy.dylib @rpath/libtbbmalloc_proxy.dylib ${GAT_SOURCE_DIR}/build/src/salmon; # COMMAND install_name_tool -add_rpath ${GAT_SOURCE_DIR}/external/install/lib ${GAT_SOURCE_DIR}/build/src/salmon; # ); # add_custom_command(TARGET unitTests; # POST_BUILD; # COMMAND install_name_tool -change libtbb.dylib @rpath/libtbb.dylib ${GAT_SOURCE_DIR}/build/src/unitTests; # COMMAND install_name_tool -change libtbbmalloc.dylib @rpath/libtbbmalloc.dylib ${GAT_SOURCE_DIR}/build/src/unitTests; # COMMAND install_name_tool -change libtbbmalloc_proxy.dylib @rpath/libtbbmalloc_proxy.dylib ${GAT_SOURCE_DIR}/build/src/unitTests; # COMMAND install_name_tool -add_rp",MatchSource.DOCS,src/CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt:9749,Deployability,install,install,9749,"cies(alevin_core libtbb); add_dependencies(salmon_core libtbb); add_dependencies(unitTests libtbb); add_dependencies(salmon libtbb); endif(). if (${FETCHED_CEREAL}); add_dependencies(alevin_core libcereal); add_dependencies(salmon_core libcereal); add_dependencies(salmon libcereal); endif(). if (${FETCHED_STADEN}); ## PUFF_INTEGRATION; # add_dependencies(alevin_core libstadenio); add_dependencies(alevin_core libstadenio); add_dependencies(salmon_core libstadenio); add_dependencies(salmon libstadenio); endif(). #add_dependencies(salmon_core libbwa); #add_dependencies(salmon libbwa). if (${FETCHED_GFF}); add_dependencies(alevin_core libgff); add_dependencies(salmon_core libgff); add_dependencies(salmon libgff); endif(). ### No need for this, I think; ## This ensures that the salmon executable should work with or without `make install`; ###; ## Grumble grumble . . . OSX; #if (APPLE); # # only attempt install_name_tool for tbb if we installed it; # if (${TBB_LIBRARY_DIRS} MATCHES ${GAT_SOURCE_DIR}/external/install/lib); # add_custom_command(TARGET salmon; # POST_BUILD; # COMMAND install_name_tool -change libtbb.dylib @rpath/libtbb.dylib ${GAT_SOURCE_DIR}/build/src/salmon; # COMMAND install_name_tool -change libtbbmalloc.dylib @rpath/libtbbmalloc.dylib ${GAT_SOURCE_DIR}/build/src/salmon; # COMMAND install_name_tool -change libtbbmalloc_proxy.dylib @rpath/libtbbmalloc_proxy.dylib ${GAT_SOURCE_DIR}/build/src/salmon; # COMMAND install_name_tool -add_rpath ${GAT_SOURCE_DIR}/external/install/lib ${GAT_SOURCE_DIR}/build/src/salmon; # ); # add_custom_command(TARGET unitTests; # POST_BUILD; # COMMAND install_name_tool -change libtbb.dylib @rpath/libtbb.dylib ${GAT_SOURCE_DIR}/build/src/unitTests; # COMMAND install_name_tool -change libtbbmalloc.dylib @rpath/libtbbmalloc.dylib ${GAT_SOURCE_DIR}/build/src/unitTests; # COMMAND install_name_tool -change libtbbmalloc_proxy.dylib @rpath/libtbbmalloc_proxy.dylib ${GAT_SOURCE_DIR}/build/src/unitTests; # COMMAND install_name_tool -add_rp",MatchSource.DOCS,src/CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt:10230,Deployability,install,install,10230,"d_dependencies(salmon_core libbwa); #add_dependencies(salmon libbwa). if (${FETCHED_GFF}); add_dependencies(alevin_core libgff); add_dependencies(salmon_core libgff); add_dependencies(salmon libgff); endif(). ### No need for this, I think; ## This ensures that the salmon executable should work with or without `make install`; ###; ## Grumble grumble . . . OSX; #if (APPLE); # # only attempt install_name_tool for tbb if we installed it; # if (${TBB_LIBRARY_DIRS} MATCHES ${GAT_SOURCE_DIR}/external/install/lib); # add_custom_command(TARGET salmon; # POST_BUILD; # COMMAND install_name_tool -change libtbb.dylib @rpath/libtbb.dylib ${GAT_SOURCE_DIR}/build/src/salmon; # COMMAND install_name_tool -change libtbbmalloc.dylib @rpath/libtbbmalloc.dylib ${GAT_SOURCE_DIR}/build/src/salmon; # COMMAND install_name_tool -change libtbbmalloc_proxy.dylib @rpath/libtbbmalloc_proxy.dylib ${GAT_SOURCE_DIR}/build/src/salmon; # COMMAND install_name_tool -add_rpath ${GAT_SOURCE_DIR}/external/install/lib ${GAT_SOURCE_DIR}/build/src/salmon; # ); # add_custom_command(TARGET unitTests; # POST_BUILD; # COMMAND install_name_tool -change libtbb.dylib @rpath/libtbb.dylib ${GAT_SOURCE_DIR}/build/src/unitTests; # COMMAND install_name_tool -change libtbbmalloc.dylib @rpath/libtbbmalloc.dylib ${GAT_SOURCE_DIR}/build/src/unitTests; # COMMAND install_name_tool -change libtbbmalloc_proxy.dylib @rpath/libtbbmalloc_proxy.dylib ${GAT_SOURCE_DIR}/build/src/unitTests; # COMMAND install_name_tool -add_rpath ${GAT_SOURCE_DIR}/external/install/lib ${GAT_SOURCE_DIR}/build/src/unitTests; # ); # endif(); #else(); # # related to complete static linking --- on hold ; # set (BOOST_THREAD_LIBRARY); #endif(). #if (APPLE); #	add_custom_command(TARGET salmon; #		POST_BUILD; #		COMMAND install_name_tool -add_rpath ${GAT_SOURCE_DIR}/external/install/lib salmon; #	COMMAND install_name_tool -add_rpath @executable_path/../lib salmon; #		); #endif(). ##### ======================================. IF(CMAKE_INSTALL_PREFIX_INITIALIZED_",MatchSource.DOCS,src/CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt:10762,Deployability,install,install,10762," salmon; # POST_BUILD; # COMMAND install_name_tool -change libtbb.dylib @rpath/libtbb.dylib ${GAT_SOURCE_DIR}/build/src/salmon; # COMMAND install_name_tool -change libtbbmalloc.dylib @rpath/libtbbmalloc.dylib ${GAT_SOURCE_DIR}/build/src/salmon; # COMMAND install_name_tool -change libtbbmalloc_proxy.dylib @rpath/libtbbmalloc_proxy.dylib ${GAT_SOURCE_DIR}/build/src/salmon; # COMMAND install_name_tool -add_rpath ${GAT_SOURCE_DIR}/external/install/lib ${GAT_SOURCE_DIR}/build/src/salmon; # ); # add_custom_command(TARGET unitTests; # POST_BUILD; # COMMAND install_name_tool -change libtbb.dylib @rpath/libtbb.dylib ${GAT_SOURCE_DIR}/build/src/unitTests; # COMMAND install_name_tool -change libtbbmalloc.dylib @rpath/libtbbmalloc.dylib ${GAT_SOURCE_DIR}/build/src/unitTests; # COMMAND install_name_tool -change libtbbmalloc_proxy.dylib @rpath/libtbbmalloc_proxy.dylib ${GAT_SOURCE_DIR}/build/src/unitTests; # COMMAND install_name_tool -add_rpath ${GAT_SOURCE_DIR}/external/install/lib ${GAT_SOURCE_DIR}/build/src/unitTests; # ); # endif(); #else(); # # related to complete static linking --- on hold ; # set (BOOST_THREAD_LIBRARY); #endif(). #if (APPLE); #	add_custom_command(TARGET salmon; #		POST_BUILD; #		COMMAND install_name_tool -add_rpath ${GAT_SOURCE_DIR}/external/install/lib salmon; #	COMMAND install_name_tool -add_rpath @executable_path/../lib salmon; #		); #endif(). ##### ======================================. IF(CMAKE_INSTALL_PREFIX_INITIALIZED_TO_DEFAULT); SET(CMAKE_INSTALL_PREFIX; ""${GAT_SOURCE_DIR}"" CACHE PATH ""Default install prefix"" FORCE; ); ENDIF(CMAKE_INSTALL_PREFIX_INITIALIZED_TO_DEFAULT). set(INSTALL_LIB_DIR lib ); set(INSTALL_BIN_DIR bin ); set(INSTALL_INCLUDE_DIR include ). if(TBB_RECONFIGURE OR TBB_TARGET_EXISTED); #set(TBB_SOURCE_DIR $<TARGET_FILE:TBB::tbb>); #add_custom_target(genexdebug COMMAND ${CMAKE_COMMAND} -E echo ""$<TARGET_LINKER_FILE:TBB::tbb>""); get_target_property(TBB_LIB_INSTALL_NAME TBB::tbb IMPORTED_LOCATION_RELEASE); get_filename_component(TBB_LI",MatchSource.DOCS,src/CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt:11062,Deployability,install,install,11062," # COMMAND install_name_tool -change libtbbmalloc_proxy.dylib @rpath/libtbbmalloc_proxy.dylib ${GAT_SOURCE_DIR}/build/src/salmon; # COMMAND install_name_tool -add_rpath ${GAT_SOURCE_DIR}/external/install/lib ${GAT_SOURCE_DIR}/build/src/salmon; # ); # add_custom_command(TARGET unitTests; # POST_BUILD; # COMMAND install_name_tool -change libtbb.dylib @rpath/libtbb.dylib ${GAT_SOURCE_DIR}/build/src/unitTests; # COMMAND install_name_tool -change libtbbmalloc.dylib @rpath/libtbbmalloc.dylib ${GAT_SOURCE_DIR}/build/src/unitTests; # COMMAND install_name_tool -change libtbbmalloc_proxy.dylib @rpath/libtbbmalloc_proxy.dylib ${GAT_SOURCE_DIR}/build/src/unitTests; # COMMAND install_name_tool -add_rpath ${GAT_SOURCE_DIR}/external/install/lib ${GAT_SOURCE_DIR}/build/src/unitTests; # ); # endif(); #else(); # # related to complete static linking --- on hold ; # set (BOOST_THREAD_LIBRARY); #endif(). #if (APPLE); #	add_custom_command(TARGET salmon; #		POST_BUILD; #		COMMAND install_name_tool -add_rpath ${GAT_SOURCE_DIR}/external/install/lib salmon; #	COMMAND install_name_tool -add_rpath @executable_path/../lib salmon; #		); #endif(). ##### ======================================. IF(CMAKE_INSTALL_PREFIX_INITIALIZED_TO_DEFAULT); SET(CMAKE_INSTALL_PREFIX; ""${GAT_SOURCE_DIR}"" CACHE PATH ""Default install prefix"" FORCE; ); ENDIF(CMAKE_INSTALL_PREFIX_INITIALIZED_TO_DEFAULT). set(INSTALL_LIB_DIR lib ); set(INSTALL_BIN_DIR bin ); set(INSTALL_INCLUDE_DIR include ). if(TBB_RECONFIGURE OR TBB_TARGET_EXISTED); #set(TBB_SOURCE_DIR $<TARGET_FILE:TBB::tbb>); #add_custom_target(genexdebug COMMAND ${CMAKE_COMMAND} -E echo ""$<TARGET_LINKER_FILE:TBB::tbb>""); get_target_property(TBB_LIB_INSTALL_NAME TBB::tbb IMPORTED_LOCATION_RELEASE); get_filename_component(TBB_LIB_INSTALL_DIR ${TBB_LIB_INSTALL_NAME} DIRECTORY); message(""TBB_LIB_INSTALL_DIR = ${TBB_LIB_INSTALL_DIR}""); file(GLOB TBB_FILES ${TBB_LIB_INSTALL_DIR}/libtbb*.${SHARED_LIB_EXTENSION}*); message(""TBBGLOBS = ${TBB_FILES}""). install(FILES ; ${TBB_F",MatchSource.DOCS,src/CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt:11330,Deployability,install,install,11330," unitTests; # POST_BUILD; # COMMAND install_name_tool -change libtbb.dylib @rpath/libtbb.dylib ${GAT_SOURCE_DIR}/build/src/unitTests; # COMMAND install_name_tool -change libtbbmalloc.dylib @rpath/libtbbmalloc.dylib ${GAT_SOURCE_DIR}/build/src/unitTests; # COMMAND install_name_tool -change libtbbmalloc_proxy.dylib @rpath/libtbbmalloc_proxy.dylib ${GAT_SOURCE_DIR}/build/src/unitTests; # COMMAND install_name_tool -add_rpath ${GAT_SOURCE_DIR}/external/install/lib ${GAT_SOURCE_DIR}/build/src/unitTests; # ); # endif(); #else(); # # related to complete static linking --- on hold ; # set (BOOST_THREAD_LIBRARY); #endif(). #if (APPLE); #	add_custom_command(TARGET salmon; #		POST_BUILD; #		COMMAND install_name_tool -add_rpath ${GAT_SOURCE_DIR}/external/install/lib salmon; #	COMMAND install_name_tool -add_rpath @executable_path/../lib salmon; #		); #endif(). ##### ======================================. IF(CMAKE_INSTALL_PREFIX_INITIALIZED_TO_DEFAULT); SET(CMAKE_INSTALL_PREFIX; ""${GAT_SOURCE_DIR}"" CACHE PATH ""Default install prefix"" FORCE; ); ENDIF(CMAKE_INSTALL_PREFIX_INITIALIZED_TO_DEFAULT). set(INSTALL_LIB_DIR lib ); set(INSTALL_BIN_DIR bin ); set(INSTALL_INCLUDE_DIR include ). if(TBB_RECONFIGURE OR TBB_TARGET_EXISTED); #set(TBB_SOURCE_DIR $<TARGET_FILE:TBB::tbb>); #add_custom_target(genexdebug COMMAND ${CMAKE_COMMAND} -E echo ""$<TARGET_LINKER_FILE:TBB::tbb>""); get_target_property(TBB_LIB_INSTALL_NAME TBB::tbb IMPORTED_LOCATION_RELEASE); get_filename_component(TBB_LIB_INSTALL_DIR ${TBB_LIB_INSTALL_NAME} DIRECTORY); message(""TBB_LIB_INSTALL_DIR = ${TBB_LIB_INSTALL_DIR}""); file(GLOB TBB_FILES ${TBB_LIB_INSTALL_DIR}/libtbb*.${SHARED_LIB_EXTENSION}*); message(""TBBGLOBS = ${TBB_FILES}""). install(FILES ; ${TBB_FILES}; DESTINATION ${INSTALL_LIB_DIR}; ) ; #install(FILES ; # $<TARGET_FILE:TBB::tbbmalloc>; # DESTINATION ${INSTALL_LIB_DIR}; #); #install(DIRECTORY; # ${TBB_SOURCE_DIR}; # DESTINATION ${INSTALL_LIB_DIR}; #	 FILES_MATCHING PATTERN ""libtbb*.${SHARED_LIB_EXTENSION}*""; #); endi",MatchSource.DOCS,src/CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt:12012,Deployability,install,install,12012,"b salmon; #		); #endif(). ##### ======================================. IF(CMAKE_INSTALL_PREFIX_INITIALIZED_TO_DEFAULT); SET(CMAKE_INSTALL_PREFIX; ""${GAT_SOURCE_DIR}"" CACHE PATH ""Default install prefix"" FORCE; ); ENDIF(CMAKE_INSTALL_PREFIX_INITIALIZED_TO_DEFAULT). set(INSTALL_LIB_DIR lib ); set(INSTALL_BIN_DIR bin ); set(INSTALL_INCLUDE_DIR include ). if(TBB_RECONFIGURE OR TBB_TARGET_EXISTED); #set(TBB_SOURCE_DIR $<TARGET_FILE:TBB::tbb>); #add_custom_target(genexdebug COMMAND ${CMAKE_COMMAND} -E echo ""$<TARGET_LINKER_FILE:TBB::tbb>""); get_target_property(TBB_LIB_INSTALL_NAME TBB::tbb IMPORTED_LOCATION_RELEASE); get_filename_component(TBB_LIB_INSTALL_DIR ${TBB_LIB_INSTALL_NAME} DIRECTORY); message(""TBB_LIB_INSTALL_DIR = ${TBB_LIB_INSTALL_DIR}""); file(GLOB TBB_FILES ${TBB_LIB_INSTALL_DIR}/libtbb*.${SHARED_LIB_EXTENSION}*); message(""TBBGLOBS = ${TBB_FILES}""). install(FILES ; ${TBB_FILES}; DESTINATION ${INSTALL_LIB_DIR}; ) ; #install(FILES ; # $<TARGET_FILE:TBB::tbbmalloc>; # DESTINATION ${INSTALL_LIB_DIR}; #); #install(DIRECTORY; # ${TBB_SOURCE_DIR}; # DESTINATION ${INSTALL_LIB_DIR}; #	 FILES_MATCHING PATTERN ""libtbb*.${SHARED_LIB_EXTENSION}*""; #); endif(). #install(DIRECTORY; # ${GAT_SOURCE_DIR}/external/install/lib/; # DESTINATION ${INSTALL_LIB_DIR}; #	 FILES_MATCHING PATTERN ""libtbb*.${SHARED_LIB_EXTENSION}*""; # ). # install(FILES ${Boost_LIBRARIES}; # 	 DESTINATION ${INSTALL_LIB_DIR}). install(TARGETS salmon salmon_core; RUNTIME DESTINATION bin; LIBRARY DESTINATION lib; ARCHIVE DESTINATION lib; ). add_custom_command(TARGET unitTests POST_BUILD; COMMAND ${CMAKE_COMMAND} -E copy $<TARGET_FILE:unitTests> ${GAT_SOURCE_DIR}/tests/$<TARGET_FILE_NAME:unitTests>; COMMENT ""Copying unitTests""; ). set(POST_INSTALL_SCRIPT ${GAT_SOURCE_DIR}/cmake/PostInstall.cmake). install(; CODE; ""; execute_process(COMMAND \""${CMAKE_COMMAND}\""; -DCMAKE_SYSTEM_NAME=${CMAKE_SYSTEM_NAME}; -DCMAKE_INSTALL_PREFIX=${CMAKE_INSTALL_PREFIX}; -P \""${POST_INSTALL_SCRIPT}\""); ""; ). include(InstallRequired",MatchSource.DOCS,src/CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt:12079,Deployability,install,install,12079,"b salmon; #		); #endif(). ##### ======================================. IF(CMAKE_INSTALL_PREFIX_INITIALIZED_TO_DEFAULT); SET(CMAKE_INSTALL_PREFIX; ""${GAT_SOURCE_DIR}"" CACHE PATH ""Default install prefix"" FORCE; ); ENDIF(CMAKE_INSTALL_PREFIX_INITIALIZED_TO_DEFAULT). set(INSTALL_LIB_DIR lib ); set(INSTALL_BIN_DIR bin ); set(INSTALL_INCLUDE_DIR include ). if(TBB_RECONFIGURE OR TBB_TARGET_EXISTED); #set(TBB_SOURCE_DIR $<TARGET_FILE:TBB::tbb>); #add_custom_target(genexdebug COMMAND ${CMAKE_COMMAND} -E echo ""$<TARGET_LINKER_FILE:TBB::tbb>""); get_target_property(TBB_LIB_INSTALL_NAME TBB::tbb IMPORTED_LOCATION_RELEASE); get_filename_component(TBB_LIB_INSTALL_DIR ${TBB_LIB_INSTALL_NAME} DIRECTORY); message(""TBB_LIB_INSTALL_DIR = ${TBB_LIB_INSTALL_DIR}""); file(GLOB TBB_FILES ${TBB_LIB_INSTALL_DIR}/libtbb*.${SHARED_LIB_EXTENSION}*); message(""TBBGLOBS = ${TBB_FILES}""). install(FILES ; ${TBB_FILES}; DESTINATION ${INSTALL_LIB_DIR}; ) ; #install(FILES ; # $<TARGET_FILE:TBB::tbbmalloc>; # DESTINATION ${INSTALL_LIB_DIR}; #); #install(DIRECTORY; # ${TBB_SOURCE_DIR}; # DESTINATION ${INSTALL_LIB_DIR}; #	 FILES_MATCHING PATTERN ""libtbb*.${SHARED_LIB_EXTENSION}*""; #); endif(). #install(DIRECTORY; # ${GAT_SOURCE_DIR}/external/install/lib/; # DESTINATION ${INSTALL_LIB_DIR}; #	 FILES_MATCHING PATTERN ""libtbb*.${SHARED_LIB_EXTENSION}*""; # ). # install(FILES ${Boost_LIBRARIES}; # 	 DESTINATION ${INSTALL_LIB_DIR}). install(TARGETS salmon salmon_core; RUNTIME DESTINATION bin; LIBRARY DESTINATION lib; ARCHIVE DESTINATION lib; ). add_custom_command(TARGET unitTests POST_BUILD; COMMAND ${CMAKE_COMMAND} -E copy $<TARGET_FILE:unitTests> ${GAT_SOURCE_DIR}/tests/$<TARGET_FILE_NAME:unitTests>; COMMENT ""Copying unitTests""; ). set(POST_INSTALL_SCRIPT ${GAT_SOURCE_DIR}/cmake/PostInstall.cmake). install(; CODE; ""; execute_process(COMMAND \""${CMAKE_COMMAND}\""; -DCMAKE_SYSTEM_NAME=${CMAKE_SYSTEM_NAME}; -DCMAKE_INSTALL_PREFIX=${CMAKE_INSTALL_PREFIX}; -P \""${POST_INSTALL_SCRIPT}\""); ""; ). include(InstallRequired",MatchSource.DOCS,src/CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt:12167,Deployability,install,install,12167,"b salmon; #		); #endif(). ##### ======================================. IF(CMAKE_INSTALL_PREFIX_INITIALIZED_TO_DEFAULT); SET(CMAKE_INSTALL_PREFIX; ""${GAT_SOURCE_DIR}"" CACHE PATH ""Default install prefix"" FORCE; ); ENDIF(CMAKE_INSTALL_PREFIX_INITIALIZED_TO_DEFAULT). set(INSTALL_LIB_DIR lib ); set(INSTALL_BIN_DIR bin ); set(INSTALL_INCLUDE_DIR include ). if(TBB_RECONFIGURE OR TBB_TARGET_EXISTED); #set(TBB_SOURCE_DIR $<TARGET_FILE:TBB::tbb>); #add_custom_target(genexdebug COMMAND ${CMAKE_COMMAND} -E echo ""$<TARGET_LINKER_FILE:TBB::tbb>""); get_target_property(TBB_LIB_INSTALL_NAME TBB::tbb IMPORTED_LOCATION_RELEASE); get_filename_component(TBB_LIB_INSTALL_DIR ${TBB_LIB_INSTALL_NAME} DIRECTORY); message(""TBB_LIB_INSTALL_DIR = ${TBB_LIB_INSTALL_DIR}""); file(GLOB TBB_FILES ${TBB_LIB_INSTALL_DIR}/libtbb*.${SHARED_LIB_EXTENSION}*); message(""TBBGLOBS = ${TBB_FILES}""). install(FILES ; ${TBB_FILES}; DESTINATION ${INSTALL_LIB_DIR}; ) ; #install(FILES ; # $<TARGET_FILE:TBB::tbbmalloc>; # DESTINATION ${INSTALL_LIB_DIR}; #); #install(DIRECTORY; # ${TBB_SOURCE_DIR}; # DESTINATION ${INSTALL_LIB_DIR}; #	 FILES_MATCHING PATTERN ""libtbb*.${SHARED_LIB_EXTENSION}*""; #); endif(). #install(DIRECTORY; # ${GAT_SOURCE_DIR}/external/install/lib/; # DESTINATION ${INSTALL_LIB_DIR}; #	 FILES_MATCHING PATTERN ""libtbb*.${SHARED_LIB_EXTENSION}*""; # ). # install(FILES ${Boost_LIBRARIES}; # 	 DESTINATION ${INSTALL_LIB_DIR}). install(TARGETS salmon salmon_core; RUNTIME DESTINATION bin; LIBRARY DESTINATION lib; ARCHIVE DESTINATION lib; ). add_custom_command(TARGET unitTests POST_BUILD; COMMAND ${CMAKE_COMMAND} -E copy $<TARGET_FILE:unitTests> ${GAT_SOURCE_DIR}/tests/$<TARGET_FILE_NAME:unitTests>; COMMENT ""Copying unitTests""; ). set(POST_INSTALL_SCRIPT ${GAT_SOURCE_DIR}/cmake/PostInstall.cmake). install(; CODE; ""; execute_process(COMMAND \""${CMAKE_COMMAND}\""; -DCMAKE_SYSTEM_NAME=${CMAKE_SYSTEM_NAME}; -DCMAKE_INSTALL_PREFIX=${CMAKE_INSTALL_PREFIX}; -P \""${POST_INSTALL_SCRIPT}\""); ""; ). include(InstallRequired",MatchSource.DOCS,src/CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt:12317,Deployability,install,install,12317,"X_INITIALIZED_TO_DEFAULT). set(INSTALL_LIB_DIR lib ); set(INSTALL_BIN_DIR bin ); set(INSTALL_INCLUDE_DIR include ). if(TBB_RECONFIGURE OR TBB_TARGET_EXISTED); #set(TBB_SOURCE_DIR $<TARGET_FILE:TBB::tbb>); #add_custom_target(genexdebug COMMAND ${CMAKE_COMMAND} -E echo ""$<TARGET_LINKER_FILE:TBB::tbb>""); get_target_property(TBB_LIB_INSTALL_NAME TBB::tbb IMPORTED_LOCATION_RELEASE); get_filename_component(TBB_LIB_INSTALL_DIR ${TBB_LIB_INSTALL_NAME} DIRECTORY); message(""TBB_LIB_INSTALL_DIR = ${TBB_LIB_INSTALL_DIR}""); file(GLOB TBB_FILES ${TBB_LIB_INSTALL_DIR}/libtbb*.${SHARED_LIB_EXTENSION}*); message(""TBBGLOBS = ${TBB_FILES}""). install(FILES ; ${TBB_FILES}; DESTINATION ${INSTALL_LIB_DIR}; ) ; #install(FILES ; # $<TARGET_FILE:TBB::tbbmalloc>; # DESTINATION ${INSTALL_LIB_DIR}; #); #install(DIRECTORY; # ${TBB_SOURCE_DIR}; # DESTINATION ${INSTALL_LIB_DIR}; #	 FILES_MATCHING PATTERN ""libtbb*.${SHARED_LIB_EXTENSION}*""; #); endif(). #install(DIRECTORY; # ${GAT_SOURCE_DIR}/external/install/lib/; # DESTINATION ${INSTALL_LIB_DIR}; #	 FILES_MATCHING PATTERN ""libtbb*.${SHARED_LIB_EXTENSION}*""; # ). # install(FILES ${Boost_LIBRARIES}; # 	 DESTINATION ${INSTALL_LIB_DIR}). install(TARGETS salmon salmon_core; RUNTIME DESTINATION bin; LIBRARY DESTINATION lib; ARCHIVE DESTINATION lib; ). add_custom_command(TARGET unitTests POST_BUILD; COMMAND ${CMAKE_COMMAND} -E copy $<TARGET_FILE:unitTests> ${GAT_SOURCE_DIR}/tests/$<TARGET_FILE_NAME:unitTests>; COMMENT ""Copying unitTests""; ). set(POST_INSTALL_SCRIPT ${GAT_SOURCE_DIR}/cmake/PostInstall.cmake). install(; CODE; ""; execute_process(COMMAND \""${CMAKE_COMMAND}\""; -DCMAKE_SYSTEM_NAME=${CMAKE_SYSTEM_NAME}; -DCMAKE_INSTALL_PREFIX=${CMAKE_INSTALL_PREFIX}; -P \""${POST_INSTALL_SCRIPT}\""); ""; ). include(InstallRequiredSystemLibraries); add_test( NAME unit_tests COMMAND ${CMAKE_COMMAND} -DTOPLEVEL_DIR=${GAT_SOURCE_DIR} -P ${GAT_SOURCE_DIR}/cmake/UnitTests.cmake ); add_test( NAME salmon_read_test_quasi COMMAND ${CMAKE_COMMAND} -DTOPLEVEL_DIR=${GAT_SOURCE",MatchSource.DOCS,src/CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt:12365,Deployability,install,install,12365,"X_INITIALIZED_TO_DEFAULT). set(INSTALL_LIB_DIR lib ); set(INSTALL_BIN_DIR bin ); set(INSTALL_INCLUDE_DIR include ). if(TBB_RECONFIGURE OR TBB_TARGET_EXISTED); #set(TBB_SOURCE_DIR $<TARGET_FILE:TBB::tbb>); #add_custom_target(genexdebug COMMAND ${CMAKE_COMMAND} -E echo ""$<TARGET_LINKER_FILE:TBB::tbb>""); get_target_property(TBB_LIB_INSTALL_NAME TBB::tbb IMPORTED_LOCATION_RELEASE); get_filename_component(TBB_LIB_INSTALL_DIR ${TBB_LIB_INSTALL_NAME} DIRECTORY); message(""TBB_LIB_INSTALL_DIR = ${TBB_LIB_INSTALL_DIR}""); file(GLOB TBB_FILES ${TBB_LIB_INSTALL_DIR}/libtbb*.${SHARED_LIB_EXTENSION}*); message(""TBBGLOBS = ${TBB_FILES}""). install(FILES ; ${TBB_FILES}; DESTINATION ${INSTALL_LIB_DIR}; ) ; #install(FILES ; # $<TARGET_FILE:TBB::tbbmalloc>; # DESTINATION ${INSTALL_LIB_DIR}; #); #install(DIRECTORY; # ${TBB_SOURCE_DIR}; # DESTINATION ${INSTALL_LIB_DIR}; #	 FILES_MATCHING PATTERN ""libtbb*.${SHARED_LIB_EXTENSION}*""; #); endif(). #install(DIRECTORY; # ${GAT_SOURCE_DIR}/external/install/lib/; # DESTINATION ${INSTALL_LIB_DIR}; #	 FILES_MATCHING PATTERN ""libtbb*.${SHARED_LIB_EXTENSION}*""; # ). # install(FILES ${Boost_LIBRARIES}; # 	 DESTINATION ${INSTALL_LIB_DIR}). install(TARGETS salmon salmon_core; RUNTIME DESTINATION bin; LIBRARY DESTINATION lib; ARCHIVE DESTINATION lib; ). add_custom_command(TARGET unitTests POST_BUILD; COMMAND ${CMAKE_COMMAND} -E copy $<TARGET_FILE:unitTests> ${GAT_SOURCE_DIR}/tests/$<TARGET_FILE_NAME:unitTests>; COMMENT ""Copying unitTests""; ). set(POST_INSTALL_SCRIPT ${GAT_SOURCE_DIR}/cmake/PostInstall.cmake). install(; CODE; ""; execute_process(COMMAND \""${CMAKE_COMMAND}\""; -DCMAKE_SYSTEM_NAME=${CMAKE_SYSTEM_NAME}; -DCMAKE_INSTALL_PREFIX=${CMAKE_INSTALL_PREFIX}; -P \""${POST_INSTALL_SCRIPT}\""); ""; ). include(InstallRequiredSystemLibraries); add_test( NAME unit_tests COMMAND ${CMAKE_COMMAND} -DTOPLEVEL_DIR=${GAT_SOURCE_DIR} -P ${GAT_SOURCE_DIR}/cmake/UnitTests.cmake ); add_test( NAME salmon_read_test_quasi COMMAND ${CMAKE_COMMAND} -DTOPLEVEL_DIR=${GAT_SOURCE",MatchSource.DOCS,src/CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt:12482,Deployability,install,install,12482," OR TBB_TARGET_EXISTED); #set(TBB_SOURCE_DIR $<TARGET_FILE:TBB::tbb>); #add_custom_target(genexdebug COMMAND ${CMAKE_COMMAND} -E echo ""$<TARGET_LINKER_FILE:TBB::tbb>""); get_target_property(TBB_LIB_INSTALL_NAME TBB::tbb IMPORTED_LOCATION_RELEASE); get_filename_component(TBB_LIB_INSTALL_DIR ${TBB_LIB_INSTALL_NAME} DIRECTORY); message(""TBB_LIB_INSTALL_DIR = ${TBB_LIB_INSTALL_DIR}""); file(GLOB TBB_FILES ${TBB_LIB_INSTALL_DIR}/libtbb*.${SHARED_LIB_EXTENSION}*); message(""TBBGLOBS = ${TBB_FILES}""). install(FILES ; ${TBB_FILES}; DESTINATION ${INSTALL_LIB_DIR}; ) ; #install(FILES ; # $<TARGET_FILE:TBB::tbbmalloc>; # DESTINATION ${INSTALL_LIB_DIR}; #); #install(DIRECTORY; # ${TBB_SOURCE_DIR}; # DESTINATION ${INSTALL_LIB_DIR}; #	 FILES_MATCHING PATTERN ""libtbb*.${SHARED_LIB_EXTENSION}*""; #); endif(). #install(DIRECTORY; # ${GAT_SOURCE_DIR}/external/install/lib/; # DESTINATION ${INSTALL_LIB_DIR}; #	 FILES_MATCHING PATTERN ""libtbb*.${SHARED_LIB_EXTENSION}*""; # ). # install(FILES ${Boost_LIBRARIES}; # 	 DESTINATION ${INSTALL_LIB_DIR}). install(TARGETS salmon salmon_core; RUNTIME DESTINATION bin; LIBRARY DESTINATION lib; ARCHIVE DESTINATION lib; ). add_custom_command(TARGET unitTests POST_BUILD; COMMAND ${CMAKE_COMMAND} -E copy $<TARGET_FILE:unitTests> ${GAT_SOURCE_DIR}/tests/$<TARGET_FILE_NAME:unitTests>; COMMENT ""Copying unitTests""; ). set(POST_INSTALL_SCRIPT ${GAT_SOURCE_DIR}/cmake/PostInstall.cmake). install(; CODE; ""; execute_process(COMMAND \""${CMAKE_COMMAND}\""; -DCMAKE_SYSTEM_NAME=${CMAKE_SYSTEM_NAME}; -DCMAKE_INSTALL_PREFIX=${CMAKE_INSTALL_PREFIX}; -P \""${POST_INSTALL_SCRIPT}\""); ""; ). include(InstallRequiredSystemLibraries); add_test( NAME unit_tests COMMAND ${CMAKE_COMMAND} -DTOPLEVEL_DIR=${GAT_SOURCE_DIR} -P ${GAT_SOURCE_DIR}/cmake/UnitTests.cmake ); add_test( NAME salmon_read_test_quasi COMMAND ${CMAKE_COMMAND} -DTOPLEVEL_DIR=${GAT_SOURCE_DIR} -P ${GAT_SOURCE_DIR}/cmake/TestSalmonQuasi.cmake ). # Remove this test since we are removing support for the FMD index. ; # add_",MatchSource.DOCS,src/CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt:12553,Deployability,install,install,12553,"xdebug COMMAND ${CMAKE_COMMAND} -E echo ""$<TARGET_LINKER_FILE:TBB::tbb>""); get_target_property(TBB_LIB_INSTALL_NAME TBB::tbb IMPORTED_LOCATION_RELEASE); get_filename_component(TBB_LIB_INSTALL_DIR ${TBB_LIB_INSTALL_NAME} DIRECTORY); message(""TBB_LIB_INSTALL_DIR = ${TBB_LIB_INSTALL_DIR}""); file(GLOB TBB_FILES ${TBB_LIB_INSTALL_DIR}/libtbb*.${SHARED_LIB_EXTENSION}*); message(""TBBGLOBS = ${TBB_FILES}""). install(FILES ; ${TBB_FILES}; DESTINATION ${INSTALL_LIB_DIR}; ) ; #install(FILES ; # $<TARGET_FILE:TBB::tbbmalloc>; # DESTINATION ${INSTALL_LIB_DIR}; #); #install(DIRECTORY; # ${TBB_SOURCE_DIR}; # DESTINATION ${INSTALL_LIB_DIR}; #	 FILES_MATCHING PATTERN ""libtbb*.${SHARED_LIB_EXTENSION}*""; #); endif(). #install(DIRECTORY; # ${GAT_SOURCE_DIR}/external/install/lib/; # DESTINATION ${INSTALL_LIB_DIR}; #	 FILES_MATCHING PATTERN ""libtbb*.${SHARED_LIB_EXTENSION}*""; # ). # install(FILES ${Boost_LIBRARIES}; # 	 DESTINATION ${INSTALL_LIB_DIR}). install(TARGETS salmon salmon_core; RUNTIME DESTINATION bin; LIBRARY DESTINATION lib; ARCHIVE DESTINATION lib; ). add_custom_command(TARGET unitTests POST_BUILD; COMMAND ${CMAKE_COMMAND} -E copy $<TARGET_FILE:unitTests> ${GAT_SOURCE_DIR}/tests/$<TARGET_FILE_NAME:unitTests>; COMMENT ""Copying unitTests""; ). set(POST_INSTALL_SCRIPT ${GAT_SOURCE_DIR}/cmake/PostInstall.cmake). install(; CODE; ""; execute_process(COMMAND \""${CMAKE_COMMAND}\""; -DCMAKE_SYSTEM_NAME=${CMAKE_SYSTEM_NAME}; -DCMAKE_INSTALL_PREFIX=${CMAKE_INSTALL_PREFIX}; -P \""${POST_INSTALL_SCRIPT}\""); ""; ). include(InstallRequiredSystemLibraries); add_test( NAME unit_tests COMMAND ${CMAKE_COMMAND} -DTOPLEVEL_DIR=${GAT_SOURCE_DIR} -P ${GAT_SOURCE_DIR}/cmake/UnitTests.cmake ); add_test( NAME salmon_read_test_quasi COMMAND ${CMAKE_COMMAND} -DTOPLEVEL_DIR=${GAT_SOURCE_DIR} -P ${GAT_SOURCE_DIR}/cmake/TestSalmonQuasi.cmake ). # Remove this test since we are removing support for the FMD index. ; # add_test( NAME salmon_read_test_fmd COMMAND ${CMAKE_COMMAND} -DTOPLEVEL_DIR=${GAT_SOURCE_DIR} -P ",MatchSource.DOCS,src/CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt:12928,Deployability,install,install,12928,"ET_LINKER_FILE:TBB::tbb>""); get_target_property(TBB_LIB_INSTALL_NAME TBB::tbb IMPORTED_LOCATION_RELEASE); get_filename_component(TBB_LIB_INSTALL_DIR ${TBB_LIB_INSTALL_NAME} DIRECTORY); message(""TBB_LIB_INSTALL_DIR = ${TBB_LIB_INSTALL_DIR}""); file(GLOB TBB_FILES ${TBB_LIB_INSTALL_DIR}/libtbb*.${SHARED_LIB_EXTENSION}*); message(""TBBGLOBS = ${TBB_FILES}""). install(FILES ; ${TBB_FILES}; DESTINATION ${INSTALL_LIB_DIR}; ) ; #install(FILES ; # $<TARGET_FILE:TBB::tbbmalloc>; # DESTINATION ${INSTALL_LIB_DIR}; #); #install(DIRECTORY; # ${TBB_SOURCE_DIR}; # DESTINATION ${INSTALL_LIB_DIR}; #	 FILES_MATCHING PATTERN ""libtbb*.${SHARED_LIB_EXTENSION}*""; #); endif(). #install(DIRECTORY; # ${GAT_SOURCE_DIR}/external/install/lib/; # DESTINATION ${INSTALL_LIB_DIR}; #	 FILES_MATCHING PATTERN ""libtbb*.${SHARED_LIB_EXTENSION}*""; # ). # install(FILES ${Boost_LIBRARIES}; # 	 DESTINATION ${INSTALL_LIB_DIR}). install(TARGETS salmon salmon_core; RUNTIME DESTINATION bin; LIBRARY DESTINATION lib; ARCHIVE DESTINATION lib; ). add_custom_command(TARGET unitTests POST_BUILD; COMMAND ${CMAKE_COMMAND} -E copy $<TARGET_FILE:unitTests> ${GAT_SOURCE_DIR}/tests/$<TARGET_FILE_NAME:unitTests>; COMMENT ""Copying unitTests""; ). set(POST_INSTALL_SCRIPT ${GAT_SOURCE_DIR}/cmake/PostInstall.cmake). install(; CODE; ""; execute_process(COMMAND \""${CMAKE_COMMAND}\""; -DCMAKE_SYSTEM_NAME=${CMAKE_SYSTEM_NAME}; -DCMAKE_INSTALL_PREFIX=${CMAKE_INSTALL_PREFIX}; -P \""${POST_INSTALL_SCRIPT}\""); ""; ). include(InstallRequiredSystemLibraries); add_test( NAME unit_tests COMMAND ${CMAKE_COMMAND} -DTOPLEVEL_DIR=${GAT_SOURCE_DIR} -P ${GAT_SOURCE_DIR}/cmake/UnitTests.cmake ); add_test( NAME salmon_read_test_quasi COMMAND ${CMAKE_COMMAND} -DTOPLEVEL_DIR=${GAT_SOURCE_DIR} -P ${GAT_SOURCE_DIR}/cmake/TestSalmonQuasi.cmake ). # Remove this test since we are removing support for the FMD index. ; # add_test( NAME salmon_read_test_fmd COMMAND ${CMAKE_COMMAND} -DTOPLEVEL_DIR=${GAT_SOURCE_DIR} -P ${GAT_SOURCE_DIR}/cmake/TestSalmonFMD.cmake ); ",MatchSource.DOCS,src/CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt:1953,Integrability,message,message,1953,"fy.cpp; FragmentLengthDistribution.cpp; FragmentStartPositionDistribution.cpp; # SequenceBiasModel.cpp; GZipWriter.cpp; SalmonQuantMerge.cpp; ProgramOptionsGenerator.cpp; ). set (SALMON_ALIGN_SRCS; FASTAParser.cpp; AlignmentModel.cpp; ONTAlignmentModel.cpp; AlignmentCommon.cpp; FragmentLengthDistribution.cpp; SalmonQuantifyAlignments.cpp; BAMUtils.cpp; ). set (ALEVIN_LIB_SRCS; edlib.cpp; SingleCellProtocols.cpp; AlevinUtils.cpp; ). set (SALMON_LIB_SRCS; ${GAT_SOURCE_DIR}/src/jellyfish/mer_dna.cc; backtrace.cc; xxhash.c; TranscriptGroup.cpp; EffectiveLengthStats.cpp; LibraryFormat.cpp; GenomicFeature.cpp; VersionChecker.cpp; SBModel.cpp; FastxParser.cpp; StadenUtils.cpp; SalmonUtils.cpp; DistributionUtils.cpp; SalmonExceptions.cpp; SalmonStringUtils.cpp; SimplePosBias.cpp; SGSmooth.cpp; ${GAT_SOURCE_DIR}/external/install/src/pufferfish/metro/metrohash64.cpp; ). # check if we know how to do IPO; check_ipo_supported(RESULT HAS_IPO). if (DEFINED NO_IPO); message(""NO_IPO = ${NO_IPO}""); else(); message(""NO_IPO = FALSE""); set(NO_IPO FALSE); endif(). if(HAS_IPO AND (NOT NO_IPO)); set_property(TARGET ksw2pp PROPERTY INTERPROCEDURAL_OPTIMIZATION True); endif(). set (UNIT_TESTS_ENTRY_SRCS; ${GAT_SOURCE_DIR}/tests/UnitTests.cpp; ). set (UNIT_TESTS_INDIVIDUAL_SRCS; ${GAT_SOURCE_DIR}/src/FragmentLengthDistribution.cpp; ${GAT_SOURCE_DIR}/external/install/src/pufferfish/rank9b.cpp; ${GAT_SOURCE_DIR}/tests/GCSampleTests.cpp; ${GAT_SOURCE_DIR}/tests/LibraryTypeTests.cpp; ). link_directories(; ${GAT_SOURCE_DIR}/lib; ${GAT_SOURCE_DIR}/external/install/lib; ${Boost_LIBRARY_DIRS}; ${TBB_LIBRARY_DIRS}; ${LAPACK_LIBRARY_DIR}; ${BLAS_LIBRARY_DIR}; ${LIB_GFF_LIBRARY_DIR}; ). message(""TBB_LIBRARIES = ${TBB_LIBRARIES}""). # Set the RPATH; if (NOT APPLE); set(CMAKE_INSTALL_RPATH ""$ORIGIN/../lib:$ORIGIN/../../lib:$ORIGIN/:$ORIGIN/../../external/install/lib""); set(CMAKE_BUILD_WITH_INSTALL_RPATH TRUE); else(); # use, i.e. do not skip the full RPATH for the build tree; set(CMAKE_SKIP_BUILD_RPATH FALS",MatchSource.DOCS,src/CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt:1992,Integrability,message,message,1992,"fy.cpp; FragmentLengthDistribution.cpp; FragmentStartPositionDistribution.cpp; # SequenceBiasModel.cpp; GZipWriter.cpp; SalmonQuantMerge.cpp; ProgramOptionsGenerator.cpp; ). set (SALMON_ALIGN_SRCS; FASTAParser.cpp; AlignmentModel.cpp; ONTAlignmentModel.cpp; AlignmentCommon.cpp; FragmentLengthDistribution.cpp; SalmonQuantifyAlignments.cpp; BAMUtils.cpp; ). set (ALEVIN_LIB_SRCS; edlib.cpp; SingleCellProtocols.cpp; AlevinUtils.cpp; ). set (SALMON_LIB_SRCS; ${GAT_SOURCE_DIR}/src/jellyfish/mer_dna.cc; backtrace.cc; xxhash.c; TranscriptGroup.cpp; EffectiveLengthStats.cpp; LibraryFormat.cpp; GenomicFeature.cpp; VersionChecker.cpp; SBModel.cpp; FastxParser.cpp; StadenUtils.cpp; SalmonUtils.cpp; DistributionUtils.cpp; SalmonExceptions.cpp; SalmonStringUtils.cpp; SimplePosBias.cpp; SGSmooth.cpp; ${GAT_SOURCE_DIR}/external/install/src/pufferfish/metro/metrohash64.cpp; ). # check if we know how to do IPO; check_ipo_supported(RESULT HAS_IPO). if (DEFINED NO_IPO); message(""NO_IPO = ${NO_IPO}""); else(); message(""NO_IPO = FALSE""); set(NO_IPO FALSE); endif(). if(HAS_IPO AND (NOT NO_IPO)); set_property(TARGET ksw2pp PROPERTY INTERPROCEDURAL_OPTIMIZATION True); endif(). set (UNIT_TESTS_ENTRY_SRCS; ${GAT_SOURCE_DIR}/tests/UnitTests.cpp; ). set (UNIT_TESTS_INDIVIDUAL_SRCS; ${GAT_SOURCE_DIR}/src/FragmentLengthDistribution.cpp; ${GAT_SOURCE_DIR}/external/install/src/pufferfish/rank9b.cpp; ${GAT_SOURCE_DIR}/tests/GCSampleTests.cpp; ${GAT_SOURCE_DIR}/tests/LibraryTypeTests.cpp; ). link_directories(; ${GAT_SOURCE_DIR}/lib; ${GAT_SOURCE_DIR}/external/install/lib; ${Boost_LIBRARY_DIRS}; ${TBB_LIBRARY_DIRS}; ${LAPACK_LIBRARY_DIR}; ${BLAS_LIBRARY_DIR}; ${LIB_GFF_LIBRARY_DIR}; ). message(""TBB_LIBRARIES = ${TBB_LIBRARIES}""). # Set the RPATH; if (NOT APPLE); set(CMAKE_INSTALL_RPATH ""$ORIGIN/../lib:$ORIGIN/../../lib:$ORIGIN/:$ORIGIN/../../external/install/lib""); set(CMAKE_BUILD_WITH_INSTALL_RPATH TRUE); else(); # use, i.e. do not skip the full RPATH for the build tree; set(CMAKE_SKIP_BUILD_RPATH FALS",MatchSource.DOCS,src/CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt:2666,Integrability,message,message,2666,"tributionUtils.cpp; SalmonExceptions.cpp; SalmonStringUtils.cpp; SimplePosBias.cpp; SGSmooth.cpp; ${GAT_SOURCE_DIR}/external/install/src/pufferfish/metro/metrohash64.cpp; ). # check if we know how to do IPO; check_ipo_supported(RESULT HAS_IPO). if (DEFINED NO_IPO); message(""NO_IPO = ${NO_IPO}""); else(); message(""NO_IPO = FALSE""); set(NO_IPO FALSE); endif(). if(HAS_IPO AND (NOT NO_IPO)); set_property(TARGET ksw2pp PROPERTY INTERPROCEDURAL_OPTIMIZATION True); endif(). set (UNIT_TESTS_ENTRY_SRCS; ${GAT_SOURCE_DIR}/tests/UnitTests.cpp; ). set (UNIT_TESTS_INDIVIDUAL_SRCS; ${GAT_SOURCE_DIR}/src/FragmentLengthDistribution.cpp; ${GAT_SOURCE_DIR}/external/install/src/pufferfish/rank9b.cpp; ${GAT_SOURCE_DIR}/tests/GCSampleTests.cpp; ${GAT_SOURCE_DIR}/tests/LibraryTypeTests.cpp; ). link_directories(; ${GAT_SOURCE_DIR}/lib; ${GAT_SOURCE_DIR}/external/install/lib; ${Boost_LIBRARY_DIRS}; ${TBB_LIBRARY_DIRS}; ${LAPACK_LIBRARY_DIR}; ${BLAS_LIBRARY_DIR}; ${LIB_GFF_LIBRARY_DIR}; ). message(""TBB_LIBRARIES = ${TBB_LIBRARIES}""). # Set the RPATH; if (NOT APPLE); set(CMAKE_INSTALL_RPATH ""$ORIGIN/../lib:$ORIGIN/../../lib:$ORIGIN/:$ORIGIN/../../external/install/lib""); set(CMAKE_BUILD_WITH_INSTALL_RPATH TRUE); else(); # use, i.e. do not skip the full RPATH for the build tree; set(CMAKE_SKIP_BUILD_RPATH FALSE). # when building, don't use the install RPATH already; # (but later on when installing); set(CMAKE_BUILD_WITH_INSTALL_RPATH FALSE) . # the RPATH to be used when installing; set(CMAKE_INSTALL_RPATH """"). # don't add the automatically determined parts of the RPATH; # which point to directories outside the build tree to the install RPATH; set(CMAKE_INSTALL_RPATH_USE_LINK_PATH FALSE); endif(). set (TGT_RELEASE_FLAGS ""${TGT_COMPILE_FLAGS};${TGT_WARN_FLAGS}""); set (TGT_DEBUG_FLAGS ""-g;${TGT_COMPILE_FLAGS};${TGT_WARN_FLAGS}""). # Build the Salmon library; add_library(salmon_core STATIC ${SALMON_LIB_SRCS} ); target_compile_definitions(salmon_core PUBLIC; RAPMAP_SALMON_SUPPORT=1; PUFFERFISH_SALMON_",MatchSource.DOCS,src/CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt:6372,Integrability,message,message,6372,"Main PUBLIC ""$<$<CONFIG:RELEASE>:${TGT_RELEASE_FLAGS}>""). add_executable(unitTests ${UNIT_TESTS_INDIVIDUAL_SRCS} ${GAT_SOURCE_DIR}/tests/catch.hpp); target_compile_options(unitTests PUBLIC ""$<$<CONFIG:DEBUG>:${TGT_DEBUG_FLAGS}>""); target_compile_options(unitTests PUBLIC ""$<$<CONFIG:RELEASE>:${TGT_RELEASE_FLAGS}>""); target_include_directories(unitTests PUBLIC ${COMPACT_VECTOR_INCLUDE_PATH}). #add_executable(salmon-read ${SALMON_READ_SRCS}); #set_target_properties(salmon-read PROPERTIES COMPILE_FLAGS ""${CMAKE_CXX_FLAGS} -DHAVE_LIBPTHREAD -D_PBGZF_USE -fopenmp""; # LINK_FLAGS ""-DHAVE_LIBPTHREAD -D_PBGZF_USE -fopenmp""). #set_target_properties(salmon_core salmon PROPERTIES LINK_SEARCH_END_STATIC TRUE). # our suffix array construction libraries; #if(NOT LIBDIVSUFSORT_FOUND); # set (SUFFARRAY_LIB ${GAT_SOURCE_DIR}/external/install/lib/libdivsufsort.a); # set (SUFFARRAY_LIB64 ${GAT_SOURCE_DIR}/external/install/lib/libdivsufsort64.a); # message (""Setting libdivsufsort = ${SUFFARRAY_LIB}"") ; # message (""Setting libdivsufsort64 = ${SUFFARRAY_LIB64}"") ; #endif(). add_dependencies(salmon puffer); add_dependencies(salmon twopaco); add_dependencies(salmon graphdump); add_dependencies(salmon ntcard); add_dependencies(salmon ksw2pp); add_dependencies(salmon salmon_core); add_dependencies(salmon alevin_core); if(TBB_RECONFIGURE OR TBB_TARGET_EXISTED). # Link the executable; target_link_libraries(salmon; Threads::Threads ; puffer ; salmon_core; twopaco; graphdump; ntcard; gff; ${Boost_LIBRARIES}; ${ICU_LIBS}; ${CURL_LIBRARIES}; ${ZLIB_LIBRARY}; m; ${STADEN_LIBRARIES} ; ${LIBLZMA_LIBRARIES}; ${BZIP2_LIBRARIES}; ${LIBSALMON_LINKER_FLAGS}; ${NON_APPLECLANG_LIBS}; ksw2pp; alevin_core; ${ASAN_LIB}; ${FAST_MALLOC_LIB}; TBB::tbb; TBB::tbbmalloc; ${LIBRT}; ${CMAKE_DL_LIBS}; ); endif(). # dependencies for unitTests; add_dependencies(salmon salmon_core); add_dependencies(salmon alevin_core); add_dependencies(unitTests UnitTestsMain); #add_dependencies(salmon puffer); #add_dependencies(salmon twop",MatchSource.DOCS,src/CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt:6429,Integrability,message,message,6429,"Main PUBLIC ""$<$<CONFIG:RELEASE>:${TGT_RELEASE_FLAGS}>""). add_executable(unitTests ${UNIT_TESTS_INDIVIDUAL_SRCS} ${GAT_SOURCE_DIR}/tests/catch.hpp); target_compile_options(unitTests PUBLIC ""$<$<CONFIG:DEBUG>:${TGT_DEBUG_FLAGS}>""); target_compile_options(unitTests PUBLIC ""$<$<CONFIG:RELEASE>:${TGT_RELEASE_FLAGS}>""); target_include_directories(unitTests PUBLIC ${COMPACT_VECTOR_INCLUDE_PATH}). #add_executable(salmon-read ${SALMON_READ_SRCS}); #set_target_properties(salmon-read PROPERTIES COMPILE_FLAGS ""${CMAKE_CXX_FLAGS} -DHAVE_LIBPTHREAD -D_PBGZF_USE -fopenmp""; # LINK_FLAGS ""-DHAVE_LIBPTHREAD -D_PBGZF_USE -fopenmp""). #set_target_properties(salmon_core salmon PROPERTIES LINK_SEARCH_END_STATIC TRUE). # our suffix array construction libraries; #if(NOT LIBDIVSUFSORT_FOUND); # set (SUFFARRAY_LIB ${GAT_SOURCE_DIR}/external/install/lib/libdivsufsort.a); # set (SUFFARRAY_LIB64 ${GAT_SOURCE_DIR}/external/install/lib/libdivsufsort64.a); # message (""Setting libdivsufsort = ${SUFFARRAY_LIB}"") ; # message (""Setting libdivsufsort64 = ${SUFFARRAY_LIB64}"") ; #endif(). add_dependencies(salmon puffer); add_dependencies(salmon twopaco); add_dependencies(salmon graphdump); add_dependencies(salmon ntcard); add_dependencies(salmon ksw2pp); add_dependencies(salmon salmon_core); add_dependencies(salmon alevin_core); if(TBB_RECONFIGURE OR TBB_TARGET_EXISTED). # Link the executable; target_link_libraries(salmon; Threads::Threads ; puffer ; salmon_core; twopaco; graphdump; ntcard; gff; ${Boost_LIBRARIES}; ${ICU_LIBS}; ${CURL_LIBRARIES}; ${ZLIB_LIBRARY}; m; ${STADEN_LIBRARIES} ; ${LIBLZMA_LIBRARIES}; ${BZIP2_LIBRARIES}; ${LIBSALMON_LINKER_FLAGS}; ${NON_APPLECLANG_LIBS}; ksw2pp; alevin_core; ${ASAN_LIB}; ${FAST_MALLOC_LIB}; TBB::tbb; TBB::tbbmalloc; ${LIBRT}; ${CMAKE_DL_LIBS}; ); endif(). # dependencies for unitTests; add_dependencies(salmon salmon_core); add_dependencies(salmon alevin_core); add_dependencies(unitTests UnitTestsMain); #add_dependencies(salmon puffer); #add_dependencies(salmon twop",MatchSource.DOCS,src/CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt:7222,Integrability,depend,dependencies,7222,"(""Setting libdivsufsort = ${SUFFARRAY_LIB}"") ; # message (""Setting libdivsufsort64 = ${SUFFARRAY_LIB64}"") ; #endif(). add_dependencies(salmon puffer); add_dependencies(salmon twopaco); add_dependencies(salmon graphdump); add_dependencies(salmon ntcard); add_dependencies(salmon ksw2pp); add_dependencies(salmon salmon_core); add_dependencies(salmon alevin_core); if(TBB_RECONFIGURE OR TBB_TARGET_EXISTED). # Link the executable; target_link_libraries(salmon; Threads::Threads ; puffer ; salmon_core; twopaco; graphdump; ntcard; gff; ${Boost_LIBRARIES}; ${ICU_LIBS}; ${CURL_LIBRARIES}; ${ZLIB_LIBRARY}; m; ${STADEN_LIBRARIES} ; ${LIBLZMA_LIBRARIES}; ${BZIP2_LIBRARIES}; ${LIBSALMON_LINKER_FLAGS}; ${NON_APPLECLANG_LIBS}; ksw2pp; alevin_core; ${ASAN_LIB}; ${FAST_MALLOC_LIB}; TBB::tbb; TBB::tbbmalloc; ${LIBRT}; ${CMAKE_DL_LIBS}; ); endif(). # dependencies for unitTests; add_dependencies(salmon salmon_core); add_dependencies(salmon alevin_core); add_dependencies(unitTests UnitTestsMain); #add_dependencies(salmon puffer); #add_dependencies(salmon twopaco); #add_dependencies(salmon graphdump); #add_dependencies(salmon ntcard); #add_dependencies(salmon ksw2pp). if(TBB_RECONFIGURE OR TBB_TARGET_EXISTED). target_link_libraries(unitTests; Threads::Threads; ## PUFF_INTEGRATION; ${Boost_LIBRARIES}; salmon_core; alevin_core; gff; UnitTestsMain; ${Boost_LIBRARIES}; ${STADEN_LIBRARIES} ; ${ICU_LIBS}; ${CURL_LIBRARIES}; ${ZLIB_LIBRARY}; m; ${LIBLZMA_LIBRARIES}; ${BZIP2_LIBRARIES}; #${TBB_LIBRARIES}; TBB::tbb; TBB::tbbmalloc; ${LIBSALMON_LINKER_FLAGS}; ${NON_APPLECLANG_LIBS}; ${ASAN_LIB}; ${LIBRT}; ${CMAKE_DL_LIBS}; #ubsan; ); endif(). if(NOT Iconv_IS_BUILT_IN); target_link_libraries(unitTests Iconv::Iconv); target_link_libraries(salmon Iconv::Iconv); endif(). add_dependencies(salmon unitTests); add_dependencies(unitTests salmon_core); add_dependencies(unitTests alevin_core). ##; # External dependencies of salmon_core and salmon; ##; if (${FETCHED_JEMALLOC}); add_dependencies(alevin_core libje",MatchSource.DOCS,src/CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt:8277,Integrability,depend,dependencies,8277,"add_dependencies(salmon puffer); #add_dependencies(salmon twopaco); #add_dependencies(salmon graphdump); #add_dependencies(salmon ntcard); #add_dependencies(salmon ksw2pp). if(TBB_RECONFIGURE OR TBB_TARGET_EXISTED). target_link_libraries(unitTests; Threads::Threads; ## PUFF_INTEGRATION; ${Boost_LIBRARIES}; salmon_core; alevin_core; gff; UnitTestsMain; ${Boost_LIBRARIES}; ${STADEN_LIBRARIES} ; ${ICU_LIBS}; ${CURL_LIBRARIES}; ${ZLIB_LIBRARY}; m; ${LIBLZMA_LIBRARIES}; ${BZIP2_LIBRARIES}; #${TBB_LIBRARIES}; TBB::tbb; TBB::tbbmalloc; ${LIBSALMON_LINKER_FLAGS}; ${NON_APPLECLANG_LIBS}; ${ASAN_LIB}; ${LIBRT}; ${CMAKE_DL_LIBS}; #ubsan; ); endif(). if(NOT Iconv_IS_BUILT_IN); target_link_libraries(unitTests Iconv::Iconv); target_link_libraries(salmon Iconv::Iconv); endif(). add_dependencies(salmon unitTests); add_dependencies(unitTests salmon_core); add_dependencies(unitTests alevin_core). ##; # External dependencies of salmon_core and salmon; ##; if (${FETCHED_JEMALLOC}); add_dependencies(alevin_core libjemalloc); add_dependencies(salmon_core libjemalloc); add_dependencies(salmon libjemalloc); endif(). if (${FETCHED_BOOST}); add_dependencies(alevin_core libboost); add_dependencies(salmon_core libboost); add_dependencies(salmon libboost); endif(). if (${FETCHED_TBB}); message(""Fetched oneTBB, so libtbb must be a dependency for targets""); add_dependencies(alevin_core libtbb); add_dependencies(salmon_core libtbb); add_dependencies(unitTests libtbb); add_dependencies(salmon libtbb); endif(). if (${FETCHED_CEREAL}); add_dependencies(alevin_core libcereal); add_dependencies(salmon_core libcereal); add_dependencies(salmon libcereal); endif(). if (${FETCHED_STADEN}); ## PUFF_INTEGRATION; # add_dependencies(alevin_core libstadenio); add_dependencies(alevin_core libstadenio); add_dependencies(salmon_core libstadenio); add_dependencies(salmon libstadenio); endif(). #add_dependencies(salmon_core libbwa); #add_dependencies(salmon libbwa). if (${FETCHED_GFF}); add_dependencies(alevin_core ",MatchSource.DOCS,src/CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt:8648,Integrability,message,message,8648,"DEN_LIBRARIES} ; ${ICU_LIBS}; ${CURL_LIBRARIES}; ${ZLIB_LIBRARY}; m; ${LIBLZMA_LIBRARIES}; ${BZIP2_LIBRARIES}; #${TBB_LIBRARIES}; TBB::tbb; TBB::tbbmalloc; ${LIBSALMON_LINKER_FLAGS}; ${NON_APPLECLANG_LIBS}; ${ASAN_LIB}; ${LIBRT}; ${CMAKE_DL_LIBS}; #ubsan; ); endif(). if(NOT Iconv_IS_BUILT_IN); target_link_libraries(unitTests Iconv::Iconv); target_link_libraries(salmon Iconv::Iconv); endif(). add_dependencies(salmon unitTests); add_dependencies(unitTests salmon_core); add_dependencies(unitTests alevin_core). ##; # External dependencies of salmon_core and salmon; ##; if (${FETCHED_JEMALLOC}); add_dependencies(alevin_core libjemalloc); add_dependencies(salmon_core libjemalloc); add_dependencies(salmon libjemalloc); endif(). if (${FETCHED_BOOST}); add_dependencies(alevin_core libboost); add_dependencies(salmon_core libboost); add_dependencies(salmon libboost); endif(). if (${FETCHED_TBB}); message(""Fetched oneTBB, so libtbb must be a dependency for targets""); add_dependencies(alevin_core libtbb); add_dependencies(salmon_core libtbb); add_dependencies(unitTests libtbb); add_dependencies(salmon libtbb); endif(). if (${FETCHED_CEREAL}); add_dependencies(alevin_core libcereal); add_dependencies(salmon_core libcereal); add_dependencies(salmon libcereal); endif(). if (${FETCHED_STADEN}); ## PUFF_INTEGRATION; # add_dependencies(alevin_core libstadenio); add_dependencies(alevin_core libstadenio); add_dependencies(salmon_core libstadenio); add_dependencies(salmon libstadenio); endif(). #add_dependencies(salmon_core libbwa); #add_dependencies(salmon libbwa). if (${FETCHED_GFF}); add_dependencies(alevin_core libgff); add_dependencies(salmon_core libgff); add_dependencies(salmon libgff); endif(). ### No need for this, I think; ## This ensures that the salmon executable should work with or without `make install`; ###; ## Grumble grumble . . . OSX; #if (APPLE); # # only attempt install_name_tool for tbb if we installed it; # if (${TBB_LIBRARY_DIRS} MATCHES ${GAT_SOURCE_DIR}/external/",MatchSource.DOCS,src/CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt:8693,Integrability,depend,dependency,8693,"DEN_LIBRARIES} ; ${ICU_LIBS}; ${CURL_LIBRARIES}; ${ZLIB_LIBRARY}; m; ${LIBLZMA_LIBRARIES}; ${BZIP2_LIBRARIES}; #${TBB_LIBRARIES}; TBB::tbb; TBB::tbbmalloc; ${LIBSALMON_LINKER_FLAGS}; ${NON_APPLECLANG_LIBS}; ${ASAN_LIB}; ${LIBRT}; ${CMAKE_DL_LIBS}; #ubsan; ); endif(). if(NOT Iconv_IS_BUILT_IN); target_link_libraries(unitTests Iconv::Iconv); target_link_libraries(salmon Iconv::Iconv); endif(). add_dependencies(salmon unitTests); add_dependencies(unitTests salmon_core); add_dependencies(unitTests alevin_core). ##; # External dependencies of salmon_core and salmon; ##; if (${FETCHED_JEMALLOC}); add_dependencies(alevin_core libjemalloc); add_dependencies(salmon_core libjemalloc); add_dependencies(salmon libjemalloc); endif(). if (${FETCHED_BOOST}); add_dependencies(alevin_core libboost); add_dependencies(salmon_core libboost); add_dependencies(salmon libboost); endif(). if (${FETCHED_TBB}); message(""Fetched oneTBB, so libtbb must be a dependency for targets""); add_dependencies(alevin_core libtbb); add_dependencies(salmon_core libtbb); add_dependencies(unitTests libtbb); add_dependencies(salmon libtbb); endif(). if (${FETCHED_CEREAL}); add_dependencies(alevin_core libcereal); add_dependencies(salmon_core libcereal); add_dependencies(salmon libcereal); endif(). if (${FETCHED_STADEN}); ## PUFF_INTEGRATION; # add_dependencies(alevin_core libstadenio); add_dependencies(alevin_core libstadenio); add_dependencies(salmon_core libstadenio); add_dependencies(salmon libstadenio); endif(). #add_dependencies(salmon_core libbwa); #add_dependencies(salmon libbwa). if (${FETCHED_GFF}); add_dependencies(alevin_core libgff); add_dependencies(salmon_core libgff); add_dependencies(salmon libgff); endif(). ### No need for this, I think; ## This ensures that the salmon executable should work with or without `make install`; ###; ## Grumble grumble . . . OSX; #if (APPLE); # # only attempt install_name_tool for tbb if we installed it; # if (${TBB_LIBRARY_DIRS} MATCHES ${GAT_SOURCE_DIR}/external/",MatchSource.DOCS,src/CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt:11841,Integrability,message,message,11841,"l -add_rpath ${GAT_SOURCE_DIR}/external/install/lib ${GAT_SOURCE_DIR}/build/src/unitTests; # ); # endif(); #else(); # # related to complete static linking --- on hold ; # set (BOOST_THREAD_LIBRARY); #endif(). #if (APPLE); #	add_custom_command(TARGET salmon; #		POST_BUILD; #		COMMAND install_name_tool -add_rpath ${GAT_SOURCE_DIR}/external/install/lib salmon; #	COMMAND install_name_tool -add_rpath @executable_path/../lib salmon; #		); #endif(). ##### ======================================. IF(CMAKE_INSTALL_PREFIX_INITIALIZED_TO_DEFAULT); SET(CMAKE_INSTALL_PREFIX; ""${GAT_SOURCE_DIR}"" CACHE PATH ""Default install prefix"" FORCE; ); ENDIF(CMAKE_INSTALL_PREFIX_INITIALIZED_TO_DEFAULT). set(INSTALL_LIB_DIR lib ); set(INSTALL_BIN_DIR bin ); set(INSTALL_INCLUDE_DIR include ). if(TBB_RECONFIGURE OR TBB_TARGET_EXISTED); #set(TBB_SOURCE_DIR $<TARGET_FILE:TBB::tbb>); #add_custom_target(genexdebug COMMAND ${CMAKE_COMMAND} -E echo ""$<TARGET_LINKER_FILE:TBB::tbb>""); get_target_property(TBB_LIB_INSTALL_NAME TBB::tbb IMPORTED_LOCATION_RELEASE); get_filename_component(TBB_LIB_INSTALL_DIR ${TBB_LIB_INSTALL_NAME} DIRECTORY); message(""TBB_LIB_INSTALL_DIR = ${TBB_LIB_INSTALL_DIR}""); file(GLOB TBB_FILES ${TBB_LIB_INSTALL_DIR}/libtbb*.${SHARED_LIB_EXTENSION}*); message(""TBBGLOBS = ${TBB_FILES}""). install(FILES ; ${TBB_FILES}; DESTINATION ${INSTALL_LIB_DIR}; ) ; #install(FILES ; # $<TARGET_FILE:TBB::tbbmalloc>; # DESTINATION ${INSTALL_LIB_DIR}; #); #install(DIRECTORY; # ${TBB_SOURCE_DIR}; # DESTINATION ${INSTALL_LIB_DIR}; #	 FILES_MATCHING PATTERN ""libtbb*.${SHARED_LIB_EXTENSION}*""; #); endif(). #install(DIRECTORY; # ${GAT_SOURCE_DIR}/external/install/lib/; # DESTINATION ${INSTALL_LIB_DIR}; #	 FILES_MATCHING PATTERN ""libtbb*.${SHARED_LIB_EXTENSION}*""; # ). # install(FILES ${Boost_LIBRARIES}; # 	 DESTINATION ${INSTALL_LIB_DIR}). install(TARGETS salmon salmon_core; RUNTIME DESTINATION bin; LIBRARY DESTINATION lib; ARCHIVE DESTINATION lib; ). add_custom_command(TARGET unitTests POST_BUILD; COMMAND ",MatchSource.DOCS,src/CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt:11976,Integrability,message,message,11976,"#		POST_BUILD; #		COMMAND install_name_tool -add_rpath ${GAT_SOURCE_DIR}/external/install/lib salmon; #	COMMAND install_name_tool -add_rpath @executable_path/../lib salmon; #		); #endif(). ##### ======================================. IF(CMAKE_INSTALL_PREFIX_INITIALIZED_TO_DEFAULT); SET(CMAKE_INSTALL_PREFIX; ""${GAT_SOURCE_DIR}"" CACHE PATH ""Default install prefix"" FORCE; ); ENDIF(CMAKE_INSTALL_PREFIX_INITIALIZED_TO_DEFAULT). set(INSTALL_LIB_DIR lib ); set(INSTALL_BIN_DIR bin ); set(INSTALL_INCLUDE_DIR include ). if(TBB_RECONFIGURE OR TBB_TARGET_EXISTED); #set(TBB_SOURCE_DIR $<TARGET_FILE:TBB::tbb>); #add_custom_target(genexdebug COMMAND ${CMAKE_COMMAND} -E echo ""$<TARGET_LINKER_FILE:TBB::tbb>""); get_target_property(TBB_LIB_INSTALL_NAME TBB::tbb IMPORTED_LOCATION_RELEASE); get_filename_component(TBB_LIB_INSTALL_DIR ${TBB_LIB_INSTALL_NAME} DIRECTORY); message(""TBB_LIB_INSTALL_DIR = ${TBB_LIB_INSTALL_DIR}""); file(GLOB TBB_FILES ${TBB_LIB_INSTALL_DIR}/libtbb*.${SHARED_LIB_EXTENSION}*); message(""TBBGLOBS = ${TBB_FILES}""). install(FILES ; ${TBB_FILES}; DESTINATION ${INSTALL_LIB_DIR}; ) ; #install(FILES ; # $<TARGET_FILE:TBB::tbbmalloc>; # DESTINATION ${INSTALL_LIB_DIR}; #); #install(DIRECTORY; # ${TBB_SOURCE_DIR}; # DESTINATION ${INSTALL_LIB_DIR}; #	 FILES_MATCHING PATTERN ""libtbb*.${SHARED_LIB_EXTENSION}*""; #); endif(). #install(DIRECTORY; # ${GAT_SOURCE_DIR}/external/install/lib/; # DESTINATION ${INSTALL_LIB_DIR}; #	 FILES_MATCHING PATTERN ""libtbb*.${SHARED_LIB_EXTENSION}*""; # ). # install(FILES ${Boost_LIBRARIES}; # 	 DESTINATION ${INSTALL_LIB_DIR}). install(TARGETS salmon salmon_core; RUNTIME DESTINATION bin; LIBRARY DESTINATION lib; ARCHIVE DESTINATION lib; ). add_custom_command(TARGET unitTests POST_BUILD; COMMAND ${CMAKE_COMMAND} -E copy $<TARGET_FILE:unitTests> ${GAT_SOURCE_DIR}/tests/$<TARGET_FILE_NAME:unitTests>; COMMENT ""Copying unitTests""; ). set(POST_INSTALL_SCRIPT ${GAT_SOURCE_DIR}/cmake/PostInstall.cmake). install(; CODE; ""; execute_process(COMMAND \""${CMAKE",MatchSource.DOCS,src/CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt:2204,Testability,test,tests,2204,"STAParser.cpp; AlignmentModel.cpp; ONTAlignmentModel.cpp; AlignmentCommon.cpp; FragmentLengthDistribution.cpp; SalmonQuantifyAlignments.cpp; BAMUtils.cpp; ). set (ALEVIN_LIB_SRCS; edlib.cpp; SingleCellProtocols.cpp; AlevinUtils.cpp; ). set (SALMON_LIB_SRCS; ${GAT_SOURCE_DIR}/src/jellyfish/mer_dna.cc; backtrace.cc; xxhash.c; TranscriptGroup.cpp; EffectiveLengthStats.cpp; LibraryFormat.cpp; GenomicFeature.cpp; VersionChecker.cpp; SBModel.cpp; FastxParser.cpp; StadenUtils.cpp; SalmonUtils.cpp; DistributionUtils.cpp; SalmonExceptions.cpp; SalmonStringUtils.cpp; SimplePosBias.cpp; SGSmooth.cpp; ${GAT_SOURCE_DIR}/external/install/src/pufferfish/metro/metrohash64.cpp; ). # check if we know how to do IPO; check_ipo_supported(RESULT HAS_IPO). if (DEFINED NO_IPO); message(""NO_IPO = ${NO_IPO}""); else(); message(""NO_IPO = FALSE""); set(NO_IPO FALSE); endif(). if(HAS_IPO AND (NOT NO_IPO)); set_property(TARGET ksw2pp PROPERTY INTERPROCEDURAL_OPTIMIZATION True); endif(). set (UNIT_TESTS_ENTRY_SRCS; ${GAT_SOURCE_DIR}/tests/UnitTests.cpp; ). set (UNIT_TESTS_INDIVIDUAL_SRCS; ${GAT_SOURCE_DIR}/src/FragmentLengthDistribution.cpp; ${GAT_SOURCE_DIR}/external/install/src/pufferfish/rank9b.cpp; ${GAT_SOURCE_DIR}/tests/GCSampleTests.cpp; ${GAT_SOURCE_DIR}/tests/LibraryTypeTests.cpp; ). link_directories(; ${GAT_SOURCE_DIR}/lib; ${GAT_SOURCE_DIR}/external/install/lib; ${Boost_LIBRARY_DIRS}; ${TBB_LIBRARY_DIRS}; ${LAPACK_LIBRARY_DIR}; ${BLAS_LIBRARY_DIR}; ${LIB_GFF_LIBRARY_DIR}; ). message(""TBB_LIBRARIES = ${TBB_LIBRARIES}""). # Set the RPATH; if (NOT APPLE); set(CMAKE_INSTALL_RPATH ""$ORIGIN/../lib:$ORIGIN/../../lib:$ORIGIN/:$ORIGIN/../../external/install/lib""); set(CMAKE_BUILD_WITH_INSTALL_RPATH TRUE); else(); # use, i.e. do not skip the full RPATH for the build tree; set(CMAKE_SKIP_BUILD_RPATH FALSE). # when building, don't use the install RPATH already; # (but later on when installing); set(CMAKE_BUILD_WITH_INSTALL_RPATH FALSE) . # the RPATH to be used when installing; set(CMAKE_INSTALL_RPATH ",MatchSource.DOCS,src/CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt:2395,Testability,test,tests,2395,"ocols.cpp; AlevinUtils.cpp; ). set (SALMON_LIB_SRCS; ${GAT_SOURCE_DIR}/src/jellyfish/mer_dna.cc; backtrace.cc; xxhash.c; TranscriptGroup.cpp; EffectiveLengthStats.cpp; LibraryFormat.cpp; GenomicFeature.cpp; VersionChecker.cpp; SBModel.cpp; FastxParser.cpp; StadenUtils.cpp; SalmonUtils.cpp; DistributionUtils.cpp; SalmonExceptions.cpp; SalmonStringUtils.cpp; SimplePosBias.cpp; SGSmooth.cpp; ${GAT_SOURCE_DIR}/external/install/src/pufferfish/metro/metrohash64.cpp; ). # check if we know how to do IPO; check_ipo_supported(RESULT HAS_IPO). if (DEFINED NO_IPO); message(""NO_IPO = ${NO_IPO}""); else(); message(""NO_IPO = FALSE""); set(NO_IPO FALSE); endif(). if(HAS_IPO AND (NOT NO_IPO)); set_property(TARGET ksw2pp PROPERTY INTERPROCEDURAL_OPTIMIZATION True); endif(). set (UNIT_TESTS_ENTRY_SRCS; ${GAT_SOURCE_DIR}/tests/UnitTests.cpp; ). set (UNIT_TESTS_INDIVIDUAL_SRCS; ${GAT_SOURCE_DIR}/src/FragmentLengthDistribution.cpp; ${GAT_SOURCE_DIR}/external/install/src/pufferfish/rank9b.cpp; ${GAT_SOURCE_DIR}/tests/GCSampleTests.cpp; ${GAT_SOURCE_DIR}/tests/LibraryTypeTests.cpp; ). link_directories(; ${GAT_SOURCE_DIR}/lib; ${GAT_SOURCE_DIR}/external/install/lib; ${Boost_LIBRARY_DIRS}; ${TBB_LIBRARY_DIRS}; ${LAPACK_LIBRARY_DIR}; ${BLAS_LIBRARY_DIR}; ${LIB_GFF_LIBRARY_DIR}; ). message(""TBB_LIBRARIES = ${TBB_LIBRARIES}""). # Set the RPATH; if (NOT APPLE); set(CMAKE_INSTALL_RPATH ""$ORIGIN/../lib:$ORIGIN/../../lib:$ORIGIN/:$ORIGIN/../../external/install/lib""); set(CMAKE_BUILD_WITH_INSTALL_RPATH TRUE); else(); # use, i.e. do not skip the full RPATH for the build tree; set(CMAKE_SKIP_BUILD_RPATH FALSE). # when building, don't use the install RPATH already; # (but later on when installing); set(CMAKE_BUILD_WITH_INSTALL_RPATH FALSE) . # the RPATH to be used when installing; set(CMAKE_INSTALL_RPATH """"). # don't add the automatically determined parts of the RPATH; # which point to directories outside the build tree to the install RPATH; set(CMAKE_INSTALL_RPATH_USE_LINK_PATH FALSE); endif(). set (TGT_R",MatchSource.DOCS,src/CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt:2438,Testability,test,tests,2438,"B_SRCS; ${GAT_SOURCE_DIR}/src/jellyfish/mer_dna.cc; backtrace.cc; xxhash.c; TranscriptGroup.cpp; EffectiveLengthStats.cpp; LibraryFormat.cpp; GenomicFeature.cpp; VersionChecker.cpp; SBModel.cpp; FastxParser.cpp; StadenUtils.cpp; SalmonUtils.cpp; DistributionUtils.cpp; SalmonExceptions.cpp; SalmonStringUtils.cpp; SimplePosBias.cpp; SGSmooth.cpp; ${GAT_SOURCE_DIR}/external/install/src/pufferfish/metro/metrohash64.cpp; ). # check if we know how to do IPO; check_ipo_supported(RESULT HAS_IPO). if (DEFINED NO_IPO); message(""NO_IPO = ${NO_IPO}""); else(); message(""NO_IPO = FALSE""); set(NO_IPO FALSE); endif(). if(HAS_IPO AND (NOT NO_IPO)); set_property(TARGET ksw2pp PROPERTY INTERPROCEDURAL_OPTIMIZATION True); endif(). set (UNIT_TESTS_ENTRY_SRCS; ${GAT_SOURCE_DIR}/tests/UnitTests.cpp; ). set (UNIT_TESTS_INDIVIDUAL_SRCS; ${GAT_SOURCE_DIR}/src/FragmentLengthDistribution.cpp; ${GAT_SOURCE_DIR}/external/install/src/pufferfish/rank9b.cpp; ${GAT_SOURCE_DIR}/tests/GCSampleTests.cpp; ${GAT_SOURCE_DIR}/tests/LibraryTypeTests.cpp; ). link_directories(; ${GAT_SOURCE_DIR}/lib; ${GAT_SOURCE_DIR}/external/install/lib; ${Boost_LIBRARY_DIRS}; ${TBB_LIBRARY_DIRS}; ${LAPACK_LIBRARY_DIR}; ${BLAS_LIBRARY_DIR}; ${LIB_GFF_LIBRARY_DIR}; ). message(""TBB_LIBRARIES = ${TBB_LIBRARIES}""). # Set the RPATH; if (NOT APPLE); set(CMAKE_INSTALL_RPATH ""$ORIGIN/../lib:$ORIGIN/../../lib:$ORIGIN/:$ORIGIN/../../external/install/lib""); set(CMAKE_BUILD_WITH_INSTALL_RPATH TRUE); else(); # use, i.e. do not skip the full RPATH for the build tree; set(CMAKE_SKIP_BUILD_RPATH FALSE). # when building, don't use the install RPATH already; # (but later on when installing); set(CMAKE_BUILD_WITH_INSTALL_RPATH FALSE) . # the RPATH to be used when installing; set(CMAKE_INSTALL_RPATH """"). # don't add the automatically determined parts of the RPATH; # which point to directories outside the build tree to the install RPATH; set(CMAKE_INSTALL_RPATH_USE_LINK_PATH FALSE); endif(). set (TGT_RELEASE_FLAGS ""${TGT_COMPILE_FLAGS};${TGT_WAR",MatchSource.DOCS,src/CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt:5562,Testability,test,tests,5562,"ude_directories(alevin_core PUBLIC ${COMPACT_VECTOR_INCLUDE_PATH}). if (USE_ARM); target_compile_definitions(alevin_core PUBLIC KSW_USE_ARM=1); endif(). target_compile_options(alevin_core PUBLIC ""$<$<CONFIG:DEBUG>:${TGT_DEBUG_FLAGS}>""); target_compile_options(alevin_core PUBLIC ""$<$<CONFIG:RELEASE>:${TGT_RELEASE_FLAGS}>""). if(HAS_IPO AND (NOT NO_IPO)); set_property(TARGET alevin_core PROPERTY INTERPROCEDURAL_OPTIMIZATION True); endif(). # Build the salmon executable; add_executable(salmon ${SALMON_MAIN_SRCS} ${SALMON_ALIGN_SRCS}); target_include_directories(salmon PUBLIC ${COMPACT_VECTOR_INCLUDE_PATH}). if(HAS_IPO AND (NOT NO_IPO)); set_property(TARGET salmon PROPERTY INTERPROCEDURAL_OPTIMIZATION True); endif(). add_library(UnitTestsMain STATIC ${UNIT_TESTS_ENTRY_SRCS}); target_compile_options(UnitTestsMain PUBLIC ""$<$<CONFIG:DEBUG>:${TGT_DEBUG_FLAGS}>""); target_compile_options(UnitTestsMain PUBLIC ""$<$<CONFIG:RELEASE>:${TGT_RELEASE_FLAGS}>""). add_executable(unitTests ${UNIT_TESTS_INDIVIDUAL_SRCS} ${GAT_SOURCE_DIR}/tests/catch.hpp); target_compile_options(unitTests PUBLIC ""$<$<CONFIG:DEBUG>:${TGT_DEBUG_FLAGS}>""); target_compile_options(unitTests PUBLIC ""$<$<CONFIG:RELEASE>:${TGT_RELEASE_FLAGS}>""); target_include_directories(unitTests PUBLIC ${COMPACT_VECTOR_INCLUDE_PATH}). #add_executable(salmon-read ${SALMON_READ_SRCS}); #set_target_properties(salmon-read PROPERTIES COMPILE_FLAGS ""${CMAKE_CXX_FLAGS} -DHAVE_LIBPTHREAD -D_PBGZF_USE -fopenmp""; # LINK_FLAGS ""-DHAVE_LIBPTHREAD -D_PBGZF_USE -fopenmp""). #set_target_properties(salmon_core salmon PROPERTIES LINK_SEARCH_END_STATIC TRUE). # our suffix array construction libraries; #if(NOT LIBDIVSUFSORT_FOUND); # set (SUFFARRAY_LIB ${GAT_SOURCE_DIR}/external/install/lib/libdivsufsort.a); # set (SUFFARRAY_LIB64 ${GAT_SOURCE_DIR}/external/install/lib/libdivsufsort64.a); # message (""Setting libdivsufsort = ${SUFFARRAY_LIB}"") ; # message (""Setting libdivsufsort64 = ${SUFFARRAY_LIB64}"") ; #endif(). add_dependencies(salmon puffer); ",MatchSource.DOCS,src/CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt:12791,Testability,test,tests,12791,"ET_LINKER_FILE:TBB::tbb>""); get_target_property(TBB_LIB_INSTALL_NAME TBB::tbb IMPORTED_LOCATION_RELEASE); get_filename_component(TBB_LIB_INSTALL_DIR ${TBB_LIB_INSTALL_NAME} DIRECTORY); message(""TBB_LIB_INSTALL_DIR = ${TBB_LIB_INSTALL_DIR}""); file(GLOB TBB_FILES ${TBB_LIB_INSTALL_DIR}/libtbb*.${SHARED_LIB_EXTENSION}*); message(""TBBGLOBS = ${TBB_FILES}""). install(FILES ; ${TBB_FILES}; DESTINATION ${INSTALL_LIB_DIR}; ) ; #install(FILES ; # $<TARGET_FILE:TBB::tbbmalloc>; # DESTINATION ${INSTALL_LIB_DIR}; #); #install(DIRECTORY; # ${TBB_SOURCE_DIR}; # DESTINATION ${INSTALL_LIB_DIR}; #	 FILES_MATCHING PATTERN ""libtbb*.${SHARED_LIB_EXTENSION}*""; #); endif(). #install(DIRECTORY; # ${GAT_SOURCE_DIR}/external/install/lib/; # DESTINATION ${INSTALL_LIB_DIR}; #	 FILES_MATCHING PATTERN ""libtbb*.${SHARED_LIB_EXTENSION}*""; # ). # install(FILES ${Boost_LIBRARIES}; # 	 DESTINATION ${INSTALL_LIB_DIR}). install(TARGETS salmon salmon_core; RUNTIME DESTINATION bin; LIBRARY DESTINATION lib; ARCHIVE DESTINATION lib; ). add_custom_command(TARGET unitTests POST_BUILD; COMMAND ${CMAKE_COMMAND} -E copy $<TARGET_FILE:unitTests> ${GAT_SOURCE_DIR}/tests/$<TARGET_FILE_NAME:unitTests>; COMMENT ""Copying unitTests""; ). set(POST_INSTALL_SCRIPT ${GAT_SOURCE_DIR}/cmake/PostInstall.cmake). install(; CODE; ""; execute_process(COMMAND \""${CMAKE_COMMAND}\""; -DCMAKE_SYSTEM_NAME=${CMAKE_SYSTEM_NAME}; -DCMAKE_INSTALL_PREFIX=${CMAKE_INSTALL_PREFIX}; -P \""${POST_INSTALL_SCRIPT}\""); ""; ). include(InstallRequiredSystemLibraries); add_test( NAME unit_tests COMMAND ${CMAKE_COMMAND} -DTOPLEVEL_DIR=${GAT_SOURCE_DIR} -P ${GAT_SOURCE_DIR}/cmake/UnitTests.cmake ); add_test( NAME salmon_read_test_quasi COMMAND ${CMAKE_COMMAND} -DTOPLEVEL_DIR=${GAT_SOURCE_DIR} -P ${GAT_SOURCE_DIR}/cmake/TestSalmonQuasi.cmake ). # Remove this test since we are removing support for the FMD index. ; # add_test( NAME salmon_read_test_fmd COMMAND ${CMAKE_COMMAND} -DTOPLEVEL_DIR=${GAT_SOURCE_DIR} -P ${GAT_SOURCE_DIR}/cmake/TestSalmonFMD.cmake ); ",MatchSource.DOCS,src/CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt
https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt:13454,Testability,test,test,13454,"ET_LINKER_FILE:TBB::tbb>""); get_target_property(TBB_LIB_INSTALL_NAME TBB::tbb IMPORTED_LOCATION_RELEASE); get_filename_component(TBB_LIB_INSTALL_DIR ${TBB_LIB_INSTALL_NAME} DIRECTORY); message(""TBB_LIB_INSTALL_DIR = ${TBB_LIB_INSTALL_DIR}""); file(GLOB TBB_FILES ${TBB_LIB_INSTALL_DIR}/libtbb*.${SHARED_LIB_EXTENSION}*); message(""TBBGLOBS = ${TBB_FILES}""). install(FILES ; ${TBB_FILES}; DESTINATION ${INSTALL_LIB_DIR}; ) ; #install(FILES ; # $<TARGET_FILE:TBB::tbbmalloc>; # DESTINATION ${INSTALL_LIB_DIR}; #); #install(DIRECTORY; # ${TBB_SOURCE_DIR}; # DESTINATION ${INSTALL_LIB_DIR}; #	 FILES_MATCHING PATTERN ""libtbb*.${SHARED_LIB_EXTENSION}*""; #); endif(). #install(DIRECTORY; # ${GAT_SOURCE_DIR}/external/install/lib/; # DESTINATION ${INSTALL_LIB_DIR}; #	 FILES_MATCHING PATTERN ""libtbb*.${SHARED_LIB_EXTENSION}*""; # ). # install(FILES ${Boost_LIBRARIES}; # 	 DESTINATION ${INSTALL_LIB_DIR}). install(TARGETS salmon salmon_core; RUNTIME DESTINATION bin; LIBRARY DESTINATION lib; ARCHIVE DESTINATION lib; ). add_custom_command(TARGET unitTests POST_BUILD; COMMAND ${CMAKE_COMMAND} -E copy $<TARGET_FILE:unitTests> ${GAT_SOURCE_DIR}/tests/$<TARGET_FILE_NAME:unitTests>; COMMENT ""Copying unitTests""; ). set(POST_INSTALL_SCRIPT ${GAT_SOURCE_DIR}/cmake/PostInstall.cmake). install(; CODE; ""; execute_process(COMMAND \""${CMAKE_COMMAND}\""; -DCMAKE_SYSTEM_NAME=${CMAKE_SYSTEM_NAME}; -DCMAKE_INSTALL_PREFIX=${CMAKE_INSTALL_PREFIX}; -P \""${POST_INSTALL_SCRIPT}\""); ""; ). include(InstallRequiredSystemLibraries); add_test( NAME unit_tests COMMAND ${CMAKE_COMMAND} -DTOPLEVEL_DIR=${GAT_SOURCE_DIR} -P ${GAT_SOURCE_DIR}/cmake/UnitTests.cmake ); add_test( NAME salmon_read_test_quasi COMMAND ${CMAKE_COMMAND} -DTOPLEVEL_DIR=${GAT_SOURCE_DIR} -P ${GAT_SOURCE_DIR}/cmake/TestSalmonQuasi.cmake ). # Remove this test since we are removing support for the FMD index. ; # add_test( NAME salmon_read_test_fmd COMMAND ${CMAKE_COMMAND} -DTOPLEVEL_DIR=${GAT_SOURCE_DIR} -P ${GAT_SOURCE_DIR}/cmake/TestSalmonFMD.cmake ); ",MatchSource.DOCS,src/CMakeLists.txt,COMBINE-lab,salmon,v1.10.1,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/tree/v1.10.1/src/CMakeLists.txt
