id,quality_attribute,keyword,matched_word,match_idx,sentence,source,filename,author,repo,version,wiki,url
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:28555,Availability,error,error,28555,"which will truncate; a single precision float's mantissa to 12 bits). Here is an example on how a user may dynamically decide how to quantize a floating point field to get the most precision out of a fixed bit width:; ```c++; auto model = RNTupleModel::Create();; auto field = std::make_unique<RField<float>>(""f"");; // assuming we have an array of floats stored in `myFloats`:; auto [minV, maxV] = std::minmax_element(myFloats.begin(), myFloats.end());; constexpr auto nBits = 24;; field->SetQuantized(*minV, *maxV, nBits);; model->AddField(std::move(field));; auto f = model->GetDefaultEntry().GetPtr<float>(""f"");. // Now we can write our floats.; auto writer = RNTupleWriter::Recreate(std::move(model), ""myNtuple"", ""myFile.root"");; for (float val : myFloats) {; *f = val;; writer->Fill();; }; ```. Relationship to other ROOT components; -------------------------------------. The RNTuple classes have the following relationship to other parts of ROOT. The RNTuple classes use core ROOT infrastructure classes, such as error handling and logging.; When necessary, RNTuple uses a `TFile` for reading and writing.; The cases of writing to a local file and reading from a local file, a file from XRootD or from HTTP, do _not_ require `TFile`.; For these cases, RNTuple depends on the `RRawFile` class and its XRootD and Davix plugins. For user-defined classes as well as sets and maps, RNTuple uses `TClass`.; Simple types and other stdlib classes are natively supported and do not require dictionaries.; See the format specification for an exhaustive list of types supported in RNTuple.; The streamer field uses the standard ROOT streaming machinery. Integration to RDataFrame is provided through an RNTuple data source.; A universal RDataFrame constructor can create a data frame from either a TTree or an RNTuple with the same syntax. The RBrowser uses RNTuple classes to display RNTuple dataset information. Future Features; ---------------. The following features are planned for after the first R",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:25770,Deployability,update,updates,25770,"control of the thread pool.; That means that RDataFrame uses a separate data source for every thread, each of the data sources runs in sequential mode. ### Concurrent Readers; Multiple readers can read the same RNTuple concurrently as long as access to every individual reader is sequential. ### Parallel REntry Preparation; Multiple `REntry` object can be concurrently prepared by multiple threads.; I.e., construction and binding of the objects can happen in parallel.; The actual reading and writing of entries (`RNTupleReader::LoadEntry()`, `RNTupleWriter::Fill()`) needs to be protected by a mutex.; This is considered ""mild scalability parallelization"" in RNTuple. ### RNTupleParallelWriter; The parallel writer offers the most scalable parallel writing interface.; Multiple _fill contexts_ can concurrently serialize and compress data.; Every fill context prepares a set of entire clusters in the final on-disk layout.; When a fill context flushes data,; a brief serialization point handles the RNTuple meta-data updates and the reservation of disk space to write into. Low precision float types; --------------------------; RNTuple supports encoding floating point types with a lower precision when writing them to disk. This encoding is specified by the; user per field and it is independent on the in-memory type used for that field (meaning both a `RField<double>` or `RField<float>` can; be mapped to e.g. a low-precision 16 bit float). RNTuple supports the following encodings (all mutually exclusive):. - **Real16**/**SplitReal16**: IEEE-754 half precision float. Set by calling `RField::SetHalfPrecision()`;; - **Real32Trunc**: floating point with less than 32 bits of precision (truncated mantissa).; Set by calling `RField::SetTruncated(n)`, with $10 <= n <= 31$ equal to the total number of bits used on disk.; Note that `SetTruncated(16)` makes this effectively a `bfloat16` on disk;; - **Real32Quant**: floating point with a normalized/quantized integer representation on disk usin",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:30676,Deployability,release,releases,30676,"dexed/unaligned) friends; - Horizontal merging: persistified friends, analogous to a classical merge being a persistified chain; - An interface for bulk writing; - Meta-data: RNTuple-specific and user-provided meta-data storage, such as file provenance, scale factors, or varied columns; - C library interface; - S3 storage backend (page source / page sink). Semantics of Reading Non-Trivial Objects; ========================================. Reading an object with RNTuple should be seen as _overwriting_ its persistent data members.; Given a properly constructed and valid object, the object must ensure that it stays valid when overwriting its persistent data members.; However, the object should not rely on its transient state to remain unchanged during reading:; it may be destructed and constructed again when it is read as part of a collection (see below). An object that is being read from disk may have been constructed by `RField::CreateValue()`.; In this case, the deleter returned by `RField::GetDeleter()` releases the resources. When reading collections of type `T` (`std::vector<T>`, `ROOT::RVec<T>`, ...), RNTuple uses `RField::CreateValue()` to construct elements of the inner type `T`.; As the size of a collection changes from event to event, this has the following effect on its elements; - If the collection shrinks, cut-off elements are destructed; - If the collection grows, new elements are constructed before reading them; - If the array buffer of the collection is reallocated (may happen for both shrinking and growing depending on the collection), all elements are destructed first in the old buffer; and the new number of elements is constructed in the new buffer. So unless the collection buffer needs to be reallocated, RNTuple tries to avoid unnecessary destruction/construction but instead overwrites existing objects.; Note that RNTuple currently does not copy or move existing objects when the collection buffer is reallocated. Naming Conventions; ================",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:15650,Energy Efficiency,reduce,reduce,15650," RNTuple data source also supports multi-threaded dataframes, parallelized on the file and cluster level. The data source exposes inner fields of complex collections.; For instance, if the data model contains a vector of `Event` classes, where each `Event` has `pt` and `eta` floats,; the dataframe can use the event vector itself (`Event` column) as well as the `float` columns `Event.pt` and `Event.eta`. ### RClusterPool; The RClusterPool is an internal class owned be a page source.; The cluster pool maintains an I/O thread that asynchronously prefetches the next few clusters.; Through `RPageSource::SetEntryRange()`, the cluster pool is instructed to not read beyond the given limit.; This is used in the RNTuple data source when multiple threads work on different clusters of the same file. ### RMiniFile; The RMiniFile is an internal class used to read and write RNTuple data in a ROOT file.; It provides a minimal subset of the `TFile` functionality.; Its purpose is to reduce the coupling between RNTuple and the ROOT I/O library. For writing data, the RMiniFile can either use a proper `TFile` (descendant) or a C file stream (only for new ROOT files with a single RNTuple).; For reading, the `RMiniFile` always uses an `RRawFile`. ### RRawFile; The RRawFile internal abstract class provides an interface to read byte ranges from a file, including vector reads.; Concrete implementations exist for local files, XRootD and HTTP (the latter two through the ROOT plugin mechanism).; The local file implementation on Linux uses uring for vector reads, if available.; `RRawFileTFile` wraps an existing `TFile` and provides access to the full set of implementations, e.g. `TMemFile`. Tooling; -------. ### RNTupleMerger; The `RNTupleMerger` is an internal class and part of the core RNTuple library.; It concatenates RNTuple data from several sources into a combined sink.; It implements ""fast merging"", i.e. copy-based merging that does not decompress and recompress pages.; The RNTupler merger",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:749,Integrability,depend,depends,749,"RNTuple Code Architecture; =========================. > This document is meant for ROOT developers. It provides background information on the RNTuple code design and behavior. > The RNTuple code uses the nomenclature from the [RNTuple format specification](https://github.com/root-project/root/blob/master/tree/ntuple/v7/doc/BinaryFormatSpecification.md) (e.g. ""field"", ""column"", ""anchor"", etc.). General Principles; ------------------. The RNTuple classes provide the functionality to read, write, and describe RNTuple datasets.; The core classes, such as `RNTupleReader` and `RNTupleWriter`, are part of the RNTuple library.; Additional tools, such as the `RNTupleImporter` and the `RNTupleInspector`, are part of the RNTupleUtils library,; which depends on the RNTuple library. The RNTuple classes are organized in layers:; the storage layer, the primitives layer, the logical layer and the event iteration layer.; Most classes in the storage layer and the primitives layer are in the `ROOT::Internal` namespace (non-public interfaces),; with the notable exception of the descriptor classes (`RNTupleDescriptor`, `RFieldDescriptor`, etc.).; Most classes in the upper layers provide public interfaces. | Layer | Description | Example of classes |; |------------|---------------------------------------------------------------------|-------------------------------------------------------------|; | Storage | Read and write pages (physical: file, object store; virtual: e.g. buffered) | RPage{Source,Sink}, RNTupleDescriptor, RClusterPool |; | Primitives | Storage-backed columns of simple types | RColumn, RColumnElement, RPage |; | Logical | Mapping of C++ types onto columns | RField, RNTupleModel, REntry |; | Iteration | Reading and writing events / properties | RNTuple{Reader,Writer}, RNTupleView, RNTupleDS (RDataFrame) |; | Tooling | Higher-level, RNTuple related utility classes | RNTupleMerger, RNTupleImporter, RNTupleInspector |. The RNTuple classes are, unless explicitly stated otherwi",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:1027,Integrability,interface,interfaces,1027,"========================. > This document is meant for ROOT developers. It provides background information on the RNTuple code design and behavior. > The RNTuple code uses the nomenclature from the [RNTuple format specification](https://github.com/root-project/root/blob/master/tree/ntuple/v7/doc/BinaryFormatSpecification.md) (e.g. ""field"", ""column"", ""anchor"", etc.). General Principles; ------------------. The RNTuple classes provide the functionality to read, write, and describe RNTuple datasets.; The core classes, such as `RNTupleReader` and `RNTupleWriter`, are part of the RNTuple library.; Additional tools, such as the `RNTupleImporter` and the `RNTupleInspector`, are part of the RNTupleUtils library,; which depends on the RNTuple library. The RNTuple classes are organized in layers:; the storage layer, the primitives layer, the logical layer and the event iteration layer.; Most classes in the storage layer and the primitives layer are in the `ROOT::Internal` namespace (non-public interfaces),; with the notable exception of the descriptor classes (`RNTupleDescriptor`, `RFieldDescriptor`, etc.).; Most classes in the upper layers provide public interfaces. | Layer | Description | Example of classes |; |------------|---------------------------------------------------------------------|-------------------------------------------------------------|; | Storage | Read and write pages (physical: file, object store; virtual: e.g. buffered) | RPage{Source,Sink}, RNTupleDescriptor, RClusterPool |; | Primitives | Storage-backed columns of simple types | RColumn, RColumnElement, RPage |; | Logical | Mapping of C++ types onto columns | RField, RNTupleModel, REntry |; | Iteration | Reading and writing events / properties | RNTuple{Reader,Writer}, RNTupleView, RNTupleDS (RDataFrame) |; | Tooling | Higher-level, RNTuple related utility classes | RNTupleMerger, RNTupleImporter, RNTupleInspector |. The RNTuple classes are, unless explicitly stated otherwise, conditionally thread sa",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:1192,Integrability,interface,interfaces,1192,"or. > The RNTuple code uses the nomenclature from the [RNTuple format specification](https://github.com/root-project/root/blob/master/tree/ntuple/v7/doc/BinaryFormatSpecification.md) (e.g. ""field"", ""column"", ""anchor"", etc.). General Principles; ------------------. The RNTuple classes provide the functionality to read, write, and describe RNTuple datasets.; The core classes, such as `RNTupleReader` and `RNTupleWriter`, are part of the RNTuple library.; Additional tools, such as the `RNTupleImporter` and the `RNTupleInspector`, are part of the RNTupleUtils library,; which depends on the RNTuple library. The RNTuple classes are organized in layers:; the storage layer, the primitives layer, the logical layer and the event iteration layer.; Most classes in the storage layer and the primitives layer are in the `ROOT::Internal` namespace (non-public interfaces),; with the notable exception of the descriptor classes (`RNTupleDescriptor`, `RFieldDescriptor`, etc.).; Most classes in the upper layers provide public interfaces. | Layer | Description | Example of classes |; |------------|---------------------------------------------------------------------|-------------------------------------------------------------|; | Storage | Read and write pages (physical: file, object store; virtual: e.g. buffered) | RPage{Source,Sink}, RNTupleDescriptor, RClusterPool |; | Primitives | Storage-backed columns of simple types | RColumn, RColumnElement, RPage |; | Logical | Mapping of C++ types onto columns | RField, RNTupleModel, REntry |; | Iteration | Reading and writing events / properties | RNTuple{Reader,Writer}, RNTupleView, RNTupleDS (RDataFrame) |; | Tooling | Higher-level, RNTuple related utility classes | RNTupleMerger, RNTupleImporter, RNTupleInspector |. The RNTuple classes are, unless explicitly stated otherwise, conditionally thread safe. The read and write APIs provide templated, compile-time type-safe APIs,; APIs where the type at hand is passed as string and which are runtim",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:5679,Integrability,interface,interface,5679,"D"");; // The writer creates a page sink and connects the model's fields to it; auto writer = RNTupleWriter::Append(std::move(model), ""ntpl"", *file);; *ptrPt = 1.0;; // Append the model's default entry; writer->Fill();; // Commit the dataset by destructing the writer; writer.reset();; ```. The points on object type-safety and ownership apply in the same way as for reading data. Creation of the RNTuple model can use runtime type information:. ```c++; auto model = RNTupleModel::Create();; model->AddField(RFieldBase::Create(""pt"", ""float"").Unwrap());; ```. Main Classes; ------------. ### RNTuple; The RNTuple class contains the information of the RNTuple anchor in a ROOT file (see specification).; It has a dictionary and is streamed through the standard ROOT I/O.; An RNTuple object represents an RNTuple dataset but it is not the dataset itself.; It can be used like a token to open the actual RNTuple dataset with, e.g., RDF or an RNTupleReader,; and it provides the `Merge(...)` interface for the `TFileMerger`. ### RPageSource / Sink; The page source and sink can read and write pages and clusters from and to a storage backend.; There are concrete class implementations for an RNTuple stored in a ROOT file (local or remote), and for an RNTuple stored in a DAOS object store.; There is a virtual page sink for buffered writes, which also groups pages of the same column before flushing them to disk.; There is a virtual page source for aligned friend datasets (horizontal data combination). Page sources and sinks do not operate entry-based but based on pages/indices of columns.; For instance, there is no API in the page sink to write an entry, but only to write pages of columns.; The higher-level APIs, e.g. `RField`, `REntry`, `RNTupleWriter`, take care of presenting the available data as entries where necessary. The page source also gives access to an `RNTupleDescriptor` through a read/write lock guard.; The `RNTupleDescriptor` owned by the page source changes only when new cluster",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:8524,Integrability,wrap,wrapped,8524,"es. The descriptor classes contain a copy of the meta-data; they are not linked to an open page source.; A descriptor can be used after its originating page source has been deleted. ### RField<T>; The RField<T> classes are central in RNTuple:; they link the in-memory representation of data types to their on-disk representation.; All field classes inherit from `RFieldBase`. Every type with RNTuple I/O supported has a corresponding RField<T> template specialization.; Complex types are composed of fields and sub fields.; E.g., a `struct` is represented by a parent field for the `struct` itself and a subfield for every member of the `struct`.; Fields of complex types have type-erased versions in addition to the templated ones (e.g., `RVectorField`, `RClassField`).; In this way, fields can be constructed even if the type information is only available at runtime.; To this end, `RFieldBase::Create()` creates an `RField` object from a type string. On the ""in-memory"" side, fields can construct and destroy objects of their wrapped type; (cf. `CreateValue()`, `CreateObject()`, `GetDeleter()` methods).; Existing objects in memory can be bound to fields (cf. `BindValue()` method). On the ""on-disk"" side, fields know about the possible column representations of their wrapped type.; Upon connecting a field to a page source or page sink,; fields create `RColumn` objects and register them with the page source/sink.; When reading and writing data, the field maps the in-memory information of an object to read/write calls on its columns.; For instance, when writing a `std::vector<float>`,; the field writes to an index column (storing information about the size of the vector).; Its subfield writes the actual values to a float column. During its lifetime, a field undergoes the following possible state transitions:; ```; [*] --> Unconnected --> ConnectedToSink ----; | | |; | --> ConnectedToSource ---> [*]; | |; -------------------------------; ```. The RField class hierarchy is fixed and n",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:8768,Integrability,wrap,wrapped,8768,"Tuple:; they link the in-memory representation of data types to their on-disk representation.; All field classes inherit from `RFieldBase`. Every type with RNTuple I/O supported has a corresponding RField<T> template specialization.; Complex types are composed of fields and sub fields.; E.g., a `struct` is represented by a parent field for the `struct` itself and a subfield for every member of the `struct`.; Fields of complex types have type-erased versions in addition to the templated ones (e.g., `RVectorField`, `RClassField`).; In this way, fields can be constructed even if the type information is only available at runtime.; To this end, `RFieldBase::Create()` creates an `RField` object from a type string. On the ""in-memory"" side, fields can construct and destroy objects of their wrapped type; (cf. `CreateValue()`, `CreateObject()`, `GetDeleter()` methods).; Existing objects in memory can be bound to fields (cf. `BindValue()` method). On the ""on-disk"" side, fields know about the possible column representations of their wrapped type.; Upon connecting a field to a page source or page sink,; fields create `RColumn` objects and register them with the page source/sink.; When reading and writing data, the field maps the in-memory information of an object to read/write calls on its columns.; For instance, when writing a `std::vector<float>`,; the field writes to an index column (storing information about the size of the vector).; Its subfield writes the actual values to a float column. During its lifetime, a field undergoes the following possible state transitions:; ```; [*] --> Unconnected --> ConnectedToSink ----; | | |; | --> ConnectedToSource ---> [*]; | |; -------------------------------; ```. The RField class hierarchy is fixed and not meant to be extended by user classes. ### RField::RValue; The `RValue` class makes the connection between an object in memory and the corresponding field used for I/O.; It contains a shared pointer of the object, i.e. RNTuple and the",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:12151,Integrability,interface,interface,12151,"the writing process has started (cf. `RNTupleWriter::CreateModelUpdater()`).; This is called _late model extension_.; Addition of fields invalidates previously created entries.; The values of deferred fields for the already written entries is set to the default constructed type of the field. ### REntry; The REntry represents a row/entry in an RNTuple.; It contains a list of `RValue` objects that correspond to the top-level fields of the originating model.; The entry gives access to the shared pointers corresponding to the top-level fields.; It also provides functionality to bind application-provided pointers. An REntry can be passed to `RNTupleWriter::Fill()` and `RNTupleReader::LoadEntry()`.; Otherwise, the reader/writer uses the default entry of its model. An entry can safely outlive its originating model.; New objects cannot anymore be created (`EmplaceNewValue` will throw an exception), but the entry is still properly destructed. ### RNTupleWriter, RNTupleParallelWriter; The RNTupleWriter is the primary interface to create an RNTuple.; The writer takes ownership of a given model.; The writer can either add an RNTuple to an existing ROOT file (`RNTupleWriter::Append()`) or create a new ROOT file with an RNTuple (`RNTupleWriter::Recreate()`).; Once created, entries are added to an RNTuple either serially (`RNTupleWriter::Fill()`) or in concurrently in multiple threads with the `RNTupleParallelWriter`.; Once committed (e.g. by releasing the RNTupleWriter), the RNTuple is immutable and cannot be amended.; An RNTuple that is currently being written cannot be read. ### RNTupleReader; The RNTupleReader is the primary interface to read and inspect an RNTuple.; An RNTupleReader owns a model: either a model created from the on-disk information or an imposed, user-provided model.; The user-provided model can be limited to a subset of fields.; Data is populated to an explicit `REntry` or the model's default entry through `RNTupleReader::LoadEntry()`. The reader can create `R",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:12770,Integrability,interface,interface,12770,"ssed to `RNTupleWriter::Fill()` and `RNTupleReader::LoadEntry()`.; Otherwise, the reader/writer uses the default entry of its model. An entry can safely outlive its originating model.; New objects cannot anymore be created (`EmplaceNewValue` will throw an exception), but the entry is still properly destructed. ### RNTupleWriter, RNTupleParallelWriter; The RNTupleWriter is the primary interface to create an RNTuple.; The writer takes ownership of a given model.; The writer can either add an RNTuple to an existing ROOT file (`RNTupleWriter::Append()`) or create a new ROOT file with an RNTuple (`RNTupleWriter::Recreate()`).; Once created, entries are added to an RNTuple either serially (`RNTupleWriter::Fill()`) or in concurrently in multiple threads with the `RNTupleParallelWriter`.; Once committed (e.g. by releasing the RNTupleWriter), the RNTuple is immutable and cannot be amended.; An RNTuple that is currently being written cannot be read. ### RNTupleReader; The RNTupleReader is the primary interface to read and inspect an RNTuple.; An RNTupleReader owns a model: either a model created from the on-disk information or an imposed, user-provided model.; The user-provided model can be limited to a subset of fields.; Data is populated to an explicit `REntry` or the model's default entry through `RNTupleReader::LoadEntry()`. The reader can create `RNTupleView` objects for the independent reading of individual fields.; The reader can create `RBulk` objects for bulk reading of individual fields. Additionally, the reader provides access to a cached copy of the descriptor.; It can display individual entries (`RNTupleReader::Show()`) and summary information (`RNTupleReader::PrintInfo()`). ### RNTupleView<T>; RNTuple views provide read access to individual fields.; Views are created from an RNTupleReader.; Views are templated; for simple types (e.g., `float`, `int`), views provide read-only access directly to an RNTuple page in memory.; Complex types and void views require addi",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:15977,Integrability,interface,interface,15977,"he event vector itself (`Event` column) as well as the `float` columns `Event.pt` and `Event.eta`. ### RClusterPool; The RClusterPool is an internal class owned be a page source.; The cluster pool maintains an I/O thread that asynchronously prefetches the next few clusters.; Through `RPageSource::SetEntryRange()`, the cluster pool is instructed to not read beyond the given limit.; This is used in the RNTuple data source when multiple threads work on different clusters of the same file. ### RMiniFile; The RMiniFile is an internal class used to read and write RNTuple data in a ROOT file.; It provides a minimal subset of the `TFile` functionality.; Its purpose is to reduce the coupling between RNTuple and the ROOT I/O library. For writing data, the RMiniFile can either use a proper `TFile` (descendant) or a C file stream (only for new ROOT files with a single RNTuple).; For reading, the `RMiniFile` always uses an `RRawFile`. ### RRawFile; The RRawFile internal abstract class provides an interface to read byte ranges from a file, including vector reads.; Concrete implementations exist for local files, XRootD and HTTP (the latter two through the ROOT plugin mechanism).; The local file implementation on Linux uses uring for vector reads, if available.; `RRawFileTFile` wraps an existing `TFile` and provides access to the full set of implementations, e.g. `TMemFile`. Tooling; -------. ### RNTupleMerger; The `RNTupleMerger` is an internal class and part of the core RNTuple library.; It concatenates RNTuple data from several sources into a combined sink.; It implements ""fast merging"", i.e. copy-based merging that does not decompress and recompress pages.; The RNTupler merger is used by the `TFileMerger` and thus provides RNTuple merge support in `hadd` and `TBufferMerger`. ### RNTupleImporter; The RNTupleImporter creates RNTuple data sets from ROOT trees.; It is part of the `ROOTNTupleUtil` library. ### RNTupleInspector; The RNTupleInspector provides insights of an RNTuple, e",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:16261,Integrability,wrap,wraps,16261,"the cluster pool is instructed to not read beyond the given limit.; This is used in the RNTuple data source when multiple threads work on different clusters of the same file. ### RMiniFile; The RMiniFile is an internal class used to read and write RNTuple data in a ROOT file.; It provides a minimal subset of the `TFile` functionality.; Its purpose is to reduce the coupling between RNTuple and the ROOT I/O library. For writing data, the RMiniFile can either use a proper `TFile` (descendant) or a C file stream (only for new ROOT files with a single RNTuple).; For reading, the `RMiniFile` always uses an `RRawFile`. ### RRawFile; The RRawFile internal abstract class provides an interface to read byte ranges from a file, including vector reads.; Concrete implementations exist for local files, XRootD and HTTP (the latter two through the ROOT plugin mechanism).; The local file implementation on Linux uses uring for vector reads, if available.; `RRawFileTFile` wraps an existing `TFile` and provides access to the full set of implementations, e.g. `TMemFile`. Tooling; -------. ### RNTupleMerger; The `RNTupleMerger` is an internal class and part of the core RNTuple library.; It concatenates RNTuple data from several sources into a combined sink.; It implements ""fast merging"", i.e. copy-based merging that does not decompress and recompress pages.; The RNTupler merger is used by the `TFileMerger` and thus provides RNTuple merge support in `hadd` and `TBufferMerger`. ### RNTupleImporter; The RNTupleImporter creates RNTuple data sets from ROOT trees.; It is part of the `ROOTNTupleUtil` library. ### RNTupleInspector; The RNTupleInspector provides insights of an RNTuple, e.g. the distribution of data volume wrt. column types.; It is part of the `ROOTNTupleUtil` library. Ownership Model; ---------------. By default, objects involved in RNTuple I/O (objects read from disk or written to disk) are passed to RNTuple as shared pointers.; Both RNTuple or the application may create the obje",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:19065,Integrability,wrap,wrapped,19065,"ly if buffered writing is turned off.; The parallel writer assumes exclusive access to the underlying file during all operations on the writer (e.g. construction and destruction) and all operations on any created fill context (e.g. `Fill()` and `FlushCluster()`).; Notable exceptions are `FlushColumns()` and `FillNoFlush()` which are guaranteed to never access the underlying `TFile` during parallel writing (which is always buffered). A `TFile` does not take ownership of any `RNTuple` objects. When reading data, RNTuple uses the `RMiniFile` and `RRawFile` classes to open a given storage path and find the `RNTuple` anchor.; When creating a `RNTupleReader` from an existing anchor object, RNTuple uses `RRawFile` only for files of dynamic type `TFile`, `TDavixFile`, and `TNetXNGFile`.; In either case, the `RRawFile` owns its own file descriptor and does not interfere with `TFile` objects concurrently reading the file.; For anchors from files of other dynamic type, including all other `TFile` subclasses, the file is wrapped in a `RRawFileTFile` and access is shared. On-Disk Encoding; ----------------. ### Writing Case; The following steps are taken to write RNTuple data to disk:. 1. On creation of the RNTupleWriter, the header is written to disk; 2. Upon `RNTupleWriter::Fill()`, the RField<T> class _serializes_ the object into its column representation.; To this end, it uses the `RColumn` class to append elements to the columns page buffer (`RPage`); 3. When a page buffer is full (cf. tuning.md), it is sent to the page sink for writing it to disk.; Note that page boundaries do _not_ need to align with entry boundaries,; e.g. information from a single entry can span multiple pages.; 1. The page is _packed_:; depending on the type of the page, a light encoding is applied to facilitate compression, e.g., byte splitting (`RColumnElement`).; Big-endian / little-endian conversion takes place here.; 2. The packed page is _compressed_ according to the user-provided compression set",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:19770,Integrability,depend,depending,19770,"File`, and `TNetXNGFile`.; In either case, the `RRawFile` owns its own file descriptor and does not interfere with `TFile` objects concurrently reading the file.; For anchors from files of other dynamic type, including all other `TFile` subclasses, the file is wrapped in a `RRawFileTFile` and access is shared. On-Disk Encoding; ----------------. ### Writing Case; The following steps are taken to write RNTuple data to disk:. 1. On creation of the RNTupleWriter, the header is written to disk; 2. Upon `RNTupleWriter::Fill()`, the RField<T> class _serializes_ the object into its column representation.; To this end, it uses the `RColumn` class to append elements to the columns page buffer (`RPage`); 3. When a page buffer is full (cf. tuning.md), it is sent to the page sink for writing it to disk.; Note that page boundaries do _not_ need to align with entry boundaries,; e.g. information from a single entry can span multiple pages.; 1. The page is _packed_:; depending on the type of the page, a light encoding is applied to facilitate compression, e.g., byte splitting (`RColumnElement`).; Big-endian / little-endian conversion takes place here.; 2. The packed page is _compressed_ according to the user-provided compression settings (default: zstd).; A packed and compressed page is _sealed_.; 3. The sealed page is written to the storage backend.; 4. When the target cluster size is reached (cf. tuning.md), the `Fill()` method automatically commits the cluster.; The user can also manually commit a cluster.; 5. When the dataset is committed (e.g., on destruction of the RNTupleWriter), the page list, the footer, and the anchor are written to disk. The header, footer, and page list are compressed. If the buffered sink is used (default), the pages of a cluster are buffered until the cluster is committed.; On committing the cluster, all pages are sealed and sent to a _persistent sink_ in one go (vector write).; Pages are also reordered to ensure locality of pages of the same column. ",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:23049,Integrability,interface,interface,23049,"e source uses an `RClusterPool` to asynchronously read-ahead data.; When a page of a certain cluster is required, the cluster pool reads pages of _active_ columns.; For instance, if only certain fields are used (e.g., through an imposed model), only the pages of columns connected to those fields are read.; Columns can be dynamically added (e.g. during event iteration, a new field view is created in a reader).; The cluster pool reads ahead a limited number of clusters given by the _cluster bunch size_ option (default = 1).; The read-ahead uses vector reads.; For the file backend, it additionally coalesces close read requests and uses uring reads when available. The page source can be restricted to a certain entry range.; This allows for optimizing the page lists that are being read.; Additionally, it allows for optimizing the cluster pool to not read-ahead beyond the limits. #### Late model extension; Reading an RNTuple with an extended model is transparent -- i.e., no additional interface calls are required.; Internally, columns that were created as part of late model extension will have synthesized zero-initialized column ranges for the clusters that were already written before the model was extended.; In addition, pages made up of 0x00 bytes are synthesized for deferred columns in the clusters that were already (partially) filled before the model was extended. Storage Backends; ----------------. Support for storage backends is implemented through derived classes of `RPageSink` and `RPageSource`.; The `RPage{Sink,Source}File` class provides a storage backend for RNTuple data in ROOT files, local or remote.; The `RPage{Sink,Source}Daos` class provides a storage backend for RNTuple data in the DAOS object store. Every new storage backend needs to define; 1) The RNTuple embedding: how are RNTuple data blobs stored, e.g. in keys of ROOT files, or in objects of object stores; 2) The RNTuple anchor: the initial link to the location of the header and footer (cf. format spe",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:25510,Integrability,interface,interface,25510,"essing. ### Implicit Multi-Threading; When `ROOT::EnableImplicitMT()` is used, RNTuple uses ROOT's task arena to compress and decompress pages.; That requires writes to be buffered and reads uses the cluster pool resp.; The RNTuple data source for RDataFrame lets RDataFrame full control of the thread pool.; That means that RDataFrame uses a separate data source for every thread, each of the data sources runs in sequential mode. ### Concurrent Readers; Multiple readers can read the same RNTuple concurrently as long as access to every individual reader is sequential. ### Parallel REntry Preparation; Multiple `REntry` object can be concurrently prepared by multiple threads.; I.e., construction and binding of the objects can happen in parallel.; The actual reading and writing of entries (`RNTupleReader::LoadEntry()`, `RNTupleWriter::Fill()`) needs to be protected by a mutex.; This is considered ""mild scalability parallelization"" in RNTuple. ### RNTupleParallelWriter; The parallel writer offers the most scalable parallel writing interface.; Multiple _fill contexts_ can concurrently serialize and compress data.; Every fill context prepares a set of entire clusters in the final on-disk layout.; When a fill context flushes data,; a brief serialization point handles the RNTuple meta-data updates and the reservation of disk space to write into. Low precision float types; --------------------------; RNTuple supports encoding floating point types with a lower precision when writing them to disk. This encoding is specified by the; user per field and it is independent on the in-memory type used for that field (meaning both a `RField<double>` or `RField<float>` can; be mapped to e.g. a low-precision 16 bit float). RNTuple supports the following encodings (all mutually exclusive):. - **Real16**/**SplitReal16**: IEEE-754 half precision float. Set by calling `RField::SetHalfPrecision()`;; - **Real32Trunc**: floating point with less than 32 bits of precision (truncated mantissa).; Set",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:28802,Integrability,depend,depends,28802,"_unique<RField<float>>(""f"");; // assuming we have an array of floats stored in `myFloats`:; auto [minV, maxV] = std::minmax_element(myFloats.begin(), myFloats.end());; constexpr auto nBits = 24;; field->SetQuantized(*minV, *maxV, nBits);; model->AddField(std::move(field));; auto f = model->GetDefaultEntry().GetPtr<float>(""f"");. // Now we can write our floats.; auto writer = RNTupleWriter::Recreate(std::move(model), ""myNtuple"", ""myFile.root"");; for (float val : myFloats) {; *f = val;; writer->Fill();; }; ```. Relationship to other ROOT components; -------------------------------------. The RNTuple classes have the following relationship to other parts of ROOT. The RNTuple classes use core ROOT infrastructure classes, such as error handling and logging.; When necessary, RNTuple uses a `TFile` for reading and writing.; The cases of writing to a local file and reading from a local file, a file from XRootD or from HTTP, do _not_ require `TFile`.; For these cases, RNTuple depends on the `RRawFile` class and its XRootD and Davix plugins. For user-defined classes as well as sets and maps, RNTuple uses `TClass`.; Simple types and other stdlib classes are natively supported and do not require dictionaries.; See the format specification for an exhaustive list of types supported in RNTuple.; The streamer field uses the standard ROOT streaming machinery. Integration to RDataFrame is provided through an RNTuple data source.; A universal RDataFrame constructor can create a data frame from either a TTree or an RNTuple with the same syntax. The RBrowser uses RNTuple classes to display RNTuple dataset information. Future Features; ---------------. The following features are planned for after the first RNTuple production version:; - RNTupleProcessor: advanced RNTupleReader that allows for free combination of chains and (indexed/unaligned) friends; - Horizontal merging: persistified friends, analogous to a classical merge being a persistified chain; - An interface for bulk writing; - M",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:29790,Integrability,interface,interface,29790,"TP, do _not_ require `TFile`.; For these cases, RNTuple depends on the `RRawFile` class and its XRootD and Davix plugins. For user-defined classes as well as sets and maps, RNTuple uses `TClass`.; Simple types and other stdlib classes are natively supported and do not require dictionaries.; See the format specification for an exhaustive list of types supported in RNTuple.; The streamer field uses the standard ROOT streaming machinery. Integration to RDataFrame is provided through an RNTuple data source.; A universal RDataFrame constructor can create a data frame from either a TTree or an RNTuple with the same syntax. The RBrowser uses RNTuple classes to display RNTuple dataset information. Future Features; ---------------. The following features are planned for after the first RNTuple production version:; - RNTupleProcessor: advanced RNTupleReader that allows for free combination of chains and (indexed/unaligned) friends; - Horizontal merging: persistified friends, analogous to a classical merge being a persistified chain; - An interface for bulk writing; - Meta-data: RNTuple-specific and user-provided meta-data storage, such as file provenance, scale factors, or varied columns; - C library interface; - S3 storage backend (page source / page sink). Semantics of Reading Non-Trivial Objects; ========================================. Reading an object with RNTuple should be seen as _overwriting_ its persistent data members.; Given a properly constructed and valid object, the object must ensure that it stays valid when overwriting its persistent data members.; However, the object should not rely on its transient state to remain unchanged during reading:; it may be destructed and constructed again when it is read as part of a collection (see below). An object that is being read from disk may have been constructed by `RField::CreateValue()`.; In this case, the deleter returned by `RField::GetDeleter()` releases the resources. When reading collections of type `T` (`std::ve",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:29956,Integrability,interface,interface,29956,"TP, do _not_ require `TFile`.; For these cases, RNTuple depends on the `RRawFile` class and its XRootD and Davix plugins. For user-defined classes as well as sets and maps, RNTuple uses `TClass`.; Simple types and other stdlib classes are natively supported and do not require dictionaries.; See the format specification for an exhaustive list of types supported in RNTuple.; The streamer field uses the standard ROOT streaming machinery. Integration to RDataFrame is provided through an RNTuple data source.; A universal RDataFrame constructor can create a data frame from either a TTree or an RNTuple with the same syntax. The RBrowser uses RNTuple classes to display RNTuple dataset information. Future Features; ---------------. The following features are planned for after the first RNTuple production version:; - RNTupleProcessor: advanced RNTupleReader that allows for free combination of chains and (indexed/unaligned) friends; - Horizontal merging: persistified friends, analogous to a classical merge being a persistified chain; - An interface for bulk writing; - Meta-data: RNTuple-specific and user-provided meta-data storage, such as file provenance, scale factors, or varied columns; - C library interface; - S3 storage backend (page source / page sink). Semantics of Reading Non-Trivial Objects; ========================================. Reading an object with RNTuple should be seen as _overwriting_ its persistent data members.; Given a properly constructed and valid object, the object must ensure that it stays valid when overwriting its persistent data members.; However, the object should not rely on its transient state to remain unchanged during reading:; it may be destructed and constructed again when it is read as part of a collection (see below). An object that is being read from disk may have been constructed by `RField::CreateValue()`.; In this case, the deleter returned by `RField::GetDeleter()` releases the resources. When reading collections of type `T` (`std::ve",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:31203,Integrability,depend,depending,31203,"=======================================. Reading an object with RNTuple should be seen as _overwriting_ its persistent data members.; Given a properly constructed and valid object, the object must ensure that it stays valid when overwriting its persistent data members.; However, the object should not rely on its transient state to remain unchanged during reading:; it may be destructed and constructed again when it is read as part of a collection (see below). An object that is being read from disk may have been constructed by `RField::CreateValue()`.; In this case, the deleter returned by `RField::GetDeleter()` releases the resources. When reading collections of type `T` (`std::vector<T>`, `ROOT::RVec<T>`, ...), RNTuple uses `RField::CreateValue()` to construct elements of the inner type `T`.; As the size of a collection changes from event to event, this has the following effect on its elements; - If the collection shrinks, cut-off elements are destructed; - If the collection grows, new elements are constructed before reading them; - If the array buffer of the collection is reallocated (may happen for both shrinking and growing depending on the collection), all elements are destructed first in the old buffer; and the new number of elements is constructed in the new buffer. So unless the collection buffer needs to be reallocated, RNTuple tries to avoid unnecessary destruction/construction but instead overwrites existing objects.; Note that RNTuple currently does not copy or move existing objects when the collection buffer is reallocated. Naming Conventions; ==================. For byte arrays and collections of things, the RNTuple code uses the following variable name suffixes:; - `XyzSize` denotes the size of Xyz in bytes on disk, i.e. after compression. Example: `fPageListSize`.; - `XyzLength` denotes the size of Xyz in bytes in memory, i.e. uncompressed. Example: `fPageListLength`.; - `NXyz` denotes the number of Xyz items in a collection. Example: `fNPageLists`.; ",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:818,Modifiability,layers,layers,818,"RNTuple Code Architecture; =========================. > This document is meant for ROOT developers. It provides background information on the RNTuple code design and behavior. > The RNTuple code uses the nomenclature from the [RNTuple format specification](https://github.com/root-project/root/blob/master/tree/ntuple/v7/doc/BinaryFormatSpecification.md) (e.g. ""field"", ""column"", ""anchor"", etc.). General Principles; ------------------. The RNTuple classes provide the functionality to read, write, and describe RNTuple datasets.; The core classes, such as `RNTupleReader` and `RNTupleWriter`, are part of the RNTuple library.; Additional tools, such as the `RNTupleImporter` and the `RNTupleInspector`, are part of the RNTupleUtils library,; which depends on the RNTuple library. The RNTuple classes are organized in layers:; the storage layer, the primitives layer, the logical layer and the event iteration layer.; Most classes in the storage layer and the primitives layer are in the `ROOT::Internal` namespace (non-public interfaces),; with the notable exception of the descriptor classes (`RNTupleDescriptor`, `RFieldDescriptor`, etc.).; Most classes in the upper layers provide public interfaces. | Layer | Description | Example of classes |; |------------|---------------------------------------------------------------------|-------------------------------------------------------------|; | Storage | Read and write pages (physical: file, object store; virtual: e.g. buffered) | RPage{Source,Sink}, RNTupleDescriptor, RClusterPool |; | Primitives | Storage-backed columns of simple types | RColumn, RColumnElement, RPage |; | Logical | Mapping of C++ types onto columns | RField, RNTupleModel, REntry |; | Iteration | Reading and writing events / properties | RNTuple{Reader,Writer}, RNTupleView, RNTupleDS (RDataFrame) |; | Tooling | Higher-level, RNTuple related utility classes | RNTupleMerger, RNTupleImporter, RNTupleInspector |. The RNTuple classes are, unless explicitly stated otherwi",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:1170,Modifiability,layers,layers,1170,"or. > The RNTuple code uses the nomenclature from the [RNTuple format specification](https://github.com/root-project/root/blob/master/tree/ntuple/v7/doc/BinaryFormatSpecification.md) (e.g. ""field"", ""column"", ""anchor"", etc.). General Principles; ------------------. The RNTuple classes provide the functionality to read, write, and describe RNTuple datasets.; The core classes, such as `RNTupleReader` and `RNTupleWriter`, are part of the RNTuple library.; Additional tools, such as the `RNTupleImporter` and the `RNTupleInspector`, are part of the RNTupleUtils library,; which depends on the RNTuple library. The RNTuple classes are organized in layers:; the storage layer, the primitives layer, the logical layer and the event iteration layer.; Most classes in the storage layer and the primitives layer are in the `ROOT::Internal` namespace (non-public interfaces),; with the notable exception of the descriptor classes (`RNTupleDescriptor`, `RFieldDescriptor`, etc.).; Most classes in the upper layers provide public interfaces. | Layer | Description | Example of classes |; |------------|---------------------------------------------------------------------|-------------------------------------------------------------|; | Storage | Read and write pages (physical: file, object store; virtual: e.g. buffered) | RPage{Source,Sink}, RNTupleDescriptor, RClusterPool |; | Primitives | Storage-backed columns of simple types | RColumn, RColumnElement, RPage |; | Logical | Mapping of C++ types onto columns | RField, RNTupleModel, REntry |; | Iteration | Reading and writing events / properties | RNTuple{Reader,Writer}, RNTupleView, RNTupleDS (RDataFrame) |; | Tooling | Higher-level, RNTuple related utility classes | RNTupleMerger, RNTupleImporter, RNTupleInspector |. The RNTuple classes are, unless explicitly stated otherwise, conditionally thread safe. The read and write APIs provide templated, compile-time type-safe APIs,; APIs where the type at hand is passed as string and which are runtim",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:7844,Modifiability,inherit,inherit,7844,"ield,Column,Cluster,...}Descriptor; The descriptor classes provide read-only access to the on-disk meta-data of an RNTuple.; The meta-data include the schema (fields and columns), information about clusters and the page locations.; The descriptor classes are closely related to the format specification. For normal read and write tasks, access to the descriptor is not necessary.; One notable exception is bulk reading, where the descriptor can be used to determine entry boundaries of clusters.; The descriptors are used internally, e.g. to build an RNTupleModel from the on-disk information.; The descriptors are also useful for inspection purposes. The descriptor classes contain a copy of the meta-data; they are not linked to an open page source.; A descriptor can be used after its originating page source has been deleted. ### RField<T>; The RField<T> classes are central in RNTuple:; they link the in-memory representation of data types to their on-disk representation.; All field classes inherit from `RFieldBase`. Every type with RNTuple I/O supported has a corresponding RField<T> template specialization.; Complex types are composed of fields and sub fields.; E.g., a `struct` is represented by a parent field for the `struct` itself and a subfield for every member of the `struct`.; Fields of complex types have type-erased versions in addition to the templated ones (e.g., `RVectorField`, `RClassField`).; In this way, fields can be constructed even if the type information is only available at runtime.; To this end, `RFieldBase::Create()` creates an `RField` object from a type string. On the ""in-memory"" side, fields can construct and destroy objects of their wrapped type; (cf. `CreateValue()`, `CreateObject()`, `GetDeleter()` methods).; Existing objects in memory can be bound to fields (cf. `BindValue()` method). On the ""on-disk"" side, fields know about the possible column representations of their wrapped type.; Upon connecting a field to a page source or page sink,; fields c",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:9510,Modifiability,extend,extended,9510," and destroy objects of their wrapped type; (cf. `CreateValue()`, `CreateObject()`, `GetDeleter()` methods).; Existing objects in memory can be bound to fields (cf. `BindValue()` method). On the ""on-disk"" side, fields know about the possible column representations of their wrapped type.; Upon connecting a field to a page source or page sink,; fields create `RColumn` objects and register them with the page source/sink.; When reading and writing data, the field maps the in-memory information of an object to read/write calls on its columns.; For instance, when writing a `std::vector<float>`,; the field writes to an index column (storing information about the size of the vector).; Its subfield writes the actual values to a float column. During its lifetime, a field undergoes the following possible state transitions:; ```; [*] --> Unconnected --> ConnectedToSink ----; | | |; | --> ConnectedToSource ---> [*]; | |; -------------------------------; ```. The RField class hierarchy is fixed and not meant to be extended by user classes. ### RField::RValue; The `RValue` class makes the connection between an object in memory and the corresponding field used for I/O.; It contains a shared pointer of the object, i.e. RNTuple and the application share ownership of objects.; The object in an RValue can either be created by an RNTuple field (cf. `RField<T>::CreateValue()` method); or provided by the application (cf. `RField<T>::BindValue()` method).; Raw pointers can be passed with the understanding that the raw pointer is owned by the application and are kept alive during I/O operations. `RValue` objects can only be created from fields, and they are linked to their originating field. ### RNTupleModel; The RNTupleModel represents a data schema as a tree of fields.; The model owns its fields.; A model undergoes the following possible state transitions:; ```; [*] ---> Building / --> Frozen --; Updating | |; ^ | |; |------------- v; ----------------->[*]; ```; During the building/updati",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:15661,Modifiability,coupling,coupling,15661," RNTuple data source also supports multi-threaded dataframes, parallelized on the file and cluster level. The data source exposes inner fields of complex collections.; For instance, if the data model contains a vector of `Event` classes, where each `Event` has `pt` and `eta` floats,; the dataframe can use the event vector itself (`Event` column) as well as the `float` columns `Event.pt` and `Event.eta`. ### RClusterPool; The RClusterPool is an internal class owned be a page source.; The cluster pool maintains an I/O thread that asynchronously prefetches the next few clusters.; Through `RPageSource::SetEntryRange()`, the cluster pool is instructed to not read beyond the given limit.; This is used in the RNTuple data source when multiple threads work on different clusters of the same file. ### RMiniFile; The RMiniFile is an internal class used to read and write RNTuple data in a ROOT file.; It provides a minimal subset of the `TFile` functionality.; Its purpose is to reduce the coupling between RNTuple and the ROOT I/O library. For writing data, the RMiniFile can either use a proper `TFile` (descendant) or a C file stream (only for new ROOT files with a single RNTuple).; For reading, the `RMiniFile` always uses an `RRawFile`. ### RRawFile; The RRawFile internal abstract class provides an interface to read byte ranges from a file, including vector reads.; Concrete implementations exist for local files, XRootD and HTTP (the latter two through the ROOT plugin mechanism).; The local file implementation on Linux uses uring for vector reads, if available.; `RRawFileTFile` wraps an existing `TFile` and provides access to the full set of implementations, e.g. `TMemFile`. Tooling; -------. ### RNTupleMerger; The `RNTupleMerger` is an internal class and part of the core RNTuple library.; It concatenates RNTuple data from several sources into a combined sink.; It implements ""fast merging"", i.e. copy-based merging that does not decompress and recompress pages.; The RNTupler merger",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:16142,Modifiability,plugin,plugin,16142,"lusterPool is an internal class owned be a page source.; The cluster pool maintains an I/O thread that asynchronously prefetches the next few clusters.; Through `RPageSource::SetEntryRange()`, the cluster pool is instructed to not read beyond the given limit.; This is used in the RNTuple data source when multiple threads work on different clusters of the same file. ### RMiniFile; The RMiniFile is an internal class used to read and write RNTuple data in a ROOT file.; It provides a minimal subset of the `TFile` functionality.; Its purpose is to reduce the coupling between RNTuple and the ROOT I/O library. For writing data, the RMiniFile can either use a proper `TFile` (descendant) or a C file stream (only for new ROOT files with a single RNTuple).; For reading, the `RMiniFile` always uses an `RRawFile`. ### RRawFile; The RRawFile internal abstract class provides an interface to read byte ranges from a file, including vector reads.; Concrete implementations exist for local files, XRootD and HTTP (the latter two through the ROOT plugin mechanism).; The local file implementation on Linux uses uring for vector reads, if available.; `RRawFileTFile` wraps an existing `TFile` and provides access to the full set of implementations, e.g. `TMemFile`. Tooling; -------. ### RNTupleMerger; The `RNTupleMerger` is an internal class and part of the core RNTuple library.; It concatenates RNTuple data from several sources into a combined sink.; It implements ""fast merging"", i.e. copy-based merging that does not decompress and recompress pages.; The RNTupler merger is used by the `TFileMerger` and thus provides RNTuple merge support in `hadd` and `TBufferMerger`. ### RNTupleImporter; The RNTupleImporter creates RNTuple data sets from ROOT trees.; It is part of the `ROOTNTupleUtil` library. ### RNTupleInspector; The RNTupleInspector provides insights of an RNTuple, e.g. the distribution of data volume wrt. column types.; It is part of the `ROOTNTupleUtil` library. Ownership Model; -------",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:22996,Modifiability,extend,extended,22996,"ader::LoadEntry()`, `RNTupleView` call operator). By default, the page source uses an `RClusterPool` to asynchronously read-ahead data.; When a page of a certain cluster is required, the cluster pool reads pages of _active_ columns.; For instance, if only certain fields are used (e.g., through an imposed model), only the pages of columns connected to those fields are read.; Columns can be dynamically added (e.g. during event iteration, a new field view is created in a reader).; The cluster pool reads ahead a limited number of clusters given by the _cluster bunch size_ option (default = 1).; The read-ahead uses vector reads.; For the file backend, it additionally coalesces close read requests and uses uring reads when available. The page source can be restricted to a certain entry range.; This allows for optimizing the page lists that are being read.; Additionally, it allows for optimizing the cluster pool to not read-ahead beyond the limits. #### Late model extension; Reading an RNTuple with an extended model is transparent -- i.e., no additional interface calls are required.; Internally, columns that were created as part of late model extension will have synthesized zero-initialized column ranges for the clusters that were already written before the model was extended.; In addition, pages made up of 0x00 bytes are synthesized for deferred columns in the clusters that were already (partially) filled before the model was extended. Storage Backends; ----------------. Support for storage backends is implemented through derived classes of `RPageSink` and `RPageSource`.; The `RPage{Sink,Source}File` class provides a storage backend for RNTuple data in ROOT files, local or remote.; The `RPage{Sink,Source}Daos` class provides a storage backend for RNTuple data in the DAOS object store. Every new storage backend needs to define; 1) The RNTuple embedding: how are RNTuple data blobs stored, e.g. in keys of ROOT files, or in objects of object stores; 2) The RNTuple anchor: the",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:23267,Modifiability,extend,extended,23267,"ter pool reads pages of _active_ columns.; For instance, if only certain fields are used (e.g., through an imposed model), only the pages of columns connected to those fields are read.; Columns can be dynamically added (e.g. during event iteration, a new field view is created in a reader).; The cluster pool reads ahead a limited number of clusters given by the _cluster bunch size_ option (default = 1).; The read-ahead uses vector reads.; For the file backend, it additionally coalesces close read requests and uses uring reads when available. The page source can be restricted to a certain entry range.; This allows for optimizing the page lists that are being read.; Additionally, it allows for optimizing the cluster pool to not read-ahead beyond the limits. #### Late model extension; Reading an RNTuple with an extended model is transparent -- i.e., no additional interface calls are required.; Internally, columns that were created as part of late model extension will have synthesized zero-initialized column ranges for the clusters that were already written before the model was extended.; In addition, pages made up of 0x00 bytes are synthesized for deferred columns in the clusters that were already (partially) filled before the model was extended. Storage Backends; ----------------. Support for storage backends is implemented through derived classes of `RPageSink` and `RPageSource`.; The `RPage{Sink,Source}File` class provides a storage backend for RNTuple data in ROOT files, local or remote.; The `RPage{Sink,Source}Daos` class provides a storage backend for RNTuple data in the DAOS object store. Every new storage backend needs to define; 1) The RNTuple embedding: how are RNTuple data blobs stored, e.g. in keys of ROOT files, or in objects of object stores; 2) The RNTuple anchor: the initial link to the location of the header and footer (cf. format specification); 3) A locator format: how are byte ranges addressed (e.g., through an offset in a file or an object ID). That",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:23430,Modifiability,extend,extended,23430,"ead.; Columns can be dynamically added (e.g. during event iteration, a new field view is created in a reader).; The cluster pool reads ahead a limited number of clusters given by the _cluster bunch size_ option (default = 1).; The read-ahead uses vector reads.; For the file backend, it additionally coalesces close read requests and uses uring reads when available. The page source can be restricted to a certain entry range.; This allows for optimizing the page lists that are being read.; Additionally, it allows for optimizing the cluster pool to not read-ahead beyond the limits. #### Late model extension; Reading an RNTuple with an extended model is transparent -- i.e., no additional interface calls are required.; Internally, columns that were created as part of late model extension will have synthesized zero-initialized column ranges for the clusters that were already written before the model was extended.; In addition, pages made up of 0x00 bytes are synthesized for deferred columns in the clusters that were already (partially) filled before the model was extended. Storage Backends; ----------------. Support for storage backends is implemented through derived classes of `RPageSink` and `RPageSource`.; The `RPage{Sink,Source}File` class provides a storage backend for RNTuple data in ROOT files, local or remote.; The `RPage{Sink,Source}Daos` class provides a storage backend for RNTuple data in the DAOS object store. Every new storage backend needs to define; 1) The RNTuple embedding: how are RNTuple data blobs stored, e.g. in keys of ROOT files, or in objects of object stores; 2) The RNTuple anchor: the initial link to the location of the header and footer (cf. format specification); 3) A locator format: how are byte ranges addressed (e.g., through an offset in a file or an object ID). That means that new backends are likely to have implications on the RNTuple format specification. The page sources and sinks are ROOT internal classes.; They are not meant to be extende",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:24351,Modifiability,extend,extended,24351,"d columns in the clusters that were already (partially) filled before the model was extended. Storage Backends; ----------------. Support for storage backends is implemented through derived classes of `RPageSink` and `RPageSource`.; The `RPage{Sink,Source}File` class provides a storage backend for RNTuple data in ROOT files, local or remote.; The `RPage{Sink,Source}Daos` class provides a storage backend for RNTuple data in the DAOS object store. Every new storage backend needs to define; 1) The RNTuple embedding: how are RNTuple data blobs stored, e.g. in keys of ROOT files, or in objects of object stores; 2) The RNTuple anchor: the initial link to the location of the header and footer (cf. format specification); 3) A locator format: how are byte ranges addressed (e.g., through an offset in a file or an object ID). That means that new backends are likely to have implications on the RNTuple format specification. The page sources and sinks are ROOT internal classes.; They are not meant to be extended by users. Multi-Threading; ---------------. The following options exist in RNTuple for multithreaded data processing. ### Implicit Multi-Threading; When `ROOT::EnableImplicitMT()` is used, RNTuple uses ROOT's task arena to compress and decompress pages.; That requires writes to be buffered and reads uses the cluster pool resp.; The RNTuple data source for RDataFrame lets RDataFrame full control of the thread pool.; That means that RDataFrame uses a separate data source for every thread, each of the data sources runs in sequential mode. ### Concurrent Readers; Multiple readers can read the same RNTuple concurrently as long as access to every individual reader is sequential. ### Parallel REntry Preparation; Multiple `REntry` object can be concurrently prepared by multiple threads.; I.e., construction and binding of the objects can happen in parallel.; The actual reading and writing of entries (`RNTupleReader::LoadEntry()`, `RNTupleWriter::Fill()`) needs to be protected by a ",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:28859,Modifiability,plugin,plugins,28859,"_unique<RField<float>>(""f"");; // assuming we have an array of floats stored in `myFloats`:; auto [minV, maxV] = std::minmax_element(myFloats.begin(), myFloats.end());; constexpr auto nBits = 24;; field->SetQuantized(*minV, *maxV, nBits);; model->AddField(std::move(field));; auto f = model->GetDefaultEntry().GetPtr<float>(""f"");. // Now we can write our floats.; auto writer = RNTupleWriter::Recreate(std::move(model), ""myNtuple"", ""myFile.root"");; for (float val : myFloats) {; *f = val;; writer->Fill();; }; ```. Relationship to other ROOT components; -------------------------------------. The RNTuple classes have the following relationship to other parts of ROOT. The RNTuple classes use core ROOT infrastructure classes, such as error handling and logging.; When necessary, RNTuple uses a `TFile` for reading and writing.; The cases of writing to a local file and reading from a local file, a file from XRootD or from HTTP, do _not_ require `TFile`.; For these cases, RNTuple depends on the `RRawFile` class and its XRootD and Davix plugins. For user-defined classes as well as sets and maps, RNTuple uses `TClass`.; Simple types and other stdlib classes are natively supported and do not require dictionaries.; See the format specification for an exhaustive list of types supported in RNTuple.; The streamer field uses the standard ROOT streaming machinery. Integration to RDataFrame is provided through an RNTuple data source.; A universal RDataFrame constructor can create a data frame from either a TTree or an RNTuple with the same syntax. The RBrowser uses RNTuple classes to display RNTuple dataset information. Future Features; ---------------. The following features are planned for after the first RNTuple production version:; - RNTupleProcessor: advanced RNTupleReader that allows for free combination of chains and (indexed/unaligned) friends; - Horizontal merging: persistified friends, analogous to a classical merge being a persistified chain; - An interface for bulk writing; - M",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:31739,Modifiability,variab,variable,31739,"=======================================. Reading an object with RNTuple should be seen as _overwriting_ its persistent data members.; Given a properly constructed and valid object, the object must ensure that it stays valid when overwriting its persistent data members.; However, the object should not rely on its transient state to remain unchanged during reading:; it may be destructed and constructed again when it is read as part of a collection (see below). An object that is being read from disk may have been constructed by `RField::CreateValue()`.; In this case, the deleter returned by `RField::GetDeleter()` releases the resources. When reading collections of type `T` (`std::vector<T>`, `ROOT::RVec<T>`, ...), RNTuple uses `RField::CreateValue()` to construct elements of the inner type `T`.; As the size of a collection changes from event to event, this has the following effect on its elements; - If the collection shrinks, cut-off elements are destructed; - If the collection grows, new elements are constructed before reading them; - If the array buffer of the collection is reallocated (may happen for both shrinking and growing depending on the collection), all elements are destructed first in the old buffer; and the new number of elements is constructed in the new buffer. So unless the collection buffer needs to be reallocated, RNTuple tries to avoid unnecessary destruction/construction but instead overwrites existing objects.; Note that RNTuple currently does not copy or move existing objects when the collection buffer is reallocated. Naming Conventions; ==================. For byte arrays and collections of things, the RNTuple code uses the following variable name suffixes:; - `XyzSize` denotes the size of Xyz in bytes on disk, i.e. after compression. Example: `fPageListSize`.; - `XyzLength` denotes the size of Xyz in bytes in memory, i.e. uncompressed. Example: `fPageListLength`.; - `NXyz` denotes the number of Xyz items in a collection. Example: `fNPageLists`.; ",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:6709,Performance,load,loaded,6709," `Merge(...)` interface for the `TFileMerger`. ### RPageSource / Sink; The page source and sink can read and write pages and clusters from and to a storage backend.; There are concrete class implementations for an RNTuple stored in a ROOT file (local or remote), and for an RNTuple stored in a DAOS object store.; There is a virtual page sink for buffered writes, which also groups pages of the same column before flushing them to disk.; There is a virtual page source for aligned friend datasets (horizontal data combination). Page sources and sinks do not operate entry-based but based on pages/indices of columns.; For instance, there is no API in the page sink to write an entry, but only to write pages of columns.; The higher-level APIs, e.g. `RField`, `REntry`, `RNTupleWriter`, take care of presenting the available data as entries where necessary. The page source also gives access to an `RNTupleDescriptor` through a read/write lock guard.; The `RNTupleDescriptor` owned by the page source changes only when new cluster meta-data are loaded.; The header and the cluster group summary information is stable throughout its lifetime (cf. format specification). ### R{NTuple,Field,Column,Cluster,...}Descriptor; The descriptor classes provide read-only access to the on-disk meta-data of an RNTuple.; The meta-data include the schema (fields and columns), information about clusters and the page locations.; The descriptor classes are closely related to the format specification. For normal read and write tasks, access to the descriptor is not necessary.; One notable exception is bulk reading, where the descriptor can be used to determine entry boundaries of clusters.; The descriptors are used internally, e.g. to build an RNTupleModel from the on-disk information.; The descriptors are also useful for inspection purposes. The descriptor classes contain a copy of the meta-data; they are not linked to an open page source.; A descriptor can be used after its originating page source has be",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:12488,Performance,concurren,concurrently,12488,"RNTuple.; It contains a list of `RValue` objects that correspond to the top-level fields of the originating model.; The entry gives access to the shared pointers corresponding to the top-level fields.; It also provides functionality to bind application-provided pointers. An REntry can be passed to `RNTupleWriter::Fill()` and `RNTupleReader::LoadEntry()`.; Otherwise, the reader/writer uses the default entry of its model. An entry can safely outlive its originating model.; New objects cannot anymore be created (`EmplaceNewValue` will throw an exception), but the entry is still properly destructed. ### RNTupleWriter, RNTupleParallelWriter; The RNTupleWriter is the primary interface to create an RNTuple.; The writer takes ownership of a given model.; The writer can either add an RNTuple to an existing ROOT file (`RNTupleWriter::Append()`) or create a new ROOT file with an RNTuple (`RNTupleWriter::Recreate()`).; Once created, entries are added to an RNTuple either serially (`RNTupleWriter::Fill()`) or in concurrently in multiple threads with the `RNTupleParallelWriter`.; Once committed (e.g. by releasing the RNTupleWriter), the RNTuple is immutable and cannot be amended.; An RNTuple that is currently being written cannot be read. ### RNTupleReader; The RNTupleReader is the primary interface to read and inspect an RNTuple.; An RNTupleReader owns a model: either a model created from the on-disk information or an imposed, user-provided model.; The user-provided model can be limited to a subset of fields.; Data is populated to an explicit `REntry` or the model's default entry through `RNTupleReader::LoadEntry()`. The reader can create `RNTupleView` objects for the independent reading of individual fields.; The reader can create `RBulk` objects for bulk reading of individual fields. Additionally, the reader provides access to a cached copy of the descriptor.; It can display individual entries (`RNTupleReader::Show()`) and summary information (`RNTupleReader::PrintInfo()`). ##",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:13323,Performance,cache,cached,13323,"d()`) or create a new ROOT file with an RNTuple (`RNTupleWriter::Recreate()`).; Once created, entries are added to an RNTuple either serially (`RNTupleWriter::Fill()`) or in concurrently in multiple threads with the `RNTupleParallelWriter`.; Once committed (e.g. by releasing the RNTupleWriter), the RNTuple is immutable and cannot be amended.; An RNTuple that is currently being written cannot be read. ### RNTupleReader; The RNTupleReader is the primary interface to read and inspect an RNTuple.; An RNTupleReader owns a model: either a model created from the on-disk information or an imposed, user-provided model.; The user-provided model can be limited to a subset of fields.; Data is populated to an explicit `REntry` or the model's default entry through `RNTupleReader::LoadEntry()`. The reader can create `RNTupleView` objects for the independent reading of individual fields.; The reader can create `RBulk` objects for bulk reading of individual fields. Additionally, the reader provides access to a cached copy of the descriptor.; It can display individual entries (`RNTupleReader::Show()`) and summary information (`RNTupleReader::PrintInfo()`). ### RNTupleView<T>; RNTuple views provide read access to individual fields.; Views are created from an RNTupleReader.; Views are templated; for simple types (e.g., `float`, `int`), views provide read-only access directly to an RNTuple page in memory.; Complex types and void views require additional memory copies to populate an object in memory from the column data. A view can iterate over the entry range, over the field range, and over the range of a collection within an entry.; For instance, for a field `std::vector<float> pt`, a view can iterate over all `pt` values of all entries, or over the `pt` values of a particular entry. A view can safely outlive its originating reader.; Once the reader is deconstructed, any attempt to read data will throw an exception, but the view is still properly destructed. Views that originate from th",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:14346,Performance,concurren,concurrently,14346,"y of the descriptor.; It can display individual entries (`RNTupleReader::Show()`) and summary information (`RNTupleReader::PrintInfo()`). ### RNTupleView<T>; RNTuple views provide read access to individual fields.; Views are created from an RNTupleReader.; Views are templated; for simple types (e.g., `float`, `int`), views provide read-only access directly to an RNTuple page in memory.; Complex types and void views require additional memory copies to populate an object in memory from the column data. A view can iterate over the entry range, over the field range, and over the range of a collection within an entry.; For instance, for a field `std::vector<float> pt`, a view can iterate over all `pt` values of all entries, or over the `pt` values of a particular entry. A view can safely outlive its originating reader.; Once the reader is deconstructed, any attempt to read data will throw an exception, but the view is still properly destructed. Views that originate from the same reader _cannot_ be used concurrently by different threads. Internal Classes; ----------------. ### RNTupleDS; The `RNTupleDS` class is an internal class that provides an RNTuple data source for RDataFrame.; It is part of the `ROOTDataFrame` library.; The RNTuple data source supports chains with a constructor that takes a list of input files.; The RNTuple data source also supports multi-threaded dataframes, parallelized on the file and cluster level. The data source exposes inner fields of complex collections.; For instance, if the data model contains a vector of `Event` classes, where each `Event` has `pt` and `eta` floats,; the dataframe can use the event vector itself (`Event` column) as well as the `float` columns `Event.pt` and `Event.eta`. ### RClusterPool; The RClusterPool is an internal class owned be a page source.; The cluster pool maintains an I/O thread that asynchronously prefetches the next few clusters.; Through `RPageSource::SetEntryRange()`, the cluster pool is instructed to not r",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:14705,Performance,multi-thread,multi-threaded,14705,".; Complex types and void views require additional memory copies to populate an object in memory from the column data. A view can iterate over the entry range, over the field range, and over the range of a collection within an entry.; For instance, for a field `std::vector<float> pt`, a view can iterate over all `pt` values of all entries, or over the `pt` values of a particular entry. A view can safely outlive its originating reader.; Once the reader is deconstructed, any attempt to read data will throw an exception, but the view is still properly destructed. Views that originate from the same reader _cannot_ be used concurrently by different threads. Internal Classes; ----------------. ### RNTupleDS; The `RNTupleDS` class is an internal class that provides an RNTuple data source for RDataFrame.; It is part of the `ROOTDataFrame` library.; The RNTuple data source supports chains with a constructor that takes a list of input files.; The RNTuple data source also supports multi-threaded dataframes, parallelized on the file and cluster level. The data source exposes inner fields of complex collections.; For instance, if the data model contains a vector of `Event` classes, where each `Event` has `pt` and `eta` floats,; the dataframe can use the event vector itself (`Event` column) as well as the `float` columns `Event.pt` and `Event.eta`. ### RClusterPool; The RClusterPool is an internal class owned be a page source.; The cluster pool maintains an I/O thread that asynchronously prefetches the next few clusters.; Through `RPageSource::SetEntryRange()`, the cluster pool is instructed to not read beyond the given limit.; This is used in the RNTuple data source when multiple threads work on different clusters of the same file. ### RMiniFile; The RMiniFile is an internal class used to read and write RNTuple data in a ROOT file.; It provides a minimal subset of the `TFile` functionality.; Its purpose is to reduce the coupling between RNTuple and the ROOT I/O library. For writ",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:18935,Performance,concurren,concurrently,18935,"as well as `CommitCluster()` and `FlushCluster()`.; For `FlushColumns()` and `FillNoFlush()`, the sequential writer assumes exclusive access only if buffered writing is turned off.; The parallel writer assumes exclusive access to the underlying file during all operations on the writer (e.g. construction and destruction) and all operations on any created fill context (e.g. `Fill()` and `FlushCluster()`).; Notable exceptions are `FlushColumns()` and `FillNoFlush()` which are guaranteed to never access the underlying `TFile` during parallel writing (which is always buffered). A `TFile` does not take ownership of any `RNTuple` objects. When reading data, RNTuple uses the `RMiniFile` and `RRawFile` classes to open a given storage path and find the `RNTuple` anchor.; When creating a `RNTupleReader` from an existing anchor object, RNTuple uses `RRawFile` only for files of dynamic type `TFile`, `TDavixFile`, and `TNetXNGFile`.; In either case, the `RRawFile` owns its own file descriptor and does not interfere with `TFile` objects concurrently reading the file.; For anchors from files of other dynamic type, including all other `TFile` subclasses, the file is wrapped in a `RRawFileTFile` and access is shared. On-Disk Encoding; ----------------. ### Writing Case; The following steps are taken to write RNTuple data to disk:. 1. On creation of the RNTupleWriter, the header is written to disk; 2. Upon `RNTupleWriter::Fill()`, the RField<T> class _serializes_ the object into its column representation.; To this end, it uses the `RColumn` class to append elements to the columns page buffer (`RPage`); 3. When a page buffer is full (cf. tuning.md), it is sent to the page sink for writing it to disk.; Note that page boundaries do _not_ need to align with entry boundaries,; e.g. information from a single entry can span multiple pages.; 1. The page is _packed_:; depending on the type of the page, a light encoding is applied to facilitate compression, e.g., byte splitting (`RColumnElement",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:21949,Performance,perform,performed,21949,":CreateModelUpdater()`), the following steps are taken:. 1. On calling `RUpdater::BeginUpdate()`, all `REntry` instances belonging to the underlying RNTupleModel are invalidated.; 2. After adding the desired additional fields, calling `RUpdater::CommitUpdate()` will add the relevant fields to the footer's [schema extension record frame](./BinaryFormatSpecification.md#schema-extensions-record-frame).; 1. The principal columns of top-level fields and record subfields will have a non-zero first element index.; These columns are referred to as ""deferred columns"".; In particular, columns in a subfield tree of collections or variants are _not_ stored as deferred columns (see next point).; 2. All other columns belonging to the added (sub)fields will be written as usual.; 3. `RNTuple(Writer|Model)::CreateEntry()` or `RNTupleModel::CreateBareEntry()` must be used to create an `REntry` matching the new model.; 4. Writing continues as described in steps 2-5 above. ### Reading Case; The reverse process is performed on reading (e.g. `RNTupleReader::LoadEntry()`, `RNTupleView` call operator). By default, the page source uses an `RClusterPool` to asynchronously read-ahead data.; When a page of a certain cluster is required, the cluster pool reads pages of _active_ columns.; For instance, if only certain fields are used (e.g., through an imposed model), only the pages of columns connected to those fields are read.; Columns can be dynamically added (e.g. during event iteration, a new field view is created in a reader).; The cluster pool reads ahead a limited number of clusters given by the _cluster bunch size_ option (default = 1).; The read-ahead uses vector reads.; For the file backend, it additionally coalesces close read requests and uses uring reads when available. The page source can be restricted to a certain entry range.; This allows for optimizing the page lists that are being read.; Additionally, it allows for optimizing the cluster pool to not read-ahead beyond the limits",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:22801,Performance,optimiz,optimizing,22801,"e an `REntry` matching the new model.; 4. Writing continues as described in steps 2-5 above. ### Reading Case; The reverse process is performed on reading (e.g. `RNTupleReader::LoadEntry()`, `RNTupleView` call operator). By default, the page source uses an `RClusterPool` to asynchronously read-ahead data.; When a page of a certain cluster is required, the cluster pool reads pages of _active_ columns.; For instance, if only certain fields are used (e.g., through an imposed model), only the pages of columns connected to those fields are read.; Columns can be dynamically added (e.g. during event iteration, a new field view is created in a reader).; The cluster pool reads ahead a limited number of clusters given by the _cluster bunch size_ option (default = 1).; The read-ahead uses vector reads.; For the file backend, it additionally coalesces close read requests and uses uring reads when available. The page source can be restricted to a certain entry range.; This allows for optimizing the page lists that are being read.; Additionally, it allows for optimizing the cluster pool to not read-ahead beyond the limits. #### Late model extension; Reading an RNTuple with an extended model is transparent -- i.e., no additional interface calls are required.; Internally, columns that were created as part of late model extension will have synthesized zero-initialized column ranges for the clusters that were already written before the model was extended.; In addition, pages made up of 0x00 bytes are synthesized for deferred columns in the clusters that were already (partially) filled before the model was extended. Storage Backends; ----------------. Support for storage backends is implemented through derived classes of `RPageSink` and `RPageSource`.; The `RPage{Sink,Source}File` class provides a storage backend for RNTuple data in ROOT files, local or remote.; The `RPage{Sink,Source}Daos` class provides a storage backend for RNTuple data in the DAOS object store. Every new storage b",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:22877,Performance,optimiz,optimizing,22877,"ps 2-5 above. ### Reading Case; The reverse process is performed on reading (e.g. `RNTupleReader::LoadEntry()`, `RNTupleView` call operator). By default, the page source uses an `RClusterPool` to asynchronously read-ahead data.; When a page of a certain cluster is required, the cluster pool reads pages of _active_ columns.; For instance, if only certain fields are used (e.g., through an imposed model), only the pages of columns connected to those fields are read.; Columns can be dynamically added (e.g. during event iteration, a new field view is created in a reader).; The cluster pool reads ahead a limited number of clusters given by the _cluster bunch size_ option (default = 1).; The read-ahead uses vector reads.; For the file backend, it additionally coalesces close read requests and uses uring reads when available. The page source can be restricted to a certain entry range.; This allows for optimizing the page lists that are being read.; Additionally, it allows for optimizing the cluster pool to not read-ahead beyond the limits. #### Late model extension; Reading an RNTuple with an extended model is transparent -- i.e., no additional interface calls are required.; Internally, columns that were created as part of late model extension will have synthesized zero-initialized column ranges for the clusters that were already written before the model was extended.; In addition, pages made up of 0x00 bytes are synthesized for deferred columns in the clusters that were already (partially) filled before the model was extended. Storage Backends; ----------------. Support for storage backends is implemented through derived classes of `RPageSink` and `RPageSource`.; The `RPage{Sink,Source}File` class provides a storage backend for RNTuple data in ROOT files, local or remote.; The `RPage{Sink,Source}Daos` class provides a storage backend for RNTuple data in the DAOS object store. Every new storage backend needs to define; 1) The RNTuple embedding: how are RNTuple data blobs st",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:24969,Performance,concurren,concurrently,24969,"ple anchor: the initial link to the location of the header and footer (cf. format specification); 3) A locator format: how are byte ranges addressed (e.g., through an offset in a file or an object ID). That means that new backends are likely to have implications on the RNTuple format specification. The page sources and sinks are ROOT internal classes.; They are not meant to be extended by users. Multi-Threading; ---------------. The following options exist in RNTuple for multithreaded data processing. ### Implicit Multi-Threading; When `ROOT::EnableImplicitMT()` is used, RNTuple uses ROOT's task arena to compress and decompress pages.; That requires writes to be buffered and reads uses the cluster pool resp.; The RNTuple data source for RDataFrame lets RDataFrame full control of the thread pool.; That means that RDataFrame uses a separate data source for every thread, each of the data sources runs in sequential mode. ### Concurrent Readers; Multiple readers can read the same RNTuple concurrently as long as access to every individual reader is sequential. ### Parallel REntry Preparation; Multiple `REntry` object can be concurrently prepared by multiple threads.; I.e., construction and binding of the objects can happen in parallel.; The actual reading and writing of entries (`RNTupleReader::LoadEntry()`, `RNTupleWriter::Fill()`) needs to be protected by a mutex.; This is considered ""mild scalability parallelization"" in RNTuple. ### RNTupleParallelWriter; The parallel writer offers the most scalable parallel writing interface.; Multiple _fill contexts_ can concurrently serialize and compress data.; Every fill context prepares a set of entire clusters in the final on-disk layout.; When a fill context flushes data,; a brief serialization point handles the RNTuple meta-data updates and the reservation of disk space to write into. Low precision float types; --------------------------; RNTuple supports encoding floating point types with a lower precision when writing them t",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:25107,Performance,concurren,concurrently,25107,"re byte ranges addressed (e.g., through an offset in a file or an object ID). That means that new backends are likely to have implications on the RNTuple format specification. The page sources and sinks are ROOT internal classes.; They are not meant to be extended by users. Multi-Threading; ---------------. The following options exist in RNTuple for multithreaded data processing. ### Implicit Multi-Threading; When `ROOT::EnableImplicitMT()` is used, RNTuple uses ROOT's task arena to compress and decompress pages.; That requires writes to be buffered and reads uses the cluster pool resp.; The RNTuple data source for RDataFrame lets RDataFrame full control of the thread pool.; That means that RDataFrame uses a separate data source for every thread, each of the data sources runs in sequential mode. ### Concurrent Readers; Multiple readers can read the same RNTuple concurrently as long as access to every individual reader is sequential. ### Parallel REntry Preparation; Multiple `REntry` object can be concurrently prepared by multiple threads.; I.e., construction and binding of the objects can happen in parallel.; The actual reading and writing of entries (`RNTupleReader::LoadEntry()`, `RNTupleWriter::Fill()`) needs to be protected by a mutex.; This is considered ""mild scalability parallelization"" in RNTuple. ### RNTupleParallelWriter; The parallel writer offers the most scalable parallel writing interface.; Multiple _fill contexts_ can concurrently serialize and compress data.; Every fill context prepares a set of entire clusters in the final on-disk layout.; When a fill context flushes data,; a brief serialization point handles the RNTuple meta-data updates and the reservation of disk space to write into. Low precision float types; --------------------------; RNTuple supports encoding floating point types with a lower precision when writing them to disk. This encoding is specified by the; user per field and it is independent on the in-memory type used for that field (m",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:25380,Performance,scalab,scalability,25380," ---------------. The following options exist in RNTuple for multithreaded data processing. ### Implicit Multi-Threading; When `ROOT::EnableImplicitMT()` is used, RNTuple uses ROOT's task arena to compress and decompress pages.; That requires writes to be buffered and reads uses the cluster pool resp.; The RNTuple data source for RDataFrame lets RDataFrame full control of the thread pool.; That means that RDataFrame uses a separate data source for every thread, each of the data sources runs in sequential mode. ### Concurrent Readers; Multiple readers can read the same RNTuple concurrently as long as access to every individual reader is sequential. ### Parallel REntry Preparation; Multiple `REntry` object can be concurrently prepared by multiple threads.; I.e., construction and binding of the objects can happen in parallel.; The actual reading and writing of entries (`RNTupleReader::LoadEntry()`, `RNTupleWriter::Fill()`) needs to be protected by a mutex.; This is considered ""mild scalability parallelization"" in RNTuple. ### RNTupleParallelWriter; The parallel writer offers the most scalable parallel writing interface.; Multiple _fill contexts_ can concurrently serialize and compress data.; Every fill context prepares a set of entire clusters in the final on-disk layout.; When a fill context flushes data,; a brief serialization point handles the RNTuple meta-data updates and the reservation of disk space to write into. Low precision float types; --------------------------; RNTuple supports encoding floating point types with a lower precision when writing them to disk. This encoding is specified by the; user per field and it is independent on the in-memory type used for that field (meaning both a `RField<double>` or `RField<float>` can; be mapped to e.g. a low-precision 16 bit float). RNTuple supports the following encodings (all mutually exclusive):. - **Real16**/**SplitReal16**: IEEE-754 half precision float. Set by calling `RField::SetHalfPrecision()`;; - **Real32Tru",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:25484,Performance,scalab,scalable,25484,"essing. ### Implicit Multi-Threading; When `ROOT::EnableImplicitMT()` is used, RNTuple uses ROOT's task arena to compress and decompress pages.; That requires writes to be buffered and reads uses the cluster pool resp.; The RNTuple data source for RDataFrame lets RDataFrame full control of the thread pool.; That means that RDataFrame uses a separate data source for every thread, each of the data sources runs in sequential mode. ### Concurrent Readers; Multiple readers can read the same RNTuple concurrently as long as access to every individual reader is sequential. ### Parallel REntry Preparation; Multiple `REntry` object can be concurrently prepared by multiple threads.; I.e., construction and binding of the objects can happen in parallel.; The actual reading and writing of entries (`RNTupleReader::LoadEntry()`, `RNTupleWriter::Fill()`) needs to be protected by a mutex.; This is considered ""mild scalability parallelization"" in RNTuple. ### RNTupleParallelWriter; The parallel writer offers the most scalable parallel writing interface.; Multiple _fill contexts_ can concurrently serialize and compress data.; Every fill context prepares a set of entire clusters in the final on-disk layout.; When a fill context flushes data,; a brief serialization point handles the RNTuple meta-data updates and the reservation of disk space to write into. Low precision float types; --------------------------; RNTuple supports encoding floating point types with a lower precision when writing them to disk. This encoding is specified by the; user per field and it is independent on the in-memory type used for that field (meaning both a `RField<double>` or `RField<float>` can; be mapped to e.g. a low-precision 16 bit float). RNTuple supports the following encodings (all mutually exclusive):. - **Real16**/**SplitReal16**: IEEE-754 half precision float. Set by calling `RField::SetHalfPrecision()`;; - **Real32Trunc**: floating point with less than 32 bits of precision (truncated mantissa).; Set",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:25551,Performance,concurren,concurrently,25551," uses ROOT's task arena to compress and decompress pages.; That requires writes to be buffered and reads uses the cluster pool resp.; The RNTuple data source for RDataFrame lets RDataFrame full control of the thread pool.; That means that RDataFrame uses a separate data source for every thread, each of the data sources runs in sequential mode. ### Concurrent Readers; Multiple readers can read the same RNTuple concurrently as long as access to every individual reader is sequential. ### Parallel REntry Preparation; Multiple `REntry` object can be concurrently prepared by multiple threads.; I.e., construction and binding of the objects can happen in parallel.; The actual reading and writing of entries (`RNTupleReader::LoadEntry()`, `RNTupleWriter::Fill()`) needs to be protected by a mutex.; This is considered ""mild scalability parallelization"" in RNTuple. ### RNTupleParallelWriter; The parallel writer offers the most scalable parallel writing interface.; Multiple _fill contexts_ can concurrently serialize and compress data.; Every fill context prepares a set of entire clusters in the final on-disk layout.; When a fill context flushes data,; a brief serialization point handles the RNTuple meta-data updates and the reservation of disk space to write into. Low precision float types; --------------------------; RNTuple supports encoding floating point types with a lower precision when writing them to disk. This encoding is specified by the; user per field and it is independent on the in-memory type used for that field (meaning both a `RField<double>` or `RField<float>` can; be mapped to e.g. a low-precision 16 bit float). RNTuple supports the following encodings (all mutually exclusive):. - **Real16**/**SplitReal16**: IEEE-754 half precision float. Set by calling `RField::SetHalfPrecision()`;; - **Real32Trunc**: floating point with less than 32 bits of precision (truncated mantissa).; Set by calling `RField::SetTruncated(n)`, with $10 <= n <= 31$ equal to the total number ",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:2026,Safety,safe,safe,2026," `ROOT::Internal` namespace (non-public interfaces),; with the notable exception of the descriptor classes (`RNTupleDescriptor`, `RFieldDescriptor`, etc.).; Most classes in the upper layers provide public interfaces. | Layer | Description | Example of classes |; |------------|---------------------------------------------------------------------|-------------------------------------------------------------|; | Storage | Read and write pages (physical: file, object store; virtual: e.g. buffered) | RPage{Source,Sink}, RNTupleDescriptor, RClusterPool |; | Primitives | Storage-backed columns of simple types | RColumn, RColumnElement, RPage |; | Logical | Mapping of C++ types onto columns | RField, RNTupleModel, REntry |; | Iteration | Reading and writing events / properties | RNTuple{Reader,Writer}, RNTupleView, RNTupleDS (RDataFrame) |; | Tooling | Higher-level, RNTuple related utility classes | RNTupleMerger, RNTupleImporter, RNTupleInspector |. The RNTuple classes are, unless explicitly stated otherwise, conditionally thread safe. The read and write APIs provide templated, compile-time type-safe APIs,; APIs where the type at hand is passed as string and which are runtime type-safe,; and type-unsafe APIs using void pointers. On I/O errors and invalid input, RNTuple classes throw an `RException`. Walkthrough: Reading Data; -------------------------. ```c++; auto file = std::make_unique<TFile>(""data.root"");; auto ntuple = std::unique_ptr<RNTuple>(file->Get<RNTuple>(""ntpl""));. // Option 1: entire row; // The reader creates a page source; the page source creates a model from the on-disk information; auto reader = RNTupleReader::Open(ntuple);; // Populate the objects that are used in the model's default entry; reader->LoadEntry(0);; std::shared_ptr<float> pt = reader->GetDefaultEntry().GetPtr<float>(""pt"");. // Option 2: imposed model; auto model = RNTupleModel::Create();; auto pt = model->MakeField<float>(""pt"");; // The reader checks the passed model for compatibility; only",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:2093,Safety,safe,safe,2093,"ptor`, etc.).; Most classes in the upper layers provide public interfaces. | Layer | Description | Example of classes |; |------------|---------------------------------------------------------------------|-------------------------------------------------------------|; | Storage | Read and write pages (physical: file, object store; virtual: e.g. buffered) | RPage{Source,Sink}, RNTupleDescriptor, RClusterPool |; | Primitives | Storage-backed columns of simple types | RColumn, RColumnElement, RPage |; | Logical | Mapping of C++ types onto columns | RField, RNTupleModel, REntry |; | Iteration | Reading and writing events / properties | RNTuple{Reader,Writer}, RNTupleView, RNTupleDS (RDataFrame) |; | Tooling | Higher-level, RNTuple related utility classes | RNTupleMerger, RNTupleImporter, RNTupleInspector |. The RNTuple classes are, unless explicitly stated otherwise, conditionally thread safe. The read and write APIs provide templated, compile-time type-safe APIs,; APIs where the type at hand is passed as string and which are runtime type-safe,; and type-unsafe APIs using void pointers. On I/O errors and invalid input, RNTuple classes throw an `RException`. Walkthrough: Reading Data; -------------------------. ```c++; auto file = std::make_unique<TFile>(""data.root"");; auto ntuple = std::unique_ptr<RNTuple>(file->Get<RNTuple>(""ntpl""));. // Option 1: entire row; // The reader creates a page source; the page source creates a model from the on-disk information; auto reader = RNTupleReader::Open(ntuple);; // Populate the objects that are used in the model's default entry; reader->LoadEntry(0);; std::shared_ptr<float> pt = reader->GetDefaultEntry().GetPtr<float>(""pt"");. // Option 2: imposed model; auto model = RNTupleModel::Create();; auto pt = model->MakeField<float>(""pt"");; // The reader checks the passed model for compatibility; only the subset of fields defined in the model is read; auto reader = RNTupleReader::Open(std::move(model), ntuple);; reader->LoadEntry(0);. // Opt",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:2180,Safety,safe,safe,2180,"ptor`, etc.).; Most classes in the upper layers provide public interfaces. | Layer | Description | Example of classes |; |------------|---------------------------------------------------------------------|-------------------------------------------------------------|; | Storage | Read and write pages (physical: file, object store; virtual: e.g. buffered) | RPage{Source,Sink}, RNTupleDescriptor, RClusterPool |; | Primitives | Storage-backed columns of simple types | RColumn, RColumnElement, RPage |; | Logical | Mapping of C++ types onto columns | RField, RNTupleModel, REntry |; | Iteration | Reading and writing events / properties | RNTuple{Reader,Writer}, RNTupleView, RNTupleDS (RDataFrame) |; | Tooling | Higher-level, RNTuple related utility classes | RNTupleMerger, RNTupleImporter, RNTupleInspector |. The RNTuple classes are, unless explicitly stated otherwise, conditionally thread safe. The read and write APIs provide templated, compile-time type-safe APIs,; APIs where the type at hand is passed as string and which are runtime type-safe,; and type-unsafe APIs using void pointers. On I/O errors and invalid input, RNTuple classes throw an `RException`. Walkthrough: Reading Data; -------------------------. ```c++; auto file = std::make_unique<TFile>(""data.root"");; auto ntuple = std::unique_ptr<RNTuple>(file->Get<RNTuple>(""ntpl""));. // Option 1: entire row; // The reader creates a page source; the page source creates a model from the on-disk information; auto reader = RNTupleReader::Open(ntuple);; // Populate the objects that are used in the model's default entry; reader->LoadEntry(0);; std::shared_ptr<float> pt = reader->GetDefaultEntry().GetPtr<float>(""pt"");. // Option 2: imposed model; auto model = RNTupleModel::Create();; auto pt = model->MakeField<float>(""pt"");; // The reader checks the passed model for compatibility; only the subset of fields defined in the model is read; auto reader = RNTupleReader::Open(std::move(model), ntuple);; reader->LoadEntry(0);. // Opt",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:2196,Safety,unsafe,unsafe,2196,"ptor`, etc.).; Most classes in the upper layers provide public interfaces. | Layer | Description | Example of classes |; |------------|---------------------------------------------------------------------|-------------------------------------------------------------|; | Storage | Read and write pages (physical: file, object store; virtual: e.g. buffered) | RPage{Source,Sink}, RNTupleDescriptor, RClusterPool |; | Primitives | Storage-backed columns of simple types | RColumn, RColumnElement, RPage |; | Logical | Mapping of C++ types onto columns | RField, RNTupleModel, REntry |; | Iteration | Reading and writing events / properties | RNTuple{Reader,Writer}, RNTupleView, RNTupleDS (RDataFrame) |; | Tooling | Higher-level, RNTuple related utility classes | RNTupleMerger, RNTupleImporter, RNTupleInspector |. The RNTuple classes are, unless explicitly stated otherwise, conditionally thread safe. The read and write APIs provide templated, compile-time type-safe APIs,; APIs where the type at hand is passed as string and which are runtime type-safe,; and type-unsafe APIs using void pointers. On I/O errors and invalid input, RNTuple classes throw an `RException`. Walkthrough: Reading Data; -------------------------. ```c++; auto file = std::make_unique<TFile>(""data.root"");; auto ntuple = std::unique_ptr<RNTuple>(file->Get<RNTuple>(""ntpl""));. // Option 1: entire row; // The reader creates a page source; the page source creates a model from the on-disk information; auto reader = RNTupleReader::Open(ntuple);; // Populate the objects that are used in the model's default entry; reader->LoadEntry(0);; std::shared_ptr<float> pt = reader->GetDefaultEntry().GetPtr<float>(""pt"");. // Option 2: imposed model; auto model = RNTupleModel::Create();; auto pt = model->MakeField<float>(""pt"");; // The reader checks the passed model for compatibility; only the subset of fields defined in the model is read; auto reader = RNTupleReader::Open(std::move(model), ntuple);; reader->LoadEntry(0);. // Opt",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:3837,Safety,safe,safe,3837," auto pt = model->MakeField<float>(""pt"");; // The reader checks the passed model for compatibility; only the subset of fields defined in the model is read; auto reader = RNTupleReader::Open(std::move(model), ntuple);; reader->LoadEntry(0);. // Option 3: through views; // Each view will only trigger reading of the related field, without reading other fields at the same entry number.; auto reader = RNTupleReader::Open(ntuple);; auto viewPt = reader->GetView<float>(""pt"");; // Load the pt from the first entry; auto pt = viewPt(0);; ```. In the above cases, RNTuple creates the objects being read into.; It is also possible to bind already existing objects.; This is shown below for entries and works similarly for views. ```c++; // A bare entry is an entry that has initially no bindings (all top-level fields need to be bound by the caller); auto entry = reader->GetModel().CreateBareEntry();; auto ptToken = entry->GetToken(""pt"");. // Option 1: type safe, shared ownership; std::shared_ptr<float> ptTypedSharedPtr;; entry->BindValue(ptToken, ptTypedSharedPtr);. // Option 2: type unsafe, shared ownership; std::shared_ptr<void> ptVoidSharedPtr;; entry->BindValue(ptToken, ptVoidSharedPtr);. // Option 3: type unsafe, application owns the object; void *ptVoidPtr;; entry->BindRawPtr(ptToken, ptVoidPtr);. // Option 4: switch back from application-provided object to RNTuple-created object; entry->EmplaceNewValue(ptToken);. // For all options: use an explicit entry; reader->LoadEntry(0, *entry);; ```. Walkthrough: Writing Data; -------------------------. ```c++; auto model = RNTupleModel::Create();; // Add a field to the model and return the shared pointer for that field in the model's default entry.; auto ptrPt = model->MakeField<float>(""pt"");. auto file = std::make_unique<TFile>(""data.root"", ""APPEND"");; // The writer creates a page sink and connects the model's fields to it; auto writer = RNTupleWriter::Append(std::move(model), ""ntpl"", *file);; *ptrPt = 1.0;; // Append the model's def",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:3967,Safety,unsafe,unsafe,3967,"ined in the model is read; auto reader = RNTupleReader::Open(std::move(model), ntuple);; reader->LoadEntry(0);. // Option 3: through views; // Each view will only trigger reading of the related field, without reading other fields at the same entry number.; auto reader = RNTupleReader::Open(ntuple);; auto viewPt = reader->GetView<float>(""pt"");; // Load the pt from the first entry; auto pt = viewPt(0);; ```. In the above cases, RNTuple creates the objects being read into.; It is also possible to bind already existing objects.; This is shown below for entries and works similarly for views. ```c++; // A bare entry is an entry that has initially no bindings (all top-level fields need to be bound by the caller); auto entry = reader->GetModel().CreateBareEntry();; auto ptToken = entry->GetToken(""pt"");. // Option 1: type safe, shared ownership; std::shared_ptr<float> ptTypedSharedPtr;; entry->BindValue(ptToken, ptTypedSharedPtr);. // Option 2: type unsafe, shared ownership; std::shared_ptr<void> ptVoidSharedPtr;; entry->BindValue(ptToken, ptVoidSharedPtr);. // Option 3: type unsafe, application owns the object; void *ptVoidPtr;; entry->BindRawPtr(ptToken, ptVoidPtr);. // Option 4: switch back from application-provided object to RNTuple-created object; entry->EmplaceNewValue(ptToken);. // For all options: use an explicit entry; reader->LoadEntry(0, *entry);; ```. Walkthrough: Writing Data; -------------------------. ```c++; auto model = RNTupleModel::Create();; // Add a field to the model and return the shared pointer for that field in the model's default entry.; auto ptrPt = model->MakeField<float>(""pt"");. auto file = std::make_unique<TFile>(""data.root"", ""APPEND"");; // The writer creates a page sink and connects the model's fields to it; auto writer = RNTupleWriter::Append(std::move(model), ""ntpl"", *file);; *ptrPt = 1.0;; // Append the model's default entry; writer->Fill();; // Commit the dataset by destructing the writer; writer.reset();; ```. The points on object type-safe",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:4096,Safety,unsafe,unsafe,4096," 3: through views; // Each view will only trigger reading of the related field, without reading other fields at the same entry number.; auto reader = RNTupleReader::Open(ntuple);; auto viewPt = reader->GetView<float>(""pt"");; // Load the pt from the first entry; auto pt = viewPt(0);; ```. In the above cases, RNTuple creates the objects being read into.; It is also possible to bind already existing objects.; This is shown below for entries and works similarly for views. ```c++; // A bare entry is an entry that has initially no bindings (all top-level fields need to be bound by the caller); auto entry = reader->GetModel().CreateBareEntry();; auto ptToken = entry->GetToken(""pt"");. // Option 1: type safe, shared ownership; std::shared_ptr<float> ptTypedSharedPtr;; entry->BindValue(ptToken, ptTypedSharedPtr);. // Option 2: type unsafe, shared ownership; std::shared_ptr<void> ptVoidSharedPtr;; entry->BindValue(ptToken, ptVoidSharedPtr);. // Option 3: type unsafe, application owns the object; void *ptVoidPtr;; entry->BindRawPtr(ptToken, ptVoidPtr);. // Option 4: switch back from application-provided object to RNTuple-created object; entry->EmplaceNewValue(ptToken);. // For all options: use an explicit entry; reader->LoadEntry(0, *entry);; ```. Walkthrough: Writing Data; -------------------------. ```c++; auto model = RNTupleModel::Create();; // Add a field to the model and return the shared pointer for that field in the model's default entry.; auto ptrPt = model->MakeField<float>(""pt"");. auto file = std::make_unique<TFile>(""data.root"", ""APPEND"");; // The writer creates a page sink and connects the model's fields to it; auto writer = RNTupleWriter::Append(std::move(model), ""ntpl"", *file);; *ptrPt = 1.0;; // Append the model's default entry; writer->Fill();; // Commit the dataset by destructing the writer; writer.reset();; ```. The points on object type-safety and ownership apply in the same way as for reading data. Creation of the RNTuple model can use runtime type informatio",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:5009,Safety,safe,safety,5009,"Ptr;; entry->BindValue(ptToken, ptVoidSharedPtr);. // Option 3: type unsafe, application owns the object; void *ptVoidPtr;; entry->BindRawPtr(ptToken, ptVoidPtr);. // Option 4: switch back from application-provided object to RNTuple-created object; entry->EmplaceNewValue(ptToken);. // For all options: use an explicit entry; reader->LoadEntry(0, *entry);; ```. Walkthrough: Writing Data; -------------------------. ```c++; auto model = RNTupleModel::Create();; // Add a field to the model and return the shared pointer for that field in the model's default entry.; auto ptrPt = model->MakeField<float>(""pt"");. auto file = std::make_unique<TFile>(""data.root"", ""APPEND"");; // The writer creates a page sink and connects the model's fields to it; auto writer = RNTupleWriter::Append(std::move(model), ""ntpl"", *file);; *ptrPt = 1.0;; // Append the model's default entry; writer->Fill();; // Commit the dataset by destructing the writer; writer.reset();; ```. The points on object type-safety and ownership apply in the same way as for reading data. Creation of the RNTuple model can use runtime type information:. ```c++; auto model = RNTupleModel::Create();; model->AddField(RFieldBase::Create(""pt"", ""float"").Unwrap());; ```. Main Classes; ------------. ### RNTuple; The RNTuple class contains the information of the RNTuple anchor in a ROOT file (see specification).; It has a dictionary and is streamed through the standard ROOT I/O.; An RNTuple object represents an RNTuple dataset but it is not the dataset itself.; It can be used like a token to open the actual RNTuple dataset with, e.g., RDF or an RNTupleReader,; and it provides the `Merge(...)` interface for the `TFileMerger`. ### RPageSource / Sink; The page source and sink can read and write pages and clusters from and to a storage backend.; There are concrete class implementations for an RNTuple stored in a ROOT file (local or remote), and for an RNTuple stored in a DAOS object store.; There is a virtual page sink for buffered writes",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:11910,Safety,safe,safely,11910,"type.; For instance, a `std::vector<Event>` can be projected onto a `std::vector<float>` for a float member of `Event`.; Projected fields are stored as header meta-data. Fields can be added to a model after the writing process has started (cf. `RNTupleWriter::CreateModelUpdater()`).; This is called _late model extension_.; Addition of fields invalidates previously created entries.; The values of deferred fields for the already written entries is set to the default constructed type of the field. ### REntry; The REntry represents a row/entry in an RNTuple.; It contains a list of `RValue` objects that correspond to the top-level fields of the originating model.; The entry gives access to the shared pointers corresponding to the top-level fields.; It also provides functionality to bind application-provided pointers. An REntry can be passed to `RNTupleWriter::Fill()` and `RNTupleReader::LoadEntry()`.; Otherwise, the reader/writer uses the default entry of its model. An entry can safely outlive its originating model.; New objects cannot anymore be created (`EmplaceNewValue` will throw an exception), but the entry is still properly destructed. ### RNTupleWriter, RNTupleParallelWriter; The RNTupleWriter is the primary interface to create an RNTuple.; The writer takes ownership of a given model.; The writer can either add an RNTuple to an existing ROOT file (`RNTupleWriter::Append()`) or create a new ROOT file with an RNTuple (`RNTupleWriter::Recreate()`).; Once created, entries are added to an RNTuple either serially (`RNTupleWriter::Fill()`) or in concurrently in multiple threads with the `RNTupleParallelWriter`.; Once committed (e.g. by releasing the RNTupleWriter), the RNTuple is immutable and cannot be amended.; An RNTuple that is currently being written cannot be read. ### RNTupleReader; The RNTupleReader is the primary interface to read and inspect an RNTuple.; An RNTupleReader owns a model: either a model created from the on-disk information or an imposed, user-provid",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:14120,Safety,safe,safely,14120,"leView` objects for the independent reading of individual fields.; The reader can create `RBulk` objects for bulk reading of individual fields. Additionally, the reader provides access to a cached copy of the descriptor.; It can display individual entries (`RNTupleReader::Show()`) and summary information (`RNTupleReader::PrintInfo()`). ### RNTupleView<T>; RNTuple views provide read access to individual fields.; Views are created from an RNTupleReader.; Views are templated; for simple types (e.g., `float`, `int`), views provide read-only access directly to an RNTuple page in memory.; Complex types and void views require additional memory copies to populate an object in memory from the column data. A view can iterate over the entry range, over the field range, and over the range of a collection within an entry.; For instance, for a field `std::vector<float> pt`, a view can iterate over all `pt` values of all entries, or over the `pt` values of a particular entry. A view can safely outlive its originating reader.; Once the reader is deconstructed, any attempt to read data will throw an exception, but the view is still properly destructed. Views that originate from the same reader _cannot_ be used concurrently by different threads. Internal Classes; ----------------. ### RNTupleDS; The `RNTupleDS` class is an internal class that provides an RNTuple data source for RDataFrame.; It is part of the `ROOTDataFrame` library.; The RNTuple data source supports chains with a constructor that takes a list of input files.; The RNTuple data source also supports multi-threaded dataframes, parallelized on the file and cluster level. The data source exposes inner fields of complex collections.; For instance, if the data model contains a vector of `Event` classes, where each `Event` has `pt` and `eta` floats,; the dataframe can use the event vector itself (`Event` column) as well as the `float` columns `Event.pt` and `Event.eta`. ### RClusterPool; The RClusterPool is an internal class ",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:31425,Safety,avoid,avoid,31425,"=======================================. Reading an object with RNTuple should be seen as _overwriting_ its persistent data members.; Given a properly constructed and valid object, the object must ensure that it stays valid when overwriting its persistent data members.; However, the object should not rely on its transient state to remain unchanged during reading:; it may be destructed and constructed again when it is read as part of a collection (see below). An object that is being read from disk may have been constructed by `RField::CreateValue()`.; In this case, the deleter returned by `RField::GetDeleter()` releases the resources. When reading collections of type `T` (`std::vector<T>`, `ROOT::RVec<T>`, ...), RNTuple uses `RField::CreateValue()` to construct elements of the inner type `T`.; As the size of a collection changes from event to event, this has the following effect on its elements; - If the collection shrinks, cut-off elements are destructed; - If the collection grows, new elements are constructed before reading them; - If the array buffer of the collection is reallocated (may happen for both shrinking and growing depending on the collection), all elements are destructed first in the old buffer; and the new number of elements is constructed in the new buffer. So unless the collection buffer needs to be reallocated, RNTuple tries to avoid unnecessary destruction/construction but instead overwrites existing objects.; Note that RNTuple currently does not copy or move existing objects when the collection buffer is reallocated. Naming Conventions; ==================. For byte arrays and collections of things, the RNTuple code uses the following variable name suffixes:; - `XyzSize` denotes the size of Xyz in bytes on disk, i.e. after compression. Example: `fPageListSize`.; - `XyzLength` denotes the size of Xyz in bytes in memory, i.e. uncompressed. Example: `fPageListLength`.; - `NXyz` denotes the number of Xyz items in a collection. Example: `fNPageLists`.; ",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:6549,Security,access,access,6549,"token to open the actual RNTuple dataset with, e.g., RDF or an RNTupleReader,; and it provides the `Merge(...)` interface for the `TFileMerger`. ### RPageSource / Sink; The page source and sink can read and write pages and clusters from and to a storage backend.; There are concrete class implementations for an RNTuple stored in a ROOT file (local or remote), and for an RNTuple stored in a DAOS object store.; There is a virtual page sink for buffered writes, which also groups pages of the same column before flushing them to disk.; There is a virtual page source for aligned friend datasets (horizontal data combination). Page sources and sinks do not operate entry-based but based on pages/indices of columns.; For instance, there is no API in the page sink to write an entry, but only to write pages of columns.; The higher-level APIs, e.g. `RField`, `REntry`, `RNTupleWriter`, take care of presenting the available data as entries where necessary. The page source also gives access to an `RNTupleDescriptor` through a read/write lock guard.; The `RNTupleDescriptor` owned by the page source changes only when new cluster meta-data are loaded.; The header and the cluster group summary information is stable throughout its lifetime (cf. format specification). ### R{NTuple,Field,Column,Cluster,...}Descriptor; The descriptor classes provide read-only access to the on-disk meta-data of an RNTuple.; The meta-data include the schema (fields and columns), information about clusters and the page locations.; The descriptor classes are closely related to the format specification. For normal read and write tasks, access to the descriptor is not necessary.; One notable exception is bulk reading, where the descriptor can be used to determine entry boundaries of clusters.; The descriptors are used internally, e.g. to build an RNTupleModel from the on-disk information.; The descriptors are also useful for inspection purposes. The descriptor classes contain a copy of the meta-data; they are not ",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:6924,Security,access,access,6924,"emote), and for an RNTuple stored in a DAOS object store.; There is a virtual page sink for buffered writes, which also groups pages of the same column before flushing them to disk.; There is a virtual page source for aligned friend datasets (horizontal data combination). Page sources and sinks do not operate entry-based but based on pages/indices of columns.; For instance, there is no API in the page sink to write an entry, but only to write pages of columns.; The higher-level APIs, e.g. `RField`, `REntry`, `RNTupleWriter`, take care of presenting the available data as entries where necessary. The page source also gives access to an `RNTupleDescriptor` through a read/write lock guard.; The `RNTupleDescriptor` owned by the page source changes only when new cluster meta-data are loaded.; The header and the cluster group summary information is stable throughout its lifetime (cf. format specification). ### R{NTuple,Field,Column,Cluster,...}Descriptor; The descriptor classes provide read-only access to the on-disk meta-data of an RNTuple.; The meta-data include the schema (fields and columns), information about clusters and the page locations.; The descriptor classes are closely related to the format specification. For normal read and write tasks, access to the descriptor is not necessary.; One notable exception is bulk reading, where the descriptor can be used to determine entry boundaries of clusters.; The descriptors are used internally, e.g. to build an RNTupleModel from the on-disk information.; The descriptors are also useful for inspection purposes. The descriptor classes contain a copy of the meta-data; they are not linked to an open page source.; A descriptor can be used after its originating page source has been deleted. ### RField<T>; The RField<T> classes are central in RNTuple:; they link the in-memory representation of data types to their on-disk representation.; All field classes inherit from `RFieldBase`. Every type with RNTuple I/O supported has a corre",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:7184,Security,access,access,7184,"on). Page sources and sinks do not operate entry-based but based on pages/indices of columns.; For instance, there is no API in the page sink to write an entry, but only to write pages of columns.; The higher-level APIs, e.g. `RField`, `REntry`, `RNTupleWriter`, take care of presenting the available data as entries where necessary. The page source also gives access to an `RNTupleDescriptor` through a read/write lock guard.; The `RNTupleDescriptor` owned by the page source changes only when new cluster meta-data are loaded.; The header and the cluster group summary information is stable throughout its lifetime (cf. format specification). ### R{NTuple,Field,Column,Cluster,...}Descriptor; The descriptor classes provide read-only access to the on-disk meta-data of an RNTuple.; The meta-data include the schema (fields and columns), information about clusters and the page locations.; The descriptor classes are closely related to the format specification. For normal read and write tasks, access to the descriptor is not necessary.; One notable exception is bulk reading, where the descriptor can be used to determine entry boundaries of clusters.; The descriptors are used internally, e.g. to build an RNTupleModel from the on-disk information.; The descriptors are also useful for inspection purposes. The descriptor classes contain a copy of the meta-data; they are not linked to an open page source.; A descriptor can be used after its originating page source has been deleted. ### RField<T>; The RField<T> classes are central in RNTuple:; they link the in-memory representation of data types to their on-disk representation.; All field classes inherit from `RFieldBase`. Every type with RNTuple I/O supported has a corresponding RField<T> template specialization.; Complex types are composed of fields and sub fields.; E.g., a `struct` is represented by a parent field for the `struct` itself and a subfield for every member of the `struct`.; Fields of complex types have type-erased vers",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:11605,Security,access,access,11605,"sed to identify the entries created from this model.; Unless a model is created as ""bare model"", it owns a default entry that is used by default by the `RNTupleReader` and the `RNTupleWriter`. A model can add _projected fields_.; Projected fields map existing physical fields to a different type.; For instance, a `std::vector<Event>` can be projected onto a `std::vector<float>` for a float member of `Event`.; Projected fields are stored as header meta-data. Fields can be added to a model after the writing process has started (cf. `RNTupleWriter::CreateModelUpdater()`).; This is called _late model extension_.; Addition of fields invalidates previously created entries.; The values of deferred fields for the already written entries is set to the default constructed type of the field. ### REntry; The REntry represents a row/entry in an RNTuple.; It contains a list of `RValue` objects that correspond to the top-level fields of the originating model.; The entry gives access to the shared pointers corresponding to the top-level fields.; It also provides functionality to bind application-provided pointers. An REntry can be passed to `RNTupleWriter::Fill()` and `RNTupleReader::LoadEntry()`.; Otherwise, the reader/writer uses the default entry of its model. An entry can safely outlive its originating model.; New objects cannot anymore be created (`EmplaceNewValue` will throw an exception), but the entry is still properly destructed. ### RNTupleWriter, RNTupleParallelWriter; The RNTupleWriter is the primary interface to create an RNTuple.; The writer takes ownership of a given model.; The writer can either add an RNTuple to an existing ROOT file (`RNTupleWriter::Append()`) or create a new ROOT file with an RNTuple (`RNTupleWriter::Recreate()`).; Once created, entries are added to an RNTuple either serially (`RNTupleWriter::Fill()`) or in concurrently in multiple threads with the `RNTupleParallelWriter`.; Once committed (e.g. by releasing the RNTupleWriter), the RNTuple is immut",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:13311,Security,access,access,13311,"d()`) or create a new ROOT file with an RNTuple (`RNTupleWriter::Recreate()`).; Once created, entries are added to an RNTuple either serially (`RNTupleWriter::Fill()`) or in concurrently in multiple threads with the `RNTupleParallelWriter`.; Once committed (e.g. by releasing the RNTupleWriter), the RNTuple is immutable and cannot be amended.; An RNTuple that is currently being written cannot be read. ### RNTupleReader; The RNTupleReader is the primary interface to read and inspect an RNTuple.; An RNTupleReader owns a model: either a model created from the on-disk information or an imposed, user-provided model.; The user-provided model can be limited to a subset of fields.; Data is populated to an explicit `REntry` or the model's default entry through `RNTupleReader::LoadEntry()`. The reader can create `RNTupleView` objects for the independent reading of individual fields.; The reader can create `RBulk` objects for bulk reading of individual fields. Additionally, the reader provides access to a cached copy of the descriptor.; It can display individual entries (`RNTupleReader::Show()`) and summary information (`RNTupleReader::PrintInfo()`). ### RNTupleView<T>; RNTuple views provide read access to individual fields.; Views are created from an RNTupleReader.; Views are templated; for simple types (e.g., `float`, `int`), views provide read-only access directly to an RNTuple page in memory.; Complex types and void views require additional memory copies to populate an object in memory from the column data. A view can iterate over the entry range, over the field range, and over the range of a collection within an entry.; For instance, for a field `std::vector<float> pt`, a view can iterate over all `pt` values of all entries, or over the `pt` values of a particular entry. A view can safely outlive its originating reader.; Once the reader is deconstructed, any attempt to read data will throw an exception, but the view is still properly destructed. Views that originate from th",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:13518,Security,access,access,13518,"iple threads with the `RNTupleParallelWriter`.; Once committed (e.g. by releasing the RNTupleWriter), the RNTuple is immutable and cannot be amended.; An RNTuple that is currently being written cannot be read. ### RNTupleReader; The RNTupleReader is the primary interface to read and inspect an RNTuple.; An RNTupleReader owns a model: either a model created from the on-disk information or an imposed, user-provided model.; The user-provided model can be limited to a subset of fields.; Data is populated to an explicit `REntry` or the model's default entry through `RNTupleReader::LoadEntry()`. The reader can create `RNTupleView` objects for the independent reading of individual fields.; The reader can create `RBulk` objects for bulk reading of individual fields. Additionally, the reader provides access to a cached copy of the descriptor.; It can display individual entries (`RNTupleReader::Show()`) and summary information (`RNTupleReader::PrintInfo()`). ### RNTupleView<T>; RNTuple views provide read access to individual fields.; Views are created from an RNTupleReader.; Views are templated; for simple types (e.g., `float`, `int`), views provide read-only access directly to an RNTuple page in memory.; Complex types and void views require additional memory copies to populate an object in memory from the column data. A view can iterate over the entry range, over the field range, and over the range of a collection within an entry.; For instance, for a field `std::vector<float> pt`, a view can iterate over all `pt` values of all entries, or over the `pt` values of a particular entry. A view can safely outlive its originating reader.; Once the reader is deconstructed, any attempt to read data will throw an exception, but the view is still properly destructed. Views that originate from the same reader _cannot_ be used concurrently by different threads. Internal Classes; ----------------. ### RNTupleDS; The `RNTupleDS` class is an internal class that provides an RNTuple data sou",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:13676,Security,access,access,13676," currently being written cannot be read. ### RNTupleReader; The RNTupleReader is the primary interface to read and inspect an RNTuple.; An RNTupleReader owns a model: either a model created from the on-disk information or an imposed, user-provided model.; The user-provided model can be limited to a subset of fields.; Data is populated to an explicit `REntry` or the model's default entry through `RNTupleReader::LoadEntry()`. The reader can create `RNTupleView` objects for the independent reading of individual fields.; The reader can create `RBulk` objects for bulk reading of individual fields. Additionally, the reader provides access to a cached copy of the descriptor.; It can display individual entries (`RNTupleReader::Show()`) and summary information (`RNTupleReader::PrintInfo()`). ### RNTupleView<T>; RNTuple views provide read access to individual fields.; Views are created from an RNTupleReader.; Views are templated; for simple types (e.g., `float`, `int`), views provide read-only access directly to an RNTuple page in memory.; Complex types and void views require additional memory copies to populate an object in memory from the column data. A view can iterate over the entry range, over the field range, and over the range of a collection within an entry.; For instance, for a field `std::vector<float> pt`, a view can iterate over all `pt` values of all entries, or over the `pt` values of a particular entry. A view can safely outlive its originating reader.; Once the reader is deconstructed, any attempt to read data will throw an exception, but the view is still properly destructed. Views that originate from the same reader _cannot_ be used concurrently by different threads. Internal Classes; ----------------. ### RNTupleDS; The `RNTupleDS` class is an internal class that provides an RNTuple data source for RDataFrame.; It is part of the `ROOTDataFrame` library.; The RNTuple data source supports chains with a constructor that takes a list of input files.; The RNTupl",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:14792,Security,expose,exposes,14792,"t in memory from the column data. A view can iterate over the entry range, over the field range, and over the range of a collection within an entry.; For instance, for a field `std::vector<float> pt`, a view can iterate over all `pt` values of all entries, or over the `pt` values of a particular entry. A view can safely outlive its originating reader.; Once the reader is deconstructed, any attempt to read data will throw an exception, but the view is still properly destructed. Views that originate from the same reader _cannot_ be used concurrently by different threads. Internal Classes; ----------------. ### RNTupleDS; The `RNTupleDS` class is an internal class that provides an RNTuple data source for RDataFrame.; It is part of the `ROOTDataFrame` library.; The RNTuple data source supports chains with a constructor that takes a list of input files.; The RNTuple data source also supports multi-threaded dataframes, parallelized on the file and cluster level. The data source exposes inner fields of complex collections.; For instance, if the data model contains a vector of `Event` classes, where each `Event` has `pt` and `eta` floats,; the dataframe can use the event vector itself (`Event` column) as well as the `float` columns `Event.pt` and `Event.eta`. ### RClusterPool; The RClusterPool is an internal class owned be a page source.; The cluster pool maintains an I/O thread that asynchronously prefetches the next few clusters.; Through `RPageSource::SetEntryRange()`, the cluster pool is instructed to not read beyond the given limit.; This is used in the RNTuple data source when multiple threads work on different clusters of the same file. ### RMiniFile; The RMiniFile is an internal class used to read and write RNTuple data in a ROOT file.; It provides a minimal subset of the `TFile` functionality.; Its purpose is to reduce the coupling between RNTuple and the ROOT I/O library. For writing data, the RMiniFile can either use a proper `TFile` (descendant) or a C file strea",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:16300,Security,access,access,16300,"the cluster pool is instructed to not read beyond the given limit.; This is used in the RNTuple data source when multiple threads work on different clusters of the same file. ### RMiniFile; The RMiniFile is an internal class used to read and write RNTuple data in a ROOT file.; It provides a minimal subset of the `TFile` functionality.; Its purpose is to reduce the coupling between RNTuple and the ROOT I/O library. For writing data, the RMiniFile can either use a proper `TFile` (descendant) or a C file stream (only for new ROOT files with a single RNTuple).; For reading, the `RMiniFile` always uses an `RRawFile`. ### RRawFile; The RRawFile internal abstract class provides an interface to read byte ranges from a file, including vector reads.; Concrete implementations exist for local files, XRootD and HTTP (the latter two through the ROOT plugin mechanism).; The local file implementation on Linux uses uring for vector reads, if available.; `RRawFileTFile` wraps an existing `TFile` and provides access to the full set of implementations, e.g. `TMemFile`. Tooling; -------. ### RNTupleMerger; The `RNTupleMerger` is an internal class and part of the core RNTuple library.; It concatenates RNTuple data from several sources into a combined sink.; It implements ""fast merging"", i.e. copy-based merging that does not decompress and recompress pages.; The RNTupler merger is used by the `TFileMerger` and thus provides RNTuple merge support in `hadd` and `TBufferMerger`. ### RNTupleImporter; The RNTupleImporter creates RNTuple data sets from ROOT trees.; It is part of the `ROOTNTupleUtil` library. ### RNTupleInspector; The RNTupleInspector provides insights of an RNTuple, e.g. the distribution of data volume wrt. column types.; It is part of the `ROOTNTupleUtil` library. Ownership Model; ---------------. By default, objects involved in RNTuple I/O (objects read from disk or written to disk) are passed to RNTuple as shared pointers.; Both RNTuple or the application may create the obje",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:17610,Security,access,access,17610," merging"", i.e. copy-based merging that does not decompress and recompress pages.; The RNTupler merger is used by the `TFileMerger` and thus provides RNTuple merge support in `hadd` and `TBufferMerger`. ### RNTupleImporter; The RNTupleImporter creates RNTuple data sets from ROOT trees.; It is part of the `ROOTNTupleUtil` library. ### RNTupleInspector; The RNTupleInspector provides insights of an RNTuple, e.g. the distribution of data volume wrt. column types.; It is part of the `ROOTNTupleUtil` library. Ownership Model; ---------------. By default, objects involved in RNTuple I/O (objects read from disk or written to disk) are passed to RNTuple as shared pointers.; Both RNTuple or the application may create the object.; Raw pointers to objects can be passed to RNTuple -- such objects are considered as owned by the application.; The caller has to ensure that the lifetime of the object lasts during the I/O operations. An RNTuple writer that is constructed without a `TFile` object (`RNTupleWriter::Recreate()`) assumes exclusive access to the underlying file.; An RNTuple writer that uses a `TFile` for writing (`RNTupleWriter::Append()`) assumes that the `TFile` object outlives the writer's lifetime.; The serial writer assumes exclusive access to the underlying file during construction, destruction and `Fill()` as well as `CommitCluster()` and `FlushCluster()`.; For `FlushColumns()` and `FillNoFlush()`, the sequential writer assumes exclusive access only if buffered writing is turned off.; The parallel writer assumes exclusive access to the underlying file during all operations on the writer (e.g. construction and destruction) and all operations on any created fill context (e.g. `Fill()` and `FlushCluster()`).; Notable exceptions are `FlushColumns()` and `FillNoFlush()` which are guaranteed to never access the underlying `TFile` during parallel writing (which is always buffered). A `TFile` does not take ownership of any `RNTuple` objects. When reading data, RNTuple uses ",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:17821,Security,access,access,17821,"rt of the `ROOTNTupleUtil` library. ### RNTupleInspector; The RNTupleInspector provides insights of an RNTuple, e.g. the distribution of data volume wrt. column types.; It is part of the `ROOTNTupleUtil` library. Ownership Model; ---------------. By default, objects involved in RNTuple I/O (objects read from disk or written to disk) are passed to RNTuple as shared pointers.; Both RNTuple or the application may create the object.; Raw pointers to objects can be passed to RNTuple -- such objects are considered as owned by the application.; The caller has to ensure that the lifetime of the object lasts during the I/O operations. An RNTuple writer that is constructed without a `TFile` object (`RNTupleWriter::Recreate()`) assumes exclusive access to the underlying file.; An RNTuple writer that uses a `TFile` for writing (`RNTupleWriter::Append()`) assumes that the `TFile` object outlives the writer's lifetime.; The serial writer assumes exclusive access to the underlying file during construction, destruction and `Fill()` as well as `CommitCluster()` and `FlushCluster()`.; For `FlushColumns()` and `FillNoFlush()`, the sequential writer assumes exclusive access only if buffered writing is turned off.; The parallel writer assumes exclusive access to the underlying file during all operations on the writer (e.g. construction and destruction) and all operations on any created fill context (e.g. `Fill()` and `FlushCluster()`).; Notable exceptions are `FlushColumns()` and `FillNoFlush()` which are guaranteed to never access the underlying `TFile` during parallel writing (which is always buffered). A `TFile` does not take ownership of any `RNTuple` objects. When reading data, RNTuple uses the `RMiniFile` and `RRawFile` classes to open a given storage path and find the `RNTuple` anchor.; When creating a `RNTupleReader` from an existing anchor object, RNTuple uses `RRawFile` only for files of dynamic type `TFile`, `TDavixFile`, and `TNetXNGFile`.; In either case, the `RRawFile` own",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:18031,Security,access,access,18031,"e wrt. column types.; It is part of the `ROOTNTupleUtil` library. Ownership Model; ---------------. By default, objects involved in RNTuple I/O (objects read from disk or written to disk) are passed to RNTuple as shared pointers.; Both RNTuple or the application may create the object.; Raw pointers to objects can be passed to RNTuple -- such objects are considered as owned by the application.; The caller has to ensure that the lifetime of the object lasts during the I/O operations. An RNTuple writer that is constructed without a `TFile` object (`RNTupleWriter::Recreate()`) assumes exclusive access to the underlying file.; An RNTuple writer that uses a `TFile` for writing (`RNTupleWriter::Append()`) assumes that the `TFile` object outlives the writer's lifetime.; The serial writer assumes exclusive access to the underlying file during construction, destruction and `Fill()` as well as `CommitCluster()` and `FlushCluster()`.; For `FlushColumns()` and `FillNoFlush()`, the sequential writer assumes exclusive access only if buffered writing is turned off.; The parallel writer assumes exclusive access to the underlying file during all operations on the writer (e.g. construction and destruction) and all operations on any created fill context (e.g. `Fill()` and `FlushCluster()`).; Notable exceptions are `FlushColumns()` and `FillNoFlush()` which are guaranteed to never access the underlying `TFile` during parallel writing (which is always buffered). A `TFile` does not take ownership of any `RNTuple` objects. When reading data, RNTuple uses the `RMiniFile` and `RRawFile` classes to open a given storage path and find the `RNTuple` anchor.; When creating a `RNTupleReader` from an existing anchor object, RNTuple uses `RRawFile` only for files of dynamic type `TFile`, `TDavixFile`, and `TNetXNGFile`.; In either case, the `RRawFile` owns its own file descriptor and does not interfere with `TFile` objects concurrently reading the file.; For anchors from files of other dynamic type,",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:18117,Security,access,access,18117," involved in RNTuple I/O (objects read from disk or written to disk) are passed to RNTuple as shared pointers.; Both RNTuple or the application may create the object.; Raw pointers to objects can be passed to RNTuple -- such objects are considered as owned by the application.; The caller has to ensure that the lifetime of the object lasts during the I/O operations. An RNTuple writer that is constructed without a `TFile` object (`RNTupleWriter::Recreate()`) assumes exclusive access to the underlying file.; An RNTuple writer that uses a `TFile` for writing (`RNTupleWriter::Append()`) assumes that the `TFile` object outlives the writer's lifetime.; The serial writer assumes exclusive access to the underlying file during construction, destruction and `Fill()` as well as `CommitCluster()` and `FlushCluster()`.; For `FlushColumns()` and `FillNoFlush()`, the sequential writer assumes exclusive access only if buffered writing is turned off.; The parallel writer assumes exclusive access to the underlying file during all operations on the writer (e.g. construction and destruction) and all operations on any created fill context (e.g. `Fill()` and `FlushCluster()`).; Notable exceptions are `FlushColumns()` and `FillNoFlush()` which are guaranteed to never access the underlying `TFile` during parallel writing (which is always buffered). A `TFile` does not take ownership of any `RNTuple` objects. When reading data, RNTuple uses the `RMiniFile` and `RRawFile` classes to open a given storage path and find the `RNTuple` anchor.; When creating a `RNTupleReader` from an existing anchor object, RNTuple uses `RRawFile` only for files of dynamic type `TFile`, `TDavixFile`, and `TNetXNGFile`.; In either case, the `RRawFile` owns its own file descriptor and does not interfere with `TFile` objects concurrently reading the file.; For anchors from files of other dynamic type, including all other `TFile` subclasses, the file is wrapped in a `RRawFileTFile` and access is shared. On-Disk Encoding",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:18395,Security,access,access,18395,"y the application.; The caller has to ensure that the lifetime of the object lasts during the I/O operations. An RNTuple writer that is constructed without a `TFile` object (`RNTupleWriter::Recreate()`) assumes exclusive access to the underlying file.; An RNTuple writer that uses a `TFile` for writing (`RNTupleWriter::Append()`) assumes that the `TFile` object outlives the writer's lifetime.; The serial writer assumes exclusive access to the underlying file during construction, destruction and `Fill()` as well as `CommitCluster()` and `FlushCluster()`.; For `FlushColumns()` and `FillNoFlush()`, the sequential writer assumes exclusive access only if buffered writing is turned off.; The parallel writer assumes exclusive access to the underlying file during all operations on the writer (e.g. construction and destruction) and all operations on any created fill context (e.g. `Fill()` and `FlushCluster()`).; Notable exceptions are `FlushColumns()` and `FillNoFlush()` which are guaranteed to never access the underlying `TFile` during parallel writing (which is always buffered). A `TFile` does not take ownership of any `RNTuple` objects. When reading data, RNTuple uses the `RMiniFile` and `RRawFile` classes to open a given storage path and find the `RNTuple` anchor.; When creating a `RNTupleReader` from an existing anchor object, RNTuple uses `RRawFile` only for files of dynamic type `TFile`, `TDavixFile`, and `TNetXNGFile`.; In either case, the `RRawFile` owns its own file descriptor and does not interfere with `TFile` objects concurrently reading the file.; For anchors from files of other dynamic type, including all other `TFile` subclasses, the file is wrapped in a `RRawFileTFile` and access is shared. On-Disk Encoding; ----------------. ### Writing Case; The following steps are taken to write RNTuple data to disk:. 1. On creation of the RNTupleWriter, the header is written to disk; 2. Upon `RNTupleWriter::Fill()`, the RField<T> class _serializes_ the object into its colu",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:19098,Security,access,access,19098,"ly if buffered writing is turned off.; The parallel writer assumes exclusive access to the underlying file during all operations on the writer (e.g. construction and destruction) and all operations on any created fill context (e.g. `Fill()` and `FlushCluster()`).; Notable exceptions are `FlushColumns()` and `FillNoFlush()` which are guaranteed to never access the underlying `TFile` during parallel writing (which is always buffered). A `TFile` does not take ownership of any `RNTuple` objects. When reading data, RNTuple uses the `RMiniFile` and `RRawFile` classes to open a given storage path and find the `RNTuple` anchor.; When creating a `RNTupleReader` from an existing anchor object, RNTuple uses `RRawFile` only for files of dynamic type `TFile`, `TDavixFile`, and `TNetXNGFile`.; In either case, the `RRawFile` owns its own file descriptor and does not interfere with `TFile` objects concurrently reading the file.; For anchors from files of other dynamic type, including all other `TFile` subclasses, the file is wrapped in a `RRawFileTFile` and access is shared. On-Disk Encoding; ----------------. ### Writing Case; The following steps are taken to write RNTuple data to disk:. 1. On creation of the RNTupleWriter, the header is written to disk; 2. Upon `RNTupleWriter::Fill()`, the RField<T> class _serializes_ the object into its column representation.; To this end, it uses the `RColumn` class to append elements to the columns page buffer (`RPage`); 3. When a page buffer is full (cf. tuning.md), it is sent to the page sink for writing it to disk.; Note that page boundaries do _not_ need to align with entry boundaries,; e.g. information from a single entry can span multiple pages.; 1. The page is _packed_:; depending on the type of the page, a light encoding is applied to facilitate compression, e.g., byte splitting (`RColumnElement`).; Big-endian / little-endian conversion takes place here.; 2. The packed page is _compressed_ according to the user-provided compression set",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:24993,Security,access,access,24993,"ple anchor: the initial link to the location of the header and footer (cf. format specification); 3) A locator format: how are byte ranges addressed (e.g., through an offset in a file or an object ID). That means that new backends are likely to have implications on the RNTuple format specification. The page sources and sinks are ROOT internal classes.; They are not meant to be extended by users. Multi-Threading; ---------------. The following options exist in RNTuple for multithreaded data processing. ### Implicit Multi-Threading; When `ROOT::EnableImplicitMT()` is used, RNTuple uses ROOT's task arena to compress and decompress pages.; That requires writes to be buffered and reads uses the cluster pool resp.; The RNTuple data source for RDataFrame lets RDataFrame full control of the thread pool.; That means that RDataFrame uses a separate data source for every thread, each of the data sources runs in sequential mode. ### Concurrent Readers; Multiple readers can read the same RNTuple concurrently as long as access to every individual reader is sequential. ### Parallel REntry Preparation; Multiple `REntry` object can be concurrently prepared by multiple threads.; I.e., construction and binding of the objects can happen in parallel.; The actual reading and writing of entries (`RNTupleReader::LoadEntry()`, `RNTupleWriter::Fill()`) needs to be protected by a mutex.; This is considered ""mild scalability parallelization"" in RNTuple. ### RNTupleParallelWriter; The parallel writer offers the most scalable parallel writing interface.; Multiple _fill contexts_ can concurrently serialize and compress data.; Every fill context prepares a set of entire clusters in the final on-disk layout.; When a fill context flushes data,; a brief serialization point handles the RNTuple meta-data updates and the reservation of disk space to write into. Low precision float types; --------------------------; RNTuple supports encoding floating point types with a lower precision when writing them t",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:872,Testability,log,logical,872,"RNTuple Code Architecture; =========================. > This document is meant for ROOT developers. It provides background information on the RNTuple code design and behavior. > The RNTuple code uses the nomenclature from the [RNTuple format specification](https://github.com/root-project/root/blob/master/tree/ntuple/v7/doc/BinaryFormatSpecification.md) (e.g. ""field"", ""column"", ""anchor"", etc.). General Principles; ------------------. The RNTuple classes provide the functionality to read, write, and describe RNTuple datasets.; The core classes, such as `RNTupleReader` and `RNTupleWriter`, are part of the RNTuple library.; Additional tools, such as the `RNTupleImporter` and the `RNTupleInspector`, are part of the RNTupleUtils library,; which depends on the RNTuple library. The RNTuple classes are organized in layers:; the storage layer, the primitives layer, the logical layer and the event iteration layer.; Most classes in the storage layer and the primitives layer are in the `ROOT::Internal` namespace (non-public interfaces),; with the notable exception of the descriptor classes (`RNTupleDescriptor`, `RFieldDescriptor`, etc.).; Most classes in the upper layers provide public interfaces. | Layer | Description | Example of classes |; |------------|---------------------------------------------------------------------|-------------------------------------------------------------|; | Storage | Read and write pages (physical: file, object store; virtual: e.g. buffered) | RPage{Source,Sink}, RNTupleDescriptor, RClusterPool |; | Primitives | Storage-backed columns of simple types | RColumn, RColumnElement, RPage |; | Logical | Mapping of C++ types onto columns | RField, RNTupleModel, REntry |; | Iteration | Reading and writing events / properties | RNTuple{Reader,Writer}, RNTupleView, RNTupleDS (RDataFrame) |; | Tooling | Higher-level, RNTuple related utility classes | RNTupleMerger, RNTupleImporter, RNTupleInspector |. The RNTuple classes are, unless explicitly stated otherwi",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:28574,Testability,log,logging,28574,"which will truncate; a single precision float's mantissa to 12 bits). Here is an example on how a user may dynamically decide how to quantize a floating point field to get the most precision out of a fixed bit width:; ```c++; auto model = RNTupleModel::Create();; auto field = std::make_unique<RField<float>>(""f"");; // assuming we have an array of floats stored in `myFloats`:; auto [minV, maxV] = std::minmax_element(myFloats.begin(), myFloats.end());; constexpr auto nBits = 24;; field->SetQuantized(*minV, *maxV, nBits);; model->AddField(std::move(field));; auto f = model->GetDefaultEntry().GetPtr<float>(""f"");. // Now we can write our floats.; auto writer = RNTupleWriter::Recreate(std::move(model), ""myNtuple"", ""myFile.root"");; for (float val : myFloats) {; *f = val;; writer->Fill();; }; ```. Relationship to other ROOT components; -------------------------------------. The RNTuple classes have the following relationship to other parts of ROOT. The RNTuple classes use core ROOT infrastructure classes, such as error handling and logging.; When necessary, RNTuple uses a `TFile` for reading and writing.; The cases of writing to a local file and reading from a local file, a file from XRootD or from HTTP, do _not_ require `TFile`.; For these cases, RNTuple depends on the `RRawFile` class and its XRootD and Davix plugins. For user-defined classes as well as sets and maps, RNTuple uses `TClass`.; Simple types and other stdlib classes are natively supported and do not require dictionaries.; See the format specification for an exhaustive list of types supported in RNTuple.; The streamer field uses the standard ROOT streaming machinery. Integration to RDataFrame is provided through an RNTuple data source.; A universal RDataFrame constructor can create a data frame from either a TTree or an RNTuple with the same syntax. The RBrowser uses RNTuple classes to display RNTuple dataset information. Future Features; ---------------. The following features are planned for after the first R",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:1584,Usability,simpl,simple,1584,"art of the RNTupleUtils library,; which depends on the RNTuple library. The RNTuple classes are organized in layers:; the storage layer, the primitives layer, the logical layer and the event iteration layer.; Most classes in the storage layer and the primitives layer are in the `ROOT::Internal` namespace (non-public interfaces),; with the notable exception of the descriptor classes (`RNTupleDescriptor`, `RFieldDescriptor`, etc.).; Most classes in the upper layers provide public interfaces. | Layer | Description | Example of classes |; |------------|---------------------------------------------------------------------|-------------------------------------------------------------|; | Storage | Read and write pages (physical: file, object store; virtual: e.g. buffered) | RPage{Source,Sink}, RNTupleDescriptor, RClusterPool |; | Primitives | Storage-backed columns of simple types | RColumn, RColumnElement, RPage |; | Logical | Mapping of C++ types onto columns | RField, RNTupleModel, REntry |; | Iteration | Reading and writing events / properties | RNTuple{Reader,Writer}, RNTupleView, RNTupleDS (RDataFrame) |; | Tooling | Higher-level, RNTuple related utility classes | RNTupleMerger, RNTupleImporter, RNTupleInspector |. The RNTuple classes are, unless explicitly stated otherwise, conditionally thread safe. The read and write APIs provide templated, compile-time type-safe APIs,; APIs where the type at hand is passed as string and which are runtime type-safe,; and type-unsafe APIs using void pointers. On I/O errors and invalid input, RNTuple classes throw an `RException`. Walkthrough: Reading Data; -------------------------. ```c++; auto file = std::make_unique<TFile>(""data.root"");; auto ntuple = std::unique_ptr<RNTuple>(file->Get<RNTuple>(""ntpl""));. // Option 1: entire row; // The reader creates a page source; the page source creates a model from the on-disk information; auto reader = RNTupleReader::Open(ntuple);; // Populate the objects that are used in the model's defau",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md:13615,Usability,simpl,simple,13615," the RNTuple is immutable and cannot be amended.; An RNTuple that is currently being written cannot be read. ### RNTupleReader; The RNTupleReader is the primary interface to read and inspect an RNTuple.; An RNTupleReader owns a model: either a model created from the on-disk information or an imposed, user-provided model.; The user-provided model can be limited to a subset of fields.; Data is populated to an explicit `REntry` or the model's default entry through `RNTupleReader::LoadEntry()`. The reader can create `RNTupleView` objects for the independent reading of individual fields.; The reader can create `RBulk` objects for bulk reading of individual fields. Additionally, the reader provides access to a cached copy of the descriptor.; It can display individual entries (`RNTupleReader::Show()`) and summary information (`RNTupleReader::PrintInfo()`). ### RNTupleView<T>; RNTuple views provide read access to individual fields.; Views are created from an RNTupleReader.; Views are templated; for simple types (e.g., `float`, `int`), views provide read-only access directly to an RNTuple page in memory.; Complex types and void views require additional memory copies to populate an object in memory from the column data. A view can iterate over the entry range, over the field range, and over the range of a collection within an entry.; For instance, for a field `std::vector<float> pt`, a view can iterate over all `pt` values of all entries, or over the `pt` values of a particular entry. A view can safely outlive its originating reader.; Once the reader is deconstructed, any attempt to read data will throw an exception, but the view is still properly destructed. Views that originate from the same reader _cannot_ be used concurrently by different threads. Internal Classes; ----------------. ### RNTupleDS; The `RNTupleDS` class is an internal class that provides an RNTuple data source for RDataFrame.; It is part of the `ROOTDataFrame` library.; The RNTuple data source supports chai",MatchSource.DOCS,tree/ntuple/v7/doc/Architecture.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/Architecture.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md:26483,Availability,avail,available,26483,"oats. If the index of the first element is negative (sign bit set), the column is deferred _and_ suppressed.; In this case, no (synthetic) pages exist up to and including the cluster of the first element index.; See Section ""Page List Envelope"" for further information about suppressed columns. #### Alias columns. An alias column has the following format. ```; 0 1 2 3; 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; + Physical Column ID +; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | Field ID |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; ```; Alias columns do not have associated data pages.; Instead, their data comes from another column referred to below as ""physical column"".; The first 32-bit integer references the physical column ID.; The second 32-bit integer references the associated ""projected"" field.; A projected field is a field using alias columns to present available data by an alternative C++ type.; Alias columns have no prescribed column ID of their own, since alias columns are not referenced.; In the footer and page list envelopes, only physical column IDs must be referenced.; However, columns should be attached to projected fields in their serialization order (first header then footer). #### Extra type information. Certain field types may come with additional information required, e.g., for schema evolution.; The type information record frame has the following contents followed by a string containing the type name. ```; 0 1 2 3; 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; + Content Identifier +; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | Type Version From |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | Type Version To |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; ``",MatchSource.DOCS,tree/ntuple/v7/doc/BinaryFormatSpecification.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md:35895,Availability,avail,available,35895,"ator does _not_ include the checksum. Note that we do not need to store the uncompressed size of the page; because the uncompressed size is given by the number of elements in the page and the element size.; We do need, however, the per-column and per-cluster element offset in order to read a certain entry range; without inspecting the meta-data of all the previous clusters. The hierarchical structure of the frames in the page list envelope is as follows:. # this is `List frame of cluster group record frames` mentioned above; - Top-most cluster list frame (one item for each cluster in this RNTuple); |; |---- Cluster 1 column list frame (outer list frame, one item for each column in this RNTuple); | |---- Column 1 page list frame (inner list frame, one item for each page in this column); | | |---- Page 1 description (inner item); | | |---- Page 2 description (inner item); | | | ...; | |---- Column 1 element offset (Int64), negative if the column is suppressed; | |---- Column 1 compression settings (UInt32), available only if the column is not suppressed; | |---- Column 2 page list frame; | | ...; |; |---- Cluster 2 column list frame; | ... In order to save space, the page descriptions (inner items) are _not_ in a record frame.; If at a later point more information per page is needed,; the page list envelope can be extended by additional list and record frames. #### Suppressed Columns. If the element offset in the inner list frame is negative (sign bit set), the column is suppressed.; Writers should write the lowest int64_t value, readers should check for a negative value.; Suppressed columns always have an empty list of pages.; Suppressed columns omit the compression settings in the inner list frame. Suppressed columns belong to a secondary column representation (see Section ""Column Description""); that is inactive in the current cluster.; The number of columns; and the absolute values of the element offsets of primary and secondary representations are identical.; When",MatchSource.DOCS,tree/ntuple/v7/doc/BinaryFormatSpecification.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md:39389,Availability,avail,available,39389,"-----:|:---------:|:----------:|:-------:|:--------:|; | Bit | W* | | R | R | R | R | R | R | R | R | R | | |; | Byte | | W* | | | | | | | | | | | |; | Char | R | | W* | R | R | R | R | R | R | R | R | | |; | Int8 | R | | R | W* | R | R | R | R | R | R | R | | |; | UInt8 | R | | R | R | W* | R | R | R | R | R | R | | |; | (Split)Int16 | R | | R | R | R | W* | R | R | R | R | R | | |; | (Split)UInt16 | R | | R | R | R | R | W* | R | R | R | R | | |; | (Split)Int32 | R | | R | R | R | R | R | W* | R | R | R | | |; | (Split)UInt32 | R | | R | R | R | R | R | R | W* | R | R | | |; | (Split)Int64 | R | | R | R | R | R | R | R | R | W* | R | | |; | (Split)UInt64 | R | | R | R | R | R | R | R | R | R | W* | | |; | Real16 | | | | | | | | | | | | W | W |; | (Split)Real32 | | | | | | | | | | | | W* | W |; | (Split)Real64 | | | | | | | | | | | | R | W* |; | Real32Trunc | | | | | | | | | | | | W | W |; | Real32Quant | | | | | | | | | | | | W | W |. Possibly available `const` and `volatile` qualifiers of the C++ types are ignored for serialization.; The default column for serialization is denoted with an asterisk.; If the ntuple is stored uncompressed, the default changes from split encoding to non-split encoding where applicable. ### Low-precision Floating Points. The ROOT type `Double32_t` is stored on disk as a `double` field with a `SplitReal32` column representation.; The field's type alias is set to `Double32_t`. ### Stdlib Types and Collections. Generally, collections have a parent column of type (Split)Index32 or (Split)Index64.; The parent column stores the offsets of the next collection entries relative to the cluster.; For instance, a `std::vector<float>` with the values `{1.0}`, `{}`, `{1.0, 2.0}`; for the first 3 entries results in an index column `[1, 1, 3]`; and a value column `[1.0, 1.0, 2.0]`. #### std::string. A string is stored as a single field with two columns.; The first (principle) column is of type `(Split)Index[64|32]`.; The second column is of type `Char",MatchSource.DOCS,tree/ntuple/v7/doc/BinaryFormatSpecification.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md:47666,Availability,avail,available,47666,"sociated to a single column; of type `(Split)Index[32|64]`.; This field presents the offsets in the index column as lengths; that correspond to the cardinality of the pointed-to collection.; It is meant to be used as a projected field and only for reading the size of a collection. The value for the $i$-th element is computed; by subtracting the $(i-1)$-th value from the $i$-th value in the index column.; If $i == 0$, i.e. it falls on the start of a cluster, the $(i-1)$-th value in the index column is assumed to be 0,; e.g. given the index column values `[1, 1, 3]`, the values yielded by `RNTupleCardinality` shall be `[1, 0, 2]`. The `SizeT` template parameter defines the in-memory integer type of the collection size.; The valid types are `std::uint32_t` and `std::uint64_t`. ### ROOT streamed types. A field with the structural role 0x04 (""streamer"") represents an object serialized by the ROOT streamer; into a single `Byte` column.; It can have any type supported by `TClass` (even types that are not available in the native RNTuple type system).; The first (principal) column is of type `(Split)Index[32|64]`.; The second column is of type `Byte`. ### Untyped collections and records. Untyped collections and records are fields with a collection or record role and an empty type name.; Only top-level fields as well as direct subfields of untyped fields may be untyped.; Except for the empty type name, untyped collections have the same on-disk representation as `std::vector`; and untyped records have the same on-disk representation as a user-defined class. ## Limits. This section summarizes key design limits of RNTuple data sets.; The limits refer to a single RNTuple and do not consider combinations/joins such as ""friends"" and ""chains"". | Limit | Value | Reason / Comment |; |------------------------------------------------|------------------------------|--------------------------------------------------------|; | Maximum volume | 10 PB (theoretically more) | Assuming 10k clust",MatchSource.DOCS,tree/ntuple/v7/doc/BinaryFormatSpecification.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md:372,Deployability,release,release,372,"# RNTuple Binary Format Specification 0.2.12.0. **Note:** This is work in progress. The RNTuple specification is not yet finalized. ## Versioning Notes. The RNTuple binary format version is inspired by semantic versioning.; It uses the following scheme: EPOCH.MAJOR.MINOR.PATCH. _Epoch_: an increment of the epoch indicates backward-incompatible changes.; The RNTuple pre-release has epoch 0.; The first public release will get epoch 1.; There is currently no further epoch foreseen. _Major_: an increment of the major version indicates forward-incompatible changes.; A forward-incompatible change is known to break reading in previous software versions that do not support that feature.; The use of new, forward-incompatible features must be indicated in the feature flag in the header (see below).; For the RNTuple pre-release (epoch == 0), the major version is the release candidate number. _Minor_: an increment of the minor version indicates new, optional format features.; Such optional features, although unknown to previous software versions,; won't prevent those software versions from properly reading the file.; Old readers will safely ignore these features. _Patch_: an increment of the patch version indicates backported features from newer format versions.; The backported features may correspond to a major or a minor release. Except for the epoch, the versioning is for reporting only.; Readers should use the feature flag in the header to determine whether they support reading the file. ## Introduction. The RNTuple binary format describes the serialized, on-disk representation of an RNTuple data set.; The data on disk is organized in **pages** (typically tens to hundreds of kilobytes in size); and several **envelopes** that contain information about the data such as header and footer.; The RNTuple format specifies the binary layout of the pages and the envelopes. Pages and envelopes are meant to be embedded in a data container; such as a ROOT file or a set of objects in an ",MatchSource.DOCS,tree/ntuple/v7/doc/BinaryFormatSpecification.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md:411,Deployability,release,release,411,"# RNTuple Binary Format Specification 0.2.12.0. **Note:** This is work in progress. The RNTuple specification is not yet finalized. ## Versioning Notes. The RNTuple binary format version is inspired by semantic versioning.; It uses the following scheme: EPOCH.MAJOR.MINOR.PATCH. _Epoch_: an increment of the epoch indicates backward-incompatible changes.; The RNTuple pre-release has epoch 0.; The first public release will get epoch 1.; There is currently no further epoch foreseen. _Major_: an increment of the major version indicates forward-incompatible changes.; A forward-incompatible change is known to break reading in previous software versions that do not support that feature.; The use of new, forward-incompatible features must be indicated in the feature flag in the header (see below).; For the RNTuple pre-release (epoch == 0), the major version is the release candidate number. _Minor_: an increment of the minor version indicates new, optional format features.; Such optional features, although unknown to previous software versions,; won't prevent those software versions from properly reading the file.; Old readers will safely ignore these features. _Patch_: an increment of the patch version indicates backported features from newer format versions.; The backported features may correspond to a major or a minor release. Except for the epoch, the versioning is for reporting only.; Readers should use the feature flag in the header to determine whether they support reading the file. ## Introduction. The RNTuple binary format describes the serialized, on-disk representation of an RNTuple data set.; The data on disk is organized in **pages** (typically tens to hundreds of kilobytes in size); and several **envelopes** that contain information about the data such as header and footer.; The RNTuple format specifies the binary layout of the pages and the envelopes. Pages and envelopes are meant to be embedded in a data container; such as a ROOT file or a set of objects in an ",MatchSource.DOCS,tree/ntuple/v7/doc/BinaryFormatSpecification.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md:821,Deployability,release,release,821,"# RNTuple Binary Format Specification 0.2.12.0. **Note:** This is work in progress. The RNTuple specification is not yet finalized. ## Versioning Notes. The RNTuple binary format version is inspired by semantic versioning.; It uses the following scheme: EPOCH.MAJOR.MINOR.PATCH. _Epoch_: an increment of the epoch indicates backward-incompatible changes.; The RNTuple pre-release has epoch 0.; The first public release will get epoch 1.; There is currently no further epoch foreseen. _Major_: an increment of the major version indicates forward-incompatible changes.; A forward-incompatible change is known to break reading in previous software versions that do not support that feature.; The use of new, forward-incompatible features must be indicated in the feature flag in the header (see below).; For the RNTuple pre-release (epoch == 0), the major version is the release candidate number. _Minor_: an increment of the minor version indicates new, optional format features.; Such optional features, although unknown to previous software versions,; won't prevent those software versions from properly reading the file.; Old readers will safely ignore these features. _Patch_: an increment of the patch version indicates backported features from newer format versions.; The backported features may correspond to a major or a minor release. Except for the epoch, the versioning is for reporting only.; Readers should use the feature flag in the header to determine whether they support reading the file. ## Introduction. The RNTuple binary format describes the serialized, on-disk representation of an RNTuple data set.; The data on disk is organized in **pages** (typically tens to hundreds of kilobytes in size); and several **envelopes** that contain information about the data such as header and footer.; The RNTuple format specifies the binary layout of the pages and the envelopes. Pages and envelopes are meant to be embedded in a data container; such as a ROOT file or a set of objects in an ",MatchSource.DOCS,tree/ntuple/v7/doc/BinaryFormatSpecification.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md:868,Deployability,release,release,868,"# RNTuple Binary Format Specification 0.2.12.0. **Note:** This is work in progress. The RNTuple specification is not yet finalized. ## Versioning Notes. The RNTuple binary format version is inspired by semantic versioning.; It uses the following scheme: EPOCH.MAJOR.MINOR.PATCH. _Epoch_: an increment of the epoch indicates backward-incompatible changes.; The RNTuple pre-release has epoch 0.; The first public release will get epoch 1.; There is currently no further epoch foreseen. _Major_: an increment of the major version indicates forward-incompatible changes.; A forward-incompatible change is known to break reading in previous software versions that do not support that feature.; The use of new, forward-incompatible features must be indicated in the feature flag in the header (see below).; For the RNTuple pre-release (epoch == 0), the major version is the release candidate number. _Minor_: an increment of the minor version indicates new, optional format features.; Such optional features, although unknown to previous software versions,; won't prevent those software versions from properly reading the file.; Old readers will safely ignore these features. _Patch_: an increment of the patch version indicates backported features from newer format versions.; The backported features may correspond to a major or a minor release. Except for the epoch, the versioning is for reporting only.; Readers should use the feature flag in the header to determine whether they support reading the file. ## Introduction. The RNTuple binary format describes the serialized, on-disk representation of an RNTuple data set.; The data on disk is organized in **pages** (typically tens to hundreds of kilobytes in size); and several **envelopes** that contain information about the data such as header and footer.; The RNTuple format specifies the binary layout of the pages and the envelopes. Pages and envelopes are meant to be embedded in a data container; such as a ROOT file or a set of objects in an ",MatchSource.DOCS,tree/ntuple/v7/doc/BinaryFormatSpecification.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md:1199,Deployability,patch,patch,1199,"ng.; It uses the following scheme: EPOCH.MAJOR.MINOR.PATCH. _Epoch_: an increment of the epoch indicates backward-incompatible changes.; The RNTuple pre-release has epoch 0.; The first public release will get epoch 1.; There is currently no further epoch foreseen. _Major_: an increment of the major version indicates forward-incompatible changes.; A forward-incompatible change is known to break reading in previous software versions that do not support that feature.; The use of new, forward-incompatible features must be indicated in the feature flag in the header (see below).; For the RNTuple pre-release (epoch == 0), the major version is the release candidate number. _Minor_: an increment of the minor version indicates new, optional format features.; Such optional features, although unknown to previous software versions,; won't prevent those software versions from properly reading the file.; Old readers will safely ignore these features. _Patch_: an increment of the patch version indicates backported features from newer format versions.; The backported features may correspond to a major or a minor release. Except for the epoch, the versioning is for reporting only.; Readers should use the feature flag in the header to determine whether they support reading the file. ## Introduction. The RNTuple binary format describes the serialized, on-disk representation of an RNTuple data set.; The data on disk is organized in **pages** (typically tens to hundreds of kilobytes in size); and several **envelopes** that contain information about the data such as header and footer.; The RNTuple format specifies the binary layout of the pages and the envelopes. Pages and envelopes are meant to be embedded in a data container; such as a ROOT file or a set of objects in an object store.; Envelopes can reference other envelopes and pages by means of a **locator** or an **envelope link**;; for a file embedding, the locator consists of an offset and a size.; The RNTuple format does _not_ est",MatchSource.DOCS,tree/ntuple/v7/doc/BinaryFormatSpecification.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md:1333,Deployability,release,release,1333,"he epoch indicates backward-incompatible changes.; The RNTuple pre-release has epoch 0.; The first public release will get epoch 1.; There is currently no further epoch foreseen. _Major_: an increment of the major version indicates forward-incompatible changes.; A forward-incompatible change is known to break reading in previous software versions that do not support that feature.; The use of new, forward-incompatible features must be indicated in the feature flag in the header (see below).; For the RNTuple pre-release (epoch == 0), the major version is the release candidate number. _Minor_: an increment of the minor version indicates new, optional format features.; Such optional features, although unknown to previous software versions,; won't prevent those software versions from properly reading the file.; Old readers will safely ignore these features. _Patch_: an increment of the patch version indicates backported features from newer format versions.; The backported features may correspond to a major or a minor release. Except for the epoch, the versioning is for reporting only.; Readers should use the feature flag in the header to determine whether they support reading the file. ## Introduction. The RNTuple binary format describes the serialized, on-disk representation of an RNTuple data set.; The data on disk is organized in **pages** (typically tens to hundreds of kilobytes in size); and several **envelopes** that contain information about the data such as header and footer.; The RNTuple format specifies the binary layout of the pages and the envelopes. Pages and envelopes are meant to be embedded in a data container; such as a ROOT file or a set of objects in an object store.; Envelopes can reference other envelopes and pages by means of a **locator** or an **envelope link**;; for a file embedding, the locator consists of an offset and a size.; The RNTuple format does _not_ establish a specific order of pages and envelopes. Every embedding must define an **ancho",MatchSource.DOCS,tree/ntuple/v7/doc/BinaryFormatSpecification.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md:4975,Integrability,wrap,wrapped,4975,"-+-+-+-+-+-+-+-+-+-+; | |; + Max Key Size +; | |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+. ```. When serialized to disk, a 64 bit checksum is appended to the anchor, calculated as the XXH3 hash of; all the (serialized) fields of the anchor object. Note that, since the anchor is serialized as a ""classic"" TFile key, all integers in the anchor, as well; as the checksum, are encoded in **big-endian**, unlike the RNTuple payload which is encoded in little-endian. The anchor may evolve in future versions only by appending new fields to the existing schema, but; fields will not be removed, renamed or reordered. `Max Key Size` represents the maximum size of an RBlob (associated to one TFile key). Payloads bigger than; that size will be written as multiple RBlobs/TKeys, and the offsets of all but the first RBlob will be; written at the end of the first one. This allows bypassing the inherent TKey size limit of 1 GiB. ## Compression Block. RNTuple envelopes and pages are wrapped in compression blocks.; In order to deserialize a page or an envelope, its compressed and uncompressed size needs to be known. If the compressed size == uncompressed size, the data is stored unmodified in uncompressed form.; Otherwise, data is represented as a series of compressed chunks.; Each chunk is prepended with the following 9 bytes header. ```; Byte; 0 1 2 3 4 5 6 7 8 9; +------+------+------+------+------+------+------+------+------+...; | Algorithm | Compressed size | Uncompressed size | <COMPRESSED DATA>; +------+------+------+------+------+------+------+------+------+...; ```. _Algorithm_: Identifies the compression algorithm used to compress the data. This can take one of the following values. | Algorithm | Meaning |; |--------------------------|----------------------------------------------|; | 'Z' 'L' '\x08' | zlib |; | 'C' 'S' '\x08' | Old Jean-loup Gailly's deflation algorithm |; | 'X' 'Z' '\x00' | LZMA |; | 'L' '4' <VERSION_MAJOR> | LZ4; third byte encodes ma",MatchSource.DOCS,tree/ntuple/v7/doc/BinaryFormatSpecification.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md:22690,Integrability,depend,depending,22690,"|; | 0x0F | 32 | SplitIndex32 | Like Index32 but pages are stored in split + delta encoding |; | 0x10 | 64 | SplitReal64 | Like Real64 but in split encoding |; | 0x11 | 32 | SplitReal32 | Like Real32 but in split encoding |; | 0x12 | 16 | SplitReal16 | Like Real16 but in split encoding |; | 0x1A | 64 | SplitInt64 | Like Int64 but in split + zigzag encoding |; | 0x13 | 64 | SplitUInt64 | Like UInt64 but in split encoding |; | 0x1B | 64 | SplitInt32 | Like Int32 but in split + zigzag encoding |; | 0x14 | 32 | SplitUInt32 | Like UInt32 but in split encoding |; | 0x1C | 16 | SplitInt16 | Like Int16 but in split + zigzag encoding |; | 0x15 | 16 | SplitUInt16 | Like UInt16 but in split encoding |; | 0x1D |10-31 | Real32Trunc | IEEE-754 single precision float with truncated mantissa |; | 0x1E | 1-32 | Real32Quant | Real value contained in a specified range with an underlying quantized integer representation |. The ""split encoding"" columns apply a byte transformation encoding to all pages of that column; and in addition, depending on the column type, delta or zigzag encoding:. Split (only); : Rearranges the bytes of elements: All the first bytes first, then all the second bytes, etc. Delta + split; : The first element is stored unmodified, all other elements store the delta to the previous element.; Followed by split encoding. Zigzag + split; : Used on signed integers only; it maps $x$ to $2x$ if $x$ is positive and to $-(2x+1)$ if $x$ is negative.; Followed by split encoding. **Note**: these encodings always happen within each page, thus decoding should be done page-wise,; not cluster-wise. The `Real32Trunc` type column is a variable-sized floating point column; with lower precision than `Real32` and `SplitReal32`.; It is an IEEE-754 single precision float with some of the mantissa's least significant bits truncated. The `Real32Quant` type column is a variable-sized real column that is internally represented as an integer within; a specified range of values. For this column",MatchSource.DOCS,tree/ntuple/v7/doc/BinaryFormatSpecification.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md:44634,Integrability,depend,depends,44634," RNTuple I/O support.; The name of the child field is `_0`. #### std::map\<K, V\>, std::unordered_map\<K, V\>, std::multimap\<K, V\>, std::unordered_multimap\<K, V\>. An (unordered) (multi)map is stored using a collection parent field,; whose principal column is of type `(Split)Index[64|32]` and a child field of type `std::pair<K, V>` named `_0`. ### std::atomic\<T\>. Atomic types are stored as a leaf field with a single subfield named `_0`.; The parent field has no attached columns.; The subfield corresponds to the inner type `T`. ### User-defined enums. User-defined enums are stored as a leaf field with a single subfield named `_0`.; The parent field has no attached columns.; The subfield corresponds to the integer type the underlies the enum.; Unscoped and scoped enums are supported as long as the enum has a dictionary. ### User-defined classes. User-defined classes might behave either as a record or as a collection of elements of a given type.; The behavior depends on whether the class has an associated collection proxy. #### Regular class / struct. User defined C++ classes are supported with the following limitations; - The class must have a dictionary; - All persistent members and base classes must be themselves types with RNTuple I/O support; - Transient members must be marked, e.g. by a `//!` comment; - The class must not be in the `std` namespace; - The class must be empty or splittable (e.g., the class must not provide a custom streamer); - There is no support for polymorphism,; i.e. a field of class `A` cannot store class `B` that derives from `A`; - Virtual inheritance is unsupported. User classes are stored as a record parent field with no attached columns.; Direct base classes and persistent members are stored as subfields with their respective types.; The field name of member subfields is identical to the C++ field name.; The field name of base class subfields are numbered and preceded by a colon (`:`), i.e. `:_0`, `:_1`, ... #### Classes with an assoc",MatchSource.DOCS,tree/ntuple/v7/doc/BinaryFormatSpecification.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md:48825,Integrability,depend,depends,48825,"e same on-disk representation as a user-defined class. ## Limits. This section summarizes key design limits of RNTuple data sets.; The limits refer to a single RNTuple and do not consider combinations/joins such as ""friends"" and ""chains"". | Limit | Value | Reason / Comment |; |------------------------------------------------|------------------------------|--------------------------------------------------------|; | Maximum volume | 10 PB (theoretically more) | Assuming 10k cluster groups of 10k clusters of 100MB |; | Maximum number of elements, entries | 2^63 | Using default (Split)Index64, otherwise 2^32 |; | Maximum cluster & entry size | 8TB (depends on pagination) | Assuming limit of 4B pages of 4kB each |; | Maximum page size | 2B elements, 256MB - 24GB | #elements * element size |; | Maximum element size | 8kB | 16bit for number of bits per element |; | Maximum number of column types | 64k | 16bit for column type |; | Maximum envelope size | 2^48B (~280TB) | Envelope header encoding |; | Maximum frame size | 2^62B, 4B items (list frame) | Frame preamble encoding |; | Maximum field / type version | 4B | Field meta-data encoding |; | Maximum number of fields, columns | 4B (foreseen: <10M) | 32bit column / field IDs, list frame limit |; | Maximum number of cluster groups | 4B (foreseen: <10k) | List frame limits |; | Maximum number of clusters per group | 4B (foreseen: <10k) | List frame limits, cluster group summary encoding |; | Maximum number of pages per cluster per column | 4B | List frame limits |; | Maximum number of entries per cluster | 2^56 | Cluster summary encoding |; | Maximum string length (meta-data) | 4GB | String encoding |; | Maximum RBlob size | 128 PiB | 1GiB / 8B * 1GiB (with maxKeySize=1GiB, offsetSize=8B) |. ## Glossary. ### Anchor. The anchor is a data block that represents the entry point to an RNTuple.; The anchor is specific to the RNTuple container in which the RNTuple data are embedded (e.g., a ROOT file or an object store).; The ancho",MatchSource.DOCS,tree/ntuple/v7/doc/BinaryFormatSpecification.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md:50592,Integrability,depend,depends,50592,"me limits, cluster group summary encoding |; | Maximum number of pages per cluster per column | 4B | List frame limits |; | Maximum number of entries per cluster | 2^56 | Cluster summary encoding |; | Maximum string length (meta-data) | 4GB | String encoding |; | Maximum RBlob size | 128 PiB | 1GiB / 8B * 1GiB (with maxKeySize=1GiB, offsetSize=8B) |. ## Glossary. ### Anchor. The anchor is a data block that represents the entry point to an RNTuple.; The anchor is specific to the RNTuple container in which the RNTuple data are embedded (e.g., a ROOT file or an object store).; The anchor must provide the information to load the header and the footer **envelopes**. ### Cluster. A cluster is a set of **pages** that contain all the data belonging to an entry range.; The data set is partitioned in clusters.; A typical cluster size is tens to hundreds of megabytes. ### Column. A column is a storage backed vector of a number of **elements** of a simple type.; Column elements have a fixed bit-length that depends on the column type.; Some column types allow setting the bit lengths within specific limits (e.g. for floats with truncated mantissa). ### Envelope. An envelope is a data block with RNTuple meta-data, such as the header and the footer. ### Field. A field describes a serialized C++ type.; A field can have a hierarchy of subfields representing a composed C++ type (e.g., a vector of integers).; A field has zero, one, or multiple **columns** attached to it.; The columns contain the data related to the field but not to its subfields, which have their own columns. ### Frame. A frame is a byte range with metadata information in an **envelope**.; A frame starts with its size and thus can be extended in a forward-compatible way. ### Locator. A locator is a generalized way to identify a byte range in the RNTuple container.; For a file container, for instance, a locator consists of an offset and a size. ### Page. A page is segment of a column.; Columns are partitioned in pages.;",MatchSource.DOCS,tree/ntuple/v7/doc/BinaryFormatSpecification.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md:4477,Modifiability,evolve,evolve,4477,"s Header +; | |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | |; + Len Header +; | |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | |; + Seek Footer +; | |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | |; + Nbytes Footer +; | |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | |; + Len Footer +; | |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | |; + Max Key Size +; | |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+. ```. When serialized to disk, a 64 bit checksum is appended to the anchor, calculated as the XXH3 hash of; all the (serialized) fields of the anchor object. Note that, since the anchor is serialized as a ""classic"" TFile key, all integers in the anchor, as well; as the checksum, are encoded in **big-endian**, unlike the RNTuple payload which is encoded in little-endian. The anchor may evolve in future versions only by appending new fields to the existing schema, but; fields will not be removed, renamed or reordered. `Max Key Size` represents the maximum size of an RBlob (associated to one TFile key). Payloads bigger than; that size will be written as multiple RBlobs/TKeys, and the offsets of all but the first RBlob will be; written at the end of the first one. This allows bypassing the inherent TKey size limit of 1 GiB. ## Compression Block. RNTuple envelopes and pages are wrapped in compression blocks.; In order to deserialize a page or an envelope, its compressed and uncompressed size needs to be known. If the compressed size == uncompressed size, the data is stored unmodified in uncompressed form.; Otherwise, data is represented as a series of compressed chunks.; Each chunk is prepended with the following 9 bytes header. ```; Byte; 0 1 2 3 4 5 6 7 8 9; +------+------+------+------+------+------+------+------+------+...; | Algorithm | Compressed size | Uncompressed size | <COMPRESSED DATA>; +------+------+------+------+--",MatchSource.DOCS,tree/ntuple/v7/doc/BinaryFormatSpecification.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md:8992,Modifiability,extend,extended,8992,"ing format; ```; 0 1 2 3; 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | |; + Size +-+; |  |T|; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | Number of Items (for list frames) |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | FRAME PAYLOAD |; | ... |; ```. _Size_: The absolute value gives the (uncompressed) size in bytes of the frame and the payload. _T(ype)_: Can be either 0 for a **record frame** or 1 for a **list frame**.; The type should be interpreted as the sign bit of the size, i.e. negative sizes indicate list frames. _Number of items_: Only used for list frames to indicate the length of the list in the frame payload. File format readers should use the size provided in the frame to seek to the data that follows a frame; instead of summing up the sizes of the elements in the frame.; This approach ensures that frames can be extended in future file format versions; without breaking the deserialization of older readers. ## Locators and Envelope Links. A locator is a generalized way to specify a certain byte range on the storage medium.; For disk-based storage, the locator is just byte offset and byte size.; For other storage systems, the locator contains enough information to retrieve the referenced block,; e.g. in object stores, the locator can specify a certain object ID.; The locator has the following format. ```; 0 1 2 3; 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | Size |T|; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | |; + Offset +; | |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; ```. _Size_: If `T` is zero, the number of bytes to read, i.e. the compressed size of the referenced block.; Otherwise, the 16 least-significant bits, i.e. bits 0:15, specify the size of the locator itself (see below",MatchSource.DOCS,tree/ntuple/v7/doc/BinaryFormatSpecification.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md:23307,Modifiability,variab,variable-sized,23307,"16 but in split encoding |; | 0x1D |10-31 | Real32Trunc | IEEE-754 single precision float with truncated mantissa |; | 0x1E | 1-32 | Real32Quant | Real value contained in a specified range with an underlying quantized integer representation |. The ""split encoding"" columns apply a byte transformation encoding to all pages of that column; and in addition, depending on the column type, delta or zigzag encoding:. Split (only); : Rearranges the bytes of elements: All the first bytes first, then all the second bytes, etc. Delta + split; : The first element is stored unmodified, all other elements store the delta to the previous element.; Followed by split encoding. Zigzag + split; : Used on signed integers only; it maps $x$ to $2x$ if $x$ is positive and to $-(2x+1)$ if $x$ is negative.; Followed by split encoding. **Note**: these encodings always happen within each page, thus decoding should be done page-wise,; not cluster-wise. The `Real32Trunc` type column is a variable-sized floating point column; with lower precision than `Real32` and `SplitReal32`.; It is an IEEE-754 single precision float with some of the mantissa's least significant bits truncated. The `Real32Quant` type column is a variable-sized real column that is internally represented as an integer within; a specified range of values. For this column type, flag 0x10 (column with range) is always set (see paragraphs below). Future versions of the file format may introduce additional column types; without changing the minimum version of the header or introducing a feature flag.; Old readers need to ignore these columns and fields constructed from such columns.; Old readers can, however, figure out the number of elements stored in such unknown columns. The ""flags"" field can have one of the following bits set. | Bit | Meaning |; |----------|-------------------------------------------------------------------|; | 0x08 | Deferred column: index of first element in the column is not zero |; | 0x10 | Column with a range",MatchSource.DOCS,tree/ntuple/v7/doc/BinaryFormatSpecification.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md:23538,Modifiability,variab,variable-sized,23538," |. The ""split encoding"" columns apply a byte transformation encoding to all pages of that column; and in addition, depending on the column type, delta or zigzag encoding:. Split (only); : Rearranges the bytes of elements: All the first bytes first, then all the second bytes, etc. Delta + split; : The first element is stored unmodified, all other elements store the delta to the previous element.; Followed by split encoding. Zigzag + split; : Used on signed integers only; it maps $x$ to $2x$ if $x$ is positive and to $-(2x+1)$ if $x$ is negative.; Followed by split encoding. **Note**: these encodings always happen within each page, thus decoding should be done page-wise,; not cluster-wise. The `Real32Trunc` type column is a variable-sized floating point column; with lower precision than `Real32` and `SplitReal32`.; It is an IEEE-754 single precision float with some of the mantissa's least significant bits truncated. The `Real32Quant` type column is a variable-sized real column that is internally represented as an integer within; a specified range of values. For this column type, flag 0x10 (column with range) is always set (see paragraphs below). Future versions of the file format may introduce additional column types; without changing the minimum version of the header or introducing a feature flag.; Old readers need to ignore these columns and fields constructed from such columns.; Old readers can, however, figure out the number of elements stored in such unknown columns. The ""flags"" field can have one of the following bits set. | Bit | Meaning |; |----------|-------------------------------------------------------------------|; | 0x08 | Deferred column: index of first element in the column is not zero |; | 0x10 | Column with a range of possible values |. If flag 0x08 (deferred column) is set, the index of the first element in this column is not zero,; which happens if the column is added at a later point during write.; In this case, an additional 64bit integer contai",MatchSource.DOCS,tree/ntuple/v7/doc/BinaryFormatSpecification.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md:29770,Modifiability,extend,extend,29770,"t of flags. #### Schema Extension Record Frame. The schema extension record frame contains an additional schema description that is incremental; with respect to the schema contained in the header (see Section Header Envelope).; Specifically, it is a record frame with the following four fields; (identical to the last four fields in Header Envelope):. - List frame: list of field record frames; - List frame: list of column record frames; - List frame: list of alias column record frames; - List frame: list of extra type information. In general, a schema extension is optional, and thus this record frame might be empty.; The interpretation of the information contained therein should be identical; as if it was found directly at the end of the header.; This is necessary when fields have been added during writing. Note that the field IDs and physical column IDs given by the serialization order; should continue from the largest IDs found in the header. Note that is it possible to extend existing fields by additional column representations.; This means that columns of the extension header may point to fields of the regular header. #### Column Group Record Frame; The column group record frame is used to set IDs for certain subsets of column IDs.; Column groups are only used when there are sharded clusters.; Otherwise, the enclosing list frame in the footer envelope is empty and all clusters span all columns.; The purpose of column groups is to prevent repetition of column ID ranges in cluster summaries. The column group record frame consists of a list frame of 32bit integer items.; Every item denotes a column ID that is part of this particular column group.; The ID of the column group is given implicitly by the order of column groups. The frame hierarchy is as follows. - Column group outer list frame; |; |---- Column group 1 record frame; | |---- List frame of column IDs; | | |---- Column ID 1 [32bit integer]; | | |---- Column ID 2 [32bit integer]; | | | ...; |; |---- Column gro",MatchSource.DOCS,tree/ntuple/v7/doc/BinaryFormatSpecification.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md:36208,Modifiability,extend,extended,36208,"; without inspecting the meta-data of all the previous clusters. The hierarchical structure of the frames in the page list envelope is as follows:. # this is `List frame of cluster group record frames` mentioned above; - Top-most cluster list frame (one item for each cluster in this RNTuple); |; |---- Cluster 1 column list frame (outer list frame, one item for each column in this RNTuple); | |---- Column 1 page list frame (inner list frame, one item for each page in this column); | | |---- Page 1 description (inner item); | | |---- Page 2 description (inner item); | | | ...; | |---- Column 1 element offset (Int64), negative if the column is suppressed; | |---- Column 1 compression settings (UInt32), available only if the column is not suppressed; | |---- Column 2 page list frame; | | ...; |; |---- Cluster 2 column list frame; | ... In order to save space, the page descriptions (inner items) are _not_ in a record frame.; If at a later point more information per page is needed,; the page list envelope can be extended by additional list and record frames. #### Suppressed Columns. If the element offset in the inner list frame is negative (sign bit set), the column is suppressed.; Writers should write the lowest int64_t value, readers should check for a negative value.; Suppressed columns always have an empty list of pages.; Suppressed columns omit the compression settings in the inner list frame. Suppressed columns belong to a secondary column representation (see Section ""Column Description""); that is inactive in the current cluster.; The number of columns; and the absolute values of the element offsets of primary and secondary representations are identical.; When reading a field of a certain entry, this assertion allows for searching the corresponding; cluster and column element indexes using any of the column representations.; It also means that readers need to get the element index offset and the number of elements of suppressed columns; from the corresponding column",MatchSource.DOCS,tree/ntuple/v7/doc/BinaryFormatSpecification.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md:43014,Modifiability,polymorphi,polymorphism,43014,"ith RNTuple I/O support.; The child fields are named `_0` and `_1`. #### std::tuple<T1, T2, ..., Tn>. A tuple is stored using an empty parent field with $n$ subfields of type `T1`, `T2`, ..., `Tn`.; All types must have RNTuple I/O support.; The child fields are named `_0`, `_1`, ... #### std::bitset\<N\>. A bitset is stored as a repetitive leaf field with an attached `Bit` column.; The bitset size `N` is stored as repetition parameter in the field meta-data.; Within the repetition blocks, bits are stored in little-endian order, i.e. the least significant bits come first. #### std::unique_ptr\<T\>, std::optional\<T\>. A unique pointer and an optional type have the same on disk representation.; They are represented as a collection of `T`s of zero or one elements.; The collection parent field has a principal column of type `(Split)Index[64|32]`.; It has a single subfield named `_0` for `T`, where `T` must have RNTuple I/O support.; Note that RNTuple does not support polymorphism, so the type `T` is expected to be `T` and not a child class of `T`. #### std::set\<T\>, std::unordered_set\<T\>, std::multiset\<T\>, std::unordered_multiset\<T\>. While STL (unordered) (multi)sets by definition are associative containers; (i.e., elements are referenced by their keys, which in the case for sets are equal to the values),; on disk they are represented as sequential collections.; This means that they have the same on-disk representation as `std::vector<T>`, using two fields:; - Collection parent field whose principal column is of type `(Split)Index[64|32]`.; - Child field of type `T`, which must be a type with RNTuple I/O support.; The name of the child field is `_0`. #### std::map\<K, V\>, std::unordered_map\<K, V\>, std::multimap\<K, V\>, std::unordered_multimap\<K, V\>. An (unordered) (multi)map is stored using a collection parent field,; whose principal column is of type `(Split)Index[64|32]` and a child field of type `std::pair<K, V>` named `_0`. ### std::atomic\<T\>. Atomic ",MatchSource.DOCS,tree/ntuple/v7/doc/BinaryFormatSpecification.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md:45157,Modifiability,polymorphi,polymorphism,45157," attached columns.; The subfield corresponds to the inner type `T`. ### User-defined enums. User-defined enums are stored as a leaf field with a single subfield named `_0`.; The parent field has no attached columns.; The subfield corresponds to the integer type the underlies the enum.; Unscoped and scoped enums are supported as long as the enum has a dictionary. ### User-defined classes. User-defined classes might behave either as a record or as a collection of elements of a given type.; The behavior depends on whether the class has an associated collection proxy. #### Regular class / struct. User defined C++ classes are supported with the following limitations; - The class must have a dictionary; - All persistent members and base classes must be themselves types with RNTuple I/O support; - Transient members must be marked, e.g. by a `//!` comment; - The class must not be in the `std` namespace; - The class must be empty or splittable (e.g., the class must not provide a custom streamer); - There is no support for polymorphism,; i.e. a field of class `A` cannot store class `B` that derives from `A`; - Virtual inheritance is unsupported. User classes are stored as a record parent field with no attached columns.; Direct base classes and persistent members are stored as subfields with their respective types.; The field name of member subfields is identical to the C++ field name.; The field name of base class subfields are numbered and preceded by a colon (`:`), i.e. `:_0`, `:_1`, ... #### Classes with an associated collection proxy. User classes that specify a collection proxy behave as collections of a given value type. The on-disk representation of non-associative collections is identical to a `std::vector<T>`, using two fields:; - Collection parent field whose principal column is of type `(Split)Index[64|32]`.; - Child field of type `T`, which must be a type with RNTuple I/O support. The on-disk representation of associative collections is identical to a `std::map<K,",MatchSource.DOCS,tree/ntuple/v7/doc/BinaryFormatSpecification.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md:45254,Modifiability,inherit,inheritance,45254,"ined enums are stored as a leaf field with a single subfield named `_0`.; The parent field has no attached columns.; The subfield corresponds to the integer type the underlies the enum.; Unscoped and scoped enums are supported as long as the enum has a dictionary. ### User-defined classes. User-defined classes might behave either as a record or as a collection of elements of a given type.; The behavior depends on whether the class has an associated collection proxy. #### Regular class / struct. User defined C++ classes are supported with the following limitations; - The class must have a dictionary; - All persistent members and base classes must be themselves types with RNTuple I/O support; - Transient members must be marked, e.g. by a `//!` comment; - The class must not be in the `std` namespace; - The class must be empty or splittable (e.g., the class must not provide a custom streamer); - There is no support for polymorphism,; i.e. a field of class `A` cannot store class `B` that derives from `A`; - Virtual inheritance is unsupported. User classes are stored as a record parent field with no attached columns.; Direct base classes and persistent members are stored as subfields with their respective types.; The field name of member subfields is identical to the C++ field name.; The field name of base class subfields are numbered and preceded by a colon (`:`), i.e. `:_0`, `:_1`, ... #### Classes with an associated collection proxy. User classes that specify a collection proxy behave as collections of a given value type. The on-disk representation of non-associative collections is identical to a `std::vector<T>`, using two fields:; - Collection parent field whose principal column is of type `(Split)Index[64|32]`.; - Child field of type `T`, which must be a type with RNTuple I/O support. The on-disk representation of associative collections is identical to a `std::map<K, V>`, using two fields:; - Collection parent field whose principal column is of type `(Split)Index[64",MatchSource.DOCS,tree/ntuple/v7/doc/BinaryFormatSpecification.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md:51292,Modifiability,extend,extended,51292,"**pages** that contain all the data belonging to an entry range.; The data set is partitioned in clusters.; A typical cluster size is tens to hundreds of megabytes. ### Column. A column is a storage backed vector of a number of **elements** of a simple type.; Column elements have a fixed bit-length that depends on the column type.; Some column types allow setting the bit lengths within specific limits (e.g. for floats with truncated mantissa). ### Envelope. An envelope is a data block with RNTuple meta-data, such as the header and the footer. ### Field. A field describes a serialized C++ type.; A field can have a hierarchy of subfields representing a composed C++ type (e.g., a vector of integers).; A field has zero, one, or multiple **columns** attached to it.; The columns contain the data related to the field but not to its subfields, which have their own columns. ### Frame. A frame is a byte range with metadata information in an **envelope**.; A frame starts with its size and thus can be extended in a forward-compatible way. ### Locator. A locator is a generalized way to identify a byte range in the RNTuple container.; For a file container, for instance, a locator consists of an offset and a size. ### Page. A page is segment of a column.; Columns are partitioned in pages.; A page is a unit of compression.; Typical page sizes are of the order of tens to hundreds of kilobytes. ### Indications of size. In this document, the `length` of something (e.g., a page) refers to its size in bytes in memory, uncompressed.; The `size` of something refers to the size in bytes on disk, possibly compressed. ## Notes on Backward and Forward Compatibility. Note that this section covers the backward and forward compatibility of the binary format itself.; It does not discuss schema evolution of the written types. Readers supporting a certain version of the specification should support reading files; that were written according to previous versions of the same epoch. Readers should sup",MatchSource.DOCS,tree/ntuple/v7/doc/BinaryFormatSpecification.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md:50206,Performance,load,load,50206,", 4B items (list frame) | Frame preamble encoding |; | Maximum field / type version | 4B | Field meta-data encoding |; | Maximum number of fields, columns | 4B (foreseen: <10M) | 32bit column / field IDs, list frame limit |; | Maximum number of cluster groups | 4B (foreseen: <10k) | List frame limits |; | Maximum number of clusters per group | 4B (foreseen: <10k) | List frame limits, cluster group summary encoding |; | Maximum number of pages per cluster per column | 4B | List frame limits |; | Maximum number of entries per cluster | 2^56 | Cluster summary encoding |; | Maximum string length (meta-data) | 4GB | String encoding |; | Maximum RBlob size | 128 PiB | 1GiB / 8B * 1GiB (with maxKeySize=1GiB, offsetSize=8B) |. ## Glossary. ### Anchor. The anchor is a data block that represents the entry point to an RNTuple.; The anchor is specific to the RNTuple container in which the RNTuple data are embedded (e.g., a ROOT file or an object store).; The anchor must provide the information to load the header and the footer **envelopes**. ### Cluster. A cluster is a set of **pages** that contain all the data belonging to an entry range.; The data set is partitioned in clusters.; A typical cluster size is tens to hundreds of megabytes. ### Column. A column is a storage backed vector of a number of **elements** of a simple type.; Column elements have a fixed bit-length that depends on the column type.; Some column types allow setting the bit lengths within specific limits (e.g. for floats with truncated mantissa). ### Envelope. An envelope is a data block with RNTuple meta-data, such as the header and the footer. ### Field. A field describes a serialized C++ type.; A field can have a hierarchy of subfields representing a composed C++ type (e.g., a vector of integers).; A field has zero, one, or multiple **columns** attached to it.; The columns contain the data related to the field but not to its subfields, which have their own columns. ### Frame. A frame is a byte range with m",MatchSource.DOCS,tree/ntuple/v7/doc/BinaryFormatSpecification.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md:1140,Safety,safe,safely,1140," Notes. The RNTuple binary format version is inspired by semantic versioning.; It uses the following scheme: EPOCH.MAJOR.MINOR.PATCH. _Epoch_: an increment of the epoch indicates backward-incompatible changes.; The RNTuple pre-release has epoch 0.; The first public release will get epoch 1.; There is currently no further epoch foreseen. _Major_: an increment of the major version indicates forward-incompatible changes.; A forward-incompatible change is known to break reading in previous software versions that do not support that feature.; The use of new, forward-incompatible features must be indicated in the feature flag in the header (see below).; For the RNTuple pre-release (epoch == 0), the major version is the release candidate number. _Minor_: an increment of the minor version indicates new, optional format features.; Such optional features, although unknown to previous software versions,; won't prevent those software versions from properly reading the file.; Old readers will safely ignore these features. _Patch_: an increment of the patch version indicates backported features from newer format versions.; The backported features may correspond to a major or a minor release. Except for the epoch, the versioning is for reporting only.; Readers should use the feature flag in the header to determine whether they support reading the file. ## Introduction. The RNTuple binary format describes the serialized, on-disk representation of an RNTuple data set.; The data on disk is organized in **pages** (typically tens to hundreds of kilobytes in size); and several **envelopes** that contain information about the data such as header and footer.; The RNTuple format specifies the binary layout of the pages and the envelopes. Pages and envelopes are meant to be embedded in a data container; such as a ROOT file or a set of objects in an object store.; Envelopes can reference other envelopes and pages by means of a **locator** or an **envelope link**;; for a file embedding, the l",MatchSource.DOCS,tree/ntuple/v7/doc/BinaryFormatSpecification.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md:7775,Safety,abort,abort,7775," and have lengths up to 64bit. _String_: A string is stored as a 32bit unsigned integer indicating the length of the string; followed by the characters.; Strings are ASCII encoded; every character is a signed 8bit integer. _Compression settings_: A 32bit integer containing both a compression algorithm and the compression level.; The compression settings are encoded according to this formula: $settings = algorithm * 100 + level$.; The level is between 1 and 9 and is extrapolated to the spectrum of levels of the corresponding algorithm. ### Feature Flags. Feature flags are 64bit integers where every bit represents a certain forward-incompatible feature that is used; in the binary format of the RNTuple at hand (see Versioning Notes).; The most significant bit is used to indicate that one or more flags is active with a bit higher than 63.; That means that readers need to continue reading feature flags as long as their signed integer value is negative. Readers should gracefully abort reading when they encounter unknown bits set. At the moment, there are no feature flag bits defined. ## Frames. RNTuple envelopes can store records and lists of basic types and other records by means of **frames**. A frame has the following format; ```; 0 1 2 3; 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | |; + Size +-+; |  |T|; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | Number of Items (for list frames) |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | FRAME PAYLOAD |; | ... |; ```. _Size_: The absolute value gives the (uncompressed) size in bytes of the frame and the payload. _T(ype)_: Can be either 0 for a **record frame** or 1 for a **list frame**.; The type should be interpreted as the sign bit of the size, i.e. negative sizes indicate list frames. _Number of items_: Only used for list frames to indicate the length of the list in the frame payload. Fil",MatchSource.DOCS,tree/ntuple/v7/doc/BinaryFormatSpecification.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md:33040,Safety,abort,abort,33040,"ure. - Header checksum (XxHash-3 64bit); - List frame of cluster summary record frames; - Nested list frame of page locations. #### Cluster Summary Record Frame; The cluster summary record frame contains the entry range of a cluster:. ```; 0 1 2 3; 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | |; + First Entry Number +; | |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | Number of Entries |; + +-+-+-+-+-+-+-+-+; | | Flags |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; ```. The order of the cluster summaries defines the cluster IDs,; starting from the first cluster ID of the cluster group that corresponds to the page list. Flag 0x01 is reserved for a future specification version that will support sharded clusters.; The future use of sharded clusters will break forward compatibility and thus introduce a corresponding feature flag.; For now, readers should abort when this flag is set.; Other flags should be ignored. #### Page Locations. The page locations are stored in a nested list frame as follows.; A top-most list frame where every item corresponds to a cluster.; The order of items corresponds to the cluster IDs as defined by the cluster groups and cluster summaries. Every item of the top-most list frame consists of an outer list frame where every item corresponds to a column.; Every item of the outer list frame is an inner list frame; whose items correspond to the pages of the column in the cluster.; The inner list is followed by a 64bit signed integer element offset and,; unless the column is suppressed, the 32bit compression settings; See next Section on ""Suppressed Columns"" for additional details.; Note that the size of the inner list frame includes the element offset and compression settings.; The order of the outer items must match the order of columns in the header and the extension header (small to large). The order of the inne",MatchSource.DOCS,tree/ntuple/v7/doc/BinaryFormatSpecification.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md:4129,Security,checksum,checksum,4129,"+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | Version Epoch | Version Major |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | Version Minor | Version Patch |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | |; + Seek Header +; | |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | |; + Nbytes Header +; | |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | |; + Len Header +; | |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | |; + Seek Footer +; | |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | |; + Nbytes Footer +; | |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | |; + Len Footer +; | |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | |; + Max Key Size +; | |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+. ```. When serialized to disk, a 64 bit checksum is appended to the anchor, calculated as the XXH3 hash of; all the (serialized) fields of the anchor object. Note that, since the anchor is serialized as a ""classic"" TFile key, all integers in the anchor, as well; as the checksum, are encoded in **big-endian**, unlike the RNTuple payload which is encoded in little-endian. The anchor may evolve in future versions only by appending new fields to the existing schema, but; fields will not be removed, renamed or reordered. `Max Key Size` represents the maximum size of an RBlob (associated to one TFile key). Payloads bigger than; that size will be written as multiple RBlobs/TKeys, and the offsets of all but the first RBlob will be; written at the end of the first one. This allows bypassing the inherent TKey size limit of 1 GiB. ## Compression Block. RNTuple envelopes and pages are wrapped in compression blocks.; In order to deserialize a page or an envelope, its compressed and uncompressed size needs to be known. If the compressed size == uncompressed size, the data is sto",MatchSource.DOCS,tree/ntuple/v7/doc/BinaryFormatSpecification.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md:4188,Security,hash,hash,4188,"+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | Version Epoch | Version Major |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | Version Minor | Version Patch |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | |; + Seek Header +; | |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | |; + Nbytes Header +; | |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | |; + Len Header +; | |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | |; + Seek Footer +; | |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | |; + Nbytes Footer +; | |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | |; + Len Footer +; | |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | |; + Max Key Size +; | |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+. ```. When serialized to disk, a 64 bit checksum is appended to the anchor, calculated as the XXH3 hash of; all the (serialized) fields of the anchor object. Note that, since the anchor is serialized as a ""classic"" TFile key, all integers in the anchor, as well; as the checksum, are encoded in **big-endian**, unlike the RNTuple payload which is encoded in little-endian. The anchor may evolve in future versions only by appending new fields to the existing schema, but; fields will not be removed, renamed or reordered. `Max Key Size` represents the maximum size of an RBlob (associated to one TFile key). Payloads bigger than; that size will be written as multiple RBlobs/TKeys, and the offsets of all but the first RBlob will be; written at the end of the first one. This allows bypassing the inherent TKey size limit of 1 GiB. ## Compression Block. RNTuple envelopes and pages are wrapped in compression blocks.; In order to deserialize a page or an envelope, its compressed and uncompressed size needs to be known. If the compressed size == uncompressed size, the data is sto",MatchSource.DOCS,tree/ntuple/v7/doc/BinaryFormatSpecification.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md:4359,Security,checksum,checksum,4359,"Patch |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | |; + Seek Header +; | |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | |; + Nbytes Header +; | |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | |; + Len Header +; | |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | |; + Seek Footer +; | |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | |; + Nbytes Footer +; | |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | |; + Len Footer +; | |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | |; + Max Key Size +; | |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+. ```. When serialized to disk, a 64 bit checksum is appended to the anchor, calculated as the XXH3 hash of; all the (serialized) fields of the anchor object. Note that, since the anchor is serialized as a ""classic"" TFile key, all integers in the anchor, as well; as the checksum, are encoded in **big-endian**, unlike the RNTuple payload which is encoded in little-endian. The anchor may evolve in future versions only by appending new fields to the existing schema, but; fields will not be removed, renamed or reordered. `Max Key Size` represents the maximum size of an RBlob (associated to one TFile key). Payloads bigger than; that size will be written as multiple RBlobs/TKeys, and the offsets of all but the first RBlob will be; written at the end of the first one. This allows bypassing the inherent TKey size limit of 1 GiB. ## Compression Block. RNTuple envelopes and pages are wrapped in compression blocks.; In order to deserialize a page or an envelope, its compressed and uncompressed size needs to be known. If the compressed size == uncompressed size, the data is stored unmodified in uncompressed form.; Otherwise, data is represented as a series of compressed chunks.; Each chunk is prepended with the following 9 bytes header. ```; Byte; 0 1 2 3 4 ",MatchSource.DOCS,tree/ntuple/v7/doc/BinaryFormatSpecification.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md:15904,Security,checksum,checksum,15904,"ield ID +; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | Structural Role | Flags |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; ```. The field version and type version are used for schema evolution. The structural role of the field can have one of the following values:. | Value | Structural role |; |----------|--------------------------------------------------------------------------|; | 0x00 | Leaf field in the schema tree |; | 0x01 | The field is the parent of a collection (e.g., a vector) |; | 0x02 | The field is the parent of a record (e.g., a struct) |; | 0x03 | The field is the parent of a variant |; | 0x04 | The field stores objects serialized with the ROOT streamer |. The ""flags"" field can have any of the following bits set:. | Bit | Meaning |; |----------|----------------------------------------------------------------------------|; | 0x01 | Repetitive field, i.e. for every entry $n$ copies of the field are stored |; | 0x02 | Projected field |; | 0x04 | Has ROOT type checksum as reported by TClass |. If `flag==0x01` (_repetitive field_) is set, the field represents a fixed-size array.; For fixed-size arrays, another (sub) field with `Parent Field ID` equal to the ID of this field; is expected to be found, representing the array content.; The field backing `std::bitmap<N>` is a single repetitive field.; (See Section ""Mapping of C++ Types to Fields and Columns""). If `flag==0x02` (_projected field_) is set,; the field has been created as a virtual field from another, non-projected source field.; If a projected field has attached columns,; these columns are alias columns to physical columns attached to the source field.; The following restrictions apply on field projections:; - The source field and the target field must have the same structural role,; except for an `RNTupleCardinality` field, which must have a collection field as a source.; - For streamer fields and leaf fields, the type name of the source field and ",MatchSource.DOCS,tree/ntuple/v7/doc/BinaryFormatSpecification.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md:17315,Security,checksum,checksum,17315,"Columns""). If `flag==0x02` (_projected field_) is set,; the field has been created as a virtual field from another, non-projected source field.; If a projected field has attached columns,; these columns are alias columns to physical columns attached to the source field.; The following restrictions apply on field projections:; - The source field and the target field must have the same structural role,; except for an `RNTupleCardinality` field, which must have a collection field as a source.; - For streamer fields and leaf fields, the type name of the source field and the projected field must be identical.; - Projections involving variants or fixed-size arrays are unsupported.; - Projected fields must be on the same schema path of collection fields as the source field.; For instance, one can project a vector of structs with floats to individual vectors of floats but cannot; project a vector of a vector of floats to a vector of floats. If `flag==0x04` (_type checksum_) is set, the field metadata contain the checksum of the ROOT streamer info.; This checksum is only used for I/O rules in order to find types that are identified by checksum. Depending on the flags, the following optional values follow:. ```; 0 1 2 3; 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | |; + Array Size (if flag 0x01 is set) +; | |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; + Source Field ID (if flag 0x02 is set) +; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; + ROOT Type Checksum (if flag 0x04 is set) +; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; ```. The block of integers is followed by a list of strings:. - String: field name; - String: type name; - String: type alias; - String: field description. The order of fields matters: every field gets an implicit field ID; which is equal the zero-based index of the field in the serialized list;; su",MatchSource.DOCS,tree/ntuple/v7/doc/BinaryFormatSpecification.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md:17357,Security,checksum,checksum,17357,"om another, non-projected source field.; If a projected field has attached columns,; these columns are alias columns to physical columns attached to the source field.; The following restrictions apply on field projections:; - The source field and the target field must have the same structural role,; except for an `RNTupleCardinality` field, which must have a collection field as a source.; - For streamer fields and leaf fields, the type name of the source field and the projected field must be identical.; - Projections involving variants or fixed-size arrays are unsupported.; - Projected fields must be on the same schema path of collection fields as the source field.; For instance, one can project a vector of structs with floats to individual vectors of floats but cannot; project a vector of a vector of floats to a vector of floats. If `flag==0x04` (_type checksum_) is set, the field metadata contain the checksum of the ROOT streamer info.; This checksum is only used for I/O rules in order to find types that are identified by checksum. Depending on the flags, the following optional values follow:. ```; 0 1 2 3; 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | |; + Array Size (if flag 0x01 is set) +; | |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; + Source Field ID (if flag 0x02 is set) +; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; + ROOT Type Checksum (if flag 0x04 is set) +; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; ```. The block of integers is followed by a list of strings:. - String: field name; - String: type name; - String: type alias; - String: field description. The order of fields matters: every field gets an implicit field ID; which is equal the zero-based index of the field in the serialized list;; subfields are ordered from smaller IDs to larger IDs.; Top-level fields have their own field ID set as pa",MatchSource.DOCS,tree/ntuple/v7/doc/BinaryFormatSpecification.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md:17439,Security,checksum,checksum,17439,"om another, non-projected source field.; If a projected field has attached columns,; these columns are alias columns to physical columns attached to the source field.; The following restrictions apply on field projections:; - The source field and the target field must have the same structural role,; except for an `RNTupleCardinality` field, which must have a collection field as a source.; - For streamer fields and leaf fields, the type name of the source field and the projected field must be identical.; - Projections involving variants or fixed-size arrays are unsupported.; - Projected fields must be on the same schema path of collection fields as the source field.; For instance, one can project a vector of structs with floats to individual vectors of floats but cannot; project a vector of a vector of floats to a vector of floats. If `flag==0x04` (_type checksum_) is set, the field metadata contain the checksum of the ROOT streamer info.; This checksum is only used for I/O rules in order to find types that are identified by checksum. Depending on the flags, the following optional values follow:. ```; 0 1 2 3; 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | |; + Array Size (if flag 0x01 is set) +; | |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; + Source Field ID (if flag 0x02 is set) +; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; + ROOT Type Checksum (if flag 0x04 is set) +; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; ```. The block of integers is followed by a list of strings:. - String: field name; - String: type name; - String: type alias; - String: field description. The order of fields matters: every field gets an implicit field ID; which is equal the zero-based index of the field in the serialized list;; subfields are ordered from smaller IDs to larger IDs.; Top-level fields have their own field ID set as pa",MatchSource.DOCS,tree/ntuple/v7/doc/BinaryFormatSpecification.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md:28331,Security,checksum,checksum,28331,"ersion To |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; ```. The combination of type version from/to, type name, and content identifier should be unique in the list.; However, not every type needs to provide additional type information. The following kinds of content are supported:. | Content identifier | Meaning of content |; |---------------------|-----------------------------------------------------|; | 0x00 | Serialized ROOT streamer info; see notes |. The serialized ROOT streamer info is not bound to a specific type.; It is the combined streamer information from all fields serialized by the ROOT streamer.; Writers set version from/to to zero and use an empty type name.; Readers should ignore the type-specific information.; The format of the content is a ROOT streamed `TList` of `TStreamerInfo` objects. ### Footer Envelope. The footer envelope has the following structure:. - Feature flags; - Header checksum (XxHash-3 64bit); - Schema extension record frame; - List frame of column group record frames; - List frame of cluster group record frames. The header checksum can be used to cross-check that header and footer belong together.; The meaning of the feature flags is the same as for the header.; The header flags do not need to be repeated.; Readers should combine (logical `or` of the bits) the feature flags from header and footer for the full set of flags. #### Schema Extension Record Frame. The schema extension record frame contains an additional schema description that is incremental; with respect to the schema contained in the header (see Section Header Envelope).; Specifically, it is a record frame with the following four fields; (identical to the last four fields in Header Envelope):. - List frame: list of field record frames; - List frame: list of column record frames; - List frame: list of alias column record frames; - List frame: list of extra type information. In general, a schema extension is optional, and thus this record frame m",MatchSource.DOCS,tree/ntuple/v7/doc/BinaryFormatSpecification.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md:28491,Security,checksum,checksum,28491,"name, and content identifier should be unique in the list.; However, not every type needs to provide additional type information. The following kinds of content are supported:. | Content identifier | Meaning of content |; |---------------------|-----------------------------------------------------|; | 0x00 | Serialized ROOT streamer info; see notes |. The serialized ROOT streamer info is not bound to a specific type.; It is the combined streamer information from all fields serialized by the ROOT streamer.; Writers set version from/to to zero and use an empty type name.; Readers should ignore the type-specific information.; The format of the content is a ROOT streamed `TList` of `TStreamerInfo` objects. ### Footer Envelope. The footer envelope has the following structure:. - Feature flags; - Header checksum (XxHash-3 64bit); - Schema extension record frame; - List frame of column group record frames; - List frame of cluster group record frames. The header checksum can be used to cross-check that header and footer belong together.; The meaning of the feature flags is the same as for the header.; The header flags do not need to be repeated.; Readers should combine (logical `or` of the bits) the feature flags from header and footer for the full set of flags. #### Schema Extension Record Frame. The schema extension record frame contains an additional schema description that is incremental; with respect to the schema contained in the header (see Section Header Envelope).; Specifically, it is a record frame with the following four fields; (identical to the last four fields in Header Envelope):. - List frame: list of field record frames; - List frame: list of column record frames; - List frame: list of alias column record frames; - List frame: list of extra type information. In general, a schema extension is optional, and thus this record frame might be empty.; The interpretation of the information contained therein should be identical; as if it was found directly at the end",MatchSource.DOCS,tree/ntuple/v7/doc/BinaryFormatSpecification.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md:31760,Security,access,access,31760,"[32bit integer]; | | | ...; |; |---- Column group 2 record frame; | ... #### Cluster Group Record Frame. The cluster group record frame references the page list envelopes for groups of clusters.; A cluster group record frame has the following contents followed by a page list envelope link. ```; 0 1 2 3; 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | |; + Minimum Entry Number +; | |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | |; + Entry Span +; | |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | Number of clusters |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; ```. To compute the minimum entry number, take first entry number from all clusters in the cluster group,; and take the minimum among these numbers.; The entry span is the number of entries that are covered by this cluster group.; The entry range allows for finding the right page list for random access requests to entries.; The number of clusters information allows for using consistent cluster IDs; even if cluster groups are accessed non-sequentially. ### Page List Envelope. The page list envelope contains cluster summaries and page locations.; It has the following structure. - Header checksum (XxHash-3 64bit); - List frame of cluster summary record frames; - Nested list frame of page locations. #### Cluster Summary Record Frame; The cluster summary record frame contains the entry range of a cluster:. ```; 0 1 2 3; 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | |; + First Entry Number +; | |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | Number of Entries |; + +-+-+-+-+-+-+-+-+; | | Flags |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; ```. The order of the cluster summaries defines the cluster IDs,; starting from the first clu",MatchSource.DOCS,tree/ntuple/v7/doc/BinaryFormatSpecification.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md:31892,Security,access,accessed,31892,"ter group record frame references the page list envelopes for groups of clusters.; A cluster group record frame has the following contents followed by a page list envelope link. ```; 0 1 2 3; 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | |; + Minimum Entry Number +; | |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | |; + Entry Span +; | |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | Number of clusters |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; ```. To compute the minimum entry number, take first entry number from all clusters in the cluster group,; and take the minimum among these numbers.; The entry span is the number of entries that are covered by this cluster group.; The entry range allows for finding the right page list for random access requests to entries.; The number of clusters information allows for using consistent cluster IDs; even if cluster groups are accessed non-sequentially. ### Page List Envelope. The page list envelope contains cluster summaries and page locations.; It has the following structure. - Header checksum (XxHash-3 64bit); - List frame of cluster summary record frames; - Nested list frame of page locations. #### Cluster Summary Record Frame; The cluster summary record frame contains the entry range of a cluster:. ```; 0 1 2 3; 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | |; + First Entry Number +; | |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | Number of Entries |; + +-+-+-+-+-+-+-+-+; | | Flags |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; ```. The order of the cluster summaries defines the cluster IDs,; starting from the first cluster ID of the cluster group that corresponds to the page list. Flag 0x01 is reserved for a future specification ",MatchSource.DOCS,tree/ntuple/v7/doc/BinaryFormatSpecification.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md:32055,Security,checksum,checksum,32055,"1; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | |; + Minimum Entry Number +; | |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | |; + Entry Span +; | |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | Number of clusters |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; ```. To compute the minimum entry number, take first entry number from all clusters in the cluster group,; and take the minimum among these numbers.; The entry span is the number of entries that are covered by this cluster group.; The entry range allows for finding the right page list for random access requests to entries.; The number of clusters information allows for using consistent cluster IDs; even if cluster groups are accessed non-sequentially. ### Page List Envelope. The page list envelope contains cluster summaries and page locations.; It has the following structure. - Header checksum (XxHash-3 64bit); - List frame of cluster summary record frames; - Nested list frame of page locations. #### Cluster Summary Record Frame; The cluster summary record frame contains the entry range of a cluster:. ```; 0 1 2 3; 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | |; + First Entry Number +; | |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | Number of Entries |; + +-+-+-+-+-+-+-+-+; | | Flags |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; ```. The order of the cluster summaries defines the cluster IDs,; starting from the first cluster ID of the cluster group that corresponds to the page list. Flag 0x01 is reserved for a future specification version that will support sharded clusters.; The future use of sharded clusters will break forward compatibility and thus introduce a corresponding feature flag.; For now, readers should abort when this flag is set.; Other flags should be ignored. #### ",MatchSource.DOCS,tree/ntuple/v7/doc/BinaryFormatSpecification.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md:34636,Security,checksum,checksum,34636,"er element offset and,; unless the column is suppressed, the 32bit compression settings; See next Section on ""Suppressed Columns"" for additional details.; Note that the size of the inner list frame includes the element offset and compression settings.; The order of the outer items must match the order of columns in the header and the extension header (small to large). The order of the inner items must match the order of pages or elements, resp.; Every inner item (that describes a page) has the following structure followed by a locator for the page. ```; 0 1 2 3; 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | Number of Elements |C|; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; ```. Note that locators for byte ranges in a file may reference identical byte ranges,; but they must not reference arbitrarily overlapping byte ranges. _C(hecksum)_: If set, an XxHash-3 64bit checksum of the compressed page data is stored just after the page.; This bit should be interpreted as the sign bit of the number of elements,; i.e. negative values indicate pages with checksums.; Note that the page size stored in the locator does _not_ include the checksum. Note that we do not need to store the uncompressed size of the page; because the uncompressed size is given by the number of elements in the page and the element size.; We do need, however, the per-column and per-cluster element offset in order to read a certain entry range; without inspecting the meta-data of all the previous clusters. The hierarchical structure of the frames in the page list envelope is as follows:. # this is `List frame of cluster group record frames` mentioned above; - Top-most cluster list frame (one item for each cluster in this RNTuple); |; |---- Cluster 1 column list frame (outer list frame, one item for each column in this RNTuple); | |---- Column 1 page list frame (inner list frame, one item for each ",MatchSource.DOCS,tree/ntuple/v7/doc/BinaryFormatSpecification.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md:34821,Security,checksum,checksums,34821,"e that the size of the inner list frame includes the element offset and compression settings.; The order of the outer items must match the order of columns in the header and the extension header (small to large). The order of the inner items must match the order of pages or elements, resp.; Every inner item (that describes a page) has the following structure followed by a locator for the page. ```; 0 1 2 3; 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | Number of Elements |C|; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; ```. Note that locators for byte ranges in a file may reference identical byte ranges,; but they must not reference arbitrarily overlapping byte ranges. _C(hecksum)_: If set, an XxHash-3 64bit checksum of the compressed page data is stored just after the page.; This bit should be interpreted as the sign bit of the number of elements,; i.e. negative values indicate pages with checksums.; Note that the page size stored in the locator does _not_ include the checksum. Note that we do not need to store the uncompressed size of the page; because the uncompressed size is given by the number of elements in the page and the element size.; We do need, however, the per-column and per-cluster element offset in order to read a certain entry range; without inspecting the meta-data of all the previous clusters. The hierarchical structure of the frames in the page list envelope is as follows:. # this is `List frame of cluster group record frames` mentioned above; - Top-most cluster list frame (one item for each cluster in this RNTuple); |; |---- Cluster 1 column list frame (outer list frame, one item for each column in this RNTuple); | |---- Column 1 page list frame (inner list frame, one item for each page in this column); | | |---- Page 1 description (inner item); | | |---- Page 2 description (inner item); | | | ...; | |---- Column 1 element offset (Int64),",MatchSource.DOCS,tree/ntuple/v7/doc/BinaryFormatSpecification.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md:34902,Security,checksum,checksum,34902,"set and compression settings.; The order of the outer items must match the order of columns in the header and the extension header (small to large). The order of the inner items must match the order of pages or elements, resp.; Every inner item (that describes a page) has the following structure followed by a locator for the page. ```; 0 1 2 3; 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | Number of Elements |C|; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; ```. Note that locators for byte ranges in a file may reference identical byte ranges,; but they must not reference arbitrarily overlapping byte ranges. _C(hecksum)_: If set, an XxHash-3 64bit checksum of the compressed page data is stored just after the page.; This bit should be interpreted as the sign bit of the number of elements,; i.e. negative values indicate pages with checksums.; Note that the page size stored in the locator does _not_ include the checksum. Note that we do not need to store the uncompressed size of the page; because the uncompressed size is given by the number of elements in the page and the element size.; We do need, however, the per-column and per-cluster element offset in order to read a certain entry range; without inspecting the meta-data of all the previous clusters. The hierarchical structure of the frames in the page list envelope is as follows:. # this is `List frame of cluster group record frames` mentioned above; - Top-most cluster list frame (one item for each cluster in this RNTuple); |; |---- Cluster 1 column list frame (outer list frame, one item for each column in this RNTuple); | |---- Column 1 page list frame (inner list frame, one item for each page in this column); | | |---- Page 1 description (inner item); | | |---- Page 2 description (inner item); | | | ...; | |---- Column 1 element offset (Int64), negative if the column is suppressed; | |---- Column 1 compres",MatchSource.DOCS,tree/ntuple/v7/doc/BinaryFormatSpecification.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md:28703,Testability,log,logical,28703,"tent |; |---------------------|-----------------------------------------------------|; | 0x00 | Serialized ROOT streamer info; see notes |. The serialized ROOT streamer info is not bound to a specific type.; It is the combined streamer information from all fields serialized by the ROOT streamer.; Writers set version from/to to zero and use an empty type name.; Readers should ignore the type-specific information.; The format of the content is a ROOT streamed `TList` of `TStreamerInfo` objects. ### Footer Envelope. The footer envelope has the following structure:. - Feature flags; - Header checksum (XxHash-3 64bit); - Schema extension record frame; - List frame of column group record frames; - List frame of cluster group record frames. The header checksum can be used to cross-check that header and footer belong together.; The meaning of the feature flags is the same as for the header.; The header flags do not need to be repeated.; Readers should combine (logical `or` of the bits) the feature flags from header and footer for the full set of flags. #### Schema Extension Record Frame. The schema extension record frame contains an additional schema description that is incremental; with respect to the schema contained in the header (see Section Header Envelope).; Specifically, it is a record frame with the following four fields; (identical to the last four fields in Header Envelope):. - List frame: list of field record frames; - List frame: list of column record frames; - List frame: list of alias column record frames; - List frame: list of extra type information. In general, a schema extension is optional, and thus this record frame might be empty.; The interpretation of the information contained therein should be identical; as if it was found directly at the end of the header.; This is necessary when fields have been added during writing. Note that the field IDs and physical column IDs given by the serialization order; should continue from the largest IDs found in the hea",MatchSource.DOCS,tree/ntuple/v7/doc/BinaryFormatSpecification.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md:36916,Testability,assert,assertion,36916,"umn 2 page list frame; | | ...; |; |---- Cluster 2 column list frame; | ... In order to save space, the page descriptions (inner items) are _not_ in a record frame.; If at a later point more information per page is needed,; the page list envelope can be extended by additional list and record frames. #### Suppressed Columns. If the element offset in the inner list frame is negative (sign bit set), the column is suppressed.; Writers should write the lowest int64_t value, readers should check for a negative value.; Suppressed columns always have an empty list of pages.; Suppressed columns omit the compression settings in the inner list frame. Suppressed columns belong to a secondary column representation (see Section ""Column Description""); that is inactive in the current cluster.; The number of columns; and the absolute values of the element offsets of primary and secondary representations are identical.; When reading a field of a certain entry, this assertion allows for searching the corresponding; cluster and column element indexes using any of the column representations.; It also means that readers need to get the element index offset and the number of elements of suppressed columns; from the corresponding columns of the primary column representation. In every cluster, every field has exactly one primary column representation.; All other representations must be suppressed.; Note that the primary column representation can change from cluster to cluster. ## Mapping of C++ Types to Fields and Columns. This section is a comprehensive list of the C++ types with RNTuple I/O support.; Within the supported type system complex types can be freely composed,; e.g. `std::vector<MyEvent>` or `std::vector<std::vector<float>>`. ### Fundamental Types. The following fundamental types are stored as `leaf` fields with a single column each.; Fundamental C++ types can potentially be stored in multiple possible column types.; The possible combinations are marked as `W` in the following ta",MatchSource.DOCS,tree/ntuple/v7/doc/BinaryFormatSpecification.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md:10042,Usability,simpl,simple,10042,"deserialization of older readers. ## Locators and Envelope Links. A locator is a generalized way to specify a certain byte range on the storage medium.; For disk-based storage, the locator is just byte offset and byte size.; For other storage systems, the locator contains enough information to retrieve the referenced block,; e.g. in object stores, the locator can specify a certain object ID.; The locator has the following format. ```; 0 1 2 3; 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | Size |T|; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | |; + Offset +; | |; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; ```. _Size_: If `T` is zero, the number of bytes to read, i.e. the compressed size of the referenced block.; Otherwise, the 16 least-significant bits, i.e. bits 0:15, specify the size of the locator itself (see below). _T(ype)_: Zero for a simple on-disk or in-file locator, 1 otherwise.; Can be interpreted as the sign bit of the size, i.e. negative sizes indicate non-standard locators.; In this case, the locator should be interpreted like a frame, i.e. size indicates the _size of the locator itself_. _Offset_:; For on-disk / in-file locators, the 64bit byte offset of the referenced byte range counted from the start of the file. For non-standard locators, i.e. `T` == 1, the locator format is as follows. ```; 0 1 2 3; 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | Size | Reserved | Type |T|; +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+; | LOCATOR PAYLOAD |; | ... |; ```. In this case, the last 8 bits of the size should be interpreted as a locator type.; To determine the locator type, the absolute value of the 8bit integer should be taken.; The type can take one of the following values. | Type | Meaning | Payload format |; |------",MatchSource.DOCS,tree/ntuple/v7/doc/BinaryFormatSpecification.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md:50533,Usability,simpl,simple,50533,"its |; | Maximum number of clusters per group | 4B (foreseen: <10k) | List frame limits, cluster group summary encoding |; | Maximum number of pages per cluster per column | 4B | List frame limits |; | Maximum number of entries per cluster | 2^56 | Cluster summary encoding |; | Maximum string length (meta-data) | 4GB | String encoding |; | Maximum RBlob size | 128 PiB | 1GiB / 8B * 1GiB (with maxKeySize=1GiB, offsetSize=8B) |. ## Glossary. ### Anchor. The anchor is a data block that represents the entry point to an RNTuple.; The anchor is specific to the RNTuple container in which the RNTuple data are embedded (e.g., a ROOT file or an object store).; The anchor must provide the information to load the header and the footer **envelopes**. ### Cluster. A cluster is a set of **pages** that contain all the data belonging to an entry range.; The data set is partitioned in clusters.; A typical cluster size is tens to hundreds of megabytes. ### Column. A column is a storage backed vector of a number of **elements** of a simple type.; Column elements have a fixed bit-length that depends on the column type.; Some column types allow setting the bit lengths within specific limits (e.g. for floats with truncated mantissa). ### Envelope. An envelope is a data block with RNTuple meta-data, such as the header and the footer. ### Field. A field describes a serialized C++ type.; A field can have a hierarchy of subfields representing a composed C++ type (e.g., a vector of integers).; A field has zero, one, or multiple **columns** attached to it.; The columns contain the data related to the field but not to its subfields, which have their own columns. ### Frame. A frame is a byte range with metadata information in an **envelope**.; A frame starts with its size and thus can be extended in a forward-compatible way. ### Locator. A locator is a generalized way to identify a byte range in the RNTuple container.; For a file container, for instance, a locator consists of an offset and a size",MatchSource.DOCS,tree/ntuple/v7/doc/BinaryFormatSpecification.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/BinaryFormatSpecification.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/README.md:200,Availability,robust,robust,200,"RNTuple Introduction; ====================. RNTuple (for n-tuple and nested tuple) is the experimental evolution of TTree columnar data storage. RNTuple introduces; new interfaces that aim to be more robust. In particular, the new interfaces are type-safe through the use of; templates, and the ownership is well-defined through the use of smart pointers. For instance. tree->Branch(""px"", &Category, ""px/F"");. becomes. auto px = model->MakeField<float>(""px"");; // px is std::shared_ptr<float>. The physical layout changes slightly from big endian to little endian so that it matches the in-memory layout on; most modern architectures. Combined with a clear separation of offset/index data and payload data for collections,; uncompressed RNTuple data can be directly mapped to memory without further copies. Goals; -----. RNTuple shall investigate improvements of the TTree I/O in the following ways. 1. More speed; * Improve mapping to vectorized and parallel hardware; * For types known at compile / JIT time: generate optimized code; * Optimized for simple types (float, int, and vectors of them); * Better memory control: work with a fixed budget of pre-defined I/O buffers; * Naturally thread-safe and asynchronous interfaces. 2. More robust interfaces; * Compile-time type safety by default; * Decomposition into layers: logical layer, primitives layer, storage layer; * Separation of data model and live data; * Self-contained I/O code to support creation of a standalone I/O library. Concepts; --------. At the **logical layer**, the user defines a data model using the RNTupleModel class.; The data model is a collection of serializable C++ types with associated names, similar to branches in a TTree.; The data model can contain (nested) collections, e.g., a type can be `std::vector<std::vector<float>>`. Each serializable type is represented by a **field**, concretely by a templated version of RField,; e.g. `RField<double>`. A field can generate or adopt an associated **value**, which re",MatchSource.DOCS,tree/ntuple/v7/doc/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/README.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/README.md:1239,Availability,robust,robust,1239,"nstance. tree->Branch(""px"", &Category, ""px/F"");. becomes. auto px = model->MakeField<float>(""px"");; // px is std::shared_ptr<float>. The physical layout changes slightly from big endian to little endian so that it matches the in-memory layout on; most modern architectures. Combined with a clear separation of offset/index data and payload data for collections,; uncompressed RNTuple data can be directly mapped to memory without further copies. Goals; -----. RNTuple shall investigate improvements of the TTree I/O in the following ways. 1. More speed; * Improve mapping to vectorized and parallel hardware; * For types known at compile / JIT time: generate optimized code; * Optimized for simple types (float, int, and vectors of them); * Better memory control: work with a fixed budget of pre-defined I/O buffers; * Naturally thread-safe and asynchronous interfaces. 2. More robust interfaces; * Compile-time type safety by default; * Decomposition into layers: logical layer, primitives layer, storage layer; * Separation of data model and live data; * Self-contained I/O code to support creation of a standalone I/O library. Concepts; --------. At the **logical layer**, the user defines a data model using the RNTupleModel class.; The data model is a collection of serializable C++ types with associated names, similar to branches in a TTree.; The data model can contain (nested) collections, e.g., a type can be `std::vector<std::vector<float>>`. Each serializable type is represented by a **field**, concretely by a templated version of RField,; e.g. `RField<double>`. A field can generate or adopt an associated **value**, which represents a memory location; storing a value of the given C++ type. These distinguished memory locations are the destinations and sources for the; deserialization and serialization. The (de-)serialization is a mapping from the C++ type to the more simple **column** type system. A column contains; an arbitrary number of fixed-sized elements of a well-defined se",MatchSource.DOCS,tree/ntuple/v7/doc/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/README.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/README.md:169,Integrability,interface,interfaces,169,"RNTuple Introduction; ====================. RNTuple (for n-tuple and nested tuple) is the experimental evolution of TTree columnar data storage. RNTuple introduces; new interfaces that aim to be more robust. In particular, the new interfaces are type-safe through the use of; templates, and the ownership is well-defined through the use of smart pointers. For instance. tree->Branch(""px"", &Category, ""px/F"");. becomes. auto px = model->MakeField<float>(""px"");; // px is std::shared_ptr<float>. The physical layout changes slightly from big endian to little endian so that it matches the in-memory layout on; most modern architectures. Combined with a clear separation of offset/index data and payload data for collections,; uncompressed RNTuple data can be directly mapped to memory without further copies. Goals; -----. RNTuple shall investigate improvements of the TTree I/O in the following ways. 1. More speed; * Improve mapping to vectorized and parallel hardware; * For types known at compile / JIT time: generate optimized code; * Optimized for simple types (float, int, and vectors of them); * Better memory control: work with a fixed budget of pre-defined I/O buffers; * Naturally thread-safe and asynchronous interfaces. 2. More robust interfaces; * Compile-time type safety by default; * Decomposition into layers: logical layer, primitives layer, storage layer; * Separation of data model and live data; * Self-contained I/O code to support creation of a standalone I/O library. Concepts; --------. At the **logical layer**, the user defines a data model using the RNTupleModel class.; The data model is a collection of serializable C++ types with associated names, similar to branches in a TTree.; The data model can contain (nested) collections, e.g., a type can be `std::vector<std::vector<float>>`. Each serializable type is represented by a **field**, concretely by a templated version of RField,; e.g. `RField<double>`. A field can generate or adopt an associated **value**, which re",MatchSource.DOCS,tree/ntuple/v7/doc/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/README.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/README.md:231,Integrability,interface,interfaces,231,"RNTuple Introduction; ====================. RNTuple (for n-tuple and nested tuple) is the experimental evolution of TTree columnar data storage. RNTuple introduces; new interfaces that aim to be more robust. In particular, the new interfaces are type-safe through the use of; templates, and the ownership is well-defined through the use of smart pointers. For instance. tree->Branch(""px"", &Category, ""px/F"");. becomes. auto px = model->MakeField<float>(""px"");; // px is std::shared_ptr<float>. The physical layout changes slightly from big endian to little endian so that it matches the in-memory layout on; most modern architectures. Combined with a clear separation of offset/index data and payload data for collections,; uncompressed RNTuple data can be directly mapped to memory without further copies. Goals; -----. RNTuple shall investigate improvements of the TTree I/O in the following ways. 1. More speed; * Improve mapping to vectorized and parallel hardware; * For types known at compile / JIT time: generate optimized code; * Optimized for simple types (float, int, and vectors of them); * Better memory control: work with a fixed budget of pre-defined I/O buffers; * Naturally thread-safe and asynchronous interfaces. 2. More robust interfaces; * Compile-time type safety by default; * Decomposition into layers: logical layer, primitives layer, storage layer; * Separation of data model and live data; * Self-contained I/O code to support creation of a standalone I/O library. Concepts; --------. At the **logical layer**, the user defines a data model using the RNTupleModel class.; The data model is a collection of serializable C++ types with associated names, similar to branches in a TTree.; The data model can contain (nested) collections, e.g., a type can be `std::vector<std::vector<float>>`. Each serializable type is represented by a **field**, concretely by a templated version of RField,; e.g. `RField<double>`. A field can generate or adopt an associated **value**, which re",MatchSource.DOCS,tree/ntuple/v7/doc/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/README.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/README.md:1219,Integrability,interface,interfaces,1219,"nd nested tuple) is the experimental evolution of TTree columnar data storage. RNTuple introduces; new interfaces that aim to be more robust. In particular, the new interfaces are type-safe through the use of; templates, and the ownership is well-defined through the use of smart pointers. For instance. tree->Branch(""px"", &Category, ""px/F"");. becomes. auto px = model->MakeField<float>(""px"");; // px is std::shared_ptr<float>. The physical layout changes slightly from big endian to little endian so that it matches the in-memory layout on; most modern architectures. Combined with a clear separation of offset/index data and payload data for collections,; uncompressed RNTuple data can be directly mapped to memory without further copies. Goals; -----. RNTuple shall investigate improvements of the TTree I/O in the following ways. 1. More speed; * Improve mapping to vectorized and parallel hardware; * For types known at compile / JIT time: generate optimized code; * Optimized for simple types (float, int, and vectors of them); * Better memory control: work with a fixed budget of pre-defined I/O buffers; * Naturally thread-safe and asynchronous interfaces. 2. More robust interfaces; * Compile-time type safety by default; * Decomposition into layers: logical layer, primitives layer, storage layer; * Separation of data model and live data; * Self-contained I/O code to support creation of a standalone I/O library. Concepts; --------. At the **logical layer**, the user defines a data model using the RNTupleModel class.; The data model is a collection of serializable C++ types with associated names, similar to branches in a TTree.; The data model can contain (nested) collections, e.g., a type can be `std::vector<std::vector<float>>`. Each serializable type is represented by a **field**, concretely by a templated version of RField,; e.g. `RField<double>`. A field can generate or adopt an associated **value**, which represents a memory location; storing a value of the given C++ type",MatchSource.DOCS,tree/ntuple/v7/doc/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/README.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/README.md:1246,Integrability,interface,interfaces,1246,"nstance. tree->Branch(""px"", &Category, ""px/F"");. becomes. auto px = model->MakeField<float>(""px"");; // px is std::shared_ptr<float>. The physical layout changes slightly from big endian to little endian so that it matches the in-memory layout on; most modern architectures. Combined with a clear separation of offset/index data and payload data for collections,; uncompressed RNTuple data can be directly mapped to memory without further copies. Goals; -----. RNTuple shall investigate improvements of the TTree I/O in the following ways. 1. More speed; * Improve mapping to vectorized and parallel hardware; * For types known at compile / JIT time: generate optimized code; * Optimized for simple types (float, int, and vectors of them); * Better memory control: work with a fixed budget of pre-defined I/O buffers; * Naturally thread-safe and asynchronous interfaces. 2. More robust interfaces; * Compile-time type safety by default; * Decomposition into layers: logical layer, primitives layer, storage layer; * Separation of data model and live data; * Self-contained I/O code to support creation of a standalone I/O library. Concepts; --------. At the **logical layer**, the user defines a data model using the RNTupleModel class.; The data model is a collection of serializable C++ types with associated names, similar to branches in a TTree.; The data model can contain (nested) collections, e.g., a type can be `std::vector<std::vector<float>>`. Each serializable type is represented by a **field**, concretely by a templated version of RField,; e.g. `RField<double>`. A field can generate or adopt an associated **value**, which represents a memory location; storing a value of the given C++ type. These distinguished memory locations are the destinations and sources for the; deserialization and serialization. The (de-)serialization is a mapping from the C++ type to the more simple **column** type system. A column contains; an arbitrary number of fixed-sized elements of a well-defined se",MatchSource.DOCS,tree/ntuple/v7/doc/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/README.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/README.md:2937,Integrability,interface,interface,2937,"erializable C++ types with associated names, similar to branches in a TTree.; The data model can contain (nested) collections, e.g., a type can be `std::vector<std::vector<float>>`. Each serializable type is represented by a **field**, concretely by a templated version of RField,; e.g. `RField<double>`. A field can generate or adopt an associated **value**, which represents a memory location; storing a value of the given C++ type. These distinguished memory locations are the destinations and sources for the; deserialization and serialization. The (de-)serialization is a mapping from the C++ type to the more simple **column** type system. A column contains; an arbitrary number of fixed-sized elements of a well-defined set of types: integers and floats of different; bit sizes. A C++ type may be mapped to multiple columns. For instance, an `std::vector<float>` maps to two columns,; an offset column indicating the size of the vector per entry, and a payload column with the float data. Columns are partitioned into **pages** (roughly: TTree baskets) of a few kB -- a few tens of kB each.; The **physical layer** (only) needs to provide the means to store and retrieve pages. The physical layer is; decoupled from the high-level C++ logic. The physical layer implements an abstract page storage interface,; so that dedicated implementations for key-value stores and other storage systems are conceivable.; At this point, the only provided backend stores the pages in ROOT files. RNTuples are further grouped into **clusters**, which are, like TTree clusters, self-contained blocks of; consecutive entries. Clusters provide a unit of writing and will provide the means for parallel writing of data; in a future version of RNTuple. Related classes; ---------------. \defgroup ROOT7 ROOT7 classes; \brief Interfaces and classes designed for future ROOT version 7 (experimental!). \defgroup NTuple NTuple-related classes; \brief tuple classes designed for future ROOT version 7 (experimental!); ",MatchSource.DOCS,tree/ntuple/v7/doc/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/README.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/README.md:1318,Modifiability,layers,layers,1318,"nstance. tree->Branch(""px"", &Category, ""px/F"");. becomes. auto px = model->MakeField<float>(""px"");; // px is std::shared_ptr<float>. The physical layout changes slightly from big endian to little endian so that it matches the in-memory layout on; most modern architectures. Combined with a clear separation of offset/index data and payload data for collections,; uncompressed RNTuple data can be directly mapped to memory without further copies. Goals; -----. RNTuple shall investigate improvements of the TTree I/O in the following ways. 1. More speed; * Improve mapping to vectorized and parallel hardware; * For types known at compile / JIT time: generate optimized code; * Optimized for simple types (float, int, and vectors of them); * Better memory control: work with a fixed budget of pre-defined I/O buffers; * Naturally thread-safe and asynchronous interfaces. 2. More robust interfaces; * Compile-time type safety by default; * Decomposition into layers: logical layer, primitives layer, storage layer; * Separation of data model and live data; * Self-contained I/O code to support creation of a standalone I/O library. Concepts; --------. At the **logical layer**, the user defines a data model using the RNTupleModel class.; The data model is a collection of serializable C++ types with associated names, similar to branches in a TTree.; The data model can contain (nested) collections, e.g., a type can be `std::vector<std::vector<float>>`. Each serializable type is represented by a **field**, concretely by a templated version of RField,; e.g. `RField<double>`. A field can generate or adopt an associated **value**, which represents a memory location; storing a value of the given C++ type. These distinguished memory locations are the destinations and sources for the; deserialization and serialization. The (de-)serialization is a mapping from the C++ type to the more simple **column** type system. A column contains; an arbitrary number of fixed-sized elements of a well-defined se",MatchSource.DOCS,tree/ntuple/v7/doc/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/README.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/README.md:1020,Performance,optimiz,optimized,1020,"nd nested tuple) is the experimental evolution of TTree columnar data storage. RNTuple introduces; new interfaces that aim to be more robust. In particular, the new interfaces are type-safe through the use of; templates, and the ownership is well-defined through the use of smart pointers. For instance. tree->Branch(""px"", &Category, ""px/F"");. becomes. auto px = model->MakeField<float>(""px"");; // px is std::shared_ptr<float>. The physical layout changes slightly from big endian to little endian so that it matches the in-memory layout on; most modern architectures. Combined with a clear separation of offset/index data and payload data for collections,; uncompressed RNTuple data can be directly mapped to memory without further copies. Goals; -----. RNTuple shall investigate improvements of the TTree I/O in the following ways. 1. More speed; * Improve mapping to vectorized and parallel hardware; * For types known at compile / JIT time: generate optimized code; * Optimized for simple types (float, int, and vectors of them); * Better memory control: work with a fixed budget of pre-defined I/O buffers; * Naturally thread-safe and asynchronous interfaces. 2. More robust interfaces; * Compile-time type safety by default; * Decomposition into layers: logical layer, primitives layer, storage layer; * Separation of data model and live data; * Self-contained I/O code to support creation of a standalone I/O library. Concepts; --------. At the **logical layer**, the user defines a data model using the RNTupleModel class.; The data model is a collection of serializable C++ types with associated names, similar to branches in a TTree.; The data model can contain (nested) collections, e.g., a type can be `std::vector<std::vector<float>>`. Each serializable type is represented by a **field**, concretely by a templated version of RField,; e.g. `RField<double>`. A field can generate or adopt an associated **value**, which represents a memory location; storing a value of the given C++ type",MatchSource.DOCS,tree/ntuple/v7/doc/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/README.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/README.md:251,Safety,safe,safe,251,"RNTuple Introduction; ====================. RNTuple (for n-tuple and nested tuple) is the experimental evolution of TTree columnar data storage. RNTuple introduces; new interfaces that aim to be more robust. In particular, the new interfaces are type-safe through the use of; templates, and the ownership is well-defined through the use of smart pointers. For instance. tree->Branch(""px"", &Category, ""px/F"");. becomes. auto px = model->MakeField<float>(""px"");; // px is std::shared_ptr<float>. The physical layout changes slightly from big endian to little endian so that it matches the in-memory layout on; most modern architectures. Combined with a clear separation of offset/index data and payload data for collections,; uncompressed RNTuple data can be directly mapped to memory without further copies. Goals; -----. RNTuple shall investigate improvements of the TTree I/O in the following ways. 1. More speed; * Improve mapping to vectorized and parallel hardware; * For types known at compile / JIT time: generate optimized code; * Optimized for simple types (float, int, and vectors of them); * Better memory control: work with a fixed budget of pre-defined I/O buffers; * Naturally thread-safe and asynchronous interfaces. 2. More robust interfaces; * Compile-time type safety by default; * Decomposition into layers: logical layer, primitives layer, storage layer; * Separation of data model and live data; * Self-contained I/O code to support creation of a standalone I/O library. Concepts; --------. At the **logical layer**, the user defines a data model using the RNTupleModel class.; The data model is a collection of serializable C++ types with associated names, similar to branches in a TTree.; The data model can contain (nested) collections, e.g., a type can be `std::vector<std::vector<float>>`. Each serializable type is represented by a **field**, concretely by a templated version of RField,; e.g. `RField<double>`. A field can generate or adopt an associated **value**, which re",MatchSource.DOCS,tree/ntuple/v7/doc/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/README.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/README.md:1197,Safety,safe,safe,1197,"nd nested tuple) is the experimental evolution of TTree columnar data storage. RNTuple introduces; new interfaces that aim to be more robust. In particular, the new interfaces are type-safe through the use of; templates, and the ownership is well-defined through the use of smart pointers. For instance. tree->Branch(""px"", &Category, ""px/F"");. becomes. auto px = model->MakeField<float>(""px"");; // px is std::shared_ptr<float>. The physical layout changes slightly from big endian to little endian so that it matches the in-memory layout on; most modern architectures. Combined with a clear separation of offset/index data and payload data for collections,; uncompressed RNTuple data can be directly mapped to memory without further copies. Goals; -----. RNTuple shall investigate improvements of the TTree I/O in the following ways. 1. More speed; * Improve mapping to vectorized and parallel hardware; * For types known at compile / JIT time: generate optimized code; * Optimized for simple types (float, int, and vectors of them); * Better memory control: work with a fixed budget of pre-defined I/O buffers; * Naturally thread-safe and asynchronous interfaces. 2. More robust interfaces; * Compile-time type safety by default; * Decomposition into layers: logical layer, primitives layer, storage layer; * Separation of data model and live data; * Self-contained I/O code to support creation of a standalone I/O library. Concepts; --------. At the **logical layer**, the user defines a data model using the RNTupleModel class.; The data model is a collection of serializable C++ types with associated names, similar to branches in a TTree.; The data model can contain (nested) collections, e.g., a type can be `std::vector<std::vector<float>>`. Each serializable type is represented by a **field**, concretely by a templated version of RField,; e.g. `RField<double>`. A field can generate or adopt an associated **value**, which represents a memory location; storing a value of the given C++ type",MatchSource.DOCS,tree/ntuple/v7/doc/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/README.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/README.md:1278,Safety,safe,safety,1278,"nstance. tree->Branch(""px"", &Category, ""px/F"");. becomes. auto px = model->MakeField<float>(""px"");; // px is std::shared_ptr<float>. The physical layout changes slightly from big endian to little endian so that it matches the in-memory layout on; most modern architectures. Combined with a clear separation of offset/index data and payload data for collections,; uncompressed RNTuple data can be directly mapped to memory without further copies. Goals; -----. RNTuple shall investigate improvements of the TTree I/O in the following ways. 1. More speed; * Improve mapping to vectorized and parallel hardware; * For types known at compile / JIT time: generate optimized code; * Optimized for simple types (float, int, and vectors of them); * Better memory control: work with a fixed budget of pre-defined I/O buffers; * Naturally thread-safe and asynchronous interfaces. 2. More robust interfaces; * Compile-time type safety by default; * Decomposition into layers: logical layer, primitives layer, storage layer; * Separation of data model and live data; * Self-contained I/O code to support creation of a standalone I/O library. Concepts; --------. At the **logical layer**, the user defines a data model using the RNTupleModel class.; The data model is a collection of serializable C++ types with associated names, similar to branches in a TTree.; The data model can contain (nested) collections, e.g., a type can be `std::vector<std::vector<float>>`. Each serializable type is represented by a **field**, concretely by a templated version of RField,; e.g. `RField<double>`. A field can generate or adopt an associated **value**, which represents a memory location; storing a value of the given C++ type. These distinguished memory locations are the destinations and sources for the; deserialization and serialization. The (de-)serialization is a mapping from the C++ type to the more simple **column** type system. A column contains; an arbitrary number of fixed-sized elements of a well-defined se",MatchSource.DOCS,tree/ntuple/v7/doc/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/README.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/README.md:1326,Testability,log,logical,1326,"nstance. tree->Branch(""px"", &Category, ""px/F"");. becomes. auto px = model->MakeField<float>(""px"");; // px is std::shared_ptr<float>. The physical layout changes slightly from big endian to little endian so that it matches the in-memory layout on; most modern architectures. Combined with a clear separation of offset/index data and payload data for collections,; uncompressed RNTuple data can be directly mapped to memory without further copies. Goals; -----. RNTuple shall investigate improvements of the TTree I/O in the following ways. 1. More speed; * Improve mapping to vectorized and parallel hardware; * For types known at compile / JIT time: generate optimized code; * Optimized for simple types (float, int, and vectors of them); * Better memory control: work with a fixed budget of pre-defined I/O buffers; * Naturally thread-safe and asynchronous interfaces. 2. More robust interfaces; * Compile-time type safety by default; * Decomposition into layers: logical layer, primitives layer, storage layer; * Separation of data model and live data; * Self-contained I/O code to support creation of a standalone I/O library. Concepts; --------. At the **logical layer**, the user defines a data model using the RNTupleModel class.; The data model is a collection of serializable C++ types with associated names, similar to branches in a TTree.; The data model can contain (nested) collections, e.g., a type can be `std::vector<std::vector<float>>`. Each serializable type is represented by a **field**, concretely by a templated version of RField,; e.g. `RField<double>`. A field can generate or adopt an associated **value**, which represents a memory location; storing a value of the given C++ type. These distinguished memory locations are the destinations and sources for the; deserialization and serialization. The (de-)serialization is a mapping from the C++ type to the more simple **column** type system. A column contains; an arbitrary number of fixed-sized elements of a well-defined se",MatchSource.DOCS,tree/ntuple/v7/doc/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/README.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/README.md:1520,Testability,log,logical,1520,"tle endian so that it matches the in-memory layout on; most modern architectures. Combined with a clear separation of offset/index data and payload data for collections,; uncompressed RNTuple data can be directly mapped to memory without further copies. Goals; -----. RNTuple shall investigate improvements of the TTree I/O in the following ways. 1. More speed; * Improve mapping to vectorized and parallel hardware; * For types known at compile / JIT time: generate optimized code; * Optimized for simple types (float, int, and vectors of them); * Better memory control: work with a fixed budget of pre-defined I/O buffers; * Naturally thread-safe and asynchronous interfaces. 2. More robust interfaces; * Compile-time type safety by default; * Decomposition into layers: logical layer, primitives layer, storage layer; * Separation of data model and live data; * Self-contained I/O code to support creation of a standalone I/O library. Concepts; --------. At the **logical layer**, the user defines a data model using the RNTupleModel class.; The data model is a collection of serializable C++ types with associated names, similar to branches in a TTree.; The data model can contain (nested) collections, e.g., a type can be `std::vector<std::vector<float>>`. Each serializable type is represented by a **field**, concretely by a templated version of RField,; e.g. `RField<double>`. A field can generate or adopt an associated **value**, which represents a memory location; storing a value of the given C++ type. These distinguished memory locations are the destinations and sources for the; deserialization and serialization. The (de-)serialization is a mapping from the C++ type to the more simple **column** type system. A column contains; an arbitrary number of fixed-sized elements of a well-defined set of types: integers and floats of different; bit sizes. A C++ type may be mapped to multiple columns. For instance, an `std::vector<float>` maps to two columns,; an offset column indicating ",MatchSource.DOCS,tree/ntuple/v7/doc/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/README.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/README.md:2875,Testability,log,logic,2875,"erializable C++ types with associated names, similar to branches in a TTree.; The data model can contain (nested) collections, e.g., a type can be `std::vector<std::vector<float>>`. Each serializable type is represented by a **field**, concretely by a templated version of RField,; e.g. `RField<double>`. A field can generate or adopt an associated **value**, which represents a memory location; storing a value of the given C++ type. These distinguished memory locations are the destinations and sources for the; deserialization and serialization. The (de-)serialization is a mapping from the C++ type to the more simple **column** type system. A column contains; an arbitrary number of fixed-sized elements of a well-defined set of types: integers and floats of different; bit sizes. A C++ type may be mapped to multiple columns. For instance, an `std::vector<float>` maps to two columns,; an offset column indicating the size of the vector per entry, and a payload column with the float data. Columns are partitioned into **pages** (roughly: TTree baskets) of a few kB -- a few tens of kB each.; The **physical layer** (only) needs to provide the means to store and retrieve pages. The physical layer is; decoupled from the high-level C++ logic. The physical layer implements an abstract page storage interface,; so that dedicated implementations for key-value stores and other storage systems are conceivable.; At this point, the only provided backend stores the pages in ROOT files. RNTuples are further grouped into **clusters**, which are, like TTree clusters, self-contained blocks of; consecutive entries. Clusters provide a unit of writing and will provide the means for parallel writing of data; in a future version of RNTuple. Related classes; ---------------. \defgroup ROOT7 ROOT7 classes; \brief Interfaces and classes designed for future ROOT version 7 (experimental!). \defgroup NTuple NTuple-related classes; \brief tuple classes designed for future ROOT version 7 (experimental!); ",MatchSource.DOCS,tree/ntuple/v7/doc/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/README.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/README.md:651,Usability,clear,clear,651,"RNTuple Introduction; ====================. RNTuple (for n-tuple and nested tuple) is the experimental evolution of TTree columnar data storage. RNTuple introduces; new interfaces that aim to be more robust. In particular, the new interfaces are type-safe through the use of; templates, and the ownership is well-defined through the use of smart pointers. For instance. tree->Branch(""px"", &Category, ""px/F"");. becomes. auto px = model->MakeField<float>(""px"");; // px is std::shared_ptr<float>. The physical layout changes slightly from big endian to little endian so that it matches the in-memory layout on; most modern architectures. Combined with a clear separation of offset/index data and payload data for collections,; uncompressed RNTuple data can be directly mapped to memory without further copies. Goals; -----. RNTuple shall investigate improvements of the TTree I/O in the following ways. 1. More speed; * Improve mapping to vectorized and parallel hardware; * For types known at compile / JIT time: generate optimized code; * Optimized for simple types (float, int, and vectors of them); * Better memory control: work with a fixed budget of pre-defined I/O buffers; * Naturally thread-safe and asynchronous interfaces. 2. More robust interfaces; * Compile-time type safety by default; * Decomposition into layers: logical layer, primitives layer, storage layer; * Separation of data model and live data; * Self-contained I/O code to support creation of a standalone I/O library. Concepts; --------. At the **logical layer**, the user defines a data model using the RNTupleModel class.; The data model is a collection of serializable C++ types with associated names, similar to branches in a TTree.; The data model can contain (nested) collections, e.g., a type can be `std::vector<std::vector<float>>`. Each serializable type is represented by a **field**, concretely by a templated version of RField,; e.g. `RField<double>`. A field can generate or adopt an associated **value**, which re",MatchSource.DOCS,tree/ntuple/v7/doc/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/README.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/README.md:1052,Usability,simpl,simple,1052,"nd nested tuple) is the experimental evolution of TTree columnar data storage. RNTuple introduces; new interfaces that aim to be more robust. In particular, the new interfaces are type-safe through the use of; templates, and the ownership is well-defined through the use of smart pointers. For instance. tree->Branch(""px"", &Category, ""px/F"");. becomes. auto px = model->MakeField<float>(""px"");; // px is std::shared_ptr<float>. The physical layout changes slightly from big endian to little endian so that it matches the in-memory layout on; most modern architectures. Combined with a clear separation of offset/index data and payload data for collections,; uncompressed RNTuple data can be directly mapped to memory without further copies. Goals; -----. RNTuple shall investigate improvements of the TTree I/O in the following ways. 1. More speed; * Improve mapping to vectorized and parallel hardware; * For types known at compile / JIT time: generate optimized code; * Optimized for simple types (float, int, and vectors of them); * Better memory control: work with a fixed budget of pre-defined I/O buffers; * Naturally thread-safe and asynchronous interfaces. 2. More robust interfaces; * Compile-time type safety by default; * Decomposition into layers: logical layer, primitives layer, storage layer; * Separation of data model and live data; * Self-contained I/O code to support creation of a standalone I/O library. Concepts; --------. At the **logical layer**, the user defines a data model using the RNTupleModel class.; The data model is a collection of serializable C++ types with associated names, similar to branches in a TTree.; The data model can contain (nested) collections, e.g., a type can be `std::vector<std::vector<float>>`. Each serializable type is represented by a **field**, concretely by a templated version of RField,; e.g. `RField<double>`. A field can generate or adopt an associated **value**, which represents a memory location; storing a value of the given C++ type",MatchSource.DOCS,tree/ntuple/v7/doc/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/README.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/README.md:2248,Usability,simpl,simple,2248,". 2. More robust interfaces; * Compile-time type safety by default; * Decomposition into layers: logical layer, primitives layer, storage layer; * Separation of data model and live data; * Self-contained I/O code to support creation of a standalone I/O library. Concepts; --------. At the **logical layer**, the user defines a data model using the RNTupleModel class.; The data model is a collection of serializable C++ types with associated names, similar to branches in a TTree.; The data model can contain (nested) collections, e.g., a type can be `std::vector<std::vector<float>>`. Each serializable type is represented by a **field**, concretely by a templated version of RField,; e.g. `RField<double>`. A field can generate or adopt an associated **value**, which represents a memory location; storing a value of the given C++ type. These distinguished memory locations are the destinations and sources for the; deserialization and serialization. The (de-)serialization is a mapping from the C++ type to the more simple **column** type system. A column contains; an arbitrary number of fixed-sized elements of a well-defined set of types: integers and floats of different; bit sizes. A C++ type may be mapped to multiple columns. For instance, an `std::vector<float>` maps to two columns,; an offset column indicating the size of the vector per entry, and a payload column with the float data. Columns are partitioned into **pages** (roughly: TTree baskets) of a few kB -- a few tens of kB each.; The **physical layer** (only) needs to provide the means to store and retrieve pages. The physical layer is; decoupled from the high-level C++ logic. The physical layer implements an abstract page storage interface,; so that dedicated implementations for key-value stores and other storage systems are conceivable.; At this point, the only provided backend stores the pages in ROOT files. RNTuples are further grouped into **clusters**, which are, like TTree clusters, self-contained blocks of; con",MatchSource.DOCS,tree/ntuple/v7/doc/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/README.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/tuning.md:1862,Energy Efficiency,allocate,allocated,1862," an ""emergency break"" and should prevent very compressible clusters from growing too large. Given the two settings, writing works as follows:; when the current cluster is larger than the maximum uncompressed size, it will be flushed unconditionally.; When the current cluster size reaches the estimate for the compressed cluster size, it will be flushed, too.; The estimated compression ratio for the first cluster is 0.5 if compression is used, and 1 otherwise.; The following clusters use the average compression ratio of all so-far written clusters as an estimate.; See the notes below on a discussion of this approximation. Page Sizes; ==========. Pages contain consecutive elements of a certain column.; They are the unit of compression and of addressability on storage.; RNTuple puts a configurable maximum uncompressed size for pages.; This limit is by default set to 1 MiB.; When the limit is reached, a page will be flushed to disk. In addition, RNTuple maintains a memory budget for the combined allocated size of the pages that are currently filled.; By default, this limit is set to twice the compressed target cluster size when compression is used,; and to the cluster target size for uncompressed data.; Initially, and after flushing, all columns use small pages,; just big enough to hold the configurable minimum number of elements (64 by default).; Page sizes are doubled as more data is filled into them.; When a page reaches the maximum page size (see above), it is flushed.; When the overall page budget is reached,; pages larger than the page at hand are flushed before the page at hand is flushed.; For the parallel writer, every fill context maintains the page memory budget independently. Note that the total amount of memory consumed for writing is usually larger than the write page budget.; For instance, if buffered writing is used (the default), additional memory is required.; Use RNTupleModel::EstimateWriteMemoryUsage() for the total estimated memory use for writing. Th",MatchSource.DOCS,tree/ntuple/v7/doc/tuning.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/tuning.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/tuning.md:2990,Energy Efficiency,consumption,consumption,2990," the cluster target size for uncompressed data.; Initially, and after flushing, all columns use small pages,; just big enough to hold the configurable minimum number of elements (64 by default).; Page sizes are doubled as more data is filled into them.; When a page reaches the maximum page size (see above), it is flushed.; When the overall page budget is reached,; pages larger than the page at hand are flushed before the page at hand is flushed.; For the parallel writer, every fill context maintains the page memory budget independently. Note that the total amount of memory consumed for writing is usually larger than the write page budget.; For instance, if buffered writing is used (the default), additional memory is required.; Use RNTupleModel::EstimateWriteMemoryUsage() for the total estimated memory use for writing. The default values are tuned for a total write memory of around 300 MB per writer resp. fill context.; In order to decrease the memory consumption,; users should decrease the target cluster size before tuning more intricate memory settings. Notes; =====. Approximation of the compressed cluster size; --------------------------------------------. The estimator for the compressed cluster size uses the average compression factor; of the so far written clusters.; This has been choosen as a simple, yet expectedly accurate enough estimator (to be validated).; The following alternative strategies were discussed:. - The average compression factor of all so-far written pages.; Easy to implement.; It would better prevent outlier clusters from skewing the estimate of the successor clusters.; It would be slower though in adjusting to systematic changes in the data set,; e.g. ones that are caused by changing experimental conditions during data taking. - The average over a window of the last $k$ clusters, possibly with exponential smoothing.; More code compared to the average compression factor or all so-far written clusters.; It would be faster in adjusting to system",MatchSource.DOCS,tree/ntuple/v7/doc/tuning.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/tuning.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/tuning.md:4460,Energy Efficiency,reduce,reduce,4460,"imator for the compressed cluster size uses the average compression factor; of the so far written clusters.; This has been choosen as a simple, yet expectedly accurate enough estimator (to be validated).; The following alternative strategies were discussed:. - The average compression factor of all so-far written pages.; Easy to implement.; It would better prevent outlier clusters from skewing the estimate of the successor clusters.; It would be slower though in adjusting to systematic changes in the data set,; e.g. ones that are caused by changing experimental conditions during data taking. - The average over a window of the last $k$ clusters, possibly with exponential smoothing.; More code compared to the average compression factor or all so-far written clusters.; It would be faster in adjusting to systematic changes in the data set,; e.g. ones that are caused by changing experimental conditions during data taking.; Could be a viable option if cluster compression ratios turn out to change significantly in a single file. - Calculate the cluster compression ratio from column-based individual estimators.; More complex to implement and to recalculate the estimator on every fill,; requires additional state for every column.; One might reduce the additional state and complexity by only applying the fine-grained estimator for collections.; Such an estimator would react better to a sudden change in the amount of data written for collections / columns; that have substentially different compression ratios. Page Checksums; --------------. By default, RNTuple appends xxhash-3 64bit checksums to every compressed page.; Typically, checksums increase the data size in the region of a per mille.; As a side effect, page checksums allow for efficient ""same page merging"":; identical pages in the same cluster will be written only once.; On typical datasets, same page merging saves a few percent.; Conversely, turning off page checksums also disables the same page merging optimization.; ",MatchSource.DOCS,tree/ntuple/v7/doc/tuning.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/tuning.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/tuning.md:4962,Energy Efficiency,efficient,efficient,4962,"imator for the compressed cluster size uses the average compression factor; of the so far written clusters.; This has been choosen as a simple, yet expectedly accurate enough estimator (to be validated).; The following alternative strategies were discussed:. - The average compression factor of all so-far written pages.; Easy to implement.; It would better prevent outlier clusters from skewing the estimate of the successor clusters.; It would be slower though in adjusting to systematic changes in the data set,; e.g. ones that are caused by changing experimental conditions during data taking. - The average over a window of the last $k$ clusters, possibly with exponential smoothing.; More code compared to the average compression factor or all so-far written clusters.; It would be faster in adjusting to systematic changes in the data set,; e.g. ones that are caused by changing experimental conditions during data taking.; Could be a viable option if cluster compression ratios turn out to change significantly in a single file. - Calculate the cluster compression ratio from column-based individual estimators.; More complex to implement and to recalculate the estimator on every fill,; requires additional state for every column.; One might reduce the additional state and complexity by only applying the fine-grained estimator for collections.; Such an estimator would react better to a sudden change in the amount of data written for collections / columns; that have substentially different compression ratios. Page Checksums; --------------. By default, RNTuple appends xxhash-3 64bit checksums to every compressed page.; Typically, checksums increase the data size in the region of a per mille.; As a side effect, page checksums allow for efficient ""same page merging"":; identical pages in the same cluster will be written only once.; On typical datasets, same page merging saves a few percent.; Conversely, turning off page checksums also disables the same page merging optimization.; ",MatchSource.DOCS,tree/ntuple/v7/doc/tuning.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/tuning.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/tuning.md:1648,Modifiability,config,configurable,1648," read,; so larger clusters increase the memory footprint. A second option in `RNTupleWriteOptions` specifies the maximum uncompressed cluster size.; The default is 1 GiB.; This setting acts as an ""emergency break"" and should prevent very compressible clusters from growing too large. Given the two settings, writing works as follows:; when the current cluster is larger than the maximum uncompressed size, it will be flushed unconditionally.; When the current cluster size reaches the estimate for the compressed cluster size, it will be flushed, too.; The estimated compression ratio for the first cluster is 0.5 if compression is used, and 1 otherwise.; The following clusters use the average compression ratio of all so-far written clusters as an estimate.; See the notes below on a discussion of this approximation. Page Sizes; ==========. Pages contain consecutive elements of a certain column.; They are the unit of compression and of addressability on storage.; RNTuple puts a configurable maximum uncompressed size for pages.; This limit is by default set to 1 MiB.; When the limit is reached, a page will be flushed to disk. In addition, RNTuple maintains a memory budget for the combined allocated size of the pages that are currently filled.; By default, this limit is set to twice the compressed target cluster size when compression is used,; and to the cluster target size for uncompressed data.; Initially, and after flushing, all columns use small pages,; just big enough to hold the configurable minimum number of elements (64 by default).; Page sizes are doubled as more data is filled into them.; When a page reaches the maximum page size (see above), it is flushed.; When the overall page budget is reached,; pages larger than the page at hand are flushed before the page at hand is flushed.; For the parallel writer, every fill context maintains the page memory budget independently. Note that the total amount of memory consumed for writing is usually larger than the write page ",MatchSource.DOCS,tree/ntuple/v7/doc/tuning.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/tuning.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/tuning.md:2163,Modifiability,config,configurable,2163,"the estimate for the compressed cluster size, it will be flushed, too.; The estimated compression ratio for the first cluster is 0.5 if compression is used, and 1 otherwise.; The following clusters use the average compression ratio of all so-far written clusters as an estimate.; See the notes below on a discussion of this approximation. Page Sizes; ==========. Pages contain consecutive elements of a certain column.; They are the unit of compression and of addressability on storage.; RNTuple puts a configurable maximum uncompressed size for pages.; This limit is by default set to 1 MiB.; When the limit is reached, a page will be flushed to disk. In addition, RNTuple maintains a memory budget for the combined allocated size of the pages that are currently filled.; By default, this limit is set to twice the compressed target cluster size when compression is used,; and to the cluster target size for uncompressed data.; Initially, and after flushing, all columns use small pages,; just big enough to hold the configurable minimum number of elements (64 by default).; Page sizes are doubled as more data is filled into them.; When a page reaches the maximum page size (see above), it is flushed.; When the overall page budget is reached,; pages larger than the page at hand are flushed before the page at hand is flushed.; For the parallel writer, every fill context maintains the page memory budget independently. Note that the total amount of memory consumed for writing is usually larger than the write page budget.; For instance, if buffered writing is used (the default), additional memory is required.; Use RNTupleModel::EstimateWriteMemoryUsage() for the total estimated memory use for writing. The default values are tuned for a total write memory of around 300 MB per writer resp. fill context.; In order to decrease the memory consumption,; users should decrease the target cluster size before tuning more intricate memory settings. Notes; =====. Approximation of the compressed clus",MatchSource.DOCS,tree/ntuple/v7/doc/tuning.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/tuning.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/tuning.md:2878,Performance,tune,tuned,2878," currently filled.; By default, this limit is set to twice the compressed target cluster size when compression is used,; and to the cluster target size for uncompressed data.; Initially, and after flushing, all columns use small pages,; just big enough to hold the configurable minimum number of elements (64 by default).; Page sizes are doubled as more data is filled into them.; When a page reaches the maximum page size (see above), it is flushed.; When the overall page budget is reached,; pages larger than the page at hand are flushed before the page at hand is flushed.; For the parallel writer, every fill context maintains the page memory budget independently. Note that the total amount of memory consumed for writing is usually larger than the write page budget.; For instance, if buffered writing is used (the default), additional memory is required.; Use RNTupleModel::EstimateWriteMemoryUsage() for the total estimated memory use for writing. The default values are tuned for a total write memory of around 300 MB per writer resp. fill context.; In order to decrease the memory consumption,; users should decrease the target cluster size before tuning more intricate memory settings. Notes; =====. Approximation of the compressed cluster size; --------------------------------------------. The estimator for the compressed cluster size uses the average compression factor; of the so far written clusters.; This has been choosen as a simple, yet expectedly accurate enough estimator (to be validated).; The following alternative strategies were discussed:. - The average compression factor of all so-far written pages.; Easy to implement.; It would better prevent outlier clusters from skewing the estimate of the successor clusters.; It would be slower though in adjusting to systematic changes in the data set,; e.g. ones that are caused by changing experimental conditions during data taking. - The average over a window of the last $k$ clusters, possibly with exponential smoothing.;",MatchSource.DOCS,tree/ntuple/v7/doc/tuning.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/tuning.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/tuning.md:5194,Performance,optimiz,optimization,5194,"imator for the compressed cluster size uses the average compression factor; of the so far written clusters.; This has been choosen as a simple, yet expectedly accurate enough estimator (to be validated).; The following alternative strategies were discussed:. - The average compression factor of all so-far written pages.; Easy to implement.; It would better prevent outlier clusters from skewing the estimate of the successor clusters.; It would be slower though in adjusting to systematic changes in the data set,; e.g. ones that are caused by changing experimental conditions during data taking. - The average over a window of the last $k$ clusters, possibly with exponential smoothing.; More code compared to the average compression factor or all so-far written clusters.; It would be faster in adjusting to systematic changes in the data set,; e.g. ones that are caused by changing experimental conditions during data taking.; Could be a viable option if cluster compression ratios turn out to change significantly in a single file. - Calculate the cluster compression ratio from column-based individual estimators.; More complex to implement and to recalculate the estimator on every fill,; requires additional state for every column.; One might reduce the additional state and complexity by only applying the fine-grained estimator for collections.; Such an estimator would react better to a sudden change in the amount of data written for collections / columns; that have substentially different compression ratios. Page Checksums; --------------. By default, RNTuple appends xxhash-3 64bit checksums to every compressed page.; Typically, checksums increase the data size in the region of a per mille.; As a side effect, page checksums allow for efficient ""same page merging"":; identical pages in the same cluster will be written only once.; On typical datasets, same page merging saves a few percent.; Conversely, turning off page checksums also disables the same page merging optimization.; ",MatchSource.DOCS,tree/ntuple/v7/doc/tuning.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/tuning.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/tuning.md:3401,Security,validat,validated,3401,"ll page budget is reached,; pages larger than the page at hand are flushed before the page at hand is flushed.; For the parallel writer, every fill context maintains the page memory budget independently. Note that the total amount of memory consumed for writing is usually larger than the write page budget.; For instance, if buffered writing is used (the default), additional memory is required.; Use RNTupleModel::EstimateWriteMemoryUsage() for the total estimated memory use for writing. The default values are tuned for a total write memory of around 300 MB per writer resp. fill context.; In order to decrease the memory consumption,; users should decrease the target cluster size before tuning more intricate memory settings. Notes; =====. Approximation of the compressed cluster size; --------------------------------------------. The estimator for the compressed cluster size uses the average compression factor; of the so far written clusters.; This has been choosen as a simple, yet expectedly accurate enough estimator (to be validated).; The following alternative strategies were discussed:. - The average compression factor of all so-far written pages.; Easy to implement.; It would better prevent outlier clusters from skewing the estimate of the successor clusters.; It would be slower though in adjusting to systematic changes in the data set,; e.g. ones that are caused by changing experimental conditions during data taking. - The average over a window of the last $k$ clusters, possibly with exponential smoothing.; More code compared to the average compression factor or all so-far written clusters.; It would be faster in adjusting to systematic changes in the data set,; e.g. ones that are caused by changing experimental conditions during data taking.; Could be a viable option if cluster compression ratios turn out to change significantly in a single file. - Calculate the cluster compression ratio from column-based individual estimators.; More complex to implement and to r",MatchSource.DOCS,tree/ntuple/v7/doc/tuning.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/tuning.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/tuning.md:4807,Security,checksum,checksums,4807,"imator for the compressed cluster size uses the average compression factor; of the so far written clusters.; This has been choosen as a simple, yet expectedly accurate enough estimator (to be validated).; The following alternative strategies were discussed:. - The average compression factor of all so-far written pages.; Easy to implement.; It would better prevent outlier clusters from skewing the estimate of the successor clusters.; It would be slower though in adjusting to systematic changes in the data set,; e.g. ones that are caused by changing experimental conditions during data taking. - The average over a window of the last $k$ clusters, possibly with exponential smoothing.; More code compared to the average compression factor or all so-far written clusters.; It would be faster in adjusting to systematic changes in the data set,; e.g. ones that are caused by changing experimental conditions during data taking.; Could be a viable option if cluster compression ratios turn out to change significantly in a single file. - Calculate the cluster compression ratio from column-based individual estimators.; More complex to implement and to recalculate the estimator on every fill,; requires additional state for every column.; One might reduce the additional state and complexity by only applying the fine-grained estimator for collections.; Such an estimator would react better to a sudden change in the amount of data written for collections / columns; that have substentially different compression ratios. Page Checksums; --------------. By default, RNTuple appends xxhash-3 64bit checksums to every compressed page.; Typically, checksums increase the data size in the region of a per mille.; As a side effect, page checksums allow for efficient ""same page merging"":; identical pages in the same cluster will be written only once.; On typical datasets, same page merging saves a few percent.; Conversely, turning off page checksums also disables the same page merging optimization.; ",MatchSource.DOCS,tree/ntuple/v7/doc/tuning.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/tuning.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/tuning.md:4855,Security,checksum,checksums,4855,"imator for the compressed cluster size uses the average compression factor; of the so far written clusters.; This has been choosen as a simple, yet expectedly accurate enough estimator (to be validated).; The following alternative strategies were discussed:. - The average compression factor of all so-far written pages.; Easy to implement.; It would better prevent outlier clusters from skewing the estimate of the successor clusters.; It would be slower though in adjusting to systematic changes in the data set,; e.g. ones that are caused by changing experimental conditions during data taking. - The average over a window of the last $k$ clusters, possibly with exponential smoothing.; More code compared to the average compression factor or all so-far written clusters.; It would be faster in adjusting to systematic changes in the data set,; e.g. ones that are caused by changing experimental conditions during data taking.; Could be a viable option if cluster compression ratios turn out to change significantly in a single file. - Calculate the cluster compression ratio from column-based individual estimators.; More complex to implement and to recalculate the estimator on every fill,; requires additional state for every column.; One might reduce the additional state and complexity by only applying the fine-grained estimator for collections.; Such an estimator would react better to a sudden change in the amount of data written for collections / columns; that have substentially different compression ratios. Page Checksums; --------------. By default, RNTuple appends xxhash-3 64bit checksums to every compressed page.; Typically, checksums increase the data size in the region of a per mille.; As a side effect, page checksums allow for efficient ""same page merging"":; identical pages in the same cluster will be written only once.; On typical datasets, same page merging saves a few percent.; Conversely, turning off page checksums also disables the same page merging optimization.; ",MatchSource.DOCS,tree/ntuple/v7/doc/tuning.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/tuning.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/tuning.md:4942,Security,checksum,checksums,4942,"imator for the compressed cluster size uses the average compression factor; of the so far written clusters.; This has been choosen as a simple, yet expectedly accurate enough estimator (to be validated).; The following alternative strategies were discussed:. - The average compression factor of all so-far written pages.; Easy to implement.; It would better prevent outlier clusters from skewing the estimate of the successor clusters.; It would be slower though in adjusting to systematic changes in the data set,; e.g. ones that are caused by changing experimental conditions during data taking. - The average over a window of the last $k$ clusters, possibly with exponential smoothing.; More code compared to the average compression factor or all so-far written clusters.; It would be faster in adjusting to systematic changes in the data set,; e.g. ones that are caused by changing experimental conditions during data taking.; Could be a viable option if cluster compression ratios turn out to change significantly in a single file. - Calculate the cluster compression ratio from column-based individual estimators.; More complex to implement and to recalculate the estimator on every fill,; requires additional state for every column.; One might reduce the additional state and complexity by only applying the fine-grained estimator for collections.; Such an estimator would react better to a sudden change in the amount of data written for collections / columns; that have substentially different compression ratios. Page Checksums; --------------. By default, RNTuple appends xxhash-3 64bit checksums to every compressed page.; Typically, checksums increase the data size in the region of a per mille.; As a side effect, page checksums allow for efficient ""same page merging"":; identical pages in the same cluster will be written only once.; On typical datasets, same page merging saves a few percent.; Conversely, turning off page checksums also disables the same page merging optimization.; ",MatchSource.DOCS,tree/ntuple/v7/doc/tuning.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/tuning.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/tuning.md:5148,Security,checksum,checksums,5148,"imator for the compressed cluster size uses the average compression factor; of the so far written clusters.; This has been choosen as a simple, yet expectedly accurate enough estimator (to be validated).; The following alternative strategies were discussed:. - The average compression factor of all so-far written pages.; Easy to implement.; It would better prevent outlier clusters from skewing the estimate of the successor clusters.; It would be slower though in adjusting to systematic changes in the data set,; e.g. ones that are caused by changing experimental conditions during data taking. - The average over a window of the last $k$ clusters, possibly with exponential smoothing.; More code compared to the average compression factor or all so-far written clusters.; It would be faster in adjusting to systematic changes in the data set,; e.g. ones that are caused by changing experimental conditions during data taking.; Could be a viable option if cluster compression ratios turn out to change significantly in a single file. - Calculate the cluster compression ratio from column-based individual estimators.; More complex to implement and to recalculate the estimator on every fill,; requires additional state for every column.; One might reduce the additional state and complexity by only applying the fine-grained estimator for collections.; Such an estimator would react better to a sudden change in the amount of data written for collections / columns; that have substentially different compression ratios. Page Checksums; --------------. By default, RNTuple appends xxhash-3 64bit checksums to every compressed page.; Typically, checksums increase the data size in the region of a per mille.; As a side effect, page checksums allow for efficient ""same page merging"":; identical pages in the same cluster will be written only once.; On typical datasets, same page merging saves a few percent.; Conversely, turning off page checksums also disables the same page merging optimization.; ",MatchSource.DOCS,tree/ntuple/v7/doc/tuning.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/tuning.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/tuning.md:254,Usability,guid,guideline,254,"Cluster Sizes; =============. A cluster contains all the data of a given event range.; As clusters are usually compressed and tied to event boundaries, an exact size cannot be enforced.; Instead, RNTuple uses a *target size* for the compressed data as a guideline for when to flush a cluster. The default cluster target size is 100 MB of compressed data.; The default can be changed by the `RNTupleWriteOptions`.; The default should work well in the majority of cases.; In general, larger clusters provide room for more and larger pages and should improve compression ratio and speed.; However, clusters also need to be buffered during write and (partially) during read,; so larger clusters increase the memory footprint. A second option in `RNTupleWriteOptions` specifies the maximum uncompressed cluster size.; The default is 1 GiB.; This setting acts as an ""emergency break"" and should prevent very compressible clusters from growing too large. Given the two settings, writing works as follows:; when the current cluster is larger than the maximum uncompressed size, it will be flushed unconditionally.; When the current cluster size reaches the estimate for the compressed cluster size, it will be flushed, too.; The estimated compression ratio for the first cluster is 0.5 if compression is used, and 1 otherwise.; The following clusters use the average compression ratio of all so-far written clusters as an estimate.; See the notes below on a discussion of this approximation. Page Sizes; ==========. Pages contain consecutive elements of a certain column.; They are the unit of compression and of addressability on storage.; RNTuple puts a configurable maximum uncompressed size for pages.; This limit is by default set to 1 MiB.; When the limit is reached, a page will be flushed to disk. In addition, RNTuple maintains a memory budget for the combined allocated size of the pages that are currently filled.; By default, this limit is set to twice the compressed target cluster size when comp",MatchSource.DOCS,tree/ntuple/v7/doc/tuning.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/tuning.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/tuning.md:3345,Usability,simpl,simple,3345,"ll page budget is reached,; pages larger than the page at hand are flushed before the page at hand is flushed.; For the parallel writer, every fill context maintains the page memory budget independently. Note that the total amount of memory consumed for writing is usually larger than the write page budget.; For instance, if buffered writing is used (the default), additional memory is required.; Use RNTupleModel::EstimateWriteMemoryUsage() for the total estimated memory use for writing. The default values are tuned for a total write memory of around 300 MB per writer resp. fill context.; In order to decrease the memory consumption,; users should decrease the target cluster size before tuning more intricate memory settings. Notes; =====. Approximation of the compressed cluster size; --------------------------------------------. The estimator for the compressed cluster size uses the average compression factor; of the so far written clusters.; This has been choosen as a simple, yet expectedly accurate enough estimator (to be validated).; The following alternative strategies were discussed:. - The average compression factor of all so-far written pages.; Easy to implement.; It would better prevent outlier clusters from skewing the estimate of the successor clusters.; It would be slower though in adjusting to systematic changes in the data set,; e.g. ones that are caused by changing experimental conditions during data taking. - The average over a window of the last $k$ clusters, possibly with exponential smoothing.; More code compared to the average compression factor or all so-far written clusters.; It would be faster in adjusting to systematic changes in the data set,; e.g. ones that are caused by changing experimental conditions during data taking.; Could be a viable option if cluster compression ratios turn out to change significantly in a single file. - Calculate the cluster compression ratio from column-based individual estimators.; More complex to implement and to r",MatchSource.DOCS,tree/ntuple/v7/doc/tuning.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/tuning.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/validation.md:297,Security,validat,validation,297,RNTuple Format and API Validation; =================================. This document is a stub.; It is meant to be edited during the RNTuple development phase until its transition into production.; The document should collect observables that need to be tested and verified; during the large-scale validation of RNTuple (we foresee test with petabyte-scale of volume and >10^5 files). Checks; ------. - Automatic sizing of cluster and page sizes:; check page size and cluster size histograms; ,MatchSource.DOCS,tree/ntuple/v7/doc/validation.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/validation.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/validation.md:89,Testability,stub,stub,89,RNTuple Format and API Validation; =================================. This document is a stub.; It is meant to be edited during the RNTuple development phase until its transition into production.; The document should collect observables that need to be tested and verified; during the large-scale validation of RNTuple (we foresee test with petabyte-scale of volume and >10^5 files). Checks; ------. - Automatic sizing of cluster and page sizes:; check page size and cluster size histograms; ,MatchSource.DOCS,tree/ntuple/v7/doc/validation.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/validation.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/validation.md:253,Testability,test,tested,253,RNTuple Format and API Validation; =================================. This document is a stub.; It is meant to be edited during the RNTuple development phase until its transition into production.; The document should collect observables that need to be tested and verified; during the large-scale validation of RNTuple (we foresee test with petabyte-scale of volume and >10^5 files). Checks; ------. - Automatic sizing of cluster and page sizes:; check page size and cluster size histograms; ,MatchSource.DOCS,tree/ntuple/v7/doc/validation.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/validation.md
https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/validation.md:331,Testability,test,test,331,RNTuple Format and API Validation; =================================. This document is a stub.; It is meant to be edited during the RNTuple development phase until its transition into production.; The document should collect observables that need to be tested and verified; during the large-scale validation of RNTuple (we foresee test with petabyte-scale of volume and >10^5 files). Checks; ------. - Automatic sizing of cluster and page sizes:; check page size and cluster size histograms; ,MatchSource.DOCS,tree/ntuple/v7/doc/validation.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tree/ntuple/v7/doc/validation.md
https://github.com/root-project/root/tree/v6-32-06/tutorials/dataframe/index.md:384,Availability,avail,available,384,"\addtogroup tutorial_dataframe. @{. [RDataFrame](classROOT_1_1RDataFrame.html) offers a high level interface for the analysis of data stored in [TTree](classTTree.html)s, [CSV files](classROOT_1_1RDF_1_1RCsvDS.html) and [other data formats](classROOT_1_1RDF_1_1RDataSource.html). In addition, multi-threading and other low-level optimisations allow users to exploit all the resources available on their machines transparently. In a nutshell:; ~~~{.cpp}; ROOT::EnableImplicitMT(); // Enable ROOT's implicit multi-threading; ROOT::RDataFrame d(""myTree"", ""file_*.root""); // Interface to TTree and TChain; auto histoA = d.Histo1D(""Branch_A""); // Book the filling of a histogram; auto histoB = d.Histo1D(""Branch_B""); // Book the filling of another histogram; // Data processing is triggered by the next line, which accesses a booked result for the first time; // All booked results are evaluated during the same parallel event loop.; histoA->Draw(); // <-- event loop runs here!; histoB->Draw(); // HistoB has already been filled, no event loop is run here; ~~~. Explore the examples below or go to [RDataFrame's user guide](classROOT_1_1RDataFrame.html). @}",MatchSource.DOCS,tutorials/dataframe/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/dataframe/index.md
https://github.com/root-project/root/tree/v6-32-06/tutorials/dataframe/index.md:99,Integrability,interface,interface,99,"\addtogroup tutorial_dataframe. @{. [RDataFrame](classROOT_1_1RDataFrame.html) offers a high level interface for the analysis of data stored in [TTree](classTTree.html)s, [CSV files](classROOT_1_1RDF_1_1RCsvDS.html) and [other data formats](classROOT_1_1RDF_1_1RDataSource.html). In addition, multi-threading and other low-level optimisations allow users to exploit all the resources available on their machines transparently. In a nutshell:; ~~~{.cpp}; ROOT::EnableImplicitMT(); // Enable ROOT's implicit multi-threading; ROOT::RDataFrame d(""myTree"", ""file_*.root""); // Interface to TTree and TChain; auto histoA = d.Histo1D(""Branch_A""); // Book the filling of a histogram; auto histoB = d.Histo1D(""Branch_B""); // Book the filling of another histogram; // Data processing is triggered by the next line, which accesses a booked result for the first time; // All booked results are evaluated during the same parallel event loop.; histoA->Draw(); // <-- event loop runs here!; histoB->Draw(); // HistoB has already been filled, no event loop is run here; ~~~. Explore the examples below or go to [RDataFrame's user guide](classROOT_1_1RDataFrame.html). @}",MatchSource.DOCS,tutorials/dataframe/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/dataframe/index.md
https://github.com/root-project/root/tree/v6-32-06/tutorials/dataframe/index.md:293,Performance,multi-thread,multi-threading,293,"\addtogroup tutorial_dataframe. @{. [RDataFrame](classROOT_1_1RDataFrame.html) offers a high level interface for the analysis of data stored in [TTree](classTTree.html)s, [CSV files](classROOT_1_1RDF_1_1RCsvDS.html) and [other data formats](classROOT_1_1RDF_1_1RDataSource.html). In addition, multi-threading and other low-level optimisations allow users to exploit all the resources available on their machines transparently. In a nutshell:; ~~~{.cpp}; ROOT::EnableImplicitMT(); // Enable ROOT's implicit multi-threading; ROOT::RDataFrame d(""myTree"", ""file_*.root""); // Interface to TTree and TChain; auto histoA = d.Histo1D(""Branch_A""); // Book the filling of a histogram; auto histoB = d.Histo1D(""Branch_B""); // Book the filling of another histogram; // Data processing is triggered by the next line, which accesses a booked result for the first time; // All booked results are evaluated during the same parallel event loop.; histoA->Draw(); // <-- event loop runs here!; histoB->Draw(); // HistoB has already been filled, no event loop is run here; ~~~. Explore the examples below or go to [RDataFrame's user guide](classROOT_1_1RDataFrame.html). @}",MatchSource.DOCS,tutorials/dataframe/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/dataframe/index.md
https://github.com/root-project/root/tree/v6-32-06/tutorials/dataframe/index.md:506,Performance,multi-thread,multi-threading,506,"\addtogroup tutorial_dataframe. @{. [RDataFrame](classROOT_1_1RDataFrame.html) offers a high level interface for the analysis of data stored in [TTree](classTTree.html)s, [CSV files](classROOT_1_1RDF_1_1RCsvDS.html) and [other data formats](classROOT_1_1RDF_1_1RDataSource.html). In addition, multi-threading and other low-level optimisations allow users to exploit all the resources available on their machines transparently. In a nutshell:; ~~~{.cpp}; ROOT::EnableImplicitMT(); // Enable ROOT's implicit multi-threading; ROOT::RDataFrame d(""myTree"", ""file_*.root""); // Interface to TTree and TChain; auto histoA = d.Histo1D(""Branch_A""); // Book the filling of a histogram; auto histoB = d.Histo1D(""Branch_B""); // Book the filling of another histogram; // Data processing is triggered by the next line, which accesses a booked result for the first time; // All booked results are evaluated during the same parallel event loop.; histoA->Draw(); // <-- event loop runs here!; histoB->Draw(); // HistoB has already been filled, no event loop is run here; ~~~. Explore the examples below or go to [RDataFrame's user guide](classROOT_1_1RDataFrame.html). @}",MatchSource.DOCS,tutorials/dataframe/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/dataframe/index.md
https://github.com/root-project/root/tree/v6-32-06/tutorials/dataframe/index.md:810,Security,access,accesses,810,"\addtogroup tutorial_dataframe. @{. [RDataFrame](classROOT_1_1RDataFrame.html) offers a high level interface for the analysis of data stored in [TTree](classTTree.html)s, [CSV files](classROOT_1_1RDF_1_1RCsvDS.html) and [other data formats](classROOT_1_1RDF_1_1RDataSource.html). In addition, multi-threading and other low-level optimisations allow users to exploit all the resources available on their machines transparently. In a nutshell:; ~~~{.cpp}; ROOT::EnableImplicitMT(); // Enable ROOT's implicit multi-threading; ROOT::RDataFrame d(""myTree"", ""file_*.root""); // Interface to TTree and TChain; auto histoA = d.Histo1D(""Branch_A""); // Book the filling of a histogram; auto histoB = d.Histo1D(""Branch_B""); // Book the filling of another histogram; // Data processing is triggered by the next line, which accesses a booked result for the first time; // All booked results are evaluated during the same parallel event loop.; histoA->Draw(); // <-- event loop runs here!; histoB->Draw(); // HistoB has already been filled, no event loop is run here; ~~~. Explore the examples below or go to [RDataFrame's user guide](classROOT_1_1RDataFrame.html). @}",MatchSource.DOCS,tutorials/dataframe/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/dataframe/index.md
https://github.com/root-project/root/tree/v6-32-06/tutorials/dataframe/index.md:1113,Usability,guid,guide,1113,"\addtogroup tutorial_dataframe. @{. [RDataFrame](classROOT_1_1RDataFrame.html) offers a high level interface for the analysis of data stored in [TTree](classTTree.html)s, [CSV files](classROOT_1_1RDF_1_1RCsvDS.html) and [other data formats](classROOT_1_1RDF_1_1RDataSource.html). In addition, multi-threading and other low-level optimisations allow users to exploit all the resources available on their machines transparently. In a nutshell:; ~~~{.cpp}; ROOT::EnableImplicitMT(); // Enable ROOT's implicit multi-threading; ROOT::RDataFrame d(""myTree"", ""file_*.root""); // Interface to TTree and TChain; auto histoA = d.Histo1D(""Branch_A""); // Book the filling of a histogram; auto histoB = d.Histo1D(""Branch_B""); // Book the filling of another histogram; // Data processing is triggered by the next line, which accesses a booked result for the first time; // All booked results are evaluated during the same parallel event loop.; histoA->Draw(); // <-- event loop runs here!; histoB->Draw(); // HistoB has already been filled, no event loop is run here; ~~~. Explore the examples below or go to [RDataFrame's user guide](classROOT_1_1RDataFrame.html). @}",MatchSource.DOCS,tutorials/dataframe/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/dataframe/index.md
https://github.com/root-project/root/tree/v6-32-06/tutorials/foam/index.md:2415,Availability,avail,available,2415,"OT shell. For more difficult problems the full FOAM may be better. ### How to run application programs ?. The application program can be run in two modes: it can be simply; interpreted by CLING or compiled. The first method is simpler but; results in slower execution. The second method employs ACLiC -; The Automatic Compiler of Libraries, which automatizes the; process of compilation and linking. In $(ROOTSYS)/tutorials there are 3 demonstration programs:. #### foam_kanwa.C; is a simple example how to run FOAM in interactive; mode. To run this macro issue the following simple command from the; Linux shell:. ```; root foam_kanwa.C; ```. or from CLING:. ```; root [0] .x foam_kanwa.C; ```. Simulation will start and graphical canvas with plot; of the distribution function appear. In this example; we defined the distribution function simply as a global; function function Camel2. #### foam_demo.C; shows usage of FOAM in compiled mode, which is; the preferred method. The integrand function is defined; now as a Density method from class TFDISTR inheriting from; abstract class TFoamIntegrand. User can modify interface to; integrand function according to their needs but they should; always remember to define Density method which provides the; density distribution.; Enter CLING interpreter and type:. ```; root [0] gSystem->Load(""libFoam.so""); root [1] .x foam_demo.C+; ```. to load FOAM library, compile and execute macro foam_demo.C.; A shared object foam_demo_C.so is created in the current; directory. At the end of exploration phase FOAM object; including distribution function will be written to disk. #### foam_demopers.C; demonstrates persistency of FOAM classes.; To run this macro type:. ```; root [0] .x foam_demopers.C; ```. Program reads the FOAM object from disk, checks its; consistency and prints geometry of cells. Next starts the; the generation. It can be interpreted directly by CLING; because compiled TFDISTR class is already available in; `foam_demo_C.so` library. @}",MatchSource.DOCS,tutorials/foam/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/foam/index.md
https://github.com/root-project/root/tree/v6-32-06/tutorials/foam/index.md:145,Deployability,integrat,integrator,145,"\addtogroup tutorial_FOAM. @{. ### What is FOAM ?. FOAM is simplified version of multi-dimensional general; purpose Monte Carlo event generator (integrator) with hyper-cubical; ""foam of cells"". Certain features of full version of FOAM are omitted.; mFOAM is intended as an easy to use tool for MC; simulation/integration in few dimensions. It relies heavily on ROOT package,; borrowing persistency of classes from ROOT. mFOAM can be easily used from; the ROOT shell. For more difficult problems the full FOAM may be better. ### How to run application programs ?. The application program can be run in two modes: it can be simply; interpreted by CLING or compiled. The first method is simpler but; results in slower execution. The second method employs ACLiC -; The Automatic Compiler of Libraries, which automatizes the; process of compilation and linking. In $(ROOTSYS)/tutorials there are 3 demonstration programs:. #### foam_kanwa.C; is a simple example how to run FOAM in interactive; mode. To run this macro issue the following simple command from the; Linux shell:. ```; root foam_kanwa.C; ```. or from CLING:. ```; root [0] .x foam_kanwa.C; ```. Simulation will start and graphical canvas with plot; of the distribution function appear. In this example; we defined the distribution function simply as a global; function function Camel2. #### foam_demo.C; shows usage of FOAM in compiled mode, which is; the preferred method. The integrand function is defined; now as a Density method from class TFDISTR inheriting from; abstract class TFoamIntegrand. User can modify interface to; integrand function according to their needs but they should; always remember to define Density method which provides the; density distribution.; Enter CLING interpreter and type:. ```; root [0] gSystem->Load(""libFoam.so""); root [1] .x foam_demo.C+; ```. to load FOAM library, compile and execute macro foam_demo.C.; A shared object foam_demo_C.so is created in the current; directory. At the end of exploration ph",MatchSource.DOCS,tutorials/foam/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/foam/index.md
https://github.com/root-project/root/tree/v6-32-06/tutorials/foam/index.md:309,Deployability,integrat,integration,309,"\addtogroup tutorial_FOAM. @{. ### What is FOAM ?. FOAM is simplified version of multi-dimensional general; purpose Monte Carlo event generator (integrator) with hyper-cubical; ""foam of cells"". Certain features of full version of FOAM are omitted.; mFOAM is intended as an easy to use tool for MC; simulation/integration in few dimensions. It relies heavily on ROOT package,; borrowing persistency of classes from ROOT. mFOAM can be easily used from; the ROOT shell. For more difficult problems the full FOAM may be better. ### How to run application programs ?. The application program can be run in two modes: it can be simply; interpreted by CLING or compiled. The first method is simpler but; results in slower execution. The second method employs ACLiC -; The Automatic Compiler of Libraries, which automatizes the; process of compilation and linking. In $(ROOTSYS)/tutorials there are 3 demonstration programs:. #### foam_kanwa.C; is a simple example how to run FOAM in interactive; mode. To run this macro issue the following simple command from the; Linux shell:. ```; root foam_kanwa.C; ```. or from CLING:. ```; root [0] .x foam_kanwa.C; ```. Simulation will start and graphical canvas with plot; of the distribution function appear. In this example; we defined the distribution function simply as a global; function function Camel2. #### foam_demo.C; shows usage of FOAM in compiled mode, which is; the preferred method. The integrand function is defined; now as a Density method from class TFDISTR inheriting from; abstract class TFoamIntegrand. User can modify interface to; integrand function according to their needs but they should; always remember to define Density method which provides the; density distribution.; Enter CLING interpreter and type:. ```; root [0] gSystem->Load(""libFoam.so""); root [1] .x foam_demo.C+; ```. to load FOAM library, compile and execute macro foam_demo.C.; A shared object foam_demo_C.so is created in the current; directory. At the end of exploration ph",MatchSource.DOCS,tutorials/foam/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/foam/index.md
https://github.com/root-project/root/tree/v6-32-06/tutorials/foam/index.md:145,Integrability,integrat,integrator,145,"\addtogroup tutorial_FOAM. @{. ### What is FOAM ?. FOAM is simplified version of multi-dimensional general; purpose Monte Carlo event generator (integrator) with hyper-cubical; ""foam of cells"". Certain features of full version of FOAM are omitted.; mFOAM is intended as an easy to use tool for MC; simulation/integration in few dimensions. It relies heavily on ROOT package,; borrowing persistency of classes from ROOT. mFOAM can be easily used from; the ROOT shell. For more difficult problems the full FOAM may be better. ### How to run application programs ?. The application program can be run in two modes: it can be simply; interpreted by CLING or compiled. The first method is simpler but; results in slower execution. The second method employs ACLiC -; The Automatic Compiler of Libraries, which automatizes the; process of compilation and linking. In $(ROOTSYS)/tutorials there are 3 demonstration programs:. #### foam_kanwa.C; is a simple example how to run FOAM in interactive; mode. To run this macro issue the following simple command from the; Linux shell:. ```; root foam_kanwa.C; ```. or from CLING:. ```; root [0] .x foam_kanwa.C; ```. Simulation will start and graphical canvas with plot; of the distribution function appear. In this example; we defined the distribution function simply as a global; function function Camel2. #### foam_demo.C; shows usage of FOAM in compiled mode, which is; the preferred method. The integrand function is defined; now as a Density method from class TFDISTR inheriting from; abstract class TFoamIntegrand. User can modify interface to; integrand function according to their needs but they should; always remember to define Density method which provides the; density distribution.; Enter CLING interpreter and type:. ```; root [0] gSystem->Load(""libFoam.so""); root [1] .x foam_demo.C+; ```. to load FOAM library, compile and execute macro foam_demo.C.; A shared object foam_demo_C.so is created in the current; directory. At the end of exploration ph",MatchSource.DOCS,tutorials/foam/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/foam/index.md
https://github.com/root-project/root/tree/v6-32-06/tutorials/foam/index.md:309,Integrability,integrat,integration,309,"\addtogroup tutorial_FOAM. @{. ### What is FOAM ?. FOAM is simplified version of multi-dimensional general; purpose Monte Carlo event generator (integrator) with hyper-cubical; ""foam of cells"". Certain features of full version of FOAM are omitted.; mFOAM is intended as an easy to use tool for MC; simulation/integration in few dimensions. It relies heavily on ROOT package,; borrowing persistency of classes from ROOT. mFOAM can be easily used from; the ROOT shell. For more difficult problems the full FOAM may be better. ### How to run application programs ?. The application program can be run in two modes: it can be simply; interpreted by CLING or compiled. The first method is simpler but; results in slower execution. The second method employs ACLiC -; The Automatic Compiler of Libraries, which automatizes the; process of compilation and linking. In $(ROOTSYS)/tutorials there are 3 demonstration programs:. #### foam_kanwa.C; is a simple example how to run FOAM in interactive; mode. To run this macro issue the following simple command from the; Linux shell:. ```; root foam_kanwa.C; ```. or from CLING:. ```; root [0] .x foam_kanwa.C; ```. Simulation will start and graphical canvas with plot; of the distribution function appear. In this example; we defined the distribution function simply as a global; function function Camel2. #### foam_demo.C; shows usage of FOAM in compiled mode, which is; the preferred method. The integrand function is defined; now as a Density method from class TFDISTR inheriting from; abstract class TFoamIntegrand. User can modify interface to; integrand function according to their needs but they should; always remember to define Density method which provides the; density distribution.; Enter CLING interpreter and type:. ```; root [0] gSystem->Load(""libFoam.so""); root [1] .x foam_demo.C+; ```. to load FOAM library, compile and execute macro foam_demo.C.; A shared object foam_demo_C.so is created in the current; directory. At the end of exploration ph",MatchSource.DOCS,tutorials/foam/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/foam/index.md
https://github.com/root-project/root/tree/v6-32-06/tutorials/foam/index.md:1574,Integrability,interface,interface,1574,"OT shell. For more difficult problems the full FOAM may be better. ### How to run application programs ?. The application program can be run in two modes: it can be simply; interpreted by CLING or compiled. The first method is simpler but; results in slower execution. The second method employs ACLiC -; The Automatic Compiler of Libraries, which automatizes the; process of compilation and linking. In $(ROOTSYS)/tutorials there are 3 demonstration programs:. #### foam_kanwa.C; is a simple example how to run FOAM in interactive; mode. To run this macro issue the following simple command from the; Linux shell:. ```; root foam_kanwa.C; ```. or from CLING:. ```; root [0] .x foam_kanwa.C; ```. Simulation will start and graphical canvas with plot; of the distribution function appear. In this example; we defined the distribution function simply as a global; function function Camel2. #### foam_demo.C; shows usage of FOAM in compiled mode, which is; the preferred method. The integrand function is defined; now as a Density method from class TFDISTR inheriting from; abstract class TFoamIntegrand. User can modify interface to; integrand function according to their needs but they should; always remember to define Density method which provides the; density distribution.; Enter CLING interpreter and type:. ```; root [0] gSystem->Load(""libFoam.so""); root [1] .x foam_demo.C+; ```. to load FOAM library, compile and execute macro foam_demo.C.; A shared object foam_demo_C.so is created in the current; directory. At the end of exploration phase FOAM object; including distribution function will be written to disk. #### foam_demopers.C; demonstrates persistency of FOAM classes.; To run this macro type:. ```; root [0] .x foam_demopers.C; ```. Program reads the FOAM object from disk, checks its; consistency and prints geometry of cells. Next starts the; the generation. It can be interpreted directly by CLING; because compiled TFDISTR class is already available in; `foam_demo_C.so` library. @}",MatchSource.DOCS,tutorials/foam/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/foam/index.md
https://github.com/root-project/root/tree/v6-32-06/tutorials/foam/index.md:1510,Modifiability,inherit,inheriting,1510,"OT shell. For more difficult problems the full FOAM may be better. ### How to run application programs ?. The application program can be run in two modes: it can be simply; interpreted by CLING or compiled. The first method is simpler but; results in slower execution. The second method employs ACLiC -; The Automatic Compiler of Libraries, which automatizes the; process of compilation and linking. In $(ROOTSYS)/tutorials there are 3 demonstration programs:. #### foam_kanwa.C; is a simple example how to run FOAM in interactive; mode. To run this macro issue the following simple command from the; Linux shell:. ```; root foam_kanwa.C; ```. or from CLING:. ```; root [0] .x foam_kanwa.C; ```. Simulation will start and graphical canvas with plot; of the distribution function appear. In this example; we defined the distribution function simply as a global; function function Camel2. #### foam_demo.C; shows usage of FOAM in compiled mode, which is; the preferred method. The integrand function is defined; now as a Density method from class TFDISTR inheriting from; abstract class TFoamIntegrand. User can modify interface to; integrand function according to their needs but they should; always remember to define Density method which provides the; density distribution.; Enter CLING interpreter and type:. ```; root [0] gSystem->Load(""libFoam.so""); root [1] .x foam_demo.C+; ```. to load FOAM library, compile and execute macro foam_demo.C.; A shared object foam_demo_C.so is created in the current; directory. At the end of exploration phase FOAM object; including distribution function will be written to disk. #### foam_demopers.C; demonstrates persistency of FOAM classes.; To run this macro type:. ```; root [0] .x foam_demopers.C; ```. Program reads the FOAM object from disk, checks its; consistency and prints geometry of cells. Next starts the; the generation. It can be interpreted directly by CLING; because compiled TFDISTR class is already available in; `foam_demo_C.so` library. @}",MatchSource.DOCS,tutorials/foam/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/foam/index.md
https://github.com/root-project/root/tree/v6-32-06/tutorials/foam/index.md:1845,Performance,load,load,1845,"OT shell. For more difficult problems the full FOAM may be better. ### How to run application programs ?. The application program can be run in two modes: it can be simply; interpreted by CLING or compiled. The first method is simpler but; results in slower execution. The second method employs ACLiC -; The Automatic Compiler of Libraries, which automatizes the; process of compilation and linking. In $(ROOTSYS)/tutorials there are 3 demonstration programs:. #### foam_kanwa.C; is a simple example how to run FOAM in interactive; mode. To run this macro issue the following simple command from the; Linux shell:. ```; root foam_kanwa.C; ```. or from CLING:. ```; root [0] .x foam_kanwa.C; ```. Simulation will start and graphical canvas with plot; of the distribution function appear. In this example; we defined the distribution function simply as a global; function function Camel2. #### foam_demo.C; shows usage of FOAM in compiled mode, which is; the preferred method. The integrand function is defined; now as a Density method from class TFDISTR inheriting from; abstract class TFoamIntegrand. User can modify interface to; integrand function according to their needs but they should; always remember to define Density method which provides the; density distribution.; Enter CLING interpreter and type:. ```; root [0] gSystem->Load(""libFoam.so""); root [1] .x foam_demo.C+; ```. to load FOAM library, compile and execute macro foam_demo.C.; A shared object foam_demo_C.so is created in the current; directory. At the end of exploration phase FOAM object; including distribution function will be written to disk. #### foam_demopers.C; demonstrates persistency of FOAM classes.; To run this macro type:. ```; root [0] .x foam_demopers.C; ```. Program reads the FOAM object from disk, checks its; consistency and prints geometry of cells. Next starts the; the generation. It can be interpreted directly by CLING; because compiled TFDISTR class is already available in; `foam_demo_C.so` library. @}",MatchSource.DOCS,tutorials/foam/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/foam/index.md
https://github.com/root-project/root/tree/v6-32-06/tutorials/foam/index.md:59,Usability,simpl,simplified,59,"\addtogroup tutorial_FOAM. @{. ### What is FOAM ?. FOAM is simplified version of multi-dimensional general; purpose Monte Carlo event generator (integrator) with hyper-cubical; ""foam of cells"". Certain features of full version of FOAM are omitted.; mFOAM is intended as an easy to use tool for MC; simulation/integration in few dimensions. It relies heavily on ROOT package,; borrowing persistency of classes from ROOT. mFOAM can be easily used from; the ROOT shell. For more difficult problems the full FOAM may be better. ### How to run application programs ?. The application program can be run in two modes: it can be simply; interpreted by CLING or compiled. The first method is simpler but; results in slower execution. The second method employs ACLiC -; The Automatic Compiler of Libraries, which automatizes the; process of compilation and linking. In $(ROOTSYS)/tutorials there are 3 demonstration programs:. #### foam_kanwa.C; is a simple example how to run FOAM in interactive; mode. To run this macro issue the following simple command from the; Linux shell:. ```; root foam_kanwa.C; ```. or from CLING:. ```; root [0] .x foam_kanwa.C; ```. Simulation will start and graphical canvas with plot; of the distribution function appear. In this example; we defined the distribution function simply as a global; function function Camel2. #### foam_demo.C; shows usage of FOAM in compiled mode, which is; the preferred method. The integrand function is defined; now as a Density method from class TFDISTR inheriting from; abstract class TFoamIntegrand. User can modify interface to; integrand function according to their needs but they should; always remember to define Density method which provides the; density distribution.; Enter CLING interpreter and type:. ```; root [0] gSystem->Load(""libFoam.so""); root [1] .x foam_demo.C+; ```. to load FOAM library, compile and execute macro foam_demo.C.; A shared object foam_demo_C.so is created in the current; directory. At the end of exploration ph",MatchSource.DOCS,tutorials/foam/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/foam/index.md
https://github.com/root-project/root/tree/v6-32-06/tutorials/foam/index.md:622,Usability,simpl,simply,622,"\addtogroup tutorial_FOAM. @{. ### What is FOAM ?. FOAM is simplified version of multi-dimensional general; purpose Monte Carlo event generator (integrator) with hyper-cubical; ""foam of cells"". Certain features of full version of FOAM are omitted.; mFOAM is intended as an easy to use tool for MC; simulation/integration in few dimensions. It relies heavily on ROOT package,; borrowing persistency of classes from ROOT. mFOAM can be easily used from; the ROOT shell. For more difficult problems the full FOAM may be better. ### How to run application programs ?. The application program can be run in two modes: it can be simply; interpreted by CLING or compiled. The first method is simpler but; results in slower execution. The second method employs ACLiC -; The Automatic Compiler of Libraries, which automatizes the; process of compilation and linking. In $(ROOTSYS)/tutorials there are 3 demonstration programs:. #### foam_kanwa.C; is a simple example how to run FOAM in interactive; mode. To run this macro issue the following simple command from the; Linux shell:. ```; root foam_kanwa.C; ```. or from CLING:. ```; root [0] .x foam_kanwa.C; ```. Simulation will start and graphical canvas with plot; of the distribution function appear. In this example; we defined the distribution function simply as a global; function function Camel2. #### foam_demo.C; shows usage of FOAM in compiled mode, which is; the preferred method. The integrand function is defined; now as a Density method from class TFDISTR inheriting from; abstract class TFoamIntegrand. User can modify interface to; integrand function according to their needs but they should; always remember to define Density method which provides the; density distribution.; Enter CLING interpreter and type:. ```; root [0] gSystem->Load(""libFoam.so""); root [1] .x foam_demo.C+; ```. to load FOAM library, compile and execute macro foam_demo.C.; A shared object foam_demo_C.so is created in the current; directory. At the end of exploration ph",MatchSource.DOCS,tutorials/foam/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/foam/index.md
https://github.com/root-project/root/tree/v6-32-06/tutorials/foam/index.md:684,Usability,simpl,simpler,684,"\addtogroup tutorial_FOAM. @{. ### What is FOAM ?. FOAM is simplified version of multi-dimensional general; purpose Monte Carlo event generator (integrator) with hyper-cubical; ""foam of cells"". Certain features of full version of FOAM are omitted.; mFOAM is intended as an easy to use tool for MC; simulation/integration in few dimensions. It relies heavily on ROOT package,; borrowing persistency of classes from ROOT. mFOAM can be easily used from; the ROOT shell. For more difficult problems the full FOAM may be better. ### How to run application programs ?. The application program can be run in two modes: it can be simply; interpreted by CLING or compiled. The first method is simpler but; results in slower execution. The second method employs ACLiC -; The Automatic Compiler of Libraries, which automatizes the; process of compilation and linking. In $(ROOTSYS)/tutorials there are 3 demonstration programs:. #### foam_kanwa.C; is a simple example how to run FOAM in interactive; mode. To run this macro issue the following simple command from the; Linux shell:. ```; root foam_kanwa.C; ```. or from CLING:. ```; root [0] .x foam_kanwa.C; ```. Simulation will start and graphical canvas with plot; of the distribution function appear. In this example; we defined the distribution function simply as a global; function function Camel2. #### foam_demo.C; shows usage of FOAM in compiled mode, which is; the preferred method. The integrand function is defined; now as a Density method from class TFDISTR inheriting from; abstract class TFoamIntegrand. User can modify interface to; integrand function according to their needs but they should; always remember to define Density method which provides the; density distribution.; Enter CLING interpreter and type:. ```; root [0] gSystem->Load(""libFoam.so""); root [1] .x foam_demo.C+; ```. to load FOAM library, compile and execute macro foam_demo.C.; A shared object foam_demo_C.so is created in the current; directory. At the end of exploration ph",MatchSource.DOCS,tutorials/foam/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/foam/index.md
https://github.com/root-project/root/tree/v6-32-06/tutorials/foam/index.md:942,Usability,simpl,simple,942,"\addtogroup tutorial_FOAM. @{. ### What is FOAM ?. FOAM is simplified version of multi-dimensional general; purpose Monte Carlo event generator (integrator) with hyper-cubical; ""foam of cells"". Certain features of full version of FOAM are omitted.; mFOAM is intended as an easy to use tool for MC; simulation/integration in few dimensions. It relies heavily on ROOT package,; borrowing persistency of classes from ROOT. mFOAM can be easily used from; the ROOT shell. For more difficult problems the full FOAM may be better. ### How to run application programs ?. The application program can be run in two modes: it can be simply; interpreted by CLING or compiled. The first method is simpler but; results in slower execution. The second method employs ACLiC -; The Automatic Compiler of Libraries, which automatizes the; process of compilation and linking. In $(ROOTSYS)/tutorials there are 3 demonstration programs:. #### foam_kanwa.C; is a simple example how to run FOAM in interactive; mode. To run this macro issue the following simple command from the; Linux shell:. ```; root foam_kanwa.C; ```. or from CLING:. ```; root [0] .x foam_kanwa.C; ```. Simulation will start and graphical canvas with plot; of the distribution function appear. In this example; we defined the distribution function simply as a global; function function Camel2. #### foam_demo.C; shows usage of FOAM in compiled mode, which is; the preferred method. The integrand function is defined; now as a Density method from class TFDISTR inheriting from; abstract class TFoamIntegrand. User can modify interface to; integrand function according to their needs but they should; always remember to define Density method which provides the; density distribution.; Enter CLING interpreter and type:. ```; root [0] gSystem->Load(""libFoam.so""); root [1] .x foam_demo.C+; ```. to load FOAM library, compile and execute macro foam_demo.C.; A shared object foam_demo_C.so is created in the current; directory. At the end of exploration ph",MatchSource.DOCS,tutorials/foam/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/foam/index.md
https://github.com/root-project/root/tree/v6-32-06/tutorials/foam/index.md:1033,Usability,simpl,simple,1033,"## What is FOAM ?. FOAM is simplified version of multi-dimensional general; purpose Monte Carlo event generator (integrator) with hyper-cubical; ""foam of cells"". Certain features of full version of FOAM are omitted.; mFOAM is intended as an easy to use tool for MC; simulation/integration in few dimensions. It relies heavily on ROOT package,; borrowing persistency of classes from ROOT. mFOAM can be easily used from; the ROOT shell. For more difficult problems the full FOAM may be better. ### How to run application programs ?. The application program can be run in two modes: it can be simply; interpreted by CLING or compiled. The first method is simpler but; results in slower execution. The second method employs ACLiC -; The Automatic Compiler of Libraries, which automatizes the; process of compilation and linking. In $(ROOTSYS)/tutorials there are 3 demonstration programs:. #### foam_kanwa.C; is a simple example how to run FOAM in interactive; mode. To run this macro issue the following simple command from the; Linux shell:. ```; root foam_kanwa.C; ```. or from CLING:. ```; root [0] .x foam_kanwa.C; ```. Simulation will start and graphical canvas with plot; of the distribution function appear. In this example; we defined the distribution function simply as a global; function function Camel2. #### foam_demo.C; shows usage of FOAM in compiled mode, which is; the preferred method. The integrand function is defined; now as a Density method from class TFDISTR inheriting from; abstract class TFoamIntegrand. User can modify interface to; integrand function according to their needs but they should; always remember to define Density method which provides the; density distribution.; Enter CLING interpreter and type:. ```; root [0] gSystem->Load(""libFoam.so""); root [1] .x foam_demo.C+; ```. to load FOAM library, compile and execute macro foam_demo.C.; A shared object foam_demo_C.so is created in the current; directory. At the end of exploration phase FOAM object; including distr",MatchSource.DOCS,tutorials/foam/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/foam/index.md
https://github.com/root-project/root/tree/v6-32-06/tutorials/foam/index.md:1298,Usability,simpl,simply,1298," MC; simulation/integration in few dimensions. It relies heavily on ROOT package,; borrowing persistency of classes from ROOT. mFOAM can be easily used from; the ROOT shell. For more difficult problems the full FOAM may be better. ### How to run application programs ?. The application program can be run in two modes: it can be simply; interpreted by CLING or compiled. The first method is simpler but; results in slower execution. The second method employs ACLiC -; The Automatic Compiler of Libraries, which automatizes the; process of compilation and linking. In $(ROOTSYS)/tutorials there are 3 demonstration programs:. #### foam_kanwa.C; is a simple example how to run FOAM in interactive; mode. To run this macro issue the following simple command from the; Linux shell:. ```; root foam_kanwa.C; ```. or from CLING:. ```; root [0] .x foam_kanwa.C; ```. Simulation will start and graphical canvas with plot; of the distribution function appear. In this example; we defined the distribution function simply as a global; function function Camel2. #### foam_demo.C; shows usage of FOAM in compiled mode, which is; the preferred method. The integrand function is defined; now as a Density method from class TFDISTR inheriting from; abstract class TFoamIntegrand. User can modify interface to; integrand function according to their needs but they should; always remember to define Density method which provides the; density distribution.; Enter CLING interpreter and type:. ```; root [0] gSystem->Load(""libFoam.so""); root [1] .x foam_demo.C+; ```. to load FOAM library, compile and execute macro foam_demo.C.; A shared object foam_demo_C.so is created in the current; directory. At the end of exploration phase FOAM object; including distribution function will be written to disk. #### foam_demopers.C; demonstrates persistency of FOAM classes.; To run this macro type:. ```; root [0] .x foam_demopers.C; ```. Program reads the FOAM object from disk, checks its; consistency and prints geometry of c",MatchSource.DOCS,tutorials/foam/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/foam/index.md
https://github.com/root-project/root/tree/v6-32-06/tutorials/legacy/index.md:70,Integrability,interface,interfaces,70,"\addtogroup tutorial_legacy. @{. Some of ROOT's tutorials demonstrate interfaces that are not recommended anymore, because; ROOT or C++ itself now offer superior ones. These have been moved here ""for the record"". @}; ",MatchSource.DOCS,tutorials/legacy/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/legacy/index.md
https://github.com/root-project/root/tree/v6-32-06/tutorials/proof/index.md:161,Testability,test,testing,161,"\defgroup tutorial_ProcFileElements ProcFileElements; \ingroup tutorial_proof; \brief Class to hold information about the processed elements of a file. Used for testing. \defgroup tutorial_ProofAux ProofAux; \ingroup tutorial_proof; \brief Selector used for auxiliary actions in the PROOF tutorials. \defgroup tutorial_ProofEvent ProofEvent; \ingroup tutorial_proof; \brief Selector for generic processing with Event. Example of TSelector implementation to do generic; processing with the test 'Event' structure.; See tutorials/proof/runProof.C, option ""event"", for an; example of how to run this selector. \defgroup tutorial_ProofEventProc ProofEventProc; \ingroup tutorial_proof; \brief Selector to process trees containing Event structures. Example of TSelector implementation to process trees; containing 'Event' structures, e.g. the files under; http://root.cern/files/data .; See tutorials/proof/runProof.C, option ""eventproc"", for; an example of how to run this selector. \defgroup tutorial_ProofFriends ProofFriends; \ingroup tutorial_proof; \brief Selector to process tree friends. Example of TSelector implementation to process tree friends in PROOF.; See tutorials/proof/runProof.C, option ""eventproc"", for; an example of how to run this selector. \defgroup tutorial_ProofNtuple ProofNtuple; \ingroup tutorial_proof; \brief Selector to fill a simple ntuple. Example of TSelector implementation to do generic processing; (filling a simple ntuple, in this case).; See tutorials/proof/runProof.C, option ""ntuple"", for an; example of how to run this selector. \defgroup tutorial_ProofPythia ProofPythia; \ingroup tutorial_proof; \brief Selector to generate Monte Carlo events with Pythia8. Example of TSelector implementation to do a Monte Carlo; generation using Pythia8.; See tutorials/proof/runProof.C, option ""pythia8"", for an; example of how to run this selector. \defgroup tutorial_ProofSimple ProofSimple; \ingroup tutorial_proof; \brief Selector to fill a set of histograms. Example of ",MatchSource.DOCS,tutorials/proof/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/proof/index.md
https://github.com/root-project/root/tree/v6-32-06/tutorials/proof/index.md:489,Testability,test,test,489,"\defgroup tutorial_ProcFileElements ProcFileElements; \ingroup tutorial_proof; \brief Class to hold information about the processed elements of a file. Used for testing. \defgroup tutorial_ProofAux ProofAux; \ingroup tutorial_proof; \brief Selector used for auxiliary actions in the PROOF tutorials. \defgroup tutorial_ProofEvent ProofEvent; \ingroup tutorial_proof; \brief Selector for generic processing with Event. Example of TSelector implementation to do generic; processing with the test 'Event' structure.; See tutorials/proof/runProof.C, option ""event"", for an; example of how to run this selector. \defgroup tutorial_ProofEventProc ProofEventProc; \ingroup tutorial_proof; \brief Selector to process trees containing Event structures. Example of TSelector implementation to process trees; containing 'Event' structures, e.g. the files under; http://root.cern/files/data .; See tutorials/proof/runProof.C, option ""eventproc"", for; an example of how to run this selector. \defgroup tutorial_ProofFriends ProofFriends; \ingroup tutorial_proof; \brief Selector to process tree friends. Example of TSelector implementation to process tree friends in PROOF.; See tutorials/proof/runProof.C, option ""eventproc"", for; an example of how to run this selector. \defgroup tutorial_ProofNtuple ProofNtuple; \ingroup tutorial_proof; \brief Selector to fill a simple ntuple. Example of TSelector implementation to do generic processing; (filling a simple ntuple, in this case).; See tutorials/proof/runProof.C, option ""ntuple"", for an; example of how to run this selector. \defgroup tutorial_ProofPythia ProofPythia; \ingroup tutorial_proof; \brief Selector to generate Monte Carlo events with Pythia8. Example of TSelector implementation to do a Monte Carlo; generation using Pythia8.; See tutorials/proof/runProof.C, option ""pythia8"", for an; example of how to run this selector. \defgroup tutorial_ProofSimple ProofSimple; \ingroup tutorial_proof; \brief Selector to fill a set of histograms. Example of ",MatchSource.DOCS,tutorials/proof/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/proof/index.md
https://github.com/root-project/root/tree/v6-32-06/tutorials/proof/index.md:3031,Testability,test,test,3031,"Selector to process tree friends. Example of TSelector implementation to process tree friends in PROOF.; See tutorials/proof/runProof.C, option ""eventproc"", for; an example of how to run this selector. \defgroup tutorial_ProofNtuple ProofNtuple; \ingroup tutorial_proof; \brief Selector to fill a simple ntuple. Example of TSelector implementation to do generic processing; (filling a simple ntuple, in this case).; See tutorials/proof/runProof.C, option ""ntuple"", for an; example of how to run this selector. \defgroup tutorial_ProofPythia ProofPythia; \ingroup tutorial_proof; \brief Selector to generate Monte Carlo events with Pythia8. Example of TSelector implementation to do a Monte Carlo; generation using Pythia8.; See tutorials/proof/runProof.C, option ""pythia8"", for an; example of how to run this selector. \defgroup tutorial_ProofSimple ProofSimple; \ingroup tutorial_proof; \brief Selector to fill a set of histograms. Example of TSelector implementation to do generic processing (filling a; set of histograms in this case).; See tutorials/proof/runProof.C, option ""simple"", for an; example of how to run this selector. \defgroup tutorial_ProofSimpleFile ProofSimpleFile; \ingroup tutorial_proof; \brief Selector to fill a set of histograms and merging via file. Example of TSelector implementation to do generic processing; (filling a set of histograms in this case) and merging via; a file, with part of the objects saved in a sub-directory.; See tutorials/proof/runProof.C, option ""simplefile"", for an; example of how to run this selector. \defgroup tutorial_ProofStdVec ProofStdVec; \ingroup tutorial_proof; \brief Selector for generic processing with stdlib collections. Example of TSelector implementation to do generic; processing with stdlib collections.; See tutorials/proof/runProof.C, option ""stdlib"", for an; example of how to run this selector. \defgroup tutorial_ProofTests ProofTests; \ingroup tutorial_proof; \brief Auxilliary selector used to test PROOF functionality; ",MatchSource.DOCS,tutorials/proof/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/proof/index.md
https://github.com/root-project/root/tree/v6-32-06/tutorials/proof/index.md:1354,Usability,simpl,simple,1354,"orial_ProofEvent ProofEvent; \ingroup tutorial_proof; \brief Selector for generic processing with Event. Example of TSelector implementation to do generic; processing with the test 'Event' structure.; See tutorials/proof/runProof.C, option ""event"", for an; example of how to run this selector. \defgroup tutorial_ProofEventProc ProofEventProc; \ingroup tutorial_proof; \brief Selector to process trees containing Event structures. Example of TSelector implementation to process trees; containing 'Event' structures, e.g. the files under; http://root.cern/files/data .; See tutorials/proof/runProof.C, option ""eventproc"", for; an example of how to run this selector. \defgroup tutorial_ProofFriends ProofFriends; \ingroup tutorial_proof; \brief Selector to process tree friends. Example of TSelector implementation to process tree friends in PROOF.; See tutorials/proof/runProof.C, option ""eventproc"", for; an example of how to run this selector. \defgroup tutorial_ProofNtuple ProofNtuple; \ingroup tutorial_proof; \brief Selector to fill a simple ntuple. Example of TSelector implementation to do generic processing; (filling a simple ntuple, in this case).; See tutorials/proof/runProof.C, option ""ntuple"", for an; example of how to run this selector. \defgroup tutorial_ProofPythia ProofPythia; \ingroup tutorial_proof; \brief Selector to generate Monte Carlo events with Pythia8. Example of TSelector implementation to do a Monte Carlo; generation using Pythia8.; See tutorials/proof/runProof.C, option ""pythia8"", for an; example of how to run this selector. \defgroup tutorial_ProofSimple ProofSimple; \ingroup tutorial_proof; \brief Selector to fill a set of histograms. Example of TSelector implementation to do generic processing (filling a; set of histograms in this case).; See tutorials/proof/runProof.C, option ""simple"", for an; example of how to run this selector. \defgroup tutorial_ProofSimpleFile ProofSimpleFile; \ingroup tutorial_proof; \brief Selector to fill a set of histograms a",MatchSource.DOCS,tutorials/proof/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/proof/index.md
https://github.com/root-project/root/tree/v6-32-06/tutorials/proof/index.md:1442,Usability,simpl,simple,1442,"xample of TSelector implementation to do generic; processing with the test 'Event' structure.; See tutorials/proof/runProof.C, option ""event"", for an; example of how to run this selector. \defgroup tutorial_ProofEventProc ProofEventProc; \ingroup tutorial_proof; \brief Selector to process trees containing Event structures. Example of TSelector implementation to process trees; containing 'Event' structures, e.g. the files under; http://root.cern/files/data .; See tutorials/proof/runProof.C, option ""eventproc"", for; an example of how to run this selector. \defgroup tutorial_ProofFriends ProofFriends; \ingroup tutorial_proof; \brief Selector to process tree friends. Example of TSelector implementation to process tree friends in PROOF.; See tutorials/proof/runProof.C, option ""eventproc"", for; an example of how to run this selector. \defgroup tutorial_ProofNtuple ProofNtuple; \ingroup tutorial_proof; \brief Selector to fill a simple ntuple. Example of TSelector implementation to do generic processing; (filling a simple ntuple, in this case).; See tutorials/proof/runProof.C, option ""ntuple"", for an; example of how to run this selector. \defgroup tutorial_ProofPythia ProofPythia; \ingroup tutorial_proof; \brief Selector to generate Monte Carlo events with Pythia8. Example of TSelector implementation to do a Monte Carlo; generation using Pythia8.; See tutorials/proof/runProof.C, option ""pythia8"", for an; example of how to run this selector. \defgroup tutorial_ProofSimple ProofSimple; \ingroup tutorial_proof; \brief Selector to fill a set of histograms. Example of TSelector implementation to do generic processing (filling a; set of histograms in this case).; See tutorials/proof/runProof.C, option ""simple"", for an; example of how to run this selector. \defgroup tutorial_ProofSimpleFile ProofSimpleFile; \ingroup tutorial_proof; \brief Selector to fill a set of histograms and merging via file. Example of TSelector implementation to do generic processing; (filling a set of histog",MatchSource.DOCS,tutorials/proof/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/proof/index.md
https://github.com/root-project/root/tree/v6-32-06/tutorials/proof/index.md:2137,Usability,simpl,simple,2137,"Selector to process tree friends. Example of TSelector implementation to process tree friends in PROOF.; See tutorials/proof/runProof.C, option ""eventproc"", for; an example of how to run this selector. \defgroup tutorial_ProofNtuple ProofNtuple; \ingroup tutorial_proof; \brief Selector to fill a simple ntuple. Example of TSelector implementation to do generic processing; (filling a simple ntuple, in this case).; See tutorials/proof/runProof.C, option ""ntuple"", for an; example of how to run this selector. \defgroup tutorial_ProofPythia ProofPythia; \ingroup tutorial_proof; \brief Selector to generate Monte Carlo events with Pythia8. Example of TSelector implementation to do a Monte Carlo; generation using Pythia8.; See tutorials/proof/runProof.C, option ""pythia8"", for an; example of how to run this selector. \defgroup tutorial_ProofSimple ProofSimple; \ingroup tutorial_proof; \brief Selector to fill a set of histograms. Example of TSelector implementation to do generic processing (filling a; set of histograms in this case).; See tutorials/proof/runProof.C, option ""simple"", for an; example of how to run this selector. \defgroup tutorial_ProofSimpleFile ProofSimpleFile; \ingroup tutorial_proof; \brief Selector to fill a set of histograms and merging via file. Example of TSelector implementation to do generic processing; (filling a set of histograms in this case) and merging via; a file, with part of the objects saved in a sub-directory.; See tutorials/proof/runProof.C, option ""simplefile"", for an; example of how to run this selector. \defgroup tutorial_ProofStdVec ProofStdVec; \ingroup tutorial_proof; \brief Selector for generic processing with stdlib collections. Example of TSelector implementation to do generic; processing with stdlib collections.; See tutorials/proof/runProof.C, option ""stdlib"", for an; example of how to run this selector. \defgroup tutorial_ProofTests ProofTests; \ingroup tutorial_proof; \brief Auxilliary selector used to test PROOF functionality; ",MatchSource.DOCS,tutorials/proof/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/proof/index.md
https://github.com/root-project/root/tree/v6-32-06/tutorials/proof/index.md:2556,Usability,simpl,simplefile,2556,"Selector to process tree friends. Example of TSelector implementation to process tree friends in PROOF.; See tutorials/proof/runProof.C, option ""eventproc"", for; an example of how to run this selector. \defgroup tutorial_ProofNtuple ProofNtuple; \ingroup tutorial_proof; \brief Selector to fill a simple ntuple. Example of TSelector implementation to do generic processing; (filling a simple ntuple, in this case).; See tutorials/proof/runProof.C, option ""ntuple"", for an; example of how to run this selector. \defgroup tutorial_ProofPythia ProofPythia; \ingroup tutorial_proof; \brief Selector to generate Monte Carlo events with Pythia8. Example of TSelector implementation to do a Monte Carlo; generation using Pythia8.; See tutorials/proof/runProof.C, option ""pythia8"", for an; example of how to run this selector. \defgroup tutorial_ProofSimple ProofSimple; \ingroup tutorial_proof; \brief Selector to fill a set of histograms. Example of TSelector implementation to do generic processing (filling a; set of histograms in this case).; See tutorials/proof/runProof.C, option ""simple"", for an; example of how to run this selector. \defgroup tutorial_ProofSimpleFile ProofSimpleFile; \ingroup tutorial_proof; \brief Selector to fill a set of histograms and merging via file. Example of TSelector implementation to do generic processing; (filling a set of histograms in this case) and merging via; a file, with part of the objects saved in a sub-directory.; See tutorials/proof/runProof.C, option ""simplefile"", for an; example of how to run this selector. \defgroup tutorial_ProofStdVec ProofStdVec; \ingroup tutorial_proof; \brief Selector for generic processing with stdlib collections. Example of TSelector implementation to do generic; processing with stdlib collections.; See tutorials/proof/runProof.C, option ""stdlib"", for an; example of how to run this selector. \defgroup tutorial_ProofTests ProofTests; \ingroup tutorial_proof; \brief Auxilliary selector used to test PROOF functionality; ",MatchSource.DOCS,tutorials/proof/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/proof/index.md
https://github.com/root-project/root/tree/v6-32-06/tutorials/vecops/index.md:115,Usability,guid,guide,115,\addtogroup tutorial_vecops. @{. Please note that you can find the exhaustive documentation [here in the reference guide](<https://root.cern/doc/master/classROOT_1_1VecOps_1_1RVec.html>). @}; ,MatchSource.DOCS,tutorials/vecops/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/vecops/index.md
https://github.com/root-project/root/tree/v6-32-06/tutorials/doc/v600/index.md:51,Testability,test,test,51,. ## Tutorials. - The new tutorial `timeonaxis3.C` test the time axis.; - New version of cernbluid.C allowing to turn off the printouts.; - New tutorial `image2hist` showing how to convert an image to a 2D; histogram. ,MatchSource.DOCS,tutorials/doc/v600/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/doc/v600/index.md
https://github.com/root-project/root/tree/v6-32-06/tutorials/tmva/keras/index.md:147,Integrability,interface,interface,147,\defgroup tutorial_tmva_keras TMVA Keras tutorials; \ingroup tutorial_tmva; \brief Example code which illustrates how to use keras with the python interface of TMVA; ,MatchSource.DOCS,tutorials/tmva/keras/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/tmva/keras/index.md
https://github.com/root-project/root/tree/v6-32-06/tutorials/tmva/pytorch/index.md:153,Integrability,interface,interface,153,\defgroup tutorial_tmva_pytorch TMVA PyTorch tutorials; \ingroup tutorial_tmva; \brief Example code which illustrates how to use pytorch with the python interface of TMVA; ,MatchSource.DOCS,tutorials/tmva/pytorch/index.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/tmva/pytorch/index.md
https://github.com/root-project/root/tree/v6-32-06/tutorials/tree/dictionary/README.md:693,Integrability,interface,interfaces,693,"How to read and write custom classes in TTree; =============================================. This example shows how to use ROOT as a toolkit to write and read a TTree containing custom classes. # Starting steps. 1. Build the project, it requires ROOT. ```; cmake -B build -S . ; cmake --build build ; ```. 2. Run the executable. ```; ./build/treeExample; ```. 3. Inspect the output rootfile, and the source code. . # Files. This example shows how to use ROOT as a library in a C++ project. The C++ main function is defined in the file main.cpp. The code that writes the TTree onto disk is contained in the file writeTree.cxx. The files readTree.cxx and readTreeDF.cxx show two different ROOT interfaces to read a TTree. The files data2tree.* contain the code for the custom class that fills the TTree. ## Definition of custom class. The TTree can be seen as a collection of objects (branches), with a number of attributes (leaves). The name of the branch corresponds to the name of the instantiated object. The name of the leaves corresponds to the name of the attributes. The class that is present in the TTree is declared in the file data2tree.hpp, and the methods defined in the file data2tree.cpp. . To be able to read and write objects of a particular user-defined type, ROOT I/O needs to know some information about the class/struct, e.g. the class members and their types, offset of each data member, etc. This information is contained in a ROOT dictionary; see [I/O of custom classes](https://root.cern/manual/io_custom_classes/#generating-dictionaries) for more information. The linkdef file contains some instructions for ROOT, to specify which classes will require a dictionary:. ```; #pragma link C++ class myFancyClass+;; ```. If for example `std::vector` of such class is also used in the TTree as well, it should be notified to ROOT as another separated instruction:. ```; #pragma link C++ class std::vector<myFancyClass>+;; ```. # Links: ; * ROOT documentation: https://root.cern/manu",MatchSource.DOCS,tutorials/tree/dictionary/README.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/tree/dictionary/README.md
https://github.com/root-project/root/tree/v6-32-06/tutorials/webgui/panel/Readme.md:323,Modifiability,config,configure,323,"## OPENUI5 Panel example. This is simplest way to use openui5 widget with RWebWindow. It is normal xml::View, but controller should be derived from rootui5/panel/Controller.; This class provides methods, which simplify handling of communication between server and client. First of all, when creating RWebWindow, one should configure panel name. Like:. auto win = ROOT::RWebWindow::Create();. win->SetPanelName(""localapp.view.TestPanel"");. Namespace ""localapp"" in this case corresponds to openui5 files, which will be loaded from current directory.; Therefore `""localapp.view.TestPanel""` means view, which will be loaded from `./view/TestPanel.view.xml` file. Controller is configured in the XML file and called `""localapp.controller.TestPanel""`.; Means it will be loaded from `./controller/TestPanel.controller.js` file. In the controller one use `onPanelInit` and `onPanelExit` methods to handle initialization and close of widget.; Method `panelSend` should be used to send string data to the server. ",MatchSource.DOCS,tutorials/webgui/panel/Readme.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/webgui/panel/Readme.md
https://github.com/root-project/root/tree/v6-32-06/tutorials/webgui/panel/Readme.md:673,Modifiability,config,configured,673,"## OPENUI5 Panel example. This is simplest way to use openui5 widget with RWebWindow. It is normal xml::View, but controller should be derived from rootui5/panel/Controller.; This class provides methods, which simplify handling of communication between server and client. First of all, when creating RWebWindow, one should configure panel name. Like:. auto win = ROOT::RWebWindow::Create();. win->SetPanelName(""localapp.view.TestPanel"");. Namespace ""localapp"" in this case corresponds to openui5 files, which will be loaded from current directory.; Therefore `""localapp.view.TestPanel""` means view, which will be loaded from `./view/TestPanel.view.xml` file. Controller is configured in the XML file and called `""localapp.controller.TestPanel""`.; Means it will be loaded from `./controller/TestPanel.controller.js` file. In the controller one use `onPanelInit` and `onPanelExit` methods to handle initialization and close of widget.; Method `panelSend` should be used to send string data to the server. ",MatchSource.DOCS,tutorials/webgui/panel/Readme.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/webgui/panel/Readme.md
https://github.com/root-project/root/tree/v6-32-06/tutorials/webgui/panel/Readme.md:517,Performance,load,loaded,517,"## OPENUI5 Panel example. This is simplest way to use openui5 widget with RWebWindow. It is normal xml::View, but controller should be derived from rootui5/panel/Controller.; This class provides methods, which simplify handling of communication between server and client. First of all, when creating RWebWindow, one should configure panel name. Like:. auto win = ROOT::RWebWindow::Create();. win->SetPanelName(""localapp.view.TestPanel"");. Namespace ""localapp"" in this case corresponds to openui5 files, which will be loaded from current directory.; Therefore `""localapp.view.TestPanel""` means view, which will be loaded from `./view/TestPanel.view.xml` file. Controller is configured in the XML file and called `""localapp.controller.TestPanel""`.; Means it will be loaded from `./controller/TestPanel.controller.js` file. In the controller one use `onPanelInit` and `onPanelExit` methods to handle initialization and close of widget.; Method `panelSend` should be used to send string data to the server. ",MatchSource.DOCS,tutorials/webgui/panel/Readme.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/webgui/panel/Readme.md
https://github.com/root-project/root/tree/v6-32-06/tutorials/webgui/panel/Readme.md:613,Performance,load,loaded,613,"## OPENUI5 Panel example. This is simplest way to use openui5 widget with RWebWindow. It is normal xml::View, but controller should be derived from rootui5/panel/Controller.; This class provides methods, which simplify handling of communication between server and client. First of all, when creating RWebWindow, one should configure panel name. Like:. auto win = ROOT::RWebWindow::Create();. win->SetPanelName(""localapp.view.TestPanel"");. Namespace ""localapp"" in this case corresponds to openui5 files, which will be loaded from current directory.; Therefore `""localapp.view.TestPanel""` means view, which will be loaded from `./view/TestPanel.view.xml` file. Controller is configured in the XML file and called `""localapp.controller.TestPanel""`.; Means it will be loaded from `./controller/TestPanel.controller.js` file. In the controller one use `onPanelInit` and `onPanelExit` methods to handle initialization and close of widget.; Method `panelSend` should be used to send string data to the server. ",MatchSource.DOCS,tutorials/webgui/panel/Readme.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/webgui/panel/Readme.md
https://github.com/root-project/root/tree/v6-32-06/tutorials/webgui/panel/Readme.md:764,Performance,load,loaded,764,"## OPENUI5 Panel example. This is simplest way to use openui5 widget with RWebWindow. It is normal xml::View, but controller should be derived from rootui5/panel/Controller.; This class provides methods, which simplify handling of communication between server and client. First of all, when creating RWebWindow, one should configure panel name. Like:. auto win = ROOT::RWebWindow::Create();. win->SetPanelName(""localapp.view.TestPanel"");. Namespace ""localapp"" in this case corresponds to openui5 files, which will be loaded from current directory.; Therefore `""localapp.view.TestPanel""` means view, which will be loaded from `./view/TestPanel.view.xml` file. Controller is configured in the XML file and called `""localapp.controller.TestPanel""`.; Means it will be loaded from `./controller/TestPanel.controller.js` file. In the controller one use `onPanelInit` and `onPanelExit` methods to handle initialization and close of widget.; Method `panelSend` should be used to send string data to the server. ",MatchSource.DOCS,tutorials/webgui/panel/Readme.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/webgui/panel/Readme.md
https://github.com/root-project/root/tree/v6-32-06/tutorials/webgui/panel/Readme.md:34,Usability,simpl,simplest,34,"## OPENUI5 Panel example. This is simplest way to use openui5 widget with RWebWindow. It is normal xml::View, but controller should be derived from rootui5/panel/Controller.; This class provides methods, which simplify handling of communication between server and client. First of all, when creating RWebWindow, one should configure panel name. Like:. auto win = ROOT::RWebWindow::Create();. win->SetPanelName(""localapp.view.TestPanel"");. Namespace ""localapp"" in this case corresponds to openui5 files, which will be loaded from current directory.; Therefore `""localapp.view.TestPanel""` means view, which will be loaded from `./view/TestPanel.view.xml` file. Controller is configured in the XML file and called `""localapp.controller.TestPanel""`.; Means it will be loaded from `./controller/TestPanel.controller.js` file. In the controller one use `onPanelInit` and `onPanelExit` methods to handle initialization and close of widget.; Method `panelSend` should be used to send string data to the server. ",MatchSource.DOCS,tutorials/webgui/panel/Readme.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/webgui/panel/Readme.md
https://github.com/root-project/root/tree/v6-32-06/tutorials/webgui/panel/Readme.md:210,Usability,simpl,simplify,210,"## OPENUI5 Panel example. This is simplest way to use openui5 widget with RWebWindow. It is normal xml::View, but controller should be derived from rootui5/panel/Controller.; This class provides methods, which simplify handling of communication between server and client. First of all, when creating RWebWindow, one should configure panel name. Like:. auto win = ROOT::RWebWindow::Create();. win->SetPanelName(""localapp.view.TestPanel"");. Namespace ""localapp"" in this case corresponds to openui5 files, which will be loaded from current directory.; Therefore `""localapp.view.TestPanel""` means view, which will be loaded from `./view/TestPanel.view.xml` file. Controller is configured in the XML file and called `""localapp.controller.TestPanel""`.; Means it will be loaded from `./controller/TestPanel.controller.js` file. In the controller one use `onPanelInit` and `onPanelExit` methods to handle initialization and close of widget.; Method `panelSend` should be used to send string data to the server. ",MatchSource.DOCS,tutorials/webgui/panel/Readme.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/webgui/panel/Readme.md
https://github.com/root-project/root/tree/v6-32-06/tutorials/webgui/ping/Readme.md:108,Availability,ping,ping,108,"# Latency tests for RWebWindow. Provide round-trip test under different conditions.; To run, execute `root ""ping.cxx(10,0)""`, where first argument is number of connections tested and; second argument is running mode. Can be tested:; 0 - default communication, no extra threads; 1 - minimal timer for THttpServer, should reduce round-trip significantly; 2 - use special thread for process requests in THttpServer, web window also runs in the thread; 3 - in addition to special THttpThread also window starts own thread; 4 - let invoke webwindow callbacks in the civetweb threads, expert mode only. One also can perform same tests with longpoll emulation of web sockets, if adding 10 to second parameter. When running in batch mode, function blocked until 200 round-trip packets send by the client; or 50s elappsed. Therefore ping.cxx test can be used for RWebWindow functionality tests ; like `root -l -b ""ping.cxx(10,2)"" -q`; ",MatchSource.DOCS,tutorials/webgui/ping/Readme.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/webgui/ping/Readme.md
https://github.com/root-project/root/tree/v6-32-06/tutorials/webgui/ping/Readme.md:824,Availability,ping,ping,824,"# Latency tests for RWebWindow. Provide round-trip test under different conditions.; To run, execute `root ""ping.cxx(10,0)""`, where first argument is number of connections tested and; second argument is running mode. Can be tested:; 0 - default communication, no extra threads; 1 - minimal timer for THttpServer, should reduce round-trip significantly; 2 - use special thread for process requests in THttpServer, web window also runs in the thread; 3 - in addition to special THttpThread also window starts own thread; 4 - let invoke webwindow callbacks in the civetweb threads, expert mode only. One also can perform same tests with longpoll emulation of web sockets, if adding 10 to second parameter. When running in batch mode, function blocked until 200 round-trip packets send by the client; or 50s elappsed. Therefore ping.cxx test can be used for RWebWindow functionality tests ; like `root -l -b ""ping.cxx(10,2)"" -q`; ",MatchSource.DOCS,tutorials/webgui/ping/Readme.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/webgui/ping/Readme.md
https://github.com/root-project/root/tree/v6-32-06/tutorials/webgui/ping/Readme.md:905,Availability,ping,ping,905,"# Latency tests for RWebWindow. Provide round-trip test under different conditions.; To run, execute `root ""ping.cxx(10,0)""`, where first argument is number of connections tested and; second argument is running mode. Can be tested:; 0 - default communication, no extra threads; 1 - minimal timer for THttpServer, should reduce round-trip significantly; 2 - use special thread for process requests in THttpServer, web window also runs in the thread; 3 - in addition to special THttpThread also window starts own thread; 4 - let invoke webwindow callbacks in the civetweb threads, expert mode only. One also can perform same tests with longpoll emulation of web sockets, if adding 10 to second parameter. When running in batch mode, function blocked until 200 round-trip packets send by the client; or 50s elappsed. Therefore ping.cxx test can be used for RWebWindow functionality tests ; like `root -l -b ""ping.cxx(10,2)"" -q`; ",MatchSource.DOCS,tutorials/webgui/ping/Readme.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/webgui/ping/Readme.md
https://github.com/root-project/root/tree/v6-32-06/tutorials/webgui/ping/Readme.md:320,Energy Efficiency,reduce,reduce,320,"# Latency tests for RWebWindow. Provide round-trip test under different conditions.; To run, execute `root ""ping.cxx(10,0)""`, where first argument is number of connections tested and; second argument is running mode. Can be tested:; 0 - default communication, no extra threads; 1 - minimal timer for THttpServer, should reduce round-trip significantly; 2 - use special thread for process requests in THttpServer, web window also runs in the thread; 3 - in addition to special THttpThread also window starts own thread; 4 - let invoke webwindow callbacks in the civetweb threads, expert mode only. One also can perform same tests with longpoll emulation of web sockets, if adding 10 to second parameter. When running in batch mode, function blocked until 200 round-trip packets send by the client; or 50s elappsed. Therefore ping.cxx test can be used for RWebWindow functionality tests ; like `root -l -b ""ping.cxx(10,2)"" -q`; ",MatchSource.DOCS,tutorials/webgui/ping/Readme.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/webgui/ping/Readme.md
https://github.com/root-project/root/tree/v6-32-06/tutorials/webgui/ping/Readme.md:610,Performance,perform,perform,610,"# Latency tests for RWebWindow. Provide round-trip test under different conditions.; To run, execute `root ""ping.cxx(10,0)""`, where first argument is number of connections tested and; second argument is running mode. Can be tested:; 0 - default communication, no extra threads; 1 - minimal timer for THttpServer, should reduce round-trip significantly; 2 - use special thread for process requests in THttpServer, web window also runs in the thread; 3 - in addition to special THttpThread also window starts own thread; 4 - let invoke webwindow callbacks in the civetweb threads, expert mode only. One also can perform same tests with longpoll emulation of web sockets, if adding 10 to second parameter. When running in batch mode, function blocked until 200 round-trip packets send by the client; or 50s elappsed. Therefore ping.cxx test can be used for RWebWindow functionality tests ; like `root -l -b ""ping.cxx(10,2)"" -q`; ",MatchSource.DOCS,tutorials/webgui/ping/Readme.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/webgui/ping/Readme.md
https://github.com/root-project/root/tree/v6-32-06/tutorials/webgui/ping/Readme.md:10,Testability,test,tests,10,"# Latency tests for RWebWindow. Provide round-trip test under different conditions.; To run, execute `root ""ping.cxx(10,0)""`, where first argument is number of connections tested and; second argument is running mode. Can be tested:; 0 - default communication, no extra threads; 1 - minimal timer for THttpServer, should reduce round-trip significantly; 2 - use special thread for process requests in THttpServer, web window also runs in the thread; 3 - in addition to special THttpThread also window starts own thread; 4 - let invoke webwindow callbacks in the civetweb threads, expert mode only. One also can perform same tests with longpoll emulation of web sockets, if adding 10 to second parameter. When running in batch mode, function blocked until 200 round-trip packets send by the client; or 50s elappsed. Therefore ping.cxx test can be used for RWebWindow functionality tests ; like `root -l -b ""ping.cxx(10,2)"" -q`; ",MatchSource.DOCS,tutorials/webgui/ping/Readme.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/webgui/ping/Readme.md
https://github.com/root-project/root/tree/v6-32-06/tutorials/webgui/ping/Readme.md:51,Testability,test,test,51,"# Latency tests for RWebWindow. Provide round-trip test under different conditions.; To run, execute `root ""ping.cxx(10,0)""`, where first argument is number of connections tested and; second argument is running mode. Can be tested:; 0 - default communication, no extra threads; 1 - minimal timer for THttpServer, should reduce round-trip significantly; 2 - use special thread for process requests in THttpServer, web window also runs in the thread; 3 - in addition to special THttpThread also window starts own thread; 4 - let invoke webwindow callbacks in the civetweb threads, expert mode only. One also can perform same tests with longpoll emulation of web sockets, if adding 10 to second parameter. When running in batch mode, function blocked until 200 round-trip packets send by the client; or 50s elappsed. Therefore ping.cxx test can be used for RWebWindow functionality tests ; like `root -l -b ""ping.cxx(10,2)"" -q`; ",MatchSource.DOCS,tutorials/webgui/ping/Readme.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/webgui/ping/Readme.md
https://github.com/root-project/root/tree/v6-32-06/tutorials/webgui/ping/Readme.md:172,Testability,test,tested,172,"# Latency tests for RWebWindow. Provide round-trip test under different conditions.; To run, execute `root ""ping.cxx(10,0)""`, where first argument is number of connections tested and; second argument is running mode. Can be tested:; 0 - default communication, no extra threads; 1 - minimal timer for THttpServer, should reduce round-trip significantly; 2 - use special thread for process requests in THttpServer, web window also runs in the thread; 3 - in addition to special THttpThread also window starts own thread; 4 - let invoke webwindow callbacks in the civetweb threads, expert mode only. One also can perform same tests with longpoll emulation of web sockets, if adding 10 to second parameter. When running in batch mode, function blocked until 200 round-trip packets send by the client; or 50s elappsed. Therefore ping.cxx test can be used for RWebWindow functionality tests ; like `root -l -b ""ping.cxx(10,2)"" -q`; ",MatchSource.DOCS,tutorials/webgui/ping/Readme.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/webgui/ping/Readme.md
https://github.com/root-project/root/tree/v6-32-06/tutorials/webgui/ping/Readme.md:224,Testability,test,tested,224,"# Latency tests for RWebWindow. Provide round-trip test under different conditions.; To run, execute `root ""ping.cxx(10,0)""`, where first argument is number of connections tested and; second argument is running mode. Can be tested:; 0 - default communication, no extra threads; 1 - minimal timer for THttpServer, should reduce round-trip significantly; 2 - use special thread for process requests in THttpServer, web window also runs in the thread; 3 - in addition to special THttpThread also window starts own thread; 4 - let invoke webwindow callbacks in the civetweb threads, expert mode only. One also can perform same tests with longpoll emulation of web sockets, if adding 10 to second parameter. When running in batch mode, function blocked until 200 round-trip packets send by the client; or 50s elappsed. Therefore ping.cxx test can be used for RWebWindow functionality tests ; like `root -l -b ""ping.cxx(10,2)"" -q`; ",MatchSource.DOCS,tutorials/webgui/ping/Readme.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/webgui/ping/Readme.md
https://github.com/root-project/root/tree/v6-32-06/tutorials/webgui/ping/Readme.md:623,Testability,test,tests,623,"# Latency tests for RWebWindow. Provide round-trip test under different conditions.; To run, execute `root ""ping.cxx(10,0)""`, where first argument is number of connections tested and; second argument is running mode. Can be tested:; 0 - default communication, no extra threads; 1 - minimal timer for THttpServer, should reduce round-trip significantly; 2 - use special thread for process requests in THttpServer, web window also runs in the thread; 3 - in addition to special THttpThread also window starts own thread; 4 - let invoke webwindow callbacks in the civetweb threads, expert mode only. One also can perform same tests with longpoll emulation of web sockets, if adding 10 to second parameter. When running in batch mode, function blocked until 200 round-trip packets send by the client; or 50s elappsed. Therefore ping.cxx test can be used for RWebWindow functionality tests ; like `root -l -b ""ping.cxx(10,2)"" -q`; ",MatchSource.DOCS,tutorials/webgui/ping/Readme.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/webgui/ping/Readme.md
https://github.com/root-project/root/tree/v6-32-06/tutorials/webgui/ping/Readme.md:833,Testability,test,test,833,"# Latency tests for RWebWindow. Provide round-trip test under different conditions.; To run, execute `root ""ping.cxx(10,0)""`, where first argument is number of connections tested and; second argument is running mode. Can be tested:; 0 - default communication, no extra threads; 1 - minimal timer for THttpServer, should reduce round-trip significantly; 2 - use special thread for process requests in THttpServer, web window also runs in the thread; 3 - in addition to special THttpThread also window starts own thread; 4 - let invoke webwindow callbacks in the civetweb threads, expert mode only. One also can perform same tests with longpoll emulation of web sockets, if adding 10 to second parameter. When running in batch mode, function blocked until 200 round-trip packets send by the client; or 50s elappsed. Therefore ping.cxx test can be used for RWebWindow functionality tests ; like `root -l -b ""ping.cxx(10,2)"" -q`; ",MatchSource.DOCS,tutorials/webgui/ping/Readme.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/webgui/ping/Readme.md
https://github.com/root-project/root/tree/v6-32-06/tutorials/webgui/ping/Readme.md:879,Testability,test,tests,879,"# Latency tests for RWebWindow. Provide round-trip test under different conditions.; To run, execute `root ""ping.cxx(10,0)""`, where first argument is number of connections tested and; second argument is running mode. Can be tested:; 0 - default communication, no extra threads; 1 - minimal timer for THttpServer, should reduce round-trip significantly; 2 - use special thread for process requests in THttpServer, web window also runs in the thread; 3 - in addition to special THttpThread also window starts own thread; 4 - let invoke webwindow callbacks in the civetweb threads, expert mode only. One also can perform same tests with longpoll emulation of web sockets, if adding 10 to second parameter. When running in batch mode, function blocked until 200 round-trip packets send by the client; or 50s elappsed. Therefore ping.cxx test can be used for RWebWindow functionality tests ; like `root -l -b ""ping.cxx(10,2)"" -q`; ",MatchSource.DOCS,tutorials/webgui/ping/Readme.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/webgui/ping/Readme.md
https://github.com/root-project/root/tree/v6-32-06/tutorials/webgui/qtweb/Readme.md:234,Modifiability,config,configured,234,"# qtweb example. Demonstration how different ROOT web-based widgets can be embed into qt application. ## Compile on Linux. Create build directory and call:. cmake $ROOTSYS/tutorials/webgui/qtweb; make -j. ROOT should be compiled with configured `-Dqt5web=ON` or `-Dqt6web=ON`.; If both are present, one can use selector `-Dwithqt=5` or `-Dwithqt=6`; As a result, `qtweb` application should be created. ## Compile on Windows. Run x86 native tools shell from MS VC. Configure Qt5 pathes:. set PATH=%PATH%;C:\Qt5\5.15.2\msvc2019\bin. Compile ROOT with qt5web support in Release mode:. cd C:\; mkdir root; cd C:\root; cmake -G""Visual Studio 16 2019"" -A Win32 -Thost=x64 c:\git\root -Droot7=ON -DCMAKE_CXX_STANDARD=17 -Dwebgui=ON -Dqt5web=ON; cmake --build . --config Release -- /maxcpucount. Configure ROOT, create build directory and build qt5web tutorial:. call C:\root\bin\thisroot.bat; cd C:\; mkdir qt5web; cd C:\qt5web; cmake -G""Visual Studio 16 2019"" -A Win32 -Thost=x64 c:\root\tutorials\webgui\qtweb; cmake --build . --config Release -- /maxcpucount. As a result, `Release\qtweb.exe` executable should be created. ## Demo application. Application based on `QTabWidget` with four tabs - standard Qt widget,; TCanvas, RCanvas and geometry drawing. Both canvas variants include different histograms drawing. ## How to include RCanvas/TCanvas into other Qt-based project. Most easy way - just include `RCanvasWidget.h` and `RCanvasWidget.cpp` files; in the project and let compile, linking with ROOT basic libraries `root-config --libs` plus `-lROOTWebDisplay -lROOTGpadv7`.; `RCanvasWidget` is just `QWidget` which internally embed `RCanvas` drawing.; See `ExampleWidget.ui` file how to embed such custom widget in normal qt ui file. To let ROOT work inside Qt event loop, one should instantiate `TApplication` object and; regularly call `gSystem->ProcessEvents()` - see how it is done in `ExampleMain.cpp`. Author: Sergey Linev; ",MatchSource.DOCS,tutorials/webgui/qtweb/Readme.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/webgui/qtweb/Readme.md
https://github.com/root-project/root/tree/v6-32-06/tutorials/webgui/qtweb/Readme.md:756,Modifiability,config,config,756,"# qtweb example. Demonstration how different ROOT web-based widgets can be embed into qt application. ## Compile on Linux. Create build directory and call:. cmake $ROOTSYS/tutorials/webgui/qtweb; make -j. ROOT should be compiled with configured `-Dqt5web=ON` or `-Dqt6web=ON`.; If both are present, one can use selector `-Dwithqt=5` or `-Dwithqt=6`; As a result, `qtweb` application should be created. ## Compile on Windows. Run x86 native tools shell from MS VC. Configure Qt5 pathes:. set PATH=%PATH%;C:\Qt5\5.15.2\msvc2019\bin. Compile ROOT with qt5web support in Release mode:. cd C:\; mkdir root; cd C:\root; cmake -G""Visual Studio 16 2019"" -A Win32 -Thost=x64 c:\git\root -Droot7=ON -DCMAKE_CXX_STANDARD=17 -Dwebgui=ON -Dqt5web=ON; cmake --build . --config Release -- /maxcpucount. Configure ROOT, create build directory and build qt5web tutorial:. call C:\root\bin\thisroot.bat; cd C:\; mkdir qt5web; cd C:\qt5web; cmake -G""Visual Studio 16 2019"" -A Win32 -Thost=x64 c:\root\tutorials\webgui\qtweb; cmake --build . --config Release -- /maxcpucount. As a result, `Release\qtweb.exe` executable should be created. ## Demo application. Application based on `QTabWidget` with four tabs - standard Qt widget,; TCanvas, RCanvas and geometry drawing. Both canvas variants include different histograms drawing. ## How to include RCanvas/TCanvas into other Qt-based project. Most easy way - just include `RCanvasWidget.h` and `RCanvasWidget.cpp` files; in the project and let compile, linking with ROOT basic libraries `root-config --libs` plus `-lROOTWebDisplay -lROOTGpadv7`.; `RCanvasWidget` is just `QWidget` which internally embed `RCanvas` drawing.; See `ExampleWidget.ui` file how to embed such custom widget in normal qt ui file. To let ROOT work inside Qt event loop, one should instantiate `TApplication` object and; regularly call `gSystem->ProcessEvents()` - see how it is done in `ExampleMain.cpp`. Author: Sergey Linev; ",MatchSource.DOCS,tutorials/webgui/qtweb/Readme.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/webgui/qtweb/Readme.md
https://github.com/root-project/root/tree/v6-32-06/tutorials/webgui/qtweb/Readme.md:1024,Modifiability,config,config,1024,"# qtweb example. Demonstration how different ROOT web-based widgets can be embed into qt application. ## Compile on Linux. Create build directory and call:. cmake $ROOTSYS/tutorials/webgui/qtweb; make -j. ROOT should be compiled with configured `-Dqt5web=ON` or `-Dqt6web=ON`.; If both are present, one can use selector `-Dwithqt=5` or `-Dwithqt=6`; As a result, `qtweb` application should be created. ## Compile on Windows. Run x86 native tools shell from MS VC. Configure Qt5 pathes:. set PATH=%PATH%;C:\Qt5\5.15.2\msvc2019\bin. Compile ROOT with qt5web support in Release mode:. cd C:\; mkdir root; cd C:\root; cmake -G""Visual Studio 16 2019"" -A Win32 -Thost=x64 c:\git\root -Droot7=ON -DCMAKE_CXX_STANDARD=17 -Dwebgui=ON -Dqt5web=ON; cmake --build . --config Release -- /maxcpucount. Configure ROOT, create build directory and build qt5web tutorial:. call C:\root\bin\thisroot.bat; cd C:\; mkdir qt5web; cd C:\qt5web; cmake -G""Visual Studio 16 2019"" -A Win32 -Thost=x64 c:\root\tutorials\webgui\qtweb; cmake --build . --config Release -- /maxcpucount. As a result, `Release\qtweb.exe` executable should be created. ## Demo application. Application based on `QTabWidget` with four tabs - standard Qt widget,; TCanvas, RCanvas and geometry drawing. Both canvas variants include different histograms drawing. ## How to include RCanvas/TCanvas into other Qt-based project. Most easy way - just include `RCanvasWidget.h` and `RCanvasWidget.cpp` files; in the project and let compile, linking with ROOT basic libraries `root-config --libs` plus `-lROOTWebDisplay -lROOTGpadv7`.; `RCanvasWidget` is just `QWidget` which internally embed `RCanvas` drawing.; See `ExampleWidget.ui` file how to embed such custom widget in normal qt ui file. To let ROOT work inside Qt event loop, one should instantiate `TApplication` object and; regularly call `gSystem->ProcessEvents()` - see how it is done in `ExampleMain.cpp`. Author: Sergey Linev; ",MatchSource.DOCS,tutorials/webgui/qtweb/Readme.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/webgui/qtweb/Readme.md
https://github.com/root-project/root/tree/v6-32-06/tutorials/webgui/qtweb/Readme.md:1523,Modifiability,config,config,1523,"# qtweb example. Demonstration how different ROOT web-based widgets can be embed into qt application. ## Compile on Linux. Create build directory and call:. cmake $ROOTSYS/tutorials/webgui/qtweb; make -j. ROOT should be compiled with configured `-Dqt5web=ON` or `-Dqt6web=ON`.; If both are present, one can use selector `-Dwithqt=5` or `-Dwithqt=6`; As a result, `qtweb` application should be created. ## Compile on Windows. Run x86 native tools shell from MS VC. Configure Qt5 pathes:. set PATH=%PATH%;C:\Qt5\5.15.2\msvc2019\bin. Compile ROOT with qt5web support in Release mode:. cd C:\; mkdir root; cd C:\root; cmake -G""Visual Studio 16 2019"" -A Win32 -Thost=x64 c:\git\root -Droot7=ON -DCMAKE_CXX_STANDARD=17 -Dwebgui=ON -Dqt5web=ON; cmake --build . --config Release -- /maxcpucount. Configure ROOT, create build directory and build qt5web tutorial:. call C:\root\bin\thisroot.bat; cd C:\; mkdir qt5web; cd C:\qt5web; cmake -G""Visual Studio 16 2019"" -A Win32 -Thost=x64 c:\root\tutorials\webgui\qtweb; cmake --build . --config Release -- /maxcpucount. As a result, `Release\qtweb.exe` executable should be created. ## Demo application. Application based on `QTabWidget` with four tabs - standard Qt widget,; TCanvas, RCanvas and geometry drawing. Both canvas variants include different histograms drawing. ## How to include RCanvas/TCanvas into other Qt-based project. Most easy way - just include `RCanvasWidget.h` and `RCanvasWidget.cpp` files; in the project and let compile, linking with ROOT basic libraries `root-config --libs` plus `-lROOTWebDisplay -lROOTGpadv7`.; `RCanvasWidget` is just `QWidget` which internally embed `RCanvas` drawing.; See `ExampleWidget.ui` file how to embed such custom widget in normal qt ui file. To let ROOT work inside Qt event loop, one should instantiate `TApplication` object and; regularly call `gSystem->ProcessEvents()` - see how it is done in `ExampleMain.cpp`. Author: Sergey Linev; ",MatchSource.DOCS,tutorials/webgui/qtweb/Readme.md,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/tutorials/webgui/qtweb/Readme.md
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/README.rst:514,Deployability,update,updated,514,".. -*- mode: rst -*-. cppyy: Python-C++ bindings interface based on Cling/LLVM; ========================================================. cppyy provides fully automatic, dynamic Python-C++ bindings by leveraging; the Cling C++ interpreter and LLVM.; It supports both PyPy (natively), CPython, and C++ language standards; through C++17 (and parts of C++20). Details and performance are described in; `this paper <http://cern.ch/wlav/Cppyy_LavrijsenDutta_PyHPC16.pdf>`_,; originally presented at PyHPC'16, but since updated with improved performance; numbers. Full documentation: `cppyy.readthedocs.io <http://cppyy.readthedocs.io/>`_. Notebook-based tutorial: `Cppyy Tutorial <https://github.com/wlav/cppyy/blob/master/doc/tutorial/CppyyTutorial.ipynb>`_. For Anaconda/miniconda, install cppyy from `conda-forge <https://anaconda.org/conda-forge/cppyy>`_. ----. Change log:; https://cppyy.readthedocs.io/en/latest/changelog.html. Bug reports/feedback:; https://github.com/wlav/cppyy/issues; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/README.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/README.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/README.rst:779,Deployability,install,install,779,".. -*- mode: rst -*-. cppyy: Python-C++ bindings interface based on Cling/LLVM; ========================================================. cppyy provides fully automatic, dynamic Python-C++ bindings by leveraging; the Cling C++ interpreter and LLVM.; It supports both PyPy (natively), CPython, and C++ language standards; through C++17 (and parts of C++20). Details and performance are described in; `this paper <http://cern.ch/wlav/Cppyy_LavrijsenDutta_PyHPC16.pdf>`_,; originally presented at PyHPC'16, but since updated with improved performance; numbers. Full documentation: `cppyy.readthedocs.io <http://cppyy.readthedocs.io/>`_. Notebook-based tutorial: `Cppyy Tutorial <https://github.com/wlav/cppyy/blob/master/doc/tutorial/CppyyTutorial.ipynb>`_. For Anaconda/miniconda, install cppyy from `conda-forge <https://anaconda.org/conda-forge/cppyy>`_. ----. Change log:; https://cppyy.readthedocs.io/en/latest/changelog.html. Bug reports/feedback:; https://github.com/wlav/cppyy/issues; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/README.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/README.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/README.rst:49,Integrability,interface,interface,49,".. -*- mode: rst -*-. cppyy: Python-C++ bindings interface based on Cling/LLVM; ========================================================. cppyy provides fully automatic, dynamic Python-C++ bindings by leveraging; the Cling C++ interpreter and LLVM.; It supports both PyPy (natively), CPython, and C++ language standards; through C++17 (and parts of C++20). Details and performance are described in; `this paper <http://cern.ch/wlav/Cppyy_LavrijsenDutta_PyHPC16.pdf>`_,; originally presented at PyHPC'16, but since updated with improved performance; numbers. Full documentation: `cppyy.readthedocs.io <http://cppyy.readthedocs.io/>`_. Notebook-based tutorial: `Cppyy Tutorial <https://github.com/wlav/cppyy/blob/master/doc/tutorial/CppyyTutorial.ipynb>`_. For Anaconda/miniconda, install cppyy from `conda-forge <https://anaconda.org/conda-forge/cppyy>`_. ----. Change log:; https://cppyy.readthedocs.io/en/latest/changelog.html. Bug reports/feedback:; https://github.com/wlav/cppyy/issues; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/README.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/README.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/README.rst:369,Performance,perform,performance,369,".. -*- mode: rst -*-. cppyy: Python-C++ bindings interface based on Cling/LLVM; ========================================================. cppyy provides fully automatic, dynamic Python-C++ bindings by leveraging; the Cling C++ interpreter and LLVM.; It supports both PyPy (natively), CPython, and C++ language standards; through C++17 (and parts of C++20). Details and performance are described in; `this paper <http://cern.ch/wlav/Cppyy_LavrijsenDutta_PyHPC16.pdf>`_,; originally presented at PyHPC'16, but since updated with improved performance; numbers. Full documentation: `cppyy.readthedocs.io <http://cppyy.readthedocs.io/>`_. Notebook-based tutorial: `Cppyy Tutorial <https://github.com/wlav/cppyy/blob/master/doc/tutorial/CppyyTutorial.ipynb>`_. For Anaconda/miniconda, install cppyy from `conda-forge <https://anaconda.org/conda-forge/cppyy>`_. ----. Change log:; https://cppyy.readthedocs.io/en/latest/changelog.html. Bug reports/feedback:; https://github.com/wlav/cppyy/issues; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/README.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/README.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/README.rst:536,Performance,perform,performance,536,".. -*- mode: rst -*-. cppyy: Python-C++ bindings interface based on Cling/LLVM; ========================================================. cppyy provides fully automatic, dynamic Python-C++ bindings by leveraging; the Cling C++ interpreter and LLVM.; It supports both PyPy (natively), CPython, and C++ language standards; through C++17 (and parts of C++20). Details and performance are described in; `this paper <http://cern.ch/wlav/Cppyy_LavrijsenDutta_PyHPC16.pdf>`_,; originally presented at PyHPC'16, but since updated with improved performance; numbers. Full documentation: `cppyy.readthedocs.io <http://cppyy.readthedocs.io/>`_. Notebook-based tutorial: `Cppyy Tutorial <https://github.com/wlav/cppyy/blob/master/doc/tutorial/CppyyTutorial.ipynb>`_. For Anaconda/miniconda, install cppyy from `conda-forge <https://anaconda.org/conda-forge/cppyy>`_. ----. Change log:; https://cppyy.readthedocs.io/en/latest/changelog.html. Bug reports/feedback:; https://github.com/wlav/cppyy/issues; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/README.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/README.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/README.rst:868,Testability,log,log,868,".. -*- mode: rst -*-. cppyy: Python-C++ bindings interface based on Cling/LLVM; ========================================================. cppyy provides fully automatic, dynamic Python-C++ bindings by leveraging; the Cling C++ interpreter and LLVM.; It supports both PyPy (natively), CPython, and C++ language standards; through C++17 (and parts of C++20). Details and performance are described in; `this paper <http://cern.ch/wlav/Cppyy_LavrijsenDutta_PyHPC16.pdf>`_,; originally presented at PyHPC'16, but since updated with improved performance; numbers. Full documentation: `cppyy.readthedocs.io <http://cppyy.readthedocs.io/>`_. Notebook-based tutorial: `Cppyy Tutorial <https://github.com/wlav/cppyy/blob/master/doc/tutorial/CppyyTutorial.ipynb>`_. For Anaconda/miniconda, install cppyy from `conda-forge <https://anaconda.org/conda-forge/cppyy>`_. ----. Change log:; https://cppyy.readthedocs.io/en/latest/changelog.html. Bug reports/feedback:; https://github.com/wlav/cppyy/issues; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/README.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/README.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/README.rst:941,Usability,feedback,feedback,941,".. -*- mode: rst -*-. cppyy: Python-C++ bindings interface based on Cling/LLVM; ========================================================. cppyy provides fully automatic, dynamic Python-C++ bindings by leveraging; the Cling C++ interpreter and LLVM.; It supports both PyPy (natively), CPython, and C++ language standards; through C++17 (and parts of C++20). Details and performance are described in; `this paper <http://cern.ch/wlav/Cppyy_LavrijsenDutta_PyHPC16.pdf>`_,; originally presented at PyHPC'16, but since updated with improved performance; numbers. Full documentation: `cppyy.readthedocs.io <http://cppyy.readthedocs.io/>`_. Notebook-based tutorial: `Cppyy Tutorial <https://github.com/wlav/cppyy/blob/master/doc/tutorial/CppyyTutorial.ipynb>`_. For Anaconda/miniconda, install cppyy from `conda-forge <https://anaconda.org/conda-forge/cppyy>`_. ----. Change log:; https://cppyy.readthedocs.io/en/latest/changelog.html. Bug reports/feedback:; https://github.com/wlav/cppyy/issues; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/README.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/README.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy-backend/README.rst:116,Deployability,patch,patched,116,"cppyy-backend; =============. A repackaging of Cling, the interactive C++ interpreter, including a version; of LLVM patched for interactive use, and C/C++ wrappers that expose no further; external headers or types. Cling documentation is here:; https://root.cern.ch/cling. ----. Find the cppyy documentation here:; http://cppyy.readthedocs.io/. Please report bugs in the `cppyy issue tracker <https://bitbucket.org/wlav/cppyy/issues>`_.; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy-backend/README.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy-backend/README.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy-backend/README.rst:155,Integrability,wrap,wrappers,155,"cppyy-backend; =============. A repackaging of Cling, the interactive C++ interpreter, including a version; of LLVM patched for interactive use, and C/C++ wrappers that expose no further; external headers or types. Cling documentation is here:; https://root.cern.ch/cling. ----. Find the cppyy documentation here:; http://cppyy.readthedocs.io/. Please report bugs in the `cppyy issue tracker <https://bitbucket.org/wlav/cppyy/issues>`_.; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy-backend/README.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy-backend/README.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy-backend/README.rst:169,Security,expose,expose,169,"cppyy-backend; =============. A repackaging of Cling, the interactive C++ interpreter, including a version; of LLVM patched for interactive use, and C/C++ wrappers that expose no further; external headers or types. Cling documentation is here:; https://root.cern.ch/cling. ----. Find the cppyy documentation here:; http://cppyy.readthedocs.io/. Please report bugs in the `cppyy issue tracker <https://bitbucket.org/wlav/cppyy/issues>`_.; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy-backend/README.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy-backend/README.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/README.rst:528,Deployability,install,installation,528,".. -*- mode: rst -*-. CPyCppyy: Python-C++ bindings interface based on Cling/LLVM; ===========================================================. CPyCppyy is the CPython equivalent of _cppyy in PyPy.; It provides dynamic Python-C++ bindings by leveraging the Cling C++; interpreter and LLVM.; Details and performance are described in; `this paper <http://conferences.computer.org/pyhpc/2016/papers/5220a027.pdf>`_. CPyCppyy is a CPython extension module built on top of the same backend API; as PyPy/_cppyy.; It thus requires the installation of the; `cppyy backend <https://pypi.python.org/pypi/cppyy-backend/>`_; for use, which will pull in Cling.; CPython/cppyy and PyPy/cppyy are designed to be compatible, although there; are differences due to the former being reference counted and the latter; being garbage collected, as well as temporary differences due to different; release cycles of the respective projects. ----. Find the cppyy documentation here:; http://cppyy.readthedocs.io. Change log:; https://cppyy.readthedocs.io/en/latest/changelog.html. Bug reports/feedback:; https://github.com/wlav/cppyy/issues; ",MatchSource.DOCS,bindings/pyroot/cppyy/CPyCppyy/README.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/README.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/README.rst:875,Deployability,release,release,875,".. -*- mode: rst -*-. CPyCppyy: Python-C++ bindings interface based on Cling/LLVM; ===========================================================. CPyCppyy is the CPython equivalent of _cppyy in PyPy.; It provides dynamic Python-C++ bindings by leveraging the Cling C++; interpreter and LLVM.; Details and performance are described in; `this paper <http://conferences.computer.org/pyhpc/2016/papers/5220a027.pdf>`_. CPyCppyy is a CPython extension module built on top of the same backend API; as PyPy/_cppyy.; It thus requires the installation of the; `cppyy backend <https://pypi.python.org/pypi/cppyy-backend/>`_; for use, which will pull in Cling.; CPython/cppyy and PyPy/cppyy are designed to be compatible, although there; are differences due to the former being reference counted and the latter; being garbage collected, as well as temporary differences due to different; release cycles of the respective projects. ----. Find the cppyy documentation here:; http://cppyy.readthedocs.io. Change log:; https://cppyy.readthedocs.io/en/latest/changelog.html. Bug reports/feedback:; https://github.com/wlav/cppyy/issues; ",MatchSource.DOCS,bindings/pyroot/cppyy/CPyCppyy/README.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/README.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/README.rst:52,Integrability,interface,interface,52,".. -*- mode: rst -*-. CPyCppyy: Python-C++ bindings interface based on Cling/LLVM; ===========================================================. CPyCppyy is the CPython equivalent of _cppyy in PyPy.; It provides dynamic Python-C++ bindings by leveraging the Cling C++; interpreter and LLVM.; Details and performance are described in; `this paper <http://conferences.computer.org/pyhpc/2016/papers/5220a027.pdf>`_. CPyCppyy is a CPython extension module built on top of the same backend API; as PyPy/_cppyy.; It thus requires the installation of the; `cppyy backend <https://pypi.python.org/pypi/cppyy-backend/>`_; for use, which will pull in Cling.; CPython/cppyy and PyPy/cppyy are designed to be compatible, although there; are differences due to the former being reference counted and the latter; being garbage collected, as well as temporary differences due to different; release cycles of the respective projects. ----. Find the cppyy documentation here:; http://cppyy.readthedocs.io. Change log:; https://cppyy.readthedocs.io/en/latest/changelog.html. Bug reports/feedback:; https://github.com/wlav/cppyy/issues; ",MatchSource.DOCS,bindings/pyroot/cppyy/CPyCppyy/README.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/README.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/README.rst:303,Performance,perform,performance,303,".. -*- mode: rst -*-. CPyCppyy: Python-C++ bindings interface based on Cling/LLVM; ===========================================================. CPyCppyy is the CPython equivalent of _cppyy in PyPy.; It provides dynamic Python-C++ bindings by leveraging the Cling C++; interpreter and LLVM.; Details and performance are described in; `this paper <http://conferences.computer.org/pyhpc/2016/papers/5220a027.pdf>`_. CPyCppyy is a CPython extension module built on top of the same backend API; as PyPy/_cppyy.; It thus requires the installation of the; `cppyy backend <https://pypi.python.org/pypi/cppyy-backend/>`_; for use, which will pull in Cling.; CPython/cppyy and PyPy/cppyy are designed to be compatible, although there; are differences due to the former being reference counted and the latter; being garbage collected, as well as temporary differences due to different; release cycles of the respective projects. ----. Find the cppyy documentation here:; http://cppyy.readthedocs.io. Change log:; https://cppyy.readthedocs.io/en/latest/changelog.html. Bug reports/feedback:; https://github.com/wlav/cppyy/issues; ",MatchSource.DOCS,bindings/pyroot/cppyy/CPyCppyy/README.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/README.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/README.rst:996,Testability,log,log,996,".. -*- mode: rst -*-. CPyCppyy: Python-C++ bindings interface based on Cling/LLVM; ===========================================================. CPyCppyy is the CPython equivalent of _cppyy in PyPy.; It provides dynamic Python-C++ bindings by leveraging the Cling C++; interpreter and LLVM.; Details and performance are described in; `this paper <http://conferences.computer.org/pyhpc/2016/papers/5220a027.pdf>`_. CPyCppyy is a CPython extension module built on top of the same backend API; as PyPy/_cppyy.; It thus requires the installation of the; `cppyy backend <https://pypi.python.org/pypi/cppyy-backend/>`_; for use, which will pull in Cling.; CPython/cppyy and PyPy/cppyy are designed to be compatible, although there; are differences due to the former being reference counted and the latter; being garbage collected, as well as temporary differences due to different; release cycles of the respective projects. ----. Find the cppyy documentation here:; http://cppyy.readthedocs.io. Change log:; https://cppyy.readthedocs.io/en/latest/changelog.html. Bug reports/feedback:; https://github.com/wlav/cppyy/issues; ",MatchSource.DOCS,bindings/pyroot/cppyy/CPyCppyy/README.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/README.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/README.rst:1069,Usability,feedback,feedback,1069,".. -*- mode: rst -*-. CPyCppyy: Python-C++ bindings interface based on Cling/LLVM; ===========================================================. CPyCppyy is the CPython equivalent of _cppyy in PyPy.; It provides dynamic Python-C++ bindings by leveraging the Cling C++; interpreter and LLVM.; Details and performance are described in; `this paper <http://conferences.computer.org/pyhpc/2016/papers/5220a027.pdf>`_. CPyCppyy is a CPython extension module built on top of the same backend API; as PyPy/_cppyy.; It thus requires the installation of the; `cppyy backend <https://pypi.python.org/pypi/cppyy-backend/>`_; for use, which will pull in Cling.; CPython/cppyy and PyPy/cppyy are designed to be compatible, although there; are differences due to the former being reference counted and the latter; being garbage collected, as well as temporary differences due to different; release cycles of the respective projects. ----. Find the cppyy documentation here:; http://cppyy.readthedocs.io. Change log:; https://cppyy.readthedocs.io/en/latest/changelog.html. Bug reports/feedback:; https://github.com/wlav/cppyy/issues; ",MatchSource.DOCS,bindings/pyroot/cppyy/CPyCppyy/README.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/CPyCppyy/README.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/basic_types.rst:5994,Availability,avail,available,5994,"cc"", ""dd""}, {""ee"", ""ff""}};'); True; >>> type(cppyy.gbl.str_array[0][1]); <class cppyy.gbl.std.string at 0x7fd650ccb650>; >>> cppyy.gbl.str_array[0][1]; 'bb'; >>> cppyy.gbl.str_array[4][0]; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; IndexError: tuple index out of range; >>>. `Pointers`; """""""""""""""""""". When the C++ code takes a pointer or reference type to a specific builtin; type (such as an ``unsigned int`` for example), then types need to match; exactly.; ``cppyy`` supports the types provided by the standard modules ``ctypes`` and; ``array`` for those cases.; Example of using a reference to builtin:. .. code-block:: python. >>> from ctypes import c_uint; >>> u = c_uint(0); >>> c.uint_ref_assign(u, 42); >>> u.value; 42; >>>. For objects, an object, a pointer to an object, and a smart pointer to an; object are represented the same way, with the necessary (de)referencing; applied automatically.; Pointer variables are also bound by reference, so that updates on either the; C++ or Python side are reflected on the other side as well. `Enums`; """""""""""""". Named, anonymous, and class enums are supported.; The Python-underlying type of an enum is implementation dependent and may even; be different for different enums on the same compiler.; Typically, however, the types are ``int`` or ``unsigned int``, which; translates to Python's ``int`` or ``long`` on Python2 or class ``int`` on; Python3.; Separate from the underlying, all enums have their own Python type to allow; them to be used in template instantiations:. .. code-block:: python. >>> from cppyy.gbl import kBanana # classic enum, globally available; >>> print(kBanana); 29; >>> cppyy.gbl.EFruit; <class '__main__.EFruit'>; >>> print(cppyy.gbl.EFruit.kApple); 78; >>> cppyy.gbl.E1 # C++11 class enum, scoped; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; AttributeError: <namespace cppyy.gbl at 0x7ff2766a4af0> has no attribute 'E1'.; >>> cppyy.gbl.NamedClassEnum.E1; 42; >>>. ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/basic_types.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/basic_types.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/basic_types.rst:5347,Deployability,update,updates,5347,"cc"", ""dd""}, {""ee"", ""ff""}};'); True; >>> type(cppyy.gbl.str_array[0][1]); <class cppyy.gbl.std.string at 0x7fd650ccb650>; >>> cppyy.gbl.str_array[0][1]; 'bb'; >>> cppyy.gbl.str_array[4][0]; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; IndexError: tuple index out of range; >>>. `Pointers`; """""""""""""""""""". When the C++ code takes a pointer or reference type to a specific builtin; type (such as an ``unsigned int`` for example), then types need to match; exactly.; ``cppyy`` supports the types provided by the standard modules ``ctypes`` and; ``array`` for those cases.; Example of using a reference to builtin:. .. code-block:: python. >>> from ctypes import c_uint; >>> u = c_uint(0); >>> c.uint_ref_assign(u, 42); >>> u.value; 42; >>>. For objects, an object, a pointer to an object, and a smart pointer to an; object are represented the same way, with the necessary (de)referencing; applied automatically.; Pointer variables are also bound by reference, so that updates on either the; C++ or Python side are reflected on the other side as well. `Enums`; """""""""""""". Named, anonymous, and class enums are supported.; The Python-underlying type of an enum is implementation dependent and may even; be different for different enums on the same compiler.; Typically, however, the types are ``int`` or ``unsigned int``, which; translates to Python's ``int`` or ``long`` on Python2 or class ``int`` on; Python3.; Separate from the underlying, all enums have their own Python type to allow; them to be used in template instantiations:. .. code-block:: python. >>> from cppyy.gbl import kBanana # classic enum, globally available; >>> print(kBanana); 29; >>> cppyy.gbl.EFruit; <class '__main__.EFruit'>; >>> print(cppyy.gbl.EFruit.kApple); 78; >>> cppyy.gbl.E1 # C++11 class enum, scoped; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; AttributeError: <namespace cppyy.gbl at 0x7ff2766a4af0> has no attribute 'E1'.; >>> cppyy.gbl.NamedClassEnum.E1; 42; >>>. ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/basic_types.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/basic_types.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/basic_types.rst:3237,Integrability,interface,interface,3237," cppyy.gbl.std.string at 0x7fa75edbf8a0>; >>> s == ""aap""; True; >>>. To pass an argument through a C++ ``char`` (signed or unsigned) use a Python; string of size 1.; In many cases, the explicit C types from module ``ctypes`` can also be used,; but that module does not have a public API (for type conversion or otherwise),; so support is somewhat limited. There are automatic conversions between C++'s ``std::vector`` and Python's; ``list`` and ``tuple``, where possible, as they are often used in a similar; manner.; These datatypes have completely different memory layouts, however, and the; ``std::vector`` requires that all elements are of the same type and laid; out consecutively in memory.; Conversion thus requires type checks, memory allocation, and copies.; This can be rather expensive.; See the section on :ref:`STL <stl>`. `Arrays`; """""""""""""""". Builtin arrays are supported through arrays from module ``array`` (or any; other builtin-type array that implements the Python buffer interface, such; as numpy arrays) and a low-level view type from ``cppyy`` for returns and; variable access (that implements the buffer interface as well).; Out-of-bounds checking is limited to those cases where the size is known at; compile time.; Example:. .. code-block:: python. >>> from cppyy.gbl import Concrete; >>> from array import array; >>> c = Concrete(); >>> c.array_method(array('d', [1., 2., 3., 4.]), 4); 1 2 3 4; >>> c.m_data[4] # static size is 4, so out of bounds; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; IndexError: buffer index out of range; >>>. Arrays of arrays are supported through the C++ low-level view objects.; This only works well if sizes are known at compile time or can be inferred.; If sizes are not known, the size is set to a large integer (depending on the; array element size) to allow access.; It is then up to the developer not to access the array out-of-bounds.; There is limited support for arrays of instances, but those should be avo",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/basic_types.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/basic_types.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/basic_types.rst:3373,Integrability,interface,interface,3373," cppyy.gbl.std.string at 0x7fa75edbf8a0>; >>> s == ""aap""; True; >>>. To pass an argument through a C++ ``char`` (signed or unsigned) use a Python; string of size 1.; In many cases, the explicit C types from module ``ctypes`` can also be used,; but that module does not have a public API (for type conversion or otherwise),; so support is somewhat limited. There are automatic conversions between C++'s ``std::vector`` and Python's; ``list`` and ``tuple``, where possible, as they are often used in a similar; manner.; These datatypes have completely different memory layouts, however, and the; ``std::vector`` requires that all elements are of the same type and laid; out consecutively in memory.; Conversion thus requires type checks, memory allocation, and copies.; This can be rather expensive.; See the section on :ref:`STL <stl>`. `Arrays`; """""""""""""""". Builtin arrays are supported through arrays from module ``array`` (or any; other builtin-type array that implements the Python buffer interface, such; as numpy arrays) and a low-level view type from ``cppyy`` for returns and; variable access (that implements the buffer interface as well).; Out-of-bounds checking is limited to those cases where the size is known at; compile time.; Example:. .. code-block:: python. >>> from cppyy.gbl import Concrete; >>> from array import array; >>> c = Concrete(); >>> c.array_method(array('d', [1., 2., 3., 4.]), 4); 1 2 3 4; >>> c.m_data[4] # static size is 4, so out of bounds; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; IndexError: buffer index out of range; >>>. Arrays of arrays are supported through the C++ low-level view objects.; This only works well if sizes are known at compile time or can be inferred.; If sizes are not known, the size is set to a large integer (depending on the; array element size) to allow access.; It is then up to the developer not to access the array out-of-bounds.; There is limited support for arrays of instances, but those should be avo",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/basic_types.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/basic_types.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/basic_types.rst:4047,Integrability,depend,depending,4047,".; See the section on :ref:`STL <stl>`. `Arrays`; """""""""""""""". Builtin arrays are supported through arrays from module ``array`` (or any; other builtin-type array that implements the Python buffer interface, such; as numpy arrays) and a low-level view type from ``cppyy`` for returns and; variable access (that implements the buffer interface as well).; Out-of-bounds checking is limited to those cases where the size is known at; compile time.; Example:. .. code-block:: python. >>> from cppyy.gbl import Concrete; >>> from array import array; >>> c = Concrete(); >>> c.array_method(array('d', [1., 2., 3., 4.]), 4); 1 2 3 4; >>> c.m_data[4] # static size is 4, so out of bounds; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; IndexError: buffer index out of range; >>>. Arrays of arrays are supported through the C++ low-level view objects.; This only works well if sizes are known at compile time or can be inferred.; If sizes are not known, the size is set to a large integer (depending on the; array element size) to allow access.; It is then up to the developer not to access the array out-of-bounds.; There is limited support for arrays of instances, but those should be avoided; in C++ anyway:. .. code-block:: python. >>> cppyy.cppdef('std::string str_array[3][2] = {{""aa"", ""bb""}, {""cc"", ""dd""}, {""ee"", ""ff""}};'); True; >>> type(cppyy.gbl.str_array[0][1]); <class cppyy.gbl.std.string at 0x7fd650ccb650>; >>> cppyy.gbl.str_array[0][1]; 'bb'; >>> cppyy.gbl.str_array[4][0]; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; IndexError: tuple index out of range; >>>. `Pointers`; """""""""""""""""""". When the C++ code takes a pointer or reference type to a specific builtin; type (such as an ``unsigned int`` for example), then types need to match; exactly.; ``cppyy`` supports the types provided by the standard modules ``ctypes`` and; ``array`` for those cases.; Example of using a reference to builtin:. .. code-block:: python. >>> from ctypes import c_",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/basic_types.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/basic_types.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/basic_types.rst:5554,Integrability,depend,dependent,5554,"cc"", ""dd""}, {""ee"", ""ff""}};'); True; >>> type(cppyy.gbl.str_array[0][1]); <class cppyy.gbl.std.string at 0x7fd650ccb650>; >>> cppyy.gbl.str_array[0][1]; 'bb'; >>> cppyy.gbl.str_array[4][0]; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; IndexError: tuple index out of range; >>>. `Pointers`; """""""""""""""""""". When the C++ code takes a pointer or reference type to a specific builtin; type (such as an ``unsigned int`` for example), then types need to match; exactly.; ``cppyy`` supports the types provided by the standard modules ``ctypes`` and; ``array`` for those cases.; Example of using a reference to builtin:. .. code-block:: python. >>> from ctypes import c_uint; >>> u = c_uint(0); >>> c.uint_ref_assign(u, 42); >>> u.value; 42; >>>. For objects, an object, a pointer to an object, and a smart pointer to an; object are represented the same way, with the necessary (de)referencing; applied automatically.; Pointer variables are also bound by reference, so that updates on either the; C++ or Python side are reflected on the other side as well. `Enums`; """""""""""""". Named, anonymous, and class enums are supported.; The Python-underlying type of an enum is implementation dependent and may even; be different for different enums on the same compiler.; Typically, however, the types are ``int`` or ``unsigned int``, which; translates to Python's ``int`` or ``long`` on Python2 or class ``int`` on; Python3.; Separate from the underlying, all enums have their own Python type to allow; them to be used in template instantiations:. .. code-block:: python. >>> from cppyy.gbl import kBanana # classic enum, globally available; >>> print(kBanana); 29; >>> cppyy.gbl.EFruit; <class '__main__.EFruit'>; >>> print(cppyy.gbl.EFruit.kApple); 78; >>> cppyy.gbl.E1 # C++11 class enum, scoped; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; AttributeError: <namespace cppyy.gbl at 0x7ff2766a4af0> has no attribute 'E1'.; >>> cppyy.gbl.NamedClassEnum.E1; 42; >>>. ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/basic_types.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/basic_types.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/basic_types.rst:3329,Modifiability,variab,variable,3329," cppyy.gbl.std.string at 0x7fa75edbf8a0>; >>> s == ""aap""; True; >>>. To pass an argument through a C++ ``char`` (signed or unsigned) use a Python; string of size 1.; In many cases, the explicit C types from module ``ctypes`` can also be used,; but that module does not have a public API (for type conversion or otherwise),; so support is somewhat limited. There are automatic conversions between C++'s ``std::vector`` and Python's; ``list`` and ``tuple``, where possible, as they are often used in a similar; manner.; These datatypes have completely different memory layouts, however, and the; ``std::vector`` requires that all elements are of the same type and laid; out consecutively in memory.; Conversion thus requires type checks, memory allocation, and copies.; This can be rather expensive.; See the section on :ref:`STL <stl>`. `Arrays`; """""""""""""""". Builtin arrays are supported through arrays from module ``array`` (or any; other builtin-type array that implements the Python buffer interface, such; as numpy arrays) and a low-level view type from ``cppyy`` for returns and; variable access (that implements the buffer interface as well).; Out-of-bounds checking is limited to those cases where the size is known at; compile time.; Example:. .. code-block:: python. >>> from cppyy.gbl import Concrete; >>> from array import array; >>> c = Concrete(); >>> c.array_method(array('d', [1., 2., 3., 4.]), 4); 1 2 3 4; >>> c.m_data[4] # static size is 4, so out of bounds; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; IndexError: buffer index out of range; >>>. Arrays of arrays are supported through the C++ low-level view objects.; This only works well if sizes are known at compile time or can be inferred.; If sizes are not known, the size is set to a large integer (depending on the; array element size) to allow access.; It is then up to the developer not to access the array out-of-bounds.; There is limited support for arrays of instances, but those should be avo",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/basic_types.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/basic_types.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/basic_types.rst:5300,Modifiability,variab,variables,5300,"cc"", ""dd""}, {""ee"", ""ff""}};'); True; >>> type(cppyy.gbl.str_array[0][1]); <class cppyy.gbl.std.string at 0x7fd650ccb650>; >>> cppyy.gbl.str_array[0][1]; 'bb'; >>> cppyy.gbl.str_array[4][0]; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; IndexError: tuple index out of range; >>>. `Pointers`; """""""""""""""""""". When the C++ code takes a pointer or reference type to a specific builtin; type (such as an ``unsigned int`` for example), then types need to match; exactly.; ``cppyy`` supports the types provided by the standard modules ``ctypes`` and; ``array`` for those cases.; Example of using a reference to builtin:. .. code-block:: python. >>> from ctypes import c_uint; >>> u = c_uint(0); >>> c.uint_ref_assign(u, 42); >>> u.value; 42; >>>. For objects, an object, a pointer to an object, and a smart pointer to an; object are represented the same way, with the necessary (de)referencing; applied automatically.; Pointer variables are also bound by reference, so that updates on either the; C++ or Python side are reflected on the other side as well. `Enums`; """""""""""""". Named, anonymous, and class enums are supported.; The Python-underlying type of an enum is implementation dependent and may even; be different for different enums on the same compiler.; Typically, however, the types are ``int`` or ``unsigned int``, which; translates to Python's ``int`` or ``long`` on Python2 or class ``int`` on; Python3.; Separate from the underlying, all enums have their own Python type to allow; them to be used in template instantiations:. .. code-block:: python. >>> from cppyy.gbl import kBanana # classic enum, globally available; >>> print(kBanana); 29; >>> cppyy.gbl.EFruit; <class '__main__.EFruit'>; >>> print(cppyy.gbl.EFruit.kApple); 78; >>> cppyy.gbl.E1 # C++11 class enum, scoped; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; AttributeError: <namespace cppyy.gbl at 0x7ff2766a4af0> has no attribute 'E1'.; >>> cppyy.gbl.NamedClassEnum.E1; 42; >>>. ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/basic_types.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/basic_types.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/basic_types.rst:533,Performance,load,loaded,533,".. _basic_types:. Basic types; ===========. C++ has a far richer set of builtin types than Python.; Most Python code can remain relatively agnostic to that, and ``cppyy``; provides automatic conversions as appropriate.; On the other hand, Python builtin types such as lists and maps are far; richer than any builtin types in C++.; These are mapped to their Standard Template Library equivalents instead. The C++ code used for the examples below can be found; :doc:`here <cppyy_features_header>`, and it is assumed that that code is; loaded before running any of the example code snippets.; Download it, save it under the name ``features.h``, and simply include it:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('features.h'); >>>. `Builtins`; """""""""""""""""""". The selection of builtin data types varies greatly between Python and C++.; Where possible, builtin data types map onto the expected equivalent Python; types, with the caveats that there may be size differences, different; precision or rounding, etc.; For example, a C++ ``float`` is returned as a Python ``float``, which is in; fact a C++ ``double``.; If sizes allow, conversions are automatic.; For example, a C++ ``unsigned int`` becomes a Python2 ``long`` or Python3; ``int``, but unsigned-ness is still honored:. .. code-block:: python. >>> cppyy.gbl.gUint; 0L; >>> type(cppyy.gbl.gUint); <type 'long'>; >>> cppyy.gbl.gUint = -1; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; ValueError: cannot convert negative integer to unsigned; >>>. On some platforms, 8-bit integer types such as ``int8_t`` and ``uint8_t`` are; represented as `char` types.; For consistency, these are mapped onto Python `int`. Some types are builtin in Python, but (STL) classes in C++.; Examples are ``str`` vs. ``std::string`` (see also the; :doc:`Strings <strings>` section) and ``complex`` vs. ``std::complex``.; These classes have been pythonized to behave the same wherever possible.; For example, string comparison work",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/basic_types.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/basic_types.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/basic_types.rst:4244,Safety,avoid,avoided,4244,"he Python buffer interface, such; as numpy arrays) and a low-level view type from ``cppyy`` for returns and; variable access (that implements the buffer interface as well).; Out-of-bounds checking is limited to those cases where the size is known at; compile time.; Example:. .. code-block:: python. >>> from cppyy.gbl import Concrete; >>> from array import array; >>> c = Concrete(); >>> c.array_method(array('d', [1., 2., 3., 4.]), 4); 1 2 3 4; >>> c.m_data[4] # static size is 4, so out of bounds; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; IndexError: buffer index out of range; >>>. Arrays of arrays are supported through the C++ low-level view objects.; This only works well if sizes are known at compile time or can be inferred.; If sizes are not known, the size is set to a large integer (depending on the; array element size) to allow access.; It is then up to the developer not to access the array out-of-bounds.; There is limited support for arrays of instances, but those should be avoided; in C++ anyway:. .. code-block:: python. >>> cppyy.cppdef('std::string str_array[3][2] = {{""aa"", ""bb""}, {""cc"", ""dd""}, {""ee"", ""ff""}};'); True; >>> type(cppyy.gbl.str_array[0][1]); <class cppyy.gbl.std.string at 0x7fd650ccb650>; >>> cppyy.gbl.str_array[0][1]; 'bb'; >>> cppyy.gbl.str_array[4][0]; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; IndexError: tuple index out of range; >>>. `Pointers`; """""""""""""""""""". When the C++ code takes a pointer or reference type to a specific builtin; type (such as an ``unsigned int`` for example), then types need to match; exactly.; ``cppyy`` supports the types provided by the standard modules ``ctypes`` and; ``array`` for those cases.; Example of using a reference to builtin:. .. code-block:: python. >>> from ctypes import c_uint; >>> u = c_uint(0); >>> c.uint_ref_assign(u, 42); >>> u.value; 42; >>>. For objects, an object, a pointer to an object, and a smart pointer to an; object are represented th",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/basic_types.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/basic_types.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/basic_types.rst:3338,Security,access,access,3338," cppyy.gbl.std.string at 0x7fa75edbf8a0>; >>> s == ""aap""; True; >>>. To pass an argument through a C++ ``char`` (signed or unsigned) use a Python; string of size 1.; In many cases, the explicit C types from module ``ctypes`` can also be used,; but that module does not have a public API (for type conversion or otherwise),; so support is somewhat limited. There are automatic conversions between C++'s ``std::vector`` and Python's; ``list`` and ``tuple``, where possible, as they are often used in a similar; manner.; These datatypes have completely different memory layouts, however, and the; ``std::vector`` requires that all elements are of the same type and laid; out consecutively in memory.; Conversion thus requires type checks, memory allocation, and copies.; This can be rather expensive.; See the section on :ref:`STL <stl>`. `Arrays`; """""""""""""""". Builtin arrays are supported through arrays from module ``array`` (or any; other builtin-type array that implements the Python buffer interface, such; as numpy arrays) and a low-level view type from ``cppyy`` for returns and; variable access (that implements the buffer interface as well).; Out-of-bounds checking is limited to those cases where the size is known at; compile time.; Example:. .. code-block:: python. >>> from cppyy.gbl import Concrete; >>> from array import array; >>> c = Concrete(); >>> c.array_method(array('d', [1., 2., 3., 4.]), 4); 1 2 3 4; >>> c.m_data[4] # static size is 4, so out of bounds; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; IndexError: buffer index out of range; >>>. Arrays of arrays are supported through the C++ low-level view objects.; This only works well if sizes are known at compile time or can be inferred.; If sizes are not known, the size is set to a large integer (depending on the; array element size) to allow access.; It is then up to the developer not to access the array out-of-bounds.; There is limited support for arrays of instances, but those should be avo",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/basic_types.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/basic_types.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/basic_types.rst:4094,Security,access,access,4094,".; See the section on :ref:`STL <stl>`. `Arrays`; """""""""""""""". Builtin arrays are supported through arrays from module ``array`` (or any; other builtin-type array that implements the Python buffer interface, such; as numpy arrays) and a low-level view type from ``cppyy`` for returns and; variable access (that implements the buffer interface as well).; Out-of-bounds checking is limited to those cases where the size is known at; compile time.; Example:. .. code-block:: python. >>> from cppyy.gbl import Concrete; >>> from array import array; >>> c = Concrete(); >>> c.array_method(array('d', [1., 2., 3., 4.]), 4); 1 2 3 4; >>> c.m_data[4] # static size is 4, so out of bounds; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; IndexError: buffer index out of range; >>>. Arrays of arrays are supported through the C++ low-level view objects.; This only works well if sizes are known at compile time or can be inferred.; If sizes are not known, the size is set to a large integer (depending on the; array element size) to allow access.; It is then up to the developer not to access the array out-of-bounds.; There is limited support for arrays of instances, but those should be avoided; in C++ anyway:. .. code-block:: python. >>> cppyy.cppdef('std::string str_array[3][2] = {{""aa"", ""bb""}, {""cc"", ""dd""}, {""ee"", ""ff""}};'); True; >>> type(cppyy.gbl.str_array[0][1]); <class cppyy.gbl.std.string at 0x7fd650ccb650>; >>> cppyy.gbl.str_array[0][1]; 'bb'; >>> cppyy.gbl.str_array[4][0]; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; IndexError: tuple index out of range; >>>. `Pointers`; """""""""""""""""""". When the C++ code takes a pointer or reference type to a specific builtin; type (such as an ``unsigned int`` for example), then types need to match; exactly.; ``cppyy`` supports the types provided by the standard modules ``ctypes`` and; ``array`` for those cases.; Example of using a reference to builtin:. .. code-block:: python. >>> from ctypes import c_",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/basic_types.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/basic_types.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/basic_types.rst:4141,Security,access,access,4141,"ugh arrays from module ``array`` (or any; other builtin-type array that implements the Python buffer interface, such; as numpy arrays) and a low-level view type from ``cppyy`` for returns and; variable access (that implements the buffer interface as well).; Out-of-bounds checking is limited to those cases where the size is known at; compile time.; Example:. .. code-block:: python. >>> from cppyy.gbl import Concrete; >>> from array import array; >>> c = Concrete(); >>> c.array_method(array('d', [1., 2., 3., 4.]), 4); 1 2 3 4; >>> c.m_data[4] # static size is 4, so out of bounds; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; IndexError: buffer index out of range; >>>. Arrays of arrays are supported through the C++ low-level view objects.; This only works well if sizes are known at compile time or can be inferred.; If sizes are not known, the size is set to a large integer (depending on the; array element size) to allow access.; It is then up to the developer not to access the array out-of-bounds.; There is limited support for arrays of instances, but those should be avoided; in C++ anyway:. .. code-block:: python. >>> cppyy.cppdef('std::string str_array[3][2] = {{""aa"", ""bb""}, {""cc"", ""dd""}, {""ee"", ""ff""}};'); True; >>> type(cppyy.gbl.str_array[0][1]); <class cppyy.gbl.std.string at 0x7fd650ccb650>; >>> cppyy.gbl.str_array[0][1]; 'bb'; >>> cppyy.gbl.str_array[4][0]; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; IndexError: tuple index out of range; >>>. `Pointers`; """""""""""""""""""". When the C++ code takes a pointer or reference type to a specific builtin; type (such as an ``unsigned int`` for example), then types need to match; exactly.; ``cppyy`` supports the types provided by the standard modules ``ctypes`` and; ``array`` for those cases.; Example of using a reference to builtin:. .. code-block:: python. >>> from ctypes import c_uint; >>> u = c_uint(0); >>> c.uint_ref_assign(u, 42); >>> u.value; 42; >>>. For objects, an o",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/basic_types.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/basic_types.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/basic_types.rst:646,Usability,simpl,simply,646,".. _basic_types:. Basic types; ===========. C++ has a far richer set of builtin types than Python.; Most Python code can remain relatively agnostic to that, and ``cppyy``; provides automatic conversions as appropriate.; On the other hand, Python builtin types such as lists and maps are far; richer than any builtin types in C++.; These are mapped to their Standard Template Library equivalents instead. The C++ code used for the examples below can be found; :doc:`here <cppyy_features_header>`, and it is assumed that that code is; loaded before running any of the example code snippets.; Download it, save it under the name ``features.h``, and simply include it:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('features.h'); >>>. `Builtins`; """""""""""""""""""". The selection of builtin data types varies greatly between Python and C++.; Where possible, builtin data types map onto the expected equivalent Python; types, with the caveats that there may be size differences, different; precision or rounding, etc.; For example, a C++ ``float`` is returned as a Python ``float``, which is in; fact a C++ ``double``.; If sizes allow, conversions are automatic.; For example, a C++ ``unsigned int`` becomes a Python2 ``long`` or Python3; ``int``, but unsigned-ness is still honored:. .. code-block:: python. >>> cppyy.gbl.gUint; 0L; >>> type(cppyy.gbl.gUint); <type 'long'>; >>> cppyy.gbl.gUint = -1; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; ValueError: cannot convert negative integer to unsigned; >>>. On some platforms, 8-bit integer types such as ``int8_t`` and ``uint8_t`` are; represented as `char` types.; For consistency, these are mapped onto Python `int`. Some types are builtin in Python, but (STL) classes in C++.; Examples are ``str`` vs. ``std::string`` (see also the; :doc:`Strings <strings>` section) and ``complex`` vs. ``std::complex``.; These classes have been pythonized to behave the same wherever possible.; For example, string comparison work",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/basic_types.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/basic_types.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/bugs.rst:20,Usability,feedback,feedback,20,".. _bugs:. Bugs and feedback; =================. Please report bugs, ask questions, request improvements, and post general; comments on the `issue tracker`_ or on `stack overflow`_ (marked with the; ""cppyy"" tag). .. _`issue tracker`: https://github.com/wlav/cppyy/issues; .. _`stack overflow`: https://stackoverflow.com/questions/tagged/cppyy; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/bugs.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/bugs.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:6927,Availability,avail,available,6927,"mplex_double/_float on Windows); * sizeof() forwards to ctypes.sizeof() for ctypes' types; * Upgrade cmake fragments for Clang9; * Prevent clash with Julia's LLVM when loading cppyy into PyCall; * Upgrade to latest Cling patch release. 2021-05-14: 2.0.0; -----------------. * Upgrade to latest Cling based on Clang/LLVM 9; * Make C++17 the default standard on Windows. 2021-04-28: 1.9.6; -----------------. * Reverse operators for ``std::complex`` targeting Python's ``complex``; * Version the precompiled header with the ``cppyy-cling`` package version; * Cover more iterator protocol use cases; * Add missing cppyy/__pyinstaller pkg to sdist; * Single-inheritance support for cross-inherited templated constructors; * Disallow ``float`` -> ``const long long&`` conversion; * Capture python exception message string in PyException from callbacks; * Thread safety in enum lookups. 2021-03-22: 1.9.5; -----------------. * Do not regulate direct smart pointers (many to one can lead to double deletion); * Use pkg_resources of ``CPyCppyy``, if available, to find the API include path. 2021-03-17: 1.9.4; -----------------. * Fix for installing into a directory that has a space in the name; * Fix empty collection printing through Cling on 64b Windows; * Fix accidental shadowing of derived class typedefs by same names in base; * Streamlined templated function lookups in namespaces; * Fix edge cases when decomposing std::function template arguments; * Enable multi-cross inheritance with non-C++ python bases; * Support Bound C++ functions as template argument; * Python functions as template arguments from ``__annotations__`` or ``__cpp_name__``; * Removed functions/apis deprecated in py3.9; * Improved support for older pip and different installation layouts. 2021-02-15: 1.9.3; -----------------. * Wheels for Linux now follow manylinux2014; * Enable direct calls of base class' methods in Python cross-overrides; * cppyy.bind_object can now re-cast types, incl. Python cross-derived ones; * Py",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:8140,Availability,error,error,8140," derived class typedefs by same names in base; * Streamlined templated function lookups in namespaces; * Fix edge cases when decomposing std::function template arguments; * Enable multi-cross inheritance with non-C++ python bases; * Support Bound C++ functions as template argument; * Python functions as template arguments from ``__annotations__`` or ``__cpp_name__``; * Removed functions/apis deprecated in py3.9; * Improved support for older pip and different installation layouts. 2021-02-15: 1.9.3; -----------------. * Wheels for Linux now follow manylinux2014; * Enable direct calls of base class' methods in Python cross-overrides; * cppyy.bind_object can now re-cast types, incl. Python cross-derived ones; * Python cross-derived objects send to (and owned by) C++ retain Python state; * Ignore, for symbol lookups, libraries that can not be reloaded; * Use PathCanonicalize when resolving paths on Windows; * Add more ways of finding the backend library; * Improve error reporting when failed to find the backend library; * Workaround for mixing std::endl in JIT-ed and compiled code on Windows 32b; * Fixed a subtle crash that arises when an invalid ``using`` is the last method; * Filter -fno-plt (coming from anaconda builds; not understood by Cling); * Fixed memory leak in generic base ``__str__``. 2021-01-05: 1.9.2; -----------------. * Added ``cppyy.types`` module for exposing cppyy builtin types; * Improve numpy integration with custom ``__array__`` methods; * Allow operator overload resolution mixing class and global methods; * Installation fixes for PyPy when using pip. 2020-11-23: 1.9.1; -----------------. * Fix custom installer in pip sdist. 2020-11-22: 1.9.0; -----------------. * In-tree build resolving build/install order for PyPy with pyproject.toml; * ``std::string`` not converterd to ``str`` on function returns; * Cover more use cases where C string memory can be managed; * Automatic memory management of converted python functions; * Added pyinstaller hooks (ht",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:10952,Availability,error,errors,10952,"tic data; * Fix performance bug when using implicit conversions; * Fix memory overwrite when parsing during sorting of methods; * PyPy pip install again falls back to setup.py install. 2020-09-21: 1.8.3; -----------------. * Add initializer constructors for PODs and aggregates; * Use actual underlying type for enums, where possible; * Enum values remain instances of their type; * Expose enum underlying type name as ``__underlying`` and ``__ctype__``; * Strictly follow C++ enum scoping rules; * Same enum in transparent scope refers to same type; * More detailed enum ``repr()`` printing, where possible; * Fix for (extern) explicit template instantiations in namespaces; * Throw objects from an std::tuple a life line; * Global pythonizors now always run on all classes; * Simplified iteraton over STL-like containers defining ``begin()``/``end()``. 2020-09-08: 1.8.2; -----------------. * Add ``cppyy.set_debug()`` to enable debug output for fixing template errors; * Cover more partial template instantiation use cases; * Force template instantiation if necessary for type deduction (i.e. ``auto``). 2020-09-01: 1.8.1; -----------------. * Setup build dependencies with pyproject.toml; * Simplified flow of pointer types for callbacks and cross-derivation; * Pointer-comparing objects performs auto-cast as needed; * Add main dimension for ptr-ptr to builtin returns; * Transparant handling of ptr-ptr to instance returns; * Stricter handling of bool type in overload with int types; * Fix uint64_t template instantiation regression; * Do not filter out enum data for ``__dir__``; * Fix lookup of interpreter-only explicit instantiations; * Fix inconsistent naming of std types with char_traits; * Further hiding of upstream code/dependencies; * Extended documentation. 2020-07-12: 1.8.0; -----------------. * Support mixing of Python and C++ types in global operators; * Capture Cling error messages from cppdef and include in the Python exception; * Add a cppexec method to evalutate stateme",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:11881,Availability,error,error,11881,"ependencies with pyproject.toml; * Simplified flow of pointer types for callbacks and cross-derivation; * Pointer-comparing objects performs auto-cast as needed; * Add main dimension for ptr-ptr to builtin returns; * Transparant handling of ptr-ptr to instance returns; * Stricter handling of bool type in overload with int types; * Fix uint64_t template instantiation regression; * Do not filter out enum data for ``__dir__``; * Fix lookup of interpreter-only explicit instantiations; * Fix inconsistent naming of std types with char_traits; * Further hiding of upstream code/dependencies; * Extended documentation. 2020-07-12: 1.8.0; -----------------. * Support mixing of Python and C++ types in global operators; * Capture Cling error messages from cppdef and include in the Python exception; * Add a cppexec method to evalutate statements in Cling's global scope; * Support initialization of ``std::array<>`` from sequences; * Support C++17 style initialization of common STL containers; * Allow base classes with no virtual destructor (with warning); * Support const by-value returns in Python-side method overrides; * Support for cross-language multiple inheritance of C++ bases; * Allow for pass-by-value of ``std::unique_ptr`` through move; * Reduced dependencies on upstream code; * Put remaining upstream code in CppyyLegacy namespace. 2020-06-06: 1.7.1; -----------------. * Expose protected members in Python derived classes; * Support for deep Python-side derived hierarchies; * Do not generate a copy ctor in the Python derived class if private; * include, c_include, and cppdef now raise exceptions on error; * Allow mixing of keywords and default values; * Fix by-ptr return of objects in Python derived classes; * Fix for passing numpy boolean array through ``bool*``; * Fix assignment to ``const char*`` data members; * Support ``__restrict`` and ``__restrict__`` in interfaces; * Allow passing sequence of strings through ``const char*[]`` argument. 2020-04-27: 1.7.0; -----------",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:12766,Availability,error,error,12766,"ython and C++ types in global operators; * Capture Cling error messages from cppdef and include in the Python exception; * Add a cppexec method to evalutate statements in Cling's global scope; * Support initialization of ``std::array<>`` from sequences; * Support C++17 style initialization of common STL containers; * Allow base classes with no virtual destructor (with warning); * Support const by-value returns in Python-side method overrides; * Support for cross-language multiple inheritance of C++ bases; * Allow for pass-by-value of ``std::unique_ptr`` through move; * Reduced dependencies on upstream code; * Put remaining upstream code in CppyyLegacy namespace. 2020-06-06: 1.7.1; -----------------. * Expose protected members in Python derived classes; * Support for deep Python-side derived hierarchies; * Do not generate a copy ctor in the Python derived class if private; * include, c_include, and cppdef now raise exceptions on error; * Allow mixing of keywords and default values; * Fix by-ptr return of objects in Python derived classes; * Fix for passing numpy boolean array through ``bool*``; * Fix assignment to ``const char*`` data members; * Support ``__restrict`` and ``__restrict__`` in interfaces; * Allow passing sequence of strings through ``const char*[]`` argument. 2020-04-27: 1.7.0; -----------------. * Upgrade to cppyy-cling 6.20.4; * Pre-empt upstream's propensity of making ``std`` classes etc. global; * Allow initialization of ``std::map`` from dict with the correct types; * Allow initialization of ``std::set`` from set with the correct types; * Add optional nonst/non-const selection to ``__overload__``; * Automatic smartification of normal object passed as smartptr by value; * Fix crash when handing a by-value object to make_shared; * Fixed a few shared/unique_ptr corner cases; * Fixed conversion of ``std::function`` taking an STL class parameter; * No longer attempt auto-cast on classes without RTTI; * Fix for ``iter()`` iteration on generic STL contain",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:18489,Availability,error,errors,18489,"----. * Upgrade cppyy-cling to 6.18.2; * Various patches to upstream's pre-compiled header generation and use; * Instantiate templates with larger integer types if argument values require; * Improve cppyy.interactive and partially enable it on PyPy, IPython, etc.; * Let ``__overload__`` be more flexible in signature matching; * Make list filtering of dir(cppyy.gbl) on Windows same as Linux/Mac; * Extended documentation. 2019-08-18: 1.5.0; -----------------. * Upgrade cppyy-cling to 6.18.0; * Allow python-derived classes to be used in templates; * Stricter template resolution and better caching/performance; * Detailed memory management for make_shared and shared_ptr; * Two-way memory management for cross-inherited objects; * Reduced memory footprint of proxy objects in most common cases; * Allow implicit conversion from a tuple of arguments; * Data set on namespaces reflected on C++ even if data not yet bound; * Generalized resolution of binary operators in wrapper generation; * Proper naming of arguments in namespaces for ``std::function<>``; * Cover more cases of STL-liker iterators; * Allow ``std::vector`` initialization with a list of constructor arguments; * Consistent naming of ``__cppname__`` to ``__cpp_name__``; * Added ``__set_lifeline__`` attribute to overloads; * Fixes to the cmake fragments for Ubuntu; * Fixes linker errors on Windows in some configurations; * Support C++ naming of typedef of bool types; * Basic views of 2D arrays of builtin types; * Extended documentation. 2019-07-01 : 1.4.12; -------------------. * Automatic conversion of python functions to ``std::function`` arguments; * Fix for templated operators that can map to different python names; * Fix on p3 crash when setting a detailed exception during exception handling; * Fix lookup of ``std::nullopt``; * Fix bug that prevented certain templated constructors from being considered; * Support for enum values as data members on ""enum class"" enums; * Support for implicit conversion when passing ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:19227,Availability,failure,failures,19227,"uments; * Consistent naming of ``__cppname__`` to ``__cpp_name__``; * Added ``__set_lifeline__`` attribute to overloads; * Fixes to the cmake fragments for Ubuntu; * Fixes linker errors on Windows in some configurations; * Support C++ naming of typedef of bool types; * Basic views of 2D arrays of builtin types; * Extended documentation. 2019-07-01 : 1.4.12; -------------------. * Automatic conversion of python functions to ``std::function`` arguments; * Fix for templated operators that can map to different python names; * Fix on p3 crash when setting a detailed exception during exception handling; * Fix lookup of ``std::nullopt``; * Fix bug that prevented certain templated constructors from being considered; * Support for enum values as data members on ""enum class"" enums; * Support for implicit conversion when passing by-value. 2019-05-23 : 1.4.11; -------------------. * Workaround for JITed RTTI lookup failures on 64b MS Windows; * Improved overload resolution between f(void*) and f<>(T*); * Minimal support for char16_t (Windows) and char32_t (Linux/Mac); * Do not unnecessarily autocast smart pointers. 2019-05-13 : 1.4.10; -------------------. * Imported several FindCppyy.cmake improvements from Camille's cppyy-bbhash; * Fixes to cppyy-generator for unresolved templates, void, etc.; * Fixes in typedef parsing for template arguments in unknown namespaces; * Fix in templated operator code generation; * Fixed ref-counting error for instantiated template methods. 2019-04-25 : 1.4.9; ------------------. * Fix import error on pypy-c. 2019-04-22 : 1.4.8; ------------------. * ``std::tuple`` is now iterable for return assignments w/o tie; * Support for opaque handles and typedefs of pointers to classes; * Keep unresolved enums desugared and provide generic converters; * Treat int8_t and uint8_t as integers (even when they are chars); * Fix lookup of enum values in global namespace; * Backported name mangling (esp. for static/global data lookup) for 32b Windows; * Fixed more",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:19754,Availability,error,error,19754,"conversion of python functions to ``std::function`` arguments; * Fix for templated operators that can map to different python names; * Fix on p3 crash when setting a detailed exception during exception handling; * Fix lookup of ``std::nullopt``; * Fix bug that prevented certain templated constructors from being considered; * Support for enum values as data members on ""enum class"" enums; * Support for implicit conversion when passing by-value. 2019-05-23 : 1.4.11; -------------------. * Workaround for JITed RTTI lookup failures on 64b MS Windows; * Improved overload resolution between f(void*) and f<>(T*); * Minimal support for char16_t (Windows) and char32_t (Linux/Mac); * Do not unnecessarily autocast smart pointers. 2019-05-13 : 1.4.10; -------------------. * Imported several FindCppyy.cmake improvements from Camille's cppyy-bbhash; * Fixes to cppyy-generator for unresolved templates, void, etc.; * Fixes in typedef parsing for template arguments in unknown namespaces; * Fix in templated operator code generation; * Fixed ref-counting error for instantiated template methods. 2019-04-25 : 1.4.9; ------------------. * Fix import error on pypy-c. 2019-04-22 : 1.4.8; ------------------. * ``std::tuple`` is now iterable for return assignments w/o tie; * Support for opaque handles and typedefs of pointers to classes; * Keep unresolved enums desugared and provide generic converters; * Treat int8_t and uint8_t as integers (even when they are chars); * Fix lookup of enum values in global namespace; * Backported name mangling (esp. for static/global data lookup) for 32b Windows; * Fixed more linker problems with malloc on 64b Windows; * Consistency in buffer length calculations and c_int/c_uint handling on Windows; * Properly resolve overloaded functions with using of templates from bases; * Get templated constructor info from decl instead of name comparison; * Fixed a performance regression for free functions. 2019-04-04 : 1.4.7; ------------------. * Enable initializer_list ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:19848,Availability,error,error,19848,"rash when setting a detailed exception during exception handling; * Fix lookup of ``std::nullopt``; * Fix bug that prevented certain templated constructors from being considered; * Support for enum values as data members on ""enum class"" enums; * Support for implicit conversion when passing by-value. 2019-05-23 : 1.4.11; -------------------. * Workaround for JITed RTTI lookup failures on 64b MS Windows; * Improved overload resolution between f(void*) and f<>(T*); * Minimal support for char16_t (Windows) and char32_t (Linux/Mac); * Do not unnecessarily autocast smart pointers. 2019-05-13 : 1.4.10; -------------------. * Imported several FindCppyy.cmake improvements from Camille's cppyy-bbhash; * Fixes to cppyy-generator for unresolved templates, void, etc.; * Fixes in typedef parsing for template arguments in unknown namespaces; * Fix in templated operator code generation; * Fixed ref-counting error for instantiated template methods. 2019-04-25 : 1.4.9; ------------------. * Fix import error on pypy-c. 2019-04-22 : 1.4.8; ------------------. * ``std::tuple`` is now iterable for return assignments w/o tie; * Support for opaque handles and typedefs of pointers to classes; * Keep unresolved enums desugared and provide generic converters; * Treat int8_t and uint8_t as integers (even when they are chars); * Fix lookup of enum values in global namespace; * Backported name mangling (esp. for static/global data lookup) for 32b Windows; * Fixed more linker problems with malloc on 64b Windows; * Consistency in buffer length calculations and c_int/c_uint handling on Windows; * Properly resolve overloaded functions with using of templates from bases; * Get templated constructor info from decl instead of name comparison; * Fixed a performance regression for free functions. 2019-04-04 : 1.4.7; ------------------. * Enable initializer_list conversion on Windows as well; * Improved mapping of operator() for indexing (e.g. for matrices); * Implicit conversion no longer uses global sta",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:21123,Availability,error,error,21123,"static/global data lookup) for 32b Windows; * Fixed more linker problems with malloc on 64b Windows; * Consistency in buffer length calculations and c_int/c_uint handling on Windows; * Properly resolve overloaded functions with using of templates from bases; * Get templated constructor info from decl instead of name comparison; * Fixed a performance regression for free functions. 2019-04-04 : 1.4.7; ------------------. * Enable initializer_list conversion on Windows as well; * Improved mapping of operator() for indexing (e.g. for matrices); * Implicit conversion no longer uses global state to prevent recursion; * Improved overload reordering; * Fixes for templated constructors in namespaces. 2019-04-02 : 1.4.6; ------------------. * More transparent use of smart pointers such as shared_ptr; * Expose versioned std namespace through using on Mac; * Improved error handling and interface checking in cross-inheritance; * Argument of (const/non-const) ref types support in callbacks/cross-inheritance; * Do template argument resolution in order: reference, pointer, value; * Fix for return type deduction of resolved but uninstantiated templates; * Fix wrapper generation for defaulted arguments of private types; * Several linker fixes on 64b Windows. 2019-03-25 : 1.4.5; ------------------. * Allow templated free functions to be attached as methods to classes; * Allow cross-derivation from templated classes; * More support for 'using' declarations (methods and inner namespaces); * Fix overload resolution for ``std::set::rbegin()``/``rend()`` ``operator==``; * Fixes for bugs #61, #67; * Several pointer truncation fixes for 64b Windows; * Linker and lookup fixes for Windows. 2019-03-20 : 1.4.4; ------------------. * Support for 'using' of namespaces; * Improved support for alias templates; * Faster template lookup; * Have rootcling/genreflex respect compile-time flags (except for --std if; overridden by CLING_EXTRA_ARGS); * Utility to build dictionarys on Windows (32/64); * Name",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:229,Deployability,release,releases,229,".. _changelog:. Changelog; =========. For convenience, this changelog keeps tracks of changes with version numbers; of the main cppyy package, but many of the actual changes are in the lower; level packages, which have their own releases.; See :doc:`packages <packages>`, for details on the package structure.; PyPy support lags CPython support. master; ------. * Fix buffering problems with std::string_view's on Python str objects; * Fix potential buffering problems in creation of initializer lists; * Improved overload selection for classes with deep hierarchies; * Fixed regression when calling static methods with default args on instances; * Fixed regression for pickling enums (in global scope only); * Auto-cast elements of std::vector<T*>, with T a class type; * Add a ``Sequence_Check()`` method to the public API; * Fix offset calculation of ``std::vector<unsigned>`` datamember on Mac arm. 2023-11-15: 3.1.2; -----------------. * Deprecate 3.1.1 b/c of an installation problem outside of virtualenv; * Fix installation problem when purelib and platlib differ; * Alt fix for ""failed to materialize symbols"" on some Linux systems. 2023-11-13: 3.1.0; -----------------. * Use xcrun to find header files on Mac as a last resort; * Fix for ""symbols failed to materialize"" with newer gcc on Linux; * Default to C++20 on all platforms; * Add C++20 standard headers to the PCH; * Fixes for new p11 and p12 type properties; * Fix std::span compatibility; * Look for ``__cast_cpp__`` for custom converters; * Add ``macro()`` helper for evaluation of preprocessor macros; * Extended support for int8_t/uint8_t array and pointer types; * Added ``cppyy.ll.as_memoryview()`` for byte-views of arrays of PODs; * Check for ``nullptr`` as ``false`` in ``operator bool()``; * Automatically array-ify std::vector<some struct>::data() results; * Use __name__ to stringify if an annotation object provides it; * Improve consistency of ``char[]`` arrays; * Extended Numba support; * Update to latest Cling rele",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:969,Deployability,install,installation,969,"ence, this changelog keeps tracks of changes with version numbers; of the main cppyy package, but many of the actual changes are in the lower; level packages, which have their own releases.; See :doc:`packages <packages>`, for details on the package structure.; PyPy support lags CPython support. master; ------. * Fix buffering problems with std::string_view's on Python str objects; * Fix potential buffering problems in creation of initializer lists; * Improved overload selection for classes with deep hierarchies; * Fixed regression when calling static methods with default args on instances; * Fixed regression for pickling enums (in global scope only); * Auto-cast elements of std::vector<T*>, with T a class type; * Add a ``Sequence_Check()`` method to the public API; * Fix offset calculation of ``std::vector<unsigned>`` datamember on Mac arm. 2023-11-15: 3.1.2; -----------------. * Deprecate 3.1.1 b/c of an installation problem outside of virtualenv; * Fix installation problem when purelib and platlib differ; * Alt fix for ""failed to materialize symbols"" on some Linux systems. 2023-11-13: 3.1.0; -----------------. * Use xcrun to find header files on Mac as a last resort; * Fix for ""symbols failed to materialize"" with newer gcc on Linux; * Default to C++20 on all platforms; * Add C++20 standard headers to the PCH; * Fixes for new p11 and p12 type properties; * Fix std::span compatibility; * Look for ``__cast_cpp__`` for custom converters; * Add ``macro()`` helper for evaluation of preprocessor macros; * Extended support for int8_t/uint8_t array and pointer types; * Added ``cppyy.ll.as_memoryview()`` for byte-views of arrays of PODs; * Check for ``nullptr`` as ``false`` in ``operator bool()``; * Automatically array-ify std::vector<some struct>::data() results; * Use __name__ to stringify if an annotation object provides it; * Improve consistency of ``char[]`` arrays; * Extended Numba support; * Update to latest Cling release (6.30). 2023-03-19: 3.0.0; -----------------",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:1019,Deployability,install,installation,1019,"ence, this changelog keeps tracks of changes with version numbers; of the main cppyy package, but many of the actual changes are in the lower; level packages, which have their own releases.; See :doc:`packages <packages>`, for details on the package structure.; PyPy support lags CPython support. master; ------. * Fix buffering problems with std::string_view's on Python str objects; * Fix potential buffering problems in creation of initializer lists; * Improved overload selection for classes with deep hierarchies; * Fixed regression when calling static methods with default args on instances; * Fixed regression for pickling enums (in global scope only); * Auto-cast elements of std::vector<T*>, with T a class type; * Add a ``Sequence_Check()`` method to the public API; * Fix offset calculation of ``std::vector<unsigned>`` datamember on Mac arm. 2023-11-15: 3.1.2; -----------------. * Deprecate 3.1.1 b/c of an installation problem outside of virtualenv; * Fix installation problem when purelib and platlib differ; * Alt fix for ""failed to materialize symbols"" on some Linux systems. 2023-11-13: 3.1.0; -----------------. * Use xcrun to find header files on Mac as a last resort; * Fix for ""symbols failed to materialize"" with newer gcc on Linux; * Default to C++20 on all platforms; * Add C++20 standard headers to the PCH; * Fixes for new p11 and p12 type properties; * Fix std::span compatibility; * Look for ``__cast_cpp__`` for custom converters; * Add ``macro()`` helper for evaluation of preprocessor macros; * Extended support for int8_t/uint8_t array and pointer types; * Added ``cppyy.ll.as_memoryview()`` for byte-views of arrays of PODs; * Check for ``nullptr`` as ``false`` in ``operator bool()``; * Automatically array-ify std::vector<some struct>::data() results; * Use __name__ to stringify if an annotation object provides it; * Improve consistency of ``char[]`` arrays; * Extended Numba support; * Update to latest Cling release (6.30). 2023-03-19: 3.0.0; -----------------",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:1997,Deployability,release,release,1997,"offset calculation of ``std::vector<unsigned>`` datamember on Mac arm. 2023-11-15: 3.1.2; -----------------. * Deprecate 3.1.1 b/c of an installation problem outside of virtualenv; * Fix installation problem when purelib and platlib differ; * Alt fix for ""failed to materialize symbols"" on some Linux systems. 2023-11-13: 3.1.0; -----------------. * Use xcrun to find header files on Mac as a last resort; * Fix for ""symbols failed to materialize"" with newer gcc on Linux; * Default to C++20 on all platforms; * Add C++20 standard headers to the PCH; * Fixes for new p11 and p12 type properties; * Fix std::span compatibility; * Look for ``__cast_cpp__`` for custom converters; * Add ``macro()`` helper for evaluation of preprocessor macros; * Extended support for int8_t/uint8_t array and pointer types; * Added ``cppyy.ll.as_memoryview()`` for byte-views of arrays of PODs; * Check for ``nullptr`` as ``false`` in ``operator bool()``; * Automatically array-ify std::vector<some struct>::data() results; * Use __name__ to stringify if an annotation object provides it; * Improve consistency of ``char[]`` arrays; * Extended Numba support; * Update to latest Cling release (6.30). 2023-03-19: 3.0.0; -----------------. * Upgrade backend to Cling on top of LLVM 13; * Improve handling of `const char*` as template argument; * Fix regression in use of unnamed but typedef'ed enums; * Report C++ warnings from ``cppdef`` as ``SyntaxWarning``; * Add pythonizations for ``std::unordered_map``. 2023-01-21: 2.4.2; -----------------. * Added a generic ``cppyy.default`` object; * Support explicitly created initializer lists as arguments; * Pass instances by-ref in Numba traces; * Support non-POD by-value returns in Numba traces; * Nullify derived class Python proxy when the C++ object is deleted; * Add ``__cpp_template__`` back reference for instantiated templated classes; * Improved buffer checking for ``std::initializer_list``; * Add convenience functions ``argc()`` and ``argv()`` to ``cppyy.ll``;",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:4228,Deployability,patch,patch,4228,"2022-10-03: 2.4.1; -----------------. * Drop Numba extension entry point. 2022-06-29: 2.4.0; -----------------. * Support for free (templated) functions in Numba; * Basic support for unboxing C++ public data members in Numba; * Basic support for calling methods of C++ structs in Numba; * Added conventional `__cpp_reflex__` method for inspection in Numba; * Support for globally overloaded ordering operators; * Special cases for `__repr__`/`__str__` returning C++ stringy types; * Fix lookup of templates of function with template args; * Correct typing of int8_t/uint8_t enums; * Basic support for hidden enums; * Support function pointer returns and optimize function point variables; * Fix reuse of CPPOverload proxies in vector calls from different threads; * Use `-march=native` instead of checking the cpu for avx; * Workaround for handling exceptions from JITed code on ARM; * Drop ``from cppyy.interactive import *`` from CPython 3.11; * Fix regression in converting `std::vector<T*` to `list`; * Update to the latest patch version of Cling (from 6.26.04). 2022-04-03: 2.3.1; -----------------; * Use portable type Py_ssize_t instead of ssize_t. 2022-03-08: 2.3.0; -----------------. * CUDA support (up to version 10.2); * Allow `std::string_view<char>` initialization from Python `str` (copies); * Provide access to extern ""C"" declared functions in namespaces; * Support for (multiple and nested) anonymous structs; * Pull forward upstream patch for PPC; * Only apply system_dirs patch (for asan) on Linux; * Add not-yet loaded classes to namespaces in dir(); * Fix lookup of templates of function with template args; * Fix lookup of templates types with << in name; * Fix regression for accessing `char16_t` data member arrays; * Add custom `__reshape__` method to CPPInstance to allow array cast; * Prioritize callee exceptions over bindings exceptions; * Prevent infinite recursion when instantiating class with no constructors. 2021-11-14: 2.2.0; -----------------. * Migrated repos to ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:4651,Deployability,patch,patch,4651,"asic support for hidden enums; * Support function pointer returns and optimize function point variables; * Fix reuse of CPPOverload proxies in vector calls from different threads; * Use `-march=native` instead of checking the cpu for avx; * Workaround for handling exceptions from JITed code on ARM; * Drop ``from cppyy.interactive import *`` from CPython 3.11; * Fix regression in converting `std::vector<T*` to `list`; * Update to the latest patch version of Cling (from 6.26.04). 2022-04-03: 2.3.1; -----------------; * Use portable type Py_ssize_t instead of ssize_t. 2022-03-08: 2.3.0; -----------------. * CUDA support (up to version 10.2); * Allow `std::string_view<char>` initialization from Python `str` (copies); * Provide access to extern ""C"" declared functions in namespaces; * Support for (multiple and nested) anonymous structs; * Pull forward upstream patch for PPC; * Only apply system_dirs patch (for asan) on Linux; * Add not-yet loaded classes to namespaces in dir(); * Fix lookup of templates of function with template args; * Fix lookup of templates types with << in name; * Fix regression for accessing `char16_t` data member arrays; * Add custom `__reshape__` method to CPPInstance to allow array cast; * Prioritize callee exceptions over bindings exceptions; * Prevent infinite recursion when instantiating class with no constructors. 2021-11-14: 2.2.0; -----------------. * Migrated repos to github/wlav; * Properly resolve enum type of class enums; * Get proper shape of ``void*`` and enum arrays; * Fix access to (const) ref data members; * Fix sometimes PCH uninstall issue; * Fix argument passing of fixed arrays of pointers; * Include all gcc system paths (for asan); * Initial support for Apple M1. 2021-07-17: 2.1.0; -----------------. * Support for vector calls with CPython 3.8 and newer; * Support for typed C++ literals as defaults when mixing with keywords; * Enable reshaping of multi-dim LowLevelViews; * Refactored multi-dim arrays and support for multi-dim ass",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:4691,Deployability,patch,patch,4691,"asic support for hidden enums; * Support function pointer returns and optimize function point variables; * Fix reuse of CPPOverload proxies in vector calls from different threads; * Use `-march=native` instead of checking the cpu for avx; * Workaround for handling exceptions from JITed code on ARM; * Drop ``from cppyy.interactive import *`` from CPython 3.11; * Fix regression in converting `std::vector<T*` to `list`; * Update to the latest patch version of Cling (from 6.26.04). 2022-04-03: 2.3.1; -----------------; * Use portable type Py_ssize_t instead of ssize_t. 2022-03-08: 2.3.0; -----------------. * CUDA support (up to version 10.2); * Allow `std::string_view<char>` initialization from Python `str` (copies); * Provide access to extern ""C"" declared functions in namespaces; * Support for (multiple and nested) anonymous structs; * Pull forward upstream patch for PPC; * Only apply system_dirs patch (for asan) on Linux; * Add not-yet loaded classes to namespaces in dir(); * Fix lookup of templates of function with template args; * Fix lookup of templates types with << in name; * Fix regression for accessing `char16_t` data member arrays; * Add custom `__reshape__` method to CPPInstance to allow array cast; * Prioritize callee exceptions over bindings exceptions; * Prevent infinite recursion when instantiating class with no constructors. 2021-11-14: 2.2.0; -----------------. * Migrated repos to github/wlav; * Properly resolve enum type of class enums; * Get proper shape of ``void*`` and enum arrays; * Fix access to (const) ref data members; * Fix sometimes PCH uninstall issue; * Fix argument passing of fixed arrays of pointers; * Include all gcc system paths (for asan); * Initial support for Apple M1. 2021-07-17: 2.1.0; -----------------. * Support for vector calls with CPython 3.8 and newer; * Support for typed C++ literals as defaults when mixing with keywords; * Enable reshaping of multi-dim LowLevelViews; * Refactored multi-dim arrays and support for multi-dim ass",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:6106,Deployability,patch,patch,6106,"ptions over bindings exceptions; * Prevent infinite recursion when instantiating class with no constructors. 2021-11-14: 2.2.0; -----------------. * Migrated repos to github/wlav; * Properly resolve enum type of class enums; * Get proper shape of ``void*`` and enum arrays; * Fix access to (const) ref data members; * Fix sometimes PCH uninstall issue; * Fix argument passing of fixed arrays of pointers; * Include all gcc system paths (for asan); * Initial support for Apple M1. 2021-07-17: 2.1.0; -----------------. * Support for vector calls with CPython 3.8 and newer; * Support for typed C++ literals as defaults when mixing with keywords; * Enable reshaping of multi-dim LowLevelViews; * Refactored multi-dim arrays and support for multi-dim assignment; * Support tuple-based indexing for multi-dim arrays; * Direct support for C's _Complex (_Complex_double/_float on Windows); * sizeof() forwards to ctypes.sizeof() for ctypes' types; * Upgrade cmake fragments for Clang9; * Prevent clash with Julia's LLVM when loading cppyy into PyCall; * Upgrade to latest Cling patch release. 2021-05-14: 2.0.0; -----------------. * Upgrade to latest Cling based on Clang/LLVM 9; * Make C++17 the default standard on Windows. 2021-04-28: 1.9.6; -----------------. * Reverse operators for ``std::complex`` targeting Python's ``complex``; * Version the precompiled header with the ``cppyy-cling`` package version; * Cover more iterator protocol use cases; * Add missing cppyy/__pyinstaller pkg to sdist; * Single-inheritance support for cross-inherited templated constructors; * Disallow ``float`` -> ``const long long&`` conversion; * Capture python exception message string in PyException from callbacks; * Thread safety in enum lookups. 2021-03-22: 1.9.5; -----------------. * Do not regulate direct smart pointers (many to one can lead to double deletion); * Use pkg_resources of ``CPyCppyy``, if available, to find the API include path. 2021-03-17: 1.9.4; -----------------. * Fix for installing into a ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:6112,Deployability,release,release,6112,"ptions over bindings exceptions; * Prevent infinite recursion when instantiating class with no constructors. 2021-11-14: 2.2.0; -----------------. * Migrated repos to github/wlav; * Properly resolve enum type of class enums; * Get proper shape of ``void*`` and enum arrays; * Fix access to (const) ref data members; * Fix sometimes PCH uninstall issue; * Fix argument passing of fixed arrays of pointers; * Include all gcc system paths (for asan); * Initial support for Apple M1. 2021-07-17: 2.1.0; -----------------. * Support for vector calls with CPython 3.8 and newer; * Support for typed C++ literals as defaults when mixing with keywords; * Enable reshaping of multi-dim LowLevelViews; * Refactored multi-dim arrays and support for multi-dim assignment; * Support tuple-based indexing for multi-dim arrays; * Direct support for C's _Complex (_Complex_double/_float on Windows); * sizeof() forwards to ctypes.sizeof() for ctypes' types; * Upgrade cmake fragments for Clang9; * Prevent clash with Julia's LLVM when loading cppyy into PyCall; * Upgrade to latest Cling patch release. 2021-05-14: 2.0.0; -----------------. * Upgrade to latest Cling based on Clang/LLVM 9; * Make C++17 the default standard on Windows. 2021-04-28: 1.9.6; -----------------. * Reverse operators for ``std::complex`` targeting Python's ``complex``; * Version the precompiled header with the ``cppyy-cling`` package version; * Cover more iterator protocol use cases; * Add missing cppyy/__pyinstaller pkg to sdist; * Single-inheritance support for cross-inherited templated constructors; * Disallow ``float`` -> ``const long long&`` conversion; * Capture python exception message string in PyException from callbacks; * Thread safety in enum lookups. 2021-03-22: 1.9.5; -----------------. * Do not regulate direct smart pointers (many to one can lead to double deletion); * Use pkg_resources of ``CPyCppyy``, if available, to find the API include path. 2021-03-17: 1.9.4; -----------------. * Fix for installing into a ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:7016,Deployability,install,installing,7016," * Reverse operators for ``std::complex`` targeting Python's ``complex``; * Version the precompiled header with the ``cppyy-cling`` package version; * Cover more iterator protocol use cases; * Add missing cppyy/__pyinstaller pkg to sdist; * Single-inheritance support for cross-inherited templated constructors; * Disallow ``float`` -> ``const long long&`` conversion; * Capture python exception message string in PyException from callbacks; * Thread safety in enum lookups. 2021-03-22: 1.9.5; -----------------. * Do not regulate direct smart pointers (many to one can lead to double deletion); * Use pkg_resources of ``CPyCppyy``, if available, to find the API include path. 2021-03-17: 1.9.4; -----------------. * Fix for installing into a directory that has a space in the name; * Fix empty collection printing through Cling on 64b Windows; * Fix accidental shadowing of derived class typedefs by same names in base; * Streamlined templated function lookups in namespaces; * Fix edge cases when decomposing std::function template arguments; * Enable multi-cross inheritance with non-C++ python bases; * Support Bound C++ functions as template argument; * Python functions as template arguments from ``__annotations__`` or ``__cpp_name__``; * Removed functions/apis deprecated in py3.9; * Improved support for older pip and different installation layouts. 2021-02-15: 1.9.3; -----------------. * Wheels for Linux now follow manylinux2014; * Enable direct calls of base class' methods in Python cross-overrides; * cppyy.bind_object can now re-cast types, incl. Python cross-derived ones; * Python cross-derived objects send to (and owned by) C++ retain Python state; * Ignore, for symbol lookups, libraries that can not be reloaded; * Use PathCanonicalize when resolving paths on Windows; * Add more ways of finding the backend library; * Improve error reporting when failed to find the backend library; * Workaround for mixing std::endl in JIT-ed and compiled code on Windows 32b; * Fixed a subtle ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:7628,Deployability,install,installation,7628," ``float`` -> ``const long long&`` conversion; * Capture python exception message string in PyException from callbacks; * Thread safety in enum lookups. 2021-03-22: 1.9.5; -----------------. * Do not regulate direct smart pointers (many to one can lead to double deletion); * Use pkg_resources of ``CPyCppyy``, if available, to find the API include path. 2021-03-17: 1.9.4; -----------------. * Fix for installing into a directory that has a space in the name; * Fix empty collection printing through Cling on 64b Windows; * Fix accidental shadowing of derived class typedefs by same names in base; * Streamlined templated function lookups in namespaces; * Fix edge cases when decomposing std::function template arguments; * Enable multi-cross inheritance with non-C++ python bases; * Support Bound C++ functions as template argument; * Python functions as template arguments from ``__annotations__`` or ``__cpp_name__``; * Removed functions/apis deprecated in py3.9; * Improved support for older pip and different installation layouts. 2021-02-15: 1.9.3; -----------------. * Wheels for Linux now follow manylinux2014; * Enable direct calls of base class' methods in Python cross-overrides; * cppyy.bind_object can now re-cast types, incl. Python cross-derived ones; * Python cross-derived objects send to (and owned by) C++ retain Python state; * Ignore, for symbol lookups, libraries that can not be reloaded; * Use PathCanonicalize when resolving paths on Windows; * Add more ways of finding the backend library; * Improve error reporting when failed to find the backend library; * Workaround for mixing std::endl in JIT-ed and compiled code on Windows 32b; * Fixed a subtle crash that arises when an invalid ``using`` is the last method; * Filter -fno-plt (coming from anaconda builds; not understood by Cling); * Fixed memory leak in generic base ``__str__``. 2021-01-05: 1.9.2; -----------------. * Added ``cppyy.types`` module for exposing cppyy builtin types; * Improve numpy integration with",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:8598,Deployability,integrat,integration,8598,"ts. 2021-02-15: 1.9.3; -----------------. * Wheels for Linux now follow manylinux2014; * Enable direct calls of base class' methods in Python cross-overrides; * cppyy.bind_object can now re-cast types, incl. Python cross-derived ones; * Python cross-derived objects send to (and owned by) C++ retain Python state; * Ignore, for symbol lookups, libraries that can not be reloaded; * Use PathCanonicalize when resolving paths on Windows; * Add more ways of finding the backend library; * Improve error reporting when failed to find the backend library; * Workaround for mixing std::endl in JIT-ed and compiled code on Windows 32b; * Fixed a subtle crash that arises when an invalid ``using`` is the last method; * Filter -fno-plt (coming from anaconda builds; not understood by Cling); * Fixed memory leak in generic base ``__str__``. 2021-01-05: 1.9.2; -----------------. * Added ``cppyy.types`` module for exposing cppyy builtin types; * Improve numpy integration with custom ``__array__`` methods; * Allow operator overload resolution mixing class and global methods; * Installation fixes for PyPy when using pip. 2020-11-23: 1.9.1; -----------------. * Fix custom installer in pip sdist. 2020-11-22: 1.9.0; -----------------. * In-tree build resolving build/install order for PyPy with pyproject.toml; * ``std::string`` not converterd to ``str`` on function returns; * Cover more use cases where C string memory can be managed; * Automatic memory management of converted python functions; * Added pyinstaller hooks (https://stackoverflow.com/questions/64406727); * Support for enums in pseudo-constructors of aggregates; * Fixes for overloaded/split-access protected members in cross-inheritance; * Support for deep, mixed, hierarchies for multi-cross-inheritance; * Added tp_iter method to low level views. 2020-11-06: 1.8.6; -----------------. * Fix preprocessor macro of CPyCppyy header for Windows/MSVC. 2020-10-31: 1.8.5; -----------------. * Fix leaks when using vector iterators on Py3/Linux.",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:8812,Deployability,install,installer,8812,"d_object can now re-cast types, incl. Python cross-derived ones; * Python cross-derived objects send to (and owned by) C++ retain Python state; * Ignore, for symbol lookups, libraries that can not be reloaded; * Use PathCanonicalize when resolving paths on Windows; * Add more ways of finding the backend library; * Improve error reporting when failed to find the backend library; * Workaround for mixing std::endl in JIT-ed and compiled code on Windows 32b; * Fixed a subtle crash that arises when an invalid ``using`` is the last method; * Filter -fno-plt (coming from anaconda builds; not understood by Cling); * Fixed memory leak in generic base ``__str__``. 2021-01-05: 1.9.2; -----------------. * Added ``cppyy.types`` module for exposing cppyy builtin types; * Improve numpy integration with custom ``__array__`` methods; * Allow operator overload resolution mixing class and global methods; * Installation fixes for PyPy when using pip. 2020-11-23: 1.9.1; -----------------. * Fix custom installer in pip sdist. 2020-11-22: 1.9.0; -----------------. * In-tree build resolving build/install order for PyPy with pyproject.toml; * ``std::string`` not converterd to ``str`` on function returns; * Cover more use cases where C string memory can be managed; * Automatic memory management of converted python functions; * Added pyinstaller hooks (https://stackoverflow.com/questions/64406727); * Support for enums in pseudo-constructors of aggregates; * Fixes for overloaded/split-access protected members in cross-inheritance; * Support for deep, mixed, hierarchies for multi-cross-inheritance; * Added tp_iter method to low level views. 2020-11-06: 1.8.6; -----------------. * Fix preprocessor macro of CPyCppyy header for Windows/MSVC. 2020-10-31: 1.8.5; -----------------. * Fix leaks when using vector iterators on Py3/Linux. 2020-10-10: 1.8.4; -----------------. * ``std::string`` globals/data members no longer automatically converted to ``str``; * New methods for std::string to allow ``str``",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:8906,Deployability,install,install,8906,"cts send to (and owned by) C++ retain Python state; * Ignore, for symbol lookups, libraries that can not be reloaded; * Use PathCanonicalize when resolving paths on Windows; * Add more ways of finding the backend library; * Improve error reporting when failed to find the backend library; * Workaround for mixing std::endl in JIT-ed and compiled code on Windows 32b; * Fixed a subtle crash that arises when an invalid ``using`` is the last method; * Filter -fno-plt (coming from anaconda builds; not understood by Cling); * Fixed memory leak in generic base ``__str__``. 2021-01-05: 1.9.2; -----------------. * Added ``cppyy.types`` module for exposing cppyy builtin types; * Improve numpy integration with custom ``__array__`` methods; * Allow operator overload resolution mixing class and global methods; * Installation fixes for PyPy when using pip. 2020-11-23: 1.9.1; -----------------. * Fix custom installer in pip sdist. 2020-11-22: 1.9.0; -----------------. * In-tree build resolving build/install order for PyPy with pyproject.toml; * ``std::string`` not converterd to ``str`` on function returns; * Cover more use cases where C string memory can be managed; * Automatic memory management of converted python functions; * Added pyinstaller hooks (https://stackoverflow.com/questions/64406727); * Support for enums in pseudo-constructors of aggregates; * Fixes for overloaded/split-access protected members in cross-inheritance; * Support for deep, mixed, hierarchies for multi-cross-inheritance; * Added tp_iter method to low level views. 2020-11-06: 1.8.6; -----------------. * Fix preprocessor macro of CPyCppyy header for Windows/MSVC. 2020-10-31: 1.8.5; -----------------. * Fix leaks when using vector iterators on Py3/Linux. 2020-10-10: 1.8.4; -----------------. * ``std::string`` globals/data members no longer automatically converted to ``str``; * New methods for std::string to allow ``str`` interchangability; * Added a ``decode`` method to ``std::string``; * Add pythonized ``__con",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:10127,Deployability,install,install,10127," PyPy with pyproject.toml; * ``std::string`` not converterd to ``str`` on function returns; * Cover more use cases where C string memory can be managed; * Automatic memory management of converted python functions; * Added pyinstaller hooks (https://stackoverflow.com/questions/64406727); * Support for enums in pseudo-constructors of aggregates; * Fixes for overloaded/split-access protected members in cross-inheritance; * Support for deep, mixed, hierarchies for multi-cross-inheritance; * Added tp_iter method to low level views. 2020-11-06: 1.8.6; -----------------. * Fix preprocessor macro of CPyCppyy header for Windows/MSVC. 2020-10-31: 1.8.5; -----------------. * Fix leaks when using vector iterators on Py3/Linux. 2020-10-10: 1.8.4; -----------------. * ``std::string`` globals/data members no longer automatically converted to ``str``; * New methods for std::string to allow ``str`` interchangability; * Added a ``decode`` method to ``std::string``; * Add pythonized ``__contains__`` to ``std::set``; * Fix constructor generation for aggregates with static data; * Fix performance bug when using implicit conversions; * Fix memory overwrite when parsing during sorting of methods; * PyPy pip install again falls back to setup.py install. 2020-09-21: 1.8.3; -----------------. * Add initializer constructors for PODs and aggregates; * Use actual underlying type for enums, where possible; * Enum values remain instances of their type; * Expose enum underlying type name as ``__underlying`` and ``__ctype__``; * Strictly follow C++ enum scoping rules; * Same enum in transparent scope refers to same type; * More detailed enum ``repr()`` printing, where possible; * Fix for (extern) explicit template instantiations in namespaces; * Throw objects from an std::tuple a life line; * Global pythonizors now always run on all classes; * Simplified iteraton over STL-like containers defining ``begin()``/``end()``. 2020-09-08: 1.8.2; -----------------. * Add ``cppyy.set_debug()`` to enable debu",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:10164,Deployability,install,install,10164,"tps://stackoverflow.com/questions/64406727); * Support for enums in pseudo-constructors of aggregates; * Fixes for overloaded/split-access protected members in cross-inheritance; * Support for deep, mixed, hierarchies for multi-cross-inheritance; * Added tp_iter method to low level views. 2020-11-06: 1.8.6; -----------------. * Fix preprocessor macro of CPyCppyy header for Windows/MSVC. 2020-10-31: 1.8.5; -----------------. * Fix leaks when using vector iterators on Py3/Linux. 2020-10-10: 1.8.4; -----------------. * ``std::string`` globals/data members no longer automatically converted to ``str``; * New methods for std::string to allow ``str`` interchangability; * Added a ``decode`` method to ``std::string``; * Add pythonized ``__contains__`` to ``std::set``; * Fix constructor generation for aggregates with static data; * Fix performance bug when using implicit conversions; * Fix memory overwrite when parsing during sorting of methods; * PyPy pip install again falls back to setup.py install. 2020-09-21: 1.8.3; -----------------. * Add initializer constructors for PODs and aggregates; * Use actual underlying type for enums, where possible; * Enum values remain instances of their type; * Expose enum underlying type name as ``__underlying`` and ``__ctype__``; * Strictly follow C++ enum scoping rules; * Same enum in transparent scope refers to same type; * More detailed enum ``repr()`` printing, where possible; * Fix for (extern) explicit template instantiations in namespaces; * Throw objects from an std::tuple a life line; * Global pythonizors now always run on all classes; * Simplified iteraton over STL-like containers defining ``begin()``/``end()``. 2020-09-08: 1.8.2; -----------------. * Add ``cppyy.set_debug()`` to enable debug output for fixing template errors; * Cover more partial template instantiation use cases; * Force template instantiation if necessary for type deduction (i.e. ``auto``). 2020-09-01: 1.8.1; -----------------. * Setup build dependencies with py",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:17188,Deployability,patch,patches,17188,"l trivial destructors; * Support for free function unary operators; * Refactored and optimized operator==/!= usage; * Refactored converters/executors for lower memory usage; * Bug fixes in rootcling and _cppyy_generator.py. 2019-09-25: 1.5.4; -----------------. * operator+/* now respect C++-side associativity; * Fix potential crash if modules are reloaded; * Fix some portability issues on Mac/Windows of cppyy-cling. 2019-09-15: 1.5.3; -----------------. * Performance improvements; * Support for anonymous/unnamed/nested unions; * Extended documentation. 2019-09-06: 1.5.2; -----------------. * Added a ""low level"" interface (cppyy.ll) for hard-casting and ll types; * Extended support for passing ctypes arguments through ptr, ref, ptr-ptr; * Fixed crash when creating an array of instances of a scoped inner struct; * Extended documentation. 2019-08-26: 1.5.1; -----------------. * Upgrade cppyy-cling to 6.18.2; * Various patches to upstream's pre-compiled header generation and use; * Instantiate templates with larger integer types if argument values require; * Improve cppyy.interactive and partially enable it on PyPy, IPython, etc.; * Let ``__overload__`` be more flexible in signature matching; * Make list filtering of dir(cppyy.gbl) on Windows same as Linux/Mac; * Extended documentation. 2019-08-18: 1.5.0; -----------------. * Upgrade cppyy-cling to 6.18.0; * Allow python-derived classes to be used in templates; * Stricter template resolution and better caching/performance; * Detailed memory management for make_shared and shared_ptr; * Two-way memory management for cross-inherited objects; * Reduced memory footprint of proxy objects in most common cases; * Allow implicit conversion from a tuple of arguments; * Data set on namespaces reflected on C++ even if data not yet bound; * Generalized resolution of binary operators in wrapper generation; * Proper naming of arguments in namespaces for ``std::function<>``; * Cover more cases of STL-liker iterators; * Allow ``std::vect",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:18515,Deployability,configurat,configurations,18515,"----. * Upgrade cppyy-cling to 6.18.2; * Various patches to upstream's pre-compiled header generation and use; * Instantiate templates with larger integer types if argument values require; * Improve cppyy.interactive and partially enable it on PyPy, IPython, etc.; * Let ``__overload__`` be more flexible in signature matching; * Make list filtering of dir(cppyy.gbl) on Windows same as Linux/Mac; * Extended documentation. 2019-08-18: 1.5.0; -----------------. * Upgrade cppyy-cling to 6.18.0; * Allow python-derived classes to be used in templates; * Stricter template resolution and better caching/performance; * Detailed memory management for make_shared and shared_ptr; * Two-way memory management for cross-inherited objects; * Reduced memory footprint of proxy objects in most common cases; * Allow implicit conversion from a tuple of arguments; * Data set on namespaces reflected on C++ even if data not yet bound; * Generalized resolution of binary operators in wrapper generation; * Proper naming of arguments in namespaces for ``std::function<>``; * Cover more cases of STL-liker iterators; * Allow ``std::vector`` initialization with a list of constructor arguments; * Consistent naming of ``__cppname__`` to ``__cpp_name__``; * Added ``__set_lifeline__`` attribute to overloads; * Fixes to the cmake fragments for Ubuntu; * Fixes linker errors on Windows in some configurations; * Support C++ naming of typedef of bool types; * Basic views of 2D arrays of builtin types; * Extended documentation. 2019-07-01 : 1.4.12; -------------------. * Automatic conversion of python functions to ``std::function`` arguments; * Fix for templated operators that can map to different python names; * Fix on p3 crash when setting a detailed exception during exception handling; * Fix lookup of ``std::nullopt``; * Fix bug that prevented certain templated constructors from being considered; * Support for enum values as data members on ""enum class"" enums; * Support for implicit conversion when passing ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:6462,Integrability,protocol,protocol,6462,"1.0; -----------------. * Support for vector calls with CPython 3.8 and newer; * Support for typed C++ literals as defaults when mixing with keywords; * Enable reshaping of multi-dim LowLevelViews; * Refactored multi-dim arrays and support for multi-dim assignment; * Support tuple-based indexing for multi-dim arrays; * Direct support for C's _Complex (_Complex_double/_float on Windows); * sizeof() forwards to ctypes.sizeof() for ctypes' types; * Upgrade cmake fragments for Clang9; * Prevent clash with Julia's LLVM when loading cppyy into PyCall; * Upgrade to latest Cling patch release. 2021-05-14: 2.0.0; -----------------. * Upgrade to latest Cling based on Clang/LLVM 9; * Make C++17 the default standard on Windows. 2021-04-28: 1.9.6; -----------------. * Reverse operators for ``std::complex`` targeting Python's ``complex``; * Version the precompiled header with the ``cppyy-cling`` package version; * Cover more iterator protocol use cases; * Add missing cppyy/__pyinstaller pkg to sdist; * Single-inheritance support for cross-inherited templated constructors; * Disallow ``float`` -> ``const long long&`` conversion; * Capture python exception message string in PyException from callbacks; * Thread safety in enum lookups. 2021-03-22: 1.9.5; -----------------. * Do not regulate direct smart pointers (many to one can lead to double deletion); * Use pkg_resources of ``CPyCppyy``, if available, to find the API include path. 2021-03-17: 1.9.4; -----------------. * Fix for installing into a directory that has a space in the name; * Fix empty collection printing through Cling on 64b Windows; * Fix accidental shadowing of derived class typedefs by same names in base; * Streamlined templated function lookups in namespaces; * Fix edge cases when decomposing std::function template arguments; * Enable multi-cross inheritance with non-C++ python bases; * Support Bound C++ functions as template argument; * Python functions as template arguments from ``__annotations__`` or ``__cpp_nam",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:6687,Integrability,message,message,6687,"1.0; -----------------. * Support for vector calls with CPython 3.8 and newer; * Support for typed C++ literals as defaults when mixing with keywords; * Enable reshaping of multi-dim LowLevelViews; * Refactored multi-dim arrays and support for multi-dim assignment; * Support tuple-based indexing for multi-dim arrays; * Direct support for C's _Complex (_Complex_double/_float on Windows); * sizeof() forwards to ctypes.sizeof() for ctypes' types; * Upgrade cmake fragments for Clang9; * Prevent clash with Julia's LLVM when loading cppyy into PyCall; * Upgrade to latest Cling patch release. 2021-05-14: 2.0.0; -----------------. * Upgrade to latest Cling based on Clang/LLVM 9; * Make C++17 the default standard on Windows. 2021-04-28: 1.9.6; -----------------. * Reverse operators for ``std::complex`` targeting Python's ``complex``; * Version the precompiled header with the ``cppyy-cling`` package version; * Cover more iterator protocol use cases; * Add missing cppyy/__pyinstaller pkg to sdist; * Single-inheritance support for cross-inherited templated constructors; * Disallow ``float`` -> ``const long long&`` conversion; * Capture python exception message string in PyException from callbacks; * Thread safety in enum lookups. 2021-03-22: 1.9.5; -----------------. * Do not regulate direct smart pointers (many to one can lead to double deletion); * Use pkg_resources of ``CPyCppyy``, if available, to find the API include path. 2021-03-17: 1.9.4; -----------------. * Fix for installing into a directory that has a space in the name; * Fix empty collection printing through Cling on 64b Windows; * Fix accidental shadowing of derived class typedefs by same names in base; * Streamlined templated function lookups in namespaces; * Fix edge cases when decomposing std::function template arguments; * Enable multi-cross inheritance with non-C++ python bases; * Support Bound C++ functions as template argument; * Python functions as template arguments from ``__annotations__`` or ``__cpp_nam",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:8598,Integrability,integrat,integration,8598,"ts. 2021-02-15: 1.9.3; -----------------. * Wheels for Linux now follow manylinux2014; * Enable direct calls of base class' methods in Python cross-overrides; * cppyy.bind_object can now re-cast types, incl. Python cross-derived ones; * Python cross-derived objects send to (and owned by) C++ retain Python state; * Ignore, for symbol lookups, libraries that can not be reloaded; * Use PathCanonicalize when resolving paths on Windows; * Add more ways of finding the backend library; * Improve error reporting when failed to find the backend library; * Workaround for mixing std::endl in JIT-ed and compiled code on Windows 32b; * Fixed a subtle crash that arises when an invalid ``using`` is the last method; * Filter -fno-plt (coming from anaconda builds; not understood by Cling); * Fixed memory leak in generic base ``__str__``. 2021-01-05: 1.9.2; -----------------. * Added ``cppyy.types`` module for exposing cppyy builtin types; * Improve numpy integration with custom ``__array__`` methods; * Allow operator overload resolution mixing class and global methods; * Installation fixes for PyPy when using pip. 2020-11-23: 1.9.1; -----------------. * Fix custom installer in pip sdist. 2020-11-22: 1.9.0; -----------------. * In-tree build resolving build/install order for PyPy with pyproject.toml; * ``std::string`` not converterd to ``str`` on function returns; * Cover more use cases where C string memory can be managed; * Automatic memory management of converted python functions; * Added pyinstaller hooks (https://stackoverflow.com/questions/64406727); * Support for enums in pseudo-constructors of aggregates; * Fixes for overloaded/split-access protected members in cross-inheritance; * Support for deep, mixed, hierarchies for multi-cross-inheritance; * Added tp_iter method to low level views. 2020-11-06: 1.8.6; -----------------. * Fix preprocessor macro of CPyCppyy header for Windows/MSVC. 2020-10-31: 1.8.5; -----------------. * Fix leaks when using vector iterators on Py3/Linux.",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:11147,Integrability,depend,dependencies,11147,"o setup.py install. 2020-09-21: 1.8.3; -----------------. * Add initializer constructors for PODs and aggregates; * Use actual underlying type for enums, where possible; * Enum values remain instances of their type; * Expose enum underlying type name as ``__underlying`` and ``__ctype__``; * Strictly follow C++ enum scoping rules; * Same enum in transparent scope refers to same type; * More detailed enum ``repr()`` printing, where possible; * Fix for (extern) explicit template instantiations in namespaces; * Throw objects from an std::tuple a life line; * Global pythonizors now always run on all classes; * Simplified iteraton over STL-like containers defining ``begin()``/``end()``. 2020-09-08: 1.8.2; -----------------. * Add ``cppyy.set_debug()`` to enable debug output for fixing template errors; * Cover more partial template instantiation use cases; * Force template instantiation if necessary for type deduction (i.e. ``auto``). 2020-09-01: 1.8.1; -----------------. * Setup build dependencies with pyproject.toml; * Simplified flow of pointer types for callbacks and cross-derivation; * Pointer-comparing objects performs auto-cast as needed; * Add main dimension for ptr-ptr to builtin returns; * Transparant handling of ptr-ptr to instance returns; * Stricter handling of bool type in overload with int types; * Fix uint64_t template instantiation regression; * Do not filter out enum data for ``__dir__``; * Fix lookup of interpreter-only explicit instantiations; * Fix inconsistent naming of std types with char_traits; * Further hiding of upstream code/dependencies; * Extended documentation. 2020-07-12: 1.8.0; -----------------. * Support mixing of Python and C++ types in global operators; * Capture Cling error messages from cppdef and include in the Python exception; * Add a cppexec method to evalutate statements in Cling's global scope; * Support initialization of ``std::array<>`` from sequences; * Support C++17 style initialization of common STL containers; * Allow base ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:11725,Integrability,depend,dependencies,11725," scoping rules; * Same enum in transparent scope refers to same type; * More detailed enum ``repr()`` printing, where possible; * Fix for (extern) explicit template instantiations in namespaces; * Throw objects from an std::tuple a life line; * Global pythonizors now always run on all classes; * Simplified iteraton over STL-like containers defining ``begin()``/``end()``. 2020-09-08: 1.8.2; -----------------. * Add ``cppyy.set_debug()`` to enable debug output for fixing template errors; * Cover more partial template instantiation use cases; * Force template instantiation if necessary for type deduction (i.e. ``auto``). 2020-09-01: 1.8.1; -----------------. * Setup build dependencies with pyproject.toml; * Simplified flow of pointer types for callbacks and cross-derivation; * Pointer-comparing objects performs auto-cast as needed; * Add main dimension for ptr-ptr to builtin returns; * Transparant handling of ptr-ptr to instance returns; * Stricter handling of bool type in overload with int types; * Fix uint64_t template instantiation regression; * Do not filter out enum data for ``__dir__``; * Fix lookup of interpreter-only explicit instantiations; * Fix inconsistent naming of std types with char_traits; * Further hiding of upstream code/dependencies; * Extended documentation. 2020-07-12: 1.8.0; -----------------. * Support mixing of Python and C++ types in global operators; * Capture Cling error messages from cppdef and include in the Python exception; * Add a cppexec method to evalutate statements in Cling's global scope; * Support initialization of ``std::array<>`` from sequences; * Support C++17 style initialization of common STL containers; * Allow base classes with no virtual destructor (with warning); * Support const by-value returns in Python-side method overrides; * Support for cross-language multiple inheritance of C++ bases; * Allow for pass-by-value of ``std::unique_ptr`` through move; * Reduced dependencies on upstream code; * Put remaining upstream code i",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:11887,Integrability,message,messages,11887,"ependencies with pyproject.toml; * Simplified flow of pointer types for callbacks and cross-derivation; * Pointer-comparing objects performs auto-cast as needed; * Add main dimension for ptr-ptr to builtin returns; * Transparant handling of ptr-ptr to instance returns; * Stricter handling of bool type in overload with int types; * Fix uint64_t template instantiation regression; * Do not filter out enum data for ``__dir__``; * Fix lookup of interpreter-only explicit instantiations; * Fix inconsistent naming of std types with char_traits; * Further hiding of upstream code/dependencies; * Extended documentation. 2020-07-12: 1.8.0; -----------------. * Support mixing of Python and C++ types in global operators; * Capture Cling error messages from cppdef and include in the Python exception; * Add a cppexec method to evalutate statements in Cling's global scope; * Support initialization of ``std::array<>`` from sequences; * Support C++17 style initialization of common STL containers; * Allow base classes with no virtual destructor (with warning); * Support const by-value returns in Python-side method overrides; * Support for cross-language multiple inheritance of C++ bases; * Allow for pass-by-value of ``std::unique_ptr`` through move; * Reduced dependencies on upstream code; * Put remaining upstream code in CppyyLegacy namespace. 2020-06-06: 1.7.1; -----------------. * Expose protected members in Python derived classes; * Support for deep Python-side derived hierarchies; * Do not generate a copy ctor in the Python derived class if private; * include, c_include, and cppdef now raise exceptions on error; * Allow mixing of keywords and default values; * Fix by-ptr return of objects in Python derived classes; * Fix for passing numpy boolean array through ``bool*``; * Fix assignment to ``const char*`` data members; * Support ``__restrict`` and ``__restrict__`` in interfaces; * Allow passing sequence of strings through ``const char*[]`` argument. 2020-04-27: 1.7.0; -----------",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:12408,Integrability,depend,dependencies,12408,"ependencies with pyproject.toml; * Simplified flow of pointer types for callbacks and cross-derivation; * Pointer-comparing objects performs auto-cast as needed; * Add main dimension for ptr-ptr to builtin returns; * Transparant handling of ptr-ptr to instance returns; * Stricter handling of bool type in overload with int types; * Fix uint64_t template instantiation regression; * Do not filter out enum data for ``__dir__``; * Fix lookup of interpreter-only explicit instantiations; * Fix inconsistent naming of std types with char_traits; * Further hiding of upstream code/dependencies; * Extended documentation. 2020-07-12: 1.8.0; -----------------. * Support mixing of Python and C++ types in global operators; * Capture Cling error messages from cppdef and include in the Python exception; * Add a cppexec method to evalutate statements in Cling's global scope; * Support initialization of ``std::array<>`` from sequences; * Support C++17 style initialization of common STL containers; * Allow base classes with no virtual destructor (with warning); * Support const by-value returns in Python-side method overrides; * Support for cross-language multiple inheritance of C++ bases; * Allow for pass-by-value of ``std::unique_ptr`` through move; * Reduced dependencies on upstream code; * Put remaining upstream code in CppyyLegacy namespace. 2020-06-06: 1.7.1; -----------------. * Expose protected members in Python derived classes; * Support for deep Python-side derived hierarchies; * Do not generate a copy ctor in the Python derived class if private; * include, c_include, and cppdef now raise exceptions on error; * Allow mixing of keywords and default values; * Fix by-ptr return of objects in Python derived classes; * Fix for passing numpy boolean array through ``bool*``; * Fix assignment to ``const char*`` data members; * Support ``__restrict`` and ``__restrict__`` in interfaces; * Allow passing sequence of strings through ``const char*[]`` argument. 2020-04-27: 1.7.0; -----------",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:13034,Integrability,interface,interfaces,13034,"ython and C++ types in global operators; * Capture Cling error messages from cppdef and include in the Python exception; * Add a cppexec method to evalutate statements in Cling's global scope; * Support initialization of ``std::array<>`` from sequences; * Support C++17 style initialization of common STL containers; * Allow base classes with no virtual destructor (with warning); * Support const by-value returns in Python-side method overrides; * Support for cross-language multiple inheritance of C++ bases; * Allow for pass-by-value of ``std::unique_ptr`` through move; * Reduced dependencies on upstream code; * Put remaining upstream code in CppyyLegacy namespace. 2020-06-06: 1.7.1; -----------------. * Expose protected members in Python derived classes; * Support for deep Python-side derived hierarchies; * Do not generate a copy ctor in the Python derived class if private; * include, c_include, and cppdef now raise exceptions on error; * Allow mixing of keywords and default values; * Fix by-ptr return of objects in Python derived classes; * Fix for passing numpy boolean array through ``bool*``; * Fix assignment to ``const char*`` data members; * Support ``__restrict`` and ``__restrict__`` in interfaces; * Allow passing sequence of strings through ``const char*[]`` argument. 2020-04-27: 1.7.0; -----------------. * Upgrade to cppyy-cling 6.20.4; * Pre-empt upstream's propensity of making ``std`` classes etc. global; * Allow initialization of ``std::map`` from dict with the correct types; * Allow initialization of ``std::set`` from set with the correct types; * Add optional nonst/non-const selection to ``__overload__``; * Automatic smartification of normal object passed as smartptr by value; * Fix crash when handing a by-value object to make_shared; * Fixed a few shared/unique_ptr corner cases; * Fixed conversion of ``std::function`` taking an STL class parameter; * No longer attempt auto-cast on classes without RTTI; * Fix for ``iter()`` iteration on generic STL contain",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:16878,Integrability,interface,interface,16878,"th non-templated ``__setitem__``; * Support for array of const char* as C-strings; * Enable type resolution of clang's builtin ``__type_pack_element``; * Fix for inner class type naming when it directly declares a variable. 2019-10-16: 1.5.5; -----------------. * Added signal -> exception support in cppyy.ll; * Support for lazily combining overloads of operator*/+-; * No longer call trivial destructors; * Support for free function unary operators; * Refactored and optimized operator==/!= usage; * Refactored converters/executors for lower memory usage; * Bug fixes in rootcling and _cppyy_generator.py. 2019-09-25: 1.5.4; -----------------. * operator+/* now respect C++-side associativity; * Fix potential crash if modules are reloaded; * Fix some portability issues on Mac/Windows of cppyy-cling. 2019-09-15: 1.5.3; -----------------. * Performance improvements; * Support for anonymous/unnamed/nested unions; * Extended documentation. 2019-09-06: 1.5.2; -----------------. * Added a ""low level"" interface (cppyy.ll) for hard-casting and ll types; * Extended support for passing ctypes arguments through ptr, ref, ptr-ptr; * Fixed crash when creating an array of instances of a scoped inner struct; * Extended documentation. 2019-08-26: 1.5.1; -----------------. * Upgrade cppyy-cling to 6.18.2; * Various patches to upstream's pre-compiled header generation and use; * Instantiate templates with larger integer types if argument values require; * Improve cppyy.interactive and partially enable it on PyPy, IPython, etc.; * Let ``__overload__`` be more flexible in signature matching; * Make list filtering of dir(cppyy.gbl) on Windows same as Linux/Mac; * Extended documentation. 2019-08-18: 1.5.0; -----------------. * Upgrade cppyy-cling to 6.18.0; * Allow python-derived classes to be used in templates; * Stricter template resolution and better caching/performance; * Detailed memory management for make_shared and shared_ptr; * Two-way memory management for cross-inherited objects; * Re",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:18110,Integrability,wrap,wrapper,18110,"----. * Upgrade cppyy-cling to 6.18.2; * Various patches to upstream's pre-compiled header generation and use; * Instantiate templates with larger integer types if argument values require; * Improve cppyy.interactive and partially enable it on PyPy, IPython, etc.; * Let ``__overload__`` be more flexible in signature matching; * Make list filtering of dir(cppyy.gbl) on Windows same as Linux/Mac; * Extended documentation. 2019-08-18: 1.5.0; -----------------. * Upgrade cppyy-cling to 6.18.0; * Allow python-derived classes to be used in templates; * Stricter template resolution and better caching/performance; * Detailed memory management for make_shared and shared_ptr; * Two-way memory management for cross-inherited objects; * Reduced memory footprint of proxy objects in most common cases; * Allow implicit conversion from a tuple of arguments; * Data set on namespaces reflected on C++ even if data not yet bound; * Generalized resolution of binary operators in wrapper generation; * Proper naming of arguments in namespaces for ``std::function<>``; * Cover more cases of STL-liker iterators; * Allow ``std::vector`` initialization with a list of constructor arguments; * Consistent naming of ``__cppname__`` to ``__cpp_name__``; * Added ``__set_lifeline__`` attribute to overloads; * Fixes to the cmake fragments for Ubuntu; * Fixes linker errors on Windows in some configurations; * Support C++ naming of typedef of bool types; * Basic views of 2D arrays of builtin types; * Extended documentation. 2019-07-01 : 1.4.12; -------------------. * Automatic conversion of python functions to ``std::function`` arguments; * Fix for templated operators that can map to different python names; * Fix on p3 crash when setting a detailed exception during exception handling; * Fix lookup of ``std::nullopt``; * Fix bug that prevented certain templated constructors from being considered; * Support for enum values as data members on ""enum class"" enums; * Support for implicit conversion when passing ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:21142,Integrability,interface,interface,21142,"static/global data lookup) for 32b Windows; * Fixed more linker problems with malloc on 64b Windows; * Consistency in buffer length calculations and c_int/c_uint handling on Windows; * Properly resolve overloaded functions with using of templates from bases; * Get templated constructor info from decl instead of name comparison; * Fixed a performance regression for free functions. 2019-04-04 : 1.4.7; ------------------. * Enable initializer_list conversion on Windows as well; * Improved mapping of operator() for indexing (e.g. for matrices); * Implicit conversion no longer uses global state to prevent recursion; * Improved overload reordering; * Fixes for templated constructors in namespaces. 2019-04-02 : 1.4.6; ------------------. * More transparent use of smart pointers such as shared_ptr; * Expose versioned std namespace through using on Mac; * Improved error handling and interface checking in cross-inheritance; * Argument of (const/non-const) ref types support in callbacks/cross-inheritance; * Do template argument resolution in order: reference, pointer, value; * Fix for return type deduction of resolved but uninstantiated templates; * Fix wrapper generation for defaulted arguments of private types; * Several linker fixes on 64b Windows. 2019-03-25 : 1.4.5; ------------------. * Allow templated free functions to be attached as methods to classes; * Allow cross-derivation from templated classes; * More support for 'using' declarations (methods and inner namespaces); * Fix overload resolution for ``std::set::rbegin()``/``rend()`` ``operator==``; * Fixes for bugs #61, #67; * Several pointer truncation fixes for 64b Windows; * Linker and lookup fixes for Windows. 2019-03-20 : 1.4.4; ------------------. * Support for 'using' of namespaces; * Improved support for alias templates; * Faster template lookup; * Have rootcling/genreflex respect compile-time flags (except for --std if; overridden by CLING_EXTRA_ARGS); * Utility to build dictionarys on Windows (32/64); * Name",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:21416,Integrability,wrap,wrapper,21416,"static/global data lookup) for 32b Windows; * Fixed more linker problems with malloc on 64b Windows; * Consistency in buffer length calculations and c_int/c_uint handling on Windows; * Properly resolve overloaded functions with using of templates from bases; * Get templated constructor info from decl instead of name comparison; * Fixed a performance regression for free functions. 2019-04-04 : 1.4.7; ------------------. * Enable initializer_list conversion on Windows as well; * Improved mapping of operator() for indexing (e.g. for matrices); * Implicit conversion no longer uses global state to prevent recursion; * Improved overload reordering; * Fixes for templated constructors in namespaces. 2019-04-02 : 1.4.6; ------------------. * More transparent use of smart pointers such as shared_ptr; * Expose versioned std namespace through using on Mac; * Improved error handling and interface checking in cross-inheritance; * Argument of (const/non-const) ref types support in callbacks/cross-inheritance; * Do template argument resolution in order: reference, pointer, value; * Fix for return type deduction of resolved but uninstantiated templates; * Fix wrapper generation for defaulted arguments of private types; * Several linker fixes on 64b Windows. 2019-03-25 : 1.4.5; ------------------. * Allow templated free functions to be attached as methods to classes; * Allow cross-derivation from templated classes; * More support for 'using' declarations (methods and inner namespaces); * Fix overload resolution for ``std::set::rbegin()``/``rend()`` ``operator==``; * Fixes for bugs #61, #67; * Several pointer truncation fixes for 64b Windows; * Linker and lookup fixes for Windows. 2019-03-20 : 1.4.4; ------------------. * Support for 'using' of namespaces; * Improved support for alias templates; * Faster template lookup; * Have rootcling/genreflex respect compile-time flags (except for --std if; overridden by CLING_EXTRA_ARGS); * Utility to build dictionarys on Windows (32/64); * Name",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:2969,Modifiability,inherit,inheritance,2969,2023-03-19: 3.0.0; -----------------. * Upgrade backend to Cling on top of LLVM 13; * Improve handling of `const char*` as template argument; * Fix regression in use of unnamed but typedef'ed enums; * Report C++ warnings from ``cppdef`` as ``SyntaxWarning``; * Add pythonizations for ``std::unordered_map``. 2023-01-21: 2.4.2; -----------------. * Added a generic ``cppyy.default`` object; * Support explicitly created initializer lists as arguments; * Pass instances by-ref in Numba traces; * Support non-POD by-value returns in Numba traces; * Nullify derived class Python proxy when the C++ object is deleted; * Add ``__cpp_template__`` back reference for instantiated templated classes; * Improved buffer checking for ``std::initializer_list``; * Add convenience functions ``argc()`` and ``argv()`` to ``cppyy.ll``; * Added ``nullptr`` comparisons for for typed ``nullptr``; * Support for ``using`` pointer types as template arguments; * Walk the full inheritance tree to find the overloads; * Allow ``__destruct__`` override in Python derived class; * Allow ``NULL`` function pointers to be returned as ``std::function`` objects; * Add Python traceback to C++ exception ``what()``. 2022-10-03: 2.4.1; -----------------. * Drop Numba extension entry point. 2022-06-29: 2.4.0; -----------------. * Support for free (templated) functions in Numba; * Basic support for unboxing C++ public data members in Numba; * Basic support for calling methods of C++ structs in Numba; * Added conventional `__cpp_reflex__` method for inspection in Numba; * Support for globally overloaded ordering operators; * Special cases for `__repr__`/`__str__` returning C++ stringy types; * Fix lookup of templates of function with template args; * Correct typing of int8_t/uint8_t enums; * Basic support for hidden enums; * Support function pointer returns and optimize function point variables; * Fix reuse of CPPOverload proxies in vector calls from different threads; * Use `-march=native` instead of checking the cpu,MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:3878,Modifiability,variab,variables,3878,"mproved buffer checking for ``std::initializer_list``; * Add convenience functions ``argc()`` and ``argv()`` to ``cppyy.ll``; * Added ``nullptr`` comparisons for for typed ``nullptr``; * Support for ``using`` pointer types as template arguments; * Walk the full inheritance tree to find the overloads; * Allow ``__destruct__`` override in Python derived class; * Allow ``NULL`` function pointers to be returned as ``std::function`` objects; * Add Python traceback to C++ exception ``what()``. 2022-10-03: 2.4.1; -----------------. * Drop Numba extension entry point. 2022-06-29: 2.4.0; -----------------. * Support for free (templated) functions in Numba; * Basic support for unboxing C++ public data members in Numba; * Basic support for calling methods of C++ structs in Numba; * Added conventional `__cpp_reflex__` method for inspection in Numba; * Support for globally overloaded ordering operators; * Special cases for `__repr__`/`__str__` returning C++ stringy types; * Fix lookup of templates of function with template args; * Correct typing of int8_t/uint8_t enums; * Basic support for hidden enums; * Support function pointer returns and optimize function point variables; * Fix reuse of CPPOverload proxies in vector calls from different threads; * Use `-march=native` instead of checking the cpu for avx; * Workaround for handling exceptions from JITed code on ARM; * Drop ``from cppyy.interactive import *`` from CPython 3.11; * Fix regression in converting `std::vector<T*` to `list`; * Update to the latest patch version of Cling (from 6.26.04). 2022-04-03: 2.3.1; -----------------; * Use portable type Py_ssize_t instead of ssize_t. 2022-03-08: 2.3.0; -----------------. * CUDA support (up to version 10.2); * Allow `std::string_view<char>` initialization from Python `str` (copies); * Provide access to extern ""C"" declared functions in namespaces; * Support for (multiple and nested) anonymous structs; * Pull forward upstream patch for PPC; * Only apply system_dirs patch (for asan) ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:4311,Modifiability,portab,portable,4311,"rt for free (templated) functions in Numba; * Basic support for unboxing C++ public data members in Numba; * Basic support for calling methods of C++ structs in Numba; * Added conventional `__cpp_reflex__` method for inspection in Numba; * Support for globally overloaded ordering operators; * Special cases for `__repr__`/`__str__` returning C++ stringy types; * Fix lookup of templates of function with template args; * Correct typing of int8_t/uint8_t enums; * Basic support for hidden enums; * Support function pointer returns and optimize function point variables; * Fix reuse of CPPOverload proxies in vector calls from different threads; * Use `-march=native` instead of checking the cpu for avx; * Workaround for handling exceptions from JITed code on ARM; * Drop ``from cppyy.interactive import *`` from CPython 3.11; * Fix regression in converting `std::vector<T*` to `list`; * Update to the latest patch version of Cling (from 6.26.04). 2022-04-03: 2.3.1; -----------------; * Use portable type Py_ssize_t instead of ssize_t. 2022-03-08: 2.3.0; -----------------. * CUDA support (up to version 10.2); * Allow `std::string_view<char>` initialization from Python `str` (copies); * Provide access to extern ""C"" declared functions in namespaces; * Support for (multiple and nested) anonymous structs; * Pull forward upstream patch for PPC; * Only apply system_dirs patch (for asan) on Linux; * Add not-yet loaded classes to namespaces in dir(); * Fix lookup of templates of function with template args; * Fix lookup of templates types with << in name; * Fix regression for accessing `char16_t` data member arrays; * Add custom `__reshape__` method to CPPInstance to allow array cast; * Prioritize callee exceptions over bindings exceptions; * Prevent infinite recursion when instantiating class with no constructors. 2021-11-14: 2.2.0; -----------------. * Migrated repos to github/wlav; * Properly resolve enum type of class enums; * Get proper shape of ``void*`` and enum arrays; * Fix acces",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:6539,Modifiability,inherit,inheritance,6539,"1.0; -----------------. * Support for vector calls with CPython 3.8 and newer; * Support for typed C++ literals as defaults when mixing with keywords; * Enable reshaping of multi-dim LowLevelViews; * Refactored multi-dim arrays and support for multi-dim assignment; * Support tuple-based indexing for multi-dim arrays; * Direct support for C's _Complex (_Complex_double/_float on Windows); * sizeof() forwards to ctypes.sizeof() for ctypes' types; * Upgrade cmake fragments for Clang9; * Prevent clash with Julia's LLVM when loading cppyy into PyCall; * Upgrade to latest Cling patch release. 2021-05-14: 2.0.0; -----------------. * Upgrade to latest Cling based on Clang/LLVM 9; * Make C++17 the default standard on Windows. 2021-04-28: 1.9.6; -----------------. * Reverse operators for ``std::complex`` targeting Python's ``complex``; * Version the precompiled header with the ``cppyy-cling`` package version; * Cover more iterator protocol use cases; * Add missing cppyy/__pyinstaller pkg to sdist; * Single-inheritance support for cross-inherited templated constructors; * Disallow ``float`` -> ``const long long&`` conversion; * Capture python exception message string in PyException from callbacks; * Thread safety in enum lookups. 2021-03-22: 1.9.5; -----------------. * Do not regulate direct smart pointers (many to one can lead to double deletion); * Use pkg_resources of ``CPyCppyy``, if available, to find the API include path. 2021-03-17: 1.9.4; -----------------. * Fix for installing into a directory that has a space in the name; * Fix empty collection printing through Cling on 64b Windows; * Fix accidental shadowing of derived class typedefs by same names in base; * Streamlined templated function lookups in namespaces; * Fix edge cases when decomposing std::function template arguments; * Enable multi-cross inheritance with non-C++ python bases; * Support Bound C++ functions as template argument; * Python functions as template arguments from ``__annotations__`` or ``__cpp_nam",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:6569,Modifiability,inherit,inherited,6569,"1.0; -----------------. * Support for vector calls with CPython 3.8 and newer; * Support for typed C++ literals as defaults when mixing with keywords; * Enable reshaping of multi-dim LowLevelViews; * Refactored multi-dim arrays and support for multi-dim assignment; * Support tuple-based indexing for multi-dim arrays; * Direct support for C's _Complex (_Complex_double/_float on Windows); * sizeof() forwards to ctypes.sizeof() for ctypes' types; * Upgrade cmake fragments for Clang9; * Prevent clash with Julia's LLVM when loading cppyy into PyCall; * Upgrade to latest Cling patch release. 2021-05-14: 2.0.0; -----------------. * Upgrade to latest Cling based on Clang/LLVM 9; * Make C++17 the default standard on Windows. 2021-04-28: 1.9.6; -----------------. * Reverse operators for ``std::complex`` targeting Python's ``complex``; * Version the precompiled header with the ``cppyy-cling`` package version; * Cover more iterator protocol use cases; * Add missing cppyy/__pyinstaller pkg to sdist; * Single-inheritance support for cross-inherited templated constructors; * Disallow ``float`` -> ``const long long&`` conversion; * Capture python exception message string in PyException from callbacks; * Thread safety in enum lookups. 2021-03-22: 1.9.5; -----------------. * Do not regulate direct smart pointers (many to one can lead to double deletion); * Use pkg_resources of ``CPyCppyy``, if available, to find the API include path. 2021-03-17: 1.9.4; -----------------. * Fix for installing into a directory that has a space in the name; * Fix empty collection printing through Cling on 64b Windows; * Fix accidental shadowing of derived class typedefs by same names in base; * Streamlined templated function lookups in namespaces; * Fix edge cases when decomposing std::function template arguments; * Enable multi-cross inheritance with non-C++ python bases; * Support Bound C++ functions as template argument; * Python functions as template arguments from ``__annotations__`` or ``__cpp_nam",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:7357,Modifiability,inherit,inheritance,7357," * Reverse operators for ``std::complex`` targeting Python's ``complex``; * Version the precompiled header with the ``cppyy-cling`` package version; * Cover more iterator protocol use cases; * Add missing cppyy/__pyinstaller pkg to sdist; * Single-inheritance support for cross-inherited templated constructors; * Disallow ``float`` -> ``const long long&`` conversion; * Capture python exception message string in PyException from callbacks; * Thread safety in enum lookups. 2021-03-22: 1.9.5; -----------------. * Do not regulate direct smart pointers (many to one can lead to double deletion); * Use pkg_resources of ``CPyCppyy``, if available, to find the API include path. 2021-03-17: 1.9.4; -----------------. * Fix for installing into a directory that has a space in the name; * Fix empty collection printing through Cling on 64b Windows; * Fix accidental shadowing of derived class typedefs by same names in base; * Streamlined templated function lookups in namespaces; * Fix edge cases when decomposing std::function template arguments; * Enable multi-cross inheritance with non-C++ python bases; * Support Bound C++ functions as template argument; * Python functions as template arguments from ``__annotations__`` or ``__cpp_name__``; * Removed functions/apis deprecated in py3.9; * Improved support for older pip and different installation layouts. 2021-02-15: 1.9.3; -----------------. * Wheels for Linux now follow manylinux2014; * Enable direct calls of base class' methods in Python cross-overrides; * cppyy.bind_object can now re-cast types, incl. Python cross-derived ones; * Python cross-derived objects send to (and owned by) C++ retain Python state; * Ignore, for symbol lookups, libraries that can not be reloaded; * Use PathCanonicalize when resolving paths on Windows; * Add more ways of finding the backend library; * Improve error reporting when failed to find the backend library; * Workaround for mixing std::endl in JIT-ed and compiled code on Windows 32b; * Fixed a subtle ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:9332,Modifiability,inherit,inheritance,9332,"valid ``using`` is the last method; * Filter -fno-plt (coming from anaconda builds; not understood by Cling); * Fixed memory leak in generic base ``__str__``. 2021-01-05: 1.9.2; -----------------. * Added ``cppyy.types`` module for exposing cppyy builtin types; * Improve numpy integration with custom ``__array__`` methods; * Allow operator overload resolution mixing class and global methods; * Installation fixes for PyPy when using pip. 2020-11-23: 1.9.1; -----------------. * Fix custom installer in pip sdist. 2020-11-22: 1.9.0; -----------------. * In-tree build resolving build/install order for PyPy with pyproject.toml; * ``std::string`` not converterd to ``str`` on function returns; * Cover more use cases where C string memory can be managed; * Automatic memory management of converted python functions; * Added pyinstaller hooks (https://stackoverflow.com/questions/64406727); * Support for enums in pseudo-constructors of aggregates; * Fixes for overloaded/split-access protected members in cross-inheritance; * Support for deep, mixed, hierarchies for multi-cross-inheritance; * Added tp_iter method to low level views. 2020-11-06: 1.8.6; -----------------. * Fix preprocessor macro of CPyCppyy header for Windows/MSVC. 2020-10-31: 1.8.5; -----------------. * Fix leaks when using vector iterators on Py3/Linux. 2020-10-10: 1.8.4; -----------------. * ``std::string`` globals/data members no longer automatically converted to ``str``; * New methods for std::string to allow ``str`` interchangability; * Added a ``decode`` method to ``std::string``; * Add pythonized ``__contains__`` to ``std::set``; * Fix constructor generation for aggregates with static data; * Fix performance bug when using implicit conversions; * Fix memory overwrite when parsing during sorting of methods; * PyPy pip install again falls back to setup.py install. 2020-09-21: 1.8.3; -----------------. * Add initializer constructors for PODs and aggregates; * Use actual underlying type for enums, where possible",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:9400,Modifiability,inherit,inheritance,9400,"valid ``using`` is the last method; * Filter -fno-plt (coming from anaconda builds; not understood by Cling); * Fixed memory leak in generic base ``__str__``. 2021-01-05: 1.9.2; -----------------. * Added ``cppyy.types`` module for exposing cppyy builtin types; * Improve numpy integration with custom ``__array__`` methods; * Allow operator overload resolution mixing class and global methods; * Installation fixes for PyPy when using pip. 2020-11-23: 1.9.1; -----------------. * Fix custom installer in pip sdist. 2020-11-22: 1.9.0; -----------------. * In-tree build resolving build/install order for PyPy with pyproject.toml; * ``std::string`` not converterd to ``str`` on function returns; * Cover more use cases where C string memory can be managed; * Automatic memory management of converted python functions; * Added pyinstaller hooks (https://stackoverflow.com/questions/64406727); * Support for enums in pseudo-constructors of aggregates; * Fixes for overloaded/split-access protected members in cross-inheritance; * Support for deep, mixed, hierarchies for multi-cross-inheritance; * Added tp_iter method to low level views. 2020-11-06: 1.8.6; -----------------. * Fix preprocessor macro of CPyCppyy header for Windows/MSVC. 2020-10-31: 1.8.5; -----------------. * Fix leaks when using vector iterators on Py3/Linux. 2020-10-10: 1.8.4; -----------------. * ``std::string`` globals/data members no longer automatically converted to ``str``; * New methods for std::string to allow ``str`` interchangability; * Added a ``decode`` method to ``std::string``; * Add pythonized ``__contains__`` to ``std::set``; * Fix constructor generation for aggregates with static data; * Fix performance bug when using implicit conversions; * Fix memory overwrite when parsing during sorting of methods; * PyPy pip install again falls back to setup.py install. 2020-09-21: 1.8.3; -----------------. * Add initializer constructors for PODs and aggregates; * Use actual underlying type for enums, where possible",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:12309,Modifiability,inherit,inheritance,12309,"ependencies with pyproject.toml; * Simplified flow of pointer types for callbacks and cross-derivation; * Pointer-comparing objects performs auto-cast as needed; * Add main dimension for ptr-ptr to builtin returns; * Transparant handling of ptr-ptr to instance returns; * Stricter handling of bool type in overload with int types; * Fix uint64_t template instantiation regression; * Do not filter out enum data for ``__dir__``; * Fix lookup of interpreter-only explicit instantiations; * Fix inconsistent naming of std types with char_traits; * Further hiding of upstream code/dependencies; * Extended documentation. 2020-07-12: 1.8.0; -----------------. * Support mixing of Python and C++ types in global operators; * Capture Cling error messages from cppdef and include in the Python exception; * Add a cppexec method to evalutate statements in Cling's global scope; * Support initialization of ``std::array<>`` from sequences; * Support C++17 style initialization of common STL containers; * Allow base classes with no virtual destructor (with warning); * Support const by-value returns in Python-side method overrides; * Support for cross-language multiple inheritance of C++ bases; * Allow for pass-by-value of ``std::unique_ptr`` through move; * Reduced dependencies on upstream code; * Put remaining upstream code in CppyyLegacy namespace. 2020-06-06: 1.7.1; -----------------. * Expose protected members in Python derived classes; * Support for deep Python-side derived hierarchies; * Do not generate a copy ctor in the Python derived class if private; * include, c_include, and cppdef now raise exceptions on error; * Allow mixing of keywords and default values; * Fix by-ptr return of objects in Python derived classes; * Fix for passing numpy boolean array through ``bool*``; * Fix assignment to ``const char*`` data members; * Support ``__restrict`` and ``__restrict__`` in interfaces; * Allow passing sequence of strings through ``const char*[]`` argument. 2020-04-27: 1.7.0; -----------",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:14072,Modifiability,variab,variable,14072,* Support ``__restrict`` and ``__restrict__`` in interfaces; * Allow passing sequence of strings through ``const char*[]`` argument. 2020-04-27: 1.7.0; -----------------. * Upgrade to cppyy-cling 6.20.4; * Pre-empt upstream's propensity of making ``std`` classes etc. global; * Allow initialization of ``std::map`` from dict with the correct types; * Allow initialization of ``std::set`` from set with the correct types; * Add optional nonst/non-const selection to ``__overload__``; * Automatic smartification of normal object passed as smartptr by value; * Fix crash when handing a by-value object to make_shared; * Fixed a few shared/unique_ptr corner cases; * Fixed conversion of ``std::function`` taking an STL class parameter; * No longer attempt auto-cast on classes without RTTI; * Fix for ``iter()`` iteration on generic STL container. 2020-03-15: 1.6.2; -----------------. * Respect ``__len__`` when using bound C++ objects in boolean expressions; * Support UTF-8 encoded ``unicode`` through ``std::string``; * Support for ``std::byte``; * Enable assignment to function pointer variable; * Allow passing cppyy.nullptr where a function pointer is expected; * Disable copy construction into constructed object (use ``__assign__`` instead); * Cover more cases when to set a lifeline; * Lower priority of implicit conversion to temporary with initializer_list ctor; * Add type reduction pythonization for trimming expression template type trees; * Allow mixing ``std::string`` and ``str`` as dictionary keys; * Support C-style pointer-to-struct as array; * Support C-style enum variable declarations; * Fixed const_iterator by-ref return type regression; * Resolve enums into the actual underlying type instead of int; * Remove '-isystem' from makepch flags; * Extended documentation. 2020-01-04: 1.6.1; -----------------. * Mapped C++ exception reporting detailing; * Mapped C++ exception cleanup bug fix; * STL vector constructor passes the CPython sequence construction; * STL vector slicing ,MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:14568,Modifiability,variab,variable,14568,"lection to ``__overload__``; * Automatic smartification of normal object passed as smartptr by value; * Fix crash when handing a by-value object to make_shared; * Fixed a few shared/unique_ptr corner cases; * Fixed conversion of ``std::function`` taking an STL class parameter; * No longer attempt auto-cast on classes without RTTI; * Fix for ``iter()`` iteration on generic STL container. 2020-03-15: 1.6.2; -----------------. * Respect ``__len__`` when using bound C++ objects in boolean expressions; * Support UTF-8 encoded ``unicode`` through ``std::string``; * Support for ``std::byte``; * Enable assignment to function pointer variable; * Allow passing cppyy.nullptr where a function pointer is expected; * Disable copy construction into constructed object (use ``__assign__`` instead); * Cover more cases when to set a lifeline; * Lower priority of implicit conversion to temporary with initializer_list ctor; * Add type reduction pythonization for trimming expression template type trees; * Allow mixing ``std::string`` and ``str`` as dictionary keys; * Support C-style pointer-to-struct as array; * Support C-style enum variable declarations; * Fixed const_iterator by-ref return type regression; * Resolve enums into the actual underlying type instead of int; * Remove '-isystem' from makepch flags; * Extended documentation. 2020-01-04: 1.6.1; -----------------. * Mapped C++ exception reporting detailing; * Mapped C++ exception cleanup bug fix; * STL vector constructor passes the CPython sequence construction; * STL vector slicing passes the CPython sequence slicing tests; * Extended documentation. 2019-12-23: 1.6.0; -----------------. * Classes derived from ``std::exception`` can be used as Python exceptions; * Template handling detailing (for Eigen); * Support keyword arguments; * Added add_library_path at module level; * Extended documentation; * Fix regression bugs: #176, #179, #180, #182. 2019-11-07: 1.5.7; -----------------. * Allow implicit converions for move arguments",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:15797,Modifiability,variab,variables,15797,"exception reporting detailing; * Mapped C++ exception cleanup bug fix; * STL vector constructor passes the CPython sequence construction; * STL vector slicing passes the CPython sequence slicing tests; * Extended documentation. 2019-12-23: 1.6.0; -----------------. * Classes derived from ``std::exception`` can be used as Python exceptions; * Template handling detailing (for Eigen); * Support keyword arguments; * Added add_library_path at module level; * Extended documentation; * Fix regression bugs: #176, #179, #180, #182. 2019-11-07: 1.5.7; -----------------. * Allow implicit converions for move arguments; * Choose vector over initializer_list if part of the template argument list. 2019-11-03: 1.5.6; -----------------. * Added public C++ API for some CPyCppyy core functions (CPython only); * Support for char16_t/char16_t* and char32_t/char32_t*; * Respect ``std::hash`` in ``__hash__``; * Fix iteration over vector of shared_ptr; * Length checking on global variables of type 'signed char[N]'; * Properly support overloaded templated with non-templated ``__setitem__``; * Support for array of const char* as C-strings; * Enable type resolution of clang's builtin ``__type_pack_element``; * Fix for inner class type naming when it directly declares a variable. 2019-10-16: 1.5.5; -----------------. * Added signal -> exception support in cppyy.ll; * Support for lazily combining overloads of operator*/+-; * No longer call trivial destructors; * Support for free function unary operators; * Refactored and optimized operator==/!= usage; * Refactored converters/executors for lower memory usage; * Bug fixes in rootcling and _cppyy_generator.py. 2019-09-25: 1.5.4; -----------------. * operator+/* now respect C++-side associativity; * Fix potential crash if modules are reloaded; * Fix some portability issues on Mac/Windows of cppyy-cling. 2019-09-15: 1.5.3; -----------------. * Performance improvements; * Support for anonymous/unnamed/nested unions; * Extended documentation. 2019-09-0",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:16089,Modifiability,variab,variable,16089,"exception reporting detailing; * Mapped C++ exception cleanup bug fix; * STL vector constructor passes the CPython sequence construction; * STL vector slicing passes the CPython sequence slicing tests; * Extended documentation. 2019-12-23: 1.6.0; -----------------. * Classes derived from ``std::exception`` can be used as Python exceptions; * Template handling detailing (for Eigen); * Support keyword arguments; * Added add_library_path at module level; * Extended documentation; * Fix regression bugs: #176, #179, #180, #182. 2019-11-07: 1.5.7; -----------------. * Allow implicit converions for move arguments; * Choose vector over initializer_list if part of the template argument list. 2019-11-03: 1.5.6; -----------------. * Added public C++ API for some CPyCppyy core functions (CPython only); * Support for char16_t/char16_t* and char32_t/char32_t*; * Respect ``std::hash`` in ``__hash__``; * Fix iteration over vector of shared_ptr; * Length checking on global variables of type 'signed char[N]'; * Properly support overloaded templated with non-templated ``__setitem__``; * Support for array of const char* as C-strings; * Enable type resolution of clang's builtin ``__type_pack_element``; * Fix for inner class type naming when it directly declares a variable. 2019-10-16: 1.5.5; -----------------. * Added signal -> exception support in cppyy.ll; * Support for lazily combining overloads of operator*/+-; * No longer call trivial destructors; * Support for free function unary operators; * Refactored and optimized operator==/!= usage; * Refactored converters/executors for lower memory usage; * Bug fixes in rootcling and _cppyy_generator.py. 2019-09-25: 1.5.4; -----------------. * operator+/* now respect C++-side associativity; * Fix potential crash if modules are reloaded; * Fix some portability issues on Mac/Windows of cppyy-cling. 2019-09-15: 1.5.3; -----------------. * Performance improvements; * Support for anonymous/unnamed/nested unions; * Extended documentation. 2019-09-0",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:16629,Modifiability,portab,portability,16629,"re functions (CPython only); * Support for char16_t/char16_t* and char32_t/char32_t*; * Respect ``std::hash`` in ``__hash__``; * Fix iteration over vector of shared_ptr; * Length checking on global variables of type 'signed char[N]'; * Properly support overloaded templated with non-templated ``__setitem__``; * Support for array of const char* as C-strings; * Enable type resolution of clang's builtin ``__type_pack_element``; * Fix for inner class type naming when it directly declares a variable. 2019-10-16: 1.5.5; -----------------. * Added signal -> exception support in cppyy.ll; * Support for lazily combining overloads of operator*/+-; * No longer call trivial destructors; * Support for free function unary operators; * Refactored and optimized operator==/!= usage; * Refactored converters/executors for lower memory usage; * Bug fixes in rootcling and _cppyy_generator.py. 2019-09-25: 1.5.4; -----------------. * operator+/* now respect C++-side associativity; * Fix potential crash if modules are reloaded; * Fix some portability issues on Mac/Windows of cppyy-cling. 2019-09-15: 1.5.3; -----------------. * Performance improvements; * Support for anonymous/unnamed/nested unions; * Extended documentation. 2019-09-06: 1.5.2; -----------------. * Added a ""low level"" interface (cppyy.ll) for hard-casting and ll types; * Extended support for passing ctypes arguments through ptr, ref, ptr-ptr; * Fixed crash when creating an array of instances of a scoped inner struct; * Extended documentation. 2019-08-26: 1.5.1; -----------------. * Upgrade cppyy-cling to 6.18.2; * Various patches to upstream's pre-compiled header generation and use; * Instantiate templates with larger integer types if argument values require; * Improve cppyy.interactive and partially enable it on PyPy, IPython, etc.; * Let ``__overload__`` be more flexible in signature matching; * Make list filtering of dir(cppyy.gbl) on Windows same as Linux/Mac; * Extended documentation. 2019-08-18: 1.5.0; -----------------",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:17435,Modifiability,flexible,flexible,17435,"cling and _cppyy_generator.py. 2019-09-25: 1.5.4; -----------------. * operator+/* now respect C++-side associativity; * Fix potential crash if modules are reloaded; * Fix some portability issues on Mac/Windows of cppyy-cling. 2019-09-15: 1.5.3; -----------------. * Performance improvements; * Support for anonymous/unnamed/nested unions; * Extended documentation. 2019-09-06: 1.5.2; -----------------. * Added a ""low level"" interface (cppyy.ll) for hard-casting and ll types; * Extended support for passing ctypes arguments through ptr, ref, ptr-ptr; * Fixed crash when creating an array of instances of a scoped inner struct; * Extended documentation. 2019-08-26: 1.5.1; -----------------. * Upgrade cppyy-cling to 6.18.2; * Various patches to upstream's pre-compiled header generation and use; * Instantiate templates with larger integer types if argument values require; * Improve cppyy.interactive and partially enable it on PyPy, IPython, etc.; * Let ``__overload__`` be more flexible in signature matching; * Make list filtering of dir(cppyy.gbl) on Windows same as Linux/Mac; * Extended documentation. 2019-08-18: 1.5.0; -----------------. * Upgrade cppyy-cling to 6.18.0; * Allow python-derived classes to be used in templates; * Stricter template resolution and better caching/performance; * Detailed memory management for make_shared and shared_ptr; * Two-way memory management for cross-inherited objects; * Reduced memory footprint of proxy objects in most common cases; * Allow implicit conversion from a tuple of arguments; * Data set on namespaces reflected on C++ even if data not yet bound; * Generalized resolution of binary operators in wrapper generation; * Proper naming of arguments in namespaces for ``std::function<>``; * Cover more cases of STL-liker iterators; * Allow ``std::vector`` initialization with a list of constructor arguments; * Consistent naming of ``__cppname__`` to ``__cpp_name__``; * Added ``__set_lifeline__`` attribute to overloads; * Fixes to the cmake ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:17852,Modifiability,inherit,inherited,17852,"----. * Upgrade cppyy-cling to 6.18.2; * Various patches to upstream's pre-compiled header generation and use; * Instantiate templates with larger integer types if argument values require; * Improve cppyy.interactive and partially enable it on PyPy, IPython, etc.; * Let ``__overload__`` be more flexible in signature matching; * Make list filtering of dir(cppyy.gbl) on Windows same as Linux/Mac; * Extended documentation. 2019-08-18: 1.5.0; -----------------. * Upgrade cppyy-cling to 6.18.0; * Allow python-derived classes to be used in templates; * Stricter template resolution and better caching/performance; * Detailed memory management for make_shared and shared_ptr; * Two-way memory management for cross-inherited objects; * Reduced memory footprint of proxy objects in most common cases; * Allow implicit conversion from a tuple of arguments; * Data set on namespaces reflected on C++ even if data not yet bound; * Generalized resolution of binary operators in wrapper generation; * Proper naming of arguments in namespaces for ``std::function<>``; * Cover more cases of STL-liker iterators; * Allow ``std::vector`` initialization with a list of constructor arguments; * Consistent naming of ``__cppname__`` to ``__cpp_name__``; * Added ``__set_lifeline__`` attribute to overloads; * Fixes to the cmake fragments for Ubuntu; * Fixes linker errors on Windows in some configurations; * Support C++ naming of typedef of bool types; * Basic views of 2D arrays of builtin types; * Extended documentation. 2019-07-01 : 1.4.12; -------------------. * Automatic conversion of python functions to ``std::function`` arguments; * Fix for templated operators that can map to different python names; * Fix on p3 crash when setting a detailed exception during exception handling; * Fix lookup of ``std::nullopt``; * Fix bug that prevented certain templated constructors from being considered; * Support for enum values as data members on ""enum class"" enums; * Support for implicit conversion when passing ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:18515,Modifiability,config,configurations,18515,"----. * Upgrade cppyy-cling to 6.18.2; * Various patches to upstream's pre-compiled header generation and use; * Instantiate templates with larger integer types if argument values require; * Improve cppyy.interactive and partially enable it on PyPy, IPython, etc.; * Let ``__overload__`` be more flexible in signature matching; * Make list filtering of dir(cppyy.gbl) on Windows same as Linux/Mac; * Extended documentation. 2019-08-18: 1.5.0; -----------------. * Upgrade cppyy-cling to 6.18.0; * Allow python-derived classes to be used in templates; * Stricter template resolution and better caching/performance; * Detailed memory management for make_shared and shared_ptr; * Two-way memory management for cross-inherited objects; * Reduced memory footprint of proxy objects in most common cases; * Allow implicit conversion from a tuple of arguments; * Data set on namespaces reflected on C++ even if data not yet bound; * Generalized resolution of binary operators in wrapper generation; * Proper naming of arguments in namespaces for ``std::function<>``; * Cover more cases of STL-liker iterators; * Allow ``std::vector`` initialization with a list of constructor arguments; * Consistent naming of ``__cppname__`` to ``__cpp_name__``; * Added ``__set_lifeline__`` attribute to overloads; * Fixes to the cmake fragments for Ubuntu; * Fixes linker errors on Windows in some configurations; * Support C++ naming of typedef of bool types; * Basic views of 2D arrays of builtin types; * Extended documentation. 2019-07-01 : 1.4.12; -------------------. * Automatic conversion of python functions to ``std::function`` arguments; * Fix for templated operators that can map to different python names; * Fix on p3 crash when setting a detailed exception during exception handling; * Fix lookup of ``std::nullopt``; * Fix bug that prevented certain templated constructors from being considered; * Support for enum values as data members on ""enum class"" enums; * Support for implicit conversion when passing ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:21170,Modifiability,inherit,inheritance,21170,"static/global data lookup) for 32b Windows; * Fixed more linker problems with malloc on 64b Windows; * Consistency in buffer length calculations and c_int/c_uint handling on Windows; * Properly resolve overloaded functions with using of templates from bases; * Get templated constructor info from decl instead of name comparison; * Fixed a performance regression for free functions. 2019-04-04 : 1.4.7; ------------------. * Enable initializer_list conversion on Windows as well; * Improved mapping of operator() for indexing (e.g. for matrices); * Implicit conversion no longer uses global state to prevent recursion; * Improved overload reordering; * Fixes for templated constructors in namespaces. 2019-04-02 : 1.4.6; ------------------. * More transparent use of smart pointers such as shared_ptr; * Expose versioned std namespace through using on Mac; * Improved error handling and interface checking in cross-inheritance; * Argument of (const/non-const) ref types support in callbacks/cross-inheritance; * Do template argument resolution in order: reference, pointer, value; * Fix for return type deduction of resolved but uninstantiated templates; * Fix wrapper generation for defaulted arguments of private types; * Several linker fixes on 64b Windows. 2019-03-25 : 1.4.5; ------------------. * Allow templated free functions to be attached as methods to classes; * Allow cross-derivation from templated classes; * More support for 'using' declarations (methods and inner namespaces); * Fix overload resolution for ``std::set::rbegin()``/``rend()`` ``operator==``; * Fixes for bugs #61, #67; * Several pointer truncation fixes for 64b Windows; * Linker and lookup fixes for Windows. 2019-03-20 : 1.4.4; ------------------. * Support for 'using' of namespaces; * Improved support for alias templates; * Faster template lookup; * Have rootcling/genreflex respect compile-time flags (except for --std if; overridden by CLING_EXTRA_ARGS); * Utility to build dictionarys on Windows (32/64); * Name",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:21252,Modifiability,inherit,inheritance,21252,"static/global data lookup) for 32b Windows; * Fixed more linker problems with malloc on 64b Windows; * Consistency in buffer length calculations and c_int/c_uint handling on Windows; * Properly resolve overloaded functions with using of templates from bases; * Get templated constructor info from decl instead of name comparison; * Fixed a performance regression for free functions. 2019-04-04 : 1.4.7; ------------------. * Enable initializer_list conversion on Windows as well; * Improved mapping of operator() for indexing (e.g. for matrices); * Implicit conversion no longer uses global state to prevent recursion; * Improved overload reordering; * Fixes for templated constructors in namespaces. 2019-04-02 : 1.4.6; ------------------. * More transparent use of smart pointers such as shared_ptr; * Expose versioned std namespace through using on Mac; * Improved error handling and interface checking in cross-inheritance; * Argument of (const/non-const) ref types support in callbacks/cross-inheritance; * Do template argument resolution in order: reference, pointer, value; * Fix for return type deduction of resolved but uninstantiated templates; * Fix wrapper generation for defaulted arguments of private types; * Several linker fixes on 64b Windows. 2019-03-25 : 1.4.5; ------------------. * Allow templated free functions to be attached as methods to classes; * Allow cross-derivation from templated classes; * More support for 'using' declarations (methods and inner namespaces); * Fix overload resolution for ``std::set::rbegin()``/``rend()`` ``operator==``; * Fixes for bugs #61, #67; * Several pointer truncation fixes for 64b Windows; * Linker and lookup fixes for Windows. 2019-03-20 : 1.4.4; ------------------. * Support for 'using' of namespaces; * Improved support for alias templates; * Faster template lookup; * Have rootcling/genreflex respect compile-time flags (except for --std if; overridden by CLING_EXTRA_ARGS); * Utility to build dictionarys on Windows (32/64); * Name",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:22304,Modifiability,variab,variables,22304,"-02 : 1.4.6; ------------------. * More transparent use of smart pointers such as shared_ptr; * Expose versioned std namespace through using on Mac; * Improved error handling and interface checking in cross-inheritance; * Argument of (const/non-const) ref types support in callbacks/cross-inheritance; * Do template argument resolution in order: reference, pointer, value; * Fix for return type deduction of resolved but uninstantiated templates; * Fix wrapper generation for defaulted arguments of private types; * Several linker fixes on 64b Windows. 2019-03-25 : 1.4.5; ------------------. * Allow templated free functions to be attached as methods to classes; * Allow cross-derivation from templated classes; * More support for 'using' declarations (methods and inner namespaces); * Fix overload resolution for ``std::set::rbegin()``/``rend()`` ``operator==``; * Fixes for bugs #61, #67; * Several pointer truncation fixes for 64b Windows; * Linker and lookup fixes for Windows. 2019-03-20 : 1.4.4; ------------------. * Support for 'using' of namespaces; * Improved support for alias templates; * Faster template lookup; * Have rootcling/genreflex respect compile-time flags (except for --std if; overridden by CLING_EXTRA_ARGS); * Utility to build dictionarys on Windows (32/64); * Name mangling fixes in Cling for JITed global/static variables on Windows; * Several pointer truncation fixes for 64b Windows. 2019-03-10 : 1.4.3; ------------------. * Cross-inheritance from abstract C++ base classes; * Preserve 'const' when overriding virtual functions; * Support for by-ref (using ctypes) for function callbacks; * Identity of nested typedef'd classes matches actual; * Expose function pointer variables as ``std::function``'s; * More descriptive printout of global functions; * Ensure that standard pch is up-to-date and that it is removed on; uninstall; * Remove standard pch from wheels on all platforms; * Add -cxxflags option to rootcling; * Install clang resource directory on Windows; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:22426,Modifiability,inherit,inheritance,22426,"-02 : 1.4.6; ------------------. * More transparent use of smart pointers such as shared_ptr; * Expose versioned std namespace through using on Mac; * Improved error handling and interface checking in cross-inheritance; * Argument of (const/non-const) ref types support in callbacks/cross-inheritance; * Do template argument resolution in order: reference, pointer, value; * Fix for return type deduction of resolved but uninstantiated templates; * Fix wrapper generation for defaulted arguments of private types; * Several linker fixes on 64b Windows. 2019-03-25 : 1.4.5; ------------------. * Allow templated free functions to be attached as methods to classes; * Allow cross-derivation from templated classes; * More support for 'using' declarations (methods and inner namespaces); * Fix overload resolution for ``std::set::rbegin()``/``rend()`` ``operator==``; * Fixes for bugs #61, #67; * Several pointer truncation fixes for 64b Windows; * Linker and lookup fixes for Windows. 2019-03-20 : 1.4.4; ------------------. * Support for 'using' of namespaces; * Improved support for alias templates; * Faster template lookup; * Have rootcling/genreflex respect compile-time flags (except for --std if; overridden by CLING_EXTRA_ARGS); * Utility to build dictionarys on Windows (32/64); * Name mangling fixes in Cling for JITed global/static variables on Windows; * Several pointer truncation fixes for 64b Windows. 2019-03-10 : 1.4.3; ------------------. * Cross-inheritance from abstract C++ base classes; * Preserve 'const' when overriding virtual functions; * Support for by-ref (using ctypes) for function callbacks; * Identity of nested typedef'd classes matches actual; * Expose function pointer variables as ``std::function``'s; * More descriptive printout of global functions; * Ensure that standard pch is up-to-date and that it is removed on; uninstall; * Remove standard pch from wheels on all platforms; * Add -cxxflags option to rootcling; * Install clang resource directory on Windows; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:22665,Modifiability,variab,variables,22665,"-02 : 1.4.6; ------------------. * More transparent use of smart pointers such as shared_ptr; * Expose versioned std namespace through using on Mac; * Improved error handling and interface checking in cross-inheritance; * Argument of (const/non-const) ref types support in callbacks/cross-inheritance; * Do template argument resolution in order: reference, pointer, value; * Fix for return type deduction of resolved but uninstantiated templates; * Fix wrapper generation for defaulted arguments of private types; * Several linker fixes on 64b Windows. 2019-03-25 : 1.4.5; ------------------. * Allow templated free functions to be attached as methods to classes; * Allow cross-derivation from templated classes; * More support for 'using' declarations (methods and inner namespaces); * Fix overload resolution for ``std::set::rbegin()``/``rend()`` ``operator==``; * Fixes for bugs #61, #67; * Several pointer truncation fixes for 64b Windows; * Linker and lookup fixes for Windows. 2019-03-20 : 1.4.4; ------------------. * Support for 'using' of namespaces; * Improved support for alias templates; * Faster template lookup; * Have rootcling/genreflex respect compile-time flags (except for --std if; overridden by CLING_EXTRA_ARGS); * Utility to build dictionarys on Windows (32/64); * Name mangling fixes in Cling for JITed global/static variables on Windows; * Several pointer truncation fixes for 64b Windows. 2019-03-10 : 1.4.3; ------------------. * Cross-inheritance from abstract C++ base classes; * Preserve 'const' when overriding virtual functions; * Support for by-ref (using ctypes) for function callbacks; * Identity of nested typedef'd classes matches actual; * Expose function pointer variables as ``std::function``'s; * More descriptive printout of global functions; * Ensure that standard pch is up-to-date and that it is removed on; uninstall; * Remove standard pch from wheels on all platforms; * Add -cxxflags option to rootcling; * Install clang resource directory on Windows; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:3854,Performance,optimiz,optimize,3854,"mproved buffer checking for ``std::initializer_list``; * Add convenience functions ``argc()`` and ``argv()`` to ``cppyy.ll``; * Added ``nullptr`` comparisons for for typed ``nullptr``; * Support for ``using`` pointer types as template arguments; * Walk the full inheritance tree to find the overloads; * Allow ``__destruct__`` override in Python derived class; * Allow ``NULL`` function pointers to be returned as ``std::function`` objects; * Add Python traceback to C++ exception ``what()``. 2022-10-03: 2.4.1; -----------------. * Drop Numba extension entry point. 2022-06-29: 2.4.0; -----------------. * Support for free (templated) functions in Numba; * Basic support for unboxing C++ public data members in Numba; * Basic support for calling methods of C++ structs in Numba; * Added conventional `__cpp_reflex__` method for inspection in Numba; * Support for globally overloaded ordering operators; * Special cases for `__repr__`/`__str__` returning C++ stringy types; * Fix lookup of templates of function with template args; * Correct typing of int8_t/uint8_t enums; * Basic support for hidden enums; * Support function pointer returns and optimize function point variables; * Fix reuse of CPPOverload proxies in vector calls from different threads; * Use `-march=native` instead of checking the cpu for avx; * Workaround for handling exceptions from JITed code on ARM; * Drop ``from cppyy.interactive import *`` from CPython 3.11; * Fix regression in converting `std::vector<T*` to `list`; * Update to the latest patch version of Cling (from 6.26.04). 2022-04-03: 2.3.1; -----------------; * Use portable type Py_ssize_t instead of ssize_t. 2022-03-08: 2.3.0; -----------------. * CUDA support (up to version 10.2); * Allow `std::string_view<char>` initialization from Python `str` (copies); * Provide access to extern ""C"" declared functions in namespaces; * Support for (multiple and nested) anonymous structs; * Pull forward upstream patch for PPC; * Only apply system_dirs patch (for asan) ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:4732,Performance,load,loaded,4732,"asic support for hidden enums; * Support function pointer returns and optimize function point variables; * Fix reuse of CPPOverload proxies in vector calls from different threads; * Use `-march=native` instead of checking the cpu for avx; * Workaround for handling exceptions from JITed code on ARM; * Drop ``from cppyy.interactive import *`` from CPython 3.11; * Fix regression in converting `std::vector<T*` to `list`; * Update to the latest patch version of Cling (from 6.26.04). 2022-04-03: 2.3.1; -----------------; * Use portable type Py_ssize_t instead of ssize_t. 2022-03-08: 2.3.0; -----------------. * CUDA support (up to version 10.2); * Allow `std::string_view<char>` initialization from Python `str` (copies); * Provide access to extern ""C"" declared functions in namespaces; * Support for (multiple and nested) anonymous structs; * Pull forward upstream patch for PPC; * Only apply system_dirs patch (for asan) on Linux; * Add not-yet loaded classes to namespaces in dir(); * Fix lookup of templates of function with template args; * Fix lookup of templates types with << in name; * Fix regression for accessing `char16_t` data member arrays; * Add custom `__reshape__` method to CPPInstance to allow array cast; * Prioritize callee exceptions over bindings exceptions; * Prevent infinite recursion when instantiating class with no constructors. 2021-11-14: 2.2.0; -----------------. * Migrated repos to github/wlav; * Properly resolve enum type of class enums; * Get proper shape of ``void*`` and enum arrays; * Fix access to (const) ref data members; * Fix sometimes PCH uninstall issue; * Fix argument passing of fixed arrays of pointers; * Include all gcc system paths (for asan); * Initial support for Apple M1. 2021-07-17: 2.1.0; -----------------. * Support for vector calls with CPython 3.8 and newer; * Support for typed C++ literals as defaults when mixing with keywords; * Enable reshaping of multi-dim LowLevelViews; * Refactored multi-dim arrays and support for multi-dim ass",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:6053,Performance,load,loading,6053,"ptions over bindings exceptions; * Prevent infinite recursion when instantiating class with no constructors. 2021-11-14: 2.2.0; -----------------. * Migrated repos to github/wlav; * Properly resolve enum type of class enums; * Get proper shape of ``void*`` and enum arrays; * Fix access to (const) ref data members; * Fix sometimes PCH uninstall issue; * Fix argument passing of fixed arrays of pointers; * Include all gcc system paths (for asan); * Initial support for Apple M1. 2021-07-17: 2.1.0; -----------------. * Support for vector calls with CPython 3.8 and newer; * Support for typed C++ literals as defaults when mixing with keywords; * Enable reshaping of multi-dim LowLevelViews; * Refactored multi-dim arrays and support for multi-dim assignment; * Support tuple-based indexing for multi-dim arrays; * Direct support for C's _Complex (_Complex_double/_float on Windows); * sizeof() forwards to ctypes.sizeof() for ctypes' types; * Upgrade cmake fragments for Clang9; * Prevent clash with Julia's LLVM when loading cppyy into PyCall; * Upgrade to latest Cling patch release. 2021-05-14: 2.0.0; -----------------. * Upgrade to latest Cling based on Clang/LLVM 9; * Make C++17 the default standard on Windows. 2021-04-28: 1.9.6; -----------------. * Reverse operators for ``std::complex`` targeting Python's ``complex``; * Version the precompiled header with the ``cppyy-cling`` package version; * Cover more iterator protocol use cases; * Add missing cppyy/__pyinstaller pkg to sdist; * Single-inheritance support for cross-inherited templated constructors; * Disallow ``float`` -> ``const long long&`` conversion; * Capture python exception message string in PyException from callbacks; * Thread safety in enum lookups. 2021-03-22: 1.9.5; -----------------. * Do not regulate direct smart pointers (many to one can lead to double deletion); * Use pkg_resources of ``CPyCppyy``, if available, to find the API include path. 2021-03-17: 1.9.4; -----------------. * Fix for installing into a ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:10004,Performance,perform,performance,10004," PyPy with pyproject.toml; * ``std::string`` not converterd to ``str`` on function returns; * Cover more use cases where C string memory can be managed; * Automatic memory management of converted python functions; * Added pyinstaller hooks (https://stackoverflow.com/questions/64406727); * Support for enums in pseudo-constructors of aggregates; * Fixes for overloaded/split-access protected members in cross-inheritance; * Support for deep, mixed, hierarchies for multi-cross-inheritance; * Added tp_iter method to low level views. 2020-11-06: 1.8.6; -----------------. * Fix preprocessor macro of CPyCppyy header for Windows/MSVC. 2020-10-31: 1.8.5; -----------------. * Fix leaks when using vector iterators on Py3/Linux. 2020-10-10: 1.8.4; -----------------. * ``std::string`` globals/data members no longer automatically converted to ``str``; * New methods for std::string to allow ``str`` interchangability; * Added a ``decode`` method to ``std::string``; * Add pythonized ``__contains__`` to ``std::set``; * Fix constructor generation for aggregates with static data; * Fix performance bug when using implicit conversions; * Fix memory overwrite when parsing during sorting of methods; * PyPy pip install again falls back to setup.py install. 2020-09-21: 1.8.3; -----------------. * Add initializer constructors for PODs and aggregates; * Use actual underlying type for enums, where possible; * Enum values remain instances of their type; * Expose enum underlying type name as ``__underlying`` and ``__ctype__``; * Strictly follow C++ enum scoping rules; * Same enum in transparent scope refers to same type; * More detailed enum ``repr()`` printing, where possible; * Fix for (extern) explicit template instantiations in namespaces; * Throw objects from an std::tuple a life line; * Global pythonizors now always run on all classes; * Simplified iteraton over STL-like containers defining ``begin()``/``end()``. 2020-09-08: 1.8.2; -----------------. * Add ``cppyy.set_debug()`` to enable debu",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:11280,Performance,perform,performs,11280," scoping rules; * Same enum in transparent scope refers to same type; * More detailed enum ``repr()`` printing, where possible; * Fix for (extern) explicit template instantiations in namespaces; * Throw objects from an std::tuple a life line; * Global pythonizors now always run on all classes; * Simplified iteraton over STL-like containers defining ``begin()``/``end()``. 2020-09-08: 1.8.2; -----------------. * Add ``cppyy.set_debug()`` to enable debug output for fixing template errors; * Cover more partial template instantiation use cases; * Force template instantiation if necessary for type deduction (i.e. ``auto``). 2020-09-01: 1.8.1; -----------------. * Setup build dependencies with pyproject.toml; * Simplified flow of pointer types for callbacks and cross-derivation; * Pointer-comparing objects performs auto-cast as needed; * Add main dimension for ptr-ptr to builtin returns; * Transparant handling of ptr-ptr to instance returns; * Stricter handling of bool type in overload with int types; * Fix uint64_t template instantiation regression; * Do not filter out enum data for ``__dir__``; * Fix lookup of interpreter-only explicit instantiations; * Fix inconsistent naming of std types with char_traits; * Further hiding of upstream code/dependencies; * Extended documentation. 2020-07-12: 1.8.0; -----------------. * Support mixing of Python and C++ types in global operators; * Capture Cling error messages from cppdef and include in the Python exception; * Add a cppexec method to evalutate statements in Cling's global scope; * Support initialization of ``std::array<>`` from sequences; * Support C++17 style initialization of common STL containers; * Allow base classes with no virtual destructor (with warning); * Support const by-value returns in Python-side method overrides; * Support for cross-language multiple inheritance of C++ bases; * Allow for pass-by-value of ``std::unique_ptr`` through move; * Reduced dependencies on upstream code; * Put remaining upstream code i",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:16344,Performance,optimiz,optimized,16344," #176, #179, #180, #182. 2019-11-07: 1.5.7; -----------------. * Allow implicit converions for move arguments; * Choose vector over initializer_list if part of the template argument list. 2019-11-03: 1.5.6; -----------------. * Added public C++ API for some CPyCppyy core functions (CPython only); * Support for char16_t/char16_t* and char32_t/char32_t*; * Respect ``std::hash`` in ``__hash__``; * Fix iteration over vector of shared_ptr; * Length checking on global variables of type 'signed char[N]'; * Properly support overloaded templated with non-templated ``__setitem__``; * Support for array of const char* as C-strings; * Enable type resolution of clang's builtin ``__type_pack_element``; * Fix for inner class type naming when it directly declares a variable. 2019-10-16: 1.5.5; -----------------. * Added signal -> exception support in cppyy.ll; * Support for lazily combining overloads of operator*/+-; * No longer call trivial destructors; * Support for free function unary operators; * Refactored and optimized operator==/!= usage; * Refactored converters/executors for lower memory usage; * Bug fixes in rootcling and _cppyy_generator.py. 2019-09-25: 1.5.4; -----------------. * operator+/* now respect C++-side associativity; * Fix potential crash if modules are reloaded; * Fix some portability issues on Mac/Windows of cppyy-cling. 2019-09-15: 1.5.3; -----------------. * Performance improvements; * Support for anonymous/unnamed/nested unions; * Extended documentation. 2019-09-06: 1.5.2; -----------------. * Added a ""low level"" interface (cppyy.ll) for hard-casting and ll types; * Extended support for passing ctypes arguments through ptr, ref, ptr-ptr; * Fixed crash when creating an array of instances of a scoped inner struct; * Extended documentation. 2019-08-26: 1.5.1; -----------------. * Upgrade cppyy-cling to 6.18.2; * Various patches to upstream's pre-compiled header generation and use; * Instantiate templates with larger integer types if argument values require; * I",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:17740,Performance,perform,performance,17740,"----. * Upgrade cppyy-cling to 6.18.2; * Various patches to upstream's pre-compiled header generation and use; * Instantiate templates with larger integer types if argument values require; * Improve cppyy.interactive and partially enable it on PyPy, IPython, etc.; * Let ``__overload__`` be more flexible in signature matching; * Make list filtering of dir(cppyy.gbl) on Windows same as Linux/Mac; * Extended documentation. 2019-08-18: 1.5.0; -----------------. * Upgrade cppyy-cling to 6.18.0; * Allow python-derived classes to be used in templates; * Stricter template resolution and better caching/performance; * Detailed memory management for make_shared and shared_ptr; * Two-way memory management for cross-inherited objects; * Reduced memory footprint of proxy objects in most common cases; * Allow implicit conversion from a tuple of arguments; * Data set on namespaces reflected on C++ even if data not yet bound; * Generalized resolution of binary operators in wrapper generation; * Proper naming of arguments in namespaces for ``std::function<>``; * Cover more cases of STL-liker iterators; * Allow ``std::vector`` initialization with a list of constructor arguments; * Consistent naming of ``__cppname__`` to ``__cpp_name__``; * Added ``__set_lifeline__`` attribute to overloads; * Fixes to the cmake fragments for Ubuntu; * Fixes linker errors on Windows in some configurations; * Support C++ naming of typedef of bool types; * Basic views of 2D arrays of builtin types; * Extended documentation. 2019-07-01 : 1.4.12; -------------------. * Automatic conversion of python functions to ``std::function`` arguments; * Fix for templated operators that can map to different python names; * Fix on p3 crash when setting a detailed exception during exception handling; * Fix lookup of ``std::nullopt``; * Fix bug that prevented certain templated constructors from being considered; * Support for enum values as data members on ""enum class"" enums; * Support for implicit conversion when passing ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:20595,Performance,perform,performance,20595," 1.4.10; -------------------. * Imported several FindCppyy.cmake improvements from Camille's cppyy-bbhash; * Fixes to cppyy-generator for unresolved templates, void, etc.; * Fixes in typedef parsing for template arguments in unknown namespaces; * Fix in templated operator code generation; * Fixed ref-counting error for instantiated template methods. 2019-04-25 : 1.4.9; ------------------. * Fix import error on pypy-c. 2019-04-22 : 1.4.8; ------------------. * ``std::tuple`` is now iterable for return assignments w/o tie; * Support for opaque handles and typedefs of pointers to classes; * Keep unresolved enums desugared and provide generic converters; * Treat int8_t and uint8_t as integers (even when they are chars); * Fix lookup of enum values in global namespace; * Backported name mangling (esp. for static/global data lookup) for 32b Windows; * Fixed more linker problems with malloc on 64b Windows; * Consistency in buffer length calculations and c_int/c_uint handling on Windows; * Properly resolve overloaded functions with using of templates from bases; * Get templated constructor info from decl instead of name comparison; * Fixed a performance regression for free functions. 2019-04-04 : 1.4.7; ------------------. * Enable initializer_list conversion on Windows as well; * Improved mapping of operator() for indexing (e.g. for matrices); * Implicit conversion no longer uses global state to prevent recursion; * Improved overload reordering; * Fixes for templated constructors in namespaces. 2019-04-02 : 1.4.6; ------------------. * More transparent use of smart pointers such as shared_ptr; * Expose versioned std namespace through using on Mac; * Improved error handling and interface checking in cross-inheritance; * Argument of (const/non-const) ref types support in callbacks/cross-inheritance; * Do template argument resolution in order: reference, pointer, value; * Fix for return type deduction of resolved but uninstantiated templates; * Fix wrapper generation for defau",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:6742,Safety,safe,safety,6742,"1.0; -----------------. * Support for vector calls with CPython 3.8 and newer; * Support for typed C++ literals as defaults when mixing with keywords; * Enable reshaping of multi-dim LowLevelViews; * Refactored multi-dim arrays and support for multi-dim assignment; * Support tuple-based indexing for multi-dim arrays; * Direct support for C's _Complex (_Complex_double/_float on Windows); * sizeof() forwards to ctypes.sizeof() for ctypes' types; * Upgrade cmake fragments for Clang9; * Prevent clash with Julia's LLVM when loading cppyy into PyCall; * Upgrade to latest Cling patch release. 2021-05-14: 2.0.0; -----------------. * Upgrade to latest Cling based on Clang/LLVM 9; * Make C++17 the default standard on Windows. 2021-04-28: 1.9.6; -----------------. * Reverse operators for ``std::complex`` targeting Python's ``complex``; * Version the precompiled header with the ``cppyy-cling`` package version; * Cover more iterator protocol use cases; * Add missing cppyy/__pyinstaller pkg to sdist; * Single-inheritance support for cross-inherited templated constructors; * Disallow ``float`` -> ``const long long&`` conversion; * Capture python exception message string in PyException from callbacks; * Thread safety in enum lookups. 2021-03-22: 1.9.5; -----------------. * Do not regulate direct smart pointers (many to one can lead to double deletion); * Use pkg_resources of ``CPyCppyy``, if available, to find the API include path. 2021-03-17: 1.9.4; -----------------. * Fix for installing into a directory that has a space in the name; * Fix empty collection printing through Cling on 64b Windows; * Fix accidental shadowing of derived class typedefs by same names in base; * Streamlined templated function lookups in namespaces; * Fix edge cases when decomposing std::function template arguments; * Enable multi-cross inheritance with non-C++ python bases; * Support Bound C++ functions as template argument; * Python functions as template arguments from ``__annotations__`` or ``__cpp_nam",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:4517,Security,access,access,4517,"asic support for hidden enums; * Support function pointer returns and optimize function point variables; * Fix reuse of CPPOverload proxies in vector calls from different threads; * Use `-march=native` instead of checking the cpu for avx; * Workaround for handling exceptions from JITed code on ARM; * Drop ``from cppyy.interactive import *`` from CPython 3.11; * Fix regression in converting `std::vector<T*` to `list`; * Update to the latest patch version of Cling (from 6.26.04). 2022-04-03: 2.3.1; -----------------; * Use portable type Py_ssize_t instead of ssize_t. 2022-03-08: 2.3.0; -----------------. * CUDA support (up to version 10.2); * Allow `std::string_view<char>` initialization from Python `str` (copies); * Provide access to extern ""C"" declared functions in namespaces; * Support for (multiple and nested) anonymous structs; * Pull forward upstream patch for PPC; * Only apply system_dirs patch (for asan) on Linux; * Add not-yet loaded classes to namespaces in dir(); * Fix lookup of templates of function with template args; * Fix lookup of templates types with << in name; * Fix regression for accessing `char16_t` data member arrays; * Add custom `__reshape__` method to CPPInstance to allow array cast; * Prioritize callee exceptions over bindings exceptions; * Prevent infinite recursion when instantiating class with no constructors. 2021-11-14: 2.2.0; -----------------. * Migrated repos to github/wlav; * Properly resolve enum type of class enums; * Get proper shape of ``void*`` and enum arrays; * Fix access to (const) ref data members; * Fix sometimes PCH uninstall issue; * Fix argument passing of fixed arrays of pointers; * Include all gcc system paths (for asan); * Initial support for Apple M1. 2021-07-17: 2.1.0; -----------------. * Support for vector calls with CPython 3.8 and newer; * Support for typed C++ literals as defaults when mixing with keywords; * Enable reshaping of multi-dim LowLevelViews; * Refactored multi-dim arrays and support for multi-dim ass",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:4899,Security,access,accessing,4899,"asic support for hidden enums; * Support function pointer returns and optimize function point variables; * Fix reuse of CPPOverload proxies in vector calls from different threads; * Use `-march=native` instead of checking the cpu for avx; * Workaround for handling exceptions from JITed code on ARM; * Drop ``from cppyy.interactive import *`` from CPython 3.11; * Fix regression in converting `std::vector<T*` to `list`; * Update to the latest patch version of Cling (from 6.26.04). 2022-04-03: 2.3.1; -----------------; * Use portable type Py_ssize_t instead of ssize_t. 2022-03-08: 2.3.0; -----------------. * CUDA support (up to version 10.2); * Allow `std::string_view<char>` initialization from Python `str` (copies); * Provide access to extern ""C"" declared functions in namespaces; * Support for (multiple and nested) anonymous structs; * Pull forward upstream patch for PPC; * Only apply system_dirs patch (for asan) on Linux; * Add not-yet loaded classes to namespaces in dir(); * Fix lookup of templates of function with template args; * Fix lookup of templates types with << in name; * Fix regression for accessing `char16_t` data member arrays; * Add custom `__reshape__` method to CPPInstance to allow array cast; * Prioritize callee exceptions over bindings exceptions; * Prevent infinite recursion when instantiating class with no constructors. 2021-11-14: 2.2.0; -----------------. * Migrated repos to github/wlav; * Properly resolve enum type of class enums; * Get proper shape of ``void*`` and enum arrays; * Fix access to (const) ref data members; * Fix sometimes PCH uninstall issue; * Fix argument passing of fixed arrays of pointers; * Include all gcc system paths (for asan); * Initial support for Apple M1. 2021-07-17: 2.1.0; -----------------. * Support for vector calls with CPython 3.8 and newer; * Support for typed C++ literals as defaults when mixing with keywords; * Enable reshaping of multi-dim LowLevelViews; * Refactored multi-dim arrays and support for multi-dim ass",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:5314,Security,access,access,5314," ssize_t. 2022-03-08: 2.3.0; -----------------. * CUDA support (up to version 10.2); * Allow `std::string_view<char>` initialization from Python `str` (copies); * Provide access to extern ""C"" declared functions in namespaces; * Support for (multiple and nested) anonymous structs; * Pull forward upstream patch for PPC; * Only apply system_dirs patch (for asan) on Linux; * Add not-yet loaded classes to namespaces in dir(); * Fix lookup of templates of function with template args; * Fix lookup of templates types with << in name; * Fix regression for accessing `char16_t` data member arrays; * Add custom `__reshape__` method to CPPInstance to allow array cast; * Prioritize callee exceptions over bindings exceptions; * Prevent infinite recursion when instantiating class with no constructors. 2021-11-14: 2.2.0; -----------------. * Migrated repos to github/wlav; * Properly resolve enum type of class enums; * Get proper shape of ``void*`` and enum arrays; * Fix access to (const) ref data members; * Fix sometimes PCH uninstall issue; * Fix argument passing of fixed arrays of pointers; * Include all gcc system paths (for asan); * Initial support for Apple M1. 2021-07-17: 2.1.0; -----------------. * Support for vector calls with CPython 3.8 and newer; * Support for typed C++ literals as defaults when mixing with keywords; * Enable reshaping of multi-dim LowLevelViews; * Refactored multi-dim arrays and support for multi-dim assignment; * Support tuple-based indexing for multi-dim arrays; * Direct support for C's _Complex (_Complex_double/_float on Windows); * sizeof() forwards to ctypes.sizeof() for ctypes' types; * Upgrade cmake fragments for Clang9; * Prevent clash with Julia's LLVM when loading cppyy into PyCall; * Upgrade to latest Cling patch release. 2021-05-14: 2.0.0; -----------------. * Upgrade to latest Cling based on Clang/LLVM 9; * Make C++17 the default standard on Windows. 2021-04-28: 1.9.6; -----------------. * Reverse operators for ``std::complex`` targeting Pyth",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:9298,Security,access,access,9298,"valid ``using`` is the last method; * Filter -fno-plt (coming from anaconda builds; not understood by Cling); * Fixed memory leak in generic base ``__str__``. 2021-01-05: 1.9.2; -----------------. * Added ``cppyy.types`` module for exposing cppyy builtin types; * Improve numpy integration with custom ``__array__`` methods; * Allow operator overload resolution mixing class and global methods; * Installation fixes for PyPy when using pip. 2020-11-23: 1.9.1; -----------------. * Fix custom installer in pip sdist. 2020-11-22: 1.9.0; -----------------. * In-tree build resolving build/install order for PyPy with pyproject.toml; * ``std::string`` not converterd to ``str`` on function returns; * Cover more use cases where C string memory can be managed; * Automatic memory management of converted python functions; * Added pyinstaller hooks (https://stackoverflow.com/questions/64406727); * Support for enums in pseudo-constructors of aggregates; * Fixes for overloaded/split-access protected members in cross-inheritance; * Support for deep, mixed, hierarchies for multi-cross-inheritance; * Added tp_iter method to low level views. 2020-11-06: 1.8.6; -----------------. * Fix preprocessor macro of CPyCppyy header for Windows/MSVC. 2020-10-31: 1.8.5; -----------------. * Fix leaks when using vector iterators on Py3/Linux. 2020-10-10: 1.8.4; -----------------. * ``std::string`` globals/data members no longer automatically converted to ``str``; * New methods for std::string to allow ``str`` interchangability; * Added a ``decode`` method to ``std::string``; * Add pythonized ``__contains__`` to ``std::set``; * Fix constructor generation for aggregates with static data; * Fix performance bug when using implicit conversions; * Fix memory overwrite when parsing during sorting of methods; * PyPy pip install again falls back to setup.py install. 2020-09-21: 1.8.3; -----------------. * Add initializer constructors for PODs and aggregates; * Use actual underlying type for enums, where possible",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:15702,Security,hash,hash,15702,"exception reporting detailing; * Mapped C++ exception cleanup bug fix; * STL vector constructor passes the CPython sequence construction; * STL vector slicing passes the CPython sequence slicing tests; * Extended documentation. 2019-12-23: 1.6.0; -----------------. * Classes derived from ``std::exception`` can be used as Python exceptions; * Template handling detailing (for Eigen); * Support keyword arguments; * Added add_library_path at module level; * Extended documentation; * Fix regression bugs: #176, #179, #180, #182. 2019-11-07: 1.5.7; -----------------. * Allow implicit converions for move arguments; * Choose vector over initializer_list if part of the template argument list. 2019-11-03: 1.5.6; -----------------. * Added public C++ API for some CPyCppyy core functions (CPython only); * Support for char16_t/char16_t* and char32_t/char32_t*; * Respect ``std::hash`` in ``__hash__``; * Fix iteration over vector of shared_ptr; * Length checking on global variables of type 'signed char[N]'; * Properly support overloaded templated with non-templated ``__setitem__``; * Support for array of const char* as C-strings; * Enable type resolution of clang's builtin ``__type_pack_element``; * Fix for inner class type naming when it directly declares a variable. 2019-10-16: 1.5.5; -----------------. * Added signal -> exception support in cppyy.ll; * Support for lazily combining overloads of operator*/+-; * No longer call trivial destructors; * Support for free function unary operators; * Refactored and optimized operator==/!= usage; * Refactored converters/executors for lower memory usage; * Bug fixes in rootcling and _cppyy_generator.py. 2019-09-25: 1.5.4; -----------------. * operator+/* now respect C++-side associativity; * Fix potential crash if modules are reloaded; * Fix some portability issues on Mac/Windows of cppyy-cling. 2019-09-15: 1.5.3; -----------------. * Performance improvements; * Support for anonymous/unnamed/nested unions; * Extended documentation. 2019-09-0",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst:15021,Testability,test,tests,15021,"ressions; * Support UTF-8 encoded ``unicode`` through ``std::string``; * Support for ``std::byte``; * Enable assignment to function pointer variable; * Allow passing cppyy.nullptr where a function pointer is expected; * Disable copy construction into constructed object (use ``__assign__`` instead); * Cover more cases when to set a lifeline; * Lower priority of implicit conversion to temporary with initializer_list ctor; * Add type reduction pythonization for trimming expression template type trees; * Allow mixing ``std::string`` and ``str`` as dictionary keys; * Support C-style pointer-to-struct as array; * Support C-style enum variable declarations; * Fixed const_iterator by-ref return type regression; * Resolve enums into the actual underlying type instead of int; * Remove '-isystem' from makepch flags; * Extended documentation. 2020-01-04: 1.6.1; -----------------. * Mapped C++ exception reporting detailing; * Mapped C++ exception cleanup bug fix; * STL vector constructor passes the CPython sequence construction; * STL vector slicing passes the CPython sequence slicing tests; * Extended documentation. 2019-12-23: 1.6.0; -----------------. * Classes derived from ``std::exception`` can be used as Python exceptions; * Template handling detailing (for Eigen); * Support keyword arguments; * Added add_library_path at module level; * Extended documentation; * Fix regression bugs: #176, #179, #180, #182. 2019-11-07: 1.5.7; -----------------. * Allow implicit converions for move arguments; * Choose vector over initializer_list if part of the template argument list. 2019-11-03: 1.5.6; -----------------. * Added public C++ API for some CPyCppyy core functions (CPython only); * Support for char16_t/char16_t* and char32_t/char32_t*; * Respect ``std::hash`` in ``__hash__``; * Fix iteration over vector of shared_ptr; * Length checking on global variables of type 'signed char[N]'; * Properly support overloaded templated with non-templated ``__setitem__``; * Support for array of c",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/changelog.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst:10027,Availability,avail,available,10027,"ons are both supported, named or anonymous.; If the latter, the field are accessible through the parent scope by their; declared name.; For example:. .. code-block:: python. >>> cppyy.cppdef(""""""\; ... struct PointXYZ {; ... PointXYZI() : intensity(5.) {}; ... double x, y, z;; ... union {; ... int offset1;; ... struct {; ... int offset2;; ... float intensity;; ... };; ... float data_c[4];; ... };; ... };""""""); True; >>> p = cppyy.gbl.PointXYZI(); >>> type(p.x); <class 'float'>; >>> p.intensity; 5.0; >>> type(p.data_c[1]); <class 'float'>; >>> p.data_c[1] = 3.0; >>> p.intensity; 3.0; >>>. `Operators`; -----------. Many C++ operators can be mapped to their Python equivalent.; When the operators are part of the C++ class definition, this is done; directly.; If they are defined globally, the lookup is done lazily (ie. can resolve; after the class definition by loading the global definition or by defining; them interactively).; Some operators have no Python equivalent and are instead made available by; mapping them onto the following conventional functions:. =================== ===================; C++ Python; =================== ===================; ``operator=`` ``__assign__``; ``operator++(int)`` ``__postinc__``; ``operator++()`` ``__preinc__``; ``operator--(int)`` ``__postdec__``; ``operator--()`` ``__predec__``; ``unary operator*`` ``__deref__``; ``operator->`` ``__follow__``; ``operator&&`` ``__dand__``; ``operator||`` ``__dor__``; ``operator,`` ``__comma__``; =================== ===================. Here is an example of operator usage, using STL iterators directly (note that; this is not necessary in practice as STL and STL-like containers work; transparently in Python for-loops):. .. code-block:: python. >>> v = cppyy.gbl.std.vector[int](range(3)); >>> i = v.begin(); >>> while (i != v.end()):; ... print(i.__deref__()); ... _ = i.__preinc__(); ...; 0; 1; 2; >>>. Overridden ``operator new`` and ``operator delete``, as well as their array; equivalents, are not access",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/classes.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst:11413,Availability,avail,available,11413,"_postdec__``; ``operator--()`` ``__predec__``; ``unary operator*`` ``__deref__``; ``operator->`` ``__follow__``; ``operator&&`` ``__dand__``; ``operator||`` ``__dor__``; ``operator,`` ``__comma__``; =================== ===================. Here is an example of operator usage, using STL iterators directly (note that; this is not necessary in practice as STL and STL-like containers work; transparently in Python for-loops):. .. code-block:: python. >>> v = cppyy.gbl.std.vector[int](range(3)); >>> i = v.begin(); >>> while (i != v.end()):; ... print(i.__deref__()); ... _ = i.__preinc__(); ...; 0; 1; 2; >>>. Overridden ``operator new`` and ``operator delete``, as well as their array; equivalents, are not accessible but will be called as appropriate. `Templates`; -----------. Templated classes are instantiated using square brackets.; (For backwards compatibility reasons, parentheses work as well.); The instantiation of a templated class yields a class, which can then; be used to create instances. Templated classes need not pre-exist in the bound code, just their; declaration needs to be available.; This is true for e.g. all of STL:. .. code-block:: python. >>> cppyy.gbl.std.vector # template metatype; <cppyy.Template 'std::vector' object at 0x7fffed2674d0>; >>> cppyy.gbl.std.vector(int) # instantiates template -> class; <class cppyy.gbl.std.vector<int> at 0x1532190>; cppyy.gbl.std.vector[int]() # instantiates class -> object; <cppyy.gbl.std.vector<int> object at 0x2341ec0>; >>>. The template arguments may be actual types or their names as a string,; whichever is more convenient.; Thus, the following are equivalent:. .. code-block:: python. >>> from cppyy.gbl.std import vector; >>> type1 = vector[Concrete]; >>> type2 = vector['Concrete']; >>> type1 == type2; True; >>>. `Typedefs`; ----------. Typedefs are simple python references to the actual classes to which; they refer. .. code-block:: python. >>> from cppyy.gbl import Concrete_t; >>> Concrete is Concrete_t; True; >>>. ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/classes.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst:2063,Energy Efficiency,allocate,allocates,2063," structure to end-users: when; developing a Python package that exposes C++ classes through ``cppyy``,; consider ``cppyy.gbl`` an ""internal"" module, and expose the classes in any; structure you see fit.; The C++ names will continue to follow the C++ structure, however, as is needed; for e.g. pickling:. .. code-block:: python. >>> from cppyy.gbl import Namespace; >>> Concrete == Namespace.Concrete; False; >>> n = Namespace.Concrete.NestedClass(); >>> type(n); <class cppyy.gbl.Namespace.Concrete.NestedClass at 0x22114c0>; >>> type(n).__name__; NestedClass; >>> type(n).__module__; cppyy.gbl.Namespace.Concrete; >>> type(n).__cpp_name__; Namespace::Concrete::NestedClass; >>>. `Constructors`; --------------. Python and C++ both make a distinction between allocation (``__new__`` in; Python, ``operator new`` in C++) and initialization (``__init__`` in Python,; the constructor call in C++).; When binding, however, there comes a subtle semantic difference: the Python; ``__new__`` allocates memory for the proxy object only, and ``__init__``; initializes the proxy by creating or binding the C++ object.; Thus, no C++ memory is allocated until ``__init__``.; The advantages are simple: the proxy can now check whether it is initialized,; because the pointer to C++ memory will be NULL if not; it can be a reference; to another proxy holding the actual C++ memory; and it can now transparently; implement a C++ smart pointer.; If ``__init__`` is never called, eg. when a call to the base class; ``__init__`` is missing in a derived class override, then accessing the proxy; will result in a Python ``ReferenceError`` exception. `Destructors`; -------------. There should no be reason to call a destructor directly in CPython, but e.g.; PyPy uses a garbage collector and that makes it sometimes useful to destruct; a C++ object exactly when you want it destroyed.; Destructors are by convention accessible through the ``__destruct__`` method; (since ""~"" can not be part of a Python method name).; If",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/classes.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst:2210,Energy Efficiency,allocate,allocated,2210,"ernal"" module, and expose the classes in any; structure you see fit.; The C++ names will continue to follow the C++ structure, however, as is needed; for e.g. pickling:. .. code-block:: python. >>> from cppyy.gbl import Namespace; >>> Concrete == Namespace.Concrete; False; >>> n = Namespace.Concrete.NestedClass(); >>> type(n); <class cppyy.gbl.Namespace.Concrete.NestedClass at 0x22114c0>; >>> type(n).__name__; NestedClass; >>> type(n).__module__; cppyy.gbl.Namespace.Concrete; >>> type(n).__cpp_name__; Namespace::Concrete::NestedClass; >>>. `Constructors`; --------------. Python and C++ both make a distinction between allocation (``__new__`` in; Python, ``operator new`` in C++) and initialization (``__init__`` in Python,; the constructor call in C++).; When binding, however, there comes a subtle semantic difference: the Python; ``__new__`` allocates memory for the proxy object only, and ``__init__``; initializes the proxy by creating or binding the C++ object.; Thus, no C++ memory is allocated until ``__init__``.; The advantages are simple: the proxy can now check whether it is initialized,; because the pointer to C++ memory will be NULL if not; it can be a reference; to another proxy holding the actual C++ memory; and it can now transparently; implement a C++ smart pointer.; If ``__init__`` is never called, eg. when a call to the base class; ``__init__`` is missing in a derived class override, then accessing the proxy; will result in a Python ``ReferenceError`` exception. `Destructors`; -------------. There should no be reason to call a destructor directly in CPython, but e.g.; PyPy uses a garbage collector and that makes it sometimes useful to destruct; a C++ object exactly when you want it destroyed.; Destructors are by convention accessible through the ``__destruct__`` method; (since ""~"" can not be part of a Python method name).; If a Python-side derived class overrides ``__destruct__``, that method will; be called when the instance gets deleted in C++.; The Pyth",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/classes.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst:4283,Integrability,interface,interface,4283," Note that ``__del__`` is not guaranteed to be called, it may e.g. be skipped; on program shutdown or because of an outstanding exception.; Accessing an object after it has been destroyed using ``__destruct__`` will; result in a Python ``ReferenceError`` exception. `Inheritance`; -------------. The output of help shows the inheritance hierarchy, constructors, public; methods, and public data.; For example, ``Concrete`` inherits from ``Abstract`` and it has; a constructor that takes an ``int`` argument, with a default value of 42.; Consider:. .. code-block:: python. >>> from cppyy.gbl import Abstract; >>> issubclass(Concrete, Abstract); True; >>> a = Abstract(); Traceback (most recent call last):; File ""<console>"", line 1, in <module>; TypeError: cannot instantiate abstract class 'Abstract'; >>> c = Concrete(); >>> isinstance(c, Concrete); True; >>> isinstance(c, Abstract); True; >>> d = Concrete(13); >>>. Just like in C++, interface classes that define pure virtual methods, such; as ``Abstract`` does, can not be instantiated, but their concrete; implementations can.; As the output of ``help`` showed, the ``Concrete`` constructor takes; an integer argument, that by default is 42. `Cross-inheritance`; -------------------. Python classes that derive from C++ classes can override virtual methods as; long as those methods are declared on class instantiation (adding methods to; the Python class after the fact will not provide overrides on the C++ side,; only on the Python side).; Example:. .. code-block:: python. >>> from cppyy.gbl import Abstract, call_abstract_method; >>> class PyConcrete(Abstract):; ... def abstract_method(self):; ... return ""Hello, Python World!\n""; ... def concrete_method(self):; ... pass; ...; >>> pc = PyConcrete(); >>> call_abstract_method(pc); Hello, Python World!; >>>. Note that it is not necessary to provide a constructor (``__init__``), but; if you do, you *must* call the base class constructor through the ``super``; mechanism. `Multiple cross-",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/classes.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst:6343,Integrability,message,message,6343,"ross-inheritance`; ----------------------------. Python requires that any multiple inheritance (also in pure Python) has an; unambiguous method resolution order (mro), including for classes and thus; also for meta-classes.; In Python2, it was possible to resolve any mro conflicts automatically, but; meta-classes in Python3, although syntactically richer, have functionally; become far more limited.; In particular, the mro is checked in the builtin class builder, instead of; in the meta-class of the meta-class (which in Python3 is the builtin ``type``; rather than the meta-class itself as in Python2, another limitation, and; which actually checks the mro a second time for no reason).; The upshot is that a helper is required (``cppyy.multi``) to resolve the mro; to support Python3.; The helper is written to also work in Python2.; Example:. .. code-block:: python. >>> class PyConcrete(cppyy.multi(cppyy.gbl.Abstract1, cppyy.gbl.Abstract2)):; ... def abstract_method1(self):; ... return ""first message""; ... def abstract_method2(self):; ... return ""second message""; ...; >>> pc = PyConcrete(); >>> cppyy.gbl.call_abstract_method1(pc); first message; >>> cppyy.gbl/call_abstract_method2(pc); second message; >>>. Contrary to multiple inheritance in Python, in C++ there are no two separate; instances representing the base classes.; Thus, a single ``__init__`` call needs to construct and initialize all bases,; rather than calling ``__init__`` on each base independently.; To support this syntax, the arguments to each base class should be grouped; together in a tuple.; If there are no arguments, provide an empty tuple (or omit them altogether,; if these arguments apply to the right-most base(s)). .. _sec-methods-label:. `Methods`; ---------. C++ methods are represented as Python ones: these are first-class objects and; can be bound to an instance.; If a method is virtual in C++, the proper concrete method is called, whether; or not the concrete class is bound.; Similarly, if all cla",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/classes.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst:6405,Integrability,message,message,6405,"res that any multiple inheritance (also in pure Python) has an; unambiguous method resolution order (mro), including for classes and thus; also for meta-classes.; In Python2, it was possible to resolve any mro conflicts automatically, but; meta-classes in Python3, although syntactically richer, have functionally; become far more limited.; In particular, the mro is checked in the builtin class builder, instead of; in the meta-class of the meta-class (which in Python3 is the builtin ``type``; rather than the meta-class itself as in Python2, another limitation, and; which actually checks the mro a second time for no reason).; The upshot is that a helper is required (``cppyy.multi``) to resolve the mro; to support Python3.; The helper is written to also work in Python2.; Example:. .. code-block:: python. >>> class PyConcrete(cppyy.multi(cppyy.gbl.Abstract1, cppyy.gbl.Abstract2)):; ... def abstract_method1(self):; ... return ""first message""; ... def abstract_method2(self):; ... return ""second message""; ...; >>> pc = PyConcrete(); >>> cppyy.gbl.call_abstract_method1(pc); first message; >>> cppyy.gbl/call_abstract_method2(pc); second message; >>>. Contrary to multiple inheritance in Python, in C++ there are no two separate; instances representing the base classes.; Thus, a single ``__init__`` call needs to construct and initialize all bases,; rather than calling ``__init__`` on each base independently.; To support this syntax, the arguments to each base class should be grouped; together in a tuple.; If there are no arguments, provide an empty tuple (or omit them altogether,; if these arguments apply to the right-most base(s)). .. _sec-methods-label:. `Methods`; ---------. C++ methods are represented as Python ones: these are first-class objects and; can be bound to an instance.; If a method is virtual in C++, the proper concrete method is called, whether; or not the concrete class is bound.; Similarly, if all classes are bound, the normal Python rules apply:. .. code-block:",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/classes.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst:6490,Integrability,message,message,6490,"d resolution order (mro), including for classes and thus; also for meta-classes.; In Python2, it was possible to resolve any mro conflicts automatically, but; meta-classes in Python3, although syntactically richer, have functionally; become far more limited.; In particular, the mro is checked in the builtin class builder, instead of; in the meta-class of the meta-class (which in Python3 is the builtin ``type``; rather than the meta-class itself as in Python2, another limitation, and; which actually checks the mro a second time for no reason).; The upshot is that a helper is required (``cppyy.multi``) to resolve the mro; to support Python3.; The helper is written to also work in Python2.; Example:. .. code-block:: python. >>> class PyConcrete(cppyy.multi(cppyy.gbl.Abstract1, cppyy.gbl.Abstract2)):; ... def abstract_method1(self):; ... return ""first message""; ... def abstract_method2(self):; ... return ""second message""; ...; >>> pc = PyConcrete(); >>> cppyy.gbl.call_abstract_method1(pc); first message; >>> cppyy.gbl/call_abstract_method2(pc); second message; >>>. Contrary to multiple inheritance in Python, in C++ there are no two separate; instances representing the base classes.; Thus, a single ``__init__`` call needs to construct and initialize all bases,; rather than calling ``__init__`` on each base independently.; To support this syntax, the arguments to each base class should be grouped; together in a tuple.; If there are no arguments, provide an empty tuple (or omit them altogether,; if these arguments apply to the right-most base(s)). .. _sec-methods-label:. `Methods`; ---------. C++ methods are represented as Python ones: these are first-class objects and; can be bound to an instance.; If a method is virtual in C++, the proper concrete method is called, whether; or not the concrete class is bound.; Similarly, if all classes are bound, the normal Python rules apply:. .. code-block:: python. >>> c.abstract_method(); called Concrete::abstract_method; >>> c.concr",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/classes.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst:6547,Integrability,message,message,6547," thus; also for meta-classes.; In Python2, it was possible to resolve any mro conflicts automatically, but; meta-classes in Python3, although syntactically richer, have functionally; become far more limited.; In particular, the mro is checked in the builtin class builder, instead of; in the meta-class of the meta-class (which in Python3 is the builtin ``type``; rather than the meta-class itself as in Python2, another limitation, and; which actually checks the mro a second time for no reason).; The upshot is that a helper is required (``cppyy.multi``) to resolve the mro; to support Python3.; The helper is written to also work in Python2.; Example:. .. code-block:: python. >>> class PyConcrete(cppyy.multi(cppyy.gbl.Abstract1, cppyy.gbl.Abstract2)):; ... def abstract_method1(self):; ... return ""first message""; ... def abstract_method2(self):; ... return ""second message""; ...; >>> pc = PyConcrete(); >>> cppyy.gbl.call_abstract_method1(pc); first message; >>> cppyy.gbl/call_abstract_method2(pc); second message; >>>. Contrary to multiple inheritance in Python, in C++ there are no two separate; instances representing the base classes.; Thus, a single ``__init__`` call needs to construct and initialize all bases,; rather than calling ``__init__`` on each base independently.; To support this syntax, the arguments to each base class should be grouped; together in a tuple.; If there are no arguments, provide an empty tuple (or omit them altogether,; if these arguments apply to the right-most base(s)). .. _sec-methods-label:. `Methods`; ---------. C++ methods are represented as Python ones: these are first-class objects and; can be bound to an instance.; If a method is virtual in C++, the proper concrete method is called, whether; or not the concrete class is bound.; Similarly, if all classes are bound, the normal Python rules apply:. .. code-block:: python. >>> c.abstract_method(); called Concrete::abstract_method; >>> c.concrete_method(); called Concrete::concrete_method; >>> ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/classes.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst:179,Modifiability,inherit,inheritance,179,".. _classes:. Classes; =======. Both Python and C++ support object-oriented code through classes and thus; it is logical to expose C++ classes as Python ones, including the full; inheritance hierarchy. The C++ code used for the examples below can be found; :doc:`here <cppyy_features_header>`, and it is assumed that that code is; loaded at the start of any session.; Download it, save it under the name ``features.h``, and load it:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('features.h'); >>>. `Basics`; --------. All bound C++ code starts off from the global C++ namespace, represented in; Python by ``gbl``.; This namespace, as any other namespace, is treated as a module after it has; been loaded.; Thus, we can import C++ classes that live underneath it:. .. code-block:: python. >>> from cppyy.gbl import Concrete; >>> Concrete; <class cppyy.gbl.Concrete at 0x2058e30>; >>>. Placing classes in the same structure as imposed by C++ guarantees identity,; even if multiple Python modules bind the same class.; There is, however, no necessity to expose that structure to end-users: when; developing a Python package that exposes C++ classes through ``cppyy``,; consider ``cppyy.gbl`` an ""internal"" module, and expose the classes in any; structure you see fit.; The C++ names will continue to follow the C++ structure, however, as is needed; for e.g. pickling:. .. code-block:: python. >>> from cppyy.gbl import Namespace; >>> Concrete == Namespace.Concrete; False; >>> n = Namespace.Concrete.NestedClass(); >>> type(n); <class cppyy.gbl.Namespace.Concrete.NestedClass at 0x22114c0>; >>> type(n).__name__; NestedClass; >>> type(n).__module__; cppyy.gbl.Namespace.Concrete; >>> type(n).__cpp_name__; Namespace::Concrete::NestedClass; >>>. `Constructors`; --------------. Python and C++ both make a distinction between allocation (``__new__`` in; Python, ``operator new`` in C++) and initialization (``__init__`` in Python,; the constructor call in C++).; When binding, however, ther",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/classes.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst:3671,Modifiability,inherit,inheritance,3671,"rror`` exception. `Destructors`; -------------. There should no be reason to call a destructor directly in CPython, but e.g.; PyPy uses a garbage collector and that makes it sometimes useful to destruct; a C++ object exactly when you want it destroyed.; Destructors are by convention accessible through the ``__destruct__`` method; (since ""~"" can not be part of a Python method name).; If a Python-side derived class overrides ``__destruct__``, that method will; be called when the instance gets deleted in C++.; The Python destructor, ``__del__``, gets called when the Python proxy goes; away, which will only delete the C++ instance if owned by Python.; Note that ``__del__`` is not guaranteed to be called, it may e.g. be skipped; on program shutdown or because of an outstanding exception.; Accessing an object after it has been destroyed using ``__destruct__`` will; result in a Python ``ReferenceError`` exception. `Inheritance`; -------------. The output of help shows the inheritance hierarchy, constructors, public; methods, and public data.; For example, ``Concrete`` inherits from ``Abstract`` and it has; a constructor that takes an ``int`` argument, with a default value of 42.; Consider:. .. code-block:: python. >>> from cppyy.gbl import Abstract; >>> issubclass(Concrete, Abstract); True; >>> a = Abstract(); Traceback (most recent call last):; File ""<console>"", line 1, in <module>; TypeError: cannot instantiate abstract class 'Abstract'; >>> c = Concrete(); >>> isinstance(c, Concrete); True; >>> isinstance(c, Abstract); True; >>> d = Concrete(13); >>>. Just like in C++, interface classes that define pure virtual methods, such; as ``Abstract`` does, can not be instantiated, but their concrete; implementations can.; As the output of ``help`` showed, the ``Concrete`` constructor takes; an integer argument, that by default is 42. `Cross-inheritance`; -------------------. Python classes that derive from C++ classes can override virtual methods as; long as those methods are de",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/classes.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst:3769,Modifiability,inherit,inherits,3769,"e.g.; PyPy uses a garbage collector and that makes it sometimes useful to destruct; a C++ object exactly when you want it destroyed.; Destructors are by convention accessible through the ``__destruct__`` method; (since ""~"" can not be part of a Python method name).; If a Python-side derived class overrides ``__destruct__``, that method will; be called when the instance gets deleted in C++.; The Python destructor, ``__del__``, gets called when the Python proxy goes; away, which will only delete the C++ instance if owned by Python.; Note that ``__del__`` is not guaranteed to be called, it may e.g. be skipped; on program shutdown or because of an outstanding exception.; Accessing an object after it has been destroyed using ``__destruct__`` will; result in a Python ``ReferenceError`` exception. `Inheritance`; -------------. The output of help shows the inheritance hierarchy, constructors, public; methods, and public data.; For example, ``Concrete`` inherits from ``Abstract`` and it has; a constructor that takes an ``int`` argument, with a default value of 42.; Consider:. .. code-block:: python. >>> from cppyy.gbl import Abstract; >>> issubclass(Concrete, Abstract); True; >>> a = Abstract(); Traceback (most recent call last):; File ""<console>"", line 1, in <module>; TypeError: cannot instantiate abstract class 'Abstract'; >>> c = Concrete(); >>> isinstance(c, Concrete); True; >>> isinstance(c, Abstract); True; >>> d = Concrete(13); >>>. Just like in C++, interface classes that define pure virtual methods, such; as ``Abstract`` does, can not be instantiated, but their concrete; implementations can.; As the output of ``help`` showed, the ``Concrete`` constructor takes; an integer argument, that by default is 42. `Cross-inheritance`; -------------------. Python classes that derive from C++ classes can override virtual methods as; long as those methods are declared on class instantiation (adding methods to; the Python class after the fact will not provide overrides on the C++ ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/classes.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst:4551,Modifiability,inherit,inheritance,4551,"esult in a Python ``ReferenceError`` exception. `Inheritance`; -------------. The output of help shows the inheritance hierarchy, constructors, public; methods, and public data.; For example, ``Concrete`` inherits from ``Abstract`` and it has; a constructor that takes an ``int`` argument, with a default value of 42.; Consider:. .. code-block:: python. >>> from cppyy.gbl import Abstract; >>> issubclass(Concrete, Abstract); True; >>> a = Abstract(); Traceback (most recent call last):; File ""<console>"", line 1, in <module>; TypeError: cannot instantiate abstract class 'Abstract'; >>> c = Concrete(); >>> isinstance(c, Concrete); True; >>> isinstance(c, Abstract); True; >>> d = Concrete(13); >>>. Just like in C++, interface classes that define pure virtual methods, such; as ``Abstract`` does, can not be instantiated, but their concrete; implementations can.; As the output of ``help`` showed, the ``Concrete`` constructor takes; an integer argument, that by default is 42. `Cross-inheritance`; -------------------. Python classes that derive from C++ classes can override virtual methods as; long as those methods are declared on class instantiation (adding methods to; the Python class after the fact will not provide overrides on the C++ side,; only on the Python side).; Example:. .. code-block:: python. >>> from cppyy.gbl import Abstract, call_abstract_method; >>> class PyConcrete(Abstract):; ... def abstract_method(self):; ... return ""Hello, Python World!\n""; ... def concrete_method(self):; ... pass; ...; >>> pc = PyConcrete(); >>> call_abstract_method(pc); Hello, Python World!; >>>. Note that it is not necessary to provide a constructor (``__init__``), but; if you do, you *must* call the base class constructor through the ``super``; mechanism. `Multiple cross-inheritance`; ----------------------------. Python requires that any multiple inheritance (also in pure Python) has an; unambiguous method resolution order (mro), including for classes and thus; also for meta-classes.;",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/classes.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst:5346,Modifiability,inherit,inheritance,5346,"es, can not be instantiated, but their concrete; implementations can.; As the output of ``help`` showed, the ``Concrete`` constructor takes; an integer argument, that by default is 42. `Cross-inheritance`; -------------------. Python classes that derive from C++ classes can override virtual methods as; long as those methods are declared on class instantiation (adding methods to; the Python class after the fact will not provide overrides on the C++ side,; only on the Python side).; Example:. .. code-block:: python. >>> from cppyy.gbl import Abstract, call_abstract_method; >>> class PyConcrete(Abstract):; ... def abstract_method(self):; ... return ""Hello, Python World!\n""; ... def concrete_method(self):; ... pass; ...; >>> pc = PyConcrete(); >>> call_abstract_method(pc); Hello, Python World!; >>>. Note that it is not necessary to provide a constructor (``__init__``), but; if you do, you *must* call the base class constructor through the ``super``; mechanism. `Multiple cross-inheritance`; ----------------------------. Python requires that any multiple inheritance (also in pure Python) has an; unambiguous method resolution order (mro), including for classes and thus; also for meta-classes.; In Python2, it was possible to resolve any mro conflicts automatically, but; meta-classes in Python3, although syntactically richer, have functionally; become far more limited.; In particular, the mro is checked in the builtin class builder, instead of; in the meta-class of the meta-class (which in Python3 is the builtin ``type``; rather than the meta-class itself as in Python2, another limitation, and; which actually checks the mro a second time for no reason).; The upshot is that a helper is required (``cppyy.multi``) to resolve the mro; to support Python3.; The helper is written to also work in Python2.; Example:. .. code-block:: python. >>> class PyConcrete(cppyy.multi(cppyy.gbl.Abstract1, cppyy.gbl.Abstract2)):; ... def abstract_method1(self):; ... return ""first message""; ... de",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/classes.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst:5424,Modifiability,inherit,inheritance,5424,"te`` constructor takes; an integer argument, that by default is 42. `Cross-inheritance`; -------------------. Python classes that derive from C++ classes can override virtual methods as; long as those methods are declared on class instantiation (adding methods to; the Python class after the fact will not provide overrides on the C++ side,; only on the Python side).; Example:. .. code-block:: python. >>> from cppyy.gbl import Abstract, call_abstract_method; >>> class PyConcrete(Abstract):; ... def abstract_method(self):; ... return ""Hello, Python World!\n""; ... def concrete_method(self):; ... pass; ...; >>> pc = PyConcrete(); >>> call_abstract_method(pc); Hello, Python World!; >>>. Note that it is not necessary to provide a constructor (``__init__``), but; if you do, you *must* call the base class constructor through the ``super``; mechanism. `Multiple cross-inheritance`; ----------------------------. Python requires that any multiple inheritance (also in pure Python) has an; unambiguous method resolution order (mro), including for classes and thus; also for meta-classes.; In Python2, it was possible to resolve any mro conflicts automatically, but; meta-classes in Python3, although syntactically richer, have functionally; become far more limited.; In particular, the mro is checked in the builtin class builder, instead of; in the meta-class of the meta-class (which in Python3 is the builtin ``type``; rather than the meta-class itself as in Python2, another limitation, and; which actually checks the mro a second time for no reason).; The upshot is that a helper is required (``cppyy.multi``) to resolve the mro; to support Python3.; The helper is written to also work in Python2.; Example:. .. code-block:: python. >>> class PyConcrete(cppyy.multi(cppyy.gbl.Abstract1, cppyy.gbl.Abstract2)):; ... def abstract_method1(self):; ... return ""first message""; ... def abstract_method2(self):; ... return ""second message""; ...; >>> pc = PyConcrete(); >>> cppyy.gbl.call_abstract_metho",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/classes.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst:6582,Modifiability,inherit,inheritance,6582,"ts automatically, but; meta-classes in Python3, although syntactically richer, have functionally; become far more limited.; In particular, the mro is checked in the builtin class builder, instead of; in the meta-class of the meta-class (which in Python3 is the builtin ``type``; rather than the meta-class itself as in Python2, another limitation, and; which actually checks the mro a second time for no reason).; The upshot is that a helper is required (``cppyy.multi``) to resolve the mro; to support Python3.; The helper is written to also work in Python2.; Example:. .. code-block:: python. >>> class PyConcrete(cppyy.multi(cppyy.gbl.Abstract1, cppyy.gbl.Abstract2)):; ... def abstract_method1(self):; ... return ""first message""; ... def abstract_method2(self):; ... return ""second message""; ...; >>> pc = PyConcrete(); >>> cppyy.gbl.call_abstract_method1(pc); first message; >>> cppyy.gbl/call_abstract_method2(pc); second message; >>>. Contrary to multiple inheritance in Python, in C++ there are no two separate; instances representing the base classes.; Thus, a single ``__init__`` call needs to construct and initialize all bases,; rather than calling ``__init__`` on each base independently.; To support this syntax, the arguments to each base class should be grouped; together in a tuple.; If there are no arguments, provide an empty tuple (or omit them altogether,; if these arguments apply to the right-most base(s)). .. _sec-methods-label:. `Methods`; ---------. C++ methods are represented as Python ones: these are first-class objects and; can be bound to an instance.; If a method is virtual in C++, the proper concrete method is called, whether; or not the concrete class is bound.; Similarly, if all classes are bound, the normal Python rules apply:. .. code-block:: python. >>> c.abstract_method(); called Concrete::abstract_method; >>> c.concrete_method(); called Concrete::concrete_method; >>> m = c.abstract_method; >>> m(); called Concrete::abstract_method; >>>. `Data members`",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/classes.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst:331,Performance,load,loaded,331,".. _classes:. Classes; =======. Both Python and C++ support object-oriented code through classes and thus; it is logical to expose C++ classes as Python ones, including the full; inheritance hierarchy. The C++ code used for the examples below can be found; :doc:`here <cppyy_features_header>`, and it is assumed that that code is; loaded at the start of any session.; Download it, save it under the name ``features.h``, and load it:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('features.h'); >>>. `Basics`; --------. All bound C++ code starts off from the global C++ namespace, represented in; Python by ``gbl``.; This namespace, as any other namespace, is treated as a module after it has; been loaded.; Thus, we can import C++ classes that live underneath it:. .. code-block:: python. >>> from cppyy.gbl import Concrete; >>> Concrete; <class cppyy.gbl.Concrete at 0x2058e30>; >>>. Placing classes in the same structure as imposed by C++ guarantees identity,; even if multiple Python modules bind the same class.; There is, however, no necessity to expose that structure to end-users: when; developing a Python package that exposes C++ classes through ``cppyy``,; consider ``cppyy.gbl`` an ""internal"" module, and expose the classes in any; structure you see fit.; The C++ names will continue to follow the C++ structure, however, as is needed; for e.g. pickling:. .. code-block:: python. >>> from cppyy.gbl import Namespace; >>> Concrete == Namespace.Concrete; False; >>> n = Namespace.Concrete.NestedClass(); >>> type(n); <class cppyy.gbl.Namespace.Concrete.NestedClass at 0x22114c0>; >>> type(n).__name__; NestedClass; >>> type(n).__module__; cppyy.gbl.Namespace.Concrete; >>> type(n).__cpp_name__; Namespace::Concrete::NestedClass; >>>. `Constructors`; --------------. Python and C++ both make a distinction between allocation (``__new__`` in; Python, ``operator new`` in C++) and initialization (``__init__`` in Python,; the constructor call in C++).; When binding, however, ther",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/classes.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst:424,Performance,load,load,424,".. _classes:. Classes; =======. Both Python and C++ support object-oriented code through classes and thus; it is logical to expose C++ classes as Python ones, including the full; inheritance hierarchy. The C++ code used for the examples below can be found; :doc:`here <cppyy_features_header>`, and it is assumed that that code is; loaded at the start of any session.; Download it, save it under the name ``features.h``, and load it:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('features.h'); >>>. `Basics`; --------. All bound C++ code starts off from the global C++ namespace, represented in; Python by ``gbl``.; This namespace, as any other namespace, is treated as a module after it has; been loaded.; Thus, we can import C++ classes that live underneath it:. .. code-block:: python. >>> from cppyy.gbl import Concrete; >>> Concrete; <class cppyy.gbl.Concrete at 0x2058e30>; >>>. Placing classes in the same structure as imposed by C++ guarantees identity,; even if multiple Python modules bind the same class.; There is, however, no necessity to expose that structure to end-users: when; developing a Python package that exposes C++ classes through ``cppyy``,; consider ``cppyy.gbl`` an ""internal"" module, and expose the classes in any; structure you see fit.; The C++ names will continue to follow the C++ structure, however, as is needed; for e.g. pickling:. .. code-block:: python. >>> from cppyy.gbl import Namespace; >>> Concrete == Namespace.Concrete; False; >>> n = Namespace.Concrete.NestedClass(); >>> type(n); <class cppyy.gbl.Namespace.Concrete.NestedClass at 0x22114c0>; >>> type(n).__name__; NestedClass; >>> type(n).__module__; cppyy.gbl.Namespace.Concrete; >>> type(n).__cpp_name__; Namespace::Concrete::NestedClass; >>>. `Constructors`; --------------. Python and C++ both make a distinction between allocation (``__new__`` in; Python, ``operator new`` in C++) and initialization (``__init__`` in Python,; the constructor call in C++).; When binding, however, ther",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/classes.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst:713,Performance,load,loaded,713,".. _classes:. Classes; =======. Both Python and C++ support object-oriented code through classes and thus; it is logical to expose C++ classes as Python ones, including the full; inheritance hierarchy. The C++ code used for the examples below can be found; :doc:`here <cppyy_features_header>`, and it is assumed that that code is; loaded at the start of any session.; Download it, save it under the name ``features.h``, and load it:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('features.h'); >>>. `Basics`; --------. All bound C++ code starts off from the global C++ namespace, represented in; Python by ``gbl``.; This namespace, as any other namespace, is treated as a module after it has; been loaded.; Thus, we can import C++ classes that live underneath it:. .. code-block:: python. >>> from cppyy.gbl import Concrete; >>> Concrete; <class cppyy.gbl.Concrete at 0x2058e30>; >>>. Placing classes in the same structure as imposed by C++ guarantees identity,; even if multiple Python modules bind the same class.; There is, however, no necessity to expose that structure to end-users: when; developing a Python package that exposes C++ classes through ``cppyy``,; consider ``cppyy.gbl`` an ""internal"" module, and expose the classes in any; structure you see fit.; The C++ names will continue to follow the C++ structure, however, as is needed; for e.g. pickling:. .. code-block:: python. >>> from cppyy.gbl import Namespace; >>> Concrete == Namespace.Concrete; False; >>> n = Namespace.Concrete.NestedClass(); >>> type(n); <class cppyy.gbl.Namespace.Concrete.NestedClass at 0x22114c0>; >>> type(n).__name__; NestedClass; >>> type(n).__module__; cppyy.gbl.Namespace.Concrete; >>> type(n).__cpp_name__; Namespace::Concrete::NestedClass; >>>. `Constructors`; --------------. Python and C++ both make a distinction between allocation (``__new__`` in; Python, ``operator new`` in C++) and initialization (``__init__`` in Python,; the constructor call in C++).; When binding, however, ther",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/classes.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst:9897,Performance,load,loading,9897,"s through instance; >>> Concrete.s_int; 123. .. _sec-operators-label:. `Structs/Unions`; ----------------. Structs and unions are both supported, named or anonymous.; If the latter, the field are accessible through the parent scope by their; declared name.; For example:. .. code-block:: python. >>> cppyy.cppdef(""""""\; ... struct PointXYZ {; ... PointXYZI() : intensity(5.) {}; ... double x, y, z;; ... union {; ... int offset1;; ... struct {; ... int offset2;; ... float intensity;; ... };; ... float data_c[4];; ... };; ... };""""""); True; >>> p = cppyy.gbl.PointXYZI(); >>> type(p.x); <class 'float'>; >>> p.intensity; 5.0; >>> type(p.data_c[1]); <class 'float'>; >>> p.data_c[1] = 3.0; >>> p.intensity; 3.0; >>>. `Operators`; -----------. Many C++ operators can be mapped to their Python equivalent.; When the operators are part of the C++ class definition, this is done; directly.; If they are defined globally, the lookup is done lazily (ie. can resolve; after the class definition by loading the global definition or by defining; them interactively).; Some operators have no Python equivalent and are instead made available by; mapping them onto the following conventional functions:. =================== ===================; C++ Python; =================== ===================; ``operator=`` ``__assign__``; ``operator++(int)`` ``__postinc__``; ``operator++()`` ``__preinc__``; ``operator--(int)`` ``__postdec__``; ``operator--()`` ``__predec__``; ``unary operator*`` ``__deref__``; ``operator->`` ``__follow__``; ``operator&&`` ``__dand__``; ``operator||`` ``__dor__``; ``operator,`` ``__comma__``; =================== ===================. Here is an example of operator usage, using STL iterators directly (note that; this is not necessary in practice as STL and STL-like containers work; transparently in Python for-loops):. .. code-block:: python. >>> v = cppyy.gbl.std.vector[int](range(3)); >>> i = v.begin(); >>> while (i != v.end()):; ... print(i.__deref__()); ... _ = i.__preinc__(); .",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/classes.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst:124,Security,expose,expose,124,".. _classes:. Classes; =======. Both Python and C++ support object-oriented code through classes and thus; it is logical to expose C++ classes as Python ones, including the full; inheritance hierarchy. The C++ code used for the examples below can be found; :doc:`here <cppyy_features_header>`, and it is assumed that that code is; loaded at the start of any session.; Download it, save it under the name ``features.h``, and load it:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('features.h'); >>>. `Basics`; --------. All bound C++ code starts off from the global C++ namespace, represented in; Python by ``gbl``.; This namespace, as any other namespace, is treated as a module after it has; been loaded.; Thus, we can import C++ classes that live underneath it:. .. code-block:: python. >>> from cppyy.gbl import Concrete; >>> Concrete; <class cppyy.gbl.Concrete at 0x2058e30>; >>>. Placing classes in the same structure as imposed by C++ guarantees identity,; even if multiple Python modules bind the same class.; There is, however, no necessity to expose that structure to end-users: when; developing a Python package that exposes C++ classes through ``cppyy``,; consider ``cppyy.gbl`` an ""internal"" module, and expose the classes in any; structure you see fit.; The C++ names will continue to follow the C++ structure, however, as is needed; for e.g. pickling:. .. code-block:: python. >>> from cppyy.gbl import Namespace; >>> Concrete == Namespace.Concrete; False; >>> n = Namespace.Concrete.NestedClass(); >>> type(n); <class cppyy.gbl.Namespace.Concrete.NestedClass at 0x22114c0>; >>> type(n).__name__; NestedClass; >>> type(n).__module__; cppyy.gbl.Namespace.Concrete; >>> type(n).__cpp_name__; Namespace::Concrete::NestedClass; >>>. `Constructors`; --------------. Python and C++ both make a distinction between allocation (``__new__`` in; Python, ``operator new`` in C++) and initialization (``__init__`` in Python,; the constructor call in C++).; When binding, however, ther",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/classes.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst:1067,Security,expose,expose,1067,"ogical to expose C++ classes as Python ones, including the full; inheritance hierarchy. The C++ code used for the examples below can be found; :doc:`here <cppyy_features_header>`, and it is assumed that that code is; loaded at the start of any session.; Download it, save it under the name ``features.h``, and load it:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('features.h'); >>>. `Basics`; --------. All bound C++ code starts off from the global C++ namespace, represented in; Python by ``gbl``.; This namespace, as any other namespace, is treated as a module after it has; been loaded.; Thus, we can import C++ classes that live underneath it:. .. code-block:: python. >>> from cppyy.gbl import Concrete; >>> Concrete; <class cppyy.gbl.Concrete at 0x2058e30>; >>>. Placing classes in the same structure as imposed by C++ guarantees identity,; even if multiple Python modules bind the same class.; There is, however, no necessity to expose that structure to end-users: when; developing a Python package that exposes C++ classes through ``cppyy``,; consider ``cppyy.gbl`` an ""internal"" module, and expose the classes in any; structure you see fit.; The C++ names will continue to follow the C++ structure, however, as is needed; for e.g. pickling:. .. code-block:: python. >>> from cppyy.gbl import Namespace; >>> Concrete == Namespace.Concrete; False; >>> n = Namespace.Concrete.NestedClass(); >>> type(n); <class cppyy.gbl.Namespace.Concrete.NestedClass at 0x22114c0>; >>> type(n).__name__; NestedClass; >>> type(n).__module__; cppyy.gbl.Namespace.Concrete; >>> type(n).__cpp_name__; Namespace::Concrete::NestedClass; >>>. `Constructors`; --------------. Python and C++ both make a distinction between allocation (``__new__`` in; Python, ``operator new`` in C++) and initialization (``__init__`` in Python,; the constructor call in C++).; When binding, however, there comes a subtle semantic difference: the Python; ``__new__`` allocates memory for the proxy object only, and ``__",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/classes.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst:1142,Security,expose,exposes,1142,"ogical to expose C++ classes as Python ones, including the full; inheritance hierarchy. The C++ code used for the examples below can be found; :doc:`here <cppyy_features_header>`, and it is assumed that that code is; loaded at the start of any session.; Download it, save it under the name ``features.h``, and load it:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('features.h'); >>>. `Basics`; --------. All bound C++ code starts off from the global C++ namespace, represented in; Python by ``gbl``.; This namespace, as any other namespace, is treated as a module after it has; been loaded.; Thus, we can import C++ classes that live underneath it:. .. code-block:: python. >>> from cppyy.gbl import Concrete; >>> Concrete; <class cppyy.gbl.Concrete at 0x2058e30>; >>>. Placing classes in the same structure as imposed by C++ guarantees identity,; even if multiple Python modules bind the same class.; There is, however, no necessity to expose that structure to end-users: when; developing a Python package that exposes C++ classes through ``cppyy``,; consider ``cppyy.gbl`` an ""internal"" module, and expose the classes in any; structure you see fit.; The C++ names will continue to follow the C++ structure, however, as is needed; for e.g. pickling:. .. code-block:: python. >>> from cppyy.gbl import Namespace; >>> Concrete == Namespace.Concrete; False; >>> n = Namespace.Concrete.NestedClass(); >>> type(n); <class cppyy.gbl.Namespace.Concrete.NestedClass at 0x22114c0>; >>> type(n).__name__; NestedClass; >>> type(n).__module__; cppyy.gbl.Namespace.Concrete; >>> type(n).__cpp_name__; Namespace::Concrete::NestedClass; >>>. `Constructors`; --------------. Python and C++ both make a distinction between allocation (``__new__`` in; Python, ``operator new`` in C++) and initialization (``__init__`` in Python,; the constructor call in C++).; When binding, however, there comes a subtle semantic difference: the Python; ``__new__`` allocates memory for the proxy object only, and ``__",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/classes.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst:1231,Security,expose,expose,1231,"low can be found; :doc:`here <cppyy_features_header>`, and it is assumed that that code is; loaded at the start of any session.; Download it, save it under the name ``features.h``, and load it:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('features.h'); >>>. `Basics`; --------. All bound C++ code starts off from the global C++ namespace, represented in; Python by ``gbl``.; This namespace, as any other namespace, is treated as a module after it has; been loaded.; Thus, we can import C++ classes that live underneath it:. .. code-block:: python. >>> from cppyy.gbl import Concrete; >>> Concrete; <class cppyy.gbl.Concrete at 0x2058e30>; >>>. Placing classes in the same structure as imposed by C++ guarantees identity,; even if multiple Python modules bind the same class.; There is, however, no necessity to expose that structure to end-users: when; developing a Python package that exposes C++ classes through ``cppyy``,; consider ``cppyy.gbl`` an ""internal"" module, and expose the classes in any; structure you see fit.; The C++ names will continue to follow the C++ structure, however, as is needed; for e.g. pickling:. .. code-block:: python. >>> from cppyy.gbl import Namespace; >>> Concrete == Namespace.Concrete; False; >>> n = Namespace.Concrete.NestedClass(); >>> type(n); <class cppyy.gbl.Namespace.Concrete.NestedClass at 0x22114c0>; >>> type(n).__name__; NestedClass; >>> type(n).__module__; cppyy.gbl.Namespace.Concrete; >>> type(n).__cpp_name__; Namespace::Concrete::NestedClass; >>>. `Constructors`; --------------. Python and C++ both make a distinction between allocation (``__new__`` in; Python, ``operator new`` in C++) and initialization (``__init__`` in Python,; the constructor call in C++).; When binding, however, there comes a subtle semantic difference: the Python; ``__new__`` allocates memory for the proxy object only, and ``__init__``; initializes the proxy by creating or binding the C++ object.; Thus, no C++ memory is allocated until ``__init__``.;",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/classes.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst:2634,Security,access,accessing,2634,"NestedClass; >>> type(n).__module__; cppyy.gbl.Namespace.Concrete; >>> type(n).__cpp_name__; Namespace::Concrete::NestedClass; >>>. `Constructors`; --------------. Python and C++ both make a distinction between allocation (``__new__`` in; Python, ``operator new`` in C++) and initialization (``__init__`` in Python,; the constructor call in C++).; When binding, however, there comes a subtle semantic difference: the Python; ``__new__`` allocates memory for the proxy object only, and ``__init__``; initializes the proxy by creating or binding the C++ object.; Thus, no C++ memory is allocated until ``__init__``.; The advantages are simple: the proxy can now check whether it is initialized,; because the pointer to C++ memory will be NULL if not; it can be a reference; to another proxy holding the actual C++ memory; and it can now transparently; implement a C++ smart pointer.; If ``__init__`` is never called, eg. when a call to the base class; ``__init__`` is missing in a derived class override, then accessing the proxy; will result in a Python ``ReferenceError`` exception. `Destructors`; -------------. There should no be reason to call a destructor directly in CPython, but e.g.; PyPy uses a garbage collector and that makes it sometimes useful to destruct; a C++ object exactly when you want it destroyed.; Destructors are by convention accessible through the ``__destruct__`` method; (since ""~"" can not be part of a Python method name).; If a Python-side derived class overrides ``__destruct__``, that method will; be called when the instance gets deleted in C++.; The Python destructor, ``__del__``, gets called when the Python proxy goes; away, which will only delete the C++ instance if owned by Python.; Note that ``__del__`` is not guaranteed to be called, it may e.g. be skipped; on program shutdown or because of an outstanding exception.; Accessing an object after it has been destroyed using ``__destruct__`` will; result in a Python ``ReferenceError`` exception. `Inheritance`;",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/classes.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst:2975,Security,access,accessible,2975,"a subtle semantic difference: the Python; ``__new__`` allocates memory for the proxy object only, and ``__init__``; initializes the proxy by creating or binding the C++ object.; Thus, no C++ memory is allocated until ``__init__``.; The advantages are simple: the proxy can now check whether it is initialized,; because the pointer to C++ memory will be NULL if not; it can be a reference; to another proxy holding the actual C++ memory; and it can now transparently; implement a C++ smart pointer.; If ``__init__`` is never called, eg. when a call to the base class; ``__init__`` is missing in a derived class override, then accessing the proxy; will result in a Python ``ReferenceError`` exception. `Destructors`; -------------. There should no be reason to call a destructor directly in CPython, but e.g.; PyPy uses a garbage collector and that makes it sometimes useful to destruct; a C++ object exactly when you want it destroyed.; Destructors are by convention accessible through the ``__destruct__`` method; (since ""~"" can not be part of a Python method name).; If a Python-side derived class overrides ``__destruct__``, that method will; be called when the instance gets deleted in C++.; The Python destructor, ``__del__``, gets called when the Python proxy goes; away, which will only delete the C++ instance if owned by Python.; Note that ``__del__`` is not guaranteed to be called, it may e.g. be skipped; on program shutdown or because of an outstanding exception.; Accessing an object after it has been destroyed using ``__destruct__`` will; result in a Python ``ReferenceError`` exception. `Inheritance`; -------------. The output of help shows the inheritance hierarchy, constructors, public; methods, and public data.; For example, ``Concrete`` inherits from ``Abstract`` and it has; a constructor that takes an ``int`` argument, with a default value of 42.; Consider:. .. code-block:: python. >>> from cppyy.gbl import Abstract; >>> issubclass(Concrete, Abstract); True; >>> a = Abstr",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/classes.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst:8347,Security,access,accessible,8347,"mal Python rules apply:. .. code-block:: python. >>> c.abstract_method(); called Concrete::abstract_method; >>> c.concrete_method(); called Concrete::concrete_method; >>> m = c.abstract_method; >>> m(); called Concrete::abstract_method; >>>. `Data members`; --------------. Data members are implemented as properties, using descriptors.; For example, The ``Concrete`` instances have a public data member ``m_int``:. .. code-block:: python. >>> c.m_int, d.m_int; (42, 13); >>>. Note however, that the data members are typed: setting them results in a; memory write on the C++ side.; This is different in Python, where references are replaced, and thus any; type will do:. .. code-block:: python. >>> c.m_int = 3.14 # a float does not fit in an int; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; TypeError: int/long conversion expects an integer object; >>> c.m_int = int(3.14); >>> c.m_int, d.m_int; (3, 13); >>>. Private and protected data members are not accessible, contrary to Python; data members, and C++ const-ness is respected:. .. code-block:: python. >>> c.m_const_int = 71 # declared 'const int' in class definition; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; TypeError: assignment to const data not allowed; >>>. Static C++ data members act like Python class-level data members.; They are also represented by property objects and both read and write access; behave as expected:. .. code-block:: python. >>> Concrete.s_int # access through class; 321; >>> c.s_int = 123 # access through instance; >>> Concrete.s_int; 123. .. _sec-operators-label:. `Structs/Unions`; ----------------. Structs and unions are both supported, named or anonymous.; If the latter, the field are accessible through the parent scope by their; declared name.; For example:. .. code-block:: python. >>> cppyy.cppdef(""""""\; ... struct PointXYZ {; ... PointXYZI() : intensity(5.) {}; ... double x, y, z;; ... union {; ... int offset1;; ... struct {; ... int offse",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/classes.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst:8782,Security,access,access,8782," member ``m_int``:. .. code-block:: python. >>> c.m_int, d.m_int; (42, 13); >>>. Note however, that the data members are typed: setting them results in a; memory write on the C++ side.; This is different in Python, where references are replaced, and thus any; type will do:. .. code-block:: python. >>> c.m_int = 3.14 # a float does not fit in an int; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; TypeError: int/long conversion expects an integer object; >>> c.m_int = int(3.14); >>> c.m_int, d.m_int; (3, 13); >>>. Private and protected data members are not accessible, contrary to Python; data members, and C++ const-ness is respected:. .. code-block:: python. >>> c.m_const_int = 71 # declared 'const int' in class definition; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; TypeError: assignment to const data not allowed; >>>. Static C++ data members act like Python class-level data members.; They are also represented by property objects and both read and write access; behave as expected:. .. code-block:: python. >>> Concrete.s_int # access through class; 321; >>> c.s_int = 123 # access through instance; >>> Concrete.s_int; 123. .. _sec-operators-label:. `Structs/Unions`; ----------------. Structs and unions are both supported, named or anonymous.; If the latter, the field are accessible through the parent scope by their; declared name.; For example:. .. code-block:: python. >>> cppyy.cppdef(""""""\; ... struct PointXYZ {; ... PointXYZI() : intensity(5.) {}; ... double x, y, z;; ... union {; ... int offset1;; ... struct {; ... int offset2;; ... float intensity;; ... };; ... float data_c[4];; ... };; ... };""""""); True; >>> p = cppyy.gbl.PointXYZI(); >>> type(p.x); <class 'float'>; >>> p.intensity; 5.0; >>> type(p.data_c[1]); <class 'float'>; >>> p.data_c[1] = 3.0; >>> p.intensity; 3.0; >>>. `Operators`; -----------. Many C++ operators can be mapped to their Python equivalent.; When the operators are part of the C++ class defi",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/classes.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst:8856,Security,access,access,8856," members are typed: setting them results in a; memory write on the C++ side.; This is different in Python, where references are replaced, and thus any; type will do:. .. code-block:: python. >>> c.m_int = 3.14 # a float does not fit in an int; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; TypeError: int/long conversion expects an integer object; >>> c.m_int = int(3.14); >>> c.m_int, d.m_int; (3, 13); >>>. Private and protected data members are not accessible, contrary to Python; data members, and C++ const-ness is respected:. .. code-block:: python. >>> c.m_const_int = 71 # declared 'const int' in class definition; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; TypeError: assignment to const data not allowed; >>>. Static C++ data members act like Python class-level data members.; They are also represented by property objects and both read and write access; behave as expected:. .. code-block:: python. >>> Concrete.s_int # access through class; 321; >>> c.s_int = 123 # access through instance; >>> Concrete.s_int; 123. .. _sec-operators-label:. `Structs/Unions`; ----------------. Structs and unions are both supported, named or anonymous.; If the latter, the field are accessible through the parent scope by their; declared name.; For example:. .. code-block:: python. >>> cppyy.cppdef(""""""\; ... struct PointXYZ {; ... PointXYZI() : intensity(5.) {}; ... double x, y, z;; ... union {; ... int offset1;; ... struct {; ... int offset2;; ... float intensity;; ... };; ... float data_c[4];; ... };; ... };""""""); True; >>> p = cppyy.gbl.PointXYZI(); >>> type(p.x); <class 'float'>; >>> p.intensity; 5.0; >>> type(p.data_c[1]); <class 'float'>; >>> p.data_c[1] = 3.0; >>> p.intensity; 3.0; >>>. `Operators`; -----------. Many C++ operators can be mapped to their Python equivalent.; When the operators are part of the C++ class definition, this is done; directly.; If they are defined globally, the lookup is done lazily (ie. can resolve; af",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/classes.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst:8903,Security,access,access,8903,"memory write on the C++ side.; This is different in Python, where references are replaced, and thus any; type will do:. .. code-block:: python. >>> c.m_int = 3.14 # a float does not fit in an int; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; TypeError: int/long conversion expects an integer object; >>> c.m_int = int(3.14); >>> c.m_int, d.m_int; (3, 13); >>>. Private and protected data members are not accessible, contrary to Python; data members, and C++ const-ness is respected:. .. code-block:: python. >>> c.m_const_int = 71 # declared 'const int' in class definition; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; TypeError: assignment to const data not allowed; >>>. Static C++ data members act like Python class-level data members.; They are also represented by property objects and both read and write access; behave as expected:. .. code-block:: python. >>> Concrete.s_int # access through class; 321; >>> c.s_int = 123 # access through instance; >>> Concrete.s_int; 123. .. _sec-operators-label:. `Structs/Unions`; ----------------. Structs and unions are both supported, named or anonymous.; If the latter, the field are accessible through the parent scope by their; declared name.; For example:. .. code-block:: python. >>> cppyy.cppdef(""""""\; ... struct PointXYZ {; ... PointXYZI() : intensity(5.) {}; ... double x, y, z;; ... union {; ... int offset1;; ... struct {; ... int offset2;; ... float intensity;; ... };; ... float data_c[4];; ... };; ... };""""""); True; >>> p = cppyy.gbl.PointXYZI(); >>> type(p.x); <class 'float'>; >>> p.intensity; 5.0; >>> type(p.data_c[1]); <class 'float'>; >>> p.data_c[1] = 3.0; >>> p.intensity; 3.0; >>>. `Operators`; -----------. Many C++ operators can be mapped to their Python equivalent.; When the operators are part of the C++ class definition, this is done; directly.; If they are defined globally, the lookup is done lazily (ie. can resolve; after the class definition by loading the global",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/classes.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst:9104,Security,access,accessible,9104,"ack (most recent call last):; File ""<stdin>"", line 1, in <module>; TypeError: int/long conversion expects an integer object; >>> c.m_int = int(3.14); >>> c.m_int, d.m_int; (3, 13); >>>. Private and protected data members are not accessible, contrary to Python; data members, and C++ const-ness is respected:. .. code-block:: python. >>> c.m_const_int = 71 # declared 'const int' in class definition; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; TypeError: assignment to const data not allowed; >>>. Static C++ data members act like Python class-level data members.; They are also represented by property objects and both read and write access; behave as expected:. .. code-block:: python. >>> Concrete.s_int # access through class; 321; >>> c.s_int = 123 # access through instance; >>> Concrete.s_int; 123. .. _sec-operators-label:. `Structs/Unions`; ----------------. Structs and unions are both supported, named or anonymous.; If the latter, the field are accessible through the parent scope by their; declared name.; For example:. .. code-block:: python. >>> cppyy.cppdef(""""""\; ... struct PointXYZ {; ... PointXYZI() : intensity(5.) {}; ... double x, y, z;; ... union {; ... int offset1;; ... struct {; ... int offset2;; ... float intensity;; ... };; ... float data_c[4];; ... };; ... };""""""); True; >>> p = cppyy.gbl.PointXYZI(); >>> type(p.x); <class 'float'>; >>> p.intensity; 5.0; >>> type(p.data_c[1]); <class 'float'>; >>> p.data_c[1] = 3.0; >>> p.intensity; 3.0; >>>. `Operators`; -----------. Many C++ operators can be mapped to their Python equivalent.; When the operators are part of the C++ class definition, this is done; directly.; If they are defined globally, the lookup is done lazily (ie. can resolve; after the class definition by loading the global definition or by defining; them interactively).; Some operators have no Python equivalent and are instead made available by; mapping them onto the following conventional functions:. =================== =",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/classes.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst:11024,Security,access,accessible,11024,"uivalent and are instead made available by; mapping them onto the following conventional functions:. =================== ===================; C++ Python; =================== ===================; ``operator=`` ``__assign__``; ``operator++(int)`` ``__postinc__``; ``operator++()`` ``__preinc__``; ``operator--(int)`` ``__postdec__``; ``operator--()`` ``__predec__``; ``unary operator*`` ``__deref__``; ``operator->`` ``__follow__``; ``operator&&`` ``__dand__``; ``operator||`` ``__dor__``; ``operator,`` ``__comma__``; =================== ===================. Here is an example of operator usage, using STL iterators directly (note that; this is not necessary in practice as STL and STL-like containers work; transparently in Python for-loops):. .. code-block:: python. >>> v = cppyy.gbl.std.vector[int](range(3)); >>> i = v.begin(); >>> while (i != v.end()):; ... print(i.__deref__()); ... _ = i.__preinc__(); ...; 0; 1; 2; >>>. Overridden ``operator new`` and ``operator delete``, as well as their array; equivalents, are not accessible but will be called as appropriate. `Templates`; -----------. Templated classes are instantiated using square brackets.; (For backwards compatibility reasons, parentheses work as well.); The instantiation of a templated class yields a class, which can then; be used to create instances. Templated classes need not pre-exist in the bound code, just their; declaration needs to be available.; This is true for e.g. all of STL:. .. code-block:: python. >>> cppyy.gbl.std.vector # template metatype; <cppyy.Template 'std::vector' object at 0x7fffed2674d0>; >>> cppyy.gbl.std.vector(int) # instantiates template -> class; <class cppyy.gbl.std.vector<int> at 0x1532190>; cppyy.gbl.std.vector[int]() # instantiates class -> object; <cppyy.gbl.std.vector<int> object at 0x2341ec0>; >>>. The template arguments may be actual types or their names as a string,; whichever is more convenient.; Thus, the following are equivalent:. .. code-block:: python. >>> from cppyy.gbl.s",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/classes.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst:113,Testability,log,logical,113,".. _classes:. Classes; =======. Both Python and C++ support object-oriented code through classes and thus; it is logical to expose C++ classes as Python ones, including the full; inheritance hierarchy. The C++ code used for the examples below can be found; :doc:`here <cppyy_features_header>`, and it is assumed that that code is; loaded at the start of any session.; Download it, save it under the name ``features.h``, and load it:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('features.h'); >>>. `Basics`; --------. All bound C++ code starts off from the global C++ namespace, represented in; Python by ``gbl``.; This namespace, as any other namespace, is treated as a module after it has; been loaded.; Thus, we can import C++ classes that live underneath it:. .. code-block:: python. >>> from cppyy.gbl import Concrete; >>> Concrete; <class cppyy.gbl.Concrete at 0x2058e30>; >>>. Placing classes in the same structure as imposed by C++ guarantees identity,; even if multiple Python modules bind the same class.; There is, however, no necessity to expose that structure to end-users: when; developing a Python package that exposes C++ classes through ``cppyy``,; consider ``cppyy.gbl`` an ""internal"" module, and expose the classes in any; structure you see fit.; The C++ names will continue to follow the C++ structure, however, as is needed; for e.g. pickling:. .. code-block:: python. >>> from cppyy.gbl import Namespace; >>> Concrete == Namespace.Concrete; False; >>> n = Namespace.Concrete.NestedClass(); >>> type(n); <class cppyy.gbl.Namespace.Concrete.NestedClass at 0x22114c0>; >>> type(n).__name__; NestedClass; >>> type(n).__module__; cppyy.gbl.Namespace.Concrete; >>> type(n).__cpp_name__; Namespace::Concrete::NestedClass; >>>. `Constructors`; --------------. Python and C++ both make a distinction between allocation (``__new__`` in; Python, ``operator new`` in C++) and initialization (``__init__`` in Python,; the constructor call in C++).; When binding, however, ther",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/classes.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst:2260,Usability,simpl,simple,2260,"ickling:. .. code-block:: python. >>> from cppyy.gbl import Namespace; >>> Concrete == Namespace.Concrete; False; >>> n = Namespace.Concrete.NestedClass(); >>> type(n); <class cppyy.gbl.Namespace.Concrete.NestedClass at 0x22114c0>; >>> type(n).__name__; NestedClass; >>> type(n).__module__; cppyy.gbl.Namespace.Concrete; >>> type(n).__cpp_name__; Namespace::Concrete::NestedClass; >>>. `Constructors`; --------------. Python and C++ both make a distinction between allocation (``__new__`` in; Python, ``operator new`` in C++) and initialization (``__init__`` in Python,; the constructor call in C++).; When binding, however, there comes a subtle semantic difference: the Python; ``__new__`` allocates memory for the proxy object only, and ``__init__``; initializes the proxy by creating or binding the C++ object.; Thus, no C++ memory is allocated until ``__init__``.; The advantages are simple: the proxy can now check whether it is initialized,; because the pointer to C++ memory will be NULL if not; it can be a reference; to another proxy holding the actual C++ memory; and it can now transparently; implement a C++ smart pointer.; If ``__init__`` is never called, eg. when a call to the base class; ``__init__`` is missing in a derived class override, then accessing the proxy; will result in a Python ``ReferenceError`` exception. `Destructors`; -------------. There should no be reason to call a destructor directly in CPython, but e.g.; PyPy uses a garbage collector and that makes it sometimes useful to destruct; a C++ object exactly when you want it destroyed.; Destructors are by convention accessible through the ``__destruct__`` method; (since ""~"" can not be part of a Python method name).; If a Python-side derived class overrides ``__destruct__``, that method will; be called when the instance gets deleted in C++.; The Python destructor, ``__del__``, gets called when the Python proxy goes; away, which will only delete the C++ instance if owned by Python.; Note that ``__del__`` is n",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/classes.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst:12145,Usability,simpl,simple,12145,"_postdec__``; ``operator--()`` ``__predec__``; ``unary operator*`` ``__deref__``; ``operator->`` ``__follow__``; ``operator&&`` ``__dand__``; ``operator||`` ``__dor__``; ``operator,`` ``__comma__``; =================== ===================. Here is an example of operator usage, using STL iterators directly (note that; this is not necessary in practice as STL and STL-like containers work; transparently in Python for-loops):. .. code-block:: python. >>> v = cppyy.gbl.std.vector[int](range(3)); >>> i = v.begin(); >>> while (i != v.end()):; ... print(i.__deref__()); ... _ = i.__preinc__(); ...; 0; 1; 2; >>>. Overridden ``operator new`` and ``operator delete``, as well as their array; equivalents, are not accessible but will be called as appropriate. `Templates`; -----------. Templated classes are instantiated using square brackets.; (For backwards compatibility reasons, parentheses work as well.); The instantiation of a templated class yields a class, which can then; be used to create instances. Templated classes need not pre-exist in the bound code, just their; declaration needs to be available.; This is true for e.g. all of STL:. .. code-block:: python. >>> cppyy.gbl.std.vector # template metatype; <cppyy.Template 'std::vector' object at 0x7fffed2674d0>; >>> cppyy.gbl.std.vector(int) # instantiates template -> class; <class cppyy.gbl.std.vector<int> at 0x1532190>; cppyy.gbl.std.vector[int]() # instantiates class -> object; <cppyy.gbl.std.vector<int> object at 0x2341ec0>; >>>. The template arguments may be actual types or their names as a string,; whichever is more convenient.; Thus, the following are equivalent:. .. code-block:: python. >>> from cppyy.gbl.std import vector; >>> type1 = vector[Concrete]; >>> type2 = vector['Concrete']; >>> type1 == type2; True; >>>. `Typedefs`; ----------. Typedefs are simple python references to the actual classes to which; they refer. .. code-block:: python. >>> from cppyy.gbl import Concrete_t; >>> Concrete is Concrete_t; True; >>>. ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/classes.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/classes.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst:3531,Availability,avail,available,3531,"sure; hopefully upstream support; will allow this to be eliminated in due course.; * FindCppyy.cmake provides the interface described further here. Details of the usage of these modules is within the modules themselves, but; here is a summary of the usage. ``FindLibClang.cmake`` sets the following; variables:. ::. LibClang_FOUND - True if libclang is found.; LibClang_LIBRARY - Clang library to link against.; LibClang_VERSION - Version number as a string (e.g. ""3.9"").; LibClang_PYTHON_EXECUTABLE - Compatible python version. ``FindCppyy.cmake`` sets the following variables:. ::. Cppyy_FOUND - set to true if Cppyy is found; Cppyy_DIR - the directory where Cppyy is installed; Cppyy_EXECUTABLE - the path to the Cppyy executable; Cppyy_INCLUDE_DIRS - Where to find the Cppyy header files.; Cppyy_VERSION - the version number of the Cppyy backend. and also defines the following functions::. cppyy_add_bindings - Generate a set of bindings from a set of header files.; cppyy_find_pips - Return a list of available pip programs. cppyy_add_bindings; ^^^^^^^^^^^^^^^^^^. Generate a set of bindings from a set of header files. Somewhat like CMake's; add_library(), the output is a compiler target. In addition ancillary files; are also generated to allow a complete set of bindings to be compiled,; packaged and installed::. cppyy_add_bindings(; pkg; pkg_version; author; author_email; [URL url]; [LICENSE license]; [LANGUAGE_STANDARD std]; [LINKDEFS linkdef...]; [IMPORTS pcm...]; [GENERATE_OPTIONS option...]; [COMPILE_OPTIONS option...]; [INCLUDE_DIRS dir...]; [LINK_LIBRARIES library...]; [H_DIRS H_DIRSectory]; H_FILES h_file...). The bindings are based on https://cppyy.readthedocs.io/en/latest/, and can be; used as per the documentation provided via the cppyy.gbl namespace. First add; the directory of the <pkg>.rootmap file to the LD_LIBRARY_PATH environment; variable, then ""import cppyy; from cppyy.gbl import <some-C++-entity>"". Alternatively, use ""import <pkg>"". This convenience wrapper",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst:4554,Availability,avail,available,4554,"ings; ^^^^^^^^^^^^^^^^^^. Generate a set of bindings from a set of header files. Somewhat like CMake's; add_library(), the output is a compiler target. In addition ancillary files; are also generated to allow a complete set of bindings to be compiled,; packaged and installed::. cppyy_add_bindings(; pkg; pkg_version; author; author_email; [URL url]; [LICENSE license]; [LANGUAGE_STANDARD std]; [LINKDEFS linkdef...]; [IMPORTS pcm...]; [GENERATE_OPTIONS option...]; [COMPILE_OPTIONS option...]; [INCLUDE_DIRS dir...]; [LINK_LIBRARIES library...]; [H_DIRS H_DIRSectory]; H_FILES h_file...). The bindings are based on https://cppyy.readthedocs.io/en/latest/, and can be; used as per the documentation provided via the cppyy.gbl namespace. First add; the directory of the <pkg>.rootmap file to the LD_LIBRARY_PATH environment; variable, then ""import cppyy; from cppyy.gbl import <some-C++-entity>"". Alternatively, use ""import <pkg>"". This convenience wrapper supports; ""discovery"" of the available C++ entities using, for example Python 3's command; line completion support. The bindings are complete with a setup.py, supporting Wheel-based; packaging, and a test.py supporting pytest/nosetest sanity test of the bindings. The bindings are generated/built/packaged using 3 environments:. - One compatible with the header files being bound. This is used to; generate the generic C++ binding code (and some ancillary files) using; a modified C++ compiler. The needed options must be compatible with the; normal build environment of the header files.; - One to compile the generated, generic C++ binding code using a standard; C++ compiler. The resulting library code is ""universal"" in that it is; compatible with both Python2 and Python3.; - One to package the library and ancillary files into standard Python2/3; wheel format. The packaging is done using native Python tooling. +----------------------+---------------------------------------------------------------------------------------------+; |Argume",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst:11263,Availability,avail,available,11263,"| Libraries to link against. |; +----------------------+---------------------------------------------------------------------------------------------+; |H_DIRS directory | Base directories for H_FILES. |; +----------------------+---------------------------------------------------------------------------------------------+; |H_FILES h_file | Header files for which to generate bindings in pkg. |; | | Absolute filenames, or filenames relative to H_DIRS. All |; | | definitions found directly in these files will contribute |; | | to the bindings. (NOTE: This means that if ""forwarding |; | | headers"" are present, the real ""legacy"" headers must be |; | | specified as H_FILES). |; | | All header files which contribute to a given C++ namespace |; | | should be grouped into a single pkg to ensure a 1-to-1 |; | | mapping with the implementing Python class. |; +----------------------+---------------------------------------------------------------------------------------------+. Returns via PARENT_SCOPE variables::. target The CMake target used to build.; setup_py The setup.py script used to build or install pkg. Examples::. find_package(Qt5Core NO_MODULE); find_package(KF5KDcraw NO_MODULE); get_target_property(_H_DIRS KF5::KDcraw INTERFACE_INCLUDE_DIRECTORIES); get_target_property(_LINK_LIBRARIES KF5::KDcraw INTERFACE_LINK_LIBRARIES); set(_LINK_LIBRARIES KF5::KDcraw ${_LINK_LIBRARIES}); include(${KF5KDcraw_DIR}/KF5KDcrawConfigVersion.cmake). cppyy_add_bindings(; ""KDCRAW"" ""${PACKAGE_VERSION}"" ""Shaheed"" ""srhaque@theiet.org""; LANGUAGE_STANDARD ""14""; LINKDEFS ""../linkdef_overrides.h""; GENERATE_OPTIONS ""-D__PIC__;-Wno-macro-redefined""; INCLUDE_DIRS ${Qt5Core_INCLUDE_DIRS}; LINK_LIBRARIES ${_LINK_LIBRARIES}; H_DIRS ${_H_DIRS}; H_FILES ""dcrawinfocontainer.h;kdcraw.h;rawdecodingsettings.h;rawfiles.h""). cppyy_find_pips; ^^^^^^^^^^^^^^^. Return a list of available pip programs. .. _`support for exporting all`: https://cmake.org/cmake/help/latest/prop_tgt/WINDOWS_EXPORT_ALL_SYMBOLS.html; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst:3194,Deployability,install,installed,3194," the; :ref:`cppyy-generator <cppyy-generator>` (included in the package) as well as; other runtime support included in ``cppyy``. CMake usage; -----------. The CMake usage is via two modules:. * FindLibClang.cmake provides some bootstrap support needed to locate clang.; This is provided mostly as a temporary measure; hopefully upstream support; will allow this to be eliminated in due course.; * FindCppyy.cmake provides the interface described further here. Details of the usage of these modules is within the modules themselves, but; here is a summary of the usage. ``FindLibClang.cmake`` sets the following; variables:. ::. LibClang_FOUND - True if libclang is found.; LibClang_LIBRARY - Clang library to link against.; LibClang_VERSION - Version number as a string (e.g. ""3.9"").; LibClang_PYTHON_EXECUTABLE - Compatible python version. ``FindCppyy.cmake`` sets the following variables:. ::. Cppyy_FOUND - set to true if Cppyy is found; Cppyy_DIR - the directory where Cppyy is installed; Cppyy_EXECUTABLE - the path to the Cppyy executable; Cppyy_INCLUDE_DIRS - Where to find the Cppyy header files.; Cppyy_VERSION - the version number of the Cppyy backend. and also defines the following functions::. cppyy_add_bindings - Generate a set of bindings from a set of header files.; cppyy_find_pips - Return a list of available pip programs. cppyy_add_bindings; ^^^^^^^^^^^^^^^^^^. Generate a set of bindings from a set of header files. Somewhat like CMake's; add_library(), the output is a compiler target. In addition ancillary files; are also generated to allow a complete set of bindings to be compiled,; packaged and installed::. cppyy_add_bindings(; pkg; pkg_version; author; author_email; [URL url]; [LICENSE license]; [LANGUAGE_STANDARD std]; [LINKDEFS linkdef...]; [IMPORTS pcm...]; [GENERATE_OPTIONS option...]; [COMPILE_OPTIONS option...]; [INCLUDE_DIRS dir...]; [LINK_LIBRARIES library...]; [H_DIRS H_DIRSectory]; H_FILES h_file...). The bindings are based on https://cppyy.readthedocs.i",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst:3835,Deployability,install,installed,3835,"FindLibClang.cmake`` sets the following; variables:. ::. LibClang_FOUND - True if libclang is found.; LibClang_LIBRARY - Clang library to link against.; LibClang_VERSION - Version number as a string (e.g. ""3.9"").; LibClang_PYTHON_EXECUTABLE - Compatible python version. ``FindCppyy.cmake`` sets the following variables:. ::. Cppyy_FOUND - set to true if Cppyy is found; Cppyy_DIR - the directory where Cppyy is installed; Cppyy_EXECUTABLE - the path to the Cppyy executable; Cppyy_INCLUDE_DIRS - Where to find the Cppyy header files.; Cppyy_VERSION - the version number of the Cppyy backend. and also defines the following functions::. cppyy_add_bindings - Generate a set of bindings from a set of header files.; cppyy_find_pips - Return a list of available pip programs. cppyy_add_bindings; ^^^^^^^^^^^^^^^^^^. Generate a set of bindings from a set of header files. Somewhat like CMake's; add_library(), the output is a compiler target. In addition ancillary files; are also generated to allow a complete set of bindings to be compiled,; packaged and installed::. cppyy_add_bindings(; pkg; pkg_version; author; author_email; [URL url]; [LICENSE license]; [LANGUAGE_STANDARD std]; [LINKDEFS linkdef...]; [IMPORTS pcm...]; [GENERATE_OPTIONS option...]; [COMPILE_OPTIONS option...]; [INCLUDE_DIRS dir...]; [LINK_LIBRARIES library...]; [H_DIRS H_DIRSectory]; H_FILES h_file...). The bindings are based on https://cppyy.readthedocs.io/en/latest/, and can be; used as per the documentation provided via the cppyy.gbl namespace. First add; the directory of the <pkg>.rootmap file to the LD_LIBRARY_PATH environment; variable, then ""import cppyy; from cppyy.gbl import <some-C++-entity>"". Alternatively, use ""import <pkg>"". This convenience wrapper supports; ""discovery"" of the available C++ entities using, for example Python 3's command; line completion support. The bindings are complete with a setup.py, supporting Wheel-based; packaging, and a test.py supporting pytest/nosetest sanity test of the bindi",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst:10503,Deployability,install,install,10503,"| Libraries to link against. |; +----------------------+---------------------------------------------------------------------------------------------+; |H_DIRS directory | Base directories for H_FILES. |; +----------------------+---------------------------------------------------------------------------------------------+; |H_FILES h_file | Header files for which to generate bindings in pkg. |; | | Absolute filenames, or filenames relative to H_DIRS. All |; | | definitions found directly in these files will contribute |; | | to the bindings. (NOTE: This means that if ""forwarding |; | | headers"" are present, the real ""legacy"" headers must be |; | | specified as H_FILES). |; | | All header files which contribute to a given C++ namespace |; | | should be grouped into a single pkg to ensure a 1-to-1 |; | | mapping with the implementing Python class. |; +----------------------+---------------------------------------------------------------------------------------------+. Returns via PARENT_SCOPE variables::. target The CMake target used to build.; setup_py The setup.py script used to build or install pkg. Examples::. find_package(Qt5Core NO_MODULE); find_package(KF5KDcraw NO_MODULE); get_target_property(_H_DIRS KF5::KDcraw INTERFACE_INCLUDE_DIRECTORIES); get_target_property(_LINK_LIBRARIES KF5::KDcraw INTERFACE_LINK_LIBRARIES); set(_LINK_LIBRARIES KF5::KDcraw ${_LINK_LIBRARIES}); include(${KF5KDcraw_DIR}/KF5KDcrawConfigVersion.cmake). cppyy_add_bindings(; ""KDCRAW"" ""${PACKAGE_VERSION}"" ""Shaheed"" ""srhaque@theiet.org""; LANGUAGE_STANDARD ""14""; LINKDEFS ""../linkdef_overrides.h""; GENERATE_OPTIONS ""-D__PIC__;-Wno-macro-redefined""; INCLUDE_DIRS ${Qt5Core_INCLUDE_DIRS}; LINK_LIBRARIES ${_LINK_LIBRARIES}; H_DIRS ${_H_DIRS}; H_FILES ""dcrawinfocontainer.h;kdcraw.h;rawdecodingsettings.h;rawfiles.h""). cppyy_find_pips; ^^^^^^^^^^^^^^^. Return a list of available pip programs. .. _`support for exporting all`: https://cmake.org/cmake/help/latest/prop_tgt/WINDOWS_EXPORT_ALL_SYMBOLS.html; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst:28,Integrability,interface,interface,28,".. _cmake_interface:. CMake interface; ===============. CMake fragments are provided for an Automated generation of an end-user; bindings package from a CMake-based project build.; The bindings generated by rootcling, are 'raw' in the sense that:. * The .cpp file be compiled. The required compilation steps are; platform-dependent.; * The bindings are not packaged for distribution. Typically, users expect; to have a pip-compatible package.; * The binding are in the 'cppyy.gbl' namespace. This is an inconvenience at; best for users who might expect C++ code from KF5::Config to appear in; Python via ""import KF5.Config"".; * The bindings are loaded lazily, which limits the discoverability of the; content of the bindings.; * ``cppyy`` supports customization of the bindings via 'Pythonization' but; there is no automated way to load them. These issues are addressed by the CMake support. This is a blend of Python; packaging and CMake where CMake provides:. * Platform-independent scripting of the creation of a Python 'wheel' package; for the bindings.; * An facility for CMake-based projects to automate the entire bindings; generation process, including basic automated tests. .. note::. The JIT needs to resolve linker symbols in order to call them through; generated wrappers.; Thus, any classes, functions, and data that will be used in Python need; to be exported.; This is the default behavior on Mac and Linux, but not on Windows.; On that platform, use ``__declspec(dllexport)`` to explicitly export the; classes and function you expect to call.; CMake has simple `support for exporting all`_ C++ symbols. Python packaging; ----------------. Modern Python packaging usage is based on the 'wheel'. This is places the onus; on the creation of binary artifacts in the package on the distributor. In this; case, this includes the platform-dependent steps necessary to compile the .cpp; file. The generated package also takes advantage of the __init__.py load-time; mechanism to enhance the b",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst:322,Integrability,depend,dependent,322,".. _cmake_interface:. CMake interface; ===============. CMake fragments are provided for an Automated generation of an end-user; bindings package from a CMake-based project build.; The bindings generated by rootcling, are 'raw' in the sense that:. * The .cpp file be compiled. The required compilation steps are; platform-dependent.; * The bindings are not packaged for distribution. Typically, users expect; to have a pip-compatible package.; * The binding are in the 'cppyy.gbl' namespace. This is an inconvenience at; best for users who might expect C++ code from KF5::Config to appear in; Python via ""import KF5.Config"".; * The bindings are loaded lazily, which limits the discoverability of the; content of the bindings.; * ``cppyy`` supports customization of the bindings via 'Pythonization' but; there is no automated way to load them. These issues are addressed by the CMake support. This is a blend of Python; packaging and CMake where CMake provides:. * Platform-independent scripting of the creation of a Python 'wheel' package; for the bindings.; * An facility for CMake-based projects to automate the entire bindings; generation process, including basic automated tests. .. note::. The JIT needs to resolve linker symbols in order to call them through; generated wrappers.; Thus, any classes, functions, and data that will be used in Python need; to be exported.; This is the default behavior on Mac and Linux, but not on Windows.; On that platform, use ``__declspec(dllexport)`` to explicitly export the; classes and function you expect to call.; CMake has simple `support for exporting all`_ C++ symbols. Python packaging; ----------------. Modern Python packaging usage is based on the 'wheel'. This is places the onus; on the creation of binary artifacts in the package on the distributor. In this; case, this includes the platform-dependent steps necessary to compile the .cpp; file. The generated package also takes advantage of the __init__.py load-time; mechanism to enhance the b",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst:1276,Integrability,wrap,wrappers,1276,"e that:. * The .cpp file be compiled. The required compilation steps are; platform-dependent.; * The bindings are not packaged for distribution. Typically, users expect; to have a pip-compatible package.; * The binding are in the 'cppyy.gbl' namespace. This is an inconvenience at; best for users who might expect C++ code from KF5::Config to appear in; Python via ""import KF5.Config"".; * The bindings are loaded lazily, which limits the discoverability of the; content of the bindings.; * ``cppyy`` supports customization of the bindings via 'Pythonization' but; there is no automated way to load them. These issues are addressed by the CMake support. This is a blend of Python; packaging and CMake where CMake provides:. * Platform-independent scripting of the creation of a Python 'wheel' package; for the bindings.; * An facility for CMake-based projects to automate the entire bindings; generation process, including basic automated tests. .. note::. The JIT needs to resolve linker symbols in order to call them through; generated wrappers.; Thus, any classes, functions, and data that will be used in Python need; to be exported.; This is the default behavior on Mac and Linux, but not on Windows.; On that platform, use ``__declspec(dllexport)`` to explicitly export the; classes and function you expect to call.; CMake has simple `support for exporting all`_ C++ symbols. Python packaging; ----------------. Modern Python packaging usage is based on the 'wheel'. This is places the onus; on the creation of binary artifacts in the package on the distributor. In this; case, this includes the platform-dependent steps necessary to compile the .cpp; file. The generated package also takes advantage of the __init__.py load-time; mechanism to enhance the bindings:. * The bindings are rehosted in a ""native"" namespace so that C++ code from; KF5::Config appears in Python via ""import KF5.Config"".; * (TBD) Load Pythonizations. Both of these need/can use the output of the; :ref:`cppyy-generator <",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst:1849,Integrability,depend,dependent,1849," issues are addressed by the CMake support. This is a blend of Python; packaging and CMake where CMake provides:. * Platform-independent scripting of the creation of a Python 'wheel' package; for the bindings.; * An facility for CMake-based projects to automate the entire bindings; generation process, including basic automated tests. .. note::. The JIT needs to resolve linker symbols in order to call them through; generated wrappers.; Thus, any classes, functions, and data that will be used in Python need; to be exported.; This is the default behavior on Mac and Linux, but not on Windows.; On that platform, use ``__declspec(dllexport)`` to explicitly export the; classes and function you expect to call.; CMake has simple `support for exporting all`_ C++ symbols. Python packaging; ----------------. Modern Python packaging usage is based on the 'wheel'. This is places the onus; on the creation of binary artifacts in the package on the distributor. In this; case, this includes the platform-dependent steps necessary to compile the .cpp; file. The generated package also takes advantage of the __init__.py load-time; mechanism to enhance the bindings:. * The bindings are rehosted in a ""native"" namespace so that C++ code from; KF5::Config appears in Python via ""import KF5.Config"".; * (TBD) Load Pythonizations. Both of these need/can use the output of the; :ref:`cppyy-generator <cppyy-generator>` (included in the package) as well as; other runtime support included in ``cppyy``. CMake usage; -----------. The CMake usage is via two modules:. * FindLibClang.cmake provides some bootstrap support needed to locate clang.; This is provided mostly as a temporary measure; hopefully upstream support; will allow this to be eliminated in due course.; * FindCppyy.cmake provides the interface described further here. Details of the usage of these modules is within the modules themselves, but; here is a summary of the usage. ``FindLibClang.cmake`` sets the following; variables:. ::. LibClang_",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst:2638,Integrability,interface,interface,2638,"---------. Modern Python packaging usage is based on the 'wheel'. This is places the onus; on the creation of binary artifacts in the package on the distributor. In this; case, this includes the platform-dependent steps necessary to compile the .cpp; file. The generated package also takes advantage of the __init__.py load-time; mechanism to enhance the bindings:. * The bindings are rehosted in a ""native"" namespace so that C++ code from; KF5::Config appears in Python via ""import KF5.Config"".; * (TBD) Load Pythonizations. Both of these need/can use the output of the; :ref:`cppyy-generator <cppyy-generator>` (included in the package) as well as; other runtime support included in ``cppyy``. CMake usage; -----------. The CMake usage is via two modules:. * FindLibClang.cmake provides some bootstrap support needed to locate clang.; This is provided mostly as a temporary measure; hopefully upstream support; will allow this to be eliminated in due course.; * FindCppyy.cmake provides the interface described further here. Details of the usage of these modules is within the modules themselves, but; here is a summary of the usage. ``FindLibClang.cmake`` sets the following; variables:. ::. LibClang_FOUND - True if libclang is found.; LibClang_LIBRARY - Clang library to link against.; LibClang_VERSION - Version number as a string (e.g. ""3.9"").; LibClang_PYTHON_EXECUTABLE - Compatible python version. ``FindCppyy.cmake`` sets the following variables:. ::. Cppyy_FOUND - set to true if Cppyy is found; Cppyy_DIR - the directory where Cppyy is installed; Cppyy_EXECUTABLE - the path to the Cppyy executable; Cppyy_INCLUDE_DIRS - Where to find the Cppyy header files.; Cppyy_VERSION - the version number of the Cppyy backend. and also defines the following functions::. cppyy_add_bindings - Generate a set of bindings from a set of header files.; cppyy_find_pips - Return a list of available pip programs. cppyy_add_bindings; ^^^^^^^^^^^^^^^^^^. Generate a set of bindings from a set of header fi",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst:4517,Integrability,wrap,wrapper,4517,"ings; ^^^^^^^^^^^^^^^^^^. Generate a set of bindings from a set of header files. Somewhat like CMake's; add_library(), the output is a compiler target. In addition ancillary files; are also generated to allow a complete set of bindings to be compiled,; packaged and installed::. cppyy_add_bindings(; pkg; pkg_version; author; author_email; [URL url]; [LICENSE license]; [LANGUAGE_STANDARD std]; [LINKDEFS linkdef...]; [IMPORTS pcm...]; [GENERATE_OPTIONS option...]; [COMPILE_OPTIONS option...]; [INCLUDE_DIRS dir...]; [LINK_LIBRARIES library...]; [H_DIRS H_DIRSectory]; H_FILES h_file...). The bindings are based on https://cppyy.readthedocs.io/en/latest/, and can be; used as per the documentation provided via the cppyy.gbl namespace. First add; the directory of the <pkg>.rootmap file to the LD_LIBRARY_PATH environment; variable, then ""import cppyy; from cppyy.gbl import <some-C++-entity>"". Alternatively, use ""import <pkg>"". This convenience wrapper supports; ""discovery"" of the available C++ entities using, for example Python 3's command; line completion support. The bindings are complete with a setup.py, supporting Wheel-based; packaging, and a test.py supporting pytest/nosetest sanity test of the bindings. The bindings are generated/built/packaged using 3 environments:. - One compatible with the header files being bound. This is used to; generate the generic C++ binding code (and some ancillary files) using; a modified C++ compiler. The needed options must be compatible with the; normal build environment of the header files.; - One to compile the generated, generic C++ binding code using a standard; C++ compiler. The resulting library code is ""universal"" in that it is; compatible with both Python2 and Python3.; - One to package the library and ancillary files into standard Python2/3; wheel format. The packaging is done using native Python tooling. +----------------------+---------------------------------------------------------------------------------------------+; |Argume",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst:7210,Integrability,depend,depends,7210,"-----------------------------------------------------------------------------+; |author | The name of the library author. |; +----------------------+---------------------------------------------------------------------------------------------+; |author_email | The email address of the library author. |; +----------------------+---------------------------------------------------------------------------------------------+; |URL url | The home page for the library. Default is |; | | ""https://pypi.python.org/pypi/<pkg>"". |; +----------------------+---------------------------------------------------------------------------------------------+; |LICENSE license | The license, default is ""LGPL 2.0"". |; +----------------------+---------------------------------------------------------------------------------------------+; |LANGUAGE_STANDARD std | The version of C++ in use, ""14"" by default. |; +----------------------+---------------------------------------------------------------------------------------------+; |IMPORTS pcm | Files which contain previously-generated bindings |; | | which pkg depends on. |; +----------------------+---------------------------------------------------------------------------------------------+; |GENERATE_OPTIONS optio| Options which are to be passed into the rootcling |; | | command. For example, bindings which depend on Qt |; | | may need ""-D__PIC__;-Wno-macro-redefined"". |; +----------------------+---------------------------------------------------------------------------------------------+; |LINKDEFS def | Files or lines which contain extra #pragma content |; | | for the linkdef.h file used by rootcling. See |; | | https://root.cern.ch/root/html/guides/users-guide/AddingaClass.html#the-linkdef.h-file. |; | | |; | | In lines, literal semi-colons must be escaped: ""\;"". |; +----------------------+---------------------------------------------------------------------------------------------+; |EXTRA_CODES code | Files which contain extra code needed ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst:7464,Integrability,depend,depend,7464,"------------------------------------------------------+; |URL url | The home page for the library. Default is |; | | ""https://pypi.python.org/pypi/<pkg>"". |; +----------------------+---------------------------------------------------------------------------------------------+; |LICENSE license | The license, default is ""LGPL 2.0"". |; +----------------------+---------------------------------------------------------------------------------------------+; |LANGUAGE_STANDARD std | The version of C++ in use, ""14"" by default. |; +----------------------+---------------------------------------------------------------------------------------------+; |IMPORTS pcm | Files which contain previously-generated bindings |; | | which pkg depends on. |; +----------------------+---------------------------------------------------------------------------------------------+; |GENERATE_OPTIONS optio| Options which are to be passed into the rootcling |; | | command. For example, bindings which depend on Qt |; | | may need ""-D__PIC__;-Wno-macro-redefined"". |; +----------------------+---------------------------------------------------------------------------------------------+; |LINKDEFS def | Files or lines which contain extra #pragma content |; | | for the linkdef.h file used by rootcling. See |; | | https://root.cern.ch/root/html/guides/users-guide/AddingaClass.html#the-linkdef.h-file. |; | | |; | | In lines, literal semi-colons must be escaped: ""\;"". |; +----------------------+---------------------------------------------------------------------------------------------+; |EXTRA_CODES code | Files which contain extra code needed by the bindings. |; | | Customization is by routines named ""c13n_<something>""; |; | | each such routine is passed the module for <pkg>: |; | | |; | | :: code-block python |; | | |; | | def c13n_doit(pkg_module): |; | | print(pkg_module.__dict__) |; | | |; | | The files and individual routines within files are |; | | processed in alphabetical order. |; +-------------",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst:8157,Integrability,rout,routines,8157,"---------+---------------------------------------------------------------------------------------------+; |GENERATE_OPTIONS optio| Options which are to be passed into the rootcling |; | | command. For example, bindings which depend on Qt |; | | may need ""-D__PIC__;-Wno-macro-redefined"". |; +----------------------+---------------------------------------------------------------------------------------------+; |LINKDEFS def | Files or lines which contain extra #pragma content |; | | for the linkdef.h file used by rootcling. See |; | | https://root.cern.ch/root/html/guides/users-guide/AddingaClass.html#the-linkdef.h-file. |; | | |; | | In lines, literal semi-colons must be escaped: ""\;"". |; +----------------------+---------------------------------------------------------------------------------------------+; |EXTRA_CODES code | Files which contain extra code needed by the bindings. |; | | Customization is by routines named ""c13n_<something>""; |; | | each such routine is passed the module for <pkg>: |; | | |; | | :: code-block python |; | | |; | | def c13n_doit(pkg_module): |; | | print(pkg_module.__dict__) |; | | |; | | The files and individual routines within files are |; | | processed in alphabetical order. |; +----------------------+---------------------------------------------------------------------------------------------+; |EXTRA_HEADERS hdr | Files which contain extra headers needed by the bindings. |; +----------------------+---------------------------------------------------------------------------------------------+; |EXTRA_PYTHONS py | Files which contain extra Python code needed by the bindings. |; +----------------------+---------------------------------------------------------------------------------------------+; |COMPILE_OPTIONS option| Options which are to be passed into the compile/link |; | | command. |; +----------------------+---------------------------------------------------------------------------------------------+; |INCLUDE_DIRS dir | Include ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst:8209,Integrability,rout,routine,8209,"---------+---------------------------------------------------------------------------------------------+; |GENERATE_OPTIONS optio| Options which are to be passed into the rootcling |; | | command. For example, bindings which depend on Qt |; | | may need ""-D__PIC__;-Wno-macro-redefined"". |; +----------------------+---------------------------------------------------------------------------------------------+; |LINKDEFS def | Files or lines which contain extra #pragma content |; | | for the linkdef.h file used by rootcling. See |; | | https://root.cern.ch/root/html/guides/users-guide/AddingaClass.html#the-linkdef.h-file. |; | | |; | | In lines, literal semi-colons must be escaped: ""\;"". |; +----------------------+---------------------------------------------------------------------------------------------+; |EXTRA_CODES code | Files which contain extra code needed by the bindings. |; | | Customization is by routines named ""c13n_<something>""; |; | | each such routine is passed the module for <pkg>: |; | | |; | | :: code-block python |; | | |; | | def c13n_doit(pkg_module): |; | | print(pkg_module.__dict__) |; | | |; | | The files and individual routines within files are |; | | processed in alphabetical order. |; +----------------------+---------------------------------------------------------------------------------------------+; |EXTRA_HEADERS hdr | Files which contain extra headers needed by the bindings. |; +----------------------+---------------------------------------------------------------------------------------------+; |EXTRA_PYTHONS py | Files which contain extra Python code needed by the bindings. |; +----------------------+---------------------------------------------------------------------------------------------+; |COMPILE_OPTIONS option| Options which are to be passed into the compile/link |; | | command. |; +----------------------+---------------------------------------------------------------------------------------------+; |INCLUDE_DIRS dir | Include ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst:8398,Integrability,rout,routines,8398,"the rootcling |; | | command. For example, bindings which depend on Qt |; | | may need ""-D__PIC__;-Wno-macro-redefined"". |; +----------------------+---------------------------------------------------------------------------------------------+; |LINKDEFS def | Files or lines which contain extra #pragma content |; | | for the linkdef.h file used by rootcling. See |; | | https://root.cern.ch/root/html/guides/users-guide/AddingaClass.html#the-linkdef.h-file. |; | | |; | | In lines, literal semi-colons must be escaped: ""\;"". |; +----------------------+---------------------------------------------------------------------------------------------+; |EXTRA_CODES code | Files which contain extra code needed by the bindings. |; | | Customization is by routines named ""c13n_<something>""; |; | | each such routine is passed the module for <pkg>: |; | | |; | | :: code-block python |; | | |; | | def c13n_doit(pkg_module): |; | | print(pkg_module.__dict__) |; | | |; | | The files and individual routines within files are |; | | processed in alphabetical order. |; +----------------------+---------------------------------------------------------------------------------------------+; |EXTRA_HEADERS hdr | Files which contain extra headers needed by the bindings. |; +----------------------+---------------------------------------------------------------------------------------------+; |EXTRA_PYTHONS py | Files which contain extra Python code needed by the bindings. |; +----------------------+---------------------------------------------------------------------------------------------+; |COMPILE_OPTIONS option| Options which are to be passed into the compile/link |; | | command. |; +----------------------+---------------------------------------------------------------------------------------------+; |INCLUDE_DIRS dir | Include directories. |; +----------------------+---------------------------------------------------------------------------------------------+; |LINK_LIBRARIES library| Librar",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst:1988,Modifiability,enhance,enhance,1988,"scripting of the creation of a Python 'wheel' package; for the bindings.; * An facility for CMake-based projects to automate the entire bindings; generation process, including basic automated tests. .. note::. The JIT needs to resolve linker symbols in order to call them through; generated wrappers.; Thus, any classes, functions, and data that will be used in Python need; to be exported.; This is the default behavior on Mac and Linux, but not on Windows.; On that platform, use ``__declspec(dllexport)`` to explicitly export the; classes and function you expect to call.; CMake has simple `support for exporting all`_ C++ symbols. Python packaging; ----------------. Modern Python packaging usage is based on the 'wheel'. This is places the onus; on the creation of binary artifacts in the package on the distributor. In this; case, this includes the platform-dependent steps necessary to compile the .cpp; file. The generated package also takes advantage of the __init__.py load-time; mechanism to enhance the bindings:. * The bindings are rehosted in a ""native"" namespace so that C++ code from; KF5::Config appears in Python via ""import KF5.Config"".; * (TBD) Load Pythonizations. Both of these need/can use the output of the; :ref:`cppyy-generator <cppyy-generator>` (included in the package) as well as; other runtime support included in ``cppyy``. CMake usage; -----------. The CMake usage is via two modules:. * FindLibClang.cmake provides some bootstrap support needed to locate clang.; This is provided mostly as a temporary measure; hopefully upstream support; will allow this to be eliminated in due course.; * FindCppyy.cmake provides the interface described further here. Details of the usage of these modules is within the modules themselves, but; here is a summary of the usage. ``FindLibClang.cmake`` sets the following; variables:. ::. LibClang_FOUND - True if libclang is found.; LibClang_LIBRARY - Clang library to link against.; LibClang_VERSION - Version number as a string (e.g",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst:2824,Modifiability,variab,variables,2824," case, this includes the platform-dependent steps necessary to compile the .cpp; file. The generated package also takes advantage of the __init__.py load-time; mechanism to enhance the bindings:. * The bindings are rehosted in a ""native"" namespace so that C++ code from; KF5::Config appears in Python via ""import KF5.Config"".; * (TBD) Load Pythonizations. Both of these need/can use the output of the; :ref:`cppyy-generator <cppyy-generator>` (included in the package) as well as; other runtime support included in ``cppyy``. CMake usage; -----------. The CMake usage is via two modules:. * FindLibClang.cmake provides some bootstrap support needed to locate clang.; This is provided mostly as a temporary measure; hopefully upstream support; will allow this to be eliminated in due course.; * FindCppyy.cmake provides the interface described further here. Details of the usage of these modules is within the modules themselves, but; here is a summary of the usage. ``FindLibClang.cmake`` sets the following; variables:. ::. LibClang_FOUND - True if libclang is found.; LibClang_LIBRARY - Clang library to link against.; LibClang_VERSION - Version number as a string (e.g. ""3.9"").; LibClang_PYTHON_EXECUTABLE - Compatible python version. ``FindCppyy.cmake`` sets the following variables:. ::. Cppyy_FOUND - set to true if Cppyy is found; Cppyy_DIR - the directory where Cppyy is installed; Cppyy_EXECUTABLE - the path to the Cppyy executable; Cppyy_INCLUDE_DIRS - Where to find the Cppyy header files.; Cppyy_VERSION - the version number of the Cppyy backend. and also defines the following functions::. cppyy_add_bindings - Generate a set of bindings from a set of header files.; cppyy_find_pips - Return a list of available pip programs. cppyy_add_bindings; ^^^^^^^^^^^^^^^^^^. Generate a set of bindings from a set of header files. Somewhat like CMake's; add_library(), the output is a compiler target. In addition ancillary files; are also generated to allow a complete set of bindings to be compi",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst:3092,Modifiability,variab,variables,3092,"; KF5::Config appears in Python via ""import KF5.Config"".; * (TBD) Load Pythonizations. Both of these need/can use the output of the; :ref:`cppyy-generator <cppyy-generator>` (included in the package) as well as; other runtime support included in ``cppyy``. CMake usage; -----------. The CMake usage is via two modules:. * FindLibClang.cmake provides some bootstrap support needed to locate clang.; This is provided mostly as a temporary measure; hopefully upstream support; will allow this to be eliminated in due course.; * FindCppyy.cmake provides the interface described further here. Details of the usage of these modules is within the modules themselves, but; here is a summary of the usage. ``FindLibClang.cmake`` sets the following; variables:. ::. LibClang_FOUND - True if libclang is found.; LibClang_LIBRARY - Clang library to link against.; LibClang_VERSION - Version number as a string (e.g. ""3.9"").; LibClang_PYTHON_EXECUTABLE - Compatible python version. ``FindCppyy.cmake`` sets the following variables:. ::. Cppyy_FOUND - set to true if Cppyy is found; Cppyy_DIR - the directory where Cppyy is installed; Cppyy_EXECUTABLE - the path to the Cppyy executable; Cppyy_INCLUDE_DIRS - Where to find the Cppyy header files.; Cppyy_VERSION - the version number of the Cppyy backend. and also defines the following functions::. cppyy_add_bindings - Generate a set of bindings from a set of header files.; cppyy_find_pips - Return a list of available pip programs. cppyy_add_bindings; ^^^^^^^^^^^^^^^^^^. Generate a set of bindings from a set of header files. Somewhat like CMake's; add_library(), the output is a compiler target. In addition ancillary files; are also generated to allow a complete set of bindings to be compiled,; packaged and installed::. cppyy_add_bindings(; pkg; pkg_version; author; author_email; [URL url]; [LICENSE license]; [LANGUAGE_STANDARD std]; [LINKDEFS linkdef...]; [IMPORTS pcm...]; [GENERATE_OPTIONS option...]; [COMPILE_OPTIONS option...]; [INCLUDE_DIRS dir...",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst:4393,Modifiability,variab,variable,4393,"es the following functions::. cppyy_add_bindings - Generate a set of bindings from a set of header files.; cppyy_find_pips - Return a list of available pip programs. cppyy_add_bindings; ^^^^^^^^^^^^^^^^^^. Generate a set of bindings from a set of header files. Somewhat like CMake's; add_library(), the output is a compiler target. In addition ancillary files; are also generated to allow a complete set of bindings to be compiled,; packaged and installed::. cppyy_add_bindings(; pkg; pkg_version; author; author_email; [URL url]; [LICENSE license]; [LANGUAGE_STANDARD std]; [LINKDEFS linkdef...]; [IMPORTS pcm...]; [GENERATE_OPTIONS option...]; [COMPILE_OPTIONS option...]; [INCLUDE_DIRS dir...]; [LINK_LIBRARIES library...]; [H_DIRS H_DIRSectory]; H_FILES h_file...). The bindings are based on https://cppyy.readthedocs.io/en/latest/, and can be; used as per the documentation provided via the cppyy.gbl namespace. First add; the directory of the <pkg>.rootmap file to the LD_LIBRARY_PATH environment; variable, then ""import cppyy; from cppyy.gbl import <some-C++-entity>"". Alternatively, use ""import <pkg>"". This convenience wrapper supports; ""discovery"" of the available C++ entities using, for example Python 3's command; line completion support. The bindings are complete with a setup.py, supporting Wheel-based; packaging, and a test.py supporting pytest/nosetest sanity test of the bindings. The bindings are generated/built/packaged using 3 environments:. - One compatible with the header files being bound. This is used to; generate the generic C++ binding code (and some ancillary files) using; a modified C++ compiler. The needed options must be compatible with the; normal build environment of the header files.; - One to compile the generated, generic C++ binding code using a standard; C++ compiler. The resulting library code is ""universal"" in that it is; compatible with both Python2 and Python3.; - One to package the library and ancillary files into standard Python2/3; wheel forma",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst:10404,Modifiability,variab,variables,10404,"y| Libraries to link against. |; +----------------------+---------------------------------------------------------------------------------------------+; |H_DIRS directory | Base directories for H_FILES. |; +----------------------+---------------------------------------------------------------------------------------------+; |H_FILES h_file | Header files for which to generate bindings in pkg. |; | | Absolute filenames, or filenames relative to H_DIRS. All |; | | definitions found directly in these files will contribute |; | | to the bindings. (NOTE: This means that if ""forwarding |; | | headers"" are present, the real ""legacy"" headers must be |; | | specified as H_FILES). |; | | All header files which contribute to a given C++ namespace |; | | should be grouped into a single pkg to ensure a 1-to-1 |; | | mapping with the implementing Python class. |; +----------------------+---------------------------------------------------------------------------------------------+. Returns via PARENT_SCOPE variables::. target The CMake target used to build.; setup_py The setup.py script used to build or install pkg. Examples::. find_package(Qt5Core NO_MODULE); find_package(KF5KDcraw NO_MODULE); get_target_property(_H_DIRS KF5::KDcraw INTERFACE_INCLUDE_DIRECTORIES); get_target_property(_LINK_LIBRARIES KF5::KDcraw INTERFACE_LINK_LIBRARIES); set(_LINK_LIBRARIES KF5::KDcraw ${_LINK_LIBRARIES}); include(${KF5KDcraw_DIR}/KF5KDcrawConfigVersion.cmake). cppyy_add_bindings(; ""KDCRAW"" ""${PACKAGE_VERSION}"" ""Shaheed"" ""srhaque@theiet.org""; LANGUAGE_STANDARD ""14""; LINKDEFS ""../linkdef_overrides.h""; GENERATE_OPTIONS ""-D__PIC__;-Wno-macro-redefined""; INCLUDE_DIRS ${Qt5Core_INCLUDE_DIRS}; LINK_LIBRARIES ${_LINK_LIBRARIES}; H_DIRS ${_H_DIRS}; H_FILES ""dcrawinfocontainer.h;kdcraw.h;rawdecodingsettings.h;rawfiles.h""). cppyy_find_pips; ^^^^^^^^^^^^^^^. Return a list of available pip programs. .. _`support for exporting all`: https://cmake.org/cmake/help/latest/prop_tgt/WINDOWS_EXPORT_ALL_SYMBOLS.html;",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst:645,Performance,load,loaded,645,".. _cmake_interface:. CMake interface; ===============. CMake fragments are provided for an Automated generation of an end-user; bindings package from a CMake-based project build.; The bindings generated by rootcling, are 'raw' in the sense that:. * The .cpp file be compiled. The required compilation steps are; platform-dependent.; * The bindings are not packaged for distribution. Typically, users expect; to have a pip-compatible package.; * The binding are in the 'cppyy.gbl' namespace. This is an inconvenience at; best for users who might expect C++ code from KF5::Config to appear in; Python via ""import KF5.Config"".; * The bindings are loaded lazily, which limits the discoverability of the; content of the bindings.; * ``cppyy`` supports customization of the bindings via 'Pythonization' but; there is no automated way to load them. These issues are addressed by the CMake support. This is a blend of Python; packaging and CMake where CMake provides:. * Platform-independent scripting of the creation of a Python 'wheel' package; for the bindings.; * An facility for CMake-based projects to automate the entire bindings; generation process, including basic automated tests. .. note::. The JIT needs to resolve linker symbols in order to call them through; generated wrappers.; Thus, any classes, functions, and data that will be used in Python need; to be exported.; This is the default behavior on Mac and Linux, but not on Windows.; On that platform, use ``__declspec(dllexport)`` to explicitly export the; classes and function you expect to call.; CMake has simple `support for exporting all`_ C++ symbols. Python packaging; ----------------. Modern Python packaging usage is based on the 'wheel'. This is places the onus; on the creation of binary artifacts in the package on the distributor. In this; case, this includes the platform-dependent steps necessary to compile the .cpp; file. The generated package also takes advantage of the __init__.py load-time; mechanism to enhance the b",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst:832,Performance,load,load,832,".. _cmake_interface:. CMake interface; ===============. CMake fragments are provided for an Automated generation of an end-user; bindings package from a CMake-based project build.; The bindings generated by rootcling, are 'raw' in the sense that:. * The .cpp file be compiled. The required compilation steps are; platform-dependent.; * The bindings are not packaged for distribution. Typically, users expect; to have a pip-compatible package.; * The binding are in the 'cppyy.gbl' namespace. This is an inconvenience at; best for users who might expect C++ code from KF5::Config to appear in; Python via ""import KF5.Config"".; * The bindings are loaded lazily, which limits the discoverability of the; content of the bindings.; * ``cppyy`` supports customization of the bindings via 'Pythonization' but; there is no automated way to load them. These issues are addressed by the CMake support. This is a blend of Python; packaging and CMake where CMake provides:. * Platform-independent scripting of the creation of a Python 'wheel' package; for the bindings.; * An facility for CMake-based projects to automate the entire bindings; generation process, including basic automated tests. .. note::. The JIT needs to resolve linker symbols in order to call them through; generated wrappers.; Thus, any classes, functions, and data that will be used in Python need; to be exported.; This is the default behavior on Mac and Linux, but not on Windows.; On that platform, use ``__declspec(dllexport)`` to explicitly export the; classes and function you expect to call.; CMake has simple `support for exporting all`_ C++ symbols. Python packaging; ----------------. Modern Python packaging usage is based on the 'wheel'. This is places the onus; on the creation of binary artifacts in the package on the distributor. In this; case, this includes the platform-dependent steps necessary to compile the .cpp; file. The generated package also takes advantage of the __init__.py load-time; mechanism to enhance the b",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst:1964,Performance,load,load-time,1964,"scripting of the creation of a Python 'wheel' package; for the bindings.; * An facility for CMake-based projects to automate the entire bindings; generation process, including basic automated tests. .. note::. The JIT needs to resolve linker symbols in order to call them through; generated wrappers.; Thus, any classes, functions, and data that will be used in Python need; to be exported.; This is the default behavior on Mac and Linux, but not on Windows.; On that platform, use ``__declspec(dllexport)`` to explicitly export the; classes and function you expect to call.; CMake has simple `support for exporting all`_ C++ symbols. Python packaging; ----------------. Modern Python packaging usage is based on the 'wheel'. This is places the onus; on the creation of binary artifacts in the package on the distributor. In this; case, this includes the platform-dependent steps necessary to compile the .cpp; file. The generated package also takes advantage of the __init__.py load-time; mechanism to enhance the bindings:. * The bindings are rehosted in a ""native"" namespace so that C++ code from; KF5::Config appears in Python via ""import KF5.Config"".; * (TBD) Load Pythonizations. Both of these need/can use the output of the; :ref:`cppyy-generator <cppyy-generator>` (included in the package) as well as; other runtime support included in ``cppyy``. CMake usage; -----------. The CMake usage is via two modules:. * FindLibClang.cmake provides some bootstrap support needed to locate clang.; This is provided mostly as a temporary measure; hopefully upstream support; will allow this to be eliminated in due course.; * FindCppyy.cmake provides the interface described further here. Details of the usage of these modules is within the modules themselves, but; here is a summary of the usage. ``FindLibClang.cmake`` sets the following; variables:. ::. LibClang_FOUND - True if libclang is found.; LibClang_LIBRARY - Clang library to link against.; LibClang_VERSION - Version number as a string (e.g",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst:1177,Testability,test,tests,1177,"nd-user; bindings package from a CMake-based project build.; The bindings generated by rootcling, are 'raw' in the sense that:. * The .cpp file be compiled. The required compilation steps are; platform-dependent.; * The bindings are not packaged for distribution. Typically, users expect; to have a pip-compatible package.; * The binding are in the 'cppyy.gbl' namespace. This is an inconvenience at; best for users who might expect C++ code from KF5::Config to appear in; Python via ""import KF5.Config"".; * The bindings are loaded lazily, which limits the discoverability of the; content of the bindings.; * ``cppyy`` supports customization of the bindings via 'Pythonization' but; there is no automated way to load them. These issues are addressed by the CMake support. This is a blend of Python; packaging and CMake where CMake provides:. * Platform-independent scripting of the creation of a Python 'wheel' package; for the bindings.; * An facility for CMake-based projects to automate the entire bindings; generation process, including basic automated tests. .. note::. The JIT needs to resolve linker symbols in order to call them through; generated wrappers.; Thus, any classes, functions, and data that will be used in Python need; to be exported.; This is the default behavior on Mac and Linux, but not on Windows.; On that platform, use ``__declspec(dllexport)`` to explicitly export the; classes and function you expect to call.; CMake has simple `support for exporting all`_ C++ symbols. Python packaging; ----------------. Modern Python packaging usage is based on the 'wheel'. This is places the onus; on the creation of binary artifacts in the package on the distributor. In this; case, this includes the platform-dependent steps necessary to compile the .cpp; file. The generated package also takes advantage of the __init__.py load-time; mechanism to enhance the bindings:. * The bindings are rehosted in a ""native"" namespace so that C++ code from; KF5::Config appears in Python via ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst:4725,Testability,test,test,4725,"ompiler target. In addition ancillary files; are also generated to allow a complete set of bindings to be compiled,; packaged and installed::. cppyy_add_bindings(; pkg; pkg_version; author; author_email; [URL url]; [LICENSE license]; [LANGUAGE_STANDARD std]; [LINKDEFS linkdef...]; [IMPORTS pcm...]; [GENERATE_OPTIONS option...]; [COMPILE_OPTIONS option...]; [INCLUDE_DIRS dir...]; [LINK_LIBRARIES library...]; [H_DIRS H_DIRSectory]; H_FILES h_file...). The bindings are based on https://cppyy.readthedocs.io/en/latest/, and can be; used as per the documentation provided via the cppyy.gbl namespace. First add; the directory of the <pkg>.rootmap file to the LD_LIBRARY_PATH environment; variable, then ""import cppyy; from cppyy.gbl import <some-C++-entity>"". Alternatively, use ""import <pkg>"". This convenience wrapper supports; ""discovery"" of the available C++ entities using, for example Python 3's command; line completion support. The bindings are complete with a setup.py, supporting Wheel-based; packaging, and a test.py supporting pytest/nosetest sanity test of the bindings. The bindings are generated/built/packaged using 3 environments:. - One compatible with the header files being bound. This is used to; generate the generic C++ binding code (and some ancillary files) using; a modified C++ compiler. The needed options must be compatible with the; normal build environment of the header files.; - One to compile the generated, generic C++ binding code using a standard; C++ compiler. The resulting library code is ""universal"" in that it is; compatible with both Python2 and Python3.; - One to package the library and ancillary files into standard Python2/3; wheel format. The packaging is done using native Python tooling. +----------------------+---------------------------------------------------------------------------------------------+; |Arguments and options | Description |; +======================+==============================================================================",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst:4767,Testability,test,test,4767,"generated to allow a complete set of bindings to be compiled,; packaged and installed::. cppyy_add_bindings(; pkg; pkg_version; author; author_email; [URL url]; [LICENSE license]; [LANGUAGE_STANDARD std]; [LINKDEFS linkdef...]; [IMPORTS pcm...]; [GENERATE_OPTIONS option...]; [COMPILE_OPTIONS option...]; [INCLUDE_DIRS dir...]; [LINK_LIBRARIES library...]; [H_DIRS H_DIRSectory]; H_FILES h_file...). The bindings are based on https://cppyy.readthedocs.io/en/latest/, and can be; used as per the documentation provided via the cppyy.gbl namespace. First add; the directory of the <pkg>.rootmap file to the LD_LIBRARY_PATH environment; variable, then ""import cppyy; from cppyy.gbl import <some-C++-entity>"". Alternatively, use ""import <pkg>"". This convenience wrapper supports; ""discovery"" of the available C++ entities using, for example Python 3's command; line completion support. The bindings are complete with a setup.py, supporting Wheel-based; packaging, and a test.py supporting pytest/nosetest sanity test of the bindings. The bindings are generated/built/packaged using 3 environments:. - One compatible with the header files being bound. This is used to; generate the generic C++ binding code (and some ancillary files) using; a modified C++ compiler. The needed options must be compatible with the; normal build environment of the header files.; - One to compile the generated, generic C++ binding code using a standard; C++ compiler. The resulting library code is ""universal"" in that it is; compatible with both Python2 and Python3.; - One to package the library and ancillary files into standard Python2/3; wheel format. The packaging is done using native Python tooling. +----------------------+---------------------------------------------------------------------------------------------+; |Arguments and options | Description |; +======================+=============================================================================================+; |pkg | The name of the package to ge",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst:1571,Usability,simpl,simple,1571,"in; Python via ""import KF5.Config"".; * The bindings are loaded lazily, which limits the discoverability of the; content of the bindings.; * ``cppyy`` supports customization of the bindings via 'Pythonization' but; there is no automated way to load them. These issues are addressed by the CMake support. This is a blend of Python; packaging and CMake where CMake provides:. * Platform-independent scripting of the creation of a Python 'wheel' package; for the bindings.; * An facility for CMake-based projects to automate the entire bindings; generation process, including basic automated tests. .. note::. The JIT needs to resolve linker symbols in order to call them through; generated wrappers.; Thus, any classes, functions, and data that will be used in Python need; to be exported.; This is the default behavior on Mac and Linux, but not on Windows.; On that platform, use ``__declspec(dllexport)`` to explicitly export the; classes and function you expect to call.; CMake has simple `support for exporting all`_ C++ symbols. Python packaging; ----------------. Modern Python packaging usage is based on the 'wheel'. This is places the onus; on the creation of binary artifacts in the package on the distributor. In this; case, this includes the platform-dependent steps necessary to compile the .cpp; file. The generated package also takes advantage of the __init__.py load-time; mechanism to enhance the bindings:. * The bindings are rehosted in a ""native"" namespace so that C++ code from; KF5::Config appears in Python via ""import KF5.Config"".; * (TBD) Load Pythonizations. Both of these need/can use the output of the; :ref:`cppyy-generator <cppyy-generator>` (included in the package) as well as; other runtime support included in ``cppyy``. CMake usage; -----------. The CMake usage is via two modules:. * FindLibClang.cmake provides some bootstrap support needed to locate clang.; This is provided mostly as a temporary measure; hopefully upstream support; will allow this to be eliminate",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst:5806,Usability,simpl,simplename,5806,"bindings are generated/built/packaged using 3 environments:. - One compatible with the header files being bound. This is used to; generate the generic C++ binding code (and some ancillary files) using; a modified C++ compiler. The needed options must be compatible with the; normal build environment of the header files.; - One to compile the generated, generic C++ binding code using a standard; C++ compiler. The resulting library code is ""universal"" in that it is; compatible with both Python2 and Python3.; - One to package the library and ancillary files into standard Python2/3; wheel format. The packaging is done using native Python tooling. +----------------------+---------------------------------------------------------------------------------------------+; |Arguments and options | Description |; +======================+=============================================================================================+; |pkg | The name of the package to generate. This can be either |; | | of the form ""simplename"" (e.g. ""Akonadi""), or of the |; | | form ""namespace.simplename"" (e.g. ""KF5.Akonadi""). |; +----------------------+---------------------------------------------------------------------------------------------+; |pkg_version | The version of the package. |; +----------------------+---------------------------------------------------------------------------------------------+; |author | The name of the library author. |; +----------------------+---------------------------------------------------------------------------------------------+; |author_email | The email address of the library author. |; +----------------------+---------------------------------------------------------------------------------------------+; |URL url | The home page for the library. Default is |; | | ""https://pypi.python.org/pypi/<pkg>"". |; +----------------------+---------------------------------------------------------------------------------------------+; |LICENSE license | The license, defa",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst:5869,Usability,simpl,simplename,5869,"the header files being bound. This is used to; generate the generic C++ binding code (and some ancillary files) using; a modified C++ compiler. The needed options must be compatible with the; normal build environment of the header files.; - One to compile the generated, generic C++ binding code using a standard; C++ compiler. The resulting library code is ""universal"" in that it is; compatible with both Python2 and Python3.; - One to package the library and ancillary files into standard Python2/3; wheel format. The packaging is done using native Python tooling. +----------------------+---------------------------------------------------------------------------------------------+; |Arguments and options | Description |; +======================+=============================================================================================+; |pkg | The name of the package to generate. This can be either |; | | of the form ""simplename"" (e.g. ""Akonadi""), or of the |; | | form ""namespace.simplename"" (e.g. ""KF5.Akonadi""). |; +----------------------+---------------------------------------------------------------------------------------------+; |pkg_version | The version of the package. |; +----------------------+---------------------------------------------------------------------------------------------+; |author | The name of the library author. |; +----------------------+---------------------------------------------------------------------------------------------+; |author_email | The email address of the library author. |; +----------------------+---------------------------------------------------------------------------------------------+; |URL url | The home page for the library. Default is |; | | ""https://pypi.python.org/pypi/<pkg>"". |; +----------------------+---------------------------------------------------------------------------------------------+; |LICENSE license | The license, default is ""LGPL 2.0"". |; +----------------------+-------------------------------------",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst:7808,Usability,guid,guides,7808,"----------------------+---------------------------------------------------------------------------------------------+; |LANGUAGE_STANDARD std | The version of C++ in use, ""14"" by default. |; +----------------------+---------------------------------------------------------------------------------------------+; |IMPORTS pcm | Files which contain previously-generated bindings |; | | which pkg depends on. |; +----------------------+---------------------------------------------------------------------------------------------+; |GENERATE_OPTIONS optio| Options which are to be passed into the rootcling |; | | command. For example, bindings which depend on Qt |; | | may need ""-D__PIC__;-Wno-macro-redefined"". |; +----------------------+---------------------------------------------------------------------------------------------+; |LINKDEFS def | Files or lines which contain extra #pragma content |; | | for the linkdef.h file used by rootcling. See |; | | https://root.cern.ch/root/html/guides/users-guide/AddingaClass.html#the-linkdef.h-file. |; | | |; | | In lines, literal semi-colons must be escaped: ""\;"". |; +----------------------+---------------------------------------------------------------------------------------------+; |EXTRA_CODES code | Files which contain extra code needed by the bindings. |; | | Customization is by routines named ""c13n_<something>""; |; | | each such routine is passed the module for <pkg>: |; | | |; | | :: code-block python |; | | |; | | def c13n_doit(pkg_module): |; | | print(pkg_module.__dict__) |; | | |; | | The files and individual routines within files are |; | | processed in alphabetical order. |; +----------------------+---------------------------------------------------------------------------------------------+; |EXTRA_HEADERS hdr | Files which contain extra headers needed by the bindings. |; +----------------------+---------------------------------------------------------------------------------------------+; |EXTRA_PYTHONS py | Files whi",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst:7821,Usability,guid,guide,7821,"----------------------+---------------------------------------------------------------------------------------------+; |LANGUAGE_STANDARD std | The version of C++ in use, ""14"" by default. |; +----------------------+---------------------------------------------------------------------------------------------+; |IMPORTS pcm | Files which contain previously-generated bindings |; | | which pkg depends on. |; +----------------------+---------------------------------------------------------------------------------------------+; |GENERATE_OPTIONS optio| Options which are to be passed into the rootcling |; | | command. For example, bindings which depend on Qt |; | | may need ""-D__PIC__;-Wno-macro-redefined"". |; +----------------------+---------------------------------------------------------------------------------------------+; |LINKDEFS def | Files or lines which contain extra #pragma content |; | | for the linkdef.h file used by rootcling. See |; | | https://root.cern.ch/root/html/guides/users-guide/AddingaClass.html#the-linkdef.h-file. |; | | |; | | In lines, literal semi-colons must be escaped: ""\;"". |; +----------------------+---------------------------------------------------------------------------------------------+; |EXTRA_CODES code | Files which contain extra code needed by the bindings. |; | | Customization is by routines named ""c13n_<something>""; |; | | each such routine is passed the module for <pkg>: |; | | |; | | :: code-block python |; | | |; | | def c13n_doit(pkg_module): |; | | print(pkg_module.__dict__) |; | | |; | | The files and individual routines within files are |; | | processed in alphabetical order. |; +----------------------+---------------------------------------------------------------------------------------------+; |EXTRA_HEADERS hdr | Files which contain extra headers needed by the bindings. |; +----------------------+---------------------------------------------------------------------------------------------+; |EXTRA_PYTHONS py | Files whi",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cmake_interface.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cuda.rst:90,Availability,avail,available,90,".. _cuda:. CUDA support; ============. .. warning::. This is an **experimental** feature, available starting with release; 2.3.0.; It is still incomplete and has only been tested on Linux on x86_64. CUDA is supported by passing all JITed code through two pipelines: one for the; CPU and one for the GPU.; Use of the ``__CUDA__`` pre-processor macro enables more fine-grained control; over which pipeline sees what, which is used e.g. in the pre-compiled header:; the GPU pipeline has the CUDA headers included, the CPU pipeline does not.; Building the pre-compiled header will also pick up common CUDA libraries such; as cuBLAS, if installed. Each version of CUDA requires specific versions of Clang and the system; compiler (e.g. gcc) for proper functioning; it's therefore best to build the; backend (``cppyy-cling``) from source for the specific combination of; interest.; The 3.x series of cppyy uses Clang13, the 2.x series Clang9, and this may; limit the CUDA versions supported (especially since CUDA has changed the APIs; for launching kernels in v11). There are three environment variables to control Cling's handling of CUDA:. * ``CLING_ENABLE_CUDA`` (required): set to ``1`` to enable the CUDA; backend. * ``CLING_CUDA_PATH`` (optional): set to the local CUDA installation if not; in a standard location. * ``CLING_CUDA_ARCH`` (optional): set the architecture to target; default is; ``sm_35`` (Clang9 is limited to ``sm_75``). After enabling CUDA with ``CLING_ENABLE_CUDA=1`` CUDA code can be used and; kernels can be launched from JITed code by in ``cppyy.cppdef()``.; There is currently no syntax or helpers yet to launch kernels from Python.; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/cuda.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cuda.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cuda.rst:114,Deployability,release,release,114,".. _cuda:. CUDA support; ============. .. warning::. This is an **experimental** feature, available starting with release; 2.3.0.; It is still incomplete and has only been tested on Linux on x86_64. CUDA is supported by passing all JITed code through two pipelines: one for the; CPU and one for the GPU.; Use of the ``__CUDA__`` pre-processor macro enables more fine-grained control; over which pipeline sees what, which is used e.g. in the pre-compiled header:; the GPU pipeline has the CUDA headers included, the CPU pipeline does not.; Building the pre-compiled header will also pick up common CUDA libraries such; as cuBLAS, if installed. Each version of CUDA requires specific versions of Clang and the system; compiler (e.g. gcc) for proper functioning; it's therefore best to build the; backend (``cppyy-cling``) from source for the specific combination of; interest.; The 3.x series of cppyy uses Clang13, the 2.x series Clang9, and this may; limit the CUDA versions supported (especially since CUDA has changed the APIs; for launching kernels in v11). There are three environment variables to control Cling's handling of CUDA:. * ``CLING_ENABLE_CUDA`` (required): set to ``1`` to enable the CUDA; backend. * ``CLING_CUDA_PATH`` (optional): set to the local CUDA installation if not; in a standard location. * ``CLING_CUDA_ARCH`` (optional): set the architecture to target; default is; ``sm_35`` (Clang9 is limited to ``sm_75``). After enabling CUDA with ``CLING_ENABLE_CUDA=1`` CUDA code can be used and; kernels can be launched from JITed code by in ``cppyy.cppdef()``.; There is currently no syntax or helpers yet to launch kernels from Python.; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/cuda.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cuda.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cuda.rst:255,Deployability,pipeline,pipelines,255,".. _cuda:. CUDA support; ============. .. warning::. This is an **experimental** feature, available starting with release; 2.3.0.; It is still incomplete and has only been tested on Linux on x86_64. CUDA is supported by passing all JITed code through two pipelines: one for the; CPU and one for the GPU.; Use of the ``__CUDA__`` pre-processor macro enables more fine-grained control; over which pipeline sees what, which is used e.g. in the pre-compiled header:; the GPU pipeline has the CUDA headers included, the CPU pipeline does not.; Building the pre-compiled header will also pick up common CUDA libraries such; as cuBLAS, if installed. Each version of CUDA requires specific versions of Clang and the system; compiler (e.g. gcc) for proper functioning; it's therefore best to build the; backend (``cppyy-cling``) from source for the specific combination of; interest.; The 3.x series of cppyy uses Clang13, the 2.x series Clang9, and this may; limit the CUDA versions supported (especially since CUDA has changed the APIs; for launching kernels in v11). There are three environment variables to control Cling's handling of CUDA:. * ``CLING_ENABLE_CUDA`` (required): set to ``1`` to enable the CUDA; backend. * ``CLING_CUDA_PATH`` (optional): set to the local CUDA installation if not; in a standard location. * ``CLING_CUDA_ARCH`` (optional): set the architecture to target; default is; ``sm_35`` (Clang9 is limited to ``sm_75``). After enabling CUDA with ``CLING_ENABLE_CUDA=1`` CUDA code can be used and; kernels can be launched from JITed code by in ``cppyy.cppdef()``.; There is currently no syntax or helpers yet to launch kernels from Python.; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/cuda.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cuda.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cuda.rst:395,Deployability,pipeline,pipeline,395,".. _cuda:. CUDA support; ============. .. warning::. This is an **experimental** feature, available starting with release; 2.3.0.; It is still incomplete and has only been tested on Linux on x86_64. CUDA is supported by passing all JITed code through two pipelines: one for the; CPU and one for the GPU.; Use of the ``__CUDA__`` pre-processor macro enables more fine-grained control; over which pipeline sees what, which is used e.g. in the pre-compiled header:; the GPU pipeline has the CUDA headers included, the CPU pipeline does not.; Building the pre-compiled header will also pick up common CUDA libraries such; as cuBLAS, if installed. Each version of CUDA requires specific versions of Clang and the system; compiler (e.g. gcc) for proper functioning; it's therefore best to build the; backend (``cppyy-cling``) from source for the specific combination of; interest.; The 3.x series of cppyy uses Clang13, the 2.x series Clang9, and this may; limit the CUDA versions supported (especially since CUDA has changed the APIs; for launching kernels in v11). There are three environment variables to control Cling's handling of CUDA:. * ``CLING_ENABLE_CUDA`` (required): set to ``1`` to enable the CUDA; backend. * ``CLING_CUDA_PATH`` (optional): set to the local CUDA installation if not; in a standard location. * ``CLING_CUDA_ARCH`` (optional): set the architecture to target; default is; ``sm_35`` (Clang9 is limited to ``sm_75``). After enabling CUDA with ``CLING_ENABLE_CUDA=1`` CUDA code can be used and; kernels can be launched from JITed code by in ``cppyy.cppdef()``.; There is currently no syntax or helpers yet to launch kernels from Python.; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/cuda.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cuda.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cuda.rst:471,Deployability,pipeline,pipeline,471,".. _cuda:. CUDA support; ============. .. warning::. This is an **experimental** feature, available starting with release; 2.3.0.; It is still incomplete and has only been tested on Linux on x86_64. CUDA is supported by passing all JITed code through two pipelines: one for the; CPU and one for the GPU.; Use of the ``__CUDA__`` pre-processor macro enables more fine-grained control; over which pipeline sees what, which is used e.g. in the pre-compiled header:; the GPU pipeline has the CUDA headers included, the CPU pipeline does not.; Building the pre-compiled header will also pick up common CUDA libraries such; as cuBLAS, if installed. Each version of CUDA requires specific versions of Clang and the system; compiler (e.g. gcc) for proper functioning; it's therefore best to build the; backend (``cppyy-cling``) from source for the specific combination of; interest.; The 3.x series of cppyy uses Clang13, the 2.x series Clang9, and this may; limit the CUDA versions supported (especially since CUDA has changed the APIs; for launching kernels in v11). There are three environment variables to control Cling's handling of CUDA:. * ``CLING_ENABLE_CUDA`` (required): set to ``1`` to enable the CUDA; backend. * ``CLING_CUDA_PATH`` (optional): set to the local CUDA installation if not; in a standard location. * ``CLING_CUDA_ARCH`` (optional): set the architecture to target; default is; ``sm_35`` (Clang9 is limited to ``sm_75``). After enabling CUDA with ``CLING_ENABLE_CUDA=1`` CUDA code can be used and; kernels can be launched from JITed code by in ``cppyy.cppdef()``.; There is currently no syntax or helpers yet to launch kernels from Python.; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/cuda.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cuda.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cuda.rst:519,Deployability,pipeline,pipeline,519,".. _cuda:. CUDA support; ============. .. warning::. This is an **experimental** feature, available starting with release; 2.3.0.; It is still incomplete and has only been tested on Linux on x86_64. CUDA is supported by passing all JITed code through two pipelines: one for the; CPU and one for the GPU.; Use of the ``__CUDA__`` pre-processor macro enables more fine-grained control; over which pipeline sees what, which is used e.g. in the pre-compiled header:; the GPU pipeline has the CUDA headers included, the CPU pipeline does not.; Building the pre-compiled header will also pick up common CUDA libraries such; as cuBLAS, if installed. Each version of CUDA requires specific versions of Clang and the system; compiler (e.g. gcc) for proper functioning; it's therefore best to build the; backend (``cppyy-cling``) from source for the specific combination of; interest.; The 3.x series of cppyy uses Clang13, the 2.x series Clang9, and this may; limit the CUDA versions supported (especially since CUDA has changed the APIs; for launching kernels in v11). There are three environment variables to control Cling's handling of CUDA:. * ``CLING_ENABLE_CUDA`` (required): set to ``1`` to enable the CUDA; backend. * ``CLING_CUDA_PATH`` (optional): set to the local CUDA installation if not; in a standard location. * ``CLING_CUDA_ARCH`` (optional): set the architecture to target; default is; ``sm_35`` (Clang9 is limited to ``sm_75``). After enabling CUDA with ``CLING_ENABLE_CUDA=1`` CUDA code can be used and; kernels can be launched from JITed code by in ``cppyy.cppdef()``.; There is currently no syntax or helpers yet to launch kernels from Python.; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/cuda.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cuda.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cuda.rst:632,Deployability,install,installed,632,".. _cuda:. CUDA support; ============. .. warning::. This is an **experimental** feature, available starting with release; 2.3.0.; It is still incomplete and has only been tested on Linux on x86_64. CUDA is supported by passing all JITed code through two pipelines: one for the; CPU and one for the GPU.; Use of the ``__CUDA__`` pre-processor macro enables more fine-grained control; over which pipeline sees what, which is used e.g. in the pre-compiled header:; the GPU pipeline has the CUDA headers included, the CPU pipeline does not.; Building the pre-compiled header will also pick up common CUDA libraries such; as cuBLAS, if installed. Each version of CUDA requires specific versions of Clang and the system; compiler (e.g. gcc) for proper functioning; it's therefore best to build the; backend (``cppyy-cling``) from source for the specific combination of; interest.; The 3.x series of cppyy uses Clang13, the 2.x series Clang9, and this may; limit the CUDA versions supported (especially since CUDA has changed the APIs; for launching kernels in v11). There are three environment variables to control Cling's handling of CUDA:. * ``CLING_ENABLE_CUDA`` (required): set to ``1`` to enable the CUDA; backend. * ``CLING_CUDA_PATH`` (optional): set to the local CUDA installation if not; in a standard location. * ``CLING_CUDA_ARCH`` (optional): set the architecture to target; default is; ``sm_35`` (Clang9 is limited to ``sm_75``). After enabling CUDA with ``CLING_ENABLE_CUDA=1`` CUDA code can be used and; kernels can be launched from JITed code by in ``cppyy.cppdef()``.; There is currently no syntax or helpers yet to launch kernels from Python.; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/cuda.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cuda.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cuda.rst:1271,Deployability,install,installation,1271,".. _cuda:. CUDA support; ============. .. warning::. This is an **experimental** feature, available starting with release; 2.3.0.; It is still incomplete and has only been tested on Linux on x86_64. CUDA is supported by passing all JITed code through two pipelines: one for the; CPU and one for the GPU.; Use of the ``__CUDA__`` pre-processor macro enables more fine-grained control; over which pipeline sees what, which is used e.g. in the pre-compiled header:; the GPU pipeline has the CUDA headers included, the CPU pipeline does not.; Building the pre-compiled header will also pick up common CUDA libraries such; as cuBLAS, if installed. Each version of CUDA requires specific versions of Clang and the system; compiler (e.g. gcc) for proper functioning; it's therefore best to build the; backend (``cppyy-cling``) from source for the specific combination of; interest.; The 3.x series of cppyy uses Clang13, the 2.x series Clang9, and this may; limit the CUDA versions supported (especially since CUDA has changed the APIs; for launching kernels in v11). There are three environment variables to control Cling's handling of CUDA:. * ``CLING_ENABLE_CUDA`` (required): set to ``1`` to enable the CUDA; backend. * ``CLING_CUDA_PATH`` (optional): set to the local CUDA installation if not; in a standard location. * ``CLING_CUDA_ARCH`` (optional): set the architecture to target; default is; ``sm_35`` (Clang9 is limited to ``sm_75``). After enabling CUDA with ``CLING_ENABLE_CUDA=1`` CUDA code can be used and; kernels can be launched from JITed code by in ``cppyy.cppdef()``.; There is currently no syntax or helpers yet to launch kernels from Python.; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/cuda.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cuda.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cuda.rst:1089,Modifiability,variab,variables,1089,".. _cuda:. CUDA support; ============. .. warning::. This is an **experimental** feature, available starting with release; 2.3.0.; It is still incomplete and has only been tested on Linux on x86_64. CUDA is supported by passing all JITed code through two pipelines: one for the; CPU and one for the GPU.; Use of the ``__CUDA__`` pre-processor macro enables more fine-grained control; over which pipeline sees what, which is used e.g. in the pre-compiled header:; the GPU pipeline has the CUDA headers included, the CPU pipeline does not.; Building the pre-compiled header will also pick up common CUDA libraries such; as cuBLAS, if installed. Each version of CUDA requires specific versions of Clang and the system; compiler (e.g. gcc) for proper functioning; it's therefore best to build the; backend (``cppyy-cling``) from source for the specific combination of; interest.; The 3.x series of cppyy uses Clang13, the 2.x series Clang9, and this may; limit the CUDA versions supported (especially since CUDA has changed the APIs; for launching kernels in v11). There are three environment variables to control Cling's handling of CUDA:. * ``CLING_ENABLE_CUDA`` (required): set to ``1`` to enable the CUDA; backend. * ``CLING_CUDA_PATH`` (optional): set to the local CUDA installation if not; in a standard location. * ``CLING_CUDA_ARCH`` (optional): set the architecture to target; default is; ``sm_35`` (Clang9 is limited to ``sm_75``). After enabling CUDA with ``CLING_ENABLE_CUDA=1`` CUDA code can be used and; kernels can be launched from JITed code by in ``cppyy.cppdef()``.; There is currently no syntax or helpers yet to launch kernels from Python.; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/cuda.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cuda.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cuda.rst:172,Testability,test,tested,172,".. _cuda:. CUDA support; ============. .. warning::. This is an **experimental** feature, available starting with release; 2.3.0.; It is still incomplete and has only been tested on Linux on x86_64. CUDA is supported by passing all JITed code through two pipelines: one for the; CPU and one for the GPU.; Use of the ``__CUDA__`` pre-processor macro enables more fine-grained control; over which pipeline sees what, which is used e.g. in the pre-compiled header:; the GPU pipeline has the CUDA headers included, the CPU pipeline does not.; Building the pre-compiled header will also pick up common CUDA libraries such; as cuBLAS, if installed. Each version of CUDA requires specific versions of Clang and the system; compiler (e.g. gcc) for proper functioning; it's therefore best to build the; backend (``cppyy-cling``) from source for the specific combination of; interest.; The 3.x series of cppyy uses Clang13, the 2.x series Clang9, and this may; limit the CUDA versions supported (especially since CUDA has changed the APIs; for launching kernels in v11). There are three environment variables to control Cling's handling of CUDA:. * ``CLING_ENABLE_CUDA`` (required): set to ``1`` to enable the CUDA; backend. * ``CLING_CUDA_PATH`` (optional): set to the local CUDA installation if not; in a standard location. * ``CLING_CUDA_ARCH`` (optional): set the architecture to target; default is; ``sm_35`` (Clang9 is limited to ``sm_75``). After enabling CUDA with ``CLING_ENABLE_CUDA=1`` CUDA code can be used and; kernels can be launched from JITed code by in ``cppyy.cppdef()``.; There is currently no syntax or helpers yet to launch kernels from Python.; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/cuda.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/cuda.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/debugging.rst:183,Availability,reliab,reliable,183,".. _debugging:; ; Debugging; =========. By default, the ``clang`` JIT as used by cppyy does not generate debugging; information.; This is first of all because it has proven to be not reliable in all cases,; but also because in a production setting this information, being internal to; the wrapper generation, goes unused.; However, that does mean that a debugger that starts from python will not be; able to step through JITed code into the C++ function that needs debugging,; even when such information is available for that C++ function. To enable debugging information in JITed code, set the ``EXTRA_CLING_ARGS``; envar to ``-g`` (and any further compiler options you need, e.g. add ``-O2``; to debug optimized code). On a crash in C++, the backend will attempt to provide a stack trace.; This works quite well on Linux (through ``gdb``) and decently on MacOS; (through ``unwind``), but is currently unreliable on MS Windows.; To prevent printing of this trace, which can be slow to produce, set the; envar ``CPPYY_CRASH_QUIET`` to '1'. It is even more useful to obtain a traceback through the Python code that led; up to the problem in C++.; Many modern debuggers allow mixed-mode C++/Python debugging (for example; `gdb`_ and `MSVC`_), but cppyy can also turn abortive C++ signals (such as a; segmentation violation) into Python exceptions, yielding a normal traceback.; This is particularly useful when working with cross-inheritance and other; cross-language callbacks. To enable the signals to exceptions conversion, import the lowlevel module; ``cppyy.ll`` and use:. .. code-block:: python. import cppyy.ll; cppyy.ll.set_signals_as_exception(True). Call ``set_signals_as_exception(False)`` to disable the conversion again.; It is recommended to only have the conversion enabled around the problematic; code, as it comes with a performance penalty.; If the problem can be localized to a specific function, you can use its; ``__sig2exc__`` flag to only have the conversion active in that functi",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/debugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/debugging.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/debugging.rst:507,Availability,avail,available,507,".. _debugging:; ; Debugging; =========. By default, the ``clang`` JIT as used by cppyy does not generate debugging; information.; This is first of all because it has proven to be not reliable in all cases,; but also because in a production setting this information, being internal to; the wrapper generation, goes unused.; However, that does mean that a debugger that starts from python will not be; able to step through JITed code into the C++ function that needs debugging,; even when such information is available for that C++ function. To enable debugging information in JITed code, set the ``EXTRA_CLING_ARGS``; envar to ``-g`` (and any further compiler options you need, e.g. add ``-O2``; to debug optimized code). On a crash in C++, the backend will attempt to provide a stack trace.; This works quite well on Linux (through ``gdb``) and decently on MacOS; (through ``unwind``), but is currently unreliable on MS Windows.; To prevent printing of this trace, which can be slow to produce, set the; envar ``CPPYY_CRASH_QUIET`` to '1'. It is even more useful to obtain a traceback through the Python code that led; up to the problem in C++.; Many modern debuggers allow mixed-mode C++/Python debugging (for example; `gdb`_ and `MSVC`_), but cppyy can also turn abortive C++ signals (such as a; segmentation violation) into Python exceptions, yielding a normal traceback.; This is particularly useful when working with cross-inheritance and other; cross-language callbacks. To enable the signals to exceptions conversion, import the lowlevel module; ``cppyy.ll`` and use:. .. code-block:: python. import cppyy.ll; cppyy.ll.set_signals_as_exception(True). Call ``set_signals_as_exception(False)`` to disable the conversion again.; It is recommended to only have the conversion enabled around the problematic; code, as it comes with a performance penalty.; If the problem can be localized to a specific function, you can use its; ``__sig2exc__`` flag to only have the conversion active in that functi",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/debugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/debugging.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/debugging.rst:289,Integrability,wrap,wrapper,289,".. _debugging:; ; Debugging; =========. By default, the ``clang`` JIT as used by cppyy does not generate debugging; information.; This is first of all because it has proven to be not reliable in all cases,; but also because in a production setting this information, being internal to; the wrapper generation, goes unused.; However, that does mean that a debugger that starts from python will not be; able to step through JITed code into the C++ function that needs debugging,; even when such information is available for that C++ function. To enable debugging information in JITed code, set the ``EXTRA_CLING_ARGS``; envar to ``-g`` (and any further compiler options you need, e.g. add ``-O2``; to debug optimized code). On a crash in C++, the backend will attempt to provide a stack trace.; This works quite well on Linux (through ``gdb``) and decently on MacOS; (through ``unwind``), but is currently unreliable on MS Windows.; To prevent printing of this trace, which can be slow to produce, set the; envar ``CPPYY_CRASH_QUIET`` to '1'. It is even more useful to obtain a traceback through the Python code that led; up to the problem in C++.; Many modern debuggers allow mixed-mode C++/Python debugging (for example; `gdb`_ and `MSVC`_), but cppyy can also turn abortive C++ signals (such as a; segmentation violation) into Python exceptions, yielding a normal traceback.; This is particularly useful when working with cross-inheritance and other; cross-language callbacks. To enable the signals to exceptions conversion, import the lowlevel module; ``cppyy.ll`` and use:. .. code-block:: python. import cppyy.ll; cppyy.ll.set_signals_as_exception(True). Call ``set_signals_as_exception(False)`` to disable the conversion again.; It is recommended to only have the conversion enabled around the problematic; code, as it comes with a performance penalty.; If the problem can be localized to a specific function, you can use its; ``__sig2exc__`` flag to only have the conversion active in that functi",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/debugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/debugging.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/debugging.rst:1428,Modifiability,inherit,inheritance,1428,"d code into the C++ function that needs debugging,; even when such information is available for that C++ function. To enable debugging information in JITed code, set the ``EXTRA_CLING_ARGS``; envar to ``-g`` (and any further compiler options you need, e.g. add ``-O2``; to debug optimized code). On a crash in C++, the backend will attempt to provide a stack trace.; This works quite well on Linux (through ``gdb``) and decently on MacOS; (through ``unwind``), but is currently unreliable on MS Windows.; To prevent printing of this trace, which can be slow to produce, set the; envar ``CPPYY_CRASH_QUIET`` to '1'. It is even more useful to obtain a traceback through the Python code that led; up to the problem in C++.; Many modern debuggers allow mixed-mode C++/Python debugging (for example; `gdb`_ and `MSVC`_), but cppyy can also turn abortive C++ signals (such as a; segmentation violation) into Python exceptions, yielding a normal traceback.; This is particularly useful when working with cross-inheritance and other; cross-language callbacks. To enable the signals to exceptions conversion, import the lowlevel module; ``cppyy.ll`` and use:. .. code-block:: python. import cppyy.ll; cppyy.ll.set_signals_as_exception(True). Call ``set_signals_as_exception(False)`` to disable the conversion again.; It is recommended to only have the conversion enabled around the problematic; code, as it comes with a performance penalty.; If the problem can be localized to a specific function, you can use its; ``__sig2exc__`` flag to only have the conversion active in that function.; Finally, for convenient scoping, you can also use:. .. code-block:: python. with cppyy.ll.signals_as_exception():; # crashing code goes here. The translation of signals to exceptions is as follows (all of the exceptions; are subclasses of ``cppyy.ll.FatalError``):. ======================================== ========================================; C++ signal Python exception; ======================================== ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/debugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/debugging.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/debugging.rst:2758,Modifiability,inherit,inheritance,2758,"ound the problematic; code, as it comes with a performance penalty.; If the problem can be localized to a specific function, you can use its; ``__sig2exc__`` flag to only have the conversion active in that function.; Finally, for convenient scoping, you can also use:. .. code-block:: python. with cppyy.ll.signals_as_exception():; # crashing code goes here. The translation of signals to exceptions is as follows (all of the exceptions; are subclasses of ``cppyy.ll.FatalError``):. ======================================== ========================================; C++ signal Python exception; ======================================== ========================================; ``SIGSEGV`` ``cppyy.ll.SegmentationViolation``; ``SIGBUS`` ``cppyy.ll.BusError``; ``SIGABRT`` ``cppyy.ll.AbortSignal``; ``SIGILL`` ``cppyy.ll.IllegalInstruction``; ======================================== ========================================. As an example, consider the following cross-inheritance code that crashes; with a segmentation violation in C++, because a ``nullptr`` is dereferenced:. .. code-block:: python. import cppyy; import cppyy.ll. cppyy.cppdef(""""""; class Base {; public:; virtual ~Base() {}; virtual int runit() = 0;; };. int callback(Base* b) {; return b->runit();; }. void segfault(int* i) { *i = 42; }; """"""). class Derived(cppyy.gbl.Base):; def runit(self):; print(""Hi, from Python!""); cppyy.gbl.segfault(cppyy.nullptr). If now used with ``signals_as_exception``, e.g. like so:. .. code-block:: python. d = Derived(); with cppyy.ll.signals_as_exception():; cppyy.gbl.callback(d). it produces the following, very informative, Python-side trace::. Traceback (most recent call last):; File ""crashit.py"", line 25, in <module>; cppyy.gbl.callback(d); cppyy.ll.SegmentationViolation: int ::callback(Base* b) =>; SegmentationViolation: void ::segfault(int* i) =>; SegmentationViolation: segfault in C++; program state was reset. whereas without, there would be no Python-side information at all. .. _`gd",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/debugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/debugging.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/debugging.rst:704,Performance,optimiz,optimized,704,".. _debugging:; ; Debugging; =========. By default, the ``clang`` JIT as used by cppyy does not generate debugging; information.; This is first of all because it has proven to be not reliable in all cases,; but also because in a production setting this information, being internal to; the wrapper generation, goes unused.; However, that does mean that a debugger that starts from python will not be; able to step through JITed code into the C++ function that needs debugging,; even when such information is available for that C++ function. To enable debugging information in JITed code, set the ``EXTRA_CLING_ARGS``; envar to ``-g`` (and any further compiler options you need, e.g. add ``-O2``; to debug optimized code). On a crash in C++, the backend will attempt to provide a stack trace.; This works quite well on Linux (through ``gdb``) and decently on MacOS; (through ``unwind``), but is currently unreliable on MS Windows.; To prevent printing of this trace, which can be slow to produce, set the; envar ``CPPYY_CRASH_QUIET`` to '1'. It is even more useful to obtain a traceback through the Python code that led; up to the problem in C++.; Many modern debuggers allow mixed-mode C++/Python debugging (for example; `gdb`_ and `MSVC`_), but cppyy can also turn abortive C++ signals (such as a; segmentation violation) into Python exceptions, yielding a normal traceback.; This is particularly useful when working with cross-inheritance and other; cross-language callbacks. To enable the signals to exceptions conversion, import the lowlevel module; ``cppyy.ll`` and use:. .. code-block:: python. import cppyy.ll; cppyy.ll.set_signals_as_exception(True). Call ``set_signals_as_exception(False)`` to disable the conversion again.; It is recommended to only have the conversion enabled around the problematic; code, as it comes with a performance penalty.; If the problem can be localized to a specific function, you can use its; ``__sig2exc__`` flag to only have the conversion active in that functi",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/debugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/debugging.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/debugging.rst:1836,Performance,perform,performance,1836,"his works quite well on Linux (through ``gdb``) and decently on MacOS; (through ``unwind``), but is currently unreliable on MS Windows.; To prevent printing of this trace, which can be slow to produce, set the; envar ``CPPYY_CRASH_QUIET`` to '1'. It is even more useful to obtain a traceback through the Python code that led; up to the problem in C++.; Many modern debuggers allow mixed-mode C++/Python debugging (for example; `gdb`_ and `MSVC`_), but cppyy can also turn abortive C++ signals (such as a; segmentation violation) into Python exceptions, yielding a normal traceback.; This is particularly useful when working with cross-inheritance and other; cross-language callbacks. To enable the signals to exceptions conversion, import the lowlevel module; ``cppyy.ll`` and use:. .. code-block:: python. import cppyy.ll; cppyy.ll.set_signals_as_exception(True). Call ``set_signals_as_exception(False)`` to disable the conversion again.; It is recommended to only have the conversion enabled around the problematic; code, as it comes with a performance penalty.; If the problem can be localized to a specific function, you can use its; ``__sig2exc__`` flag to only have the conversion active in that function.; Finally, for convenient scoping, you can also use:. .. code-block:: python. with cppyy.ll.signals_as_exception():; # crashing code goes here. The translation of signals to exceptions is as follows (all of the exceptions; are subclasses of ``cppyy.ll.FatalError``):. ======================================== ========================================; C++ signal Python exception; ======================================== ========================================; ``SIGSEGV`` ``cppyy.ll.SegmentationViolation``; ``SIGBUS`` ``cppyy.ll.BusError``; ``SIGABRT`` ``cppyy.ll.AbortSignal``; ``SIGILL`` ``cppyy.ll.IllegalInstruction``; ======================================== ========================================. As an example, consider the following cross-inheritance code that crashes; with ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/debugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/debugging.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/debugging.rst:1265,Safety,abort,abortive,1265,"ation, being internal to; the wrapper generation, goes unused.; However, that does mean that a debugger that starts from python will not be; able to step through JITed code into the C++ function that needs debugging,; even when such information is available for that C++ function. To enable debugging information in JITed code, set the ``EXTRA_CLING_ARGS``; envar to ``-g`` (and any further compiler options you need, e.g. add ``-O2``; to debug optimized code). On a crash in C++, the backend will attempt to provide a stack trace.; This works quite well on Linux (through ``gdb``) and decently on MacOS; (through ``unwind``), but is currently unreliable on MS Windows.; To prevent printing of this trace, which can be slow to produce, set the; envar ``CPPYY_CRASH_QUIET`` to '1'. It is even more useful to obtain a traceback through the Python code that led; up to the problem in C++.; Many modern debuggers allow mixed-mode C++/Python debugging (for example; `gdb`_ and `MSVC`_), but cppyy can also turn abortive C++ signals (such as a; segmentation violation) into Python exceptions, yielding a normal traceback.; This is particularly useful when working with cross-inheritance and other; cross-language callbacks. To enable the signals to exceptions conversion, import the lowlevel module; ``cppyy.ll`` and use:. .. code-block:: python. import cppyy.ll; cppyy.ll.set_signals_as_exception(True). Call ``set_signals_as_exception(False)`` to disable the conversion again.; It is recommended to only have the conversion enabled around the problematic; code, as it comes with a performance penalty.; If the problem can be localized to a specific function, you can use its; ``__sig2exc__`` flag to only have the conversion active in that function.; Finally, for convenient scoping, you can also use:. .. code-block:: python. with cppyy.ll.signals_as_exception():; # crashing code goes here. The translation of signals to exceptions is as follows (all of the exceptions; are subclasses of ``cppyy.ll.Fat",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/debugging.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/debugging.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/exceptions.rst:2314,Availability,error,error,2314," onto standard Python; exceptions, since other than a few simple cases, the mapping is too crude to; be useful as the typical usage in each standard library is too different.; Thus, for example, a thrown ``std::runtime_error`` instance will become a; ``cppyy.gbl.std.runtime_error`` instance on the Python side (with Python's; ``Exception`` as its base class), not a ``RuntimeError`` instance. The C++ code used for the examples below can be found; :doc:`here <cppyy_features_header>`, and it is assumed that that code is; loaded at the start of any session.; Download it, save it under the name ``features.h``, and load it:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('features.h'); >>>. In addition, the examples require the ``throw`` to be in compiled code.; Save the following and build it into a shared library ``libfeatures.so`` (or; ``libfeatures.dll`` on MS Windows):. .. code-block:: C++. #include ""features.h"". void throw_an_error(int i) {; if (i) throw SomeError{""this is an error""};; throw SomeOtherError{""this is another error""};; }. And load the resulting library:. .. code-block:: python. >>> cppyy.load_library('libfeatures'); >>>. Then try it out:. .. code-block:: python. >>> cppyy.gbl.throw_an_error(1); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; cppyy.gbl.SomeError: void ::throw_an_error(int i) =>; SomeError: this is an error; >>> . Note how the full type is preserved and how the result of ``what()`` is used; for printing the exception.; By preserving the full C++ type, it is possible to call any other member; functions the exception may provide beyond ``what`` or access any additional; data it carries. To catch the exception, you can either use the full type, or any of its base; classes, including ``Exception`` and ``cppyy.gbl.std.exception``:. .. code-block:: python. >>> try:; ... cppyy.gbl.throw_an_error(0); ... except cppyy.gbl.SomeOtherError as e: # catch by exact type; ... print(""received:"", e); ... ; received: <c",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/exceptions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/exceptions.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/exceptions.rst:2362,Availability,error,error,2362," onto standard Python; exceptions, since other than a few simple cases, the mapping is too crude to; be useful as the typical usage in each standard library is too different.; Thus, for example, a thrown ``std::runtime_error`` instance will become a; ``cppyy.gbl.std.runtime_error`` instance on the Python side (with Python's; ``Exception`` as its base class), not a ``RuntimeError`` instance. The C++ code used for the examples below can be found; :doc:`here <cppyy_features_header>`, and it is assumed that that code is; loaded at the start of any session.; Download it, save it under the name ``features.h``, and load it:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('features.h'); >>>. In addition, the examples require the ``throw`` to be in compiled code.; Save the following and build it into a shared library ``libfeatures.so`` (or; ``libfeatures.dll`` on MS Windows):. .. code-block:: C++. #include ""features.h"". void throw_an_error(int i) {; if (i) throw SomeError{""this is an error""};; throw SomeOtherError{""this is another error""};; }. And load the resulting library:. .. code-block:: python. >>> cppyy.load_library('libfeatures'); >>>. Then try it out:. .. code-block:: python. >>> cppyy.gbl.throw_an_error(1); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; cppyy.gbl.SomeError: void ::throw_an_error(int i) =>; SomeError: this is an error; >>> . Note how the full type is preserved and how the result of ``what()`` is used; for printing the exception.; By preserving the full C++ type, it is possible to call any other member; functions the exception may provide beyond ``what`` or access any additional; data it carries. To catch the exception, you can either use the full type, or any of its base; classes, including ``Exception`` and ``cppyy.gbl.std.exception``:. .. code-block:: python. >>> try:; ... cppyy.gbl.throw_an_error(0); ... except cppyy.gbl.SomeOtherError as e: # catch by exact type; ... print(""received:"", e); ... ; received: <c",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/exceptions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/exceptions.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/exceptions.rst:2700,Availability,error,error,2700,"``cppyy.gbl.std.runtime_error`` instance on the Python side (with Python's; ``Exception`` as its base class), not a ``RuntimeError`` instance. The C++ code used for the examples below can be found; :doc:`here <cppyy_features_header>`, and it is assumed that that code is; loaded at the start of any session.; Download it, save it under the name ``features.h``, and load it:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('features.h'); >>>. In addition, the examples require the ``throw`` to be in compiled code.; Save the following and build it into a shared library ``libfeatures.so`` (or; ``libfeatures.dll`` on MS Windows):. .. code-block:: C++. #include ""features.h"". void throw_an_error(int i) {; if (i) throw SomeError{""this is an error""};; throw SomeOtherError{""this is another error""};; }. And load the resulting library:. .. code-block:: python. >>> cppyy.load_library('libfeatures'); >>>. Then try it out:. .. code-block:: python. >>> cppyy.gbl.throw_an_error(1); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; cppyy.gbl.SomeError: void ::throw_an_error(int i) =>; SomeError: this is an error; >>> . Note how the full type is preserved and how the result of ``what()`` is used; for printing the exception.; By preserving the full C++ type, it is possible to call any other member; functions the exception may provide beyond ``what`` or access any additional; data it carries. To catch the exception, you can either use the full type, or any of its base; classes, including ``Exception`` and ``cppyy.gbl.std.exception``:. .. code-block:: python. >>> try:; ... cppyy.gbl.throw_an_error(0); ... except cppyy.gbl.SomeOtherError as e: # catch by exact type; ... print(""received:"", e); ... ; received: <cppyy.gbl.SomeOtherError object at 0x7f9e11d3db10>; >>> try:; ... cppyy.gbl.throw_an_error(0); ... except Exception as e: # catch through base class; ... print(""received:"", e); ... ; received: <cppyy.gbl.SomeOtherError object at 0x7f9e11e00310>; >>> . ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/exceptions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/exceptions.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/exceptions.rst:1249,Integrability,message,message,1249,"low exception propagation; through multiple levels of callbacks, while retaining the option to handle; the outstanding exception as needed in either language.; To preserve an exception across the language boundaries, it must derive from; ``std::exception``.; If preserving the exception (or its type) is not possible, generic exceptions; are used to propagate the exception: ``Exception`` in Python or; ``CPyCppyy::PyException`` in C++. In the most common case of an instance of a C++ exception class derived from; ``std::exception`` that is thrown from a compiled library and which is; copyable, the exception can be caught and handled like any other bound C++; object (or with ``Exception`` on the Python and ``std::exception`` on the; C++ side).; If the exception is not copyable, but derived from ``std::exception``, the; result of its ``what()`` reported with an instance of Python's ``Exception``.; In all other cases, including exceptions thrown from interpreted code (due to; limitations of the Clang JIT), the exception will turn into an instance of; ``Exception`` with a generic message. The standard C++ exceptions are explicitly not mapped onto standard Python; exceptions, since other than a few simple cases, the mapping is too crude to; be useful as the typical usage in each standard library is too different.; Thus, for example, a thrown ``std::runtime_error`` instance will become a; ``cppyy.gbl.std.runtime_error`` instance on the Python side (with Python's; ``Exception`` as its base class), not a ``RuntimeError`` instance. The C++ code used for the examples below can be found; :doc:`here <cppyy_features_header>`, and it is assumed that that code is; loaded at the start of any session.; Download it, save it under the name ``features.h``, and load it:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('features.h'); >>>. In addition, the examples require the ``throw`` to be in compiled code.; Save the following and build it into a shared library ``libfeatures.so",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/exceptions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/exceptions.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/exceptions.rst:1834,Performance,load,loaded,1834,"nd handled like any other bound C++; object (or with ``Exception`` on the Python and ``std::exception`` on the; C++ side).; If the exception is not copyable, but derived from ``std::exception``, the; result of its ``what()`` reported with an instance of Python's ``Exception``.; In all other cases, including exceptions thrown from interpreted code (due to; limitations of the Clang JIT), the exception will turn into an instance of; ``Exception`` with a generic message. The standard C++ exceptions are explicitly not mapped onto standard Python; exceptions, since other than a few simple cases, the mapping is too crude to; be useful as the typical usage in each standard library is too different.; Thus, for example, a thrown ``std::runtime_error`` instance will become a; ``cppyy.gbl.std.runtime_error`` instance on the Python side (with Python's; ``Exception`` as its base class), not a ``RuntimeError`` instance. The C++ code used for the examples below can be found; :doc:`here <cppyy_features_header>`, and it is assumed that that code is; loaded at the start of any session.; Download it, save it under the name ``features.h``, and load it:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('features.h'); >>>. In addition, the examples require the ``throw`` to be in compiled code.; Save the following and build it into a shared library ``libfeatures.so`` (or; ``libfeatures.dll`` on MS Windows):. .. code-block:: C++. #include ""features.h"". void throw_an_error(int i) {; if (i) throw SomeError{""this is an error""};; throw SomeOtherError{""this is another error""};; }. And load the resulting library:. .. code-block:: python. >>> cppyy.load_library('libfeatures'); >>>. Then try it out:. .. code-block:: python. >>> cppyy.gbl.throw_an_error(1); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; cppyy.gbl.SomeError: void ::throw_an_error(int i) =>; SomeError: this is an error; >>> . Note how the full type is preserved and how the result of ``what()`` is us",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/exceptions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/exceptions.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/exceptions.rst:1927,Performance,load,load,1927,"is not copyable, but derived from ``std::exception``, the; result of its ``what()`` reported with an instance of Python's ``Exception``.; In all other cases, including exceptions thrown from interpreted code (due to; limitations of the Clang JIT), the exception will turn into an instance of; ``Exception`` with a generic message. The standard C++ exceptions are explicitly not mapped onto standard Python; exceptions, since other than a few simple cases, the mapping is too crude to; be useful as the typical usage in each standard library is too different.; Thus, for example, a thrown ``std::runtime_error`` instance will become a; ``cppyy.gbl.std.runtime_error`` instance on the Python side (with Python's; ``Exception`` as its base class), not a ``RuntimeError`` instance. The C++ code used for the examples below can be found; :doc:`here <cppyy_features_header>`, and it is assumed that that code is; loaded at the start of any session.; Download it, save it under the name ``features.h``, and load it:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('features.h'); >>>. In addition, the examples require the ``throw`` to be in compiled code.; Save the following and build it into a shared library ``libfeatures.so`` (or; ``libfeatures.dll`` on MS Windows):. .. code-block:: C++. #include ""features.h"". void throw_an_error(int i) {; if (i) throw SomeError{""this is an error""};; throw SomeOtherError{""this is another error""};; }. And load the resulting library:. .. code-block:: python. >>> cppyy.load_library('libfeatures'); >>>. Then try it out:. .. code-block:: python. >>> cppyy.gbl.throw_an_error(1); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; cppyy.gbl.SomeError: void ::throw_an_error(int i) =>; SomeError: this is an error; >>> . Note how the full type is preserved and how the result of ``what()`` is used; for printing the exception.; By preserving the full C++ type, it is possible to call any other member; functions the exception may provi",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/exceptions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/exceptions.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/exceptions.rst:2379,Performance,load,load,2379,"ping is too crude to; be useful as the typical usage in each standard library is too different.; Thus, for example, a thrown ``std::runtime_error`` instance will become a; ``cppyy.gbl.std.runtime_error`` instance on the Python side (with Python's; ``Exception`` as its base class), not a ``RuntimeError`` instance. The C++ code used for the examples below can be found; :doc:`here <cppyy_features_header>`, and it is assumed that that code is; loaded at the start of any session.; Download it, save it under the name ``features.h``, and load it:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('features.h'); >>>. In addition, the examples require the ``throw`` to be in compiled code.; Save the following and build it into a shared library ``libfeatures.so`` (or; ``libfeatures.dll`` on MS Windows):. .. code-block:: C++. #include ""features.h"". void throw_an_error(int i) {; if (i) throw SomeError{""this is an error""};; throw SomeOtherError{""this is another error""};; }. And load the resulting library:. .. code-block:: python. >>> cppyy.load_library('libfeatures'); >>>. Then try it out:. .. code-block:: python. >>> cppyy.gbl.throw_an_error(1); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; cppyy.gbl.SomeError: void ::throw_an_error(int i) =>; SomeError: this is an error; >>> . Note how the full type is preserved and how the result of ``what()`` is used; for printing the exception.; By preserving the full C++ type, it is possible to call any other member; functions the exception may provide beyond ``what`` or access any additional; data it carries. To catch the exception, you can either use the full type, or any of its base; classes, including ``Exception`` and ``cppyy.gbl.std.exception``:. .. code-block:: python. >>> try:; ... cppyy.gbl.throw_an_error(0); ... except cppyy.gbl.SomeOtherError as e: # catch by exact type; ... print(""received:"", e); ... ; received: <cppyy.gbl.SomeOtherError object at 0x7f9e11d3db10>; >>> try:; ... cppyy.gbl.throw",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/exceptions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/exceptions.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/exceptions.rst:2949,Security,access,access,2949,"``cppyy.gbl.std.runtime_error`` instance on the Python side (with Python's; ``Exception`` as its base class), not a ``RuntimeError`` instance. The C++ code used for the examples below can be found; :doc:`here <cppyy_features_header>`, and it is assumed that that code is; loaded at the start of any session.; Download it, save it under the name ``features.h``, and load it:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('features.h'); >>>. In addition, the examples require the ``throw`` to be in compiled code.; Save the following and build it into a shared library ``libfeatures.so`` (or; ``libfeatures.dll`` on MS Windows):. .. code-block:: C++. #include ""features.h"". void throw_an_error(int i) {; if (i) throw SomeError{""this is an error""};; throw SomeOtherError{""this is another error""};; }. And load the resulting library:. .. code-block:: python. >>> cppyy.load_library('libfeatures'); >>>. Then try it out:. .. code-block:: python. >>> cppyy.gbl.throw_an_error(1); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; cppyy.gbl.SomeError: void ::throw_an_error(int i) =>; SomeError: this is an error; >>> . Note how the full type is preserved and how the result of ``what()`` is used; for printing the exception.; By preserving the full C++ type, it is possible to call any other member; functions the exception may provide beyond ``what`` or access any additional; data it carries. To catch the exception, you can either use the full type, or any of its base; classes, including ``Exception`` and ``cppyy.gbl.std.exception``:. .. code-block:: python. >>> try:; ... cppyy.gbl.throw_an_error(0); ... except cppyy.gbl.SomeOtherError as e: # catch by exact type; ... print(""received:"", e); ... ; received: <cppyy.gbl.SomeOtherError object at 0x7f9e11d3db10>; >>> try:; ... cppyy.gbl.throw_an_error(0); ... except Exception as e: # catch through base class; ... print(""received:"", e); ... ; received: <cppyy.gbl.SomeOtherError object at 0x7f9e11e00310>; >>> . ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/exceptions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/exceptions.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/exceptions.rst:1369,Usability,simpl,simple,1369,"ries, it must derive from; ``std::exception``.; If preserving the exception (or its type) is not possible, generic exceptions; are used to propagate the exception: ``Exception`` in Python or; ``CPyCppyy::PyException`` in C++. In the most common case of an instance of a C++ exception class derived from; ``std::exception`` that is thrown from a compiled library and which is; copyable, the exception can be caught and handled like any other bound C++; object (or with ``Exception`` on the Python and ``std::exception`` on the; C++ side).; If the exception is not copyable, but derived from ``std::exception``, the; result of its ``what()`` reported with an instance of Python's ``Exception``.; In all other cases, including exceptions thrown from interpreted code (due to; limitations of the Clang JIT), the exception will turn into an instance of; ``Exception`` with a generic message. The standard C++ exceptions are explicitly not mapped onto standard Python; exceptions, since other than a few simple cases, the mapping is too crude to; be useful as the typical usage in each standard library is too different.; Thus, for example, a thrown ``std::runtime_error`` instance will become a; ``cppyy.gbl.std.runtime_error`` instance on the Python side (with Python's; ``Exception`` as its base class), not a ``RuntimeError`` instance. The C++ code used for the examples below can be found; :doc:`here <cppyy_features_header>`, and it is assumed that that code is; loaded at the start of any session.; Download it, save it under the name ``features.h``, and load it:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('features.h'); >>>. In addition, the examples require the ``throw`` to be in compiled code.; Save the following and build it into a shared library ``libfeatures.so`` (or; ``libfeatures.dll`` on MS Windows):. .. code-block:: C++. #include ""features.h"". void throw_an_error(int i) {; if (i) throw SomeError{""this is an error""};; throw SomeOtherError{""this is another error""};;",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/exceptions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/exceptions.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst:1193,Availability,avail,available,1193,". The C++ code used for the examples below can be found; :doc:`here <cppyy_features_header>`, and it is assumed that that code is; loaded at the start of any session.; Download it, save it under the name ``features.h``, and load it:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('features.h'); >>>. Function argument type conversions follow the expected rules, with implicit; conversions allowed, including between Python builtin types and STL types,; but it is rather more efficient to make conversions explicit. `Free functions`; ----------------. All bound C++ code starts off from the global C++ namespace, represented in; Python by ``gbl``.; This namespace, as any other namespace, is treated as a module after it has; been loaded.; Thus, we can directly import C++ functions from it and other namespaces that; themselves may contain more functions.; All lookups on namespaces are done lazily, thus if loading more headers bring; in more functions (incl. new overloads), these become available dynamically. .. code-block:: python. >>> from cppyy.gbl import global_function, Namespace; >>> global_function == Namespace.global_function; False; >>> from cppyy.gbl.Namespace import global_function; >>> global_function == Namespace.global_function; True; >>> from cppyy.gbl import global_function; >>>. Free functions can be bound to a class, following the same rules as apply to; Python functions: unless marked as static, they will turn into member; functions when bound to an instance, but act as static functions when called; through the class.; Consider this example:. .. code-block:: python. >>> from cppyy.gbl import Concrete, call_abstract_method; >>> c = Concrete(); >>> Concrete.callit = call_abstract_method; >>> Concrete.callit(c); called Concrete::abstract_method; >>> c.callit(); called Concrete::abstract_method; >>> Concrete.callit = staticmethod(call_abstract_method); >>> c.callit(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; TypeError",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/functions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst:5050,Availability,avail,available,5050,"C ``double`` as its internal representation.; The motivation is that doing so makes the Python code more readable (and; Python may anyway change its internal representation in the future).; The same has been true for Python ``int``, which used to be a C ``long``; internally. Examples, using multiply from :doc:`features.h <cppyy_features_header>`:. .. code-block:: python. >>> mul = cppyy.gbl.multiply; >>> mul(1, 2); 2; >>> mul(1., 5); 5.0; >>> mul[int](1, 1); 1; >>> mul[int, int](1, 1); 1; >>> mul[int, int, float](1, 1); 1.0; >>> mul[int, int](1, 'a'); TypeError: Template method resolution failed:; none of the 6 overloaded methods succeeded. Full details:; int ::multiply(int a, int b) =>; TypeError: could not convert argument 2 (int/long conversion expects an integer object); ...; Failed to instantiate ""multiply(int,std::string)""; >>> mul['double, double, double'](1., 5); 5.0; >>>. `Overloading`; -------------. C++ supports overloading, whereas Python supports ""duck typing"", thus C++; overloads have to be selected dynamically in response to the available; ""ducks.""; This may lead to additional lookups or template instantiations.; However, pre-existing methods (incl. auto-instantiated methods) are always; preferred over new template instantiations:. .. code-block:: python. >>> global_function(1.) # selects 'double' overload; 2.718281828459045; >>> global_function(1) # selects 'int' overload; 42; >>>. C++ does a static dispatch at compile time based on the argument types.; The dispatch is a selection among overloads (incl. templates) visible at the; current parse location in the *translation unit*.; Bound C++ in Python does a dynamic dispatch: it considers all overloads; visible *globally* at the time of execution.; These two approaches, even if completely in line with the expectations of the; respective languages, are fundamentally different and there can thus be; discrepancies in overload selection.; For example, if overloads live in different header files and are only",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/functions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst:6219,Availability,error,errors,6219,"ed over new template instantiations:. .. code-block:: python. >>> global_function(1.) # selects 'double' overload; 2.718281828459045; >>> global_function(1) # selects 'int' overload; 42; >>>. C++ does a static dispatch at compile time based on the argument types.; The dispatch is a selection among overloads (incl. templates) visible at the; current parse location in the *translation unit*.; Bound C++ in Python does a dynamic dispatch: it considers all overloads; visible *globally* at the time of execution.; These two approaches, even if completely in line with the expectations of the; respective languages, are fundamentally different and there can thus be; discrepancies in overload selection.; For example, if overloads live in different header files and are only an; implicit conversion apart; or if types that have no direct equivalent in; Python, such as e.g. ``unsigned short``, are used. It is implicitly assumed that the Python code is correct as-written and there; are no warnings or errors for overloads that C++ would consider ambiguous,; but only if every possible overload fails.; For example, the following overload would be ambiguous in C++ (the value; provided is an integer, but can not be passed through a 4-byte ``int`` type),; but instead ``cppyy`` silently accepts promotion to ``double``:. .. code-block:: python. >>> cppyy.cppdef(r""""""\; ... void process_data(double) { std::cerr << ""processing double\n""; }; ... void process_data(int32_t) { std::cerr << ""processing int\n""; }""""""); True; >>> cppyy.gbl.process_data(2**32) # too large for int32_t type; processing double; >>>. There are two rounds to run-time overload resolution.; The first round considers all overloads in sorted order, with promotion but; no implicit conversion allowed.; The sorting is based on priority scores of each overload.; Higher priority is given to overloads with argument types that can be; promoted or align better with Python types.; E.g. ``int`` is preferred over ``double`` and ``double`",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/functions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst:7802,Availability,avail,available,7802,"rload resolution.; The first round considers all overloads in sorted order, with promotion but; no implicit conversion allowed.; The sorting is based on priority scores of each overload.; Higher priority is given to overloads with argument types that can be; promoted or align better with Python types.; E.g. ``int`` is preferred over ``double`` and ``double`` is preferred over; ``float``.; If argument conversion fails for all overloads during this round *and* at; least one argument converter has indicated that it can do implicit; conversion, a second round is tried where implicit conversion, including; instantiation of temporaries, is allowed.; The implicit creation of temporaries, although convenient, can be costly in; terms of run-time performance. During some template calls, implicit conversion is not allowed, giving; preference to new instantiations (as is the case in C++).; If, however, a previously instantiated overload is available and would match; with promotion, it is preferred over a (costly) new instantiation, unless a; template overload is explicitly selected using template arguments.; For example:. .. code-block:: python. >>> cppyy.cppdef(r""""""\; ... template<typename T>; ... T process_T(T t) { return t; }""""""); True; >>> type(cppyy.gbl.process_T(1.0)); <class 'float'>; >>> type(cppyy.gbl.process_T(1)) # selects available ""double"" overload; <class 'float'>; >>> type(cppyy.gbl.process_T[int](1)) # explicit selection of ""int"" overload; <class 'int'>; >>>. The template parameters used for instantiation can depend on the argument; values.; For example, if the type of an argument is Python ``int``, but its value is; too large for a 4-byte C++ ``int``, the template may be instantiated with,; for example, an ``int64_t`` instead (if available on the platform).; Since Python does not have unsigned types, the instantiation mechanism; strongly prefers signed types.; However, if an argument value is too large to fit in a signed integer type,; but would fit in an unsign",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/functions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst:8204,Availability,avail,available,8204,"s preferred over; ``float``.; If argument conversion fails for all overloads during this round *and* at; least one argument converter has indicated that it can do implicit; conversion, a second round is tried where implicit conversion, including; instantiation of temporaries, is allowed.; The implicit creation of temporaries, although convenient, can be costly in; terms of run-time performance. During some template calls, implicit conversion is not allowed, giving; preference to new instantiations (as is the case in C++).; If, however, a previously instantiated overload is available and would match; with promotion, it is preferred over a (costly) new instantiation, unless a; template overload is explicitly selected using template arguments.; For example:. .. code-block:: python. >>> cppyy.cppdef(r""""""\; ... template<typename T>; ... T process_T(T t) { return t; }""""""); True; >>> type(cppyy.gbl.process_T(1.0)); <class 'float'>; >>> type(cppyy.gbl.process_T(1)) # selects available ""double"" overload; <class 'float'>; >>> type(cppyy.gbl.process_T[int](1)) # explicit selection of ""int"" overload; <class 'int'>; >>>. The template parameters used for instantiation can depend on the argument; values.; For example, if the type of an argument is Python ``int``, but its value is; too large for a 4-byte C++ ``int``, the template may be instantiated with,; for example, an ``int64_t`` instead (if available on the platform).; Since Python does not have unsigned types, the instantiation mechanism; strongly prefers signed types.; However, if an argument value is too large to fit in a signed integer type,; but would fit in an unsigned type, then that will be used. If it is important that a specific overload is selected, then use the; ``__overload__`` method to match a specific function signature.; An optional boolean second parameter can be used to restrict the selected; method to be const (if ``True``) or non-const (if ``False``).; The return value of which is a first-class callable obj",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/functions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst:8625,Availability,avail,available,8625,"oraries, although convenient, can be costly in; terms of run-time performance. During some template calls, implicit conversion is not allowed, giving; preference to new instantiations (as is the case in C++).; If, however, a previously instantiated overload is available and would match; with promotion, it is preferred over a (costly) new instantiation, unless a; template overload is explicitly selected using template arguments.; For example:. .. code-block:: python. >>> cppyy.cppdef(r""""""\; ... template<typename T>; ... T process_T(T t) { return t; }""""""); True; >>> type(cppyy.gbl.process_T(1.0)); <class 'float'>; >>> type(cppyy.gbl.process_T(1)) # selects available ""double"" overload; <class 'float'>; >>> type(cppyy.gbl.process_T[int](1)) # explicit selection of ""int"" overload; <class 'int'>; >>>. The template parameters used for instantiation can depend on the argument; values.; For example, if the type of an argument is Python ``int``, but its value is; too large for a 4-byte C++ ``int``, the template may be instantiated with,; for example, an ``int64_t`` instead (if available on the platform).; Since Python does not have unsigned types, the instantiation mechanism; strongly prefers signed types.; However, if an argument value is too large to fit in a signed integer type,; but would fit in an unsigned type, then that will be used. If it is important that a specific overload is selected, then use the; ``__overload__`` method to match a specific function signature.; An optional boolean second parameter can be used to restrict the selected; method to be const (if ``True``) or non-const (if ``False``).; The return value of which is a first-class callable object, that can be; stored to by-pass the overload resolution:. .. code-block:: python. >>> gf_double = global_function.__overload__('double'); >>> gf_double(1) # int implicitly promoted; 2.718281828459045; >>>. The ``__overload__`` method only does a lookup; it performs no (implicit); conversions and the types in the ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/functions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst:9632,Availability,avail,available,9632," does not have unsigned types, the instantiation mechanism; strongly prefers signed types.; However, if an argument value is too large to fit in a signed integer type,; but would fit in an unsigned type, then that will be used. If it is important that a specific overload is selected, then use the; ``__overload__`` method to match a specific function signature.; An optional boolean second parameter can be used to restrict the selected; method to be const (if ``True``) or non-const (if ``False``).; The return value of which is a first-class callable object, that can be; stored to by-pass the overload resolution:. .. code-block:: python. >>> gf_double = global_function.__overload__('double'); >>> gf_double(1) # int implicitly promoted; 2.718281828459045; >>>. The ``__overload__`` method only does a lookup; it performs no (implicit); conversions and the types in the signature to match should be the fully; resolved ones (no typedefs).; To see all overloads available for selection, use ``help()`` on the function; or look at its ``__doc__`` string:. .. code-block:: python. >>> print(global_function.__doc__); int ::global_function(int); double ::global_function(double); >>>. For convenience, the ``:any:`` signature allows matching any overload, for; example to reduce a method to its ``const`` overload only, use:. .. code-block:: python. MyClass.some_method = MyClass.some_method.__overload__(':any:', True). `Overloads and exceptions`; --------------------------. Python error reporting is done using exceptions.; Failed argument conversion during overload resolution can lead to different; types of exceptions coming from respective attempted overloads.; The final error report issued if all overloads fail, is a summary of the; individual errors, but by Python language requirements it has to have a; single exception type.; If all the exception types match, that type is used, but if there is an; amalgam of types, the exception type chosen will be ``TypeError``.; For example, attemp",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/functions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst:10151,Availability,error,error,10151," The return value of which is a first-class callable object, that can be; stored to by-pass the overload resolution:. .. code-block:: python. >>> gf_double = global_function.__overload__('double'); >>> gf_double(1) # int implicitly promoted; 2.718281828459045; >>>. The ``__overload__`` method only does a lookup; it performs no (implicit); conversions and the types in the signature to match should be the fully; resolved ones (no typedefs).; To see all overloads available for selection, use ``help()`` on the function; or look at its ``__doc__`` string:. .. code-block:: python. >>> print(global_function.__doc__); int ::global_function(int); double ::global_function(double); >>>. For convenience, the ``:any:`` signature allows matching any overload, for; example to reduce a method to its ``const`` overload only, use:. .. code-block:: python. MyClass.some_method = MyClass.some_method.__overload__(':any:', True). `Overloads and exceptions`; --------------------------. Python error reporting is done using exceptions.; Failed argument conversion during overload resolution can lead to different; types of exceptions coming from respective attempted overloads.; The final error report issued if all overloads fail, is a summary of the; individual errors, but by Python language requirements it has to have a; single exception type.; If all the exception types match, that type is used, but if there is an; amalgam of types, the exception type chosen will be ``TypeError``.; For example, attempting to pass a too large value through ``uint8_t`` will; uniquely raise a ``ValueError``. .. code-block:: python. >>> cppyy.cppdef(""void somefunc(uint8_t) {}""); True; >>> cppyy.gbl.somefunc(2**16); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; ValueError: void ::somefunc(uint8_t) =>; ValueError: could not convert argument 1 (integer to character: value 65536 not in range [0,255]); >>>. But if other overloads are present that fail in a different way, the error; report wi",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/functions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst:10346,Availability,error,error,10346,"8459045; >>>. The ``__overload__`` method only does a lookup; it performs no (implicit); conversions and the types in the signature to match should be the fully; resolved ones (no typedefs).; To see all overloads available for selection, use ``help()`` on the function; or look at its ``__doc__`` string:. .. code-block:: python. >>> print(global_function.__doc__); int ::global_function(int); double ::global_function(double); >>>. For convenience, the ``:any:`` signature allows matching any overload, for; example to reduce a method to its ``const`` overload only, use:. .. code-block:: python. MyClass.some_method = MyClass.some_method.__overload__(':any:', True). `Overloads and exceptions`; --------------------------. Python error reporting is done using exceptions.; Failed argument conversion during overload resolution can lead to different; types of exceptions coming from respective attempted overloads.; The final error report issued if all overloads fail, is a summary of the; individual errors, but by Python language requirements it has to have a; single exception type.; If all the exception types match, that type is used, but if there is an; amalgam of types, the exception type chosen will be ``TypeError``.; For example, attempting to pass a too large value through ``uint8_t`` will; uniquely raise a ``ValueError``. .. code-block:: python. >>> cppyy.cppdef(""void somefunc(uint8_t) {}""); True; >>> cppyy.gbl.somefunc(2**16); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; ValueError: void ::somefunc(uint8_t) =>; ValueError: could not convert argument 1 (integer to character: value 65536 not in range [0,255]); >>>. But if other overloads are present that fail in a different way, the error; report will be a ``TypeError``:. .. code-block:: python. >>> cppyy.cppdef(r""""""; ... void somefunc(uint8_t) {}; ... void somefunc(std::string) {}""""""); True; >>> cppyy.gbl.somefunc(2**16); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; T",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/functions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst:10421,Availability,error,errors,10421,"8459045; >>>. The ``__overload__`` method only does a lookup; it performs no (implicit); conversions and the types in the signature to match should be the fully; resolved ones (no typedefs).; To see all overloads available for selection, use ``help()`` on the function; or look at its ``__doc__`` string:. .. code-block:: python. >>> print(global_function.__doc__); int ::global_function(int); double ::global_function(double); >>>. For convenience, the ``:any:`` signature allows matching any overload, for; example to reduce a method to its ``const`` overload only, use:. .. code-block:: python. MyClass.some_method = MyClass.some_method.__overload__(':any:', True). `Overloads and exceptions`; --------------------------. Python error reporting is done using exceptions.; Failed argument conversion during overload resolution can lead to different; types of exceptions coming from respective attempted overloads.; The final error report issued if all overloads fail, is a summary of the; individual errors, but by Python language requirements it has to have a; single exception type.; If all the exception types match, that type is used, but if there is an; amalgam of types, the exception type chosen will be ``TypeError``.; For example, attempting to pass a too large value through ``uint8_t`` will; uniquely raise a ``ValueError``. .. code-block:: python. >>> cppyy.cppdef(""void somefunc(uint8_t) {}""); True; >>> cppyy.gbl.somefunc(2**16); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; ValueError: void ::somefunc(uint8_t) =>; ValueError: could not convert argument 1 (integer to character: value 65536 not in range [0,255]); >>>. But if other overloads are present that fail in a different way, the error; report will be a ``TypeError``:. .. code-block:: python. >>> cppyy.cppdef(r""""""; ... void somefunc(uint8_t) {}; ... void somefunc(std::string) {}""""""); True; >>> cppyy.gbl.somefunc(2**16); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; T",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/functions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst:11152,Availability,error,error,11152,"------. Python error reporting is done using exceptions.; Failed argument conversion during overload resolution can lead to different; types of exceptions coming from respective attempted overloads.; The final error report issued if all overloads fail, is a summary of the; individual errors, but by Python language requirements it has to have a; single exception type.; If all the exception types match, that type is used, but if there is an; amalgam of types, the exception type chosen will be ``TypeError``.; For example, attempting to pass a too large value through ``uint8_t`` will; uniquely raise a ``ValueError``. .. code-block:: python. >>> cppyy.cppdef(""void somefunc(uint8_t) {}""); True; >>> cppyy.gbl.somefunc(2**16); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; ValueError: void ::somefunc(uint8_t) =>; ValueError: could not convert argument 1 (integer to character: value 65536 not in range [0,255]); >>>. But if other overloads are present that fail in a different way, the error; report will be a ``TypeError``:. .. code-block:: python. >>> cppyy.cppdef(r""""""; ... void somefunc(uint8_t) {}; ... void somefunc(std::string) {}""""""); True; >>> cppyy.gbl.somefunc(2**16); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; TypeError: none of the 2 overloaded methods succeeded. Full details:; void ::somefunc(std::string) =>; TypeError: could not convert argument 1; void ::somefunc(uint8_t) =>; ValueError: could not convert argument 1 (integer to character: value 65536 not in range [0,255]); >>>. Since C++ exceptions are converted to Python ones, there is an interplay; possible between the two as part of overload resolution and ``cppyy``; allows C++ exceptions as such, enabling detailed type disambiguation and; input validation.; (The original use case was for filling database fields, requiring an exact; field label and data type match.). If, however, all methods fail and there is only one C++ exception (the other; exceptions ori",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/functions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst:14435,Availability,alive,alive,14435," argument names are repeated in the definition,; making the names in the declaration irrelevant: they do not even need to be; provided).; Thus, although ``cppyy`` will map keyword argument names to formal argument; names from the C++ declaration, use of this feature is not recommended unless; you have a guarantee that the names in C++ the interface are maintained.; Example:. .. code-block:: python. >>> from cppyy.gbl import Concrete; >>> c = Concrete() # uses default argument; >>> c.m_int; 42; >>> c = Concrete(13) # uses provided argument; >>> c.m_int; 13; >>> args = (27,); >>> c = Concrete(*args) # argument pack; >>> c.m_int; 27; >>> c = Concrete(n=17); >>> c.m_int; 17; >>> kwds = {'n' : 18}; >>> c = Concrete(**kwds); >>> c.m_int; 18; >>>. `Callbacks`; -----------. Python callables (functions/lambdas/instances) can be passed to C++ through; function pointers and/or ``std::function``.; This involves creation of a temporary wrapper, which has the same life time as; the Python callable it wraps, so the callable needs to be kept alive on the; Python side if the C++ side stores the callback.; Example:. .. code-block:: python. >>> from cppyy.gbl import call_int_int; >>> print(call_int_int.__doc__); int ::call_int_int(int(*)(int,int) f, int i1, int i2); >>> def add(a, b):; ... return a+b; ...; >>> call_int_int(add, 3, 7); 7; >>> call_int_int(lambda x, y: x*y, 3, 7); 21; >>>. Python functions can be used to instantiate C++ templates, assuming the; type information of the arguments and return types can be inferred.; If this can not be done directly from the template arguments, then it can; be provided through Python annotations, by explicitly adding the; ``__annotations__`` special data member (e.g. for older versions of Python; that do not support annotations), or by the function having been bound by; ``cppyy`` in the first place.; For example:. .. code-block:: python. >>> import cppyy; >>> cppyy.cppdef(""""""\; ... template<typename R, typename... U, typename... A>; ... R cal",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/functions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst:678,Energy Efficiency,efficient,efficient,678,".. _functions:. Functions; =========. C++ functions are first-class objects in Python and can be used wherever; Python functions can be used, including for dynamically constructing; classes. The C++ code used for the examples below can be found; :doc:`here <cppyy_features_header>`, and it is assumed that that code is; loaded at the start of any session.; Download it, save it under the name ``features.h``, and load it:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('features.h'); >>>. Function argument type conversions follow the expected rules, with implicit; conversions allowed, including between Python builtin types and STL types,; but it is rather more efficient to make conversions explicit. `Free functions`; ----------------. All bound C++ code starts off from the global C++ namespace, represented in; Python by ``gbl``.; This namespace, as any other namespace, is treated as a module after it has; been loaded.; Thus, we can directly import C++ functions from it and other namespaces that; themselves may contain more functions.; All lookups on namespaces are done lazily, thus if loading more headers bring; in more functions (incl. new overloads), these become available dynamically. .. code-block:: python. >>> from cppyy.gbl import global_function, Namespace; >>> global_function == Namespace.global_function; False; >>> from cppyy.gbl.Namespace import global_function; >>> global_function == Namespace.global_function; True; >>> from cppyy.gbl import global_function; >>>. Free functions can be bound to a class, following the same rules as apply to; Python functions: unless marked as static, they will turn into member; functions when bound to an instance, but act as static functions when called; through the class.; Consider this example:. .. code-block:: python. >>> from cppyy.gbl import Concrete, call_abstract_method; >>> c = Concrete(); >>> Concrete.callit = call_abstract_method; >>> Concrete.callit(c); called Concrete::abstract_method; >>> c.callit(); ca",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/functions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst:9939,Energy Efficiency,reduce,reduce,9939,"pecific overload is selected, then use the; ``__overload__`` method to match a specific function signature.; An optional boolean second parameter can be used to restrict the selected; method to be const (if ``True``) or non-const (if ``False``).; The return value of which is a first-class callable object, that can be; stored to by-pass the overload resolution:. .. code-block:: python. >>> gf_double = global_function.__overload__('double'); >>> gf_double(1) # int implicitly promoted; 2.718281828459045; >>>. The ``__overload__`` method only does a lookup; it performs no (implicit); conversions and the types in the signature to match should be the fully; resolved ones (no typedefs).; To see all overloads available for selection, use ``help()`` on the function; or look at its ``__doc__`` string:. .. code-block:: python. >>> print(global_function.__doc__); int ::global_function(int); double ::global_function(double); >>>. For convenience, the ``:any:`` signature allows matching any overload, for; example to reduce a method to its ``const`` overload only, use:. .. code-block:: python. MyClass.some_method = MyClass.some_method.__overload__(':any:', True). `Overloads and exceptions`; --------------------------. Python error reporting is done using exceptions.; Failed argument conversion during overload resolution can lead to different; types of exceptions coming from respective attempted overloads.; The final error report issued if all overloads fail, is a summary of the; individual errors, but by Python language requirements it has to have a; single exception type.; If all the exception types match, that type is used, but if there is an; amalgam of types, the exception type chosen will be ``TypeError``.; For example, attempting to pass a too large value through ``uint8_t`` will; uniquely raise a ``ValueError``. .. code-block:: python. >>> cppyy.cppdef(""void somefunc(uint8_t) {}""); True; >>> cppyy.gbl.somefunc(2**16); Traceback (most recent call last):; File ""<stdin>"", line ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/functions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst:12929,Energy Efficiency,allocate,allocated,12929," validation.; (The original use case was for filling database fields, requiring an exact; field label and data type match.). If, however, all methods fail and there is only one C++ exception (the other; exceptions originating from argument conversion, never succeeding to call; into C++), this C++ exception will be preferentially reported and will have; the original C++ type. `Return values`; ---------------. Most return types are readily amenable to automatic memory management: builtin; returns, by-value returns, (const-)reference returns to internal data, smart; pointers, etc.; The important exception is pointer returns.; ; A function that returns a pointer to an object over which Python should claim; ownership, should have its ``__creates__`` flag set through its; :doc:`pythonization <pythonizations>`.; Well-written APIs will have clear clues in their naming convention about the; ownership rules.; For example, functions called ``New...``, ``Clone...``, etc. can be expected; to return freshly allocated objects.; A basic name-matching in the pythonization then makes it simple to mark all; these functions as creators. The return values are :ref:`auto-casted <sec-auto-casting-label>`. `\*args and \*\*kwds`; ---------------------. C++ default arguments work as expected.; Keywords, however, are a Python language feature that does not exist in C++.; Many C++ function declarations do have formal arguments, but these are not; part of the C++ interface (the argument names are repeated in the definition,; making the names in the declaration irrelevant: they do not even need to be; provided).; Thus, although ``cppyy`` will map keyword argument names to formal argument; names from the C++ declaration, use of this feature is not recommended unless; you have a guarantee that the names in C++ the interface are maintained.; Example:. .. code-block:: python. >>> from cppyy.gbl import Concrete; >>> c = Concrete() # uses default argument; >>> c.m_int; 42; >>> c = Concrete(13) # uses ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/functions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst:8399,Integrability,depend,depend,8399,"licit; conversion, a second round is tried where implicit conversion, including; instantiation of temporaries, is allowed.; The implicit creation of temporaries, although convenient, can be costly in; terms of run-time performance. During some template calls, implicit conversion is not allowed, giving; preference to new instantiations (as is the case in C++).; If, however, a previously instantiated overload is available and would match; with promotion, it is preferred over a (costly) new instantiation, unless a; template overload is explicitly selected using template arguments.; For example:. .. code-block:: python. >>> cppyy.cppdef(r""""""\; ... template<typename T>; ... T process_T(T t) { return t; }""""""); True; >>> type(cppyy.gbl.process_T(1.0)); <class 'float'>; >>> type(cppyy.gbl.process_T(1)) # selects available ""double"" overload; <class 'float'>; >>> type(cppyy.gbl.process_T[int](1)) # explicit selection of ""int"" overload; <class 'int'>; >>>. The template parameters used for instantiation can depend on the argument; values.; For example, if the type of an argument is Python ``int``, but its value is; too large for a 4-byte C++ ``int``, the template may be instantiated with,; for example, an ``int64_t`` instead (if available on the platform).; Since Python does not have unsigned types, the instantiation mechanism; strongly prefers signed types.; However, if an argument value is too large to fit in a signed integer type,; but would fit in an unsigned type, then that will be used. If it is important that a specific overload is selected, then use the; ``__overload__`` method to match a specific function signature.; An optional boolean second parameter can be used to restrict the selected; method to be const (if ``True``) or non-const (if ``False``).; The return value of which is a first-class callable object, that can be; stored to by-pass the overload resolution:. .. code-block:: python. >>> gf_double = global_function.__overload__('double'); >>> gf_double(1) # int i",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/functions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst:13379,Integrability,interface,interface,13379,"tin; returns, by-value returns, (const-)reference returns to internal data, smart; pointers, etc.; The important exception is pointer returns.; ; A function that returns a pointer to an object over which Python should claim; ownership, should have its ``__creates__`` flag set through its; :doc:`pythonization <pythonizations>`.; Well-written APIs will have clear clues in their naming convention about the; ownership rules.; For example, functions called ``New...``, ``Clone...``, etc. can be expected; to return freshly allocated objects.; A basic name-matching in the pythonization then makes it simple to mark all; these functions as creators. The return values are :ref:`auto-casted <sec-auto-casting-label>`. `\*args and \*\*kwds`; ---------------------. C++ default arguments work as expected.; Keywords, however, are a Python language feature that does not exist in C++.; Many C++ function declarations do have formal arguments, but these are not; part of the C++ interface (the argument names are repeated in the definition,; making the names in the declaration irrelevant: they do not even need to be; provided).; Thus, although ``cppyy`` will map keyword argument names to formal argument; names from the C++ declaration, use of this feature is not recommended unless; you have a guarantee that the names in C++ the interface are maintained.; Example:. .. code-block:: python. >>> from cppyy.gbl import Concrete; >>> c = Concrete() # uses default argument; >>> c.m_int; 42; >>> c = Concrete(13) # uses provided argument; >>> c.m_int; 13; >>> args = (27,); >>> c = Concrete(*args) # argument pack; >>> c.m_int; 27; >>> c = Concrete(n=17); >>> c.m_int; 17; >>> kwds = {'n' : 18}; >>> c = Concrete(**kwds); >>> c.m_int; 18; >>>. `Callbacks`; -----------. Python callables (functions/lambdas/instances) can be passed to C++ through; function pointers and/or ``std::function``.; This involves creation of a temporary wrapper, which has the same life time as; the Python callable it wraps, so th",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/functions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst:13734,Integrability,interface,interface,13734,"hould have its ``__creates__`` flag set through its; :doc:`pythonization <pythonizations>`.; Well-written APIs will have clear clues in their naming convention about the; ownership rules.; For example, functions called ``New...``, ``Clone...``, etc. can be expected; to return freshly allocated objects.; A basic name-matching in the pythonization then makes it simple to mark all; these functions as creators. The return values are :ref:`auto-casted <sec-auto-casting-label>`. `\*args and \*\*kwds`; ---------------------. C++ default arguments work as expected.; Keywords, however, are a Python language feature that does not exist in C++.; Many C++ function declarations do have formal arguments, but these are not; part of the C++ interface (the argument names are repeated in the definition,; making the names in the declaration irrelevant: they do not even need to be; provided).; Thus, although ``cppyy`` will map keyword argument names to formal argument; names from the C++ declaration, use of this feature is not recommended unless; you have a guarantee that the names in C++ the interface are maintained.; Example:. .. code-block:: python. >>> from cppyy.gbl import Concrete; >>> c = Concrete() # uses default argument; >>> c.m_int; 42; >>> c = Concrete(13) # uses provided argument; >>> c.m_int; 13; >>> args = (27,); >>> c = Concrete(*args) # argument pack; >>> c.m_int; 27; >>> c = Concrete(n=17); >>> c.m_int; 17; >>> kwds = {'n' : 18}; >>> c = Concrete(**kwds); >>> c.m_int; 18; >>>. `Callbacks`; -----------. Python callables (functions/lambdas/instances) can be passed to C++ through; function pointers and/or ``std::function``.; This involves creation of a temporary wrapper, which has the same life time as; the Python callable it wraps, so the callable needs to be kept alive on the; Python side if the C++ side stores the callback.; Example:. .. code-block:: python. >>> from cppyy.gbl import call_int_int; >>> print(call_int_int.__doc__); int ::call_int_int(int(*)(int,int) f, ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/functions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst:14330,Integrability,wrap,wrapper,14330," argument names are repeated in the definition,; making the names in the declaration irrelevant: they do not even need to be; provided).; Thus, although ``cppyy`` will map keyword argument names to formal argument; names from the C++ declaration, use of this feature is not recommended unless; you have a guarantee that the names in C++ the interface are maintained.; Example:. .. code-block:: python. >>> from cppyy.gbl import Concrete; >>> c = Concrete() # uses default argument; >>> c.m_int; 42; >>> c = Concrete(13) # uses provided argument; >>> c.m_int; 13; >>> args = (27,); >>> c = Concrete(*args) # argument pack; >>> c.m_int; 27; >>> c = Concrete(n=17); >>> c.m_int; 17; >>> kwds = {'n' : 18}; >>> c = Concrete(**kwds); >>> c.m_int; 18; >>>. `Callbacks`; -----------. Python callables (functions/lambdas/instances) can be passed to C++ through; function pointers and/or ``std::function``.; This involves creation of a temporary wrapper, which has the same life time as; the Python callable it wraps, so the callable needs to be kept alive on the; Python side if the C++ side stores the callback.; Example:. .. code-block:: python. >>> from cppyy.gbl import call_int_int; >>> print(call_int_int.__doc__); int ::call_int_int(int(*)(int,int) f, int i1, int i2); >>> def add(a, b):; ... return a+b; ...; >>> call_int_int(add, 3, 7); 7; >>> call_int_int(lambda x, y: x*y, 3, 7); 21; >>>. Python functions can be used to instantiate C++ templates, assuming the; type information of the arguments and return types can be inferred.; If this can not be done directly from the template arguments, then it can; be provided through Python annotations, by explicitly adding the; ``__annotations__`` special data member (e.g. for older versions of Python; that do not support annotations), or by the function having been bound by; ``cppyy`` in the first place.; For example:. .. code-block:: python. >>> import cppyy; >>> cppyy.cppdef(""""""\; ... template<typename R, typename... U, typename... A>; ... R cal",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/functions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst:14395,Integrability,wrap,wraps,14395," argument names are repeated in the definition,; making the names in the declaration irrelevant: they do not even need to be; provided).; Thus, although ``cppyy`` will map keyword argument names to formal argument; names from the C++ declaration, use of this feature is not recommended unless; you have a guarantee that the names in C++ the interface are maintained.; Example:. .. code-block:: python. >>> from cppyy.gbl import Concrete; >>> c = Concrete() # uses default argument; >>> c.m_int; 42; >>> c = Concrete(13) # uses provided argument; >>> c.m_int; 13; >>> args = (27,); >>> c = Concrete(*args) # argument pack; >>> c.m_int; 27; >>> c = Concrete(n=17); >>> c.m_int; 17; >>> kwds = {'n' : 18}; >>> c = Concrete(**kwds); >>> c.m_int; 18; >>>. `Callbacks`; -----------. Python callables (functions/lambdas/instances) can be passed to C++ through; function pointers and/or ``std::function``.; This involves creation of a temporary wrapper, which has the same life time as; the Python callable it wraps, so the callable needs to be kept alive on the; Python side if the C++ side stores the callback.; Example:. .. code-block:: python. >>> from cppyy.gbl import call_int_int; >>> print(call_int_int.__doc__); int ::call_int_int(int(*)(int,int) f, int i1, int i2); >>> def add(a, b):; ... return a+b; ...; >>> call_int_int(add, 3, 7); 7; >>> call_int_int(lambda x, y: x*y, 3, 7); 21; >>>. Python functions can be used to instantiate C++ templates, assuming the; type information of the arguments and return types can be inferred.; If this can not be done directly from the template arguments, then it can; be provided through Python annotations, by explicitly adding the; ``__annotations__`` special data member (e.g. for older versions of Python; that do not support annotations), or by the function having been bound by; ``cppyy`` in the first place.; For example:. .. code-block:: python. >>> import cppyy; >>> cppyy.cppdef(""""""\; ... template<typename R, typename... U, typename... A>; ... R cal",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/functions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst:320,Performance,load,loaded,320,".. _functions:. Functions; =========. C++ functions are first-class objects in Python and can be used wherever; Python functions can be used, including for dynamically constructing; classes. The C++ code used for the examples below can be found; :doc:`here <cppyy_features_header>`, and it is assumed that that code is; loaded at the start of any session.; Download it, save it under the name ``features.h``, and load it:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('features.h'); >>>. Function argument type conversions follow the expected rules, with implicit; conversions allowed, including between Python builtin types and STL types,; but it is rather more efficient to make conversions explicit. `Free functions`; ----------------. All bound C++ code starts off from the global C++ namespace, represented in; Python by ``gbl``.; This namespace, as any other namespace, is treated as a module after it has; been loaded.; Thus, we can directly import C++ functions from it and other namespaces that; themselves may contain more functions.; All lookups on namespaces are done lazily, thus if loading more headers bring; in more functions (incl. new overloads), these become available dynamically. .. code-block:: python. >>> from cppyy.gbl import global_function, Namespace; >>> global_function == Namespace.global_function; False; >>> from cppyy.gbl.Namespace import global_function; >>> global_function == Namespace.global_function; True; >>> from cppyy.gbl import global_function; >>>. Free functions can be bound to a class, following the same rules as apply to; Python functions: unless marked as static, they will turn into member; functions when bound to an instance, but act as static functions when called; through the class.; Consider this example:. .. code-block:: python. >>> from cppyy.gbl import Concrete, call_abstract_method; >>> c = Concrete(); >>> Concrete.callit = call_abstract_method; >>> Concrete.callit(c); called Concrete::abstract_method; >>> c.callit(); ca",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/functions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst:413,Performance,load,load,413,".. _functions:. Functions; =========. C++ functions are first-class objects in Python and can be used wherever; Python functions can be used, including for dynamically constructing; classes. The C++ code used for the examples below can be found; :doc:`here <cppyy_features_header>`, and it is assumed that that code is; loaded at the start of any session.; Download it, save it under the name ``features.h``, and load it:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('features.h'); >>>. Function argument type conversions follow the expected rules, with implicit; conversions allowed, including between Python builtin types and STL types,; but it is rather more efficient to make conversions explicit. `Free functions`; ----------------. All bound C++ code starts off from the global C++ namespace, represented in; Python by ``gbl``.; This namespace, as any other namespace, is treated as a module after it has; been loaded.; Thus, we can directly import C++ functions from it and other namespaces that; themselves may contain more functions.; All lookups on namespaces are done lazily, thus if loading more headers bring; in more functions (incl. new overloads), these become available dynamically. .. code-block:: python. >>> from cppyy.gbl import global_function, Namespace; >>> global_function == Namespace.global_function; False; >>> from cppyy.gbl.Namespace import global_function; >>> global_function == Namespace.global_function; True; >>> from cppyy.gbl import global_function; >>>. Free functions can be bound to a class, following the same rules as apply to; Python functions: unless marked as static, they will turn into member; functions when bound to an instance, but act as static functions when called; through the class.; Consider this example:. .. code-block:: python. >>> from cppyy.gbl import Concrete, call_abstract_method; >>> c = Concrete(); >>> Concrete.callit = call_abstract_method; >>> Concrete.callit(c); called Concrete::abstract_method; >>> c.callit(); ca",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/functions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst:933,Performance,load,loaded,933,".. _functions:. Functions; =========. C++ functions are first-class objects in Python and can be used wherever; Python functions can be used, including for dynamically constructing; classes. The C++ code used for the examples below can be found; :doc:`here <cppyy_features_header>`, and it is assumed that that code is; loaded at the start of any session.; Download it, save it under the name ``features.h``, and load it:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('features.h'); >>>. Function argument type conversions follow the expected rules, with implicit; conversions allowed, including between Python builtin types and STL types,; but it is rather more efficient to make conversions explicit. `Free functions`; ----------------. All bound C++ code starts off from the global C++ namespace, represented in; Python by ``gbl``.; This namespace, as any other namespace, is treated as a module after it has; been loaded.; Thus, we can directly import C++ functions from it and other namespaces that; themselves may contain more functions.; All lookups on namespaces are done lazily, thus if loading more headers bring; in more functions (incl. new overloads), these become available dynamically. .. code-block:: python. >>> from cppyy.gbl import global_function, Namespace; >>> global_function == Namespace.global_function; False; >>> from cppyy.gbl.Namespace import global_function; >>> global_function == Namespace.global_function; True; >>> from cppyy.gbl import global_function; >>>. Free functions can be bound to a class, following the same rules as apply to; Python functions: unless marked as static, they will turn into member; functions when bound to an instance, but act as static functions when called; through the class.; Consider this example:. .. code-block:: python. >>> from cppyy.gbl import Concrete, call_abstract_method; >>> c = Concrete(); >>> Concrete.callit = call_abstract_method; >>> Concrete.callit(c); called Concrete::abstract_method; >>> c.callit(); ca",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/functions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst:1111,Performance,load,loading,1111,"; Python functions can be used, including for dynamically constructing; classes. The C++ code used for the examples below can be found; :doc:`here <cppyy_features_header>`, and it is assumed that that code is; loaded at the start of any session.; Download it, save it under the name ``features.h``, and load it:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('features.h'); >>>. Function argument type conversions follow the expected rules, with implicit; conversions allowed, including between Python builtin types and STL types,; but it is rather more efficient to make conversions explicit. `Free functions`; ----------------. All bound C++ code starts off from the global C++ namespace, represented in; Python by ``gbl``.; This namespace, as any other namespace, is treated as a module after it has; been loaded.; Thus, we can directly import C++ functions from it and other namespaces that; themselves may contain more functions.; All lookups on namespaces are done lazily, thus if loading more headers bring; in more functions (incl. new overloads), these become available dynamically. .. code-block:: python. >>> from cppyy.gbl import global_function, Namespace; >>> global_function == Namespace.global_function; False; >>> from cppyy.gbl.Namespace import global_function; >>> global_function == Namespace.global_function; True; >>> from cppyy.gbl import global_function; >>>. Free functions can be bound to a class, following the same rules as apply to; Python functions: unless marked as static, they will turn into member; functions when bound to an instance, but act as static functions when called; through the class.; Consider this example:. .. code-block:: python. >>> from cppyy.gbl import Concrete, call_abstract_method; >>> c = Concrete(); >>> Concrete.callit = call_abstract_method; >>> Concrete.callit(c); called Concrete::abstract_method; >>> c.callit(); called Concrete::abstract_method; >>> Concrete.callit = staticmethod(call_abstract_method); >>> c.callit(); Trac",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/functions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst:3238,Performance,load,loading,3238," given); >>> c.callit(c); called Concrete::abstract_method; >>>. `Static methods`; ----------------. Class static functions are treated the same way as free functions, except; that they are accessible either through the class or through an instance,; just like Python's ``staticmethod``. `Instance methods`; ------------------. For class methods, see the :ref:`methods section <sec-methods-label>` under; the :doc:`classes heading<classes>`. `Lambda's`; ----------. C++ lambda functions are supported by first binding to a ``std::function``,; then providing a proxy to that on the Python side.; Example::. >>> cppyy.cppdef(""""""\; ... auto create_lambda(int a) {; ... return [a](int b) { return a+b; };; ... }""""""); True; >>> l = cppyy.gbl.create_lambda(4); >>> type(l); <class cppyy.gbl.std.function<int(int)> at 0x11505b830>; >>> l(2); 6; >>> . `Operators`; -----------. Globally defined operators are found lazily (ie. can resolve after the class; definition by loading the global definition or by defining them interactively); and are mapped onto a Python equivalent when possible.; See the :ref:`operators section <sec-operators-label>` under the; :doc:`classes heading<classes>` for more details. `Templates`; -----------. Templated functions (and class methods) can either be called using square; brackets (``[]``) to provide the template arguments explicitly, or called; directly, through automatic lookup.; The template arguments may either be a string of type names (this results; in faster code, as it needs no further lookup/verification) or a list of; the actual types to use (which tends to be more convenient). **Note**: the Python type ``float`` maps to the C++ type ``float``, even; as Python uses a C ``double`` as its internal representation.; The motivation is that doing so makes the Python code more readable (and; Python may anyway change its internal representation in the future).; The same has been true for Python ``int``, which used to be a C ``long``; internally. Examples, ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/functions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst:7607,Performance,perform,performance,7607,"> cppyy.cppdef(r""""""\; ... void process_data(double) { std::cerr << ""processing double\n""; }; ... void process_data(int32_t) { std::cerr << ""processing int\n""; }""""""); True; >>> cppyy.gbl.process_data(2**32) # too large for int32_t type; processing double; >>>. There are two rounds to run-time overload resolution.; The first round considers all overloads in sorted order, with promotion but; no implicit conversion allowed.; The sorting is based on priority scores of each overload.; Higher priority is given to overloads with argument types that can be; promoted or align better with Python types.; E.g. ``int`` is preferred over ``double`` and ``double`` is preferred over; ``float``.; If argument conversion fails for all overloads during this round *and* at; least one argument converter has indicated that it can do implicit; conversion, a second round is tried where implicit conversion, including; instantiation of temporaries, is allowed.; The implicit creation of temporaries, although convenient, can be costly in; terms of run-time performance. During some template calls, implicit conversion is not allowed, giving; preference to new instantiations (as is the case in C++).; If, however, a previously instantiated overload is available and would match; with promotion, it is preferred over a (costly) new instantiation, unless a; template overload is explicitly selected using template arguments.; For example:. .. code-block:: python. >>> cppyy.cppdef(r""""""\; ... template<typename T>; ... T process_T(T t) { return t; }""""""); True; >>> type(cppyy.gbl.process_T(1.0)); <class 'float'>; >>> type(cppyy.gbl.process_T(1)) # selects available ""double"" overload; <class 'float'>; >>> type(cppyy.gbl.process_T[int](1)) # explicit selection of ""int"" overload; <class 'int'>; >>>. The template parameters used for instantiation can depend on the argument; values.; For example, if the type of an argument is Python ``int``, but its value is; too large for a 4-byte C++ ``int``, the template may be ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/functions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst:9484,Performance,perform,performs,9484,"or a 4-byte C++ ``int``, the template may be instantiated with,; for example, an ``int64_t`` instead (if available on the platform).; Since Python does not have unsigned types, the instantiation mechanism; strongly prefers signed types.; However, if an argument value is too large to fit in a signed integer type,; but would fit in an unsigned type, then that will be used. If it is important that a specific overload is selected, then use the; ``__overload__`` method to match a specific function signature.; An optional boolean second parameter can be used to restrict the selected; method to be const (if ``True``) or non-const (if ``False``).; The return value of which is a first-class callable object, that can be; stored to by-pass the overload resolution:. .. code-block:: python. >>> gf_double = global_function.__overload__('double'); >>> gf_double(1) # int implicitly promoted; 2.718281828459045; >>>. The ``__overload__`` method only does a lookup; it performs no (implicit); conversions and the types in the signature to match should be the fully; resolved ones (no typedefs).; To see all overloads available for selection, use ``help()`` on the function; or look at its ``__doc__`` string:. .. code-block:: python. >>> print(global_function.__doc__); int ::global_function(int); double ::global_function(double); >>>. For convenience, the ``:any:`` signature allows matching any overload, for; example to reduce a method to its ``const`` overload only, use:. .. code-block:: python. MyClass.some_method = MyClass.some_method.__overload__(':any:', True). `Overloads and exceptions`; --------------------------. Python error reporting is done using exceptions.; Failed argument conversion during overload resolution can lead to different; types of exceptions coming from respective attempted overloads.; The final error report issued if all overloads fail, is a summary of the; individual errors, but by Python language requirements it has to have a; single exception type.; If all the exc",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/functions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst:2466,Security,access,accessible,2466,"cppyy.gbl import global_function; >>>. Free functions can be bound to a class, following the same rules as apply to; Python functions: unless marked as static, they will turn into member; functions when bound to an instance, but act as static functions when called; through the class.; Consider this example:. .. code-block:: python. >>> from cppyy.gbl import Concrete, call_abstract_method; >>> c = Concrete(); >>> Concrete.callit = call_abstract_method; >>> Concrete.callit(c); called Concrete::abstract_method; >>> c.callit(); called Concrete::abstract_method; >>> Concrete.callit = staticmethod(call_abstract_method); >>> c.callit(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; TypeError: void ::call_abstract_method(Abstract* a) =>; TypeError: takes at least 1 arguments (0 given); >>> c.callit(c); called Concrete::abstract_method; >>>. `Static methods`; ----------------. Class static functions are treated the same way as free functions, except; that they are accessible either through the class or through an instance,; just like Python's ``staticmethod``. `Instance methods`; ------------------. For class methods, see the :ref:`methods section <sec-methods-label>` under; the :doc:`classes heading<classes>`. `Lambda's`; ----------. C++ lambda functions are supported by first binding to a ``std::function``,; then providing a proxy to that on the Python side.; Example::. >>> cppyy.cppdef(""""""\; ... auto create_lambda(int a) {; ... return [a](int b) { return a+b; };; ... }""""""); True; >>> l = cppyy.gbl.create_lambda(4); >>> type(l); <class cppyy.gbl.std.function<int(int)> at 0x11505b830>; >>> l(2); 6; >>> . `Operators`; -----------. Globally defined operators are found lazily (ie. can resolve after the class; definition by loading the global definition or by defining them interactively); and are mapped onto a Python equivalent when possible.; See the :ref:`operators section <sec-operators-label>` under the; :doc:`classes heading<classes>` for more det",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/functions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst:11921,Security,validat,validation,11921,"uint8_t) {}""); True; >>> cppyy.gbl.somefunc(2**16); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; ValueError: void ::somefunc(uint8_t) =>; ValueError: could not convert argument 1 (integer to character: value 65536 not in range [0,255]); >>>. But if other overloads are present that fail in a different way, the error; report will be a ``TypeError``:. .. code-block:: python. >>> cppyy.cppdef(r""""""; ... void somefunc(uint8_t) {}; ... void somefunc(std::string) {}""""""); True; >>> cppyy.gbl.somefunc(2**16); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; TypeError: none of the 2 overloaded methods succeeded. Full details:; void ::somefunc(std::string) =>; TypeError: could not convert argument 1; void ::somefunc(uint8_t) =>; ValueError: could not convert argument 1 (integer to character: value 65536 not in range [0,255]); >>>. Since C++ exceptions are converted to Python ones, there is an interplay; possible between the two as part of overload resolution and ``cppyy``; allows C++ exceptions as such, enabling detailed type disambiguation and; input validation.; (The original use case was for filling database fields, requiring an exact; field label and data type match.). If, however, all methods fail and there is only one C++ exception (the other; exceptions originating from argument conversion, never succeeding to call; into C++), this C++ exception will be preferentially reported and will have; the original C++ type. `Return values`; ---------------. Most return types are readily amenable to automatic memory management: builtin; returns, by-value returns, (const-)reference returns to internal data, smart; pointers, etc.; The important exception is pointer returns.; ; A function that returns a pointer to an object over which Python should claim; ownership, should have its ``__creates__`` flag set through its; :doc:`pythonization <pythonizations>`.; Well-written APIs will have clear clues in their naming convention about the;",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/functions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst:12765,Usability,clear,clear,12765,"een the two as part of overload resolution and ``cppyy``; allows C++ exceptions as such, enabling detailed type disambiguation and; input validation.; (The original use case was for filling database fields, requiring an exact; field label and data type match.). If, however, all methods fail and there is only one C++ exception (the other; exceptions originating from argument conversion, never succeeding to call; into C++), this C++ exception will be preferentially reported and will have; the original C++ type. `Return values`; ---------------. Most return types are readily amenable to automatic memory management: builtin; returns, by-value returns, (const-)reference returns to internal data, smart; pointers, etc.; The important exception is pointer returns.; ; A function that returns a pointer to an object over which Python should claim; ownership, should have its ``__creates__`` flag set through its; :doc:`pythonization <pythonizations>`.; Well-written APIs will have clear clues in their naming convention about the; ownership rules.; For example, functions called ``New...``, ``Clone...``, etc. can be expected; to return freshly allocated objects.; A basic name-matching in the pythonization then makes it simple to mark all; these functions as creators. The return values are :ref:`auto-casted <sec-auto-casting-label>`. `\*args and \*\*kwds`; ---------------------. C++ default arguments work as expected.; Keywords, however, are a Python language feature that does not exist in C++.; Many C++ function declarations do have formal arguments, but these are not; part of the C++ interface (the argument names are repeated in the definition,; making the names in the declaration irrelevant: they do not even need to be; provided).; Thus, although ``cppyy`` will map keyword argument names to formal argument; names from the C++ declaration, use of this feature is not recommended unless; you have a guarantee that the names in C++ the interface are maintained.; Example:. .. code-bloc",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/functions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst:13006,Usability,simpl,simple,13006,"an exact; field label and data type match.). If, however, all methods fail and there is only one C++ exception (the other; exceptions originating from argument conversion, never succeeding to call; into C++), this C++ exception will be preferentially reported and will have; the original C++ type. `Return values`; ---------------. Most return types are readily amenable to automatic memory management: builtin; returns, by-value returns, (const-)reference returns to internal data, smart; pointers, etc.; The important exception is pointer returns.; ; A function that returns a pointer to an object over which Python should claim; ownership, should have its ``__creates__`` flag set through its; :doc:`pythonization <pythonizations>`.; Well-written APIs will have clear clues in their naming convention about the; ownership rules.; For example, functions called ``New...``, ``Clone...``, etc. can be expected; to return freshly allocated objects.; A basic name-matching in the pythonization then makes it simple to mark all; these functions as creators. The return values are :ref:`auto-casted <sec-auto-casting-label>`. `\*args and \*\*kwds`; ---------------------. C++ default arguments work as expected.; Keywords, however, are a Python language feature that does not exist in C++.; Many C++ function declarations do have formal arguments, but these are not; part of the C++ interface (the argument names are repeated in the definition,; making the names in the declaration irrelevant: they do not even need to be; provided).; Thus, although ``cppyy`` will map keyword argument names to formal argument; names from the C++ declaration, use of this feature is not recommended unless; you have a guarantee that the names in C++ the interface are maintained.; Example:. .. code-block:: python. >>> from cppyy.gbl import Concrete; >>> c = Concrete() # uses default argument; >>> c.m_int; 42; >>> c = Concrete(13) # uses provided argument; >>> c.m_int; 13; >>> args = (27,); >>> c = Concrete(*args) # a",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/functions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst:15734,Usability,simpl,simply,15734,"efault argument; >>> c.m_int; 42; >>> c = Concrete(13) # uses provided argument; >>> c.m_int; 13; >>> args = (27,); >>> c = Concrete(*args) # argument pack; >>> c.m_int; 27; >>> c = Concrete(n=17); >>> c.m_int; 17; >>> kwds = {'n' : 18}; >>> c = Concrete(**kwds); >>> c.m_int; 18; >>>. `Callbacks`; -----------. Python callables (functions/lambdas/instances) can be passed to C++ through; function pointers and/or ``std::function``.; This involves creation of a temporary wrapper, which has the same life time as; the Python callable it wraps, so the callable needs to be kept alive on the; Python side if the C++ side stores the callback.; Example:. .. code-block:: python. >>> from cppyy.gbl import call_int_int; >>> print(call_int_int.__doc__); int ::call_int_int(int(*)(int,int) f, int i1, int i2); >>> def add(a, b):; ... return a+b; ...; >>> call_int_int(add, 3, 7); 7; >>> call_int_int(lambda x, y: x*y, 3, 7); 21; >>>. Python functions can be used to instantiate C++ templates, assuming the; type information of the arguments and return types can be inferred.; If this can not be done directly from the template arguments, then it can; be provided through Python annotations, by explicitly adding the; ``__annotations__`` special data member (e.g. for older versions of Python; that do not support annotations), or by the function having been bound by; ``cppyy`` in the first place.; For example:. .. code-block:: python. >>> import cppyy; >>> cppyy.cppdef(""""""\; ... template<typename R, typename... U, typename... A>; ... R callT(R(*f)(U...), A&&... a) {; ... return f(a...);; ... }""""""); True; >>> def f(a: 'int') -> 'double':; ... return 3.1415*a; ...; >>> cppyy.gbl.callT(f, 2); 6.283; >>> def f(a: 'int', b: 'int') -> 'int':; ... return 3*a*b; ...; >>> cppyy.gbl.callT(f, 6, 7); 126; >>>. `extern ""C""`; ------------. Functions with C linkage are supported and are simply represented as; overloads of a single function.; Such functions are allowed both globally as well as in namespaces.; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/functions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/functions.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/history.rst:629,Deployability,release,released,629,".. _history:. History; =======. .. toctree::; :hidden:. What is now called `cppyy` started life as `RootPython` from `CERN`_, but; cppyy is not associated with CERN (it is still used there, however,; underpinning `PyROOT`_). Back in late 2002, Pere Mato of CERN, had the idea of using the `CINT`_ C++; interpreter, which formed the interactive interface to `ROOT`_, to call from; Python into C++: this became RootPython.; This binder interfaced with Python through `boost.python`_ (v1), transpiling; Python code into C++ and interpreting the result with CINT.; In early 2003, I ported this code to boost.python v2, then recently released.; In practice, however, re-interpreting the transpiled code was unusably slow,; thus I modified the code to make direct use of CINT's internal reflection; system, gaining about 25x in performance.; I presented this work as `PyROOT` at the ROOT Users' Workshop in early 2004,; and, after removing the boost.python dependency by using the C-API directly; (gaining another factor 7 in speedup!), it was included in ROOT.; PyROOT was presented at the SciPy'06 conference, but was otherwise not; advocated outside of High Energy Physics (HEP). In 2010, the PyPy core developers and I held a `sprint at CERN`_ to use; `Reflex`, a standalone alternative to CINT's reflection of C++, to add; automatic C++ bindings, PyROOT-style, to `PyPy`_.; This is where the name ""cppyy"" originated.; Coined by Carl Friedrich Bolz, if you want to understand the meaning, just; pronounce it slowly: cpp-y-y. After the ROOT team replaced CINT with `Cling`_, PyROOT soon followed.; As part of Google's Summer of Code '16, Aditi Dutta moved PyPy/cppyy to Cling; as well, and packaged the code for use through `PyPI`_.; I continued this integration with the Python eco-system by forking PyROOT,; reducing its dependencies, and repackaging it as CPython/cppyy.; The combined result is the current cppyy project.; Mid 2018, version 1.0 was released. .. _`CERN`: https://cern.ch/; .. _`PyROOT`",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/history.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/history.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/history.rst:1748,Deployability,integrat,integration,1748,"on`_ (v1), transpiling; Python code into C++ and interpreting the result with CINT.; In early 2003, I ported this code to boost.python v2, then recently released.; In practice, however, re-interpreting the transpiled code was unusably slow,; thus I modified the code to make direct use of CINT's internal reflection; system, gaining about 25x in performance.; I presented this work as `PyROOT` at the ROOT Users' Workshop in early 2004,; and, after removing the boost.python dependency by using the C-API directly; (gaining another factor 7 in speedup!), it was included in ROOT.; PyROOT was presented at the SciPy'06 conference, but was otherwise not; advocated outside of High Energy Physics (HEP). In 2010, the PyPy core developers and I held a `sprint at CERN`_ to use; `Reflex`, a standalone alternative to CINT's reflection of C++, to add; automatic C++ bindings, PyROOT-style, to `PyPy`_.; This is where the name ""cppyy"" originated.; Coined by Carl Friedrich Bolz, if you want to understand the meaning, just; pronounce it slowly: cpp-y-y. After the ROOT team replaced CINT with `Cling`_, PyROOT soon followed.; As part of Google's Summer of Code '16, Aditi Dutta moved PyPy/cppyy to Cling; as well, and packaged the code for use through `PyPI`_.; I continued this integration with the Python eco-system by forking PyROOT,; reducing its dependencies, and repackaging it as CPython/cppyy.; The combined result is the current cppyy project.; Mid 2018, version 1.0 was released. .. _`CERN`: https://cern.ch/; .. _`PyROOT`: https://root.cern.ch/root/htmldoc/guides/users-guide/ROOTUsersGuide.html#python-interface; .. _`CINT`: https://en.wikipedia.org/wiki/CINT; .. _`ROOT`: https://root.cern.ch; .. _`boost.python`: https://wiki.python.org/moin/boost.python/GettingStarted; .. _`sprint at CERN`: https://morepypy.blogspot.com/2010/07/cern-sprint-report-wrapping-c-libraries.html; .. _`PyPy`: https://www.pypy.org/; .. _`Cling`: https://github.com/vgvassilev/cling; .. _`PyPI`: https://pypi.org/; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/history.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/history.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/history.rst:1949,Deployability,release,released,1949,"on`_ (v1), transpiling; Python code into C++ and interpreting the result with CINT.; In early 2003, I ported this code to boost.python v2, then recently released.; In practice, however, re-interpreting the transpiled code was unusably slow,; thus I modified the code to make direct use of CINT's internal reflection; system, gaining about 25x in performance.; I presented this work as `PyROOT` at the ROOT Users' Workshop in early 2004,; and, after removing the boost.python dependency by using the C-API directly; (gaining another factor 7 in speedup!), it was included in ROOT.; PyROOT was presented at the SciPy'06 conference, but was otherwise not; advocated outside of High Energy Physics (HEP). In 2010, the PyPy core developers and I held a `sprint at CERN`_ to use; `Reflex`, a standalone alternative to CINT's reflection of C++, to add; automatic C++ bindings, PyROOT-style, to `PyPy`_.; This is where the name ""cppyy"" originated.; Coined by Carl Friedrich Bolz, if you want to understand the meaning, just; pronounce it slowly: cpp-y-y. After the ROOT team replaced CINT with `Cling`_, PyROOT soon followed.; As part of Google's Summer of Code '16, Aditi Dutta moved PyPy/cppyy to Cling; as well, and packaged the code for use through `PyPI`_.; I continued this integration with the Python eco-system by forking PyROOT,; reducing its dependencies, and repackaging it as CPython/cppyy.; The combined result is the current cppyy project.; Mid 2018, version 1.0 was released. .. _`CERN`: https://cern.ch/; .. _`PyROOT`: https://root.cern.ch/root/htmldoc/guides/users-guide/ROOTUsersGuide.html#python-interface; .. _`CINT`: https://en.wikipedia.org/wiki/CINT; .. _`ROOT`: https://root.cern.ch; .. _`boost.python`: https://wiki.python.org/moin/boost.python/GettingStarted; .. _`sprint at CERN`: https://morepypy.blogspot.com/2010/07/cern-sprint-report-wrapping-c-libraries.html; .. _`PyPy`: https://www.pypy.org/; .. _`Cling`: https://github.com/vgvassilev/cling; .. _`PyPI`: https://pypi.org/; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/history.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/history.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/history.rst:344,Integrability,interface,interface,344,".. _history:. History; =======. .. toctree::; :hidden:. What is now called `cppyy` started life as `RootPython` from `CERN`_, but; cppyy is not associated with CERN (it is still used there, however,; underpinning `PyROOT`_). Back in late 2002, Pere Mato of CERN, had the idea of using the `CINT`_ C++; interpreter, which formed the interactive interface to `ROOT`_, to call from; Python into C++: this became RootPython.; This binder interfaced with Python through `boost.python`_ (v1), transpiling; Python code into C++ and interpreting the result with CINT.; In early 2003, I ported this code to boost.python v2, then recently released.; In practice, however, re-interpreting the transpiled code was unusably slow,; thus I modified the code to make direct use of CINT's internal reflection; system, gaining about 25x in performance.; I presented this work as `PyROOT` at the ROOT Users' Workshop in early 2004,; and, after removing the boost.python dependency by using the C-API directly; (gaining another factor 7 in speedup!), it was included in ROOT.; PyROOT was presented at the SciPy'06 conference, but was otherwise not; advocated outside of High Energy Physics (HEP). In 2010, the PyPy core developers and I held a `sprint at CERN`_ to use; `Reflex`, a standalone alternative to CINT's reflection of C++, to add; automatic C++ bindings, PyROOT-style, to `PyPy`_.; This is where the name ""cppyy"" originated.; Coined by Carl Friedrich Bolz, if you want to understand the meaning, just; pronounce it slowly: cpp-y-y. After the ROOT team replaced CINT with `Cling`_, PyROOT soon followed.; As part of Google's Summer of Code '16, Aditi Dutta moved PyPy/cppyy to Cling; as well, and packaged the code for use through `PyPI`_.; I continued this integration with the Python eco-system by forking PyROOT,; reducing its dependencies, and repackaging it as CPython/cppyy.; The combined result is the current cppyy project.; Mid 2018, version 1.0 was released. .. _`CERN`: https://cern.ch/; .. _`PyROOT`",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/history.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/history.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/history.rst:434,Integrability,interface,interfaced,434,".. _history:. History; =======. .. toctree::; :hidden:. What is now called `cppyy` started life as `RootPython` from `CERN`_, but; cppyy is not associated with CERN (it is still used there, however,; underpinning `PyROOT`_). Back in late 2002, Pere Mato of CERN, had the idea of using the `CINT`_ C++; interpreter, which formed the interactive interface to `ROOT`_, to call from; Python into C++: this became RootPython.; This binder interfaced with Python through `boost.python`_ (v1), transpiling; Python code into C++ and interpreting the result with CINT.; In early 2003, I ported this code to boost.python v2, then recently released.; In practice, however, re-interpreting the transpiled code was unusably slow,; thus I modified the code to make direct use of CINT's internal reflection; system, gaining about 25x in performance.; I presented this work as `PyROOT` at the ROOT Users' Workshop in early 2004,; and, after removing the boost.python dependency by using the C-API directly; (gaining another factor 7 in speedup!), it was included in ROOT.; PyROOT was presented at the SciPy'06 conference, but was otherwise not; advocated outside of High Energy Physics (HEP). In 2010, the PyPy core developers and I held a `sprint at CERN`_ to use; `Reflex`, a standalone alternative to CINT's reflection of C++, to add; automatic C++ bindings, PyROOT-style, to `PyPy`_.; This is where the name ""cppyy"" originated.; Coined by Carl Friedrich Bolz, if you want to understand the meaning, just; pronounce it slowly: cpp-y-y. After the ROOT team replaced CINT with `Cling`_, PyROOT soon followed.; As part of Google's Summer of Code '16, Aditi Dutta moved PyPy/cppyy to Cling; as well, and packaged the code for use through `PyPI`_.; I continued this integration with the Python eco-system by forking PyROOT,; reducing its dependencies, and repackaging it as CPython/cppyy.; The combined result is the current cppyy project.; Mid 2018, version 1.0 was released. .. _`CERN`: https://cern.ch/; .. _`PyROOT`",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/history.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/history.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/history.rst:951,Integrability,depend,dependency,951,".. _history:. History; =======. .. toctree::; :hidden:. What is now called `cppyy` started life as `RootPython` from `CERN`_, but; cppyy is not associated with CERN (it is still used there, however,; underpinning `PyROOT`_). Back in late 2002, Pere Mato of CERN, had the idea of using the `CINT`_ C++; interpreter, which formed the interactive interface to `ROOT`_, to call from; Python into C++: this became RootPython.; This binder interfaced with Python through `boost.python`_ (v1), transpiling; Python code into C++ and interpreting the result with CINT.; In early 2003, I ported this code to boost.python v2, then recently released.; In practice, however, re-interpreting the transpiled code was unusably slow,; thus I modified the code to make direct use of CINT's internal reflection; system, gaining about 25x in performance.; I presented this work as `PyROOT` at the ROOT Users' Workshop in early 2004,; and, after removing the boost.python dependency by using the C-API directly; (gaining another factor 7 in speedup!), it was included in ROOT.; PyROOT was presented at the SciPy'06 conference, but was otherwise not; advocated outside of High Energy Physics (HEP). In 2010, the PyPy core developers and I held a `sprint at CERN`_ to use; `Reflex`, a standalone alternative to CINT's reflection of C++, to add; automatic C++ bindings, PyROOT-style, to `PyPy`_.; This is where the name ""cppyy"" originated.; Coined by Carl Friedrich Bolz, if you want to understand the meaning, just; pronounce it slowly: cpp-y-y. After the ROOT team replaced CINT with `Cling`_, PyROOT soon followed.; As part of Google's Summer of Code '16, Aditi Dutta moved PyPy/cppyy to Cling; as well, and packaged the code for use through `PyPI`_.; I continued this integration with the Python eco-system by forking PyROOT,; reducing its dependencies, and repackaging it as CPython/cppyy.; The combined result is the current cppyy project.; Mid 2018, version 1.0 was released. .. _`CERN`: https://cern.ch/; .. _`PyROOT`",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/history.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/history.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/history.rst:1748,Integrability,integrat,integration,1748,"on`_ (v1), transpiling; Python code into C++ and interpreting the result with CINT.; In early 2003, I ported this code to boost.python v2, then recently released.; In practice, however, re-interpreting the transpiled code was unusably slow,; thus I modified the code to make direct use of CINT's internal reflection; system, gaining about 25x in performance.; I presented this work as `PyROOT` at the ROOT Users' Workshop in early 2004,; and, after removing the boost.python dependency by using the C-API directly; (gaining another factor 7 in speedup!), it was included in ROOT.; PyROOT was presented at the SciPy'06 conference, but was otherwise not; advocated outside of High Energy Physics (HEP). In 2010, the PyPy core developers and I held a `sprint at CERN`_ to use; `Reflex`, a standalone alternative to CINT's reflection of C++, to add; automatic C++ bindings, PyROOT-style, to `PyPy`_.; This is where the name ""cppyy"" originated.; Coined by Carl Friedrich Bolz, if you want to understand the meaning, just; pronounce it slowly: cpp-y-y. After the ROOT team replaced CINT with `Cling`_, PyROOT soon followed.; As part of Google's Summer of Code '16, Aditi Dutta moved PyPy/cppyy to Cling; as well, and packaged the code for use through `PyPI`_.; I continued this integration with the Python eco-system by forking PyROOT,; reducing its dependencies, and repackaging it as CPython/cppyy.; The combined result is the current cppyy project.; Mid 2018, version 1.0 was released. .. _`CERN`: https://cern.ch/; .. _`PyROOT`: https://root.cern.ch/root/htmldoc/guides/users-guide/ROOTUsersGuide.html#python-interface; .. _`CINT`: https://en.wikipedia.org/wiki/CINT; .. _`ROOT`: https://root.cern.ch; .. _`boost.python`: https://wiki.python.org/moin/boost.python/GettingStarted; .. _`sprint at CERN`: https://morepypy.blogspot.com/2010/07/cern-sprint-report-wrapping-c-libraries.html; .. _`PyPy`: https://www.pypy.org/; .. _`Cling`: https://github.com/vgvassilev/cling; .. _`PyPI`: https://pypi.org/; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/history.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/history.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/history.rst:1820,Integrability,depend,dependencies,1820,"on`_ (v1), transpiling; Python code into C++ and interpreting the result with CINT.; In early 2003, I ported this code to boost.python v2, then recently released.; In practice, however, re-interpreting the transpiled code was unusably slow,; thus I modified the code to make direct use of CINT's internal reflection; system, gaining about 25x in performance.; I presented this work as `PyROOT` at the ROOT Users' Workshop in early 2004,; and, after removing the boost.python dependency by using the C-API directly; (gaining another factor 7 in speedup!), it was included in ROOT.; PyROOT was presented at the SciPy'06 conference, but was otherwise not; advocated outside of High Energy Physics (HEP). In 2010, the PyPy core developers and I held a `sprint at CERN`_ to use; `Reflex`, a standalone alternative to CINT's reflection of C++, to add; automatic C++ bindings, PyROOT-style, to `PyPy`_.; This is where the name ""cppyy"" originated.; Coined by Carl Friedrich Bolz, if you want to understand the meaning, just; pronounce it slowly: cpp-y-y. After the ROOT team replaced CINT with `Cling`_, PyROOT soon followed.; As part of Google's Summer of Code '16, Aditi Dutta moved PyPy/cppyy to Cling; as well, and packaged the code for use through `PyPI`_.; I continued this integration with the Python eco-system by forking PyROOT,; reducing its dependencies, and repackaging it as CPython/cppyy.; The combined result is the current cppyy project.; Mid 2018, version 1.0 was released. .. _`CERN`: https://cern.ch/; .. _`PyROOT`: https://root.cern.ch/root/htmldoc/guides/users-guide/ROOTUsersGuide.html#python-interface; .. _`CINT`: https://en.wikipedia.org/wiki/CINT; .. _`ROOT`: https://root.cern.ch; .. _`boost.python`: https://wiki.python.org/moin/boost.python/GettingStarted; .. _`sprint at CERN`: https://morepypy.blogspot.com/2010/07/cern-sprint-report-wrapping-c-libraries.html; .. _`PyPy`: https://www.pypy.org/; .. _`Cling`: https://github.com/vgvassilev/cling; .. _`PyPI`: https://pypi.org/; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/history.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/history.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/history.rst:2083,Integrability,interface,interface,2083,"on`_ (v1), transpiling; Python code into C++ and interpreting the result with CINT.; In early 2003, I ported this code to boost.python v2, then recently released.; In practice, however, re-interpreting the transpiled code was unusably slow,; thus I modified the code to make direct use of CINT's internal reflection; system, gaining about 25x in performance.; I presented this work as `PyROOT` at the ROOT Users' Workshop in early 2004,; and, after removing the boost.python dependency by using the C-API directly; (gaining another factor 7 in speedup!), it was included in ROOT.; PyROOT was presented at the SciPy'06 conference, but was otherwise not; advocated outside of High Energy Physics (HEP). In 2010, the PyPy core developers and I held a `sprint at CERN`_ to use; `Reflex`, a standalone alternative to CINT's reflection of C++, to add; automatic C++ bindings, PyROOT-style, to `PyPy`_.; This is where the name ""cppyy"" originated.; Coined by Carl Friedrich Bolz, if you want to understand the meaning, just; pronounce it slowly: cpp-y-y. After the ROOT team replaced CINT with `Cling`_, PyROOT soon followed.; As part of Google's Summer of Code '16, Aditi Dutta moved PyPy/cppyy to Cling; as well, and packaged the code for use through `PyPI`_.; I continued this integration with the Python eco-system by forking PyROOT,; reducing its dependencies, and repackaging it as CPython/cppyy.; The combined result is the current cppyy project.; Mid 2018, version 1.0 was released. .. _`CERN`: https://cern.ch/; .. _`PyROOT`: https://root.cern.ch/root/htmldoc/guides/users-guide/ROOTUsersGuide.html#python-interface; .. _`CINT`: https://en.wikipedia.org/wiki/CINT; .. _`ROOT`: https://root.cern.ch; .. _`boost.python`: https://wiki.python.org/moin/boost.python/GettingStarted; .. _`sprint at CERN`: https://morepypy.blogspot.com/2010/07/cern-sprint-report-wrapping-c-libraries.html; .. _`PyPy`: https://www.pypy.org/; .. _`Cling`: https://github.com/vgvassilev/cling; .. _`PyPI`: https://pypi.org/; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/history.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/history.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/history.rst:2333,Integrability,wrap,wrapping-c-libraries,2333,"on`_ (v1), transpiling; Python code into C++ and interpreting the result with CINT.; In early 2003, I ported this code to boost.python v2, then recently released.; In practice, however, re-interpreting the transpiled code was unusably slow,; thus I modified the code to make direct use of CINT's internal reflection; system, gaining about 25x in performance.; I presented this work as `PyROOT` at the ROOT Users' Workshop in early 2004,; and, after removing the boost.python dependency by using the C-API directly; (gaining another factor 7 in speedup!), it was included in ROOT.; PyROOT was presented at the SciPy'06 conference, but was otherwise not; advocated outside of High Energy Physics (HEP). In 2010, the PyPy core developers and I held a `sprint at CERN`_ to use; `Reflex`, a standalone alternative to CINT's reflection of C++, to add; automatic C++ bindings, PyROOT-style, to `PyPy`_.; This is where the name ""cppyy"" originated.; Coined by Carl Friedrich Bolz, if you want to understand the meaning, just; pronounce it slowly: cpp-y-y. After the ROOT team replaced CINT with `Cling`_, PyROOT soon followed.; As part of Google's Summer of Code '16, Aditi Dutta moved PyPy/cppyy to Cling; as well, and packaged the code for use through `PyPI`_.; I continued this integration with the Python eco-system by forking PyROOT,; reducing its dependencies, and repackaging it as CPython/cppyy.; The combined result is the current cppyy project.; Mid 2018, version 1.0 was released. .. _`CERN`: https://cern.ch/; .. _`PyROOT`: https://root.cern.ch/root/htmldoc/guides/users-guide/ROOTUsersGuide.html#python-interface; .. _`CINT`: https://en.wikipedia.org/wiki/CINT; .. _`ROOT`: https://root.cern.ch; .. _`boost.python`: https://wiki.python.org/moin/boost.python/GettingStarted; .. _`sprint at CERN`: https://morepypy.blogspot.com/2010/07/cern-sprint-report-wrapping-c-libraries.html; .. _`PyPy`: https://www.pypy.org/; .. _`Cling`: https://github.com/vgvassilev/cling; .. _`PyPI`: https://pypi.org/; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/history.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/history.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/history.rst:822,Performance,perform,performance,822,".. _history:. History; =======. .. toctree::; :hidden:. What is now called `cppyy` started life as `RootPython` from `CERN`_, but; cppyy is not associated with CERN (it is still used there, however,; underpinning `PyROOT`_). Back in late 2002, Pere Mato of CERN, had the idea of using the `CINT`_ C++; interpreter, which formed the interactive interface to `ROOT`_, to call from; Python into C++: this became RootPython.; This binder interfaced with Python through `boost.python`_ (v1), transpiling; Python code into C++ and interpreting the result with CINT.; In early 2003, I ported this code to boost.python v2, then recently released.; In practice, however, re-interpreting the transpiled code was unusably slow,; thus I modified the code to make direct use of CINT's internal reflection; system, gaining about 25x in performance.; I presented this work as `PyROOT` at the ROOT Users' Workshop in early 2004,; and, after removing the boost.python dependency by using the C-API directly; (gaining another factor 7 in speedup!), it was included in ROOT.; PyROOT was presented at the SciPy'06 conference, but was otherwise not; advocated outside of High Energy Physics (HEP). In 2010, the PyPy core developers and I held a `sprint at CERN`_ to use; `Reflex`, a standalone alternative to CINT's reflection of C++, to add; automatic C++ bindings, PyROOT-style, to `PyPy`_.; This is where the name ""cppyy"" originated.; Coined by Carl Friedrich Bolz, if you want to understand the meaning, just; pronounce it slowly: cpp-y-y. After the ROOT team replaced CINT with `Cling`_, PyROOT soon followed.; As part of Google's Summer of Code '16, Aditi Dutta moved PyPy/cppyy to Cling; as well, and packaged the code for use through `PyPI`_.; I continued this integration with the Python eco-system by forking PyROOT,; reducing its dependencies, and repackaging it as CPython/cppyy.; The combined result is the current cppyy project.; Mid 2018, version 1.0 was released. .. _`CERN`: https://cern.ch/; .. _`PyROOT`",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/history.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/history.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/history.rst:2037,Usability,guid,guides,2037,"on`_ (v1), transpiling; Python code into C++ and interpreting the result with CINT.; In early 2003, I ported this code to boost.python v2, then recently released.; In practice, however, re-interpreting the transpiled code was unusably slow,; thus I modified the code to make direct use of CINT's internal reflection; system, gaining about 25x in performance.; I presented this work as `PyROOT` at the ROOT Users' Workshop in early 2004,; and, after removing the boost.python dependency by using the C-API directly; (gaining another factor 7 in speedup!), it was included in ROOT.; PyROOT was presented at the SciPy'06 conference, but was otherwise not; advocated outside of High Energy Physics (HEP). In 2010, the PyPy core developers and I held a `sprint at CERN`_ to use; `Reflex`, a standalone alternative to CINT's reflection of C++, to add; automatic C++ bindings, PyROOT-style, to `PyPy`_.; This is where the name ""cppyy"" originated.; Coined by Carl Friedrich Bolz, if you want to understand the meaning, just; pronounce it slowly: cpp-y-y. After the ROOT team replaced CINT with `Cling`_, PyROOT soon followed.; As part of Google's Summer of Code '16, Aditi Dutta moved PyPy/cppyy to Cling; as well, and packaged the code for use through `PyPI`_.; I continued this integration with the Python eco-system by forking PyROOT,; reducing its dependencies, and repackaging it as CPython/cppyy.; The combined result is the current cppyy project.; Mid 2018, version 1.0 was released. .. _`CERN`: https://cern.ch/; .. _`PyROOT`: https://root.cern.ch/root/htmldoc/guides/users-guide/ROOTUsersGuide.html#python-interface; .. _`CINT`: https://en.wikipedia.org/wiki/CINT; .. _`ROOT`: https://root.cern.ch; .. _`boost.python`: https://wiki.python.org/moin/boost.python/GettingStarted; .. _`sprint at CERN`: https://morepypy.blogspot.com/2010/07/cern-sprint-report-wrapping-c-libraries.html; .. _`PyPy`: https://www.pypy.org/; .. _`Cling`: https://github.com/vgvassilev/cling; .. _`PyPI`: https://pypi.org/; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/history.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/history.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/history.rst:2050,Usability,guid,guide,2050,"on`_ (v1), transpiling; Python code into C++ and interpreting the result with CINT.; In early 2003, I ported this code to boost.python v2, then recently released.; In practice, however, re-interpreting the transpiled code was unusably slow,; thus I modified the code to make direct use of CINT's internal reflection; system, gaining about 25x in performance.; I presented this work as `PyROOT` at the ROOT Users' Workshop in early 2004,; and, after removing the boost.python dependency by using the C-API directly; (gaining another factor 7 in speedup!), it was included in ROOT.; PyROOT was presented at the SciPy'06 conference, but was otherwise not; advocated outside of High Energy Physics (HEP). In 2010, the PyPy core developers and I held a `sprint at CERN`_ to use; `Reflex`, a standalone alternative to CINT's reflection of C++, to add; automatic C++ bindings, PyROOT-style, to `PyPy`_.; This is where the name ""cppyy"" originated.; Coined by Carl Friedrich Bolz, if you want to understand the meaning, just; pronounce it slowly: cpp-y-y. After the ROOT team replaced CINT with `Cling`_, PyROOT soon followed.; As part of Google's Summer of Code '16, Aditi Dutta moved PyPy/cppyy to Cling; as well, and packaged the code for use through `PyPI`_.; I continued this integration with the Python eco-system by forking PyROOT,; reducing its dependencies, and repackaging it as CPython/cppyy.; The combined result is the current cppyy project.; Mid 2018, version 1.0 was released. .. _`CERN`: https://cern.ch/; .. _`PyROOT`: https://root.cern.ch/root/htmldoc/guides/users-guide/ROOTUsersGuide.html#python-interface; .. _`CINT`: https://en.wikipedia.org/wiki/CINT; .. _`ROOT`: https://root.cern.ch; .. _`boost.python`: https://wiki.python.org/moin/boost.python/GettingStarted; .. _`sprint at CERN`: https://morepypy.blogspot.com/2010/07/cern-sprint-report-wrapping-c-libraries.html; .. _`PyPy`: https://www.pypy.org/; .. _`Cling`: https://github.com/vgvassilev/cling; .. _`PyPI`: https://pypi.org/; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/history.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/history.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/index.rst:936,Availability,down,downcasting,936,".. cppyy documentation master file, created by; sphinx-quickstart on Wed Jul 12 14:35:45 2017.; You can adapt this file completely to your liking, but it should at least; contain the root `toctree` directive. .. meta::; :description: cppyy: Automatic Python-C++ bindings; :keywords: Python, C++, llvm, cling, binding, bindings, automatic bindings, bindings generator, cross-language inheritance, calling C++ from Python, calling Python from C++, high performance, data science. cppyy: Automatic Python-C++ bindings; ====================================. cppyy is an automatic, run-time, Python-C++ bindings generator, for calling; C++ from Python and Python from C++.; Run-time generation enables detailed specialization for higher performance,; lazy loading for reduced memory use in large scale projects, Python-side; cross-inheritance and callbacks for working with C++ frameworks, run-time; template instantiation, automatic object downcasting, exception mapping, and; interactive exploration of C++ libraries.; cppyy delivers this without any language extensions, intermediate languages,; or the need for boiler-plate hand-written code.; For design and performance, see this `PyHPC'16 paper`_, albeit that the; CPython/cppyy performance has been vastly improved since, as well as this; `CAAS presentation`_.; For a quick teaser, see `Jason Turner's`_ introduction video. cppyy is based on `Cling`_, the C++ interpreter, to match Python's dynamism,; interactivity, and run-time behavior.; Consider this session, showing dynamic, interactive, mixing of C++ and Python; features (there are more examples throughout the documentation and in the; `tutorial`_):. .. code-block:: python. >>> import cppyy; >>> cppyy.cppdef(""""""; ... class MyClass {; ... public:; ... MyClass(int i) : m_data(i) {}; ... virtual ~MyClass() {}; ... virtual int add_int(int i) { return m_data + i; }; ... int m_data;; ... };""""""); True; >>> from cppyy.gbl import MyClass; >>> m = MyClass(42); >>> cppyy.cppdef(""""""; ... void sa",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/index.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/index.rst:4257,Availability,avail,available,4257,"st[int](std.move(val)) # wrong cast; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; cppyy.gbl.boost.bad_any_cast: Could not instantiate any_cast<int>:; int boost::any_cast(boost::any&& operand) =>; wrapexcept<boost::bad_any_cast>: boost::bad_any_cast: failed conversion using boost::any_cast; >>> extract = boost.any_cast[std.vector[int]](val) # correct cast; >>> type(extract) is std.vector[int]; True; >>> extract += xrange(100); >>> len(extract); 100; >>> val.__assign__(std.move(extract)) # move forced; <cppyy.gbl.boost.any object at 0xf6a8a0>; >>> len(extract) # now empty (or invalid); 0; >>> extract = boost.any_cast[std.vector[int]](val); >>> list(extract); [0, 1, 2, 3, 4, 5, 6, ..., 97, 98, 99]; >>>. Of course, there is no reason to use Boost from Python (in fact, this example; calls out for :doc:`pythonizations <pythonizations>`), but it shows that; cppyy seamlessly supports many advanced C++ features. cppyy is available for both `CPython`_ (v2 and v3) and `PyPy`_, reaching; C++-like performance with the latter.; It makes judicious use of precompiled headers, dynamic loading, and lazy; instantiation, to support C++ programs consisting of millions of lines of; code and many thousands of classes.; cppyy minimizes dependencies to allow its use in distributed, heterogeneous,; development environments. .. _Cling: https://github.com/vgvassilev/cling; .. _tutorial: https://github.com/wlav/cppyy/blob/master/doc/tutorial/CppyyTutorial.ipynb; .. _`PyHPC'16 paper`: http://wlav.web.cern.ch/wlav/Cppyy_LavrijsenDutta_PyHPC16.pdf; .. _`CAAS presentation`: https://www.youtube.com/watch?v=stMD7VDWlVU; .. _`Jason Turner's`: https://www.youtube.com/watch?v=TL83P77vZ1k; .. _`Boost`: http://www.boost.org/; .. _`CPython`: http://python.org; .. _`PyPy`: http://pypy.org. .. only: not latex. Contents:. .. toctree::; :maxdepth: 1. changelog; license. .. toctree::; :caption: Getting Started; :maxdepth: 1. installation; starting; examples; bugs. .. toctree::; :capt",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/index.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/index.rst:3009,Deployability,install,installed,3009,"lo(MyClass* m) {; ... std::cout << ""Hello, the number is: "" << m->m_data << std::endl;; ... }""""""); True; >>> MyClass.say_hello = cppyy.gbl.say_hello; >>> m.say_hello(); Hello, the number is: 42; >>> m.m_data = 13; >>> m.say_hello(); Hello, the number is: 13; >>> class PyMyClass(MyClass):; ... def add_int(self, i): # python side override (CPython only); ... return self.m_data + 2*i; ...; >>> cppyy.cppdef(""int callback(MyClass* m, int i) { return m->add_int(i); }""); True; >>> cppyy.gbl.callback(m, 2) # calls C++ add_int; 15; >>> cppyy.gbl.callback(PyMyClass(1), 2) # calls Python-side override; 5; >>>. With a modern C++ compiler having its back, cppyy is future-proof.; Consider the following session using ``boost::any``, a capsule-type that; allows for heterogeneous containers in C++.; The `Boost`_ library is well known for its no holds barred use of modern C++; and heavy use of templates:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('boost/any.hpp') # assumes you have boost installed; >>> from cppyy.gbl import std, boost; >>> val = boost.any() # the capsule ; >>> val.__assign__(std.vector[int]()) # assign it a std::vector<int>; <cppyy.gbl.boost.any object at 0xf6a8a0>; >>> val.type() == cppyy.typeid(std.vector[int]) # verify type; True; >>> extract = boost.any_cast[int](std.move(val)) # wrong cast; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; cppyy.gbl.boost.bad_any_cast: Could not instantiate any_cast<int>:; int boost::any_cast(boost::any&& operand) =>; wrapexcept<boost::bad_any_cast>: boost::bad_any_cast: failed conversion using boost::any_cast; >>> extract = boost.any_cast[std.vector[int]](val) # correct cast; >>> type(extract) is std.vector[int]; True; >>> extract += xrange(100); >>> len(extract); 100; >>> val.__assign__(std.move(extract)) # move forced; <cppyy.gbl.boost.any object at 0xf6a8a0>; >>> len(extract) # now empty (or invalid); 0; >>> extract = boost.any_cast[std.vector[int]](val); >>> list(extract); [0, 1, 2, 3",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/index.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/index.rst:5244,Deployability,install,installation,5244,"xtract) # now empty (or invalid); 0; >>> extract = boost.any_cast[std.vector[int]](val); >>> list(extract); [0, 1, 2, 3, 4, 5, 6, ..., 97, 98, 99]; >>>. Of course, there is no reason to use Boost from Python (in fact, this example; calls out for :doc:`pythonizations <pythonizations>`), but it shows that; cppyy seamlessly supports many advanced C++ features. cppyy is available for both `CPython`_ (v2 and v3) and `PyPy`_, reaching; C++-like performance with the latter.; It makes judicious use of precompiled headers, dynamic loading, and lazy; instantiation, to support C++ programs consisting of millions of lines of; code and many thousands of classes.; cppyy minimizes dependencies to allow its use in distributed, heterogeneous,; development environments. .. _Cling: https://github.com/vgvassilev/cling; .. _tutorial: https://github.com/wlav/cppyy/blob/master/doc/tutorial/CppyyTutorial.ipynb; .. _`PyHPC'16 paper`: http://wlav.web.cern.ch/wlav/Cppyy_LavrijsenDutta_PyHPC16.pdf; .. _`CAAS presentation`: https://www.youtube.com/watch?v=stMD7VDWlVU; .. _`Jason Turner's`: https://www.youtube.com/watch?v=TL83P77vZ1k; .. _`Boost`: http://www.boost.org/; .. _`CPython`: http://python.org; .. _`PyPy`: http://pypy.org. .. only: not latex. Contents:. .. toctree::; :maxdepth: 1. changelog; license. .. toctree::; :caption: Getting Started; :maxdepth: 1. installation; starting; examples; bugs. .. toctree::; :caption: Features; :maxdepth: 1. toplevel; basic_types; strings; classes; functions; type_conversions; stl; exceptions; python; numba; cuda; lowlevel; misc; debugging. .. toctree::; :caption: Redistribution; :maxdepth: 1. pythonizations; utilities; cmake_interface. .. toctree::; :caption: Developers; :maxdepth: 1. packages; repositories; testing. .. toctree::; :caption: Background; :maxdepth: 1. history; philosophy. Bugs and feedback; -----------------. Please report bugs or requests for improvement on the `issue tracker`_. .. _`issue tracker`: https://github.com/wlav/cppyy/issues; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/index.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/index.rst:104,Energy Efficiency,adapt,adapt,104,".. cppyy documentation master file, created by; sphinx-quickstart on Wed Jul 12 14:35:45 2017.; You can adapt this file completely to your liking, but it should at least; contain the root `toctree` directive. .. meta::; :description: cppyy: Automatic Python-C++ bindings; :keywords: Python, C++, llvm, cling, binding, bindings, automatic bindings, bindings generator, cross-language inheritance, calling C++ from Python, calling Python from C++, high performance, data science. cppyy: Automatic Python-C++ bindings; ====================================. cppyy is an automatic, run-time, Python-C++ bindings generator, for calling; C++ from Python and Python from C++.; Run-time generation enables detailed specialization for higher performance,; lazy loading for reduced memory use in large scale projects, Python-side; cross-inheritance and callbacks for working with C++ frameworks, run-time; template instantiation, automatic object downcasting, exception mapping, and; interactive exploration of C++ libraries.; cppyy delivers this without any language extensions, intermediate languages,; or the need for boiler-plate hand-written code.; For design and performance, see this `PyHPC'16 paper`_, albeit that the; CPython/cppyy performance has been vastly improved since, as well as this; `CAAS presentation`_.; For a quick teaser, see `Jason Turner's`_ introduction video. cppyy is based on `Cling`_, the C++ interpreter, to match Python's dynamism,; interactivity, and run-time behavior.; Consider this session, showing dynamic, interactive, mixing of C++ and Python; features (there are more examples throughout the documentation and in the; `tutorial`_):. .. code-block:: python. >>> import cppyy; >>> cppyy.cppdef(""""""; ... class MyClass {; ... public:; ... MyClass(int i) : m_data(i) {}; ... virtual ~MyClass() {}; ... virtual int add_int(int i) { return m_data + i; }; ... int m_data;; ... };""""""); True; >>> from cppyy.gbl import MyClass; >>> m = MyClass(42); >>> cppyy.cppdef(""""""; ... void sa",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/index.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/index.rst:763,Energy Efficiency,reduce,reduced,763,".. cppyy documentation master file, created by; sphinx-quickstart on Wed Jul 12 14:35:45 2017.; You can adapt this file completely to your liking, but it should at least; contain the root `toctree` directive. .. meta::; :description: cppyy: Automatic Python-C++ bindings; :keywords: Python, C++, llvm, cling, binding, bindings, automatic bindings, bindings generator, cross-language inheritance, calling C++ from Python, calling Python from C++, high performance, data science. cppyy: Automatic Python-C++ bindings; ====================================. cppyy is an automatic, run-time, Python-C++ bindings generator, for calling; C++ from Python and Python from C++.; Run-time generation enables detailed specialization for higher performance,; lazy loading for reduced memory use in large scale projects, Python-side; cross-inheritance and callbacks for working with C++ frameworks, run-time; template instantiation, automatic object downcasting, exception mapping, and; interactive exploration of C++ libraries.; cppyy delivers this without any language extensions, intermediate languages,; or the need for boiler-plate hand-written code.; For design and performance, see this `PyHPC'16 paper`_, albeit that the; CPython/cppyy performance has been vastly improved since, as well as this; `CAAS presentation`_.; For a quick teaser, see `Jason Turner's`_ introduction video. cppyy is based on `Cling`_, the C++ interpreter, to match Python's dynamism,; interactivity, and run-time behavior.; Consider this session, showing dynamic, interactive, mixing of C++ and Python; features (there are more examples throughout the documentation and in the; `tutorial`_):. .. code-block:: python. >>> import cppyy; >>> cppyy.cppdef(""""""; ... class MyClass {; ... public:; ... MyClass(int i) : m_data(i) {}; ... virtual ~MyClass() {}; ... virtual int add_int(int i) { return m_data + i; }; ... int m_data;; ... };""""""); True; >>> from cppyy.gbl import MyClass; >>> m = MyClass(42); >>> cppyy.cppdef(""""""; ... void sa",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/index.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/index.rst:3527,Integrability,wrap,wrapexcept,3527,">>> cppyy.gbl.callback(PyMyClass(1), 2) # calls Python-side override; 5; >>>. With a modern C++ compiler having its back, cppyy is future-proof.; Consider the following session using ``boost::any``, a capsule-type that; allows for heterogeneous containers in C++.; The `Boost`_ library is well known for its no holds barred use of modern C++; and heavy use of templates:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('boost/any.hpp') # assumes you have boost installed; >>> from cppyy.gbl import std, boost; >>> val = boost.any() # the capsule ; >>> val.__assign__(std.vector[int]()) # assign it a std::vector<int>; <cppyy.gbl.boost.any object at 0xf6a8a0>; >>> val.type() == cppyy.typeid(std.vector[int]) # verify type; True; >>> extract = boost.any_cast[int](std.move(val)) # wrong cast; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; cppyy.gbl.boost.bad_any_cast: Could not instantiate any_cast<int>:; int boost::any_cast(boost::any&& operand) =>; wrapexcept<boost::bad_any_cast>: boost::bad_any_cast: failed conversion using boost::any_cast; >>> extract = boost.any_cast[std.vector[int]](val) # correct cast; >>> type(extract) is std.vector[int]; True; >>> extract += xrange(100); >>> len(extract); 100; >>> val.__assign__(std.move(extract)) # move forced; <cppyy.gbl.boost.any object at 0xf6a8a0>; >>> len(extract) # now empty (or invalid); 0; >>> extract = boost.any_cast[std.vector[int]](val); >>> list(extract); [0, 1, 2, 3, 4, 5, 6, ..., 97, 98, 99]; >>>. Of course, there is no reason to use Boost from Python (in fact, this example; calls out for :doc:`pythonizations <pythonizations>`), but it shows that; cppyy seamlessly supports many advanced C++ features. cppyy is available for both `CPython`_ (v2 and v3) and `PyPy`_, reaching; C++-like performance with the latter.; It makes judicious use of precompiled headers, dynamic loading, and lazy; instantiation, to support C++ programs consisting of millions of lines of; code and many thousands of",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/index.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/index.rst:4563,Integrability,depend,dependencies,4563,"n using boost::any_cast; >>> extract = boost.any_cast[std.vector[int]](val) # correct cast; >>> type(extract) is std.vector[int]; True; >>> extract += xrange(100); >>> len(extract); 100; >>> val.__assign__(std.move(extract)) # move forced; <cppyy.gbl.boost.any object at 0xf6a8a0>; >>> len(extract) # now empty (or invalid); 0; >>> extract = boost.any_cast[std.vector[int]](val); >>> list(extract); [0, 1, 2, 3, 4, 5, 6, ..., 97, 98, 99]; >>>. Of course, there is no reason to use Boost from Python (in fact, this example; calls out for :doc:`pythonizations <pythonizations>`), but it shows that; cppyy seamlessly supports many advanced C++ features. cppyy is available for both `CPython`_ (v2 and v3) and `PyPy`_, reaching; C++-like performance with the latter.; It makes judicious use of precompiled headers, dynamic loading, and lazy; instantiation, to support C++ programs consisting of millions of lines of; code and many thousands of classes.; cppyy minimizes dependencies to allow its use in distributed, heterogeneous,; development environments. .. _Cling: https://github.com/vgvassilev/cling; .. _tutorial: https://github.com/wlav/cppyy/blob/master/doc/tutorial/CppyyTutorial.ipynb; .. _`PyHPC'16 paper`: http://wlav.web.cern.ch/wlav/Cppyy_LavrijsenDutta_PyHPC16.pdf; .. _`CAAS presentation`: https://www.youtube.com/watch?v=stMD7VDWlVU; .. _`Jason Turner's`: https://www.youtube.com/watch?v=TL83P77vZ1k; .. _`Boost`: http://www.boost.org/; .. _`CPython`: http://python.org; .. _`PyPy`: http://pypy.org. .. only: not latex. Contents:. .. toctree::; :maxdepth: 1. changelog; license. .. toctree::; :caption: Getting Started; :maxdepth: 1. installation; starting; examples; bugs. .. toctree::; :caption: Features; :maxdepth: 1. toplevel; basic_types; strings; classes; functions; type_conversions; stl; exceptions; python; numba; cuda; lowlevel; misc; debugging. .. toctree::; :caption: Redistribution; :maxdepth: 1. pythonizations; utilities; cmake_interface. .. toctree::; :caption: Developer",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/index.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/index.rst:104,Modifiability,adapt,adapt,104,".. cppyy documentation master file, created by; sphinx-quickstart on Wed Jul 12 14:35:45 2017.; You can adapt this file completely to your liking, but it should at least; contain the root `toctree` directive. .. meta::; :description: cppyy: Automatic Python-C++ bindings; :keywords: Python, C++, llvm, cling, binding, bindings, automatic bindings, bindings generator, cross-language inheritance, calling C++ from Python, calling Python from C++, high performance, data science. cppyy: Automatic Python-C++ bindings; ====================================. cppyy is an automatic, run-time, Python-C++ bindings generator, for calling; C++ from Python and Python from C++.; Run-time generation enables detailed specialization for higher performance,; lazy loading for reduced memory use in large scale projects, Python-side; cross-inheritance and callbacks for working with C++ frameworks, run-time; template instantiation, automatic object downcasting, exception mapping, and; interactive exploration of C++ libraries.; cppyy delivers this without any language extensions, intermediate languages,; or the need for boiler-plate hand-written code.; For design and performance, see this `PyHPC'16 paper`_, albeit that the; CPython/cppyy performance has been vastly improved since, as well as this; `CAAS presentation`_.; For a quick teaser, see `Jason Turner's`_ introduction video. cppyy is based on `Cling`_, the C++ interpreter, to match Python's dynamism,; interactivity, and run-time behavior.; Consider this session, showing dynamic, interactive, mixing of C++ and Python; features (there are more examples throughout the documentation and in the; `tutorial`_):. .. code-block:: python. >>> import cppyy; >>> cppyy.cppdef(""""""; ... class MyClass {; ... public:; ... MyClass(int i) : m_data(i) {}; ... virtual ~MyClass() {}; ... virtual int add_int(int i) { return m_data + i; }; ... int m_data;; ... };""""""); True; >>> from cppyy.gbl import MyClass; >>> m = MyClass(42); >>> cppyy.cppdef(""""""; ... void sa",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/index.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/index.rst:383,Modifiability,inherit,inheritance,383,".. cppyy documentation master file, created by; sphinx-quickstart on Wed Jul 12 14:35:45 2017.; You can adapt this file completely to your liking, but it should at least; contain the root `toctree` directive. .. meta::; :description: cppyy: Automatic Python-C++ bindings; :keywords: Python, C++, llvm, cling, binding, bindings, automatic bindings, bindings generator, cross-language inheritance, calling C++ from Python, calling Python from C++, high performance, data science. cppyy: Automatic Python-C++ bindings; ====================================. cppyy is an automatic, run-time, Python-C++ bindings generator, for calling; C++ from Python and Python from C++.; Run-time generation enables detailed specialization for higher performance,; lazy loading for reduced memory use in large scale projects, Python-side; cross-inheritance and callbacks for working with C++ frameworks, run-time; template instantiation, automatic object downcasting, exception mapping, and; interactive exploration of C++ libraries.; cppyy delivers this without any language extensions, intermediate languages,; or the need for boiler-plate hand-written code.; For design and performance, see this `PyHPC'16 paper`_, albeit that the; CPython/cppyy performance has been vastly improved since, as well as this; `CAAS presentation`_.; For a quick teaser, see `Jason Turner's`_ introduction video. cppyy is based on `Cling`_, the C++ interpreter, to match Python's dynamism,; interactivity, and run-time behavior.; Consider this session, showing dynamic, interactive, mixing of C++ and Python; features (there are more examples throughout the documentation and in the; `tutorial`_):. .. code-block:: python. >>> import cppyy; >>> cppyy.cppdef(""""""; ... class MyClass {; ... public:; ... MyClass(int i) : m_data(i) {}; ... virtual ~MyClass() {}; ... virtual int add_int(int i) { return m_data + i; }; ... int m_data;; ... };""""""); True; >>> from cppyy.gbl import MyClass; >>> m = MyClass(42); >>> cppyy.cppdef(""""""; ... void sa",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/index.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/index.rst:826,Modifiability,inherit,inheritance,826,".. cppyy documentation master file, created by; sphinx-quickstart on Wed Jul 12 14:35:45 2017.; You can adapt this file completely to your liking, but it should at least; contain the root `toctree` directive. .. meta::; :description: cppyy: Automatic Python-C++ bindings; :keywords: Python, C++, llvm, cling, binding, bindings, automatic bindings, bindings generator, cross-language inheritance, calling C++ from Python, calling Python from C++, high performance, data science. cppyy: Automatic Python-C++ bindings; ====================================. cppyy is an automatic, run-time, Python-C++ bindings generator, for calling; C++ from Python and Python from C++.; Run-time generation enables detailed specialization for higher performance,; lazy loading for reduced memory use in large scale projects, Python-side; cross-inheritance and callbacks for working with C++ frameworks, run-time; template instantiation, automatic object downcasting, exception mapping, and; interactive exploration of C++ libraries.; cppyy delivers this without any language extensions, intermediate languages,; or the need for boiler-plate hand-written code.; For design and performance, see this `PyHPC'16 paper`_, albeit that the; CPython/cppyy performance has been vastly improved since, as well as this; `CAAS presentation`_.; For a quick teaser, see `Jason Turner's`_ introduction video. cppyy is based on `Cling`_, the C++ interpreter, to match Python's dynamism,; interactivity, and run-time behavior.; Consider this session, showing dynamic, interactive, mixing of C++ and Python; features (there are more examples throughout the documentation and in the; `tutorial`_):. .. code-block:: python. >>> import cppyy; >>> cppyy.cppdef(""""""; ... class MyClass {; ... public:; ... MyClass(int i) : m_data(i) {}; ... virtual ~MyClass() {}; ... virtual int add_int(int i) { return m_data + i; }; ... int m_data;; ... };""""""); True; >>> from cppyy.gbl import MyClass; >>> m = MyClass(42); >>> cppyy.cppdef(""""""; ... void sa",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/index.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/index.rst:451,Performance,perform,performance,451,".. cppyy documentation master file, created by; sphinx-quickstart on Wed Jul 12 14:35:45 2017.; You can adapt this file completely to your liking, but it should at least; contain the root `toctree` directive. .. meta::; :description: cppyy: Automatic Python-C++ bindings; :keywords: Python, C++, llvm, cling, binding, bindings, automatic bindings, bindings generator, cross-language inheritance, calling C++ from Python, calling Python from C++, high performance, data science. cppyy: Automatic Python-C++ bindings; ====================================. cppyy is an automatic, run-time, Python-C++ bindings generator, for calling; C++ from Python and Python from C++.; Run-time generation enables detailed specialization for higher performance,; lazy loading for reduced memory use in large scale projects, Python-side; cross-inheritance and callbacks for working with C++ frameworks, run-time; template instantiation, automatic object downcasting, exception mapping, and; interactive exploration of C++ libraries.; cppyy delivers this without any language extensions, intermediate languages,; or the need for boiler-plate hand-written code.; For design and performance, see this `PyHPC'16 paper`_, albeit that the; CPython/cppyy performance has been vastly improved since, as well as this; `CAAS presentation`_.; For a quick teaser, see `Jason Turner's`_ introduction video. cppyy is based on `Cling`_, the C++ interpreter, to match Python's dynamism,; interactivity, and run-time behavior.; Consider this session, showing dynamic, interactive, mixing of C++ and Python; features (there are more examples throughout the documentation and in the; `tutorial`_):. .. code-block:: python. >>> import cppyy; >>> cppyy.cppdef(""""""; ... class MyClass {; ... public:; ... MyClass(int i) : m_data(i) {}; ... virtual ~MyClass() {}; ... virtual int add_int(int i) { return m_data + i; }; ... int m_data;; ... };""""""); True; >>> from cppyy.gbl import MyClass; >>> m = MyClass(42); >>> cppyy.cppdef(""""""; ... void sa",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/index.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/index.rst:732,Performance,perform,performance,732,".. cppyy documentation master file, created by; sphinx-quickstart on Wed Jul 12 14:35:45 2017.; You can adapt this file completely to your liking, but it should at least; contain the root `toctree` directive. .. meta::; :description: cppyy: Automatic Python-C++ bindings; :keywords: Python, C++, llvm, cling, binding, bindings, automatic bindings, bindings generator, cross-language inheritance, calling C++ from Python, calling Python from C++, high performance, data science. cppyy: Automatic Python-C++ bindings; ====================================. cppyy is an automatic, run-time, Python-C++ bindings generator, for calling; C++ from Python and Python from C++.; Run-time generation enables detailed specialization for higher performance,; lazy loading for reduced memory use in large scale projects, Python-side; cross-inheritance and callbacks for working with C++ frameworks, run-time; template instantiation, automatic object downcasting, exception mapping, and; interactive exploration of C++ libraries.; cppyy delivers this without any language extensions, intermediate languages,; or the need for boiler-plate hand-written code.; For design and performance, see this `PyHPC'16 paper`_, albeit that the; CPython/cppyy performance has been vastly improved since, as well as this; `CAAS presentation`_.; For a quick teaser, see `Jason Turner's`_ introduction video. cppyy is based on `Cling`_, the C++ interpreter, to match Python's dynamism,; interactivity, and run-time behavior.; Consider this session, showing dynamic, interactive, mixing of C++ and Python; features (there are more examples throughout the documentation and in the; `tutorial`_):. .. code-block:: python. >>> import cppyy; >>> cppyy.cppdef(""""""; ... class MyClass {; ... public:; ... MyClass(int i) : m_data(i) {}; ... virtual ~MyClass() {}; ... virtual int add_int(int i) { return m_data + i; }; ... int m_data;; ... };""""""); True; >>> from cppyy.gbl import MyClass; >>> m = MyClass(42); >>> cppyy.cppdef(""""""; ... void sa",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/index.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/index.rst:751,Performance,load,loading,751,".. cppyy documentation master file, created by; sphinx-quickstart on Wed Jul 12 14:35:45 2017.; You can adapt this file completely to your liking, but it should at least; contain the root `toctree` directive. .. meta::; :description: cppyy: Automatic Python-C++ bindings; :keywords: Python, C++, llvm, cling, binding, bindings, automatic bindings, bindings generator, cross-language inheritance, calling C++ from Python, calling Python from C++, high performance, data science. cppyy: Automatic Python-C++ bindings; ====================================. cppyy is an automatic, run-time, Python-C++ bindings generator, for calling; C++ from Python and Python from C++.; Run-time generation enables detailed specialization for higher performance,; lazy loading for reduced memory use in large scale projects, Python-side; cross-inheritance and callbacks for working with C++ frameworks, run-time; template instantiation, automatic object downcasting, exception mapping, and; interactive exploration of C++ libraries.; cppyy delivers this without any language extensions, intermediate languages,; or the need for boiler-plate hand-written code.; For design and performance, see this `PyHPC'16 paper`_, albeit that the; CPython/cppyy performance has been vastly improved since, as well as this; `CAAS presentation`_.; For a quick teaser, see `Jason Turner's`_ introduction video. cppyy is based on `Cling`_, the C++ interpreter, to match Python's dynamism,; interactivity, and run-time behavior.; Consider this session, showing dynamic, interactive, mixing of C++ and Python; features (there are more examples throughout the documentation and in the; `tutorial`_):. .. code-block:: python. >>> import cppyy; >>> cppyy.cppdef(""""""; ... class MyClass {; ... public:; ... MyClass(int i) : m_data(i) {}; ... virtual ~MyClass() {}; ... virtual int add_int(int i) { return m_data + i; }; ... int m_data;; ... };""""""); True; >>> from cppyy.gbl import MyClass; >>> m = MyClass(42); >>> cppyy.cppdef(""""""; ... void sa",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/index.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/index.rst:1158,Performance,perform,performance,1158,"iption: cppyy: Automatic Python-C++ bindings; :keywords: Python, C++, llvm, cling, binding, bindings, automatic bindings, bindings generator, cross-language inheritance, calling C++ from Python, calling Python from C++, high performance, data science. cppyy: Automatic Python-C++ bindings; ====================================. cppyy is an automatic, run-time, Python-C++ bindings generator, for calling; C++ from Python and Python from C++.; Run-time generation enables detailed specialization for higher performance,; lazy loading for reduced memory use in large scale projects, Python-side; cross-inheritance and callbacks for working with C++ frameworks, run-time; template instantiation, automatic object downcasting, exception mapping, and; interactive exploration of C++ libraries.; cppyy delivers this without any language extensions, intermediate languages,; or the need for boiler-plate hand-written code.; For design and performance, see this `PyHPC'16 paper`_, albeit that the; CPython/cppyy performance has been vastly improved since, as well as this; `CAAS presentation`_.; For a quick teaser, see `Jason Turner's`_ introduction video. cppyy is based on `Cling`_, the C++ interpreter, to match Python's dynamism,; interactivity, and run-time behavior.; Consider this session, showing dynamic, interactive, mixing of C++ and Python; features (there are more examples throughout the documentation and in the; `tutorial`_):. .. code-block:: python. >>> import cppyy; >>> cppyy.cppdef(""""""; ... class MyClass {; ... public:; ... MyClass(int i) : m_data(i) {}; ... virtual ~MyClass() {}; ... virtual int add_int(int i) { return m_data + i; }; ... int m_data;; ... };""""""); True; >>> from cppyy.gbl import MyClass; >>> m = MyClass(42); >>> cppyy.cppdef(""""""; ... void say_hello(MyClass* m) {; ... std::cout << ""Hello, the number is: "" << m->m_data << std::endl;; ... }""""""); True; >>> MyClass.say_hello = cppyy.gbl.say_hello; >>> m.say_hello(); Hello, the number is: 42; >>> m.m_data = 13; >>> m.s",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/index.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/index.rst:1230,Performance,perform,performance,1230,"iption: cppyy: Automatic Python-C++ bindings; :keywords: Python, C++, llvm, cling, binding, bindings, automatic bindings, bindings generator, cross-language inheritance, calling C++ from Python, calling Python from C++, high performance, data science. cppyy: Automatic Python-C++ bindings; ====================================. cppyy is an automatic, run-time, Python-C++ bindings generator, for calling; C++ from Python and Python from C++.; Run-time generation enables detailed specialization for higher performance,; lazy loading for reduced memory use in large scale projects, Python-side; cross-inheritance and callbacks for working with C++ frameworks, run-time; template instantiation, automatic object downcasting, exception mapping, and; interactive exploration of C++ libraries.; cppyy delivers this without any language extensions, intermediate languages,; or the need for boiler-plate hand-written code.; For design and performance, see this `PyHPC'16 paper`_, albeit that the; CPython/cppyy performance has been vastly improved since, as well as this; `CAAS presentation`_.; For a quick teaser, see `Jason Turner's`_ introduction video. cppyy is based on `Cling`_, the C++ interpreter, to match Python's dynamism,; interactivity, and run-time behavior.; Consider this session, showing dynamic, interactive, mixing of C++ and Python; features (there are more examples throughout the documentation and in the; `tutorial`_):. .. code-block:: python. >>> import cppyy; >>> cppyy.cppdef(""""""; ... class MyClass {; ... public:; ... MyClass(int i) : m_data(i) {}; ... virtual ~MyClass() {}; ... virtual int add_int(int i) { return m_data + i; }; ... int m_data;; ... };""""""); True; >>> from cppyy.gbl import MyClass; >>> m = MyClass(42); >>> cppyy.cppdef(""""""; ... void say_hello(MyClass* m) {; ... std::cout << ""Hello, the number is: "" << m->m_data << std::endl;; ... }""""""); True; >>> MyClass.say_hello = cppyy.gbl.say_hello; >>> m.say_hello(); Hello, the number is: 42; >>> m.m_data = 13; >>> m.s",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/index.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/index.rst:4331,Performance,perform,performance,4331,"st[int](std.move(val)) # wrong cast; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; cppyy.gbl.boost.bad_any_cast: Could not instantiate any_cast<int>:; int boost::any_cast(boost::any&& operand) =>; wrapexcept<boost::bad_any_cast>: boost::bad_any_cast: failed conversion using boost::any_cast; >>> extract = boost.any_cast[std.vector[int]](val) # correct cast; >>> type(extract) is std.vector[int]; True; >>> extract += xrange(100); >>> len(extract); 100; >>> val.__assign__(std.move(extract)) # move forced; <cppyy.gbl.boost.any object at 0xf6a8a0>; >>> len(extract) # now empty (or invalid); 0; >>> extract = boost.any_cast[std.vector[int]](val); >>> list(extract); [0, 1, 2, 3, 4, 5, 6, ..., 97, 98, 99]; >>>. Of course, there is no reason to use Boost from Python (in fact, this example; calls out for :doc:`pythonizations <pythonizations>`), but it shows that; cppyy seamlessly supports many advanced C++ features. cppyy is available for both `CPython`_ (v2 and v3) and `PyPy`_, reaching; C++-like performance with the latter.; It makes judicious use of precompiled headers, dynamic loading, and lazy; instantiation, to support C++ programs consisting of millions of lines of; code and many thousands of classes.; cppyy minimizes dependencies to allow its use in distributed, heterogeneous,; development environments. .. _Cling: https://github.com/vgvassilev/cling; .. _tutorial: https://github.com/wlav/cppyy/blob/master/doc/tutorial/CppyyTutorial.ipynb; .. _`PyHPC'16 paper`: http://wlav.web.cern.ch/wlav/Cppyy_LavrijsenDutta_PyHPC16.pdf; .. _`CAAS presentation`: https://www.youtube.com/watch?v=stMD7VDWlVU; .. _`Jason Turner's`: https://www.youtube.com/watch?v=TL83P77vZ1k; .. _`Boost`: http://www.boost.org/; .. _`CPython`: http://python.org; .. _`PyPy`: http://pypy.org. .. only: not latex. Contents:. .. toctree::; :maxdepth: 1. changelog; license. .. toctree::; :caption: Getting Started; :maxdepth: 1. installation; starting; examples; bugs. .. toctree::; :capt",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/index.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/index.rst:4416,Performance,load,loading,4416," instantiate any_cast<int>:; int boost::any_cast(boost::any&& operand) =>; wrapexcept<boost::bad_any_cast>: boost::bad_any_cast: failed conversion using boost::any_cast; >>> extract = boost.any_cast[std.vector[int]](val) # correct cast; >>> type(extract) is std.vector[int]; True; >>> extract += xrange(100); >>> len(extract); 100; >>> val.__assign__(std.move(extract)) # move forced; <cppyy.gbl.boost.any object at 0xf6a8a0>; >>> len(extract) # now empty (or invalid); 0; >>> extract = boost.any_cast[std.vector[int]](val); >>> list(extract); [0, 1, 2, 3, 4, 5, 6, ..., 97, 98, 99]; >>>. Of course, there is no reason to use Boost from Python (in fact, this example; calls out for :doc:`pythonizations <pythonizations>`), but it shows that; cppyy seamlessly supports many advanced C++ features. cppyy is available for both `CPython`_ (v2 and v3) and `PyPy`_, reaching; C++-like performance with the latter.; It makes judicious use of precompiled headers, dynamic loading, and lazy; instantiation, to support C++ programs consisting of millions of lines of; code and many thousands of classes.; cppyy minimizes dependencies to allow its use in distributed, heterogeneous,; development environments. .. _Cling: https://github.com/vgvassilev/cling; .. _tutorial: https://github.com/wlav/cppyy/blob/master/doc/tutorial/CppyyTutorial.ipynb; .. _`PyHPC'16 paper`: http://wlav.web.cern.ch/wlav/Cppyy_LavrijsenDutta_PyHPC16.pdf; .. _`CAAS presentation`: https://www.youtube.com/watch?v=stMD7VDWlVU; .. _`Jason Turner's`: https://www.youtube.com/watch?v=TL83P77vZ1k; .. _`Boost`: http://www.boost.org/; .. _`CPython`: http://python.org; .. _`PyPy`: http://pypy.org. .. only: not latex. Contents:. .. toctree::; :maxdepth: 1. changelog; license. .. toctree::; :caption: Getting Started; :maxdepth: 1. installation; starting; examples; bugs. .. toctree::; :caption: Features; :maxdepth: 1. toplevel; basic_types; strings; classes; functions; type_conversions; stl; exceptions; python; numba; cuda; lowlevel; mi",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/index.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/index.rst:5639,Testability,test,testing,5639,"xtract) # now empty (or invalid); 0; >>> extract = boost.any_cast[std.vector[int]](val); >>> list(extract); [0, 1, 2, 3, 4, 5, 6, ..., 97, 98, 99]; >>>. Of course, there is no reason to use Boost from Python (in fact, this example; calls out for :doc:`pythonizations <pythonizations>`), but it shows that; cppyy seamlessly supports many advanced C++ features. cppyy is available for both `CPython`_ (v2 and v3) and `PyPy`_, reaching; C++-like performance with the latter.; It makes judicious use of precompiled headers, dynamic loading, and lazy; instantiation, to support C++ programs consisting of millions of lines of; code and many thousands of classes.; cppyy minimizes dependencies to allow its use in distributed, heterogeneous,; development environments. .. _Cling: https://github.com/vgvassilev/cling; .. _tutorial: https://github.com/wlav/cppyy/blob/master/doc/tutorial/CppyyTutorial.ipynb; .. _`PyHPC'16 paper`: http://wlav.web.cern.ch/wlav/Cppyy_LavrijsenDutta_PyHPC16.pdf; .. _`CAAS presentation`: https://www.youtube.com/watch?v=stMD7VDWlVU; .. _`Jason Turner's`: https://www.youtube.com/watch?v=TL83P77vZ1k; .. _`Boost`: http://www.boost.org/; .. _`CPython`: http://python.org; .. _`PyPy`: http://pypy.org. .. only: not latex. Contents:. .. toctree::; :maxdepth: 1. changelog; license. .. toctree::; :caption: Getting Started; :maxdepth: 1. installation; starting; examples; bugs. .. toctree::; :caption: Features; :maxdepth: 1. toplevel; basic_types; strings; classes; functions; type_conversions; stl; exceptions; python; numba; cuda; lowlevel; misc; debugging. .. toctree::; :caption: Redistribution; :maxdepth: 1. pythonizations; utilities; cmake_interface. .. toctree::; :caption: Developers; :maxdepth: 1. packages; repositories; testing. .. toctree::; :caption: Background; :maxdepth: 1. history; philosophy. Bugs and feedback; -----------------. Please report bugs or requests for improvement on the `issue tracker`_. .. _`issue tracker`: https://github.com/wlav/cppyy/issues; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/index.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/index.rst:5728,Usability,feedback,feedback,5728,"xtract) # now empty (or invalid); 0; >>> extract = boost.any_cast[std.vector[int]](val); >>> list(extract); [0, 1, 2, 3, 4, 5, 6, ..., 97, 98, 99]; >>>. Of course, there is no reason to use Boost from Python (in fact, this example; calls out for :doc:`pythonizations <pythonizations>`), but it shows that; cppyy seamlessly supports many advanced C++ features. cppyy is available for both `CPython`_ (v2 and v3) and `PyPy`_, reaching; C++-like performance with the latter.; It makes judicious use of precompiled headers, dynamic loading, and lazy; instantiation, to support C++ programs consisting of millions of lines of; code and many thousands of classes.; cppyy minimizes dependencies to allow its use in distributed, heterogeneous,; development environments. .. _Cling: https://github.com/vgvassilev/cling; .. _tutorial: https://github.com/wlav/cppyy/blob/master/doc/tutorial/CppyyTutorial.ipynb; .. _`PyHPC'16 paper`: http://wlav.web.cern.ch/wlav/Cppyy_LavrijsenDutta_PyHPC16.pdf; .. _`CAAS presentation`: https://www.youtube.com/watch?v=stMD7VDWlVU; .. _`Jason Turner's`: https://www.youtube.com/watch?v=TL83P77vZ1k; .. _`Boost`: http://www.boost.org/; .. _`CPython`: http://python.org; .. _`PyPy`: http://pypy.org. .. only: not latex. Contents:. .. toctree::; :maxdepth: 1. changelog; license. .. toctree::; :caption: Getting Started; :maxdepth: 1. installation; starting; examples; bugs. .. toctree::; :caption: Features; :maxdepth: 1. toplevel; basic_types; strings; classes; functions; type_conversions; stl; exceptions; python; numba; cuda; lowlevel; misc; debugging. .. toctree::; :caption: Redistribution; :maxdepth: 1. pythonizations; utilities; cmake_interface. .. toctree::; :caption: Developers; :maxdepth: 1. packages; repositories; testing. .. toctree::; :caption: Background; :maxdepth: 1. history; philosophy. Bugs and feedback; -----------------. Please report bugs or requests for improvement on the `issue tracker`_. .. _`issue tracker`: https://github.com/wlav/cppyy/issues; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/index.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:806,Availability,avail,available,806,".. _installation:. Installation; ============. cppyy requires a (modern) C++ compiler.; When installing through `conda-forge`_, ``conda`` will install the compiler; for you, to match the other conda-forge packages.; When using ``pip`` and the wheels from `PyPI`_, you minimally need gcc5,; clang5, or MSVC'17. .. note::. On Windows, a command prompt from which to run Python (or Python run; directly) needs to be opened from within an environment with MSVC setup,; otherwise the compiler will not be accessible. When installing from source, the only requirement is a compiler that supports; C++14, this in order to build LLVM. With CPython on Linux or MacOS, probably by far the easiest way to install; cppyy, is through conda-forge on `Anaconda`_ (or `miniconda`_).; A Windows recipe for ``conda`` is not available yet, but is forthcoming, so; use ``pip`` for that platform for now (see below).; PyPI always has the authoritative releases (conda-forge pulls the sources; from there), so conda-forge may sometimes lag PyPI.; If you absolutely need the latest release, use PyPI or consider; :ref:`building from source <building_from_source>`. To install using ``conda``, create and/or activate your (new) work environment; and install from the conda-forge channel::. $ conda create -n WORK; $ conda activate WORK; (WORK) $ conda install -c conda-forge cppyy; (WORK) [current compiler] $. To install with ``pip`` through `PyPI`_, use `venv`.; The use of virtual environment (`venv`) prevents pollution of any system directories and allows; you to wipe out the full installation simply by removing the virtual environment (`venv`); created directory (""WORK"" in this example)::. $ python -m venv WORK ; $ WORK\Scripts\activate; (WORK) $ python -m pip install cppyy; (WORK) $. .. note:: ; If you are using python version less than 3.3, you should use `virtualenv` instead of `venv`.; First install virtualenv package that allows you to create virtual environment. $ python -m pip install virtualenv . $ vir",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:2724,Availability,avail,available,2724," -m pip install cppyy; (WORK) $. .. note:: ; If you are using python version less than 3.3, you should use `virtualenv` instead of `venv`.; First install virtualenv package that allows you to create virtual environment. $ python -m pip install virtualenv . $ virtualenv WORK. $ source WORK/bin/activate. (WORK) $ python -m pip install cppyy. (WORK) $. If you use the ``--user`` option to ``pip`` and use ``pip`` directly on the; command line, instead of through ``python``, make sure that the ``PATH``; envar points to the bin directory that will contain the installed entry; points during the installation, as the build process needs them.; You may also need to install ``wheel`` first if you have an older version of; ``pip`` and/or do not use virtualenv (which installs wheel by default).; Example::. $ python -m pip install wheel --user; $ PATH=$HOME/.local/bin:$PATH python -m pip install cppyy --user. Wheels on PyPI; --------------. Wheels for the backend (``cppyy-cling``) are available on PyPI for GNU/Linux,; MacOS-X, and MS Windows (both 32b and 64b).; The Linux wheels are built for manylinux2014, but with the dual ABI enabled.; The wheels for MS Windows were build with MSVC Community Edition 2017. There are no wheels for the ``CPyCppyy`` and ``cppyy`` packages, to allow; the C++ standard chosen to match the local compiler. pip with conda; --------------. Although installing ``cppyy`` through `conda-forge`_ is recommended, it is; possible to build/install with ``pip`` under Anaconda/miniconda. Typical Python extensions only expose a C interface for use through the; Python C-API, requiring only calling conventions (and the Python C-API; version, of course) to match to be binary compatible.; Here, cppyy differs because it exposes C++ APIs: it thus requires a C++; run-time that is ABI compatible with the C++ compiler that was used during; build-time. A set of modern compilers is available through conda-forge, but are only; intended for use with ``conda-build``.; In particula",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:3643,Availability,avail,available,3643,"--------. Wheels for the backend (``cppyy-cling``) are available on PyPI for GNU/Linux,; MacOS-X, and MS Windows (both 32b and 64b).; The Linux wheels are built for manylinux2014, but with the dual ABI enabled.; The wheels for MS Windows were build with MSVC Community Edition 2017. There are no wheels for the ``CPyCppyy`` and ``cppyy`` packages, to allow; the C++ standard chosen to match the local compiler. pip with conda; --------------. Although installing ``cppyy`` through `conda-forge`_ is recommended, it is; possible to build/install with ``pip`` under Anaconda/miniconda. Typical Python extensions only expose a C interface for use through the; Python C-API, requiring only calling conventions (and the Python C-API; version, of course) to match to be binary compatible.; Here, cppyy differs because it exposes C++ APIs: it thus requires a C++; run-time that is ABI compatible with the C++ compiler that was used during; build-time. A set of modern compilers is available through conda-forge, but are only; intended for use with ``conda-build``.; In particular, the corresponding run-time is installed (for use through rpath; when building), but not set up.; That is, the conda compilers are added to ``PATH`` but not their libraries; to ``LD_LIBRARY_PATH`` (Mac, Linux; ``PATH`` for both on MS Windows).; Thus, you get the conda compilers and your system libraries mixed in the same; build environment, unless you set ``LD_LIBRARY_PATH`` (``PATH`` on Windows); explicitly, e.g. by adding ``$CONDA_PREFIX/lib``.; Note that the conda documentation recommends against this.; Furthermore, the compilers from conda-forge are not vanilla distributions:; header files have been modified, which can can lead to parsing problems if; your system C library does not support C11, for example. Nevertheless, with the above caveats, if your system C/C++ run-times are new; enough, the following can be made to work::. $ conda create -n WORK; $ conda activate WORK; (WORK) $ conda install python; (WORK)",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:5456,Availability,down,download,5456,"upport C11, for example. Nevertheless, with the above caveats, if your system C/C++ run-times are new; enough, the following can be made to work::. $ conda create -n WORK; $ conda activate WORK; (WORK) $ conda install python; (WORK) $ conda install -c conda-forge compilers; (WORK) [current compiler] $ python -m pip install cppyy. C++ standard with pip; ---------------------. The C++20 standard is the default on all systems as of release 3.0.1 (both; PyPI and conda-forge); it is C++17 for older releases.; When installing from PyPI using ``pip``, you can control the standard; selection by setting the ``STDCXX`` envar to '20', '17', or '14' (for Linux,; the backend does not need to be recompiled) for the 3.x releases; '17', '14',; or '11' for the 2.x releases.; Note that the build will automatically lower your choice if the compiler used; does not support a newer standard. Install from source; -------------------; .. _installation_from_source:. To build an existing release from source, tell ``pip`` to not download any; binary wheels.; Build-time only dependencies are ``cmake`` (for general build), ``python``; (obviously, but also for LLVM), and a modern C++ compiler (one that supports; at least C++14).; Use the envar ``STDCXX`` to control the C++ standard version; ``MAKE`` to; change the ``make`` command, ``MAKE_NPROCS`` to control the maximum number of; parallel jobs allowed, and ``VERBOSE=1`` to see full build/compile commands.; Example (using ``--verbose`` to see ``pip`` progress)::. $ STDCXX=17 MAKE_NPROCS=32 pip install --verbose cppyy --no-binary=cppyy-cling. Compilation of the backend, which contains a customized version of; Clang/LLVM, can take a long time, so by default the setup script will use all; cores (x2 if hyperthreading is enabled).; Once built, however, the wheel of ``cppyy-cling`` is reused by pip for all; versions of CPython and for PyPy, thus the long compilation is needed only; once for all different versions of Python on the same machine. See the ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:93,Deployability,install,installing,93,".. _installation:. Installation; ============. cppyy requires a (modern) C++ compiler.; When installing through `conda-forge`_, ``conda`` will install the compiler; for you, to match the other conda-forge packages.; When using ``pip`` and the wheels from `PyPI`_, you minimally need gcc5,; clang5, or MSVC'17. .. note::. On Windows, a command prompt from which to run Python (or Python run; directly) needs to be opened from within an environment with MSVC setup,; otherwise the compiler will not be accessible. When installing from source, the only requirement is a compiler that supports; C++14, this in order to build LLVM. With CPython on Linux or MacOS, probably by far the easiest way to install; cppyy, is through conda-forge on `Anaconda`_ (or `miniconda`_).; A Windows recipe for ``conda`` is not available yet, but is forthcoming, so; use ``pip`` for that platform for now (see below).; PyPI always has the authoritative releases (conda-forge pulls the sources; from there), so conda-forge may sometimes lag PyPI.; If you absolutely need the latest release, use PyPI or consider; :ref:`building from source <building_from_source>`. To install using ``conda``, create and/or activate your (new) work environment; and install from the conda-forge channel::. $ conda create -n WORK; $ conda activate WORK; (WORK) $ conda install -c conda-forge cppyy; (WORK) [current compiler] $. To install with ``pip`` through `PyPI`_, use `venv`.; The use of virtual environment (`venv`) prevents pollution of any system directories and allows; you to wipe out the full installation simply by removing the virtual environment (`venv`); created directory (""WORK"" in this example)::. $ python -m venv WORK ; $ WORK\Scripts\activate; (WORK) $ python -m pip install cppyy; (WORK) $. .. note:: ; If you are using python version less than 3.3, you should use `virtualenv` instead of `venv`.; First install virtualenv package that allows you to create virtual environment. $ python -m pip install virtualenv . $ vir",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:143,Deployability,install,install,143,".. _installation:. Installation; ============. cppyy requires a (modern) C++ compiler.; When installing through `conda-forge`_, ``conda`` will install the compiler; for you, to match the other conda-forge packages.; When using ``pip`` and the wheels from `PyPI`_, you minimally need gcc5,; clang5, or MSVC'17. .. note::. On Windows, a command prompt from which to run Python (or Python run; directly) needs to be opened from within an environment with MSVC setup,; otherwise the compiler will not be accessible. When installing from source, the only requirement is a compiler that supports; C++14, this in order to build LLVM. With CPython on Linux or MacOS, probably by far the easiest way to install; cppyy, is through conda-forge on `Anaconda`_ (or `miniconda`_).; A Windows recipe for ``conda`` is not available yet, but is forthcoming, so; use ``pip`` for that platform for now (see below).; PyPI always has the authoritative releases (conda-forge pulls the sources; from there), so conda-forge may sometimes lag PyPI.; If you absolutely need the latest release, use PyPI or consider; :ref:`building from source <building_from_source>`. To install using ``conda``, create and/or activate your (new) work environment; and install from the conda-forge channel::. $ conda create -n WORK; $ conda activate WORK; (WORK) $ conda install -c conda-forge cppyy; (WORK) [current compiler] $. To install with ``pip`` through `PyPI`_, use `venv`.; The use of virtual environment (`venv`) prevents pollution of any system directories and allows; you to wipe out the full installation simply by removing the virtual environment (`venv`); created directory (""WORK"" in this example)::. $ python -m venv WORK ; $ WORK\Scripts\activate; (WORK) $ python -m pip install cppyy; (WORK) $. .. note:: ; If you are using python version less than 3.3, you should use `virtualenv` instead of `venv`.; First install virtualenv package that allows you to create virtual environment. $ python -m pip install virtualenv . $ vir",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:517,Deployability,install,installing,517,".. _installation:. Installation; ============. cppyy requires a (modern) C++ compiler.; When installing through `conda-forge`_, ``conda`` will install the compiler; for you, to match the other conda-forge packages.; When using ``pip`` and the wheels from `PyPI`_, you minimally need gcc5,; clang5, or MSVC'17. .. note::. On Windows, a command prompt from which to run Python (or Python run; directly) needs to be opened from within an environment with MSVC setup,; otherwise the compiler will not be accessible. When installing from source, the only requirement is a compiler that supports; C++14, this in order to build LLVM. With CPython on Linux or MacOS, probably by far the easiest way to install; cppyy, is through conda-forge on `Anaconda`_ (or `miniconda`_).; A Windows recipe for ``conda`` is not available yet, but is forthcoming, so; use ``pip`` for that platform for now (see below).; PyPI always has the authoritative releases (conda-forge pulls the sources; from there), so conda-forge may sometimes lag PyPI.; If you absolutely need the latest release, use PyPI or consider; :ref:`building from source <building_from_source>`. To install using ``conda``, create and/or activate your (new) work environment; and install from the conda-forge channel::. $ conda create -n WORK; $ conda activate WORK; (WORK) $ conda install -c conda-forge cppyy; (WORK) [current compiler] $. To install with ``pip`` through `PyPI`_, use `venv`.; The use of virtual environment (`venv`) prevents pollution of any system directories and allows; you to wipe out the full installation simply by removing the virtual environment (`venv`); created directory (""WORK"" in this example)::. $ python -m venv WORK ; $ WORK\Scripts\activate; (WORK) $ python -m pip install cppyy; (WORK) $. .. note:: ; If you are using python version less than 3.3, you should use `virtualenv` instead of `venv`.; First install virtualenv package that allows you to create virtual environment. $ python -m pip install virtualenv . $ vir",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:694,Deployability,install,install,694,".. _installation:. Installation; ============. cppyy requires a (modern) C++ compiler.; When installing through `conda-forge`_, ``conda`` will install the compiler; for you, to match the other conda-forge packages.; When using ``pip`` and the wheels from `PyPI`_, you minimally need gcc5,; clang5, or MSVC'17. .. note::. On Windows, a command prompt from which to run Python (or Python run; directly) needs to be opened from within an environment with MSVC setup,; otherwise the compiler will not be accessible. When installing from source, the only requirement is a compiler that supports; C++14, this in order to build LLVM. With CPython on Linux or MacOS, probably by far the easiest way to install; cppyy, is through conda-forge on `Anaconda`_ (or `miniconda`_).; A Windows recipe for ``conda`` is not available yet, but is forthcoming, so; use ``pip`` for that platform for now (see below).; PyPI always has the authoritative releases (conda-forge pulls the sources; from there), so conda-forge may sometimes lag PyPI.; If you absolutely need the latest release, use PyPI or consider; :ref:`building from source <building_from_source>`. To install using ``conda``, create and/or activate your (new) work environment; and install from the conda-forge channel::. $ conda create -n WORK; $ conda activate WORK; (WORK) $ conda install -c conda-forge cppyy; (WORK) [current compiler] $. To install with ``pip`` through `PyPI`_, use `venv`.; The use of virtual environment (`venv`) prevents pollution of any system directories and allows; you to wipe out the full installation simply by removing the virtual environment (`venv`); created directory (""WORK"" in this example)::. $ python -m venv WORK ; $ WORK\Scripts\activate; (WORK) $ python -m pip install cppyy; (WORK) $. .. note:: ; If you are using python version less than 3.3, you should use `virtualenv` instead of `venv`.; First install virtualenv package that allows you to create virtual environment. $ python -m pip install virtualenv . $ vir",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:931,Deployability,release,releases,931,".. _installation:. Installation; ============. cppyy requires a (modern) C++ compiler.; When installing through `conda-forge`_, ``conda`` will install the compiler; for you, to match the other conda-forge packages.; When using ``pip`` and the wheels from `PyPI`_, you minimally need gcc5,; clang5, or MSVC'17. .. note::. On Windows, a command prompt from which to run Python (or Python run; directly) needs to be opened from within an environment with MSVC setup,; otherwise the compiler will not be accessible. When installing from source, the only requirement is a compiler that supports; C++14, this in order to build LLVM. With CPython on Linux or MacOS, probably by far the easiest way to install; cppyy, is through conda-forge on `Anaconda`_ (or `miniconda`_).; A Windows recipe for ``conda`` is not available yet, but is forthcoming, so; use ``pip`` for that platform for now (see below).; PyPI always has the authoritative releases (conda-forge pulls the sources; from there), so conda-forge may sometimes lag PyPI.; If you absolutely need the latest release, use PyPI or consider; :ref:`building from source <building_from_source>`. To install using ``conda``, create and/or activate your (new) work environment; and install from the conda-forge channel::. $ conda create -n WORK; $ conda activate WORK; (WORK) $ conda install -c conda-forge cppyy; (WORK) [current compiler] $. To install with ``pip`` through `PyPI`_, use `venv`.; The use of virtual environment (`venv`) prevents pollution of any system directories and allows; you to wipe out the full installation simply by removing the virtual environment (`venv`); created directory (""WORK"" in this example)::. $ python -m venv WORK ; $ WORK\Scripts\activate; (WORK) $ python -m pip install cppyy; (WORK) $. .. note:: ; If you are using python version less than 3.3, you should use `virtualenv` instead of `venv`.; First install virtualenv package that allows you to create virtual environment. $ python -m pip install virtualenv . $ vir",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:1059,Deployability,release,release,1059,"ler.; When installing through `conda-forge`_, ``conda`` will install the compiler; for you, to match the other conda-forge packages.; When using ``pip`` and the wheels from `PyPI`_, you minimally need gcc5,; clang5, or MSVC'17. .. note::. On Windows, a command prompt from which to run Python (or Python run; directly) needs to be opened from within an environment with MSVC setup,; otherwise the compiler will not be accessible. When installing from source, the only requirement is a compiler that supports; C++14, this in order to build LLVM. With CPython on Linux or MacOS, probably by far the easiest way to install; cppyy, is through conda-forge on `Anaconda`_ (or `miniconda`_).; A Windows recipe for ``conda`` is not available yet, but is forthcoming, so; use ``pip`` for that platform for now (see below).; PyPI always has the authoritative releases (conda-forge pulls the sources; from there), so conda-forge may sometimes lag PyPI.; If you absolutely need the latest release, use PyPI or consider; :ref:`building from source <building_from_source>`. To install using ``conda``, create and/or activate your (new) work environment; and install from the conda-forge channel::. $ conda create -n WORK; $ conda activate WORK; (WORK) $ conda install -c conda-forge cppyy; (WORK) [current compiler] $. To install with ``pip`` through `PyPI`_, use `venv`.; The use of virtual environment (`venv`) prevents pollution of any system directories and allows; you to wipe out the full installation simply by removing the virtual environment (`venv`); created directory (""WORK"" in this example)::. $ python -m venv WORK ; $ WORK\Scripts\activate; (WORK) $ python -m pip install cppyy; (WORK) $. .. note:: ; If you are using python version less than 3.3, you should use `virtualenv` instead of `venv`.; First install virtualenv package that allows you to create virtual environment. $ python -m pip install virtualenv . $ virtualenv WORK. $ source WORK/bin/activate. (WORK) $ python -m pip install cppyy. (",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:1145,Deployability,install,install,1145,"e packages.; When using ``pip`` and the wheels from `PyPI`_, you minimally need gcc5,; clang5, or MSVC'17. .. note::. On Windows, a command prompt from which to run Python (or Python run; directly) needs to be opened from within an environment with MSVC setup,; otherwise the compiler will not be accessible. When installing from source, the only requirement is a compiler that supports; C++14, this in order to build LLVM. With CPython on Linux or MacOS, probably by far the easiest way to install; cppyy, is through conda-forge on `Anaconda`_ (or `miniconda`_).; A Windows recipe for ``conda`` is not available yet, but is forthcoming, so; use ``pip`` for that platform for now (see below).; PyPI always has the authoritative releases (conda-forge pulls the sources; from there), so conda-forge may sometimes lag PyPI.; If you absolutely need the latest release, use PyPI or consider; :ref:`building from source <building_from_source>`. To install using ``conda``, create and/or activate your (new) work environment; and install from the conda-forge channel::. $ conda create -n WORK; $ conda activate WORK; (WORK) $ conda install -c conda-forge cppyy; (WORK) [current compiler] $. To install with ``pip`` through `PyPI`_, use `venv`.; The use of virtual environment (`venv`) prevents pollution of any system directories and allows; you to wipe out the full installation simply by removing the virtual environment (`venv`); created directory (""WORK"" in this example)::. $ python -m venv WORK ; $ WORK\Scripts\activate; (WORK) $ python -m pip install cppyy; (WORK) $. .. note:: ; If you are using python version less than 3.3, you should use `virtualenv` instead of `venv`.; First install virtualenv package that allows you to create virtual environment. $ python -m pip install virtualenv . $ virtualenv WORK. $ source WORK/bin/activate. (WORK) $ python -m pip install cppyy. (WORK) $. If you use the ``--user`` option to ``pip`` and use ``pip`` directly on the; command line, instead of through ``",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:1226,Deployability,install,install,1226,"e packages.; When using ``pip`` and the wheels from `PyPI`_, you minimally need gcc5,; clang5, or MSVC'17. .. note::. On Windows, a command prompt from which to run Python (or Python run; directly) needs to be opened from within an environment with MSVC setup,; otherwise the compiler will not be accessible. When installing from source, the only requirement is a compiler that supports; C++14, this in order to build LLVM. With CPython on Linux or MacOS, probably by far the easiest way to install; cppyy, is through conda-forge on `Anaconda`_ (or `miniconda`_).; A Windows recipe for ``conda`` is not available yet, but is forthcoming, so; use ``pip`` for that platform for now (see below).; PyPI always has the authoritative releases (conda-forge pulls the sources; from there), so conda-forge may sometimes lag PyPI.; If you absolutely need the latest release, use PyPI or consider; :ref:`building from source <building_from_source>`. To install using ``conda``, create and/or activate your (new) work environment; and install from the conda-forge channel::. $ conda create -n WORK; $ conda activate WORK; (WORK) $ conda install -c conda-forge cppyy; (WORK) [current compiler] $. To install with ``pip`` through `PyPI`_, use `venv`.; The use of virtual environment (`venv`) prevents pollution of any system directories and allows; you to wipe out the full installation simply by removing the virtual environment (`venv`); created directory (""WORK"" in this example)::. $ python -m venv WORK ; $ WORK\Scripts\activate; (WORK) $ python -m pip install cppyy; (WORK) $. .. note:: ; If you are using python version less than 3.3, you should use `virtualenv` instead of `venv`.; First install virtualenv package that allows you to create virtual environment. $ python -m pip install virtualenv . $ virtualenv WORK. $ source WORK/bin/activate. (WORK) $ python -m pip install cppyy. (WORK) $. If you use the ``--user`` option to ``pip`` and use ``pip`` directly on the; command line, instead of through ``",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:1328,Deployability,install,install,1328,"indows, a command prompt from which to run Python (or Python run; directly) needs to be opened from within an environment with MSVC setup,; otherwise the compiler will not be accessible. When installing from source, the only requirement is a compiler that supports; C++14, this in order to build LLVM. With CPython on Linux or MacOS, probably by far the easiest way to install; cppyy, is through conda-forge on `Anaconda`_ (or `miniconda`_).; A Windows recipe for ``conda`` is not available yet, but is forthcoming, so; use ``pip`` for that platform for now (see below).; PyPI always has the authoritative releases (conda-forge pulls the sources; from there), so conda-forge may sometimes lag PyPI.; If you absolutely need the latest release, use PyPI or consider; :ref:`building from source <building_from_source>`. To install using ``conda``, create and/or activate your (new) work environment; and install from the conda-forge channel::. $ conda create -n WORK; $ conda activate WORK; (WORK) $ conda install -c conda-forge cppyy; (WORK) [current compiler] $. To install with ``pip`` through `PyPI`_, use `venv`.; The use of virtual environment (`venv`) prevents pollution of any system directories and allows; you to wipe out the full installation simply by removing the virtual environment (`venv`); created directory (""WORK"" in this example)::. $ python -m venv WORK ; $ WORK\Scripts\activate; (WORK) $ python -m pip install cppyy; (WORK) $. .. note:: ; If you are using python version less than 3.3, you should use `virtualenv` instead of `venv`.; First install virtualenv package that allows you to create virtual environment. $ python -m pip install virtualenv . $ virtualenv WORK. $ source WORK/bin/activate. (WORK) $ python -m pip install cppyy. (WORK) $. If you use the ``--user`` option to ``pip`` and use ``pip`` directly on the; command line, instead of through ``python``, make sure that the ``PATH``; envar points to the bin directory that will contain the installed entry; points duri",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:1390,Deployability,install,install,1390," opened from within an environment with MSVC setup,; otherwise the compiler will not be accessible. When installing from source, the only requirement is a compiler that supports; C++14, this in order to build LLVM. With CPython on Linux or MacOS, probably by far the easiest way to install; cppyy, is through conda-forge on `Anaconda`_ (or `miniconda`_).; A Windows recipe for ``conda`` is not available yet, but is forthcoming, so; use ``pip`` for that platform for now (see below).; PyPI always has the authoritative releases (conda-forge pulls the sources; from there), so conda-forge may sometimes lag PyPI.; If you absolutely need the latest release, use PyPI or consider; :ref:`building from source <building_from_source>`. To install using ``conda``, create and/or activate your (new) work environment; and install from the conda-forge channel::. $ conda create -n WORK; $ conda activate WORK; (WORK) $ conda install -c conda-forge cppyy; (WORK) [current compiler] $. To install with ``pip`` through `PyPI`_, use `venv`.; The use of virtual environment (`venv`) prevents pollution of any system directories and allows; you to wipe out the full installation simply by removing the virtual environment (`venv`); created directory (""WORK"" in this example)::. $ python -m venv WORK ; $ WORK\Scripts\activate; (WORK) $ python -m pip install cppyy; (WORK) $. .. note:: ; If you are using python version less than 3.3, you should use `virtualenv` instead of `venv`.; First install virtualenv package that allows you to create virtual environment. $ python -m pip install virtualenv . $ virtualenv WORK. $ source WORK/bin/activate. (WORK) $ python -m pip install cppyy. (WORK) $. If you use the ``--user`` option to ``pip`` and use ``pip`` directly on the; command line, instead of through ``python``, make sure that the ``PATH``; envar points to the bin directory that will contain the installed entry; points during the installation, as the build process needs them.; You may also need to install ``w",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:1563,Deployability,install,installation,1563,"ement is a compiler that supports; C++14, this in order to build LLVM. With CPython on Linux or MacOS, probably by far the easiest way to install; cppyy, is through conda-forge on `Anaconda`_ (or `miniconda`_).; A Windows recipe for ``conda`` is not available yet, but is forthcoming, so; use ``pip`` for that platform for now (see below).; PyPI always has the authoritative releases (conda-forge pulls the sources; from there), so conda-forge may sometimes lag PyPI.; If you absolutely need the latest release, use PyPI or consider; :ref:`building from source <building_from_source>`. To install using ``conda``, create and/or activate your (new) work environment; and install from the conda-forge channel::. $ conda create -n WORK; $ conda activate WORK; (WORK) $ conda install -c conda-forge cppyy; (WORK) [current compiler] $. To install with ``pip`` through `PyPI`_, use `venv`.; The use of virtual environment (`venv`) prevents pollution of any system directories and allows; you to wipe out the full installation simply by removing the virtual environment (`venv`); created directory (""WORK"" in this example)::. $ python -m venv WORK ; $ WORK\Scripts\activate; (WORK) $ python -m pip install cppyy; (WORK) $. .. note:: ; If you are using python version less than 3.3, you should use `virtualenv` instead of `venv`.; First install virtualenv package that allows you to create virtual environment. $ python -m pip install virtualenv . $ virtualenv WORK. $ source WORK/bin/activate. (WORK) $ python -m pip install cppyy. (WORK) $. If you use the ``--user`` option to ``pip`` and use ``pip`` directly on the; command line, instead of through ``python``, make sure that the ``PATH``; envar points to the bin directory that will contain the installed entry; points during the installation, as the build process needs them.; You may also need to install ``wheel`` first if you have an older version of; ``pip`` and/or do not use virtualenv (which installs wheel by default).; Example::. $ python -m pi",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:1747,Deployability,install,install,1747,"onda-forge on `Anaconda`_ (or `miniconda`_).; A Windows recipe for ``conda`` is not available yet, but is forthcoming, so; use ``pip`` for that platform for now (see below).; PyPI always has the authoritative releases (conda-forge pulls the sources; from there), so conda-forge may sometimes lag PyPI.; If you absolutely need the latest release, use PyPI or consider; :ref:`building from source <building_from_source>`. To install using ``conda``, create and/or activate your (new) work environment; and install from the conda-forge channel::. $ conda create -n WORK; $ conda activate WORK; (WORK) $ conda install -c conda-forge cppyy; (WORK) [current compiler] $. To install with ``pip`` through `PyPI`_, use `venv`.; The use of virtual environment (`venv`) prevents pollution of any system directories and allows; you to wipe out the full installation simply by removing the virtual environment (`venv`); created directory (""WORK"" in this example)::. $ python -m venv WORK ; $ WORK\Scripts\activate; (WORK) $ python -m pip install cppyy; (WORK) $. .. note:: ; If you are using python version less than 3.3, you should use `virtualenv` instead of `venv`.; First install virtualenv package that allows you to create virtual environment. $ python -m pip install virtualenv . $ virtualenv WORK. $ source WORK/bin/activate. (WORK) $ python -m pip install cppyy. (WORK) $. If you use the ``--user`` option to ``pip`` and use ``pip`` directly on the; command line, instead of through ``python``, make sure that the ``PATH``; envar points to the bin directory that will contain the installed entry; points during the installation, as the build process needs them.; You may also need to install ``wheel`` first if you have an older version of; ``pip`` and/or do not use virtualenv (which installs wheel by default).; Example::. $ python -m pip install wheel --user; $ PATH=$HOME/.local/bin:$PATH python -m pip install cppyy --user. Wheels on PyPI; --------------. Wheels for the backend (``cppyy-cling``) are",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:1885,Deployability,install,install,1885,"authoritative releases (conda-forge pulls the sources; from there), so conda-forge may sometimes lag PyPI.; If you absolutely need the latest release, use PyPI or consider; :ref:`building from source <building_from_source>`. To install using ``conda``, create and/or activate your (new) work environment; and install from the conda-forge channel::. $ conda create -n WORK; $ conda activate WORK; (WORK) $ conda install -c conda-forge cppyy; (WORK) [current compiler] $. To install with ``pip`` through `PyPI`_, use `venv`.; The use of virtual environment (`venv`) prevents pollution of any system directories and allows; you to wipe out the full installation simply by removing the virtual environment (`venv`); created directory (""WORK"" in this example)::. $ python -m venv WORK ; $ WORK\Scripts\activate; (WORK) $ python -m pip install cppyy; (WORK) $. .. note:: ; If you are using python version less than 3.3, you should use `virtualenv` instead of `venv`.; First install virtualenv package that allows you to create virtual environment. $ python -m pip install virtualenv . $ virtualenv WORK. $ source WORK/bin/activate. (WORK) $ python -m pip install cppyy. (WORK) $. If you use the ``--user`` option to ``pip`` and use ``pip`` directly on the; command line, instead of through ``python``, make sure that the ``PATH``; envar points to the bin directory that will contain the installed entry; points during the installation, as the build process needs them.; You may also need to install ``wheel`` first if you have an older version of; ``pip`` and/or do not use virtualenv (which installs wheel by default).; Example::. $ python -m pip install wheel --user; $ PATH=$HOME/.local/bin:$PATH python -m pip install cppyy --user. Wheels on PyPI; --------------. Wheels for the backend (``cppyy-cling``) are available on PyPI for GNU/Linux,; MacOS-X, and MS Windows (both 32b and 64b).; The Linux wheels are built for manylinux2014, but with the dual ABI enabled.; The wheels for MS Windows were build ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:1975,Deployability,install,install,1975," there), so conda-forge may sometimes lag PyPI.; If you absolutely need the latest release, use PyPI or consider; :ref:`building from source <building_from_source>`. To install using ``conda``, create and/or activate your (new) work environment; and install from the conda-forge channel::. $ conda create -n WORK; $ conda activate WORK; (WORK) $ conda install -c conda-forge cppyy; (WORK) [current compiler] $. To install with ``pip`` through `PyPI`_, use `venv`.; The use of virtual environment (`venv`) prevents pollution of any system directories and allows; you to wipe out the full installation simply by removing the virtual environment (`venv`); created directory (""WORK"" in this example)::. $ python -m venv WORK ; $ WORK\Scripts\activate; (WORK) $ python -m pip install cppyy; (WORK) $. .. note:: ; If you are using python version less than 3.3, you should use `virtualenv` instead of `venv`.; First install virtualenv package that allows you to create virtual environment. $ python -m pip install virtualenv . $ virtualenv WORK. $ source WORK/bin/activate. (WORK) $ python -m pip install cppyy. (WORK) $. If you use the ``--user`` option to ``pip`` and use ``pip`` directly on the; command line, instead of through ``python``, make sure that the ``PATH``; envar points to the bin directory that will contain the installed entry; points during the installation, as the build process needs them.; You may also need to install ``wheel`` first if you have an older version of; ``pip`` and/or do not use virtualenv (which installs wheel by default).; Example::. $ python -m pip install wheel --user; $ PATH=$HOME/.local/bin:$PATH python -m pip install cppyy --user. Wheels on PyPI; --------------. Wheels for the backend (``cppyy-cling``) are available on PyPI for GNU/Linux,; MacOS-X, and MS Windows (both 32b and 64b).; The Linux wheels are built for manylinux2014, but with the dual ABI enabled.; The wheels for MS Windows were build with MSVC Community Edition 2017. There are no wheels for t",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:2066,Deployability,install,install,2066,"lease, use PyPI or consider; :ref:`building from source <building_from_source>`. To install using ``conda``, create and/or activate your (new) work environment; and install from the conda-forge channel::. $ conda create -n WORK; $ conda activate WORK; (WORK) $ conda install -c conda-forge cppyy; (WORK) [current compiler] $. To install with ``pip`` through `PyPI`_, use `venv`.; The use of virtual environment (`venv`) prevents pollution of any system directories and allows; you to wipe out the full installation simply by removing the virtual environment (`venv`); created directory (""WORK"" in this example)::. $ python -m venv WORK ; $ WORK\Scripts\activate; (WORK) $ python -m pip install cppyy; (WORK) $. .. note:: ; If you are using python version less than 3.3, you should use `virtualenv` instead of `venv`.; First install virtualenv package that allows you to create virtual environment. $ python -m pip install virtualenv . $ virtualenv WORK. $ source WORK/bin/activate. (WORK) $ python -m pip install cppyy. (WORK) $. If you use the ``--user`` option to ``pip`` and use ``pip`` directly on the; command line, instead of through ``python``, make sure that the ``PATH``; envar points to the bin directory that will contain the installed entry; points during the installation, as the build process needs them.; You may also need to install ``wheel`` first if you have an older version of; ``pip`` and/or do not use virtualenv (which installs wheel by default).; Example::. $ python -m pip install wheel --user; $ PATH=$HOME/.local/bin:$PATH python -m pip install cppyy --user. Wheels on PyPI; --------------. Wheels for the backend (``cppyy-cling``) are available on PyPI for GNU/Linux,; MacOS-X, and MS Windows (both 32b and 64b).; The Linux wheels are built for manylinux2014, but with the dual ABI enabled.; The wheels for MS Windows were build with MSVC Community Edition 2017. There are no wheels for the ``CPyCppyy`` and ``cppyy`` packages, to allow; the C++ standard chosen to match t",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:2298,Deployability,install,installed,2298,"from the conda-forge channel::. $ conda create -n WORK; $ conda activate WORK; (WORK) $ conda install -c conda-forge cppyy; (WORK) [current compiler] $. To install with ``pip`` through `PyPI`_, use `venv`.; The use of virtual environment (`venv`) prevents pollution of any system directories and allows; you to wipe out the full installation simply by removing the virtual environment (`venv`); created directory (""WORK"" in this example)::. $ python -m venv WORK ; $ WORK\Scripts\activate; (WORK) $ python -m pip install cppyy; (WORK) $. .. note:: ; If you are using python version less than 3.3, you should use `virtualenv` instead of `venv`.; First install virtualenv package that allows you to create virtual environment. $ python -m pip install virtualenv . $ virtualenv WORK. $ source WORK/bin/activate. (WORK) $ python -m pip install cppyy. (WORK) $. If you use the ``--user`` option to ``pip`` and use ``pip`` directly on the; command line, instead of through ``python``, make sure that the ``PATH``; envar points to the bin directory that will contain the installed entry; points during the installation, as the build process needs them.; You may also need to install ``wheel`` first if you have an older version of; ``pip`` and/or do not use virtualenv (which installs wheel by default).; Example::. $ python -m pip install wheel --user; $ PATH=$HOME/.local/bin:$PATH python -m pip install cppyy --user. Wheels on PyPI; --------------. Wheels for the backend (``cppyy-cling``) are available on PyPI for GNU/Linux,; MacOS-X, and MS Windows (both 32b and 64b).; The Linux wheels are built for manylinux2014, but with the dual ABI enabled.; The wheels for MS Windows were build with MSVC Community Edition 2017. There are no wheels for the ``CPyCppyy`` and ``cppyy`` packages, to allow; the C++ standard chosen to match the local compiler. pip with conda; --------------. Although installing ``cppyy`` through `conda-forge`_ is recommended, it is; possible to build/install with ``pip`` under An",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:2333,Deployability,install,installation,2333,"from the conda-forge channel::. $ conda create -n WORK; $ conda activate WORK; (WORK) $ conda install -c conda-forge cppyy; (WORK) [current compiler] $. To install with ``pip`` through `PyPI`_, use `venv`.; The use of virtual environment (`venv`) prevents pollution of any system directories and allows; you to wipe out the full installation simply by removing the virtual environment (`venv`); created directory (""WORK"" in this example)::. $ python -m venv WORK ; $ WORK\Scripts\activate; (WORK) $ python -m pip install cppyy; (WORK) $. .. note:: ; If you are using python version less than 3.3, you should use `virtualenv` instead of `venv`.; First install virtualenv package that allows you to create virtual environment. $ python -m pip install virtualenv . $ virtualenv WORK. $ source WORK/bin/activate. (WORK) $ python -m pip install cppyy. (WORK) $. If you use the ``--user`` option to ``pip`` and use ``pip`` directly on the; command line, instead of through ``python``, make sure that the ``PATH``; envar points to the bin directory that will contain the installed entry; points during the installation, as the build process needs them.; You may also need to install ``wheel`` first if you have an older version of; ``pip`` and/or do not use virtualenv (which installs wheel by default).; Example::. $ python -m pip install wheel --user; $ PATH=$HOME/.local/bin:$PATH python -m pip install cppyy --user. Wheels on PyPI; --------------. Wheels for the backend (``cppyy-cling``) are available on PyPI for GNU/Linux,; MacOS-X, and MS Windows (both 32b and 64b).; The Linux wheels are built for manylinux2014, but with the dual ABI enabled.; The wheels for MS Windows were build with MSVC Community Edition 2017. There are no wheels for the ``CPyCppyy`` and ``cppyy`` packages, to allow; the C++ standard chosen to match the local compiler. pip with conda; --------------. Although installing ``cppyy`` through `conda-forge`_ is recommended, it is; possible to build/install with ``pip`` under An",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:2402,Deployability,install,install,2402,"rtual environment (`venv`) prevents pollution of any system directories and allows; you to wipe out the full installation simply by removing the virtual environment (`venv`); created directory (""WORK"" in this example)::. $ python -m venv WORK ; $ WORK\Scripts\activate; (WORK) $ python -m pip install cppyy; (WORK) $. .. note:: ; If you are using python version less than 3.3, you should use `virtualenv` instead of `venv`.; First install virtualenv package that allows you to create virtual environment. $ python -m pip install virtualenv . $ virtualenv WORK. $ source WORK/bin/activate. (WORK) $ python -m pip install cppyy. (WORK) $. If you use the ``--user`` option to ``pip`` and use ``pip`` directly on the; command line, instead of through ``python``, make sure that the ``PATH``; envar points to the bin directory that will contain the installed entry; points during the installation, as the build process needs them.; You may also need to install ``wheel`` first if you have an older version of; ``pip`` and/or do not use virtualenv (which installs wheel by default).; Example::. $ python -m pip install wheel --user; $ PATH=$HOME/.local/bin:$PATH python -m pip install cppyy --user. Wheels on PyPI; --------------. Wheels for the backend (``cppyy-cling``) are available on PyPI for GNU/Linux,; MacOS-X, and MS Windows (both 32b and 64b).; The Linux wheels are built for manylinux2014, but with the dual ABI enabled.; The wheels for MS Windows were build with MSVC Community Edition 2017. There are no wheels for the ``CPyCppyy`` and ``cppyy`` packages, to allow; the C++ standard chosen to match the local compiler. pip with conda; --------------. Although installing ``cppyy`` through `conda-forge`_ is recommended, it is; possible to build/install with ``pip`` under Anaconda/miniconda. Typical Python extensions only expose a C interface for use through the; Python C-API, requiring only calling conventions (and the Python C-API; version, of course) to match to be binary compatible.; He",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:2503,Deployability,install,installs,2503,"rtual environment (`venv`) prevents pollution of any system directories and allows; you to wipe out the full installation simply by removing the virtual environment (`venv`); created directory (""WORK"" in this example)::. $ python -m venv WORK ; $ WORK\Scripts\activate; (WORK) $ python -m pip install cppyy; (WORK) $. .. note:: ; If you are using python version less than 3.3, you should use `virtualenv` instead of `venv`.; First install virtualenv package that allows you to create virtual environment. $ python -m pip install virtualenv . $ virtualenv WORK. $ source WORK/bin/activate. (WORK) $ python -m pip install cppyy. (WORK) $. If you use the ``--user`` option to ``pip`` and use ``pip`` directly on the; command line, instead of through ``python``, make sure that the ``PATH``; envar points to the bin directory that will contain the installed entry; points during the installation, as the build process needs them.; You may also need to install ``wheel`` first if you have an older version of; ``pip`` and/or do not use virtualenv (which installs wheel by default).; Example::. $ python -m pip install wheel --user; $ PATH=$HOME/.local/bin:$PATH python -m pip install cppyy --user. Wheels on PyPI; --------------. Wheels for the backend (``cppyy-cling``) are available on PyPI for GNU/Linux,; MacOS-X, and MS Windows (both 32b and 64b).; The Linux wheels are built for manylinux2014, but with the dual ABI enabled.; The wheels for MS Windows were build with MSVC Community Edition 2017. There are no wheels for the ``CPyCppyy`` and ``cppyy`` packages, to allow; the C++ standard chosen to match the local compiler. pip with conda; --------------. Although installing ``cppyy`` through `conda-forge`_ is recommended, it is; possible to build/install with ``pip`` under Anaconda/miniconda. Typical Python extensions only expose a C interface for use through the; Python C-API, requiring only calling conventions (and the Python C-API; version, of course) to match to be binary compatible.; He",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:2559,Deployability,install,install,2559,"llation simply by removing the virtual environment (`venv`); created directory (""WORK"" in this example)::. $ python -m venv WORK ; $ WORK\Scripts\activate; (WORK) $ python -m pip install cppyy; (WORK) $. .. note:: ; If you are using python version less than 3.3, you should use `virtualenv` instead of `venv`.; First install virtualenv package that allows you to create virtual environment. $ python -m pip install virtualenv . $ virtualenv WORK. $ source WORK/bin/activate. (WORK) $ python -m pip install cppyy. (WORK) $. If you use the ``--user`` option to ``pip`` and use ``pip`` directly on the; command line, instead of through ``python``, make sure that the ``PATH``; envar points to the bin directory that will contain the installed entry; points during the installation, as the build process needs them.; You may also need to install ``wheel`` first if you have an older version of; ``pip`` and/or do not use virtualenv (which installs wheel by default).; Example::. $ python -m pip install wheel --user; $ PATH=$HOME/.local/bin:$PATH python -m pip install cppyy --user. Wheels on PyPI; --------------. Wheels for the backend (``cppyy-cling``) are available on PyPI for GNU/Linux,; MacOS-X, and MS Windows (both 32b and 64b).; The Linux wheels are built for manylinux2014, but with the dual ABI enabled.; The wheels for MS Windows were build with MSVC Community Edition 2017. There are no wheels for the ``CPyCppyy`` and ``cppyy`` packages, to allow; the C++ standard chosen to match the local compiler. pip with conda; --------------. Although installing ``cppyy`` through `conda-forge`_ is recommended, it is; possible to build/install with ``pip`` under Anaconda/miniconda. Typical Python extensions only expose a C interface for use through the; Python C-API, requiring only calling conventions (and the Python C-API; version, of course) to match to be binary compatible.; Here, cppyy differs because it exposes C++ APIs: it thus requires a C++; run-time that is ABI compatible with the C+",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:2625,Deployability,install,install,2625,"`venv`); created directory (""WORK"" in this example)::. $ python -m venv WORK ; $ WORK\Scripts\activate; (WORK) $ python -m pip install cppyy; (WORK) $. .. note:: ; If you are using python version less than 3.3, you should use `virtualenv` instead of `venv`.; First install virtualenv package that allows you to create virtual environment. $ python -m pip install virtualenv . $ virtualenv WORK. $ source WORK/bin/activate. (WORK) $ python -m pip install cppyy. (WORK) $. If you use the ``--user`` option to ``pip`` and use ``pip`` directly on the; command line, instead of through ``python``, make sure that the ``PATH``; envar points to the bin directory that will contain the installed entry; points during the installation, as the build process needs them.; You may also need to install ``wheel`` first if you have an older version of; ``pip`` and/or do not use virtualenv (which installs wheel by default).; Example::. $ python -m pip install wheel --user; $ PATH=$HOME/.local/bin:$PATH python -m pip install cppyy --user. Wheels on PyPI; --------------. Wheels for the backend (``cppyy-cling``) are available on PyPI for GNU/Linux,; MacOS-X, and MS Windows (both 32b and 64b).; The Linux wheels are built for manylinux2014, but with the dual ABI enabled.; The wheels for MS Windows were build with MSVC Community Edition 2017. There are no wheels for the ``CPyCppyy`` and ``cppyy`` packages, to allow; the C++ standard chosen to match the local compiler. pip with conda; --------------. Although installing ``cppyy`` through `conda-forge`_ is recommended, it is; possible to build/install with ``pip`` under Anaconda/miniconda. Typical Python extensions only expose a C interface for use through the; Python C-API, requiring only calling conventions (and the Python C-API; version, of course) to match to be binary compatible.; Here, cppyy differs because it exposes C++ APIs: it thus requires a C++; run-time that is ABI compatible with the C++ compiler that was used during; build-time. A set o",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:3121,Deployability,install,installing,3121," instead of through ``python``, make sure that the ``PATH``; envar points to the bin directory that will contain the installed entry; points during the installation, as the build process needs them.; You may also need to install ``wheel`` first if you have an older version of; ``pip`` and/or do not use virtualenv (which installs wheel by default).; Example::. $ python -m pip install wheel --user; $ PATH=$HOME/.local/bin:$PATH python -m pip install cppyy --user. Wheels on PyPI; --------------. Wheels for the backend (``cppyy-cling``) are available on PyPI for GNU/Linux,; MacOS-X, and MS Windows (both 32b and 64b).; The Linux wheels are built for manylinux2014, but with the dual ABI enabled.; The wheels for MS Windows were build with MSVC Community Edition 2017. There are no wheels for the ``CPyCppyy`` and ``cppyy`` packages, to allow; the C++ standard chosen to match the local compiler. pip with conda; --------------. Although installing ``cppyy`` through `conda-forge`_ is recommended, it is; possible to build/install with ``pip`` under Anaconda/miniconda. Typical Python extensions only expose a C interface for use through the; Python C-API, requiring only calling conventions (and the Python C-API; version, of course) to match to be binary compatible.; Here, cppyy differs because it exposes C++ APIs: it thus requires a C++; run-time that is ABI compatible with the C++ compiler that was used during; build-time. A set of modern compilers is available through conda-forge, but are only; intended for use with ``conda-build``.; In particular, the corresponding run-time is installed (for use through rpath; when building), but not set up.; That is, the conda compilers are added to ``PATH`` but not their libraries; to ``LD_LIBRARY_PATH`` (Mac, Linux; ``PATH`` for both on MS Windows).; Thus, you get the conda compilers and your system libraries mixed in the same; build environment, unless you set ``LD_LIBRARY_PATH`` (``PATH`` on Windows); explicitly, e.g. by adding ``$CONDA_PRE",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:3206,Deployability,install,install,3206," instead of through ``python``, make sure that the ``PATH``; envar points to the bin directory that will contain the installed entry; points during the installation, as the build process needs them.; You may also need to install ``wheel`` first if you have an older version of; ``pip`` and/or do not use virtualenv (which installs wheel by default).; Example::. $ python -m pip install wheel --user; $ PATH=$HOME/.local/bin:$PATH python -m pip install cppyy --user. Wheels on PyPI; --------------. Wheels for the backend (``cppyy-cling``) are available on PyPI for GNU/Linux,; MacOS-X, and MS Windows (both 32b and 64b).; The Linux wheels are built for manylinux2014, but with the dual ABI enabled.; The wheels for MS Windows were build with MSVC Community Edition 2017. There are no wheels for the ``CPyCppyy`` and ``cppyy`` packages, to allow; the C++ standard chosen to match the local compiler. pip with conda; --------------. Although installing ``cppyy`` through `conda-forge`_ is recommended, it is; possible to build/install with ``pip`` under Anaconda/miniconda. Typical Python extensions only expose a C interface for use through the; Python C-API, requiring only calling conventions (and the Python C-API; version, of course) to match to be binary compatible.; Here, cppyy differs because it exposes C++ APIs: it thus requires a C++; run-time that is ABI compatible with the C++ compiler that was used during; build-time. A set of modern compilers is available through conda-forge, but are only; intended for use with ``conda-build``.; In particular, the corresponding run-time is installed (for use through rpath; when building), but not set up.; That is, the conda compilers are added to ``PATH`` but not their libraries; to ``LD_LIBRARY_PATH`` (Mac, Linux; ``PATH`` for both on MS Windows).; Thus, you get the conda compilers and your system libraries mixed in the same; build environment, unless you set ``LD_LIBRARY_PATH`` (``PATH`` on Windows); explicitly, e.g. by adding ``$CONDA_PRE",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:3773,Deployability,install,installed,3773,"(both 32b and 64b).; The Linux wheels are built for manylinux2014, but with the dual ABI enabled.; The wheels for MS Windows were build with MSVC Community Edition 2017. There are no wheels for the ``CPyCppyy`` and ``cppyy`` packages, to allow; the C++ standard chosen to match the local compiler. pip with conda; --------------. Although installing ``cppyy`` through `conda-forge`_ is recommended, it is; possible to build/install with ``pip`` under Anaconda/miniconda. Typical Python extensions only expose a C interface for use through the; Python C-API, requiring only calling conventions (and the Python C-API; version, of course) to match to be binary compatible.; Here, cppyy differs because it exposes C++ APIs: it thus requires a C++; run-time that is ABI compatible with the C++ compiler that was used during; build-time. A set of modern compilers is available through conda-forge, but are only; intended for use with ``conda-build``.; In particular, the corresponding run-time is installed (for use through rpath; when building), but not set up.; That is, the conda compilers are added to ``PATH`` but not their libraries; to ``LD_LIBRARY_PATH`` (Mac, Linux; ``PATH`` for both on MS Windows).; Thus, you get the conda compilers and your system libraries mixed in the same; build environment, unless you set ``LD_LIBRARY_PATH`` (``PATH`` on Windows); explicitly, e.g. by adding ``$CONDA_PREFIX/lib``.; Note that the conda documentation recommends against this.; Furthermore, the compilers from conda-forge are not vanilla distributions:; header files have been modified, which can can lead to parsing problems if; your system C library does not support C11, for example. Nevertheless, with the above caveats, if your system C/C++ run-times are new; enough, the following can be made to work::. $ conda create -n WORK; $ conda activate WORK; (WORK) $ conda install python; (WORK) $ conda install -c conda-forge compilers; (WORK) [current compiler] $ python -m pip install cppyy. C++ standard",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:4648,Deployability,install,install,4648," are only; intended for use with ``conda-build``.; In particular, the corresponding run-time is installed (for use through rpath; when building), but not set up.; That is, the conda compilers are added to ``PATH`` but not their libraries; to ``LD_LIBRARY_PATH`` (Mac, Linux; ``PATH`` for both on MS Windows).; Thus, you get the conda compilers and your system libraries mixed in the same; build environment, unless you set ``LD_LIBRARY_PATH`` (``PATH`` on Windows); explicitly, e.g. by adding ``$CONDA_PREFIX/lib``.; Note that the conda documentation recommends against this.; Furthermore, the compilers from conda-forge are not vanilla distributions:; header files have been modified, which can can lead to parsing problems if; your system C library does not support C11, for example. Nevertheless, with the above caveats, if your system C/C++ run-times are new; enough, the following can be made to work::. $ conda create -n WORK; $ conda activate WORK; (WORK) $ conda install python; (WORK) $ conda install -c conda-forge compilers; (WORK) [current compiler] $ python -m pip install cppyy. C++ standard with pip; ---------------------. The C++20 standard is the default on all systems as of release 3.0.1 (both; PyPI and conda-forge); it is C++17 for older releases.; When installing from PyPI using ``pip``, you can control the standard; selection by setting the ``STDCXX`` envar to '20', '17', or '14' (for Linux,; the backend does not need to be recompiled) for the 3.x releases; '17', '14',; or '11' for the 2.x releases.; Note that the build will automatically lower your choice if the compiler used; does not support a newer standard. Install from source; -------------------; .. _installation_from_source:. To build an existing release from source, tell ``pip`` to not download any; binary wheels.; Build-time only dependencies are ``cmake`` (for general build), ``python``; (obviously, but also for LLVM), and a modern C++ compiler (one that supports; at least C++14).; Use the envar ``STD",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:4679,Deployability,install,install,4679," are only; intended for use with ``conda-build``.; In particular, the corresponding run-time is installed (for use through rpath; when building), but not set up.; That is, the conda compilers are added to ``PATH`` but not their libraries; to ``LD_LIBRARY_PATH`` (Mac, Linux; ``PATH`` for both on MS Windows).; Thus, you get the conda compilers and your system libraries mixed in the same; build environment, unless you set ``LD_LIBRARY_PATH`` (``PATH`` on Windows); explicitly, e.g. by adding ``$CONDA_PREFIX/lib``.; Note that the conda documentation recommends against this.; Furthermore, the compilers from conda-forge are not vanilla distributions:; header files have been modified, which can can lead to parsing problems if; your system C library does not support C11, for example. Nevertheless, with the above caveats, if your system C/C++ run-times are new; enough, the following can be made to work::. $ conda create -n WORK; $ conda activate WORK; (WORK) $ conda install python; (WORK) $ conda install -c conda-forge compilers; (WORK) [current compiler] $ python -m pip install cppyy. C++ standard with pip; ---------------------. The C++20 standard is the default on all systems as of release 3.0.1 (both; PyPI and conda-forge); it is C++17 for older releases.; When installing from PyPI using ``pip``, you can control the standard; selection by setting the ``STDCXX`` envar to '20', '17', or '14' (for Linux,; the backend does not need to be recompiled) for the 3.x releases; '17', '14',; or '11' for the 2.x releases.; Note that the build will automatically lower your choice if the compiler used; does not support a newer standard. Install from source; -------------------; .. _installation_from_source:. To build an existing release from source, tell ``pip`` to not download any; binary wheels.; Build-time only dependencies are ``cmake`` (for general build), ``python``; (obviously, but also for LLVM), and a modern C++ compiler (one that supports; at least C++14).; Use the envar ``STD",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:4755,Deployability,install,install,4755," are only; intended for use with ``conda-build``.; In particular, the corresponding run-time is installed (for use through rpath; when building), but not set up.; That is, the conda compilers are added to ``PATH`` but not their libraries; to ``LD_LIBRARY_PATH`` (Mac, Linux; ``PATH`` for both on MS Windows).; Thus, you get the conda compilers and your system libraries mixed in the same; build environment, unless you set ``LD_LIBRARY_PATH`` (``PATH`` on Windows); explicitly, e.g. by adding ``$CONDA_PREFIX/lib``.; Note that the conda documentation recommends against this.; Furthermore, the compilers from conda-forge are not vanilla distributions:; header files have been modified, which can can lead to parsing problems if; your system C library does not support C11, for example. Nevertheless, with the above caveats, if your system C/C++ run-times are new; enough, the following can be made to work::. $ conda create -n WORK; $ conda activate WORK; (WORK) $ conda install python; (WORK) $ conda install -c conda-forge compilers; (WORK) [current compiler] $ python -m pip install cppyy. C++ standard with pip; ---------------------. The C++20 standard is the default on all systems as of release 3.0.1 (both; PyPI and conda-forge); it is C++17 for older releases.; When installing from PyPI using ``pip``, you can control the standard; selection by setting the ``STDCXX`` envar to '20', '17', or '14' (for Linux,; the backend does not need to be recompiled) for the 3.x releases; '17', '14',; or '11' for the 2.x releases.; Note that the build will automatically lower your choice if the compiler used; does not support a newer standard. Install from source; -------------------; .. _installation_from_source:. To build an existing release from source, tell ``pip`` to not download any; binary wheels.; Build-time only dependencies are ``cmake`` (for general build), ``python``; (obviously, but also for LLVM), and a modern C++ compiler (one that supports; at least C++14).; Use the envar ``STD",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:4871,Deployability,release,release,4871," the conda compilers are added to ``PATH`` but not their libraries; to ``LD_LIBRARY_PATH`` (Mac, Linux; ``PATH`` for both on MS Windows).; Thus, you get the conda compilers and your system libraries mixed in the same; build environment, unless you set ``LD_LIBRARY_PATH`` (``PATH`` on Windows); explicitly, e.g. by adding ``$CONDA_PREFIX/lib``.; Note that the conda documentation recommends against this.; Furthermore, the compilers from conda-forge are not vanilla distributions:; header files have been modified, which can can lead to parsing problems if; your system C library does not support C11, for example. Nevertheless, with the above caveats, if your system C/C++ run-times are new; enough, the following can be made to work::. $ conda create -n WORK; $ conda activate WORK; (WORK) $ conda install python; (WORK) $ conda install -c conda-forge compilers; (WORK) [current compiler] $ python -m pip install cppyy. C++ standard with pip; ---------------------. The C++20 standard is the default on all systems as of release 3.0.1 (both; PyPI and conda-forge); it is C++17 for older releases.; When installing from PyPI using ``pip``, you can control the standard; selection by setting the ``STDCXX`` envar to '20', '17', or '14' (for Linux,; the backend does not need to be recompiled) for the 3.x releases; '17', '14',; or '11' for the 2.x releases.; Note that the build will automatically lower your choice if the compiler used; does not support a newer standard. Install from source; -------------------; .. _installation_from_source:. To build an existing release from source, tell ``pip`` to not download any; binary wheels.; Build-time only dependencies are ``cmake`` (for general build), ``python``; (obviously, but also for LLVM), and a modern C++ compiler (one that supports; at least C++14).; Use the envar ``STDCXX`` to control the C++ standard version; ``MAKE`` to; change the ``make`` command, ``MAKE_NPROCS`` to control the maximum number of; parallel jobs allowed, and ``VERBOSE",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:4937,Deployability,release,releases,4937,"; to ``LD_LIBRARY_PATH`` (Mac, Linux; ``PATH`` for both on MS Windows).; Thus, you get the conda compilers and your system libraries mixed in the same; build environment, unless you set ``LD_LIBRARY_PATH`` (``PATH`` on Windows); explicitly, e.g. by adding ``$CONDA_PREFIX/lib``.; Note that the conda documentation recommends against this.; Furthermore, the compilers from conda-forge are not vanilla distributions:; header files have been modified, which can can lead to parsing problems if; your system C library does not support C11, for example. Nevertheless, with the above caveats, if your system C/C++ run-times are new; enough, the following can be made to work::. $ conda create -n WORK; $ conda activate WORK; (WORK) $ conda install python; (WORK) $ conda install -c conda-forge compilers; (WORK) [current compiler] $ python -m pip install cppyy. C++ standard with pip; ---------------------. The C++20 standard is the default on all systems as of release 3.0.1 (both; PyPI and conda-forge); it is C++17 for older releases.; When installing from PyPI using ``pip``, you can control the standard; selection by setting the ``STDCXX`` envar to '20', '17', or '14' (for Linux,; the backend does not need to be recompiled) for the 3.x releases; '17', '14',; or '11' for the 2.x releases.; Note that the build will automatically lower your choice if the compiler used; does not support a newer standard. Install from source; -------------------; .. _installation_from_source:. To build an existing release from source, tell ``pip`` to not download any; binary wheels.; Build-time only dependencies are ``cmake`` (for general build), ``python``; (obviously, but also for LLVM), and a modern C++ compiler (one that supports; at least C++14).; Use the envar ``STDCXX`` to control the C++ standard version; ``MAKE`` to; change the ``make`` command, ``MAKE_NPROCS`` to control the maximum number of; parallel jobs allowed, and ``VERBOSE=1`` to see full build/compile commands.; Example (using ``--verbos",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:4953,Deployability,install,installing,4953,"ixed in the same; build environment, unless you set ``LD_LIBRARY_PATH`` (``PATH`` on Windows); explicitly, e.g. by adding ``$CONDA_PREFIX/lib``.; Note that the conda documentation recommends against this.; Furthermore, the compilers from conda-forge are not vanilla distributions:; header files have been modified, which can can lead to parsing problems if; your system C library does not support C11, for example. Nevertheless, with the above caveats, if your system C/C++ run-times are new; enough, the following can be made to work::. $ conda create -n WORK; $ conda activate WORK; (WORK) $ conda install python; (WORK) $ conda install -c conda-forge compilers; (WORK) [current compiler] $ python -m pip install cppyy. C++ standard with pip; ---------------------. The C++20 standard is the default on all systems as of release 3.0.1 (both; PyPI and conda-forge); it is C++17 for older releases.; When installing from PyPI using ``pip``, you can control the standard; selection by setting the ``STDCXX`` envar to '20', '17', or '14' (for Linux,; the backend does not need to be recompiled) for the 3.x releases; '17', '14',; or '11' for the 2.x releases.; Note that the build will automatically lower your choice if the compiler used; does not support a newer standard. Install from source; -------------------; .. _installation_from_source:. To build an existing release from source, tell ``pip`` to not download any; binary wheels.; Build-time only dependencies are ``cmake`` (for general build), ``python``; (obviously, but also for LLVM), and a modern C++ compiler (one that supports; at least C++14).; Use the envar ``STDCXX`` to control the C++ standard version; ``MAKE`` to; change the ``make`` command, ``MAKE_NPROCS`` to control the maximum number of; parallel jobs allowed, and ``VERBOSE=1`` to see full build/compile commands.; Example (using ``--verbose`` to see ``pip`` progress)::. $ STDCXX=17 MAKE_NPROCS=32 pip install --verbose cppyy --no-binary=cppyy-cling. Compilation of the bac",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:5153,Deployability,release,releases,5153,"$CONDA_PREFIX/lib``.; Note that the conda documentation recommends against this.; Furthermore, the compilers from conda-forge are not vanilla distributions:; header files have been modified, which can can lead to parsing problems if; your system C library does not support C11, for example. Nevertheless, with the above caveats, if your system C/C++ run-times are new; enough, the following can be made to work::. $ conda create -n WORK; $ conda activate WORK; (WORK) $ conda install python; (WORK) $ conda install -c conda-forge compilers; (WORK) [current compiler] $ python -m pip install cppyy. C++ standard with pip; ---------------------. The C++20 standard is the default on all systems as of release 3.0.1 (both; PyPI and conda-forge); it is C++17 for older releases.; When installing from PyPI using ``pip``, you can control the standard; selection by setting the ``STDCXX`` envar to '20', '17', or '14' (for Linux,; the backend does not need to be recompiled) for the 3.x releases; '17', '14',; or '11' for the 2.x releases.; Note that the build will automatically lower your choice if the compiler used; does not support a newer standard. Install from source; -------------------; .. _installation_from_source:. To build an existing release from source, tell ``pip`` to not download any; binary wheels.; Build-time only dependencies are ``cmake`` (for general build), ``python``; (obviously, but also for LLVM), and a modern C++ compiler (one that supports; at least C++14).; Use the envar ``STDCXX`` to control the C++ standard version; ``MAKE`` to; change the ``make`` command, ``MAKE_NPROCS`` to control the maximum number of; parallel jobs allowed, and ``VERBOSE=1`` to see full build/compile commands.; Example (using ``--verbose`` to see ``pip`` progress)::. $ STDCXX=17 MAKE_NPROCS=32 pip install --verbose cppyy --no-binary=cppyy-cling. Compilation of the backend, which contains a customized version of; Clang/LLVM, can take a long time, so by default the setup script will use all;",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:5196,Deployability,release,releases,5196,"that the conda documentation recommends against this.; Furthermore, the compilers from conda-forge are not vanilla distributions:; header files have been modified, which can can lead to parsing problems if; your system C library does not support C11, for example. Nevertheless, with the above caveats, if your system C/C++ run-times are new; enough, the following can be made to work::. $ conda create -n WORK; $ conda activate WORK; (WORK) $ conda install python; (WORK) $ conda install -c conda-forge compilers; (WORK) [current compiler] $ python -m pip install cppyy. C++ standard with pip; ---------------------. The C++20 standard is the default on all systems as of release 3.0.1 (both; PyPI and conda-forge); it is C++17 for older releases.; When installing from PyPI using ``pip``, you can control the standard; selection by setting the ``STDCXX`` envar to '20', '17', or '14' (for Linux,; the backend does not need to be recompiled) for the 3.x releases; '17', '14',; or '11' for the 2.x releases.; Note that the build will automatically lower your choice if the compiler used; does not support a newer standard. Install from source; -------------------; .. _installation_from_source:. To build an existing release from source, tell ``pip`` to not download any; binary wheels.; Build-time only dependencies are ``cmake`` (for general build), ``python``; (obviously, but also for LLVM), and a modern C++ compiler (one that supports; at least C++14).; Use the envar ``STDCXX`` to control the C++ standard version; ``MAKE`` to; change the ``make`` command, ``MAKE_NPROCS`` to control the maximum number of; parallel jobs allowed, and ``VERBOSE=1`` to see full build/compile commands.; Example (using ``--verbose`` to see ``pip`` progress)::. $ STDCXX=17 MAKE_NPROCS=32 pip install --verbose cppyy --no-binary=cppyy-cling. Compilation of the backend, which contains a customized version of; Clang/LLVM, can take a long time, so by default the setup script will use all; cores (x2 if hyperthreadin",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:5415,Deployability,release,release,5415,"upport C11, for example. Nevertheless, with the above caveats, if your system C/C++ run-times are new; enough, the following can be made to work::. $ conda create -n WORK; $ conda activate WORK; (WORK) $ conda install python; (WORK) $ conda install -c conda-forge compilers; (WORK) [current compiler] $ python -m pip install cppyy. C++ standard with pip; ---------------------. The C++20 standard is the default on all systems as of release 3.0.1 (both; PyPI and conda-forge); it is C++17 for older releases.; When installing from PyPI using ``pip``, you can control the standard; selection by setting the ``STDCXX`` envar to '20', '17', or '14' (for Linux,; the backend does not need to be recompiled) for the 3.x releases; '17', '14',; or '11' for the 2.x releases.; Note that the build will automatically lower your choice if the compiler used; does not support a newer standard. Install from source; -------------------; .. _installation_from_source:. To build an existing release from source, tell ``pip`` to not download any; binary wheels.; Build-time only dependencies are ``cmake`` (for general build), ``python``; (obviously, but also for LLVM), and a modern C++ compiler (one that supports; at least C++14).; Use the envar ``STDCXX`` to control the C++ standard version; ``MAKE`` to; change the ``make`` command, ``MAKE_NPROCS`` to control the maximum number of; parallel jobs allowed, and ``VERBOSE=1`` to see full build/compile commands.; Example (using ``--verbose`` to see ``pip`` progress)::. $ STDCXX=17 MAKE_NPROCS=32 pip install --verbose cppyy --no-binary=cppyy-cling. Compilation of the backend, which contains a customized version of; Clang/LLVM, can take a long time, so by default the setup script will use all; cores (x2 if hyperthreading is enabled).; Once built, however, the wheel of ``cppyy-cling`` is reused by pip for all; versions of CPython and for PyPy, thus the long compilation is needed only; once for all different versions of Python on the same machine. See the ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:5978,Deployability,install,install,5978,"`, you can control the standard; selection by setting the ``STDCXX`` envar to '20', '17', or '14' (for Linux,; the backend does not need to be recompiled) for the 3.x releases; '17', '14',; or '11' for the 2.x releases.; Note that the build will automatically lower your choice if the compiler used; does not support a newer standard. Install from source; -------------------; .. _installation_from_source:. To build an existing release from source, tell ``pip`` to not download any; binary wheels.; Build-time only dependencies are ``cmake`` (for general build), ``python``; (obviously, but also for LLVM), and a modern C++ compiler (one that supports; at least C++14).; Use the envar ``STDCXX`` to control the C++ standard version; ``MAKE`` to; change the ``make`` command, ``MAKE_NPROCS`` to control the maximum number of; parallel jobs allowed, and ``VERBOSE=1`` to see full build/compile commands.; Example (using ``--verbose`` to see ``pip`` progress)::. $ STDCXX=17 MAKE_NPROCS=32 pip install --verbose cppyy --no-binary=cppyy-cling. Compilation of the backend, which contains a customized version of; Clang/LLVM, can take a long time, so by default the setup script will use all; cores (x2 if hyperthreading is enabled).; Once built, however, the wheel of ``cppyy-cling`` is reused by pip for all; versions of CPython and for PyPy, thus the long compilation is needed only; once for all different versions of Python on the same machine. See the :ref:`section on repos <building_from_source>` for more; details/options. PyPy; ----. PyPy 5.7 and 5.8 have a built-in module ``cppyy``.; You can still install the cppyy package, but the built-in module takes; precedence.; To use cppyy, first import a compatibility module::. $ pypy; [PyPy 5.8.0 with GCC 5.4.0] on linux2; >>>> import cppyy_compat, cppyy; >>>>. You may have to set ``LD_LIBRARY_PATH`` appropriately if you get an; ``EnvironmentError`` (it will indicate the needed directory). Note that your python interpreter (whether CPython or ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:6591,Deployability,install,install,6591,"er (one that supports; at least C++14).; Use the envar ``STDCXX`` to control the C++ standard version; ``MAKE`` to; change the ``make`` command, ``MAKE_NPROCS`` to control the maximum number of; parallel jobs allowed, and ``VERBOSE=1`` to see full build/compile commands.; Example (using ``--verbose`` to see ``pip`` progress)::. $ STDCXX=17 MAKE_NPROCS=32 pip install --verbose cppyy --no-binary=cppyy-cling. Compilation of the backend, which contains a customized version of; Clang/LLVM, can take a long time, so by default the setup script will use all; cores (x2 if hyperthreading is enabled).; Once built, however, the wheel of ``cppyy-cling`` is reused by pip for all; versions of CPython and for PyPy, thus the long compilation is needed only; once for all different versions of Python on the same machine. See the :ref:`section on repos <building_from_source>` for more; details/options. PyPy; ----. PyPy 5.7 and 5.8 have a built-in module ``cppyy``.; You can still install the cppyy package, but the built-in module takes; precedence.; To use cppyy, first import a compatibility module::. $ pypy; [PyPy 5.8.0 with GCC 5.4.0] on linux2; >>>> import cppyy_compat, cppyy; >>>>. You may have to set ``LD_LIBRARY_PATH`` appropriately if you get an; ``EnvironmentError`` (it will indicate the needed directory). Note that your python interpreter (whether CPython or ``pypy-c``) may not have; been linked by the C++ compiler.; This can lead to problems during loading of C++ libraries and program shutdown.; In that case, re-linking is highly recommended. Very old versions of PyPy (5.6.0 and earlier) have a built-in ``cppyy`` based; on `Reflex`_, which is less feature-rich and no longer supported.; However, both the :doc:`distribution utilities <utilities>` and user-facing; Python codes are very backwards compatible, making migration straightforward. Precompiled header; ------------------. For performance reasons (reduced memory and CPU usage), a precompiled header; (PCH) of the system and ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:7648,Deployability,install,installed,7648,"yy package, but the built-in module takes; precedence.; To use cppyy, first import a compatibility module::. $ pypy; [PyPy 5.8.0 with GCC 5.4.0] on linux2; >>>> import cppyy_compat, cppyy; >>>>. You may have to set ``LD_LIBRARY_PATH`` appropriately if you get an; ``EnvironmentError`` (it will indicate the needed directory). Note that your python interpreter (whether CPython or ``pypy-c``) may not have; been linked by the C++ compiler.; This can lead to problems during loading of C++ libraries and program shutdown.; In that case, re-linking is highly recommended. Very old versions of PyPy (5.6.0 and earlier) have a built-in ``cppyy`` based; on `Reflex`_, which is less feature-rich and no longer supported.; However, both the :doc:`distribution utilities <utilities>` and user-facing; Python codes are very backwards compatible, making migration straightforward. Precompiled header; ------------------. For performance reasons (reduced memory and CPU usage), a precompiled header; (PCH) of the system and compiler header files will be installed or, failing; that, generated on startup.; Obviously, this PCH is not portable and should not be part of any wheel. Some compiler features, such as AVX, OpenMP, fast math, etc. need to be; active during compilation of the PCH, as they depend both on compiler flags; and system headers (for intrinsics, or API calls).; You can control compiler flags through the ``EXTRA_CLING_ARGS`` envar and thus; what is active in the PCH.; In principle, you can also change the C++ language standard by setting the; appropriate flag on ``EXTRA_CLING_ARGS`` and rebuilding the PCH.; However, if done at this stage, that disables some automatic conversion for; C++ types that were introduced after C++11 (such as ``string_view`` and; ``optional``). If you want multiple PCHs living side-by-side, you can generate them; yourself (note that the given path must be absolute)::. >>> import cppyy_backend.loader as l; >>> l.set_cling_compile_options(True) # adds defaults",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:7541,Energy Efficiency,reduce,reduced,7541,"yy package, but the built-in module takes; precedence.; To use cppyy, first import a compatibility module::. $ pypy; [PyPy 5.8.0 with GCC 5.4.0] on linux2; >>>> import cppyy_compat, cppyy; >>>>. You may have to set ``LD_LIBRARY_PATH`` appropriately if you get an; ``EnvironmentError`` (it will indicate the needed directory). Note that your python interpreter (whether CPython or ``pypy-c``) may not have; been linked by the C++ compiler.; This can lead to problems during loading of C++ libraries and program shutdown.; In that case, re-linking is highly recommended. Very old versions of PyPy (5.6.0 and earlier) have a built-in ``cppyy`` based; on `Reflex`_, which is less feature-rich and no longer supported.; However, both the :doc:`distribution utilities <utilities>` and user-facing; Python codes are very backwards compatible, making migration straightforward. Precompiled header; ------------------. For performance reasons (reduced memory and CPU usage), a precompiled header; (PCH) of the system and compiler header files will be installed or, failing; that, generated on startup.; Obviously, this PCH is not portable and should not be part of any wheel. Some compiler features, such as AVX, OpenMP, fast math, etc. need to be; active during compilation of the PCH, as they depend both on compiler flags; and system headers (for intrinsics, or API calls).; You can control compiler flags through the ``EXTRA_CLING_ARGS`` envar and thus; what is active in the PCH.; In principle, you can also change the C++ language standard by setting the; appropriate flag on ``EXTRA_CLING_ARGS`` and rebuilding the PCH.; However, if done at this stage, that disables some automatic conversion for; C++ types that were introduced after C++11 (such as ``string_view`` and; ``optional``). If you want multiple PCHs living side-by-side, you can generate them; yourself (note that the given path must be absolute)::. >>> import cppyy_backend.loader as l; >>> l.set_cling_compile_options(True) # adds defaults",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:3295,Integrability,interface,interface,3295,"he build process needs them.; You may also need to install ``wheel`` first if you have an older version of; ``pip`` and/or do not use virtualenv (which installs wheel by default).; Example::. $ python -m pip install wheel --user; $ PATH=$HOME/.local/bin:$PATH python -m pip install cppyy --user. Wheels on PyPI; --------------. Wheels for the backend (``cppyy-cling``) are available on PyPI for GNU/Linux,; MacOS-X, and MS Windows (both 32b and 64b).; The Linux wheels are built for manylinux2014, but with the dual ABI enabled.; The wheels for MS Windows were build with MSVC Community Edition 2017. There are no wheels for the ``CPyCppyy`` and ``cppyy`` packages, to allow; the C++ standard chosen to match the local compiler. pip with conda; --------------. Although installing ``cppyy`` through `conda-forge`_ is recommended, it is; possible to build/install with ``pip`` under Anaconda/miniconda. Typical Python extensions only expose a C interface for use through the; Python C-API, requiring only calling conventions (and the Python C-API; version, of course) to match to be binary compatible.; Here, cppyy differs because it exposes C++ APIs: it thus requires a C++; run-time that is ABI compatible with the C++ compiler that was used during; build-time. A set of modern compilers is available through conda-forge, but are only; intended for use with ``conda-build``.; In particular, the corresponding run-time is installed (for use through rpath; when building), but not set up.; That is, the conda compilers are added to ``PATH`` but not their libraries; to ``LD_LIBRARY_PATH`` (Mac, Linux; ``PATH`` for both on MS Windows).; Thus, you get the conda compilers and your system libraries mixed in the same; build environment, unless you set ``LD_LIBRARY_PATH`` (``PATH`` on Windows); explicitly, e.g. by adding ``$CONDA_PREFIX/lib``.; Note that the conda documentation recommends against this.; Furthermore, the compilers from conda-forge are not vanilla distributions:; header files have been",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:5502,Integrability,depend,dependencies,5502,"made to work::. $ conda create -n WORK; $ conda activate WORK; (WORK) $ conda install python; (WORK) $ conda install -c conda-forge compilers; (WORK) [current compiler] $ python -m pip install cppyy. C++ standard with pip; ---------------------. The C++20 standard is the default on all systems as of release 3.0.1 (both; PyPI and conda-forge); it is C++17 for older releases.; When installing from PyPI using ``pip``, you can control the standard; selection by setting the ``STDCXX`` envar to '20', '17', or '14' (for Linux,; the backend does not need to be recompiled) for the 3.x releases; '17', '14',; or '11' for the 2.x releases.; Note that the build will automatically lower your choice if the compiler used; does not support a newer standard. Install from source; -------------------; .. _installation_from_source:. To build an existing release from source, tell ``pip`` to not download any; binary wheels.; Build-time only dependencies are ``cmake`` (for general build), ``python``; (obviously, but also for LLVM), and a modern C++ compiler (one that supports; at least C++14).; Use the envar ``STDCXX`` to control the C++ standard version; ``MAKE`` to; change the ``make`` command, ``MAKE_NPROCS`` to control the maximum number of; parallel jobs allowed, and ``VERBOSE=1`` to see full build/compile commands.; Example (using ``--verbose`` to see ``pip`` progress)::. $ STDCXX=17 MAKE_NPROCS=32 pip install --verbose cppyy --no-binary=cppyy-cling. Compilation of the backend, which contains a customized version of; Clang/LLVM, can take a long time, so by default the setup script will use all; cores (x2 if hyperthreading is enabled).; Once built, however, the wheel of ``cppyy-cling`` is reused by pip for all; versions of CPython and for PyPy, thus the long compilation is needed only; once for all different versions of Python on the same machine. See the :ref:`section on repos <building_from_source>` for more; details/options. PyPy; ----. PyPy 5.7 and 5.8 have a built-in module ``cpp",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:7892,Integrability,depend,depend,7892,"icate the needed directory). Note that your python interpreter (whether CPython or ``pypy-c``) may not have; been linked by the C++ compiler.; This can lead to problems during loading of C++ libraries and program shutdown.; In that case, re-linking is highly recommended. Very old versions of PyPy (5.6.0 and earlier) have a built-in ``cppyy`` based; on `Reflex`_, which is less feature-rich and no longer supported.; However, both the :doc:`distribution utilities <utilities>` and user-facing; Python codes are very backwards compatible, making migration straightforward. Precompiled header; ------------------. For performance reasons (reduced memory and CPU usage), a precompiled header; (PCH) of the system and compiler header files will be installed or, failing; that, generated on startup.; Obviously, this PCH is not portable and should not be part of any wheel. Some compiler features, such as AVX, OpenMP, fast math, etc. need to be; active during compilation of the PCH, as they depend both on compiler flags; and system headers (for intrinsics, or API calls).; You can control compiler flags through the ``EXTRA_CLING_ARGS`` envar and thus; what is active in the PCH.; In principle, you can also change the C++ language standard by setting the; appropriate flag on ``EXTRA_CLING_ARGS`` and rebuilding the PCH.; However, if done at this stage, that disables some automatic conversion for; C++ types that were introduced after C++11 (such as ``string_view`` and; ``optional``). If you want multiple PCHs living side-by-side, you can generate them; yourself (note that the given path must be absolute)::. >>> import cppyy_backend.loader as l; >>> l.set_cling_compile_options(True) # adds defaults to EXTRA_CLING_ARGS; >>> install_path = '/full/path/to/target/location/for/PCH'; >>> l.ensure_precompiled_header(install_path). You can then select the appropriate PCH with the ``CLING_STANDARD_PCH`` envar::. $ export CLING_STANDARD_PCH=/full/path/to/target/location/for/PCH/allDict.cxx.pch. Or ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:7727,Modifiability,portab,portable,7727,"with GCC 5.4.0] on linux2; >>>> import cppyy_compat, cppyy; >>>>. You may have to set ``LD_LIBRARY_PATH`` appropriately if you get an; ``EnvironmentError`` (it will indicate the needed directory). Note that your python interpreter (whether CPython or ``pypy-c``) may not have; been linked by the C++ compiler.; This can lead to problems during loading of C++ libraries and program shutdown.; In that case, re-linking is highly recommended. Very old versions of PyPy (5.6.0 and earlier) have a built-in ``cppyy`` based; on `Reflex`_, which is less feature-rich and no longer supported.; However, both the :doc:`distribution utilities <utilities>` and user-facing; Python codes are very backwards compatible, making migration straightforward. Precompiled header; ------------------. For performance reasons (reduced memory and CPU usage), a precompiled header; (PCH) of the system and compiler header files will be installed or, failing; that, generated on startup.; Obviously, this PCH is not portable and should not be part of any wheel. Some compiler features, such as AVX, OpenMP, fast math, etc. need to be; active during compilation of the PCH, as they depend both on compiler flags; and system headers (for intrinsics, or API calls).; You can control compiler flags through the ``EXTRA_CLING_ARGS`` envar and thus; what is active in the PCH.; In principle, you can also change the C++ language standard by setting the; appropriate flag on ``EXTRA_CLING_ARGS`` and rebuilding the PCH.; However, if done at this stage, that disables some automatic conversion for; C++ types that were introduced after C++11 (such as ``string_view`` and; ``optional``). If you want multiple PCHs living side-by-side, you can generate them; yourself (note that the given path must be absolute)::. >>> import cppyy_backend.loader as l; >>> l.set_cling_compile_options(True) # adds defaults to EXTRA_CLING_ARGS; >>> install_path = '/full/path/to/target/location/for/PCH'; >>> l.ensure_precompiled_header(install_path).",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:7079,Performance,load,loading,7079,"ersion of; Clang/LLVM, can take a long time, so by default the setup script will use all; cores (x2 if hyperthreading is enabled).; Once built, however, the wheel of ``cppyy-cling`` is reused by pip for all; versions of CPython and for PyPy, thus the long compilation is needed only; once for all different versions of Python on the same machine. See the :ref:`section on repos <building_from_source>` for more; details/options. PyPy; ----. PyPy 5.7 and 5.8 have a built-in module ``cppyy``.; You can still install the cppyy package, but the built-in module takes; precedence.; To use cppyy, first import a compatibility module::. $ pypy; [PyPy 5.8.0 with GCC 5.4.0] on linux2; >>>> import cppyy_compat, cppyy; >>>>. You may have to set ``LD_LIBRARY_PATH`` appropriately if you get an; ``EnvironmentError`` (it will indicate the needed directory). Note that your python interpreter (whether CPython or ``pypy-c``) may not have; been linked by the C++ compiler.; This can lead to problems during loading of C++ libraries and program shutdown.; In that case, re-linking is highly recommended. Very old versions of PyPy (5.6.0 and earlier) have a built-in ``cppyy`` based; on `Reflex`_, which is less feature-rich and no longer supported.; However, both the :doc:`distribution utilities <utilities>` and user-facing; Python codes are very backwards compatible, making migration straightforward. Precompiled header; ------------------. For performance reasons (reduced memory and CPU usage), a precompiled header; (PCH) of the system and compiler header files will be installed or, failing; that, generated on startup.; Obviously, this PCH is not portable and should not be part of any wheel. Some compiler features, such as AVX, OpenMP, fast math, etc. need to be; active during compilation of the PCH, as they depend both on compiler flags; and system headers (for intrinsics, or API calls).; You can control compiler flags through the ``EXTRA_CLING_ARGS`` envar and thus; what is active in the PCH.; In",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:7520,Performance,perform,performance,7520,"yy package, but the built-in module takes; precedence.; To use cppyy, first import a compatibility module::. $ pypy; [PyPy 5.8.0 with GCC 5.4.0] on linux2; >>>> import cppyy_compat, cppyy; >>>>. You may have to set ``LD_LIBRARY_PATH`` appropriately if you get an; ``EnvironmentError`` (it will indicate the needed directory). Note that your python interpreter (whether CPython or ``pypy-c``) may not have; been linked by the C++ compiler.; This can lead to problems during loading of C++ libraries and program shutdown.; In that case, re-linking is highly recommended. Very old versions of PyPy (5.6.0 and earlier) have a built-in ``cppyy`` based; on `Reflex`_, which is less feature-rich and no longer supported.; However, both the :doc:`distribution utilities <utilities>` and user-facing; Python codes are very backwards compatible, making migration straightforward. Precompiled header; ------------------. For performance reasons (reduced memory and CPU usage), a precompiled header; (PCH) of the system and compiler header files will be installed or, failing; that, generated on startup.; Obviously, this PCH is not portable and should not be part of any wheel. Some compiler features, such as AVX, OpenMP, fast math, etc. need to be; active during compilation of the PCH, as they depend both on compiler flags; and system headers (for intrinsics, or API calls).; You can control compiler flags through the ``EXTRA_CLING_ARGS`` envar and thus; what is active in the PCH.; In principle, you can also change the C++ language standard by setting the; appropriate flag on ``EXTRA_CLING_ARGS`` and rebuilding the PCH.; However, if done at this stage, that disables some automatic conversion for; C++ types that were introduced after C++11 (such as ``string_view`` and; ``optional``). If you want multiple PCHs living side-by-side, you can generate them; yourself (note that the given path must be absolute)::. >>> import cppyy_backend.loader as l; >>> l.set_cling_compile_options(True) # adds defaults",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:8541,Performance,load,loader,8541,"tforward. Precompiled header; ------------------. For performance reasons (reduced memory and CPU usage), a precompiled header; (PCH) of the system and compiler header files will be installed or, failing; that, generated on startup.; Obviously, this PCH is not portable and should not be part of any wheel. Some compiler features, such as AVX, OpenMP, fast math, etc. need to be; active during compilation of the PCH, as they depend both on compiler flags; and system headers (for intrinsics, or API calls).; You can control compiler flags through the ``EXTRA_CLING_ARGS`` envar and thus; what is active in the PCH.; In principle, you can also change the C++ language standard by setting the; appropriate flag on ``EXTRA_CLING_ARGS`` and rebuilding the PCH.; However, if done at this stage, that disables some automatic conversion for; C++ types that were introduced after C++11 (such as ``string_view`` and; ``optional``). If you want multiple PCHs living side-by-side, you can generate them; yourself (note that the given path must be absolute)::. >>> import cppyy_backend.loader as l; >>> l.set_cling_compile_options(True) # adds defaults to EXTRA_CLING_ARGS; >>> install_path = '/full/path/to/target/location/for/PCH'; >>> l.ensure_precompiled_header(install_path). You can then select the appropriate PCH with the ``CLING_STANDARD_PCH`` envar::. $ export CLING_STANDARD_PCH=/full/path/to/target/location/for/PCH/allDict.cxx.pch. Or disable it completely by setting that envar to ""none"". .. note::. Without the PCH, the default C++ standard will be the one with which; ``cppyy-cling`` was built. .. _`conda-forge`: https://anaconda.org/conda-forge/cppyy; .. _`Anaconda`: https://www.anaconda.com/distribution/; .. _`miniconda`: https://docs.conda.io/en/latest/miniconda.html; .. _`PyPI`: https://pypi.python.org/pypi/cppyy/; .. _`virtualenv`: https://pypi.python.org/pypi/virtualenv; .. _`venv`: https://docs.python.org/3/library/venv.html; .. _`Reflex`: https://root.cern.ch/how/how-use-reflex; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:500,Security,access,accessible,500,".. _installation:. Installation; ============. cppyy requires a (modern) C++ compiler.; When installing through `conda-forge`_, ``conda`` will install the compiler; for you, to match the other conda-forge packages.; When using ``pip`` and the wheels from `PyPI`_, you minimally need gcc5,; clang5, or MSVC'17. .. note::. On Windows, a command prompt from which to run Python (or Python run; directly) needs to be opened from within an environment with MSVC setup,; otherwise the compiler will not be accessible. When installing from source, the only requirement is a compiler that supports; C++14, this in order to build LLVM. With CPython on Linux or MacOS, probably by far the easiest way to install; cppyy, is through conda-forge on `Anaconda`_ (or `miniconda`_).; A Windows recipe for ``conda`` is not available yet, but is forthcoming, so; use ``pip`` for that platform for now (see below).; PyPI always has the authoritative releases (conda-forge pulls the sources; from there), so conda-forge may sometimes lag PyPI.; If you absolutely need the latest release, use PyPI or consider; :ref:`building from source <building_from_source>`. To install using ``conda``, create and/or activate your (new) work environment; and install from the conda-forge channel::. $ conda create -n WORK; $ conda activate WORK; (WORK) $ conda install -c conda-forge cppyy; (WORK) [current compiler] $. To install with ``pip`` through `PyPI`_, use `venv`.; The use of virtual environment (`venv`) prevents pollution of any system directories and allows; you to wipe out the full installation simply by removing the virtual environment (`venv`); created directory (""WORK"" in this example)::. $ python -m venv WORK ; $ WORK\Scripts\activate; (WORK) $ python -m pip install cppyy; (WORK) $. .. note:: ; If you are using python version less than 3.3, you should use `virtualenv` instead of `venv`.; First install virtualenv package that allows you to create virtual environment. $ python -m pip install virtualenv . $ vir",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:3284,Security,expose,expose,3284,"he build process needs them.; You may also need to install ``wheel`` first if you have an older version of; ``pip`` and/or do not use virtualenv (which installs wheel by default).; Example::. $ python -m pip install wheel --user; $ PATH=$HOME/.local/bin:$PATH python -m pip install cppyy --user. Wheels on PyPI; --------------. Wheels for the backend (``cppyy-cling``) are available on PyPI for GNU/Linux,; MacOS-X, and MS Windows (both 32b and 64b).; The Linux wheels are built for manylinux2014, but with the dual ABI enabled.; The wheels for MS Windows were build with MSVC Community Edition 2017. There are no wheels for the ``CPyCppyy`` and ``cppyy`` packages, to allow; the C++ standard chosen to match the local compiler. pip with conda; --------------. Although installing ``cppyy`` through `conda-forge`_ is recommended, it is; possible to build/install with ``pip`` under Anaconda/miniconda. Typical Python extensions only expose a C interface for use through the; Python C-API, requiring only calling conventions (and the Python C-API; version, of course) to match to be binary compatible.; Here, cppyy differs because it exposes C++ APIs: it thus requires a C++; run-time that is ABI compatible with the C++ compiler that was used during; build-time. A set of modern compilers is available through conda-forge, but are only; intended for use with ``conda-build``.; In particular, the corresponding run-time is installed (for use through rpath; when building), but not set up.; That is, the conda compilers are added to ``PATH`` but not their libraries; to ``LD_LIBRARY_PATH`` (Mac, Linux; ``PATH`` for both on MS Windows).; Thus, you get the conda compilers and your system libraries mixed in the same; build environment, unless you set ``LD_LIBRARY_PATH`` (``PATH`` on Windows); explicitly, e.g. by adding ``$CONDA_PREFIX/lib``.; Note that the conda documentation recommends against this.; Furthermore, the compilers from conda-forge are not vanilla distributions:; header files have been",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:3484,Security,expose,exposes,3484,"Example::. $ python -m pip install wheel --user; $ PATH=$HOME/.local/bin:$PATH python -m pip install cppyy --user. Wheels on PyPI; --------------. Wheels for the backend (``cppyy-cling``) are available on PyPI for GNU/Linux,; MacOS-X, and MS Windows (both 32b and 64b).; The Linux wheels are built for manylinux2014, but with the dual ABI enabled.; The wheels for MS Windows were build with MSVC Community Edition 2017. There are no wheels for the ``CPyCppyy`` and ``cppyy`` packages, to allow; the C++ standard chosen to match the local compiler. pip with conda; --------------. Although installing ``cppyy`` through `conda-forge`_ is recommended, it is; possible to build/install with ``pip`` under Anaconda/miniconda. Typical Python extensions only expose a C interface for use through the; Python C-API, requiring only calling conventions (and the Python C-API; version, of course) to match to be binary compatible.; Here, cppyy differs because it exposes C++ APIs: it thus requires a C++; run-time that is ABI compatible with the C++ compiler that was used during; build-time. A set of modern compilers is available through conda-forge, but are only; intended for use with ``conda-build``.; In particular, the corresponding run-time is installed (for use through rpath; when building), but not set up.; That is, the conda compilers are added to ``PATH`` but not their libraries; to ``LD_LIBRARY_PATH`` (Mac, Linux; ``PATH`` for both on MS Windows).; Thus, you get the conda compilers and your system libraries mixed in the same; build environment, unless you set ``LD_LIBRARY_PATH`` (``PATH`` on Windows); explicitly, e.g. by adding ``$CONDA_PREFIX/lib``.; Note that the conda documentation recommends against this.; Furthermore, the compilers from conda-forge are not vanilla distributions:; header files have been modified, which can can lead to parsing problems if; your system C library does not support C11, for example. Nevertheless, with the above caveats, if your system C/C++ run-times ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst:1576,Usability,simpl,simply,1576,"ement is a compiler that supports; C++14, this in order to build LLVM. With CPython on Linux or MacOS, probably by far the easiest way to install; cppyy, is through conda-forge on `Anaconda`_ (or `miniconda`_).; A Windows recipe for ``conda`` is not available yet, but is forthcoming, so; use ``pip`` for that platform for now (see below).; PyPI always has the authoritative releases (conda-forge pulls the sources; from there), so conda-forge may sometimes lag PyPI.; If you absolutely need the latest release, use PyPI or consider; :ref:`building from source <building_from_source>`. To install using ``conda``, create and/or activate your (new) work environment; and install from the conda-forge channel::. $ conda create -n WORK; $ conda activate WORK; (WORK) $ conda install -c conda-forge cppyy; (WORK) [current compiler] $. To install with ``pip`` through `PyPI`_, use `venv`.; The use of virtual environment (`venv`) prevents pollution of any system directories and allows; you to wipe out the full installation simply by removing the virtual environment (`venv`); created directory (""WORK"" in this example)::. $ python -m venv WORK ; $ WORK\Scripts\activate; (WORK) $ python -m pip install cppyy; (WORK) $. .. note:: ; If you are using python version less than 3.3, you should use `virtualenv` instead of `venv`.; First install virtualenv package that allows you to create virtual environment. $ python -m pip install virtualenv . $ virtualenv WORK. $ source WORK/bin/activate. (WORK) $ python -m pip install cppyy. (WORK) $. If you use the ``--user`` option to ``pip`` and use ``pip`` directly on the; command line, instead of through ``python``, make sure that the ``PATH``; envar points to the bin directory that will contain the installed entry; points during the installation, as the build process needs them.; You may also need to install ``wheel`` first if you have an older version of; ``pip`` and/or do not use virtualenv (which installs wheel by default).; Example::. $ python -m pi",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/installation.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/installation.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/license.rst:2011,Availability,avail,available,2011,"RANTIES, INCLUDING, BUT NOT LIMITED; TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR; PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS; BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE; GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION); HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT; LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY; OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF; SUCH DAMAGE. You are under no obligation whatsoever to provide any bug fixes,; patches, or upgrades to the features, functionality or performance of; the source code (""Enhancements"") to anyone; however, if you choose to; make your Enhancements available either publicly, or directly to; Lawrence Berkeley National Laboratory, without imposing a separate; written license agreement for such Enhancements, then you hereby grant; the following license: a non-exclusive, royalty-free perpetual license; to install, use, modify, prepare derivative works, incorporate into; other computer software, distribute, and sublicense such Enhancements; or derivative works thereof, in binary and source code form. Additional copyright holders; ----------------------------. In addition to LBNL/UC Berkeley, this package contains files copyrighted by; one or more of the following people and organizations, and licensed under; the same conditions (except for some compatible licenses as retained in the; source code):. * CERN; * Lucio Asnaghi; * Simone Bacchio; * Robert Bradshaw; * Ellis Breen; * Antonio Cuni; * Aditi Dutta; * Shaheed Haque; * Jonsomi; * Max Kolin; * Alvaro Moran; * Tarmo Pikaro; * Matti Picus; * Camille Scott; * Toby StClere-Smithe; * Stefan Wunsch. Conda-forge recipes were provided by Julian Rueth and Isuru Fernando. External code; -------------.",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/license.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/license.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/license.rst:1846,Deployability,patch,patches,1846,"RANTIES, INCLUDING, BUT NOT LIMITED; TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR; PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS; BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE; GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION); HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT; LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY; OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF; SUCH DAMAGE. You are under no obligation whatsoever to provide any bug fixes,; patches, or upgrades to the features, functionality or performance of; the source code (""Enhancements"") to anyone; however, if you choose to; make your Enhancements available either publicly, or directly to; Lawrence Berkeley National Laboratory, without imposing a separate; written license agreement for such Enhancements, then you hereby grant; the following license: a non-exclusive, royalty-free perpetual license; to install, use, modify, prepare derivative works, incorporate into; other computer software, distribute, and sublicense such Enhancements; or derivative works thereof, in binary and source code form. Additional copyright holders; ----------------------------. In addition to LBNL/UC Berkeley, this package contains files copyrighted by; one or more of the following people and organizations, and licensed under; the same conditions (except for some compatible licenses as retained in the; source code):. * CERN; * Lucio Asnaghi; * Simone Bacchio; * Robert Bradshaw; * Ellis Breen; * Antonio Cuni; * Aditi Dutta; * Shaheed Haque; * Jonsomi; * Max Kolin; * Alvaro Moran; * Tarmo Pikaro; * Matti Picus; * Camille Scott; * Toby StClere-Smithe; * Stefan Wunsch. Conda-forge recipes were provided by Julian Rueth and Isuru Fernando. External code; -------------.",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/license.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/license.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/license.rst:1858,Deployability,upgrade,upgrades,1858,"RANTIES, INCLUDING, BUT NOT LIMITED; TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR; PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS; BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE; GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION); HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT; LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY; OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF; SUCH DAMAGE. You are under no obligation whatsoever to provide any bug fixes,; patches, or upgrades to the features, functionality or performance of; the source code (""Enhancements"") to anyone; however, if you choose to; make your Enhancements available either publicly, or directly to; Lawrence Berkeley National Laboratory, without imposing a separate; written license agreement for such Enhancements, then you hereby grant; the following license: a non-exclusive, royalty-free perpetual license; to install, use, modify, prepare derivative works, incorporate into; other computer software, distribute, and sublicense such Enhancements; or derivative works thereof, in binary and source code form. Additional copyright holders; ----------------------------. In addition to LBNL/UC Berkeley, this package contains files copyrighted by; one or more of the following people and organizations, and licensed under; the same conditions (except for some compatible licenses as retained in the; source code):. * CERN; * Lucio Asnaghi; * Simone Bacchio; * Robert Bradshaw; * Ellis Breen; * Antonio Cuni; * Aditi Dutta; * Shaheed Haque; * Jonsomi; * Max Kolin; * Alvaro Moran; * Tarmo Pikaro; * Matti Picus; * Camille Scott; * Toby StClere-Smithe; * Stefan Wunsch. Conda-forge recipes were provided by Julian Rueth and Isuru Fernando. External code; -------------.",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/license.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/license.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/license.rst:2269,Deployability,install,install,2269,"RANTIES, INCLUDING, BUT NOT LIMITED; TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR; PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS; BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE; GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION); HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT; LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY; OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF; SUCH DAMAGE. You are under no obligation whatsoever to provide any bug fixes,; patches, or upgrades to the features, functionality or performance of; the source code (""Enhancements"") to anyone; however, if you choose to; make your Enhancements available either publicly, or directly to; Lawrence Berkeley National Laboratory, without imposing a separate; written license agreement for such Enhancements, then you hereby grant; the following license: a non-exclusive, royalty-free perpetual license; to install, use, modify, prepare derivative works, incorporate into; other computer software, distribute, and sublicense such Enhancements; or derivative works thereof, in binary and source code form. Additional copyright holders; ----------------------------. In addition to LBNL/UC Berkeley, this package contains files copyrighted by; one or more of the following people and organizations, and licensed under; the same conditions (except for some compatible licenses as retained in the; source code):. * CERN; * Lucio Asnaghi; * Simone Bacchio; * Robert Bradshaw; * Ellis Breen; * Antonio Cuni; * Aditi Dutta; * Shaheed Haque; * Jonsomi; * Max Kolin; * Alvaro Moran; * Tarmo Pikaro; * Matti Picus; * Camille Scott; * Toby StClere-Smithe; * Stefan Wunsch. Conda-forge recipes were provided by Julian Rueth and Isuru Fernando. External code; -------------.",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/license.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/license.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/license.rst:3455,Deployability,patch,patched,3455,"E, DATA, OR PROFITS; OR BUSINESS INTERRUPTION); HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT; LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY; OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF; SUCH DAMAGE. You are under no obligation whatsoever to provide any bug fixes,; patches, or upgrades to the features, functionality or performance of; the source code (""Enhancements"") to anyone; however, if you choose to; make your Enhancements available either publicly, or directly to; Lawrence Berkeley National Laboratory, without imposing a separate; written license agreement for such Enhancements, then you hereby grant; the following license: a non-exclusive, royalty-free perpetual license; to install, use, modify, prepare derivative works, incorporate into; other computer software, distribute, and sublicense such Enhancements; or derivative works thereof, in binary and source code form. Additional copyright holders; ----------------------------. In addition to LBNL/UC Berkeley, this package contains files copyrighted by; one or more of the following people and organizations, and licensed under; the same conditions (except for some compatible licenses as retained in the; source code):. * CERN; * Lucio Asnaghi; * Simone Bacchio; * Robert Bradshaw; * Ellis Breen; * Antonio Cuni; * Aditi Dutta; * Shaheed Haque; * Jonsomi; * Max Kolin; * Alvaro Moran; * Tarmo Pikaro; * Matti Picus; * Camille Scott; * Toby StClere-Smithe; * Stefan Wunsch. Conda-forge recipes were provided by Julian Rueth and Isuru Fernando. External code; -------------. The create_src_directory.py script will pull in ROOT and LLVM sources, which; are licensed differently:. LLVM: distributed under University of Illinois/NCSA Open Source License; https://opensource.org/licenses/UoI-NCSA.php; ROOT: distributed under LGPL 2.1; https://root.cern.ch/license. The ROOT and LLVM/Clang codes are modified/patched, as part of the build; process.; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/license.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/license.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/license.rst:1901,Performance,perform,performance,1901,"RANTIES, INCLUDING, BUT NOT LIMITED; TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR; PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS; BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR; CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE; GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION); HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT; LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY; OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF; SUCH DAMAGE. You are under no obligation whatsoever to provide any bug fixes,; patches, or upgrades to the features, functionality or performance of; the source code (""Enhancements"") to anyone; however, if you choose to; make your Enhancements available either publicly, or directly to; Lawrence Berkeley National Laboratory, without imposing a separate; written license agreement for such Enhancements, then you hereby grant; the following license: a non-exclusive, royalty-free perpetual license; to install, use, modify, prepare derivative works, incorporate into; other computer software, distribute, and sublicense such Enhancements; or derivative works thereof, in binary and source code form. Additional copyright holders; ----------------------------. In addition to LBNL/UC Berkeley, this package contains files copyrighted by; one or more of the following people and organizations, and licensed under; the same conditions (except for some compatible licenses as retained in the; source code):. * CERN; * Lucio Asnaghi; * Simone Bacchio; * Robert Bradshaw; * Ellis Breen; * Antonio Cuni; * Aditi Dutta; * Shaheed Haque; * Jonsomi; * Max Kolin; * Alvaro Moran; * Tarmo Pikaro; * Matti Picus; * Camille Scott; * Toby StClere-Smithe; * Stefan Wunsch. Conda-forge recipes were provided by Julian Rueth and Isuru Fernando. External code; -------------.",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/license.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/license.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst:1883,Availability,avail,available,1883," use is, or; should be, uncommon).; It needs to be imported explicitly:. .. code-block:: python. >>> import cppyy.ll; >>>. `LowLevelView`; --------------. Python has an elaborate array interface (buffer) specification, but no; standard library array type that completely implements it; instead, the; canonical Python array type is the NumPy one.; cppyy introduces the basic ``LowLevelView`` array class to avoid having a; direct dependency on NumPy and to guarantee zero copy.; The ``LowLevelView`` type gives access to array details such as the size,; type, etc. and allows reading/writing of array elements, both for interactive; use and through the buffer interface to allow NumPy to interface with them.; For more complex operations, it's recommended to copy from the; ``LowLevelView`` inta a NumPy array, or to create a NumPy view (see below,; under :ref:`NumPy Casts <npcasts>`). `C/C++ casts`; -------------. C++ instances are auto-casted to the most derived available type, so do not; require explicit casts even when a function returns a pointer to a base; class or interface.; However, when given only a ``void*`` or ``intptr_t`` type on return, a cast; is required to turn it into something usable. * **bind_object**: This is the preferred method to proxy a C++ address,; and lives in ``cppyy``, not ``cppyy.ll``, as it is not a low-level C++; cast, but a ``cppyy`` API that is also used internally.; It thus plays well with object identity, references, etc.; Example:. .. code-block:: python. >>> cppyy.cppdef(""""""; ... struct MyStruct { int fInt; };; ... void* create_mystruct() { return new MyStruct{42}; }; ... """"""); ... ; >>> s = cppyy.gbl.create_mystruct(); >>> print(s); <cppyy.LowLevelView object at 0x10559d430>; >>> sobj = cppyy.bind_object(s, 'MyStruct'); >>> print(sobj); <cppyy.gbl.MyStruct object at 0x7ff25e28eb20>; >>> print(sobj.fInt); 42; >>>. Instead of the type name as a string, ``bind_object`` can also take the; actual class (here: ``cppyy.gbl.MyStruct``). * **Typed ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst:7396,Availability,avail,available,7396,"object and returns its address as; an integer value.; Takes an optional ``byref`` parameter and if set to true, returns a pointer; to the address instead. * **ll.as_capsule**: Takes a cppyy bound C++ object and returns its address as; a PyCapsule object.; Takes an optional ``byref`` parameter and if set to true, returns a pointer; to the address instead. * **ll.as_cobject**: Takes a cppyy bound C++ object and returns its address as; a PyCObject object for Python2 and a PyCapsule object for Python3.; Takes an optional ``byref`` parameter and if set to true, returns a pointer; to the address instead. * **ll.as_ctypes**: Takes a cppyy bound C++ object and returns its address as; a ``ctypes.c_void_p`` object.; Takes an optional ``byref`` parameter and if set to true, returns a pointer; to the address instead. `ctypes`; --------. The `ctypes module`_ has been part of Python since version 2.5 and provides a; Python-side foreign function interface.; It is clunky to use and has very bad performance, but it is guaranteed to be; available.; It does not have a public C interface, only the Python one, but its internals; have been stable since its introduction, making it safe to use for tight and; efficient integration at the C level (with a few Python helpers to assure; lazy lookup). Objects from ``ctypes`` can be passed through arguments of functions that; take a pointer to a single C++ builtin, and ``ctypes`` pointers can be passed ; when a pointer-to-pointer is expected, e.g. for array out-parameters.; This leads to the following set of possible mappings:. ======================================== ========================================; C++ ctypes; ======================================== ========================================; by value (ex.: ``int``) ``.value`` (ex.: ``c_int(0).value``); by const reference (ex.: ``const int&``) ``.value`` (ex.: ``c_int(0).value``); by reference (ex.: ``int&``) direct (ex.: ``c_int(0)``); by pointer (ex.: ``int*``) direct (ex.: ``c_int(0)",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst:597,Deployability,integrat,integration,597,"Low-level code; ==============. .. toctree::; :hidden:. C code and older C++ code sometimes makes use of low-level features such as; pointers to builtin types, some of which do not have any Python equivalent; (e.g. ``unsigned short*``).; Furthermore, such codes tend to be ambiguous: the information from header; file is not sufficient to determine the full purpose.; For example, an ``int*`` type may refer to the address of a single ``int``; (an out-parameter, say) or it may refer to an array of ``int``, the ownership; of which is not clear either.; cppyy provides a few low-level helpers and integration with the Python; `ctypes module`_ to cover these cases. Use of these low-level helpers will obviously lead to very ""C-like"" code and; it is recommended to :doc:`pythonize <pythonizations>` the code, perhaps; using the Cling JIT and embedded C++. Note: the low-level module is not loaded by default (since its use is, or; should be, uncommon).; It needs to be imported explicitly:. .. code-block:: python. >>> import cppyy.ll; >>>. `LowLevelView`; --------------. Python has an elaborate array interface (buffer) specification, but no; standard library array type that completely implements it; instead, the; canonical Python array type is the NumPy one.; cppyy introduces the basic ``LowLevelView`` array class to avoid having a; direct dependency on NumPy and to guarantee zero copy.; The ``LowLevelView`` type gives access to array details such as the size,; type, etc. and allows reading/writing of array elements, both for interactive; use and through the buffer interface to allow NumPy to interface with them.; For more complex operations, it's recommended to copy from the; ``LowLevelView`` inta a NumPy array, or to create a NumPy view (see below,; under :ref:`NumPy Casts <npcasts>`). `C/C++ casts`; -------------. C++ instances are auto-casted to the most derived available type, so do not; require explicit casts even when a function returns a pointer to a base; class or interface",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst:4815,Deployability,integrat,integration,4815,"(int sz) {; ... int* iptr = (int*)malloc(sizeof(int)*sz);; ... for (int i=0; i<sz; ++i) iptr[i] = i;; ... return iptr;; ... }""""""); ...; >>> NDATA = 4; >>> d = cppyy.gbl.get_data(NDATA); >>> print(d); <cppyy.LowLevelView object at 0x1068cba30>; >>> d = cppyy.ll.cast['int*'](d); >>> d.reshape((NDATA,)); >>> print(list(d)); [0, 1, 2, 3]; >>>. * **C++-style casts**: Similar to the C-style cast, there are; ``ll.static_cast`` and ``ll.reinterpret_cast``.; There should never be a reason for a ``dynamic_cast``, since that only; applies to objects, for which auto-casting will work.; The syntax is ""template-style"", just like for the C-style cast above. .. _npcasts:. `NumPy casts`; -------------. The ``cppyy.LowLevelView`` type returned for pointers to basic types,; including for ``void*``, is a simple and light-weight view on memory, given a; pointer, type, and number of elements (or unchecked, if unknown).; It only supports basic operations such as indexing and iterations, but also; the buffer protocol for integration with full-fledged functional arrays such; as NumPy`s ``ndarray``. In addition, specifically when dealing with ``void*`` returns, you can use; NumPy's low-level ``frombuffer`` interface to perform the cast.; Example:. .. code-block:: python. >>> cppyy.cppdef(""""""; ... void* create_float_array(int sz) {; ... float* pf = (float*)malloc(sizeof(float)*sz);; ... for (int i = 0; i < sz; ++i) pf[i] = 2*i;; ... return pf;; ... }""""""); ...; >>> import numpy as np; >>> NDATA = 8; >>> arr = cppyy.gbl.create_float_array(NDATA); >>> print(arr); <cppyy.LowLevelView object at 0x109f15230>; >>> arr.reshape((NDATA,)) # adjust the llv's size; >>> v = np.frombuffer(arr, dtype=np.float32, count=NDATA) # cast to float; >>> print(len(v)); 8; >>> print(v); array([ 0., 2., 4., 6., 8., 10., 12., 14.], dtype=float32); >>>. Note that NumPy will internally check the total buffer size, so if the size; you are casting *to* is larger than the size you are casting *from*, then; the number of ele",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst:7575,Deployability,integrat,integration,7575,"sule**: Takes a cppyy bound C++ object and returns its address as; a PyCapsule object.; Takes an optional ``byref`` parameter and if set to true, returns a pointer; to the address instead. * **ll.as_cobject**: Takes a cppyy bound C++ object and returns its address as; a PyCObject object for Python2 and a PyCapsule object for Python3.; Takes an optional ``byref`` parameter and if set to true, returns a pointer; to the address instead. * **ll.as_ctypes**: Takes a cppyy bound C++ object and returns its address as; a ``ctypes.c_void_p`` object.; Takes an optional ``byref`` parameter and if set to true, returns a pointer; to the address instead. `ctypes`; --------. The `ctypes module`_ has been part of Python since version 2.5 and provides a; Python-side foreign function interface.; It is clunky to use and has very bad performance, but it is guaranteed to be; available.; It does not have a public C interface, only the Python one, but its internals; have been stable since its introduction, making it safe to use for tight and; efficient integration at the C level (with a few Python helpers to assure; lazy lookup). Objects from ``ctypes`` can be passed through arguments of functions that; take a pointer to a single C++ builtin, and ``ctypes`` pointers can be passed ; when a pointer-to-pointer is expected, e.g. for array out-parameters.; This leads to the following set of possible mappings:. ======================================== ========================================; C++ ctypes; ======================================== ========================================; by value (ex.: ``int``) ``.value`` (ex.: ``c_int(0).value``); by const reference (ex.: ``const int&``) ``.value`` (ex.: ``c_int(0).value``); by reference (ex.: ``int&``) direct (ex.: ``c_int(0)``); by pointer (ex.: ``int*``) direct (ex.: ``c_int(0)``); by ptr-ref (ex.: ``int*&``) ``pointer`` (ex.: ``pointer(c_int(0))``); by ptr-ptr **in** (ex.: ``int**``) ``pointer`` (ex.: ``pointer(c_int(0))``); by ptr-ptr **out*",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst:3026,Energy Efficiency,allocate,allocates,3026,"However, when given only a ``void*`` or ``intptr_t`` type on return, a cast; is required to turn it into something usable. * **bind_object**: This is the preferred method to proxy a C++ address,; and lives in ``cppyy``, not ``cppyy.ll``, as it is not a low-level C++; cast, but a ``cppyy`` API that is also used internally.; It thus plays well with object identity, references, etc.; Example:. .. code-block:: python. >>> cppyy.cppdef(""""""; ... struct MyStruct { int fInt; };; ... void* create_mystruct() { return new MyStruct{42}; }; ... """"""); ... ; >>> s = cppyy.gbl.create_mystruct(); >>> print(s); <cppyy.LowLevelView object at 0x10559d430>; >>> sobj = cppyy.bind_object(s, 'MyStruct'); >>> print(sobj); <cppyy.gbl.MyStruct object at 0x7ff25e28eb20>; >>> print(sobj.fInt); 42; >>>. Instead of the type name as a string, ``bind_object`` can also take the; actual class (here: ``cppyy.gbl.MyStruct``). * **Typed nullptr**: A Python side proxy can pass through a pointer to; pointer function argument, but if the C++ side allocates memory and; stores it in the pointer, the result is a memory leak.; In that case, use ``bind_object`` to bind ``cppyy.nullptr`` instead, to; get a typed nullptr to pass to the function.; Example (continuing from the example above):. .. code-block:: python. >>> cppyy.cppdef(""""""; ... void create_mystruct(MyStruct** ptr) { *ptr = new MyStruct{42}; }; ... """"""); ...; >>> s = cppyy.bind_object(cppyy.nullptr, 'MyStruct'); >>> print(s); <cppyy.gbl.MyStruct object at 0x0>; >>> cppyy.gbl.create_mystruct(s); >>> print(s); <cppyy.gbl.MyStruct object at 0x7fc7d85b91c0>; >>> print(s.fInt); 42; >>>. * **C-style cast**: This is the simplest option for builtin types.; The syntax is ""template-style"", example:. .. code-block:: python. >>> cppyy.cppdef(""""""; ... void* get_data(int sz) {; ... int* iptr = (int*)malloc(sizeof(int)*sz);; ... for (int i=0; i<sz; ++i) iptr[i] = i;; ... return iptr;; ... }""""""); ...; >>> NDATA = 4; >>> d = cppyy.gbl.get_data(NDATA); >>> print(d); <c",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst:7565,Energy Efficiency,efficient,efficient,7565,"sule**: Takes a cppyy bound C++ object and returns its address as; a PyCapsule object.; Takes an optional ``byref`` parameter and if set to true, returns a pointer; to the address instead. * **ll.as_cobject**: Takes a cppyy bound C++ object and returns its address as; a PyCObject object for Python2 and a PyCapsule object for Python3.; Takes an optional ``byref`` parameter and if set to true, returns a pointer; to the address instead. * **ll.as_ctypes**: Takes a cppyy bound C++ object and returns its address as; a ``ctypes.c_void_p`` object.; Takes an optional ``byref`` parameter and if set to true, returns a pointer; to the address instead. `ctypes`; --------. The `ctypes module`_ has been part of Python since version 2.5 and provides a; Python-side foreign function interface.; It is clunky to use and has very bad performance, but it is guaranteed to be; available.; It does not have a public C interface, only the Python one, but its internals; have been stable since its introduction, making it safe to use for tight and; efficient integration at the C level (with a few Python helpers to assure; lazy lookup). Objects from ``ctypes`` can be passed through arguments of functions that; take a pointer to a single C++ builtin, and ``ctypes`` pointers can be passed ; when a pointer-to-pointer is expected, e.g. for array out-parameters.; This leads to the following set of possible mappings:. ======================================== ========================================; C++ ctypes; ======================================== ========================================; by value (ex.: ``int``) ``.value`` (ex.: ``c_int(0).value``); by const reference (ex.: ``const int&``) ``.value`` (ex.: ``c_int(0).value``); by reference (ex.: ``int&``) direct (ex.: ``c_int(0)``); by pointer (ex.: ``int*``) direct (ex.: ``c_int(0)``); by ptr-ref (ex.: ``int*&``) ``pointer`` (ex.: ``pointer(c_int(0))``); by ptr-ptr **in** (ex.: ``int**``) ``pointer`` (ex.: ``pointer(c_int(0))``); by ptr-ptr **out*",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst:9892,Energy Efficiency,allocate,allocated,9892," can pass through all pointer types.; The addresses will be adjusted internally by cppyy. Note that ``ctypes.c_char_p`` is expected to be a NULL-terminated C string,; not a character array (see the `ctypes module`_ documentation), and that; ``ctypes.c_bool`` is a C ``_Bool`` type, not C++ ``bool``. `Memory`; --------. C++ has three ways of allocating heap memory (``malloc``, ``new``, and; ``new[]``) and three corresponding ways of deallocation (``free``,; ``delete``, and ``delete[]``).; Direct use of ``malloc`` and ``new`` should be avoided for C++ classes, as; these may override ``operator new`` to control their own allocation.; However these low-level allocators can be necessary for builtin types on; occasion if the C++ side takes ownership (otherwise, prefer either; ``array`` from the builtin module ``array`` or ``ndarray`` from Numpy). The low-level module adds the following functions:. * **ll.malloc**: an interface on top of C's malloc.; Use it as a template with the number of elements (not the number types) to; be allocated.; The result is a ``cppyy.LowLevelView`` with the proper type and size:. .. code-block:: python. >>> arr = cppyy.ll.malloc[int](4) # allocates memory for 4 C ints; >>> print(len(arr)); 4; >>> print(type(arr[0])); <type 'int'>; >>>. The actual C malloc can also be used directly, through ``cppyy.gbl.malloc``,; taking the number of *bytes* to be allocated and returning a ``void*``. * **ll.free**: an interface to C's free, to deallocate memory allocated by; C's malloc.; To continue to example above:. .. code-block:: python. >>> cppyy.ll.free(arr); >>>. The actual C free can also be used directly, through ``cppyy.gbl.free``. * **ll.array_new**: an interface on top of C++'s ``new[]``.; Use it as a template; the result is a ``cppyy.LowLevelView`` with the; proper type and size:. .. code-block:: python. >>> arr = cppyy.ll.array_new[int](4) # allocates memory for 4 C ints; >>> print(len(arr)); 4; >>> print(type(arr[0])); <type 'int'>; >>>. * **ll.arr",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst:10035,Energy Efficiency,allocate,allocates,10035,"mentation), and that; ``ctypes.c_bool`` is a C ``_Bool`` type, not C++ ``bool``. `Memory`; --------. C++ has three ways of allocating heap memory (``malloc``, ``new``, and; ``new[]``) and three corresponding ways of deallocation (``free``,; ``delete``, and ``delete[]``).; Direct use of ``malloc`` and ``new`` should be avoided for C++ classes, as; these may override ``operator new`` to control their own allocation.; However these low-level allocators can be necessary for builtin types on; occasion if the C++ side takes ownership (otherwise, prefer either; ``array`` from the builtin module ``array`` or ``ndarray`` from Numpy). The low-level module adds the following functions:. * **ll.malloc**: an interface on top of C's malloc.; Use it as a template with the number of elements (not the number types) to; be allocated.; The result is a ``cppyy.LowLevelView`` with the proper type and size:. .. code-block:: python. >>> arr = cppyy.ll.malloc[int](4) # allocates memory for 4 C ints; >>> print(len(arr)); 4; >>> print(type(arr[0])); <type 'int'>; >>>. The actual C malloc can also be used directly, through ``cppyy.gbl.malloc``,; taking the number of *bytes* to be allocated and returning a ``void*``. * **ll.free**: an interface to C's free, to deallocate memory allocated by; C's malloc.; To continue to example above:. .. code-block:: python. >>> cppyy.ll.free(arr); >>>. The actual C free can also be used directly, through ``cppyy.gbl.free``. * **ll.array_new**: an interface on top of C++'s ``new[]``.; Use it as a template; the result is a ``cppyy.LowLevelView`` with the; proper type and size:. .. code-block:: python. >>> arr = cppyy.ll.array_new[int](4) # allocates memory for 4 C ints; >>> print(len(arr)); 4; >>> print(type(arr[0])); <type 'int'>; >>>. * **ll.array_delete**: an interface on top of C++'s ``delete[]``.; To continue to example above:. .. code-block:: python. >>> cppyy.ll.array_delete(arr); >>>. `argc/argv`; -----------. C/C++'s ``main`` function can take the numbe",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst:10247,Energy Efficiency,allocate,allocated,10247," and; ``new[]``) and three corresponding ways of deallocation (``free``,; ``delete``, and ``delete[]``).; Direct use of ``malloc`` and ``new`` should be avoided for C++ classes, as; these may override ``operator new`` to control their own allocation.; However these low-level allocators can be necessary for builtin types on; occasion if the C++ side takes ownership (otherwise, prefer either; ``array`` from the builtin module ``array`` or ``ndarray`` from Numpy). The low-level module adds the following functions:. * **ll.malloc**: an interface on top of C's malloc.; Use it as a template with the number of elements (not the number types) to; be allocated.; The result is a ``cppyy.LowLevelView`` with the proper type and size:. .. code-block:: python. >>> arr = cppyy.ll.malloc[int](4) # allocates memory for 4 C ints; >>> print(len(arr)); 4; >>> print(type(arr[0])); <type 'int'>; >>>. The actual C malloc can also be used directly, through ``cppyy.gbl.malloc``,; taking the number of *bytes* to be allocated and returning a ``void*``. * **ll.free**: an interface to C's free, to deallocate memory allocated by; C's malloc.; To continue to example above:. .. code-block:: python. >>> cppyy.ll.free(arr); >>>. The actual C free can also be used directly, through ``cppyy.gbl.free``. * **ll.array_new**: an interface on top of C++'s ``new[]``.; Use it as a template; the result is a ``cppyy.LowLevelView`` with the; proper type and size:. .. code-block:: python. >>> arr = cppyy.ll.array_new[int](4) # allocates memory for 4 C ints; >>> print(len(arr)); 4; >>> print(type(arr[0])); <type 'int'>; >>>. * **ll.array_delete**: an interface on top of C++'s ``delete[]``.; To continue to example above:. .. code-block:: python. >>> cppyy.ll.array_delete(arr); >>>. `argc/argv`; -----------. C/C++'s ``main`` function can take the number of command line arguments; (``argc``) and their values (``argv``) as function arguments.; A common idiom has these values subsequently passed on to the entry point ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst:10346,Energy Efficiency,allocate,allocated,10346," ``delete[]``).; Direct use of ``malloc`` and ``new`` should be avoided for C++ classes, as; these may override ``operator new`` to control their own allocation.; However these low-level allocators can be necessary for builtin types on; occasion if the C++ side takes ownership (otherwise, prefer either; ``array`` from the builtin module ``array`` or ``ndarray`` from Numpy). The low-level module adds the following functions:. * **ll.malloc**: an interface on top of C's malloc.; Use it as a template with the number of elements (not the number types) to; be allocated.; The result is a ``cppyy.LowLevelView`` with the proper type and size:. .. code-block:: python. >>> arr = cppyy.ll.malloc[int](4) # allocates memory for 4 C ints; >>> print(len(arr)); 4; >>> print(type(arr[0])); <type 'int'>; >>>. The actual C malloc can also be used directly, through ``cppyy.gbl.malloc``,; taking the number of *bytes* to be allocated and returning a ``void*``. * **ll.free**: an interface to C's free, to deallocate memory allocated by; C's malloc.; To continue to example above:. .. code-block:: python. >>> cppyy.ll.free(arr); >>>. The actual C free can also be used directly, through ``cppyy.gbl.free``. * **ll.array_new**: an interface on top of C++'s ``new[]``.; Use it as a template; the result is a ``cppyy.LowLevelView`` with the; proper type and size:. .. code-block:: python. >>> arr = cppyy.ll.array_new[int](4) # allocates memory for 4 C ints; >>> print(len(arr)); 4; >>> print(type(arr[0])); <type 'int'>; >>>. * **ll.array_delete**: an interface on top of C++'s ``delete[]``.; To continue to example above:. .. code-block:: python. >>> cppyy.ll.array_delete(arr); >>>. `argc/argv`; -----------. C/C++'s ``main`` function can take the number of command line arguments; (``argc``) and their values (``argv``) as function arguments.; A common idiom has these values subsequently passed on to the entry point of; e.g. a framework or library.; Since the type of ``argv`` in particular (``char*[]``) ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst:10748,Energy Efficiency,allocate,allocates,10748,"le ``array`` or ``ndarray`` from Numpy). The low-level module adds the following functions:. * **ll.malloc**: an interface on top of C's malloc.; Use it as a template with the number of elements (not the number types) to; be allocated.; The result is a ``cppyy.LowLevelView`` with the proper type and size:. .. code-block:: python. >>> arr = cppyy.ll.malloc[int](4) # allocates memory for 4 C ints; >>> print(len(arr)); 4; >>> print(type(arr[0])); <type 'int'>; >>>. The actual C malloc can also be used directly, through ``cppyy.gbl.malloc``,; taking the number of *bytes* to be allocated and returning a ``void*``. * **ll.free**: an interface to C's free, to deallocate memory allocated by; C's malloc.; To continue to example above:. .. code-block:: python. >>> cppyy.ll.free(arr); >>>. The actual C free can also be used directly, through ``cppyy.gbl.free``. * **ll.array_new**: an interface on top of C++'s ``new[]``.; Use it as a template; the result is a ``cppyy.LowLevelView`` with the; proper type and size:. .. code-block:: python. >>> arr = cppyy.ll.array_new[int](4) # allocates memory for 4 C ints; >>> print(len(arr)); 4; >>> print(type(arr[0])); <type 'int'>; >>>. * **ll.array_delete**: an interface on top of C++'s ``delete[]``.; To continue to example above:. .. code-block:: python. >>> cppyy.ll.array_delete(arr); >>>. `argc/argv`; -----------. C/C++'s ``main`` function can take the number of command line arguments; (``argc``) and their values (``argv``) as function arguments.; A common idiom has these values subsequently passed on to the entry point of; e.g. a framework or library.; Since the type of ``argv`` in particular (``char*[]``) is clunky to work with; in Python, the low level module contains two convenient helper functions,; ``ll.argc()`` and ``ll.argv()``, that convert the command line arguments as; provided by Python's ``sys`` module, into typed values that are can be passed; to by C/C++. .. _`ctypes module`: https://docs.python.org/3/library/ctypes.html; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst:597,Integrability,integrat,integration,597,"Low-level code; ==============. .. toctree::; :hidden:. C code and older C++ code sometimes makes use of low-level features such as; pointers to builtin types, some of which do not have any Python equivalent; (e.g. ``unsigned short*``).; Furthermore, such codes tend to be ambiguous: the information from header; file is not sufficient to determine the full purpose.; For example, an ``int*`` type may refer to the address of a single ``int``; (an out-parameter, say) or it may refer to an array of ``int``, the ownership; of which is not clear either.; cppyy provides a few low-level helpers and integration with the Python; `ctypes module`_ to cover these cases. Use of these low-level helpers will obviously lead to very ""C-like"" code and; it is recommended to :doc:`pythonize <pythonizations>` the code, perhaps; using the Cling JIT and embedded C++. Note: the low-level module is not loaded by default (since its use is, or; should be, uncommon).; It needs to be imported explicitly:. .. code-block:: python. >>> import cppyy.ll; >>>. `LowLevelView`; --------------. Python has an elaborate array interface (buffer) specification, but no; standard library array type that completely implements it; instead, the; canonical Python array type is the NumPy one.; cppyy introduces the basic ``LowLevelView`` array class to avoid having a; direct dependency on NumPy and to guarantee zero copy.; The ``LowLevelView`` type gives access to array details such as the size,; type, etc. and allows reading/writing of array elements, both for interactive; use and through the buffer interface to allow NumPy to interface with them.; For more complex operations, it's recommended to copy from the; ``LowLevelView`` inta a NumPy array, or to create a NumPy view (see below,; under :ref:`NumPy Casts <npcasts>`). `C/C++ casts`; -------------. C++ instances are auto-casted to the most derived available type, so do not; require explicit casts even when a function returns a pointer to a base; class or interface",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst:1102,Integrability,interface,interface,1102,"f which do not have any Python equivalent; (e.g. ``unsigned short*``).; Furthermore, such codes tend to be ambiguous: the information from header; file is not sufficient to determine the full purpose.; For example, an ``int*`` type may refer to the address of a single ``int``; (an out-parameter, say) or it may refer to an array of ``int``, the ownership; of which is not clear either.; cppyy provides a few low-level helpers and integration with the Python; `ctypes module`_ to cover these cases. Use of these low-level helpers will obviously lead to very ""C-like"" code and; it is recommended to :doc:`pythonize <pythonizations>` the code, perhaps; using the Cling JIT and embedded C++. Note: the low-level module is not loaded by default (since its use is, or; should be, uncommon).; It needs to be imported explicitly:. .. code-block:: python. >>> import cppyy.ll; >>>. `LowLevelView`; --------------. Python has an elaborate array interface (buffer) specification, but no; standard library array type that completely implements it; instead, the; canonical Python array type is the NumPy one.; cppyy introduces the basic ``LowLevelView`` array class to avoid having a; direct dependency on NumPy and to guarantee zero copy.; The ``LowLevelView`` type gives access to array details such as the size,; type, etc. and allows reading/writing of array elements, both for interactive; use and through the buffer interface to allow NumPy to interface with them.; For more complex operations, it's recommended to copy from the; ``LowLevelView`` inta a NumPy array, or to create a NumPy view (see below,; under :ref:`NumPy Casts <npcasts>`). `C/C++ casts`; -------------. C++ instances are auto-casted to the most derived available type, so do not; require explicit casts even when a function returns a pointer to a base; class or interface.; However, when given only a ``void*`` or ``intptr_t`` type on return, a cast; is required to turn it into something usable. * **bind_object**: This is the preferred",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst:1346,Integrability,depend,dependency,1346,"fficient to determine the full purpose.; For example, an ``int*`` type may refer to the address of a single ``int``; (an out-parameter, say) or it may refer to an array of ``int``, the ownership; of which is not clear either.; cppyy provides a few low-level helpers and integration with the Python; `ctypes module`_ to cover these cases. Use of these low-level helpers will obviously lead to very ""C-like"" code and; it is recommended to :doc:`pythonize <pythonizations>` the code, perhaps; using the Cling JIT and embedded C++. Note: the low-level module is not loaded by default (since its use is, or; should be, uncommon).; It needs to be imported explicitly:. .. code-block:: python. >>> import cppyy.ll; >>>. `LowLevelView`; --------------. Python has an elaborate array interface (buffer) specification, but no; standard library array type that completely implements it; instead, the; canonical Python array type is the NumPy one.; cppyy introduces the basic ``LowLevelView`` array class to avoid having a; direct dependency on NumPy and to guarantee zero copy.; The ``LowLevelView`` type gives access to array details such as the size,; type, etc. and allows reading/writing of array elements, both for interactive; use and through the buffer interface to allow NumPy to interface with them.; For more complex operations, it's recommended to copy from the; ``LowLevelView`` inta a NumPy array, or to create a NumPy view (see below,; under :ref:`NumPy Casts <npcasts>`). `C/C++ casts`; -------------. C++ instances are auto-casted to the most derived available type, so do not; require explicit casts even when a function returns a pointer to a base; class or interface.; However, when given only a ``void*`` or ``intptr_t`` type on return, a cast; is required to turn it into something usable. * **bind_object**: This is the preferred method to proxy a C++ address,; and lives in ``cppyy``, not ``cppyy.ll``, as it is not a low-level C++; cast, but a ``cppyy`` API that is also used internally.;",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst:1576,Integrability,interface,interface,1576,"; cppyy provides a few low-level helpers and integration with the Python; `ctypes module`_ to cover these cases. Use of these low-level helpers will obviously lead to very ""C-like"" code and; it is recommended to :doc:`pythonize <pythonizations>` the code, perhaps; using the Cling JIT and embedded C++. Note: the low-level module is not loaded by default (since its use is, or; should be, uncommon).; It needs to be imported explicitly:. .. code-block:: python. >>> import cppyy.ll; >>>. `LowLevelView`; --------------. Python has an elaborate array interface (buffer) specification, but no; standard library array type that completely implements it; instead, the; canonical Python array type is the NumPy one.; cppyy introduces the basic ``LowLevelView`` array class to avoid having a; direct dependency on NumPy and to guarantee zero copy.; The ``LowLevelView`` type gives access to array details such as the size,; type, etc. and allows reading/writing of array elements, both for interactive; use and through the buffer interface to allow NumPy to interface with them.; For more complex operations, it's recommended to copy from the; ``LowLevelView`` inta a NumPy array, or to create a NumPy view (see below,; under :ref:`NumPy Casts <npcasts>`). `C/C++ casts`; -------------. C++ instances are auto-casted to the most derived available type, so do not; require explicit casts even when a function returns a pointer to a base; class or interface.; However, when given only a ``void*`` or ``intptr_t`` type on return, a cast; is required to turn it into something usable. * **bind_object**: This is the preferred method to proxy a C++ address,; and lives in ``cppyy``, not ``cppyy.ll``, as it is not a low-level C++; cast, but a ``cppyy`` API that is also used internally.; It thus plays well with object identity, references, etc.; Example:. .. code-block:: python. >>> cppyy.cppdef(""""""; ... struct MyStruct { int fInt; };; ... void* create_mystruct() { return new MyStruct{42}; }; ... """"""); ... ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst:1604,Integrability,interface,interface,1604,"; cppyy provides a few low-level helpers and integration with the Python; `ctypes module`_ to cover these cases. Use of these low-level helpers will obviously lead to very ""C-like"" code and; it is recommended to :doc:`pythonize <pythonizations>` the code, perhaps; using the Cling JIT and embedded C++. Note: the low-level module is not loaded by default (since its use is, or; should be, uncommon).; It needs to be imported explicitly:. .. code-block:: python. >>> import cppyy.ll; >>>. `LowLevelView`; --------------. Python has an elaborate array interface (buffer) specification, but no; standard library array type that completely implements it; instead, the; canonical Python array type is the NumPy one.; cppyy introduces the basic ``LowLevelView`` array class to avoid having a; direct dependency on NumPy and to guarantee zero copy.; The ``LowLevelView`` type gives access to array details such as the size,; type, etc. and allows reading/writing of array elements, both for interactive; use and through the buffer interface to allow NumPy to interface with them.; For more complex operations, it's recommended to copy from the; ``LowLevelView`` inta a NumPy array, or to create a NumPy view (see below,; under :ref:`NumPy Casts <npcasts>`). `C/C++ casts`; -------------. C++ instances are auto-casted to the most derived available type, so do not; require explicit casts even when a function returns a pointer to a base; class or interface.; However, when given only a ``void*`` or ``intptr_t`` type on return, a cast; is required to turn it into something usable. * **bind_object**: This is the preferred method to proxy a C++ address,; and lives in ``cppyy``, not ``cppyy.ll``, as it is not a low-level C++; cast, but a ``cppyy`` API that is also used internally.; It thus plays well with object identity, references, etc.; Example:. .. code-block:: python. >>> cppyy.cppdef(""""""; ... struct MyStruct { int fInt; };; ... void* create_mystruct() { return new MyStruct{42}; }; ... """"""); ... ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst:1992,Integrability,interface,interface,1992," use is, or; should be, uncommon).; It needs to be imported explicitly:. .. code-block:: python. >>> import cppyy.ll; >>>. `LowLevelView`; --------------. Python has an elaborate array interface (buffer) specification, but no; standard library array type that completely implements it; instead, the; canonical Python array type is the NumPy one.; cppyy introduces the basic ``LowLevelView`` array class to avoid having a; direct dependency on NumPy and to guarantee zero copy.; The ``LowLevelView`` type gives access to array details such as the size,; type, etc. and allows reading/writing of array elements, both for interactive; use and through the buffer interface to allow NumPy to interface with them.; For more complex operations, it's recommended to copy from the; ``LowLevelView`` inta a NumPy array, or to create a NumPy view (see below,; under :ref:`NumPy Casts <npcasts>`). `C/C++ casts`; -------------. C++ instances are auto-casted to the most derived available type, so do not; require explicit casts even when a function returns a pointer to a base; class or interface.; However, when given only a ``void*`` or ``intptr_t`` type on return, a cast; is required to turn it into something usable. * **bind_object**: This is the preferred method to proxy a C++ address,; and lives in ``cppyy``, not ``cppyy.ll``, as it is not a low-level C++; cast, but a ``cppyy`` API that is also used internally.; It thus plays well with object identity, references, etc.; Example:. .. code-block:: python. >>> cppyy.cppdef(""""""; ... struct MyStruct { int fInt; };; ... void* create_mystruct() { return new MyStruct{42}; }; ... """"""); ... ; >>> s = cppyy.gbl.create_mystruct(); >>> print(s); <cppyy.LowLevelView object at 0x10559d430>; >>> sobj = cppyy.bind_object(s, 'MyStruct'); >>> print(sobj); <cppyy.gbl.MyStruct object at 0x7ff25e28eb20>; >>> print(sobj.fInt); 42; >>>. Instead of the type name as a string, ``bind_object`` can also take the; actual class (here: ``cppyy.gbl.MyStruct``). * **Typed ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst:4802,Integrability,protocol,protocol,4802,"(int sz) {; ... int* iptr = (int*)malloc(sizeof(int)*sz);; ... for (int i=0; i<sz; ++i) iptr[i] = i;; ... return iptr;; ... }""""""); ...; >>> NDATA = 4; >>> d = cppyy.gbl.get_data(NDATA); >>> print(d); <cppyy.LowLevelView object at 0x1068cba30>; >>> d = cppyy.ll.cast['int*'](d); >>> d.reshape((NDATA,)); >>> print(list(d)); [0, 1, 2, 3]; >>>. * **C++-style casts**: Similar to the C-style cast, there are; ``ll.static_cast`` and ``ll.reinterpret_cast``.; There should never be a reason for a ``dynamic_cast``, since that only; applies to objects, for which auto-casting will work.; The syntax is ""template-style"", just like for the C-style cast above. .. _npcasts:. `NumPy casts`; -------------. The ``cppyy.LowLevelView`` type returned for pointers to basic types,; including for ``void*``, is a simple and light-weight view on memory, given a; pointer, type, and number of elements (or unchecked, if unknown).; It only supports basic operations such as indexing and iterations, but also; the buffer protocol for integration with full-fledged functional arrays such; as NumPy`s ``ndarray``. In addition, specifically when dealing with ``void*`` returns, you can use; NumPy's low-level ``frombuffer`` interface to perform the cast.; Example:. .. code-block:: python. >>> cppyy.cppdef(""""""; ... void* create_float_array(int sz) {; ... float* pf = (float*)malloc(sizeof(float)*sz);; ... for (int i = 0; i < sz; ++i) pf[i] = 2*i;; ... return pf;; ... }""""""); ...; >>> import numpy as np; >>> NDATA = 8; >>> arr = cppyy.gbl.create_float_array(NDATA); >>> print(arr); <cppyy.LowLevelView object at 0x109f15230>; >>> arr.reshape((NDATA,)) # adjust the llv's size; >>> v = np.frombuffer(arr, dtype=np.float32, count=NDATA) # cast to float; >>> print(len(v)); 8; >>> print(v); array([ 0., 2., 4., 6., 8., 10., 12., 14.], dtype=float32); >>>. Note that NumPy will internally check the total buffer size, so if the size; you are casting *to* is larger than the size you are casting *from*, then; the number of ele",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst:4815,Integrability,integrat,integration,4815,"(int sz) {; ... int* iptr = (int*)malloc(sizeof(int)*sz);; ... for (int i=0; i<sz; ++i) iptr[i] = i;; ... return iptr;; ... }""""""); ...; >>> NDATA = 4; >>> d = cppyy.gbl.get_data(NDATA); >>> print(d); <cppyy.LowLevelView object at 0x1068cba30>; >>> d = cppyy.ll.cast['int*'](d); >>> d.reshape((NDATA,)); >>> print(list(d)); [0, 1, 2, 3]; >>>. * **C++-style casts**: Similar to the C-style cast, there are; ``ll.static_cast`` and ``ll.reinterpret_cast``.; There should never be a reason for a ``dynamic_cast``, since that only; applies to objects, for which auto-casting will work.; The syntax is ""template-style"", just like for the C-style cast above. .. _npcasts:. `NumPy casts`; -------------. The ``cppyy.LowLevelView`` type returned for pointers to basic types,; including for ``void*``, is a simple and light-weight view on memory, given a; pointer, type, and number of elements (or unchecked, if unknown).; It only supports basic operations such as indexing and iterations, but also; the buffer protocol for integration with full-fledged functional arrays such; as NumPy`s ``ndarray``. In addition, specifically when dealing with ``void*`` returns, you can use; NumPy's low-level ``frombuffer`` interface to perform the cast.; Example:. .. code-block:: python. >>> cppyy.cppdef(""""""; ... void* create_float_array(int sz) {; ... float* pf = (float*)malloc(sizeof(float)*sz);; ... for (int i = 0; i < sz; ++i) pf[i] = 2*i;; ... return pf;; ... }""""""); ...; >>> import numpy as np; >>> NDATA = 8; >>> arr = cppyy.gbl.create_float_array(NDATA); >>> print(arr); <cppyy.LowLevelView object at 0x109f15230>; >>> arr.reshape((NDATA,)) # adjust the llv's size; >>> v = np.frombuffer(arr, dtype=np.float32, count=NDATA) # cast to float; >>> print(len(v)); 8; >>> print(v); array([ 0., 2., 4., 6., 8., 10., 12., 14.], dtype=float32); >>>. Note that NumPy will internally check the total buffer size, so if the size; you are casting *to* is larger than the size you are casting *from*, then; the number of ele",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst:5002,Integrability,interface,interface,5002,"ppyy.gbl.get_data(NDATA); >>> print(d); <cppyy.LowLevelView object at 0x1068cba30>; >>> d = cppyy.ll.cast['int*'](d); >>> d.reshape((NDATA,)); >>> print(list(d)); [0, 1, 2, 3]; >>>. * **C++-style casts**: Similar to the C-style cast, there are; ``ll.static_cast`` and ``ll.reinterpret_cast``.; There should never be a reason for a ``dynamic_cast``, since that only; applies to objects, for which auto-casting will work.; The syntax is ""template-style"", just like for the C-style cast above. .. _npcasts:. `NumPy casts`; -------------. The ``cppyy.LowLevelView`` type returned for pointers to basic types,; including for ``void*``, is a simple and light-weight view on memory, given a; pointer, type, and number of elements (or unchecked, if unknown).; It only supports basic operations such as indexing and iterations, but also; the buffer protocol for integration with full-fledged functional arrays such; as NumPy`s ``ndarray``. In addition, specifically when dealing with ``void*`` returns, you can use; NumPy's low-level ``frombuffer`` interface to perform the cast.; Example:. .. code-block:: python. >>> cppyy.cppdef(""""""; ... void* create_float_array(int sz) {; ... float* pf = (float*)malloc(sizeof(float)*sz);; ... for (int i = 0; i < sz; ++i) pf[i] = 2*i;; ... return pf;; ... }""""""); ...; >>> import numpy as np; >>> NDATA = 8; >>> arr = cppyy.gbl.create_float_array(NDATA); >>> print(arr); <cppyy.LowLevelView object at 0x109f15230>; >>> arr.reshape((NDATA,)) # adjust the llv's size; >>> v = np.frombuffer(arr, dtype=np.float32, count=NDATA) # cast to float; >>> print(len(v)); 8; >>> print(v); array([ 0., 2., 4., 6., 8., 10., 12., 14.], dtype=float32); >>>. Note that NumPy will internally check the total buffer size, so if the size; you are casting *to* is larger than the size you are casting *from*, then; the number of elements set in the ``reshape`` call needs to be adjusted; accordingly. `Capsules`; ----------. It is not possible to pass proxies from cppyy through function argu",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst:7306,Integrability,interface,interface,7306," least one of the following:. * **ll.addressof**: Takes a cppyy bound C++ object and returns its address as; an integer value.; Takes an optional ``byref`` parameter and if set to true, returns a pointer; to the address instead. * **ll.as_capsule**: Takes a cppyy bound C++ object and returns its address as; a PyCapsule object.; Takes an optional ``byref`` parameter and if set to true, returns a pointer; to the address instead. * **ll.as_cobject**: Takes a cppyy bound C++ object and returns its address as; a PyCObject object for Python2 and a PyCapsule object for Python3.; Takes an optional ``byref`` parameter and if set to true, returns a pointer; to the address instead. * **ll.as_ctypes**: Takes a cppyy bound C++ object and returns its address as; a ``ctypes.c_void_p`` object.; Takes an optional ``byref`` parameter and if set to true, returns a pointer; to the address instead. `ctypes`; --------. The `ctypes module`_ has been part of Python since version 2.5 and provides a; Python-side foreign function interface.; It is clunky to use and has very bad performance, but it is guaranteed to be; available.; It does not have a public C interface, only the Python one, but its internals; have been stable since its introduction, making it safe to use for tight and; efficient integration at the C level (with a few Python helpers to assure; lazy lookup). Objects from ``ctypes`` can be passed through arguments of functions that; take a pointer to a single C++ builtin, and ``ctypes`` pointers can be passed ; when a pointer-to-pointer is expected, e.g. for array out-parameters.; This leads to the following set of possible mappings:. ======================================== ========================================; C++ ctypes; ======================================== ========================================; by value (ex.: ``int``) ``.value`` (ex.: ``c_int(0).value``); by const reference (ex.: ``const int&``) ``.value`` (ex.: ``c_int(0).value``); by reference (ex.: ``int&``) direc",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst:7436,Integrability,interface,interface,7436,"sule**: Takes a cppyy bound C++ object and returns its address as; a PyCapsule object.; Takes an optional ``byref`` parameter and if set to true, returns a pointer; to the address instead. * **ll.as_cobject**: Takes a cppyy bound C++ object and returns its address as; a PyCObject object for Python2 and a PyCapsule object for Python3.; Takes an optional ``byref`` parameter and if set to true, returns a pointer; to the address instead. * **ll.as_ctypes**: Takes a cppyy bound C++ object and returns its address as; a ``ctypes.c_void_p`` object.; Takes an optional ``byref`` parameter and if set to true, returns a pointer; to the address instead. `ctypes`; --------. The `ctypes module`_ has been part of Python since version 2.5 and provides a; Python-side foreign function interface.; It is clunky to use and has very bad performance, but it is guaranteed to be; available.; It does not have a public C interface, only the Python one, but its internals; have been stable since its introduction, making it safe to use for tight and; efficient integration at the C level (with a few Python helpers to assure; lazy lookup). Objects from ``ctypes`` can be passed through arguments of functions that; take a pointer to a single C++ builtin, and ``ctypes`` pointers can be passed ; when a pointer-to-pointer is expected, e.g. for array out-parameters.; This leads to the following set of possible mappings:. ======================================== ========================================; C++ ctypes; ======================================== ========================================; by value (ex.: ``int``) ``.value`` (ex.: ``c_int(0).value``); by const reference (ex.: ``const int&``) ``.value`` (ex.: ``c_int(0).value``); by reference (ex.: ``int&``) direct (ex.: ``c_int(0)``); by pointer (ex.: ``int*``) direct (ex.: ``c_int(0)``); by ptr-ref (ex.: ``int*&``) ``pointer`` (ex.: ``pointer(c_int(0))``); by ptr-ptr **in** (ex.: ``int**``) ``pointer`` (ex.: ``pointer(c_int(0))``); by ptr-ptr **out*",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst:7575,Integrability,integrat,integration,7575,"sule**: Takes a cppyy bound C++ object and returns its address as; a PyCapsule object.; Takes an optional ``byref`` parameter and if set to true, returns a pointer; to the address instead. * **ll.as_cobject**: Takes a cppyy bound C++ object and returns its address as; a PyCObject object for Python2 and a PyCapsule object for Python3.; Takes an optional ``byref`` parameter and if set to true, returns a pointer; to the address instead. * **ll.as_ctypes**: Takes a cppyy bound C++ object and returns its address as; a ``ctypes.c_void_p`` object.; Takes an optional ``byref`` parameter and if set to true, returns a pointer; to the address instead. `ctypes`; --------. The `ctypes module`_ has been part of Python since version 2.5 and provides a; Python-side foreign function interface.; It is clunky to use and has very bad performance, but it is guaranteed to be; available.; It does not have a public C interface, only the Python one, but its internals; have been stable since its introduction, making it safe to use for tight and; efficient integration at the C level (with a few Python helpers to assure; lazy lookup). Objects from ``ctypes`` can be passed through arguments of functions that; take a pointer to a single C++ builtin, and ``ctypes`` pointers can be passed ; when a pointer-to-pointer is expected, e.g. for array out-parameters.; This leads to the following set of possible mappings:. ======================================== ========================================; C++ ctypes; ======================================== ========================================; by value (ex.: ``int``) ``.value`` (ex.: ``c_int(0).value``); by const reference (ex.: ``const int&``) ``.value`` (ex.: ``c_int(0).value``); by reference (ex.: ``int&``) direct (ex.: ``c_int(0)``); by pointer (ex.: ``int*``) direct (ex.: ``c_int(0)``); by ptr-ref (ex.: ``int*&``) ``pointer`` (ex.: ``pointer(c_int(0))``); by ptr-ptr **in** (ex.: ``int**``) ``pointer`` (ex.: ``pointer(c_int(0))``); by ptr-ptr **out*",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst:9780,Integrability,interface,interface,9780," or pointer, instead of the direct; object, and ``ctypes.c_void_p`` can pass through all pointer types.; The addresses will be adjusted internally by cppyy. Note that ``ctypes.c_char_p`` is expected to be a NULL-terminated C string,; not a character array (see the `ctypes module`_ documentation), and that; ``ctypes.c_bool`` is a C ``_Bool`` type, not C++ ``bool``. `Memory`; --------. C++ has three ways of allocating heap memory (``malloc``, ``new``, and; ``new[]``) and three corresponding ways of deallocation (``free``,; ``delete``, and ``delete[]``).; Direct use of ``malloc`` and ``new`` should be avoided for C++ classes, as; these may override ``operator new`` to control their own allocation.; However these low-level allocators can be necessary for builtin types on; occasion if the C++ side takes ownership (otherwise, prefer either; ``array`` from the builtin module ``array`` or ``ndarray`` from Numpy). The low-level module adds the following functions:. * **ll.malloc**: an interface on top of C's malloc.; Use it as a template with the number of elements (not the number types) to; be allocated.; The result is a ``cppyy.LowLevelView`` with the proper type and size:. .. code-block:: python. >>> arr = cppyy.ll.malloc[int](4) # allocates memory for 4 C ints; >>> print(len(arr)); 4; >>> print(type(arr[0])); <type 'int'>; >>>. The actual C malloc can also be used directly, through ``cppyy.gbl.malloc``,; taking the number of *bytes* to be allocated and returning a ``void*``. * **ll.free**: an interface to C's free, to deallocate memory allocated by; C's malloc.; To continue to example above:. .. code-block:: python. >>> cppyy.ll.free(arr); >>>. The actual C free can also be used directly, through ``cppyy.gbl.free``. * **ll.array_new**: an interface on top of C++'s ``new[]``.; Use it as a template; the result is a ``cppyy.LowLevelView`` with the; proper type and size:. .. code-block:: python. >>> arr = cppyy.ll.array_new[int](4) # allocates memory for 4 C ints; >>> print(",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst:10302,Integrability,interface,interface,10302," ``delete[]``).; Direct use of ``malloc`` and ``new`` should be avoided for C++ classes, as; these may override ``operator new`` to control their own allocation.; However these low-level allocators can be necessary for builtin types on; occasion if the C++ side takes ownership (otherwise, prefer either; ``array`` from the builtin module ``array`` or ``ndarray`` from Numpy). The low-level module adds the following functions:. * **ll.malloc**: an interface on top of C's malloc.; Use it as a template with the number of elements (not the number types) to; be allocated.; The result is a ``cppyy.LowLevelView`` with the proper type and size:. .. code-block:: python. >>> arr = cppyy.ll.malloc[int](4) # allocates memory for 4 C ints; >>> print(len(arr)); 4; >>> print(type(arr[0])); <type 'int'>; >>>. The actual C malloc can also be used directly, through ``cppyy.gbl.malloc``,; taking the number of *bytes* to be allocated and returning a ``void*``. * **ll.free**: an interface to C's free, to deallocate memory allocated by; C's malloc.; To continue to example above:. .. code-block:: python. >>> cppyy.ll.free(arr); >>>. The actual C free can also be used directly, through ``cppyy.gbl.free``. * **ll.array_new**: an interface on top of C++'s ``new[]``.; Use it as a template; the result is a ``cppyy.LowLevelView`` with the; proper type and size:. .. code-block:: python. >>> arr = cppyy.ll.array_new[int](4) # allocates memory for 4 C ints; >>> print(len(arr)); 4; >>> print(type(arr[0])); <type 'int'>; >>>. * **ll.array_delete**: an interface on top of C++'s ``delete[]``.; To continue to example above:. .. code-block:: python. >>> cppyy.ll.array_delete(arr); >>>. `argc/argv`; -----------. C/C++'s ``main`` function can take the number of command line arguments; (``argc``) and their values (``argv``) as function arguments.; A common idiom has these values subsequently passed on to the entry point of; e.g. a framework or library.; Since the type of ``argv`` in particular (``char*[]``) ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst:10553,Integrability,interface,interface,10553," on; occasion if the C++ side takes ownership (otherwise, prefer either; ``array`` from the builtin module ``array`` or ``ndarray`` from Numpy). The low-level module adds the following functions:. * **ll.malloc**: an interface on top of C's malloc.; Use it as a template with the number of elements (not the number types) to; be allocated.; The result is a ``cppyy.LowLevelView`` with the proper type and size:. .. code-block:: python. >>> arr = cppyy.ll.malloc[int](4) # allocates memory for 4 C ints; >>> print(len(arr)); 4; >>> print(type(arr[0])); <type 'int'>; >>>. The actual C malloc can also be used directly, through ``cppyy.gbl.malloc``,; taking the number of *bytes* to be allocated and returning a ``void*``. * **ll.free**: an interface to C's free, to deallocate memory allocated by; C's malloc.; To continue to example above:. .. code-block:: python. >>> cppyy.ll.free(arr); >>>. The actual C free can also be used directly, through ``cppyy.gbl.free``. * **ll.array_new**: an interface on top of C++'s ``new[]``.; Use it as a template; the result is a ``cppyy.LowLevelView`` with the; proper type and size:. .. code-block:: python. >>> arr = cppyy.ll.array_new[int](4) # allocates memory for 4 C ints; >>> print(len(arr)); 4; >>> print(type(arr[0])); <type 'int'>; >>>. * **ll.array_delete**: an interface on top of C++'s ``delete[]``.; To continue to example above:. .. code-block:: python. >>> cppyy.ll.array_delete(arr); >>>. `argc/argv`; -----------. C/C++'s ``main`` function can take the number of command line arguments; (``argc``) and their values (``argv``) as function arguments.; A common idiom has these values subsequently passed on to the entry point of; e.g. a framework or library.; Since the type of ``argv`` in particular (``char*[]``) is clunky to work with; in Python, the low level module contains two convenient helper functions,; ``ll.argc()`` and ``ll.argv()``, that convert the command line arguments as; provided by Python's ``sys`` module, into typed values t",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst:10873,Integrability,interface,interface,10873,"le ``array`` or ``ndarray`` from Numpy). The low-level module adds the following functions:. * **ll.malloc**: an interface on top of C's malloc.; Use it as a template with the number of elements (not the number types) to; be allocated.; The result is a ``cppyy.LowLevelView`` with the proper type and size:. .. code-block:: python. >>> arr = cppyy.ll.malloc[int](4) # allocates memory for 4 C ints; >>> print(len(arr)); 4; >>> print(type(arr[0])); <type 'int'>; >>>. The actual C malloc can also be used directly, through ``cppyy.gbl.malloc``,; taking the number of *bytes* to be allocated and returning a ``void*``. * **ll.free**: an interface to C's free, to deallocate memory allocated by; C's malloc.; To continue to example above:. .. code-block:: python. >>> cppyy.ll.free(arr); >>>. The actual C free can also be used directly, through ``cppyy.gbl.free``. * **ll.array_new**: an interface on top of C++'s ``new[]``.; Use it as a template; the result is a ``cppyy.LowLevelView`` with the; proper type and size:. .. code-block:: python. >>> arr = cppyy.ll.array_new[int](4) # allocates memory for 4 C ints; >>> print(len(arr)); 4; >>> print(type(arr[0])); <type 'int'>; >>>. * **ll.array_delete**: an interface on top of C++'s ``delete[]``.; To continue to example above:. .. code-block:: python. >>> cppyy.ll.array_delete(arr); >>>. `argc/argv`; -----------. C/C++'s ``main`` function can take the number of command line arguments; (``argc``) and their values (``argv``) as function arguments.; A common idiom has these values subsequently passed on to the entry point of; e.g. a framework or library.; Since the type of ``argv`` in particular (``char*[]``) is clunky to work with; in Python, the low level module contains two convenient helper functions,; ``ll.argc()`` and ``ll.argv()``, that convert the command line arguments as; provided by Python's ``sys`` module, into typed values that are can be passed; to by C/C++. .. _`ctypes module`: https://docs.python.org/3/library/ctypes.html; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst:889,Performance,load,loaded,889,"Low-level code; ==============. .. toctree::; :hidden:. C code and older C++ code sometimes makes use of low-level features such as; pointers to builtin types, some of which do not have any Python equivalent; (e.g. ``unsigned short*``).; Furthermore, such codes tend to be ambiguous: the information from header; file is not sufficient to determine the full purpose.; For example, an ``int*`` type may refer to the address of a single ``int``; (an out-parameter, say) or it may refer to an array of ``int``, the ownership; of which is not clear either.; cppyy provides a few low-level helpers and integration with the Python; `ctypes module`_ to cover these cases. Use of these low-level helpers will obviously lead to very ""C-like"" code and; it is recommended to :doc:`pythonize <pythonizations>` the code, perhaps; using the Cling JIT and embedded C++. Note: the low-level module is not loaded by default (since its use is, or; should be, uncommon).; It needs to be imported explicitly:. .. code-block:: python. >>> import cppyy.ll; >>>. `LowLevelView`; --------------. Python has an elaborate array interface (buffer) specification, but no; standard library array type that completely implements it; instead, the; canonical Python array type is the NumPy one.; cppyy introduces the basic ``LowLevelView`` array class to avoid having a; direct dependency on NumPy and to guarantee zero copy.; The ``LowLevelView`` type gives access to array details such as the size,; type, etc. and allows reading/writing of array elements, both for interactive; use and through the buffer interface to allow NumPy to interface with them.; For more complex operations, it's recommended to copy from the; ``LowLevelView`` inta a NumPy array, or to create a NumPy view (see below,; under :ref:`NumPy Casts <npcasts>`). `C/C++ casts`; -------------. C++ instances are auto-casted to the most derived available type, so do not; require explicit casts even when a function returns a pointer to a base; class or interface",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst:5015,Performance,perform,perform,5015,"ppyy.gbl.get_data(NDATA); >>> print(d); <cppyy.LowLevelView object at 0x1068cba30>; >>> d = cppyy.ll.cast['int*'](d); >>> d.reshape((NDATA,)); >>> print(list(d)); [0, 1, 2, 3]; >>>. * **C++-style casts**: Similar to the C-style cast, there are; ``ll.static_cast`` and ``ll.reinterpret_cast``.; There should never be a reason for a ``dynamic_cast``, since that only; applies to objects, for which auto-casting will work.; The syntax is ""template-style"", just like for the C-style cast above. .. _npcasts:. `NumPy casts`; -------------. The ``cppyy.LowLevelView`` type returned for pointers to basic types,; including for ``void*``, is a simple and light-weight view on memory, given a; pointer, type, and number of elements (or unchecked, if unknown).; It only supports basic operations such as indexing and iterations, but also; the buffer protocol for integration with full-fledged functional arrays such; as NumPy`s ``ndarray``. In addition, specifically when dealing with ``void*`` returns, you can use; NumPy's low-level ``frombuffer`` interface to perform the cast.; Example:. .. code-block:: python. >>> cppyy.cppdef(""""""; ... void* create_float_array(int sz) {; ... float* pf = (float*)malloc(sizeof(float)*sz);; ... for (int i = 0; i < sz; ++i) pf[i] = 2*i;; ... return pf;; ... }""""""); ...; >>> import numpy as np; >>> NDATA = 8; >>> arr = cppyy.gbl.create_float_array(NDATA); >>> print(arr); <cppyy.LowLevelView object at 0x109f15230>; >>> arr.reshape((NDATA,)) # adjust the llv's size; >>> v = np.frombuffer(arr, dtype=np.float32, count=NDATA) # cast to float; >>> print(len(v)); 8; >>> print(v); array([ 0., 2., 4., 6., 8., 10., 12., 14.], dtype=float32); >>>. Note that NumPy will internally check the total buffer size, so if the size; you are casting *to* is larger than the size you are casting *from*, then; the number of elements set in the ``reshape`` call needs to be adjusted; accordingly. `Capsules`; ----------. It is not possible to pass proxies from cppyy through function argu",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst:7355,Performance,perform,performance,7355,"object and returns its address as; an integer value.; Takes an optional ``byref`` parameter and if set to true, returns a pointer; to the address instead. * **ll.as_capsule**: Takes a cppyy bound C++ object and returns its address as; a PyCapsule object.; Takes an optional ``byref`` parameter and if set to true, returns a pointer; to the address instead. * **ll.as_cobject**: Takes a cppyy bound C++ object and returns its address as; a PyCObject object for Python2 and a PyCapsule object for Python3.; Takes an optional ``byref`` parameter and if set to true, returns a pointer; to the address instead. * **ll.as_ctypes**: Takes a cppyy bound C++ object and returns its address as; a ``ctypes.c_void_p`` object.; Takes an optional ``byref`` parameter and if set to true, returns a pointer; to the address instead. `ctypes`; --------. The `ctypes module`_ has been part of Python since version 2.5 and provides a; Python-side foreign function interface.; It is clunky to use and has very bad performance, but it is guaranteed to be; available.; It does not have a public C interface, only the Python one, but its internals; have been stable since its introduction, making it safe to use for tight and; efficient integration at the C level (with a few Python helpers to assure; lazy lookup). Objects from ``ctypes`` can be passed through arguments of functions that; take a pointer to a single C++ builtin, and ``ctypes`` pointers can be passed ; when a pointer-to-pointer is expected, e.g. for array out-parameters.; This leads to the following set of possible mappings:. ======================================== ========================================; C++ ctypes; ======================================== ========================================; by value (ex.: ``int``) ``.value`` (ex.: ``c_int(0).value``); by const reference (ex.: ``const int&``) ``.value`` (ex.: ``c_int(0).value``); by reference (ex.: ``int&``) direct (ex.: ``c_int(0)``); by pointer (ex.: ``int*``) direct (ex.: ``c_int(0)",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst:1323,Safety,avoid,avoid,1323,"fficient to determine the full purpose.; For example, an ``int*`` type may refer to the address of a single ``int``; (an out-parameter, say) or it may refer to an array of ``int``, the ownership; of which is not clear either.; cppyy provides a few low-level helpers and integration with the Python; `ctypes module`_ to cover these cases. Use of these low-level helpers will obviously lead to very ""C-like"" code and; it is recommended to :doc:`pythonize <pythonizations>` the code, perhaps; using the Cling JIT and embedded C++. Note: the low-level module is not loaded by default (since its use is, or; should be, uncommon).; It needs to be imported explicitly:. .. code-block:: python. >>> import cppyy.ll; >>>. `LowLevelView`; --------------. Python has an elaborate array interface (buffer) specification, but no; standard library array type that completely implements it; instead, the; canonical Python array type is the NumPy one.; cppyy introduces the basic ``LowLevelView`` array class to avoid having a; direct dependency on NumPy and to guarantee zero copy.; The ``LowLevelView`` type gives access to array details such as the size,; type, etc. and allows reading/writing of array elements, both for interactive; use and through the buffer interface to allow NumPy to interface with them.; For more complex operations, it's recommended to copy from the; ``LowLevelView`` inta a NumPy array, or to create a NumPy view (see below,; under :ref:`NumPy Casts <npcasts>`). `C/C++ casts`; -------------. C++ instances are auto-casted to the most derived available type, so do not; require explicit casts even when a function returns a pointer to a base; class or interface.; However, when given only a ``void*`` or ``intptr_t`` type on return, a cast; is required to turn it into something usable. * **bind_object**: This is the preferred method to proxy a C++ address,; and lives in ``cppyy``, not ``cppyy.ll``, as it is not a low-level C++; cast, but a ``cppyy`` API that is also used internally.;",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst:7538,Safety,safe,safe,7538,"sule**: Takes a cppyy bound C++ object and returns its address as; a PyCapsule object.; Takes an optional ``byref`` parameter and if set to true, returns a pointer; to the address instead. * **ll.as_cobject**: Takes a cppyy bound C++ object and returns its address as; a PyCObject object for Python2 and a PyCapsule object for Python3.; Takes an optional ``byref`` parameter and if set to true, returns a pointer; to the address instead. * **ll.as_ctypes**: Takes a cppyy bound C++ object and returns its address as; a ``ctypes.c_void_p`` object.; Takes an optional ``byref`` parameter and if set to true, returns a pointer; to the address instead. `ctypes`; --------. The `ctypes module`_ has been part of Python since version 2.5 and provides a; Python-side foreign function interface.; It is clunky to use and has very bad performance, but it is guaranteed to be; available.; It does not have a public C interface, only the Python one, but its internals; have been stable since its introduction, making it safe to use for tight and; efficient integration at the C level (with a few Python helpers to assure; lazy lookup). Objects from ``ctypes`` can be passed through arguments of functions that; take a pointer to a single C++ builtin, and ``ctypes`` pointers can be passed ; when a pointer-to-pointer is expected, e.g. for array out-parameters.; This leads to the following set of possible mappings:. ======================================== ========================================; C++ ctypes; ======================================== ========================================; by value (ex.: ``int``) ``.value`` (ex.: ``c_int(0).value``); by const reference (ex.: ``const int&``) ``.value`` (ex.: ``c_int(0).value``); by reference (ex.: ``int&``) direct (ex.: ``c_int(0)``); by pointer (ex.: ``int*``) direct (ex.: ``c_int(0)``); by ptr-ref (ex.: ``int*&``) ``pointer`` (ex.: ``pointer(c_int(0))``); by ptr-ptr **in** (ex.: ``int**``) ``pointer`` (ex.: ``pointer(c_int(0))``); by ptr-ptr **out*",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst:9395,Safety,avoid,avoided,9395,"er(c_int(0))``); by ptr-ptr **in** (ex.: ``int**``) ``pointer`` (ex.: ``pointer(c_int(0))``); by ptr-ptr **out** (ex.: ``int**``) ``POINTER`` (ex.: ``POINTER(c_int)()``); ======================================== ========================================. The ``ctypes`` pointer objects (from ``POINTER``, ``pointer``, or ``byref``); can also be used for pass by reference or pointer, instead of the direct; object, and ``ctypes.c_void_p`` can pass through all pointer types.; The addresses will be adjusted internally by cppyy. Note that ``ctypes.c_char_p`` is expected to be a NULL-terminated C string,; not a character array (see the `ctypes module`_ documentation), and that; ``ctypes.c_bool`` is a C ``_Bool`` type, not C++ ``bool``. `Memory`; --------. C++ has three ways of allocating heap memory (``malloc``, ``new``, and; ``new[]``) and three corresponding ways of deallocation (``free``,; ``delete``, and ``delete[]``).; Direct use of ``malloc`` and ``new`` should be avoided for C++ classes, as; these may override ``operator new`` to control their own allocation.; However these low-level allocators can be necessary for builtin types on; occasion if the C++ side takes ownership (otherwise, prefer either; ``array`` from the builtin module ``array`` or ``ndarray`` from Numpy). The low-level module adds the following functions:. * **ll.malloc**: an interface on top of C's malloc.; Use it as a template with the number of elements (not the number types) to; be allocated.; The result is a ``cppyy.LowLevelView`` with the proper type and size:. .. code-block:: python. >>> arr = cppyy.ll.malloc[int](4) # allocates memory for 4 C ints; >>> print(len(arr)); 4; >>> print(type(arr[0])); <type 'int'>; >>>. The actual C malloc can also be used directly, through ``cppyy.gbl.malloc``,; taking the number of *bytes* to be allocated and returning a ``void*``. * **ll.free**: an interface to C's free, to deallocate memory allocated by; C's malloc.; To continue to example above:. .. code-block::",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst:1427,Security,access,access,1427,"`int``; (an out-parameter, say) or it may refer to an array of ``int``, the ownership; of which is not clear either.; cppyy provides a few low-level helpers and integration with the Python; `ctypes module`_ to cover these cases. Use of these low-level helpers will obviously lead to very ""C-like"" code and; it is recommended to :doc:`pythonize <pythonizations>` the code, perhaps; using the Cling JIT and embedded C++. Note: the low-level module is not loaded by default (since its use is, or; should be, uncommon).; It needs to be imported explicitly:. .. code-block:: python. >>> import cppyy.ll; >>>. `LowLevelView`; --------------. Python has an elaborate array interface (buffer) specification, but no; standard library array type that completely implements it; instead, the; canonical Python array type is the NumPy one.; cppyy introduces the basic ``LowLevelView`` array class to avoid having a; direct dependency on NumPy and to guarantee zero copy.; The ``LowLevelView`` type gives access to array details such as the size,; type, etc. and allows reading/writing of array elements, both for interactive; use and through the buffer interface to allow NumPy to interface with them.; For more complex operations, it's recommended to copy from the; ``LowLevelView`` inta a NumPy array, or to create a NumPy view (see below,; under :ref:`NumPy Casts <npcasts>`). `C/C++ casts`; -------------. C++ instances are auto-casted to the most derived available type, so do not; require explicit casts even when a function returns a pointer to a base; class or interface.; However, when given only a ``void*`` or ``intptr_t`` type on return, a cast; is required to turn it into something usable. * **bind_object**: This is the preferred method to proxy a C++ address,; and lives in ``cppyy``, not ``cppyy.ll``, as it is not a low-level C++; cast, but a ``cppyy`` API that is also used internally.; It thus plays well with object identity, references, etc.; Example:. .. code-block:: python. >>> cppyy.cppde",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst:539,Usability,clear,clear,539,"Low-level code; ==============. .. toctree::; :hidden:. C code and older C++ code sometimes makes use of low-level features such as; pointers to builtin types, some of which do not have any Python equivalent; (e.g. ``unsigned short*``).; Furthermore, such codes tend to be ambiguous: the information from header; file is not sufficient to determine the full purpose.; For example, an ``int*`` type may refer to the address of a single ``int``; (an out-parameter, say) or it may refer to an array of ``int``, the ownership; of which is not clear either.; cppyy provides a few low-level helpers and integration with the Python; `ctypes module`_ to cover these cases. Use of these low-level helpers will obviously lead to very ""C-like"" code and; it is recommended to :doc:`pythonize <pythonizations>` the code, perhaps; using the Cling JIT and embedded C++. Note: the low-level module is not loaded by default (since its use is, or; should be, uncommon).; It needs to be imported explicitly:. .. code-block:: python. >>> import cppyy.ll; >>>. `LowLevelView`; --------------. Python has an elaborate array interface (buffer) specification, but no; standard library array type that completely implements it; instead, the; canonical Python array type is the NumPy one.; cppyy introduces the basic ``LowLevelView`` array class to avoid having a; direct dependency on NumPy and to guarantee zero copy.; The ``LowLevelView`` type gives access to array details such as the size,; type, etc. and allows reading/writing of array elements, both for interactive; use and through the buffer interface to allow NumPy to interface with them.; For more complex operations, it's recommended to copy from the; ``LowLevelView`` inta a NumPy array, or to create a NumPy view (see below,; under :ref:`NumPy Casts <npcasts>`). `C/C++ casts`; -------------. C++ instances are auto-casted to the most derived available type, so do not; require explicit casts even when a function returns a pointer to a base; class or interface",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst:2119,Usability,usab,usable,2119,"------. Python has an elaborate array interface (buffer) specification, but no; standard library array type that completely implements it; instead, the; canonical Python array type is the NumPy one.; cppyy introduces the basic ``LowLevelView`` array class to avoid having a; direct dependency on NumPy and to guarantee zero copy.; The ``LowLevelView`` type gives access to array details such as the size,; type, etc. and allows reading/writing of array elements, both for interactive; use and through the buffer interface to allow NumPy to interface with them.; For more complex operations, it's recommended to copy from the; ``LowLevelView`` inta a NumPy array, or to create a NumPy view (see below,; under :ref:`NumPy Casts <npcasts>`). `C/C++ casts`; -------------. C++ instances are auto-casted to the most derived available type, so do not; require explicit casts even when a function returns a pointer to a base; class or interface.; However, when given only a ``void*`` or ``intptr_t`` type on return, a cast; is required to turn it into something usable. * **bind_object**: This is the preferred method to proxy a C++ address,; and lives in ``cppyy``, not ``cppyy.ll``, as it is not a low-level C++; cast, but a ``cppyy`` API that is also used internally.; It thus plays well with object identity, references, etc.; Example:. .. code-block:: python. >>> cppyy.cppdef(""""""; ... struct MyStruct { int fInt; };; ... void* create_mystruct() { return new MyStruct{42}; }; ... """"""); ... ; >>> s = cppyy.gbl.create_mystruct(); >>> print(s); <cppyy.LowLevelView object at 0x10559d430>; >>> sobj = cppyy.bind_object(s, 'MyStruct'); >>> print(sobj); <cppyy.gbl.MyStruct object at 0x7ff25e28eb20>; >>> print(sobj.fInt); 42; >>>. Instead of the type name as a string, ``bind_object`` can also take the; actual class (here: ``cppyy.gbl.MyStruct``). * **Typed nullptr**: A Python side proxy can pass through a pointer to; pointer function argument, but if the C++ side allocates memory and; stores it in the",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst:3660,Usability,simpl,simplest,3660,"cppyy.bind_object(s, 'MyStruct'); >>> print(sobj); <cppyy.gbl.MyStruct object at 0x7ff25e28eb20>; >>> print(sobj.fInt); 42; >>>. Instead of the type name as a string, ``bind_object`` can also take the; actual class (here: ``cppyy.gbl.MyStruct``). * **Typed nullptr**: A Python side proxy can pass through a pointer to; pointer function argument, but if the C++ side allocates memory and; stores it in the pointer, the result is a memory leak.; In that case, use ``bind_object`` to bind ``cppyy.nullptr`` instead, to; get a typed nullptr to pass to the function.; Example (continuing from the example above):. .. code-block:: python. >>> cppyy.cppdef(""""""; ... void create_mystruct(MyStruct** ptr) { *ptr = new MyStruct{42}; }; ... """"""); ...; >>> s = cppyy.bind_object(cppyy.nullptr, 'MyStruct'); >>> print(s); <cppyy.gbl.MyStruct object at 0x0>; >>> cppyy.gbl.create_mystruct(s); >>> print(s); <cppyy.gbl.MyStruct object at 0x7fc7d85b91c0>; >>> print(s.fInt); 42; >>>. * **C-style cast**: This is the simplest option for builtin types.; The syntax is ""template-style"", example:. .. code-block:: python. >>> cppyy.cppdef(""""""; ... void* get_data(int sz) {; ... int* iptr = (int*)malloc(sizeof(int)*sz);; ... for (int i=0; i<sz; ++i) iptr[i] = i;; ... return iptr;; ... }""""""); ...; >>> NDATA = 4; >>> d = cppyy.gbl.get_data(NDATA); >>> print(d); <cppyy.LowLevelView object at 0x1068cba30>; >>> d = cppyy.ll.cast['int*'](d); >>> d.reshape((NDATA,)); >>> print(list(d)); [0, 1, 2, 3]; >>>. * **C++-style casts**: Similar to the C-style cast, there are; ``ll.static_cast`` and ``ll.reinterpret_cast``.; There should never be a reason for a ``dynamic_cast``, since that only; applies to objects, for which auto-casting will work.; The syntax is ""template-style"", just like for the C-style cast above. .. _npcasts:. `NumPy casts`; -------------. The ``cppyy.LowLevelView`` type returned for pointers to basic types,; including for ``void*``, is a simple and light-weight view on memory, given a; pointer, type,",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst:4598,Usability,simpl,simple,4598,"s.fInt); 42; >>>. * **C-style cast**: This is the simplest option for builtin types.; The syntax is ""template-style"", example:. .. code-block:: python. >>> cppyy.cppdef(""""""; ... void* get_data(int sz) {; ... int* iptr = (int*)malloc(sizeof(int)*sz);; ... for (int i=0; i<sz; ++i) iptr[i] = i;; ... return iptr;; ... }""""""); ...; >>> NDATA = 4; >>> d = cppyy.gbl.get_data(NDATA); >>> print(d); <cppyy.LowLevelView object at 0x1068cba30>; >>> d = cppyy.ll.cast['int*'](d); >>> d.reshape((NDATA,)); >>> print(list(d)); [0, 1, 2, 3]; >>>. * **C++-style casts**: Similar to the C-style cast, there are; ``ll.static_cast`` and ``ll.reinterpret_cast``.; There should never be a reason for a ``dynamic_cast``, since that only; applies to objects, for which auto-casting will work.; The syntax is ""template-style"", just like for the C-style cast above. .. _npcasts:. `NumPy casts`; -------------. The ``cppyy.LowLevelView`` type returned for pointers to basic types,; including for ``void*``, is a simple and light-weight view on memory, given a; pointer, type, and number of elements (or unchecked, if unknown).; It only supports basic operations such as indexing and iterations, but also; the buffer protocol for integration with full-fledged functional arrays such; as NumPy`s ``ndarray``. In addition, specifically when dealing with ``void*`` returns, you can use; NumPy's low-level ``frombuffer`` interface to perform the cast.; Example:. .. code-block:: python. >>> cppyy.cppdef(""""""; ... void* create_float_array(int sz) {; ... float* pf = (float*)malloc(sizeof(float)*sz);; ... for (int i = 0; i < sz; ++i) pf[i] = 2*i;; ... return pf;; ... }""""""); ...; >>> import numpy as np; >>> NDATA = 8; >>> arr = cppyy.gbl.create_float_array(NDATA); >>> print(arr); <cppyy.LowLevelView object at 0x109f15230>; >>> arr.reshape((NDATA,)) # adjust the llv's size; >>> v = np.frombuffer(arr, dtype=np.float32, count=NDATA) # cast to float; >>> print(len(v)); 8; >>> print(v); array([ 0., 2., 4., 6., 8., 10., 12., 14.],",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/lowlevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/misc.rst:5392,Availability,avail,available,5392," can be defined dynamically after that statement and then; they would be missed by the import.; In scripts, it is easy enough to rebind names to achieve a good amount of; reduction in typing (and a modest performance improvement to boot, because of; fewer dictionary lookups), e.g.:. .. code-block:: python. import cppyy; std = cppyy.gbl.std; v = std.vector[int](range(10)). But even such rebinding becomes annoying for (brief) interactive sessions. For CPython only (and not with tools such as IPython or in IDEs that replace; the interactive prompt), there is a fix, using; ``from cppyy.interactive import *``.; This makes lookups in the global dictionary of the current frame also; consider everything under ``cppyy.gbl``.; This feature comes with a performance `penalty` and is not meant for; production code.; Example usage:. .. code-block:: python. >>> from cppyy.interactive import *; >>> v = std.vector[int](range(10)); >>> print(list(v)); [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]; >>>; >>> cppdef(""struct SomeStruct {};""); True; >>> s = SomeStruct() # <- dynamically made available; >>> s; <cppyy.gbl.SomeStruct object at 0x7fa9b8624320>; >>>. For PyPy, IPython, etc. ``cppyy.gbl`` is simply rebound as ``g`` and; ``cppyy.gbl.std`` is made available as ``std``.; Not as convenient as full lookup, and missing any other namespaces that may be; available, but still saves some typing in may cases. `Odds and ends`; ---------------. * **namespaces**: Are represented as python classes.; Namespaces are more open-ended than classes, so sometimes initial access may; result in updates as data and functions are looked up and constructed; lazily.; Thus the result of ``dir()`` on a namespace shows the classes and functions; available for binding, even if these may not have been created yet.; Once created, namespaces are registered as modules, to allow importing from; them.; The global namespace is ``cppyy.gbl``. * **NULL**: Is represented as ``cppyy.nullptr``.; Starting C++11, the keyword ``nullptr`` ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/misc.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/misc.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/misc.rst:5560,Availability,avail,available,5560,"use of; fewer dictionary lookups), e.g.:. .. code-block:: python. import cppyy; std = cppyy.gbl.std; v = std.vector[int](range(10)). But even such rebinding becomes annoying for (brief) interactive sessions. For CPython only (and not with tools such as IPython or in IDEs that replace; the interactive prompt), there is a fix, using; ``from cppyy.interactive import *``.; This makes lookups in the global dictionary of the current frame also; consider everything under ``cppyy.gbl``.; This feature comes with a performance `penalty` and is not meant for; production code.; Example usage:. .. code-block:: python. >>> from cppyy.interactive import *; >>> v = std.vector[int](range(10)); >>> print(list(v)); [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]; >>>; >>> cppdef(""struct SomeStruct {};""); True; >>> s = SomeStruct() # <- dynamically made available; >>> s; <cppyy.gbl.SomeStruct object at 0x7fa9b8624320>; >>>. For PyPy, IPython, etc. ``cppyy.gbl`` is simply rebound as ``g`` and; ``cppyy.gbl.std`` is made available as ``std``.; Not as convenient as full lookup, and missing any other namespaces that may be; available, but still saves some typing in may cases. `Odds and ends`; ---------------. * **namespaces**: Are represented as python classes.; Namespaces are more open-ended than classes, so sometimes initial access may; result in updates as data and functions are looked up and constructed; lazily.; Thus the result of ``dir()`` on a namespace shows the classes and functions; available for binding, even if these may not have been created yet.; Once created, namespaces are registered as modules, to allow importing from; them.; The global namespace is ``cppyy.gbl``. * **NULL**: Is represented as ``cppyy.nullptr``.; Starting C++11, the keyword ``nullptr`` is used to represent ``NULL``.; For clarity of intent, it is recommended to use this instead of ``None``; (or the integer ``0``, which can serve in some cases), as ``None`` is better; understood as ``void`` in C++. * **default value**: Represe",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/misc.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/misc.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/misc.rst:5663,Availability,avail,available,5663," cppyy.gbl.std; v = std.vector[int](range(10)). But even such rebinding becomes annoying for (brief) interactive sessions. For CPython only (and not with tools such as IPython or in IDEs that replace; the interactive prompt), there is a fix, using; ``from cppyy.interactive import *``.; This makes lookups in the global dictionary of the current frame also; consider everything under ``cppyy.gbl``.; This feature comes with a performance `penalty` and is not meant for; production code.; Example usage:. .. code-block:: python. >>> from cppyy.interactive import *; >>> v = std.vector[int](range(10)); >>> print(list(v)); [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]; >>>; >>> cppdef(""struct SomeStruct {};""); True; >>> s = SomeStruct() # <- dynamically made available; >>> s; <cppyy.gbl.SomeStruct object at 0x7fa9b8624320>; >>>. For PyPy, IPython, etc. ``cppyy.gbl`` is simply rebound as ``g`` and; ``cppyy.gbl.std`` is made available as ``std``.; Not as convenient as full lookup, and missing any other namespaces that may be; available, but still saves some typing in may cases. `Odds and ends`; ---------------. * **namespaces**: Are represented as python classes.; Namespaces are more open-ended than classes, so sometimes initial access may; result in updates as data and functions are looked up and constructed; lazily.; Thus the result of ``dir()`` on a namespace shows the classes and functions; available for binding, even if these may not have been created yet.; Once created, namespaces are registered as modules, to allow importing from; them.; The global namespace is ``cppyy.gbl``. * **NULL**: Is represented as ``cppyy.nullptr``.; Starting C++11, the keyword ``nullptr`` is used to represent ``NULL``.; For clarity of intent, it is recommended to use this instead of ``None``; (or the integer ``0``, which can serve in some cases), as ``None`` is better; understood as ``void`` in C++. * **default value**: Represented with The untyped ``cppyy.default``.; The generic value ``cppyy.default`` will c",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/misc.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/misc.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/misc.rst:6039,Availability,avail,available,6039,"e sessions. For CPython only (and not with tools such as IPython or in IDEs that replace; the interactive prompt), there is a fix, using; ``from cppyy.interactive import *``.; This makes lookups in the global dictionary of the current frame also; consider everything under ``cppyy.gbl``.; This feature comes with a performance `penalty` and is not meant for; production code.; Example usage:. .. code-block:: python. >>> from cppyy.interactive import *; >>> v = std.vector[int](range(10)); >>> print(list(v)); [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]; >>>; >>> cppdef(""struct SomeStruct {};""); True; >>> s = SomeStruct() # <- dynamically made available; >>> s; <cppyy.gbl.SomeStruct object at 0x7fa9b8624320>; >>>. For PyPy, IPython, etc. ``cppyy.gbl`` is simply rebound as ``g`` and; ``cppyy.gbl.std`` is made available as ``std``.; Not as convenient as full lookup, and missing any other namespaces that may be; available, but still saves some typing in may cases. `Odds and ends`; ---------------. * **namespaces**: Are represented as python classes.; Namespaces are more open-ended than classes, so sometimes initial access may; result in updates as data and functions are looked up and constructed; lazily.; Thus the result of ``dir()`` on a namespace shows the classes and functions; available for binding, even if these may not have been created yet.; Once created, namespaces are registered as modules, to allow importing from; them.; The global namespace is ``cppyy.gbl``. * **NULL**: Is represented as ``cppyy.nullptr``.; Starting C++11, the keyword ``nullptr`` is used to represent ``NULL``.; For clarity of intent, it is recommended to use this instead of ``None``; (or the integer ``0``, which can serve in some cases), as ``None`` is better; understood as ``void`` in C++. * **default value**: Represented with The untyped ``cppyy.default``.; The generic value ``cppyy.default`` will convert to the type specific default; value (per C++ rules) when used as a function argument or in assignment.; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/misc.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/misc.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/misc.rst:800,Deployability,release,release,800,".. _features:. Miscellaneous; =============. .. toctree::; :hidden:. cppyy_features_header. This is a collection of a few more features listed that do not have a proper; place yet in the rest of the documentation. The C++ code used for the examples below can be found; :doc:`here <cppyy_features_header>`, and it is assumed that that code is; loaded at the start of any session.; Download it, save it under the name ``features.h``, and load it:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('features.h'); >>>. `Special variables`; -------------------. There are several conventional ""special variables"" that control behavior of; functions or provide (internal) information.; Often, these can be set/used in pythonizations to handle memory management or; Global Interpreter Lock (GIL) release. * ``__python_owns__``: a flag that every bound instance carries and determines; whether Python or C++ owns the C++ instance (and associated memory).; If Python owns the instance, it will be destructed when the last Python; reference to the proxy disappears.; You can check/change the ownership with the __python_owns__ flag that every; bound instance carries.; Example:. .. code-block:: python. >>> from cppyy.gbl import Concrete; >>> c = Concrete(); >>> c.__python_owns__ # True: object created in Python; True; >>>. * ``__creates__``: a flag that every C++ overload carries and determines; whether the return value is owned by C++ or Python: if ``True``, Python owns; the return value, otherwise C++. * ``__set_lifeline__``: a flag that every C++ overload carries and determines; whether the return value should place a back-reference on ``self``, to; prevent the latter from going out of scope before the return value does.; The default is ``False``, but will be automatically set at run-time if a; return value's address is a C++ object pointing into the memory of ``this``,; or if ``self`` is a by-value return. * ``__release_gil__``: a flag that every C++ overload carries and determine",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/misc.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/misc.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/misc.rst:2056,Deployability,release,released,2056," last Python; reference to the proxy disappears.; You can check/change the ownership with the __python_owns__ flag that every; bound instance carries.; Example:. .. code-block:: python. >>> from cppyy.gbl import Concrete; >>> c = Concrete(); >>> c.__python_owns__ # True: object created in Python; True; >>>. * ``__creates__``: a flag that every C++ overload carries and determines; whether the return value is owned by C++ or Python: if ``True``, Python owns; the return value, otherwise C++. * ``__set_lifeline__``: a flag that every C++ overload carries and determines; whether the return value should place a back-reference on ``self``, to; prevent the latter from going out of scope before the return value does.; The default is ``False``, but will be automatically set at run-time if a; return value's address is a C++ object pointing into the memory of ``this``,; or if ``self`` is a by-value return. * ``__release_gil__``: a flag that every C++ overload carries and determines; whether the Global Interpreter Lock (GIL) should be released during the C++; call to allow multi-threading.; The default is ``False``. * ``__useffi__``: a flag that every C++ overload carries and determines; whether generated wrappers or direct foreign functions should be used.; This is for PyPy only; the flag has no effect on CPython. * ``__sig2exc__``: a flag that every C++ overload carries and determines; whether C++ signals (such as SIGABRT) should be converted into Python; exceptions. * ``__cpp_name__``: a string that every C++ bound class carries and contains; the actual C++ name (as opposed to ``__name__`` which has the Python name).; This can be useful for template instantiations, documentation, etc. * ``__cpp_template__``: a back-reference to the template used to instantiate; a templated class.; This variable only exists if the class was dynamically instantiated from; Python at least once. `STL algorithms`; ----------------. It is usually easier to use a Python equivalent or code up the eff",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/misc.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/misc.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/misc.rst:5892,Deployability,update,updates,5892,"e sessions. For CPython only (and not with tools such as IPython or in IDEs that replace; the interactive prompt), there is a fix, using; ``from cppyy.interactive import *``.; This makes lookups in the global dictionary of the current frame also; consider everything under ``cppyy.gbl``.; This feature comes with a performance `penalty` and is not meant for; production code.; Example usage:. .. code-block:: python. >>> from cppyy.interactive import *; >>> v = std.vector[int](range(10)); >>> print(list(v)); [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]; >>>; >>> cppdef(""struct SomeStruct {};""); True; >>> s = SomeStruct() # <- dynamically made available; >>> s; <cppyy.gbl.SomeStruct object at 0x7fa9b8624320>; >>>. For PyPy, IPython, etc. ``cppyy.gbl`` is simply rebound as ``g`` and; ``cppyy.gbl.std`` is made available as ``std``.; Not as convenient as full lookup, and missing any other namespaces that may be; available, but still saves some typing in may cases. `Odds and ends`; ---------------. * **namespaces**: Are represented as python classes.; Namespaces are more open-ended than classes, so sometimes initial access may; result in updates as data and functions are looked up and constructed; lazily.; Thus the result of ``dir()`` on a namespace shows the classes and functions; available for binding, even if these may not have been created yet.; Once created, namespaces are registered as modules, to allow importing from; them.; The global namespace is ``cppyy.gbl``. * **NULL**: Is represented as ``cppyy.nullptr``.; Starting C++11, the keyword ``nullptr`` is used to represent ``NULL``.; For clarity of intent, it is recommended to use this instead of ``None``; (or the integer ``0``, which can serve in some cases), as ``None`` is better; understood as ``void`` in C++. * **default value**: Represented with The untyped ``cppyy.default``.; The generic value ``cppyy.default`` will convert to the type specific default; value (per C++ rules) when used as a function argument or in assignment.; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/misc.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/misc.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/misc.rst:2230,Integrability,wrap,wrappers,2230,"om cppyy.gbl import Concrete; >>> c = Concrete(); >>> c.__python_owns__ # True: object created in Python; True; >>>. * ``__creates__``: a flag that every C++ overload carries and determines; whether the return value is owned by C++ or Python: if ``True``, Python owns; the return value, otherwise C++. * ``__set_lifeline__``: a flag that every C++ overload carries and determines; whether the return value should place a back-reference on ``self``, to; prevent the latter from going out of scope before the return value does.; The default is ``False``, but will be automatically set at run-time if a; return value's address is a C++ object pointing into the memory of ``this``,; or if ``self`` is a by-value return. * ``__release_gil__``: a flag that every C++ overload carries and determines; whether the Global Interpreter Lock (GIL) should be released during the C++; call to allow multi-threading.; The default is ``False``. * ``__useffi__``: a flag that every C++ overload carries and determines; whether generated wrappers or direct foreign functions should be used.; This is for PyPy only; the flag has no effect on CPython. * ``__sig2exc__``: a flag that every C++ overload carries and determines; whether C++ signals (such as SIGABRT) should be converted into Python; exceptions. * ``__cpp_name__``: a string that every C++ bound class carries and contains; the actual C++ name (as opposed to ``__name__`` which has the Python name).; This can be useful for template instantiations, documentation, etc. * ``__cpp_template__``: a back-reference to the template used to instantiate; a templated class.; This variable only exists if the class was dynamically instantiated from; Python at least once. `STL algorithms`; ----------------. It is usually easier to use a Python equivalent or code up the effect of an; STL algorithm directly, but when operating on a large container, calling an; STL algorithm may offer better performance.; It is important to note that all STL algorithms are templat",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/misc.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/misc.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/misc.rst:535,Modifiability,variab,variables,535,".. _features:. Miscellaneous; =============. .. toctree::; :hidden:. cppyy_features_header. This is a collection of a few more features listed that do not have a proper; place yet in the rest of the documentation. The C++ code used for the examples below can be found; :doc:`here <cppyy_features_header>`, and it is assumed that that code is; loaded at the start of any session.; Download it, save it under the name ``features.h``, and load it:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('features.h'); >>>. `Special variables`; -------------------. There are several conventional ""special variables"" that control behavior of; functions or provide (internal) information.; Often, these can be set/used in pythonizations to handle memory management or; Global Interpreter Lock (GIL) release. * ``__python_owns__``: a flag that every bound instance carries and determines; whether Python or C++ owns the C++ instance (and associated memory).; If Python owns the instance, it will be destructed when the last Python; reference to the proxy disappears.; You can check/change the ownership with the __python_owns__ flag that every; bound instance carries.; Example:. .. code-block:: python. >>> from cppyy.gbl import Concrete; >>> c = Concrete(); >>> c.__python_owns__ # True: object created in Python; True; >>>. * ``__creates__``: a flag that every C++ overload carries and determines; whether the return value is owned by C++ or Python: if ``True``, Python owns; the return value, otherwise C++. * ``__set_lifeline__``: a flag that every C++ overload carries and determines; whether the return value should place a back-reference on ``self``, to; prevent the latter from going out of scope before the return value does.; The default is ``False``, but will be automatically set at run-time if a; return value's address is a C++ object pointing into the memory of ``this``,; or if ``self`` is a by-value return. * ``__release_gil__``: a flag that every C++ overload carries and determine",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/misc.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/misc.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/misc.rst:608,Modifiability,variab,variables,608,".. _features:. Miscellaneous; =============. .. toctree::; :hidden:. cppyy_features_header. This is a collection of a few more features listed that do not have a proper; place yet in the rest of the documentation. The C++ code used for the examples below can be found; :doc:`here <cppyy_features_header>`, and it is assumed that that code is; loaded at the start of any session.; Download it, save it under the name ``features.h``, and load it:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('features.h'); >>>. `Special variables`; -------------------. There are several conventional ""special variables"" that control behavior of; functions or provide (internal) information.; Often, these can be set/used in pythonizations to handle memory management or; Global Interpreter Lock (GIL) release. * ``__python_owns__``: a flag that every bound instance carries and determines; whether Python or C++ owns the C++ instance (and associated memory).; If Python owns the instance, it will be destructed when the last Python; reference to the proxy disappears.; You can check/change the ownership with the __python_owns__ flag that every; bound instance carries.; Example:. .. code-block:: python. >>> from cppyy.gbl import Concrete; >>> c = Concrete(); >>> c.__python_owns__ # True: object created in Python; True; >>>. * ``__creates__``: a flag that every C++ overload carries and determines; whether the return value is owned by C++ or Python: if ``True``, Python owns; the return value, otherwise C++. * ``__set_lifeline__``: a flag that every C++ overload carries and determines; whether the return value should place a back-reference on ``self``, to; prevent the latter from going out of scope before the return value does.; The default is ``False``, but will be automatically set at run-time if a; return value's address is a C++ object pointing into the memory of ``this``,; or if ``self`` is a by-value return. * ``__release_gil__``: a flag that every C++ overload carries and determine",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/misc.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/misc.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/misc.rst:2825,Modifiability,variab,variable,2825,"e memory of ``this``,; or if ``self`` is a by-value return. * ``__release_gil__``: a flag that every C++ overload carries and determines; whether the Global Interpreter Lock (GIL) should be released during the C++; call to allow multi-threading.; The default is ``False``. * ``__useffi__``: a flag that every C++ overload carries and determines; whether generated wrappers or direct foreign functions should be used.; This is for PyPy only; the flag has no effect on CPython. * ``__sig2exc__``: a flag that every C++ overload carries and determines; whether C++ signals (such as SIGABRT) should be converted into Python; exceptions. * ``__cpp_name__``: a string that every C++ bound class carries and contains; the actual C++ name (as opposed to ``__name__`` which has the Python name).; This can be useful for template instantiations, documentation, etc. * ``__cpp_template__``: a back-reference to the template used to instantiate; a templated class.; This variable only exists if the class was dynamically instantiated from; Python at least once. `STL algorithms`; ----------------. It is usually easier to use a Python equivalent or code up the effect of an; STL algorithm directly, but when operating on a large container, calling an; STL algorithm may offer better performance.; It is important to note that all STL algorithms are templates and need the; correct types to be properly instantiated.; STL containers offer typedefs to obtain those exact types and these should; be used rather than relying on the usual implicit conversions of Python types; to C++ ones.; For example, as there is no ``char`` type in Python, the ``std::remove`` call; below can not be instantiated using a Python string, but the; ``std::string::value_type`` must be used instead:. .. code-block:: python. >>> cppstr = cppyy.gbl.std.string; >>> n = cppstr('this is a C++ string'); >>> print(n); this is a C++ string; >>> n.erase(cppyy.gbl.std.remove(n.begin(), n.end(), cppstr.value_type(' '))); <cppyy.gbl.__wrap_ite",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/misc.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/misc.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/misc.rst:343,Performance,load,loaded,343,".. _features:. Miscellaneous; =============. .. toctree::; :hidden:. cppyy_features_header. This is a collection of a few more features listed that do not have a proper; place yet in the rest of the documentation. The C++ code used for the examples below can be found; :doc:`here <cppyy_features_header>`, and it is assumed that that code is; loaded at the start of any session.; Download it, save it under the name ``features.h``, and load it:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('features.h'); >>>. `Special variables`; -------------------. There are several conventional ""special variables"" that control behavior of; functions or provide (internal) information.; Often, these can be set/used in pythonizations to handle memory management or; Global Interpreter Lock (GIL) release. * ``__python_owns__``: a flag that every bound instance carries and determines; whether Python or C++ owns the C++ instance (and associated memory).; If Python owns the instance, it will be destructed when the last Python; reference to the proxy disappears.; You can check/change the ownership with the __python_owns__ flag that every; bound instance carries.; Example:. .. code-block:: python. >>> from cppyy.gbl import Concrete; >>> c = Concrete(); >>> c.__python_owns__ # True: object created in Python; True; >>>. * ``__creates__``: a flag that every C++ overload carries and determines; whether the return value is owned by C++ or Python: if ``True``, Python owns; the return value, otherwise C++. * ``__set_lifeline__``: a flag that every C++ overload carries and determines; whether the return value should place a back-reference on ``self``, to; prevent the latter from going out of scope before the return value does.; The default is ``False``, but will be automatically set at run-time if a; return value's address is a C++ object pointing into the memory of ``this``,; or if ``self`` is a by-value return. * ``__release_gil__``: a flag that every C++ overload carries and determine",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/misc.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/misc.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/misc.rst:436,Performance,load,load,436,".. _features:. Miscellaneous; =============. .. toctree::; :hidden:. cppyy_features_header. This is a collection of a few more features listed that do not have a proper; place yet in the rest of the documentation. The C++ code used for the examples below can be found; :doc:`here <cppyy_features_header>`, and it is assumed that that code is; loaded at the start of any session.; Download it, save it under the name ``features.h``, and load it:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('features.h'); >>>. `Special variables`; -------------------. There are several conventional ""special variables"" that control behavior of; functions or provide (internal) information.; Often, these can be set/used in pythonizations to handle memory management or; Global Interpreter Lock (GIL) release. * ``__python_owns__``: a flag that every bound instance carries and determines; whether Python or C++ owns the C++ instance (and associated memory).; If Python owns the instance, it will be destructed when the last Python; reference to the proxy disappears.; You can check/change the ownership with the __python_owns__ flag that every; bound instance carries.; Example:. .. code-block:: python. >>> from cppyy.gbl import Concrete; >>> c = Concrete(); >>> c.__python_owns__ # True: object created in Python; True; >>>. * ``__creates__``: a flag that every C++ overload carries and determines; whether the return value is owned by C++ or Python: if ``True``, Python owns; the return value, otherwise C++. * ``__set_lifeline__``: a flag that every C++ overload carries and determines; whether the return value should place a back-reference on ``self``, to; prevent the latter from going out of scope before the return value does.; The default is ``False``, but will be automatically set at run-time if a; return value's address is a C++ object pointing into the memory of ``this``,; or if ``self`` is a by-value return. * ``__release_gil__``: a flag that every C++ overload carries and determine",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/misc.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/misc.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/misc.rst:2095,Performance,multi-thread,multi-threading,2095," last Python; reference to the proxy disappears.; You can check/change the ownership with the __python_owns__ flag that every; bound instance carries.; Example:. .. code-block:: python. >>> from cppyy.gbl import Concrete; >>> c = Concrete(); >>> c.__python_owns__ # True: object created in Python; True; >>>. * ``__creates__``: a flag that every C++ overload carries and determines; whether the return value is owned by C++ or Python: if ``True``, Python owns; the return value, otherwise C++. * ``__set_lifeline__``: a flag that every C++ overload carries and determines; whether the return value should place a back-reference on ``self``, to; prevent the latter from going out of scope before the return value does.; The default is ``False``, but will be automatically set at run-time if a; return value's address is a C++ object pointing into the memory of ``this``,; or if ``self`` is a by-value return. * ``__release_gil__``: a flag that every C++ overload carries and determines; whether the Global Interpreter Lock (GIL) should be released during the C++; call to allow multi-threading.; The default is ``False``. * ``__useffi__``: a flag that every C++ overload carries and determines; whether generated wrappers or direct foreign functions should be used.; This is for PyPy only; the flag has no effect on CPython. * ``__sig2exc__``: a flag that every C++ overload carries and determines; whether C++ signals (such as SIGABRT) should be converted into Python; exceptions. * ``__cpp_name__``: a string that every C++ bound class carries and contains; the actual C++ name (as opposed to ``__name__`` which has the Python name).; This can be useful for template instantiations, documentation, etc. * ``__cpp_template__``: a back-reference to the template used to instantiate; a templated class.; This variable only exists if the class was dynamically instantiated from; Python at least once. `STL algorithms`; ----------------. It is usually easier to use a Python equivalent or code up the eff",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/misc.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/misc.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/misc.rst:3137,Performance,perform,performance,3137,"ld be released during the C++; call to allow multi-threading.; The default is ``False``. * ``__useffi__``: a flag that every C++ overload carries and determines; whether generated wrappers or direct foreign functions should be used.; This is for PyPy only; the flag has no effect on CPython. * ``__sig2exc__``: a flag that every C++ overload carries and determines; whether C++ signals (such as SIGABRT) should be converted into Python; exceptions. * ``__cpp_name__``: a string that every C++ bound class carries and contains; the actual C++ name (as opposed to ``__name__`` which has the Python name).; This can be useful for template instantiations, documentation, etc. * ``__cpp_template__``: a back-reference to the template used to instantiate; a templated class.; This variable only exists if the class was dynamically instantiated from; Python at least once. `STL algorithms`; ----------------. It is usually easier to use a Python equivalent or code up the effect of an; STL algorithm directly, but when operating on a large container, calling an; STL algorithm may offer better performance.; It is important to note that all STL algorithms are templates and need the; correct types to be properly instantiated.; STL containers offer typedefs to obtain those exact types and these should; be used rather than relying on the usual implicit conversions of Python types; to C++ ones.; For example, as there is no ``char`` type in Python, the ``std::remove`` call; below can not be instantiated using a Python string, but the; ``std::string::value_type`` must be used instead:. .. code-block:: python. >>> cppstr = cppyy.gbl.std.string; >>> n = cppstr('this is a C++ string'); >>> print(n); this is a C++ string; >>> n.erase(cppyy.gbl.std.remove(n.begin(), n.end(), cppstr.value_type(' '))); <cppyy.gbl.__wrap_iter<char*> object at 0x7fba35d1af50>; >>> print(n); thisisaC++stringing; >>>. `Reduced typing`; ----------------. Note: ``from cppyy.interactive import *`` is no longer supported for CP",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/misc.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/misc.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/misc.rst:4526,Performance,perform,performance,4526,"ove`` call; below can not be instantiated using a Python string, but the; ``std::string::value_type`` must be used instead:. .. code-block:: python. >>> cppstr = cppyy.gbl.std.string; >>> n = cppstr('this is a C++ string'); >>> print(n); this is a C++ string; >>> n.erase(cppyy.gbl.std.remove(n.begin(), n.end(), cppstr.value_type(' '))); <cppyy.gbl.__wrap_iter<char*> object at 0x7fba35d1af50>; >>> print(n); thisisaC++stringing; >>>. `Reduced typing`; ----------------. Note: ``from cppyy.interactive import *`` is no longer supported for CPython; 3.11 and later because the ``dict`` object features it relies on have been; removed. Typing ``cppyy.gbl`` all the time gets old rather quickly, but the dynamic; nature of ``cppyy`` makes something like ``from cppyy.gbl import *``; impossible.; For example, classes can be defined dynamically after that statement and then; they would be missed by the import.; In scripts, it is easy enough to rebind names to achieve a good amount of; reduction in typing (and a modest performance improvement to boot, because of; fewer dictionary lookups), e.g.:. .. code-block:: python. import cppyy; std = cppyy.gbl.std; v = std.vector[int](range(10)). But even such rebinding becomes annoying for (brief) interactive sessions. For CPython only (and not with tools such as IPython or in IDEs that replace; the interactive prompt), there is a fix, using; ``from cppyy.interactive import *``.; This makes lookups in the global dictionary of the current frame also; consider everything under ``cppyy.gbl``.; This feature comes with a performance `penalty` and is not meant for; production code.; Example usage:. .. code-block:: python. >>> from cppyy.interactive import *; >>> v = std.vector[int](range(10)); >>> print(list(v)); [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]; >>>; >>> cppdef(""struct SomeStruct {};""); True; >>> s = SomeStruct() # <- dynamically made available; >>> s; <cppyy.gbl.SomeStruct object at 0x7fa9b8624320>; >>>. For PyPy, IPython, etc. ``cppyy.gbl`` is sim",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/misc.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/misc.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/misc.rst:5074,Performance,perform,performance,5074,"`` object features it relies on have been; removed. Typing ``cppyy.gbl`` all the time gets old rather quickly, but the dynamic; nature of ``cppyy`` makes something like ``from cppyy.gbl import *``; impossible.; For example, classes can be defined dynamically after that statement and then; they would be missed by the import.; In scripts, it is easy enough to rebind names to achieve a good amount of; reduction in typing (and a modest performance improvement to boot, because of; fewer dictionary lookups), e.g.:. .. code-block:: python. import cppyy; std = cppyy.gbl.std; v = std.vector[int](range(10)). But even such rebinding becomes annoying for (brief) interactive sessions. For CPython only (and not with tools such as IPython or in IDEs that replace; the interactive prompt), there is a fix, using; ``from cppyy.interactive import *``.; This makes lookups in the global dictionary of the current frame also; consider everything under ``cppyy.gbl``.; This feature comes with a performance `penalty` and is not meant for; production code.; Example usage:. .. code-block:: python. >>> from cppyy.interactive import *; >>> v = std.vector[int](range(10)); >>> print(list(v)); [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]; >>>; >>> cppdef(""struct SomeStruct {};""); True; >>> s = SomeStruct() # <- dynamically made available; >>> s; <cppyy.gbl.SomeStruct object at 0x7fa9b8624320>; >>>. For PyPy, IPython, etc. ``cppyy.gbl`` is simply rebound as ``g`` and; ``cppyy.gbl.std`` is made available as ``std``.; Not as convenient as full lookup, and missing any other namespaces that may be; available, but still saves some typing in may cases. `Odds and ends`; ---------------. * **namespaces**: Are represented as python classes.; Namespaces are more open-ended than classes, so sometimes initial access may; result in updates as data and functions are looked up and constructed; lazily.; Thus the result of ``dir()`` on a namespace shows the classes and functions; available for binding, even if these may not have b",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/misc.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/misc.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/misc.rst:5870,Security,access,access,5870,"e sessions. For CPython only (and not with tools such as IPython or in IDEs that replace; the interactive prompt), there is a fix, using; ``from cppyy.interactive import *``.; This makes lookups in the global dictionary of the current frame also; consider everything under ``cppyy.gbl``.; This feature comes with a performance `penalty` and is not meant for; production code.; Example usage:. .. code-block:: python. >>> from cppyy.interactive import *; >>> v = std.vector[int](range(10)); >>> print(list(v)); [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]; >>>; >>> cppdef(""struct SomeStruct {};""); True; >>> s = SomeStruct() # <- dynamically made available; >>> s; <cppyy.gbl.SomeStruct object at 0x7fa9b8624320>; >>>. For PyPy, IPython, etc. ``cppyy.gbl`` is simply rebound as ``g`` and; ``cppyy.gbl.std`` is made available as ``std``.; Not as convenient as full lookup, and missing any other namespaces that may be; available, but still saves some typing in may cases. `Odds and ends`; ---------------. * **namespaces**: Are represented as python classes.; Namespaces are more open-ended than classes, so sometimes initial access may; result in updates as data and functions are looked up and constructed; lazily.; Thus the result of ``dir()`` on a namespace shows the classes and functions; available for binding, even if these may not have been created yet.; Once created, namespaces are registered as modules, to allow importing from; them.; The global namespace is ``cppyy.gbl``. * **NULL**: Is represented as ``cppyy.nullptr``.; Starting C++11, the keyword ``nullptr`` is used to represent ``NULL``.; For clarity of intent, it is recommended to use this instead of ``None``; (or the integer ``0``, which can serve in some cases), as ``None`` is better; understood as ``void`` in C++. * **default value**: Represented with The untyped ``cppyy.default``.; The generic value ``cppyy.default`` will convert to the type specific default; value (per C++ rules) when used as a function argument or in assignment.; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/misc.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/misc.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/misc.rst:5505,Usability,simpl,simply,5505,"modest performance improvement to boot, because of; fewer dictionary lookups), e.g.:. .. code-block:: python. import cppyy; std = cppyy.gbl.std; v = std.vector[int](range(10)). But even such rebinding becomes annoying for (brief) interactive sessions. For CPython only (and not with tools such as IPython or in IDEs that replace; the interactive prompt), there is a fix, using; ``from cppyy.interactive import *``.; This makes lookups in the global dictionary of the current frame also; consider everything under ``cppyy.gbl``.; This feature comes with a performance `penalty` and is not meant for; production code.; Example usage:. .. code-block:: python. >>> from cppyy.interactive import *; >>> v = std.vector[int](range(10)); >>> print(list(v)); [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]; >>>; >>> cppdef(""struct SomeStruct {};""); True; >>> s = SomeStruct() # <- dynamically made available; >>> s; <cppyy.gbl.SomeStruct object at 0x7fa9b8624320>; >>>. For PyPy, IPython, etc. ``cppyy.gbl`` is simply rebound as ``g`` and; ``cppyy.gbl.std`` is made available as ``std``.; Not as convenient as full lookup, and missing any other namespaces that may be; available, but still saves some typing in may cases. `Odds and ends`; ---------------. * **namespaces**: Are represented as python classes.; Namespaces are more open-ended than classes, so sometimes initial access may; result in updates as data and functions are looked up and constructed; lazily.; Thus the result of ``dir()`` on a namespace shows the classes and functions; available for binding, even if these may not have been created yet.; Once created, namespaces are registered as modules, to allow importing from; them.; The global namespace is ``cppyy.gbl``. * **NULL**: Is represented as ``cppyy.nullptr``.; Starting C++11, the keyword ``nullptr`` is used to represent ``NULL``.; For clarity of intent, it is recommended to use this instead of ``None``; (or the integer ``0``, which can serve in some cases), as ``None`` is better; understood as ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/misc.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/misc.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst:93,Availability,avail,available,93,".. _numba:. Numba support; =============. .. caution::. This is an **experimental** feature, available starting with release; 2.4.0.; It is still incomplete (see listing below) and has only been tested on; Linux on x86_64. Numba `is a JIT compiler`_ for Python functions that can be statically typed; based on their input arguments.; Since C++ objects are always statically typed and already implemented at the; machine level, they can be dynamically integrated into the Numba type tracing; and lowering by exposing type details through C++ reflection at runtime. JIT-compiling traces of mixed Python/bound C++ code reduces, and in some; cases removes, the overhead of boxing/unboxing native data into their Python; proxies and vice versa.; It can also reduce or remove temporaries, especially for template; expressions.; Thus, there can be significant speedups for mixed code, beyond the Numba; compilation of Python code itself.; The current implementation integrates compiled C++ through function pointers,; object pointers, and pointer offsets, into the intermediate representation; (IR) as generated by Numba.; A future version may integrate Cling-generated IR directly into Numba IR (or; vice versa), e.g. if the C++ code is exposed from (precompiled) headers.; This would allow inlining of C++ code into Numba traces, for further; expected speedups. Why Numba?; ----------. The advertised premise of Numba is that it ""makes Python code fast.""; However, there is a much more compelling reason: Numba allows developers to; stay in their chosen ecosystem, be it Python or C++, in mixed environments,; without paying for their choice in lost performance.; For example, a Python developer using Numba does not need to rewrite a kernel; into C++ just to run performantly in a C++ framework.; Similarly, a C++ developer can use Numba to compile and create function; pointers to Python code for easy, performant, access.; This becomes even more compelling if the deployment target is a GPU, which; woul",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/numba.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst:10890,Availability,avail,available,10890,"one that uses C++ bound ones whether from the standard library; or a templated versions from e.g. Eigen.; Use of very complex template expressions may change this balance, but in; principle, wherever it makes sense in the first place to use Numba JITing, it; is also fine, performance-wise, to use ``cppyy`` bound C++ inside the trace. A second important overhead is in unboxing Python proxies of C++ objects,; in particular when passed as an argument to a Numba-JITed function.; The main costs are in the lookup (types are matched at every invocation) and; to a lesser extent the subsequent copying of the instance data.; Thus, functions that take a C++ object as an argument will require more time; spent in the function body for JITing to be worth it than functions that do; not. The current implementation invokes C++ callables through function pointers; and accesses data through offsets calculations from the object's base; address.; A future implementation may be able to inline C++ into the Numba trace if; code is available in headers files or was JITed. Further Information; -------------------. - Numba documentation:; `numba.readthedocs.io <https://numba.readthedocs.io/en/stable/user/index.html>`_. - ""Using C++ From Numba, Fast and Automatic"", presented at `PyHEP 2022 <https://compiler-research.org/presentations/#CppyyNumbaPyHEP2022>`_. - `PyHEP 2022 video <https://www.youtube.com/watch?v=RceFPtB4m1I>`_; - `PyHEP 2022 slides <https://compiler-research.org/assets/presentations/B_Kundu-PyHEP22_Cppyy_Numba.pdf>`_; - `PyHEP 2022 notebook <https://github.com/sudo-panda/PyHEP-2022>`_. - Presentation at CERN's ROOT Parallelism, Performance and Programming Model; (`PPP <https://indico.cern.ch/event/1196174/>`_) Meeting. - `PPP slides <https://indico.cern.ch/event/1196174/contributions/5028203/attachments/2501253/4296778/PPP.pdf>`_; - `PPP notebook <https://indico.cern.ch/event/1196174/contributions/5028203/attachments/2501253/4296735/PPP.ipynb>`_. Acknowledgements; ---------------",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/numba.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst:117,Deployability,release,release,117,".. _numba:. Numba support; =============. .. caution::. This is an **experimental** feature, available starting with release; 2.4.0.; It is still incomplete (see listing below) and has only been tested on; Linux on x86_64. Numba `is a JIT compiler`_ for Python functions that can be statically typed; based on their input arguments.; Since C++ objects are always statically typed and already implemented at the; machine level, they can be dynamically integrated into the Numba type tracing; and lowering by exposing type details through C++ reflection at runtime. JIT-compiling traces of mixed Python/bound C++ code reduces, and in some; cases removes, the overhead of boxing/unboxing native data into their Python; proxies and vice versa.; It can also reduce or remove temporaries, especially for template; expressions.; Thus, there can be significant speedups for mixed code, beyond the Numba; compilation of Python code itself.; The current implementation integrates compiled C++ through function pointers,; object pointers, and pointer offsets, into the intermediate representation; (IR) as generated by Numba.; A future version may integrate Cling-generated IR directly into Numba IR (or; vice versa), e.g. if the C++ code is exposed from (precompiled) headers.; This would allow inlining of C++ code into Numba traces, for further; expected speedups. Why Numba?; ----------. The advertised premise of Numba is that it ""makes Python code fast.""; However, there is a much more compelling reason: Numba allows developers to; stay in their chosen ecosystem, be it Python or C++, in mixed environments,; without paying for their choice in lost performance.; For example, a Python developer using Numba does not need to rewrite a kernel; into C++ just to run performantly in a C++ framework.; Similarly, a C++ developer can use Numba to compile and create function; pointers to Python code for easy, performant, access.; This becomes even more compelling if the deployment target is a GPU, which; woul",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/numba.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst:451,Deployability,integrat,integrated,451,".. _numba:. Numba support; =============. .. caution::. This is an **experimental** feature, available starting with release; 2.4.0.; It is still incomplete (see listing below) and has only been tested on; Linux on x86_64. Numba `is a JIT compiler`_ for Python functions that can be statically typed; based on their input arguments.; Since C++ objects are always statically typed and already implemented at the; machine level, they can be dynamically integrated into the Numba type tracing; and lowering by exposing type details through C++ reflection at runtime. JIT-compiling traces of mixed Python/bound C++ code reduces, and in some; cases removes, the overhead of boxing/unboxing native data into their Python; proxies and vice versa.; It can also reduce or remove temporaries, especially for template; expressions.; Thus, there can be significant speedups for mixed code, beyond the Numba; compilation of Python code itself.; The current implementation integrates compiled C++ through function pointers,; object pointers, and pointer offsets, into the intermediate representation; (IR) as generated by Numba.; A future version may integrate Cling-generated IR directly into Numba IR (or; vice versa), e.g. if the C++ code is exposed from (precompiled) headers.; This would allow inlining of C++ code into Numba traces, for further; expected speedups. Why Numba?; ----------. The advertised premise of Numba is that it ""makes Python code fast.""; However, there is a much more compelling reason: Numba allows developers to; stay in their chosen ecosystem, be it Python or C++, in mixed environments,; without paying for their choice in lost performance.; For example, a Python developer using Numba does not need to rewrite a kernel; into C++ just to run performantly in a C++ framework.; Similarly, a C++ developer can use Numba to compile and create function; pointers to Python code for easy, performant, access.; This becomes even more compelling if the deployment target is a GPU, which; woul",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/numba.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst:959,Deployability,integrat,integrates,959,"ort; =============. .. caution::. This is an **experimental** feature, available starting with release; 2.4.0.; It is still incomplete (see listing below) and has only been tested on; Linux on x86_64. Numba `is a JIT compiler`_ for Python functions that can be statically typed; based on their input arguments.; Since C++ objects are always statically typed and already implemented at the; machine level, they can be dynamically integrated into the Numba type tracing; and lowering by exposing type details through C++ reflection at runtime. JIT-compiling traces of mixed Python/bound C++ code reduces, and in some; cases removes, the overhead of boxing/unboxing native data into their Python; proxies and vice versa.; It can also reduce or remove temporaries, especially for template; expressions.; Thus, there can be significant speedups for mixed code, beyond the Numba; compilation of Python code itself.; The current implementation integrates compiled C++ through function pointers,; object pointers, and pointer offsets, into the intermediate representation; (IR) as generated by Numba.; A future version may integrate Cling-generated IR directly into Numba IR (or; vice versa), e.g. if the C++ code is exposed from (precompiled) headers.; This would allow inlining of C++ code into Numba traces, for further; expected speedups. Why Numba?; ----------. The advertised premise of Numba is that it ""makes Python code fast.""; However, there is a much more compelling reason: Numba allows developers to; stay in their chosen ecosystem, be it Python or C++, in mixed environments,; without paying for their choice in lost performance.; For example, a Python developer using Numba does not need to rewrite a kernel; into C++ just to run performantly in a C++ framework.; Similarly, a C++ developer can use Numba to compile and create function; pointers to Python code for easy, performant, access.; This becomes even more compelling if the deployment target is a GPU, which; would otherwise certainly",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/numba.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst:1137,Deployability,integrat,integrate,1137," listing below) and has only been tested on; Linux on x86_64. Numba `is a JIT compiler`_ for Python functions that can be statically typed; based on their input arguments.; Since C++ objects are always statically typed and already implemented at the; machine level, they can be dynamically integrated into the Numba type tracing; and lowering by exposing type details through C++ reflection at runtime. JIT-compiling traces of mixed Python/bound C++ code reduces, and in some; cases removes, the overhead of boxing/unboxing native data into their Python; proxies and vice versa.; It can also reduce or remove temporaries, especially for template; expressions.; Thus, there can be significant speedups for mixed code, beyond the Numba; compilation of Python code itself.; The current implementation integrates compiled C++ through function pointers,; object pointers, and pointer offsets, into the intermediate representation; (IR) as generated by Numba.; A future version may integrate Cling-generated IR directly into Numba IR (or; vice versa), e.g. if the C++ code is exposed from (precompiled) headers.; This would allow inlining of C++ code into Numba traces, for further; expected speedups. Why Numba?; ----------. The advertised premise of Numba is that it ""makes Python code fast.""; However, there is a much more compelling reason: Numba allows developers to; stay in their chosen ecosystem, be it Python or C++, in mixed environments,; without paying for their choice in lost performance.; For example, a Python developer using Numba does not need to rewrite a kernel; into C++ just to run performantly in a C++ framework.; Similarly, a C++ developer can use Numba to compile and create function; pointers to Python code for easy, performant, access.; This becomes even more compelling if the deployment target is a GPU, which; would otherwise certainly require a rewrite of the Python code.; Add that Numba, as a JIT-compiler, is fully run-time just like ``cppyy``,; and the use case for inte",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/numba.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst:1962,Deployability,deploy,deployment,1962,"h function pointers,; object pointers, and pointer offsets, into the intermediate representation; (IR) as generated by Numba.; A future version may integrate Cling-generated IR directly into Numba IR (or; vice versa), e.g. if the C++ code is exposed from (precompiled) headers.; This would allow inlining of C++ code into Numba traces, for further; expected speedups. Why Numba?; ----------. The advertised premise of Numba is that it ""makes Python code fast.""; However, there is a much more compelling reason: Numba allows developers to; stay in their chosen ecosystem, be it Python or C++, in mixed environments,; without paying for their choice in lost performance.; For example, a Python developer using Numba does not need to rewrite a kernel; into C++ just to run performantly in a C++ framework.; Similarly, a C++ developer can use Numba to compile and create function; pointers to Python code for easy, performant, access.; This becomes even more compelling if the deployment target is a GPU, which; would otherwise certainly require a rewrite of the Python code.; Add that Numba, as a JIT-compiler, is fully run-time just like ``cppyy``,; and the use case for integration is clear.; (Numba does not currently provide support for C++.). Usage; -------. ``cppyy`` does not use Numba extension hooks to minimize accidental; dependencies.; Instead, it requires that the extensions are loaded explicitly by any code; that uses it::. import cppyy.numba_ext. After that, Numba is able to trace ``cppyy`` bound code when applying the; usual ``numba.njit`` decorator. Numba type declarations are done lazily, with the ``numba_ext`` module only; initially registering hooks on proxy base classes, to keep overheads in; Numba's type-resolution to a minimum.; On use in a JITed trace, each C++ type or function call is refined to the; actual, concrete types and type-specific overloads, with templates; instantiated as-needed.; Where possible, lowering is kept generic to reduce the number of callbacks; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/numba.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst:2158,Deployability,integrat,integration,2158,"uture version may integrate Cling-generated IR directly into Numba IR (or; vice versa), e.g. if the C++ code is exposed from (precompiled) headers.; This would allow inlining of C++ code into Numba traces, for further; expected speedups. Why Numba?; ----------. The advertised premise of Numba is that it ""makes Python code fast.""; However, there is a much more compelling reason: Numba allows developers to; stay in their chosen ecosystem, be it Python or C++, in mixed environments,; without paying for their choice in lost performance.; For example, a Python developer using Numba does not need to rewrite a kernel; into C++ just to run performantly in a C++ framework.; Similarly, a C++ developer can use Numba to compile and create function; pointers to Python code for easy, performant, access.; This becomes even more compelling if the deployment target is a GPU, which; would otherwise certainly require a rewrite of the Python code.; Add that Numba, as a JIT-compiler, is fully run-time just like ``cppyy``,; and the use case for integration is clear.; (Numba does not currently provide support for C++.). Usage; -------. ``cppyy`` does not use Numba extension hooks to minimize accidental; dependencies.; Instead, it requires that the extensions are loaded explicitly by any code; that uses it::. import cppyy.numba_ext. After that, Numba is able to trace ``cppyy`` bound code when applying the; usual ``numba.njit`` decorator. Numba type declarations are done lazily, with the ``numba_ext`` module only; initially registering hooks on proxy base classes, to keep overheads in; Numba's type-resolution to a minimum.; On use in a JITed trace, each C++ type or function call is refined to the; actual, concrete types and type-specific overloads, with templates; instantiated as-needed.; Where possible, lowering is kept generic to reduce the number of callbacks; in Numba's compilation chain. Examples; --------. The following, non-exhaustive, set of examples gives an idea of the; current lev",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/numba.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst:616,Energy Efficiency,reduce,reduces,616,".. _numba:. Numba support; =============. .. caution::. This is an **experimental** feature, available starting with release; 2.4.0.; It is still incomplete (see listing below) and has only been tested on; Linux on x86_64. Numba `is a JIT compiler`_ for Python functions that can be statically typed; based on their input arguments.; Since C++ objects are always statically typed and already implemented at the; machine level, they can be dynamically integrated into the Numba type tracing; and lowering by exposing type details through C++ reflection at runtime. JIT-compiling traces of mixed Python/bound C++ code reduces, and in some; cases removes, the overhead of boxing/unboxing native data into their Python; proxies and vice versa.; It can also reduce or remove temporaries, especially for template; expressions.; Thus, there can be significant speedups for mixed code, beyond the Numba; compilation of Python code itself.; The current implementation integrates compiled C++ through function pointers,; object pointers, and pointer offsets, into the intermediate representation; (IR) as generated by Numba.; A future version may integrate Cling-generated IR directly into Numba IR (or; vice versa), e.g. if the C++ code is exposed from (precompiled) headers.; This would allow inlining of C++ code into Numba traces, for further; expected speedups. Why Numba?; ----------. The advertised premise of Numba is that it ""makes Python code fast.""; However, there is a much more compelling reason: Numba allows developers to; stay in their chosen ecosystem, be it Python or C++, in mixed environments,; without paying for their choice in lost performance.; For example, a Python developer using Numba does not need to rewrite a kernel; into C++ just to run performantly in a C++ framework.; Similarly, a C++ developer can use Numba to compile and create function; pointers to Python code for easy, performant, access.; This becomes even more compelling if the deployment target is a GPU, which; woul",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/numba.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst:753,Energy Efficiency,reduce,reduce,753,".. _numba:. Numba support; =============. .. caution::. This is an **experimental** feature, available starting with release; 2.4.0.; It is still incomplete (see listing below) and has only been tested on; Linux on x86_64. Numba `is a JIT compiler`_ for Python functions that can be statically typed; based on their input arguments.; Since C++ objects are always statically typed and already implemented at the; machine level, they can be dynamically integrated into the Numba type tracing; and lowering by exposing type details through C++ reflection at runtime. JIT-compiling traces of mixed Python/bound C++ code reduces, and in some; cases removes, the overhead of boxing/unboxing native data into their Python; proxies and vice versa.; It can also reduce or remove temporaries, especially for template; expressions.; Thus, there can be significant speedups for mixed code, beyond the Numba; compilation of Python code itself.; The current implementation integrates compiled C++ through function pointers,; object pointers, and pointer offsets, into the intermediate representation; (IR) as generated by Numba.; A future version may integrate Cling-generated IR directly into Numba IR (or; vice versa), e.g. if the C++ code is exposed from (precompiled) headers.; This would allow inlining of C++ code into Numba traces, for further; expected speedups. Why Numba?; ----------. The advertised premise of Numba is that it ""makes Python code fast.""; However, there is a much more compelling reason: Numba allows developers to; stay in their chosen ecosystem, be it Python or C++, in mixed environments,; without paying for their choice in lost performance.; For example, a Python developer using Numba does not need to rewrite a kernel; into C++ just to run performantly in a C++ framework.; Similarly, a C++ developer can use Numba to compile and create function; pointers to Python code for easy, performant, access.; This becomes even more compelling if the deployment target is a GPU, which; woul",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/numba.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst:2958,Energy Efficiency,reduce,reduce,2958,"loyment target is a GPU, which; would otherwise certainly require a rewrite of the Python code.; Add that Numba, as a JIT-compiler, is fully run-time just like ``cppyy``,; and the use case for integration is clear.; (Numba does not currently provide support for C++.). Usage; -------. ``cppyy`` does not use Numba extension hooks to minimize accidental; dependencies.; Instead, it requires that the extensions are loaded explicitly by any code; that uses it::. import cppyy.numba_ext. After that, Numba is able to trace ``cppyy`` bound code when applying the; usual ``numba.njit`` decorator. Numba type declarations are done lazily, with the ``numba_ext`` module only; initially registering hooks on proxy base classes, to keep overheads in; Numba's type-resolution to a minimum.; On use in a JITed trace, each C++ type or function call is refined to the; actual, concrete types and type-specific overloads, with templates; instantiated as-needed.; Where possible, lowering is kept generic to reduce the number of callbacks; in Numba's compilation chain. Examples; --------. The following, non-exhaustive, set of examples gives an idea of the; current level of support.; More examples can be found in the `test suite`_. C++ free (global) functions can be called and overloads will be selected, or; a template will be instantiated, based on the provided types.; Exact type matches are fully supported, there is some support for typedefs; add implicit conversions for builtin types, there is no support for; conversions of custom types or default arguments. - **Basic usage**: To use ``cppyy`` in Numba JITed code, simply import; ``cppyy.numba_ext``, after which further use is transparent and the same; as when otherwise using ``cppyy`` in Python.; Example:. .. code-block:: python. >>> import numba; >>> import cppyy; >>> import cppyy.numba_ext # enables numba to work with cppyy; >>> import math; >>> @numba.jit(nopython=True); ... def cpp_sqrt(x):; ... return cppyy.gbl.sqrt(x) # direct use, no extr",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/numba.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst:8866,Energy Efficiency,energy,energy,8866,"d1 + d.get_field2(); ... return total; ...; >>> print(tsdcm(a, d)); 155; >>>. Demo: Numba physics example; ---------------------------. Motivating example taken from:; `numba_scalar_impl.py <https://github.com/numba/numba-examples/blob/master/examples/physics/lennard_jones/numba_scalar_impl.py>`_. .. code-block:: python. >>> import numba; >>> import cppyy; >>> import cppyy.numba_ext; ...; >>> cppyy.cppdef(""""""; ... #include <vector>; ... struct Atom {; ... float x;; ... float y;; ... float z;; ... };; ...; ... std::vector<Atom> atoms = {{1, 2, 3}, {2, 3, 4}, {3, 4, 5}, {4, 5, 6}, {5, 6, 7}};; ... """"""); ...; >>> @numba.njit; >>> def lj_numba_scalar(r):; ... sr6 = (1./r)**6; ... pot = 4.*(sr6*sr6 - sr6); ... return pot. >>> @numba.njit; >>> def distance_numba_scalar(atom1, atom2):; ... dx = atom2.x - atom1.x; ... dy = atom2.y - atom1.y; ... dz = atom2.z - atom1.z; ...; ... r = (dx * dx + dy * dy + dz * dz) ** 0.5; ...; ... return r; ...; >>> def potential_numba_scalar(cluster):; ... energy = 0.0; ... for i in range(cluster.size() - 1):; ... for j in range(i + 1, cluster.size()):; ... r = distance_numba_scalar(cluster[i], cluster[j]); ... e = lj_numba_scalar(r); ... energy += e; ...; ... return energy; ...; >>> print(""Total lennard jones potential ="", potential_numba_scalar(cppyy.gbl.atoms)); Total lennard jones potential = -0.5780277345740283. Overhead; --------. The main overhead of JITing Numba traces is in the type annotation in Numba; itself, optimization of the IR and assembly by the backend less so.; (There is also a non-negligible cost to Numba initialization, which is why; ``cppyy`` does not provide automatic extension hooks.); The use of ``cppyy`` bound C++, which relies on the same Numba machinery,; does not change that, since the reflection-based lookups are in C++ and; comparatively very fast.; For example, there is no appreciable difference in wall clock time to JIT a; trace using Numba's included math functions (from module ``math`` or; ``numpy``) or one ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/numba.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst:9052,Energy Efficiency,energy,energy,9052,"py <https://github.com/numba/numba-examples/blob/master/examples/physics/lennard_jones/numba_scalar_impl.py>`_. .. code-block:: python. >>> import numba; >>> import cppyy; >>> import cppyy.numba_ext; ...; >>> cppyy.cppdef(""""""; ... #include <vector>; ... struct Atom {; ... float x;; ... float y;; ... float z;; ... };; ...; ... std::vector<Atom> atoms = {{1, 2, 3}, {2, 3, 4}, {3, 4, 5}, {4, 5, 6}, {5, 6, 7}};; ... """"""); ...; >>> @numba.njit; >>> def lj_numba_scalar(r):; ... sr6 = (1./r)**6; ... pot = 4.*(sr6*sr6 - sr6); ... return pot. >>> @numba.njit; >>> def distance_numba_scalar(atom1, atom2):; ... dx = atom2.x - atom1.x; ... dy = atom2.y - atom1.y; ... dz = atom2.z - atom1.z; ...; ... r = (dx * dx + dy * dy + dz * dz) ** 0.5; ...; ... return r; ...; >>> def potential_numba_scalar(cluster):; ... energy = 0.0; ... for i in range(cluster.size() - 1):; ... for j in range(i + 1, cluster.size()):; ... r = distance_numba_scalar(cluster[i], cluster[j]); ... e = lj_numba_scalar(r); ... energy += e; ...; ... return energy; ...; >>> print(""Total lennard jones potential ="", potential_numba_scalar(cppyy.gbl.atoms)); Total lennard jones potential = -0.5780277345740283. Overhead; --------. The main overhead of JITing Numba traces is in the type annotation in Numba; itself, optimization of the IR and assembly by the backend less so.; (There is also a non-negligible cost to Numba initialization, which is why; ``cppyy`` does not provide automatic extension hooks.); The use of ``cppyy`` bound C++, which relies on the same Numba machinery,; does not change that, since the reflection-based lookups are in C++ and; comparatively very fast.; For example, there is no appreciable difference in wall clock time to JIT a; trace using Numba's included math functions (from module ``math`` or; ``numpy``) or one that uses C++ bound ones whether from the standard library; or a templated versions from e.g. Eigen.; Use of very complex template expressions may change this balance, but in; principle, w",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/numba.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst:9081,Energy Efficiency,energy,energy,9081,"numba/numba-examples/blob/master/examples/physics/lennard_jones/numba_scalar_impl.py>`_. .. code-block:: python. >>> import numba; >>> import cppyy; >>> import cppyy.numba_ext; ...; >>> cppyy.cppdef(""""""; ... #include <vector>; ... struct Atom {; ... float x;; ... float y;; ... float z;; ... };; ...; ... std::vector<Atom> atoms = {{1, 2, 3}, {2, 3, 4}, {3, 4, 5}, {4, 5, 6}, {5, 6, 7}};; ... """"""); ...; >>> @numba.njit; >>> def lj_numba_scalar(r):; ... sr6 = (1./r)**6; ... pot = 4.*(sr6*sr6 - sr6); ... return pot. >>> @numba.njit; >>> def distance_numba_scalar(atom1, atom2):; ... dx = atom2.x - atom1.x; ... dy = atom2.y - atom1.y; ... dz = atom2.z - atom1.z; ...; ... r = (dx * dx + dy * dy + dz * dz) ** 0.5; ...; ... return r; ...; >>> def potential_numba_scalar(cluster):; ... energy = 0.0; ... for i in range(cluster.size() - 1):; ... for j in range(i + 1, cluster.size()):; ... r = distance_numba_scalar(cluster[i], cluster[j]); ... e = lj_numba_scalar(r); ... energy += e; ...; ... return energy; ...; >>> print(""Total lennard jones potential ="", potential_numba_scalar(cppyy.gbl.atoms)); Total lennard jones potential = -0.5780277345740283. Overhead; --------. The main overhead of JITing Numba traces is in the type annotation in Numba; itself, optimization of the IR and assembly by the backend less so.; (There is also a non-negligible cost to Numba initialization, which is why; ``cppyy`` does not provide automatic extension hooks.); The use of ``cppyy`` bound C++, which relies on the same Numba machinery,; does not change that, since the reflection-based lookups are in C++ and; comparatively very fast.; For example, there is no appreciable difference in wall clock time to JIT a; trace using Numba's included math functions (from module ``math`` or; ``numpy``) or one that uses C++ bound ones whether from the standard library; or a templated versions from e.g. Eigen.; Use of very complex template expressions may change this balance, but in; principle, wherever it makes sense ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/numba.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst:451,Integrability,integrat,integrated,451,".. _numba:. Numba support; =============. .. caution::. This is an **experimental** feature, available starting with release; 2.4.0.; It is still incomplete (see listing below) and has only been tested on; Linux on x86_64. Numba `is a JIT compiler`_ for Python functions that can be statically typed; based on their input arguments.; Since C++ objects are always statically typed and already implemented at the; machine level, they can be dynamically integrated into the Numba type tracing; and lowering by exposing type details through C++ reflection at runtime. JIT-compiling traces of mixed Python/bound C++ code reduces, and in some; cases removes, the overhead of boxing/unboxing native data into their Python; proxies and vice versa.; It can also reduce or remove temporaries, especially for template; expressions.; Thus, there can be significant speedups for mixed code, beyond the Numba; compilation of Python code itself.; The current implementation integrates compiled C++ through function pointers,; object pointers, and pointer offsets, into the intermediate representation; (IR) as generated by Numba.; A future version may integrate Cling-generated IR directly into Numba IR (or; vice versa), e.g. if the C++ code is exposed from (precompiled) headers.; This would allow inlining of C++ code into Numba traces, for further; expected speedups. Why Numba?; ----------. The advertised premise of Numba is that it ""makes Python code fast.""; However, there is a much more compelling reason: Numba allows developers to; stay in their chosen ecosystem, be it Python or C++, in mixed environments,; without paying for their choice in lost performance.; For example, a Python developer using Numba does not need to rewrite a kernel; into C++ just to run performantly in a C++ framework.; Similarly, a C++ developer can use Numba to compile and create function; pointers to Python code for easy, performant, access.; This becomes even more compelling if the deployment target is a GPU, which; woul",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/numba.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst:959,Integrability,integrat,integrates,959,"ort; =============. .. caution::. This is an **experimental** feature, available starting with release; 2.4.0.; It is still incomplete (see listing below) and has only been tested on; Linux on x86_64. Numba `is a JIT compiler`_ for Python functions that can be statically typed; based on their input arguments.; Since C++ objects are always statically typed and already implemented at the; machine level, they can be dynamically integrated into the Numba type tracing; and lowering by exposing type details through C++ reflection at runtime. JIT-compiling traces of mixed Python/bound C++ code reduces, and in some; cases removes, the overhead of boxing/unboxing native data into their Python; proxies and vice versa.; It can also reduce or remove temporaries, especially for template; expressions.; Thus, there can be significant speedups for mixed code, beyond the Numba; compilation of Python code itself.; The current implementation integrates compiled C++ through function pointers,; object pointers, and pointer offsets, into the intermediate representation; (IR) as generated by Numba.; A future version may integrate Cling-generated IR directly into Numba IR (or; vice versa), e.g. if the C++ code is exposed from (precompiled) headers.; This would allow inlining of C++ code into Numba traces, for further; expected speedups. Why Numba?; ----------. The advertised premise of Numba is that it ""makes Python code fast.""; However, there is a much more compelling reason: Numba allows developers to; stay in their chosen ecosystem, be it Python or C++, in mixed environments,; without paying for their choice in lost performance.; For example, a Python developer using Numba does not need to rewrite a kernel; into C++ just to run performantly in a C++ framework.; Similarly, a C++ developer can use Numba to compile and create function; pointers to Python code for easy, performant, access.; This becomes even more compelling if the deployment target is a GPU, which; would otherwise certainly",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/numba.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst:1137,Integrability,integrat,integrate,1137," listing below) and has only been tested on; Linux on x86_64. Numba `is a JIT compiler`_ for Python functions that can be statically typed; based on their input arguments.; Since C++ objects are always statically typed and already implemented at the; machine level, they can be dynamically integrated into the Numba type tracing; and lowering by exposing type details through C++ reflection at runtime. JIT-compiling traces of mixed Python/bound C++ code reduces, and in some; cases removes, the overhead of boxing/unboxing native data into their Python; proxies and vice versa.; It can also reduce or remove temporaries, especially for template; expressions.; Thus, there can be significant speedups for mixed code, beyond the Numba; compilation of Python code itself.; The current implementation integrates compiled C++ through function pointers,; object pointers, and pointer offsets, into the intermediate representation; (IR) as generated by Numba.; A future version may integrate Cling-generated IR directly into Numba IR (or; vice versa), e.g. if the C++ code is exposed from (precompiled) headers.; This would allow inlining of C++ code into Numba traces, for further; expected speedups. Why Numba?; ----------. The advertised premise of Numba is that it ""makes Python code fast.""; However, there is a much more compelling reason: Numba allows developers to; stay in their chosen ecosystem, be it Python or C++, in mixed environments,; without paying for their choice in lost performance.; For example, a Python developer using Numba does not need to rewrite a kernel; into C++ just to run performantly in a C++ framework.; Similarly, a C++ developer can use Numba to compile and create function; pointers to Python code for easy, performant, access.; This becomes even more compelling if the deployment target is a GPU, which; would otherwise certainly require a rewrite of the Python code.; Add that Numba, as a JIT-compiler, is fully run-time just like ``cppyy``,; and the use case for inte",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/numba.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst:2158,Integrability,integrat,integration,2158,"uture version may integrate Cling-generated IR directly into Numba IR (or; vice versa), e.g. if the C++ code is exposed from (precompiled) headers.; This would allow inlining of C++ code into Numba traces, for further; expected speedups. Why Numba?; ----------. The advertised premise of Numba is that it ""makes Python code fast.""; However, there is a much more compelling reason: Numba allows developers to; stay in their chosen ecosystem, be it Python or C++, in mixed environments,; without paying for their choice in lost performance.; For example, a Python developer using Numba does not need to rewrite a kernel; into C++ just to run performantly in a C++ framework.; Similarly, a C++ developer can use Numba to compile and create function; pointers to Python code for easy, performant, access.; This becomes even more compelling if the deployment target is a GPU, which; would otherwise certainly require a rewrite of the Python code.; Add that Numba, as a JIT-compiler, is fully run-time just like ``cppyy``,; and the use case for integration is clear.; (Numba does not currently provide support for C++.). Usage; -------. ``cppyy`` does not use Numba extension hooks to minimize accidental; dependencies.; Instead, it requires that the extensions are loaded explicitly by any code; that uses it::. import cppyy.numba_ext. After that, Numba is able to trace ``cppyy`` bound code when applying the; usual ``numba.njit`` decorator. Numba type declarations are done lazily, with the ``numba_ext`` module only; initially registering hooks on proxy base classes, to keep overheads in; Numba's type-resolution to a minimum.; On use in a JITed trace, each C++ type or function call is refined to the; actual, concrete types and type-specific overloads, with templates; instantiated as-needed.; Where possible, lowering is kept generic to reduce the number of callbacks; in Numba's compilation chain. Examples; --------. The following, non-exhaustive, set of examples gives an idea of the; current lev",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/numba.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst:2319,Integrability,depend,dependencies,2319,"ing of C++ code into Numba traces, for further; expected speedups. Why Numba?; ----------. The advertised premise of Numba is that it ""makes Python code fast.""; However, there is a much more compelling reason: Numba allows developers to; stay in their chosen ecosystem, be it Python or C++, in mixed environments,; without paying for their choice in lost performance.; For example, a Python developer using Numba does not need to rewrite a kernel; into C++ just to run performantly in a C++ framework.; Similarly, a C++ developer can use Numba to compile and create function; pointers to Python code for easy, performant, access.; This becomes even more compelling if the deployment target is a GPU, which; would otherwise certainly require a rewrite of the Python code.; Add that Numba, as a JIT-compiler, is fully run-time just like ``cppyy``,; and the use case for integration is clear.; (Numba does not currently provide support for C++.). Usage; -------. ``cppyy`` does not use Numba extension hooks to minimize accidental; dependencies.; Instead, it requires that the extensions are loaded explicitly by any code; that uses it::. import cppyy.numba_ext. After that, Numba is able to trace ``cppyy`` bound code when applying the; usual ``numba.njit`` decorator. Numba type declarations are done lazily, with the ``numba_ext`` module only; initially registering hooks on proxy base classes, to keep overheads in; Numba's type-resolution to a minimum.; On use in a JITed trace, each C++ type or function call is refined to the; actual, concrete types and type-specific overloads, with templates; instantiated as-needed.; Where possible, lowering is kept generic to reduce the number of callbacks; in Numba's compilation chain. Examples; --------. The following, non-exhaustive, set of examples gives an idea of the; current level of support.; More examples can be found in the `test suite`_. C++ free (global) functions can be called and overloads will be selected, or; a template will be instantia",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/numba.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst:4592,Integrability,depend,dependent,4592,"mba_ext``, after which further use is transparent and the same; as when otherwise using ``cppyy`` in Python.; Example:. .. code-block:: python. >>> import numba; >>> import cppyy; >>> import cppyy.numba_ext # enables numba to work with cppyy; >>> import math; >>> @numba.jit(nopython=True); ... def cpp_sqrt(x):; ... return cppyy.gbl.sqrt(x) # direct use, no extra setup required; >>> print(""Sqrt of 4: "", cpp_sqrt(4.0)); Sqrt of 4: 2.0; >>> print(""Sqrt of Pi: "", cpp_sqrt(math.pi)); Sqrt of Pi: 1.7724538509055159. - **Overload selection**: C++ overloads provide different implementations; for different argument types (not to be confused with Numba overloads,; which provide different implementations for the same argument types).; Unfortunately, mapping of Python types to C++ types is often not exact,; so a ""best match"" is chosen, similarly to what ``cppyy`` normally does.; However, the latter, being dynamic, is more flexible.; For example, best-match C++ integer type can be value dependent, whereas; in the Numba trace, it is by definition fixed at JIT time.; Example:. .. code-block:: python. >>> cppyy.cppdef(""""""; ... int mul(int x) { return x * 2; }; ... float mul(float x) { return x * 3; }; ... """"""); >>> @numba.jit(nopython=True); ... def oversel(a):; ... total = type(a[0])(0); ... for i in range(len(a)):; ... total += cppyy.gbl.mul(a[i]); ... return total. >>> a = np.array(range(10), dtype=np.float32); >>> print(""Array: "", a); Array: [0. 1. 2. 3. 4. 5. 6. 7. 8. 9.]; >>> print(""Overload selection output: "", oversel(a)); Overload selection output: 135.0; >>> a = np.array(range(10), dtype=np.int32); >>> print(""Array: "", a); Array: [0 1 2 3 4 5 6 7 8 9]; >>> print(""Overload selection output: "", oversel(a)); Overload selection output: 90. - **Template instantiation**: templates are instantiated as needed as part; of the overload selection.; The best match is done for the arguments provided at the point of first; use.; If those arguments vary based on program input, it may ma",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/numba.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst:1720,Modifiability,rewrite,rewrite,1720,"and vice versa.; It can also reduce or remove temporaries, especially for template; expressions.; Thus, there can be significant speedups for mixed code, beyond the Numba; compilation of Python code itself.; The current implementation integrates compiled C++ through function pointers,; object pointers, and pointer offsets, into the intermediate representation; (IR) as generated by Numba.; A future version may integrate Cling-generated IR directly into Numba IR (or; vice versa), e.g. if the C++ code is exposed from (precompiled) headers.; This would allow inlining of C++ code into Numba traces, for further; expected speedups. Why Numba?; ----------. The advertised premise of Numba is that it ""makes Python code fast.""; However, there is a much more compelling reason: Numba allows developers to; stay in their chosen ecosystem, be it Python or C++, in mixed environments,; without paying for their choice in lost performance.; For example, a Python developer using Numba does not need to rewrite a kernel; into C++ just to run performantly in a C++ framework.; Similarly, a C++ developer can use Numba to compile and create function; pointers to Python code for easy, performant, access.; This becomes even more compelling if the deployment target is a GPU, which; would otherwise certainly require a rewrite of the Python code.; Add that Numba, as a JIT-compiler, is fully run-time just like ``cppyy``,; and the use case for integration is clear.; (Numba does not currently provide support for C++.). Usage; -------. ``cppyy`` does not use Numba extension hooks to minimize accidental; dependencies.; Instead, it requires that the extensions are loaded explicitly by any code; that uses it::. import cppyy.numba_ext. After that, Numba is able to trace ``cppyy`` bound code when applying the; usual ``numba.njit`` decorator. Numba type declarations are done lazily, with the ``numba_ext`` module only; initially registering hooks on proxy base classes, to keep overheads in; Numba's type-reso",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/numba.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst:2033,Modifiability,rewrite,rewrite,2033,"h function pointers,; object pointers, and pointer offsets, into the intermediate representation; (IR) as generated by Numba.; A future version may integrate Cling-generated IR directly into Numba IR (or; vice versa), e.g. if the C++ code is exposed from (precompiled) headers.; This would allow inlining of C++ code into Numba traces, for further; expected speedups. Why Numba?; ----------. The advertised premise of Numba is that it ""makes Python code fast.""; However, there is a much more compelling reason: Numba allows developers to; stay in their chosen ecosystem, be it Python or C++, in mixed environments,; without paying for their choice in lost performance.; For example, a Python developer using Numba does not need to rewrite a kernel; into C++ just to run performantly in a C++ framework.; Similarly, a C++ developer can use Numba to compile and create function; pointers to Python code for easy, performant, access.; This becomes even more compelling if the deployment target is a GPU, which; would otherwise certainly require a rewrite of the Python code.; Add that Numba, as a JIT-compiler, is fully run-time just like ``cppyy``,; and the use case for integration is clear.; (Numba does not currently provide support for C++.). Usage; -------. ``cppyy`` does not use Numba extension hooks to minimize accidental; dependencies.; Instead, it requires that the extensions are loaded explicitly by any code; that uses it::. import cppyy.numba_ext. After that, Numba is able to trace ``cppyy`` bound code when applying the; usual ``numba.njit`` decorator. Numba type declarations are done lazily, with the ``numba_ext`` module only; initially registering hooks on proxy base classes, to keep overheads in; Numba's type-resolution to a minimum.; On use in a JITed trace, each C++ type or function call is refined to the; actual, concrete types and type-specific overloads, with templates; instantiated as-needed.; Where possible, lowering is kept generic to reduce the number of callbacks; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/numba.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst:4527,Modifiability,flexible,flexible,4527,"t arguments. - **Basic usage**: To use ``cppyy`` in Numba JITed code, simply import; ``cppyy.numba_ext``, after which further use is transparent and the same; as when otherwise using ``cppyy`` in Python.; Example:. .. code-block:: python. >>> import numba; >>> import cppyy; >>> import cppyy.numba_ext # enables numba to work with cppyy; >>> import math; >>> @numba.jit(nopython=True); ... def cpp_sqrt(x):; ... return cppyy.gbl.sqrt(x) # direct use, no extra setup required; >>> print(""Sqrt of 4: "", cpp_sqrt(4.0)); Sqrt of 4: 2.0; >>> print(""Sqrt of Pi: "", cpp_sqrt(math.pi)); Sqrt of Pi: 1.7724538509055159. - **Overload selection**: C++ overloads provide different implementations; for different argument types (not to be confused with Numba overloads,; which provide different implementations for the same argument types).; Unfortunately, mapping of Python types to C++ types is often not exact,; so a ""best match"" is chosen, similarly to what ``cppyy`` normally does.; However, the latter, being dynamic, is more flexible.; For example, best-match C++ integer type can be value dependent, whereas; in the Numba trace, it is by definition fixed at JIT time.; Example:. .. code-block:: python. >>> cppyy.cppdef(""""""; ... int mul(int x) { return x * 2; }; ... float mul(float x) { return x * 3; }; ... """"""); >>> @numba.jit(nopython=True); ... def oversel(a):; ... total = type(a[0])(0); ... for i in range(len(a)):; ... total += cppyy.gbl.mul(a[i]); ... return total. >>> a = np.array(range(10), dtype=np.float32); >>> print(""Array: "", a); Array: [0. 1. 2. 3. 4. 5. 6. 7. 8. 9.]; >>> print(""Overload selection output: "", oversel(a)); Overload selection output: 135.0; >>> a = np.array(range(10), dtype=np.int32); >>> print(""Array: "", a); Array: [0 1 2 3 4 5 6 7 8 9]; >>> print(""Overload selection output: "", oversel(a)); Overload selection output: 90. - **Template instantiation**: templates are instantiated as needed as part; of the overload selection.; The best match is done for the arguments p",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/numba.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst:1645,Performance,perform,performance,1645,"at runtime. JIT-compiling traces of mixed Python/bound C++ code reduces, and in some; cases removes, the overhead of boxing/unboxing native data into their Python; proxies and vice versa.; It can also reduce or remove temporaries, especially for template; expressions.; Thus, there can be significant speedups for mixed code, beyond the Numba; compilation of Python code itself.; The current implementation integrates compiled C++ through function pointers,; object pointers, and pointer offsets, into the intermediate representation; (IR) as generated by Numba.; A future version may integrate Cling-generated IR directly into Numba IR (or; vice versa), e.g. if the C++ code is exposed from (precompiled) headers.; This would allow inlining of C++ code into Numba traces, for further; expected speedups. Why Numba?; ----------. The advertised premise of Numba is that it ""makes Python code fast.""; However, there is a much more compelling reason: Numba allows developers to; stay in their chosen ecosystem, be it Python or C++, in mixed environments,; without paying for their choice in lost performance.; For example, a Python developer using Numba does not need to rewrite a kernel; into C++ just to run performantly in a C++ framework.; Similarly, a C++ developer can use Numba to compile and create function; pointers to Python code for easy, performant, access.; This becomes even more compelling if the deployment target is a GPU, which; would otherwise certainly require a rewrite of the Python code.; Add that Numba, as a JIT-compiler, is fully run-time just like ``cppyy``,; and the use case for integration is clear.; (Numba does not currently provide support for C++.). Usage; -------. ``cppyy`` does not use Numba extension hooks to minimize accidental; dependencies.; Instead, it requires that the extensions are loaded explicitly by any code; that uses it::. import cppyy.numba_ext. After that, Numba is able to trace ``cppyy`` bound code when applying the; usual ``numba.njit`` decorat",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/numba.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst:1759,Performance,perform,performantly,1759,"and vice versa.; It can also reduce or remove temporaries, especially for template; expressions.; Thus, there can be significant speedups for mixed code, beyond the Numba; compilation of Python code itself.; The current implementation integrates compiled C++ through function pointers,; object pointers, and pointer offsets, into the intermediate representation; (IR) as generated by Numba.; A future version may integrate Cling-generated IR directly into Numba IR (or; vice versa), e.g. if the C++ code is exposed from (precompiled) headers.; This would allow inlining of C++ code into Numba traces, for further; expected speedups. Why Numba?; ----------. The advertised premise of Numba is that it ""makes Python code fast.""; However, there is a much more compelling reason: Numba allows developers to; stay in their chosen ecosystem, be it Python or C++, in mixed environments,; without paying for their choice in lost performance.; For example, a Python developer using Numba does not need to rewrite a kernel; into C++ just to run performantly in a C++ framework.; Similarly, a C++ developer can use Numba to compile and create function; pointers to Python code for easy, performant, access.; This becomes even more compelling if the deployment target is a GPU, which; would otherwise certainly require a rewrite of the Python code.; Add that Numba, as a JIT-compiler, is fully run-time just like ``cppyy``,; and the use case for integration is clear.; (Numba does not currently provide support for C++.). Usage; -------. ``cppyy`` does not use Numba extension hooks to minimize accidental; dependencies.; Instead, it requires that the extensions are loaded explicitly by any code; that uses it::. import cppyy.numba_ext. After that, Numba is able to trace ``cppyy`` bound code when applying the; usual ``numba.njit`` decorator. Numba type declarations are done lazily, with the ``numba_ext`` module only; initially registering hooks on proxy base classes, to keep overheads in; Numba's type-reso",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/numba.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst:1900,Performance,perform,performant,1900,"eedups for mixed code, beyond the Numba; compilation of Python code itself.; The current implementation integrates compiled C++ through function pointers,; object pointers, and pointer offsets, into the intermediate representation; (IR) as generated by Numba.; A future version may integrate Cling-generated IR directly into Numba IR (or; vice versa), e.g. if the C++ code is exposed from (precompiled) headers.; This would allow inlining of C++ code into Numba traces, for further; expected speedups. Why Numba?; ----------. The advertised premise of Numba is that it ""makes Python code fast.""; However, there is a much more compelling reason: Numba allows developers to; stay in their chosen ecosystem, be it Python or C++, in mixed environments,; without paying for their choice in lost performance.; For example, a Python developer using Numba does not need to rewrite a kernel; into C++ just to run performantly in a C++ framework.; Similarly, a C++ developer can use Numba to compile and create function; pointers to Python code for easy, performant, access.; This becomes even more compelling if the deployment target is a GPU, which; would otherwise certainly require a rewrite of the Python code.; Add that Numba, as a JIT-compiler, is fully run-time just like ``cppyy``,; and the use case for integration is clear.; (Numba does not currently provide support for C++.). Usage; -------. ``cppyy`` does not use Numba extension hooks to minimize accidental; dependencies.; Instead, it requires that the extensions are loaded explicitly by any code; that uses it::. import cppyy.numba_ext. After that, Numba is able to trace ``cppyy`` bound code when applying the; usual ``numba.njit`` decorator. Numba type declarations are done lazily, with the ``numba_ext`` module only; initially registering hooks on proxy base classes, to keep overheads in; Numba's type-resolution to a minimum.; On use in a JITed trace, each C++ type or function call is refined to the; actual, concrete types and type-sp",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/numba.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst:2379,Performance,load,loaded,2379,"-. The advertised premise of Numba is that it ""makes Python code fast.""; However, there is a much more compelling reason: Numba allows developers to; stay in their chosen ecosystem, be it Python or C++, in mixed environments,; without paying for their choice in lost performance.; For example, a Python developer using Numba does not need to rewrite a kernel; into C++ just to run performantly in a C++ framework.; Similarly, a C++ developer can use Numba to compile and create function; pointers to Python code for easy, performant, access.; This becomes even more compelling if the deployment target is a GPU, which; would otherwise certainly require a rewrite of the Python code.; Add that Numba, as a JIT-compiler, is fully run-time just like ``cppyy``,; and the use case for integration is clear.; (Numba does not currently provide support for C++.). Usage; -------. ``cppyy`` does not use Numba extension hooks to minimize accidental; dependencies.; Instead, it requires that the extensions are loaded explicitly by any code; that uses it::. import cppyy.numba_ext. After that, Numba is able to trace ``cppyy`` bound code when applying the; usual ``numba.njit`` decorator. Numba type declarations are done lazily, with the ``numba_ext`` module only; initially registering hooks on proxy base classes, to keep overheads in; Numba's type-resolution to a minimum.; On use in a JITed trace, each C++ type or function call is refined to the; actual, concrete types and type-specific overloads, with templates; instantiated as-needed.; Where possible, lowering is kept generic to reduce the number of callbacks; in Numba's compilation chain. Examples; --------. The following, non-exhaustive, set of examples gives an idea of the; current level of support.; More examples can be found in the `test suite`_. C++ free (global) functions can be called and overloads will be selected, or; a template will be instantiated, based on the provided types.; Exact type matches are fully supported, there is some",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/numba.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst:9339,Performance,optimiz,optimization,9339,"; ... float x;; ... float y;; ... float z;; ... };; ...; ... std::vector<Atom> atoms = {{1, 2, 3}, {2, 3, 4}, {3, 4, 5}, {4, 5, 6}, {5, 6, 7}};; ... """"""); ...; >>> @numba.njit; >>> def lj_numba_scalar(r):; ... sr6 = (1./r)**6; ... pot = 4.*(sr6*sr6 - sr6); ... return pot. >>> @numba.njit; >>> def distance_numba_scalar(atom1, atom2):; ... dx = atom2.x - atom1.x; ... dy = atom2.y - atom1.y; ... dz = atom2.z - atom1.z; ...; ... r = (dx * dx + dy * dy + dz * dz) ** 0.5; ...; ... return r; ...; >>> def potential_numba_scalar(cluster):; ... energy = 0.0; ... for i in range(cluster.size() - 1):; ... for j in range(i + 1, cluster.size()):; ... r = distance_numba_scalar(cluster[i], cluster[j]); ... e = lj_numba_scalar(r); ... energy += e; ...; ... return energy; ...; >>> print(""Total lennard jones potential ="", potential_numba_scalar(cppyy.gbl.atoms)); Total lennard jones potential = -0.5780277345740283. Overhead; --------. The main overhead of JITing Numba traces is in the type annotation in Numba; itself, optimization of the IR and assembly by the backend less so.; (There is also a non-negligible cost to Numba initialization, which is why; ``cppyy`` does not provide automatic extension hooks.); The use of ``cppyy`` bound C++, which relies on the same Numba machinery,; does not change that, since the reflection-based lookups are in C++ and; comparatively very fast.; For example, there is no appreciable difference in wall clock time to JIT a; trace using Numba's included math functions (from module ``math`` or; ``numpy``) or one that uses C++ bound ones whether from the standard library; or a templated versions from e.g. Eigen.; Use of very complex template expressions may change this balance, but in; principle, wherever it makes sense in the first place to use Numba JITing, it; is also fine, performance-wise, to use ``cppyy`` bound C++ inside the trace. A second important overhead is in unboxing Python proxies of C++ objects,; in particular when passed as an argument to a Nu",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/numba.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst:10140,Performance,perform,performance-wise,10140,"y; ...; >>> print(""Total lennard jones potential ="", potential_numba_scalar(cppyy.gbl.atoms)); Total lennard jones potential = -0.5780277345740283. Overhead; --------. The main overhead of JITing Numba traces is in the type annotation in Numba; itself, optimization of the IR and assembly by the backend less so.; (There is also a non-negligible cost to Numba initialization, which is why; ``cppyy`` does not provide automatic extension hooks.); The use of ``cppyy`` bound C++, which relies on the same Numba machinery,; does not change that, since the reflection-based lookups are in C++ and; comparatively very fast.; For example, there is no appreciable difference in wall clock time to JIT a; trace using Numba's included math functions (from module ``math`` or; ``numpy``) or one that uses C++ bound ones whether from the standard library; or a templated versions from e.g. Eigen.; Use of very complex template expressions may change this balance, but in; principle, wherever it makes sense in the first place to use Numba JITing, it; is also fine, performance-wise, to use ``cppyy`` bound C++ inside the trace. A second important overhead is in unboxing Python proxies of C++ objects,; in particular when passed as an argument to a Numba-JITed function.; The main costs are in the lookup (types are matched at every invocation) and; to a lesser extent the subsequent copying of the instance data.; Thus, functions that take a C++ object as an argument will require more time; spent in the function body for JITing to be worth it than functions that do; not. The current implementation invokes C++ callables through function pointers; and accesses data through offsets calculations from the object's base; address.; A future implementation may be able to inline C++ into the Numba trace if; code is available in headers files or was JITed. Further Information; -------------------. - Numba documentation:; `numba.readthedocs.io <https://numba.readthedocs.io/en/stable/user/index.html>`_. - ""Using",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/numba.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst:1231,Security,expose,exposed,1231," compiler`_ for Python functions that can be statically typed; based on their input arguments.; Since C++ objects are always statically typed and already implemented at the; machine level, they can be dynamically integrated into the Numba type tracing; and lowering by exposing type details through C++ reflection at runtime. JIT-compiling traces of mixed Python/bound C++ code reduces, and in some; cases removes, the overhead of boxing/unboxing native data into their Python; proxies and vice versa.; It can also reduce or remove temporaries, especially for template; expressions.; Thus, there can be significant speedups for mixed code, beyond the Numba; compilation of Python code itself.; The current implementation integrates compiled C++ through function pointers,; object pointers, and pointer offsets, into the intermediate representation; (IR) as generated by Numba.; A future version may integrate Cling-generated IR directly into Numba IR (or; vice versa), e.g. if the C++ code is exposed from (precompiled) headers.; This would allow inlining of C++ code into Numba traces, for further; expected speedups. Why Numba?; ----------. The advertised premise of Numba is that it ""makes Python code fast.""; However, there is a much more compelling reason: Numba allows developers to; stay in their chosen ecosystem, be it Python or C++, in mixed environments,; without paying for their choice in lost performance.; For example, a Python developer using Numba does not need to rewrite a kernel; into C++ just to run performantly in a C++ framework.; Similarly, a C++ developer can use Numba to compile and create function; pointers to Python code for easy, performant, access.; This becomes even more compelling if the deployment target is a GPU, which; would otherwise certainly require a rewrite of the Python code.; Add that Numba, as a JIT-compiler, is fully run-time just like ``cppyy``,; and the use case for integration is clear.; (Numba does not currently provide support for C++.). Usage",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/numba.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst:1912,Security,access,access,1912,"eedups for mixed code, beyond the Numba; compilation of Python code itself.; The current implementation integrates compiled C++ through function pointers,; object pointers, and pointer offsets, into the intermediate representation; (IR) as generated by Numba.; A future version may integrate Cling-generated IR directly into Numba IR (or; vice versa), e.g. if the C++ code is exposed from (precompiled) headers.; This would allow inlining of C++ code into Numba traces, for further; expected speedups. Why Numba?; ----------. The advertised premise of Numba is that it ""makes Python code fast.""; However, there is a much more compelling reason: Numba allows developers to; stay in their chosen ecosystem, be it Python or C++, in mixed environments,; without paying for their choice in lost performance.; For example, a Python developer using Numba does not need to rewrite a kernel; into C++ just to run performantly in a C++ framework.; Similarly, a C++ developer can use Numba to compile and create function; pointers to Python code for easy, performant, access.; This becomes even more compelling if the deployment target is a GPU, which; would otherwise certainly require a rewrite of the Python code.; Add that Numba, as a JIT-compiler, is fully run-time just like ``cppyy``,; and the use case for integration is clear.; (Numba does not currently provide support for C++.). Usage; -------. ``cppyy`` does not use Numba extension hooks to minimize accidental; dependencies.; Instead, it requires that the extensions are loaded explicitly by any code; that uses it::. import cppyy.numba_ext. After that, Numba is able to trace ``cppyy`` bound code when applying the; usual ``numba.njit`` decorator. Numba type declarations are done lazily, with the ``numba_ext`` module only; initially registering hooks on proxy base classes, to keep overheads in; Numba's type-resolution to a minimum.; On use in a JITed trace, each C++ type or function call is refined to the; actual, concrete types and type-sp",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/numba.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst:6618,Security,access,accessible,6618," functions.; Example:. .. code-block:: python. >>> import cppyy; >>> import cppyy.numba_ext; >>> import numba; >>> import numpy as np; >>> cppyy.cppdef(""""""; ... template<typename T>; ... T square(T t) { return t*t; }; ... """"""); >>> @numba.jit(nopython=True); ... def tsa(a):; ... total = type(a[0])(0); ... for i in range(len(a)):; ... total += cppyy.gbl.square(a[i]); ... return total; >>> a = np.array(range(10), dtype=np.float32); >>> print(""Float array: "", a); Float array: [0. 1. 2. 3. 4. 5. 6. 7. 8. 9.]; >>> print(""Sum of squares: "", tsa(a)); Sum of squares: 285.0; >>> print(); >>> a = np.array(range(10), dtype=np.int32); >>> print(""Integer array: "", a); Integer array: [0 1 2 3 4 5 6 7 8 9]; >>> print(""Sum of squares: "", tsa(a)); Sum of squares: 285. Instances of C++ classes can be passed into Numba traces.; They can be returned from functions called *within* the trace, but cannot yet; be returned *from* the trace.; Their public data is accessible (read-only) if of built-in type and their; public methods can be called, for which overload selection works.; Example:. .. code-block:: python. >>> import cppyy; >>> import numba; >>> import numpy as np; >>> ; >>> cppyy.cppdef(""""""\; ... class MyData {; ... public:; ... MyData(int i, int j) : fField1(i), fField2(j) {}; ...; ... public:; ... int get_field1() { return fField1; }; ... int get_field2() { return fField2; }; ...; ... MyData copy() { return *this; }; ...; ... public:; ... int fField1;; ... int fField2;; ... };""""""); True; >>> @numba.jit(nopython=True); >>> def tsdf(a, d):; ... total = type(a[0])(0); ... for i in range(len(a)):; ... total += a[i] + d.fField1 + d.fField2; ... return total; ...; >>> d = cppyy.gbl.MyData(5, 6); >>> a = np.array(range(10), dtype=np.int32); >>> print(tsdf(a, d)); 155; >>> # example of method calls; >>> @numba.jit(nopython=True); >>> def tsdm(a, d):; ... total = type(a[0])(0); ... for i in range(len(a)):; ... total += a[i] + d.get_field1() + d.get_field2(); ... return total; ...; >>> pri",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/numba.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst:10730,Security,access,accesses,10730," no appreciable difference in wall clock time to JIT a; trace using Numba's included math functions (from module ``math`` or; ``numpy``) or one that uses C++ bound ones whether from the standard library; or a templated versions from e.g. Eigen.; Use of very complex template expressions may change this balance, but in; principle, wherever it makes sense in the first place to use Numba JITing, it; is also fine, performance-wise, to use ``cppyy`` bound C++ inside the trace. A second important overhead is in unboxing Python proxies of C++ objects,; in particular when passed as an argument to a Numba-JITed function.; The main costs are in the lookup (types are matched at every invocation) and; to a lesser extent the subsequent copying of the instance data.; Thus, functions that take a C++ object as an argument will require more time; spent in the function body for JITing to be worth it than functions that do; not. The current implementation invokes C++ callables through function pointers; and accesses data through offsets calculations from the object's base; address.; A future implementation may be able to inline C++ into the Numba trace if; code is available in headers files or was JITed. Further Information; -------------------. - Numba documentation:; `numba.readthedocs.io <https://numba.readthedocs.io/en/stable/user/index.html>`_. - ""Using C++ From Numba, Fast and Automatic"", presented at `PyHEP 2022 <https://compiler-research.org/presentations/#CppyyNumbaPyHEP2022>`_. - `PyHEP 2022 video <https://www.youtube.com/watch?v=RceFPtB4m1I>`_; - `PyHEP 2022 slides <https://compiler-research.org/assets/presentations/B_Kundu-PyHEP22_Cppyy_Numba.pdf>`_; - `PyHEP 2022 notebook <https://github.com/sudo-panda/PyHEP-2022>`_. - Presentation at CERN's ROOT Parallelism, Performance and Programming Model; (`PPP <https://indico.cern.ch/event/1196174/>`_) Meeting. - `PPP slides <https://indico.cern.ch/event/1196174/contributions/5028203/attachments/2501253/4296778/PPP.pdf>`_; - `PPP not",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/numba.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst:195,Testability,test,tested,195,".. _numba:. Numba support; =============. .. caution::. This is an **experimental** feature, available starting with release; 2.4.0.; It is still incomplete (see listing below) and has only been tested on; Linux on x86_64. Numba `is a JIT compiler`_ for Python functions that can be statically typed; based on their input arguments.; Since C++ objects are always statically typed and already implemented at the; machine level, they can be dynamically integrated into the Numba type tracing; and lowering by exposing type details through C++ reflection at runtime. JIT-compiling traces of mixed Python/bound C++ code reduces, and in some; cases removes, the overhead of boxing/unboxing native data into their Python; proxies and vice versa.; It can also reduce or remove temporaries, especially for template; expressions.; Thus, there can be significant speedups for mixed code, beyond the Numba; compilation of Python code itself.; The current implementation integrates compiled C++ through function pointers,; object pointers, and pointer offsets, into the intermediate representation; (IR) as generated by Numba.; A future version may integrate Cling-generated IR directly into Numba IR (or; vice versa), e.g. if the C++ code is exposed from (precompiled) headers.; This would allow inlining of C++ code into Numba traces, for further; expected speedups. Why Numba?; ----------. The advertised premise of Numba is that it ""makes Python code fast.""; However, there is a much more compelling reason: Numba allows developers to; stay in their chosen ecosystem, be it Python or C++, in mixed environments,; without paying for their choice in lost performance.; For example, a Python developer using Numba does not need to rewrite a kernel; into C++ just to run performantly in a C++ framework.; Similarly, a C++ developer can use Numba to compile and create function; pointers to Python code for easy, performant, access.; This becomes even more compelling if the deployment target is a GPU, which; woul",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/numba.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst:3171,Testability,test,test,3171,"ntegration is clear.; (Numba does not currently provide support for C++.). Usage; -------. ``cppyy`` does not use Numba extension hooks to minimize accidental; dependencies.; Instead, it requires that the extensions are loaded explicitly by any code; that uses it::. import cppyy.numba_ext. After that, Numba is able to trace ``cppyy`` bound code when applying the; usual ``numba.njit`` decorator. Numba type declarations are done lazily, with the ``numba_ext`` module only; initially registering hooks on proxy base classes, to keep overheads in; Numba's type-resolution to a minimum.; On use in a JITed trace, each C++ type or function call is refined to the; actual, concrete types and type-specific overloads, with templates; instantiated as-needed.; Where possible, lowering is kept generic to reduce the number of callbacks; in Numba's compilation chain. Examples; --------. The following, non-exhaustive, set of examples gives an idea of the; current level of support.; More examples can be found in the `test suite`_. C++ free (global) functions can be called and overloads will be selected, or; a template will be instantiated, based on the provided types.; Exact type matches are fully supported, there is some support for typedefs; add implicit conversions for builtin types, there is no support for; conversions of custom types or default arguments. - **Basic usage**: To use ``cppyy`` in Numba JITed code, simply import; ``cppyy.numba_ext``, after which further use is transparent and the same; as when otherwise using ``cppyy`` in Python.; Example:. .. code-block:: python. >>> import numba; >>> import cppyy; >>> import cppyy.numba_ext # enables numba to work with cppyy; >>> import math; >>> @numba.jit(nopython=True); ... def cpp_sqrt(x):; ... return cppyy.gbl.sqrt(x) # direct use, no extra setup required; >>> print(""Sqrt of 4: "", cpp_sqrt(4.0)); Sqrt of 4: 2.0; >>> print(""Sqrt of Pi: "", cpp_sqrt(math.pi)); Sqrt of Pi: 1.7724538509055159. - **Overload selection**: C++ overloads ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/numba.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst:12259,Testability,test,test,12259,"The main costs are in the lookup (types are matched at every invocation) and; to a lesser extent the subsequent copying of the instance data.; Thus, functions that take a C++ object as an argument will require more time; spent in the function body for JITing to be worth it than functions that do; not. The current implementation invokes C++ callables through function pointers; and accesses data through offsets calculations from the object's base; address.; A future implementation may be able to inline C++ into the Numba trace if; code is available in headers files or was JITed. Further Information; -------------------. - Numba documentation:; `numba.readthedocs.io <https://numba.readthedocs.io/en/stable/user/index.html>`_. - ""Using C++ From Numba, Fast and Automatic"", presented at `PyHEP 2022 <https://compiler-research.org/presentations/#CppyyNumbaPyHEP2022>`_. - `PyHEP 2022 video <https://www.youtube.com/watch?v=RceFPtB4m1I>`_; - `PyHEP 2022 slides <https://compiler-research.org/assets/presentations/B_Kundu-PyHEP22_Cppyy_Numba.pdf>`_; - `PyHEP 2022 notebook <https://github.com/sudo-panda/PyHEP-2022>`_. - Presentation at CERN's ROOT Parallelism, Performance and Programming Model; (`PPP <https://indico.cern.ch/event/1196174/>`_) Meeting. - `PPP slides <https://indico.cern.ch/event/1196174/contributions/5028203/attachments/2501253/4296778/PPP.pdf>`_; - `PPP notebook <https://indico.cern.ch/event/1196174/contributions/5028203/attachments/2501253/4296735/PPP.ipynb>`_. Acknowledgements; ----------------. This work is supported in part by the `Compiler Research Organization`_; (Princeton University), with contributions from; `Vassil Vassilev <https://github.com/vgvassilev>`_,; `Baidyanath Kundu <https://github.com/sudo-panda>`_, and; `Aaron Jomy <https://github.com/maximusron>`_. .. _is a JIT compiler: https://numba.pydata.org/. .. _test suite: https://github.com/wlav/cppyy/blob/master/test/test_numba.py. .. _Compiler Research Organization: https://compiler-research.org/; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/numba.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst:2173,Usability,clear,clear,2173,"uture version may integrate Cling-generated IR directly into Numba IR (or; vice versa), e.g. if the C++ code is exposed from (precompiled) headers.; This would allow inlining of C++ code into Numba traces, for further; expected speedups. Why Numba?; ----------. The advertised premise of Numba is that it ""makes Python code fast.""; However, there is a much more compelling reason: Numba allows developers to; stay in their chosen ecosystem, be it Python or C++, in mixed environments,; without paying for their choice in lost performance.; For example, a Python developer using Numba does not need to rewrite a kernel; into C++ just to run performantly in a C++ framework.; Similarly, a C++ developer can use Numba to compile and create function; pointers to Python code for easy, performant, access.; This becomes even more compelling if the deployment target is a GPU, which; would otherwise certainly require a rewrite of the Python code.; Add that Numba, as a JIT-compiler, is fully run-time just like ``cppyy``,; and the use case for integration is clear.; (Numba does not currently provide support for C++.). Usage; -------. ``cppyy`` does not use Numba extension hooks to minimize accidental; dependencies.; Instead, it requires that the extensions are loaded explicitly by any code; that uses it::. import cppyy.numba_ext. After that, Numba is able to trace ``cppyy`` bound code when applying the; usual ``numba.njit`` decorator. Numba type declarations are done lazily, with the ``numba_ext`` module only; initially registering hooks on proxy base classes, to keep overheads in; Numba's type-resolution to a minimum.; On use in a JITed trace, each C++ type or function call is refined to the; actual, concrete types and type-specific overloads, with templates; instantiated as-needed.; Where possible, lowering is kept generic to reduce the number of callbacks; in Numba's compilation chain. Examples; --------. The following, non-exhaustive, set of examples gives an idea of the; current lev",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/numba.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst:3578,Usability,simpl,simply,3578,"ba type declarations are done lazily, with the ``numba_ext`` module only; initially registering hooks on proxy base classes, to keep overheads in; Numba's type-resolution to a minimum.; On use in a JITed trace, each C++ type or function call is refined to the; actual, concrete types and type-specific overloads, with templates; instantiated as-needed.; Where possible, lowering is kept generic to reduce the number of callbacks; in Numba's compilation chain. Examples; --------. The following, non-exhaustive, set of examples gives an idea of the; current level of support.; More examples can be found in the `test suite`_. C++ free (global) functions can be called and overloads will be selected, or; a template will be instantiated, based on the provided types.; Exact type matches are fully supported, there is some support for typedefs; add implicit conversions for builtin types, there is no support for; conversions of custom types or default arguments. - **Basic usage**: To use ``cppyy`` in Numba JITed code, simply import; ``cppyy.numba_ext``, after which further use is transparent and the same; as when otherwise using ``cppyy`` in Python.; Example:. .. code-block:: python. >>> import numba; >>> import cppyy; >>> import cppyy.numba_ext # enables numba to work with cppyy; >>> import math; >>> @numba.jit(nopython=True); ... def cpp_sqrt(x):; ... return cppyy.gbl.sqrt(x) # direct use, no extra setup required; >>> print(""Sqrt of 4: "", cpp_sqrt(4.0)); Sqrt of 4: 2.0; >>> print(""Sqrt of Pi: "", cpp_sqrt(math.pi)); Sqrt of Pi: 1.7724538509055159. - **Overload selection**: C++ overloads provide different implementations; for different argument types (not to be confused with Numba overloads,; which provide different implementations for the same argument types).; Unfortunately, mapping of Python types to C++ types is often not exact,; so a ""best match"" is chosen, similarly to what ``cppyy`` normally does.; However, the latter, being dynamic, is more flexible.; For example, best-match",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/numba.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/numba.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/packages.rst:1951,Availability,down,download,1951,"://www.sphinx-doc.org/en/stable/ and published to; http://cppyy.readthedocs.io/en/latest/index.html using a webhook. To create; the docs::. $ pip install sphinx_rtd_theme; Collecting sphinx_rtd_theme; ...; Successfully installed sphinx-rtd-theme-0.2.4; $ cd docs; $ make html. The Python code in this module supports:. * Interfacing to the correct backend for CPython or PyPy.; * Pythonizations (TBD). Cppyy-backend; -------------. The ``cppyy-backend`` module contains two areas:. * A patched copy of cling; * Wrapper code. Package structure; -----------------; .. _package-structure:. There are four PyPA packages involved in a full installation, with the; following structure::. (A) _cppyy (PyPy); / \; (1) cppyy (3) cppyy-backend -- (4) cppyy-cling; \ /; (2) CPyCppyy (CPython). The user-facing package is always ``cppyy`` (1).; It is used to select the other (versioned) required packages, based on the; python interpreter for which it is being installed. Below (1) follows a bifurcation based on interpreter.; This is needed for functionality and performance: for CPython, there is the; CPyCppyy package (2).; It is written in C++, makes use of the Python C-API, and installs as a Python; extension module.; For PyPy, there is the builtin module ``_cppyy`` (A).; This is not a PyPA package.; It is written in RPython as it needs access to low-level pointers, JIT hints,; and the ``_cffi_backend`` backend module (itself builtin). Shared again across interpreters is the backend, which is split in a small; wrapper (3) and a large package that contains Cling/LLVM (4).; The former is still under development and expected to be updated frequently.; It is small enough to download and build very quickly.; The latter, however, takes a long time to build, but since it is very stable,; splitting it off allows the creation of binary wheels that need updating; only infrequently (expected about twice a year). All code is publicly available; see the; :doc:`section on repositories <repositories>`.; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/packages.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/packages.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/packages.rst:2208,Availability,avail,available,2208,"://www.sphinx-doc.org/en/stable/ and published to; http://cppyy.readthedocs.io/en/latest/index.html using a webhook. To create; the docs::. $ pip install sphinx_rtd_theme; Collecting sphinx_rtd_theme; ...; Successfully installed sphinx-rtd-theme-0.2.4; $ cd docs; $ make html. The Python code in this module supports:. * Interfacing to the correct backend for CPython or PyPy.; * Pythonizations (TBD). Cppyy-backend; -------------. The ``cppyy-backend`` module contains two areas:. * A patched copy of cling; * Wrapper code. Package structure; -----------------; .. _package-structure:. There are four PyPA packages involved in a full installation, with the; following structure::. (A) _cppyy (PyPy); / \; (1) cppyy (3) cppyy-backend -- (4) cppyy-cling; \ /; (2) CPyCppyy (CPython). The user-facing package is always ``cppyy`` (1).; It is used to select the other (versioned) required packages, based on the; python interpreter for which it is being installed. Below (1) follows a bifurcation based on interpreter.; This is needed for functionality and performance: for CPython, there is the; CPyCppyy package (2).; It is written in C++, makes use of the Python C-API, and installs as a Python; extension module.; For PyPy, there is the builtin module ``_cppyy`` (A).; This is not a PyPA package.; It is written in RPython as it needs access to low-level pointers, JIT hints,; and the ``_cffi_backend`` backend module (itself builtin). Shared again across interpreters is the backend, which is split in a small; wrapper (3) and a large package that contains Cling/LLVM (4).; The former is still under development and expected to be updated frequently.; It is small enough to download and build very quickly.; The latter, however, takes a long time to build, but since it is very stable,; splitting it off allows the creation of binary wheels that need updating; only infrequently (expected about twice a year). All code is publicly available; see the; :doc:`section on repositories <repositories>`.; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/packages.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/packages.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/packages.rst:422,Deployability,install,install,422,".. _packages:. PyPI Packages; =============. Cppyy; -----. The ``cppyy`` module is a frontend (see :ref:`Package Structure; <package-structure>`), and most of the code is elsewhere. However, it does; contain the docs for all of the modules, which are built using; Sphinx: http://www.sphinx-doc.org/en/stable/ and published to; http://cppyy.readthedocs.io/en/latest/index.html using a webhook. To create; the docs::. $ pip install sphinx_rtd_theme; Collecting sphinx_rtd_theme; ...; Successfully installed sphinx-rtd-theme-0.2.4; $ cd docs; $ make html. The Python code in this module supports:. * Interfacing to the correct backend for CPython or PyPy.; * Pythonizations (TBD). Cppyy-backend; -------------. The ``cppyy-backend`` module contains two areas:. * A patched copy of cling; * Wrapper code. Package structure; -----------------; .. _package-structure:. There are four PyPA packages involved in a full installation, with the; following structure::. (A) _cppyy (PyPy); / \; (1) cppyy (3) cppyy-backend -- (4) cppyy-cling; \ /; (2) CPyCppyy (CPython). The user-facing package is always ``cppyy`` (1).; It is used to select the other (versioned) required packages, based on the; python interpreter for which it is being installed. Below (1) follows a bifurcation based on interpreter.; This is needed for functionality and performance: for CPython, there is the; CPyCppyy package (2).; It is written in C++, makes use of the Python C-API, and installs as a Python; extension module.; For PyPy, there is the builtin module ``_cppyy`` (A).; This is not a PyPA package.; It is written in RPython as it needs access to low-level pointers, JIT hints,; and the ``_cffi_backend`` backend module (itself builtin). Shared again across interpreters is the backend, which is split in a small; wrapper (3) and a large package that contains Cling/LLVM (4).; The former is still under development and expected to be updated frequently.; It is small enough to download and build very quickly.; The latter, howe",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/packages.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/packages.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/packages.rst:495,Deployability,install,installed,495,".. _packages:. PyPI Packages; =============. Cppyy; -----. The ``cppyy`` module is a frontend (see :ref:`Package Structure; <package-structure>`), and most of the code is elsewhere. However, it does; contain the docs for all of the modules, which are built using; Sphinx: http://www.sphinx-doc.org/en/stable/ and published to; http://cppyy.readthedocs.io/en/latest/index.html using a webhook. To create; the docs::. $ pip install sphinx_rtd_theme; Collecting sphinx_rtd_theme; ...; Successfully installed sphinx-rtd-theme-0.2.4; $ cd docs; $ make html. The Python code in this module supports:. * Interfacing to the correct backend for CPython or PyPy.; * Pythonizations (TBD). Cppyy-backend; -------------. The ``cppyy-backend`` module contains two areas:. * A patched copy of cling; * Wrapper code. Package structure; -----------------; .. _package-structure:. There are four PyPA packages involved in a full installation, with the; following structure::. (A) _cppyy (PyPy); / \; (1) cppyy (3) cppyy-backend -- (4) cppyy-cling; \ /; (2) CPyCppyy (CPython). The user-facing package is always ``cppyy`` (1).; It is used to select the other (versioned) required packages, based on the; python interpreter for which it is being installed. Below (1) follows a bifurcation based on interpreter.; This is needed for functionality and performance: for CPython, there is the; CPyCppyy package (2).; It is written in C++, makes use of the Python C-API, and installs as a Python; extension module.; For PyPy, there is the builtin module ``_cppyy`` (A).; This is not a PyPA package.; It is written in RPython as it needs access to low-level pointers, JIT hints,; and the ``_cffi_backend`` backend module (itself builtin). Shared again across interpreters is the backend, which is split in a small; wrapper (3) and a large package that contains Cling/LLVM (4).; The former is still under development and expected to be updated frequently.; It is small enough to download and build very quickly.; The latter, howe",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/packages.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/packages.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/packages.rst:762,Deployability,patch,patched,762,".. _packages:. PyPI Packages; =============. Cppyy; -----. The ``cppyy`` module is a frontend (see :ref:`Package Structure; <package-structure>`), and most of the code is elsewhere. However, it does; contain the docs for all of the modules, which are built using; Sphinx: http://www.sphinx-doc.org/en/stable/ and published to; http://cppyy.readthedocs.io/en/latest/index.html using a webhook. To create; the docs::. $ pip install sphinx_rtd_theme; Collecting sphinx_rtd_theme; ...; Successfully installed sphinx-rtd-theme-0.2.4; $ cd docs; $ make html. The Python code in this module supports:. * Interfacing to the correct backend for CPython or PyPy.; * Pythonizations (TBD). Cppyy-backend; -------------. The ``cppyy-backend`` module contains two areas:. * A patched copy of cling; * Wrapper code. Package structure; -----------------; .. _package-structure:. There are four PyPA packages involved in a full installation, with the; following structure::. (A) _cppyy (PyPy); / \; (1) cppyy (3) cppyy-backend -- (4) cppyy-cling; \ /; (2) CPyCppyy (CPython). The user-facing package is always ``cppyy`` (1).; It is used to select the other (versioned) required packages, based on the; python interpreter for which it is being installed. Below (1) follows a bifurcation based on interpreter.; This is needed for functionality and performance: for CPython, there is the; CPyCppyy package (2).; It is written in C++, makes use of the Python C-API, and installs as a Python; extension module.; For PyPy, there is the builtin module ``_cppyy`` (A).; This is not a PyPA package.; It is written in RPython as it needs access to low-level pointers, JIT hints,; and the ``_cffi_backend`` backend module (itself builtin). Shared again across interpreters is the backend, which is split in a small; wrapper (3) and a large package that contains Cling/LLVM (4).; The former is still under development and expected to be updated frequently.; It is small enough to download and build very quickly.; The latter, howe",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/packages.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/packages.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/packages.rst:911,Deployability,install,installation,911,".. _packages:. PyPI Packages; =============. Cppyy; -----. The ``cppyy`` module is a frontend (see :ref:`Package Structure; <package-structure>`), and most of the code is elsewhere. However, it does; contain the docs for all of the modules, which are built using; Sphinx: http://www.sphinx-doc.org/en/stable/ and published to; http://cppyy.readthedocs.io/en/latest/index.html using a webhook. To create; the docs::. $ pip install sphinx_rtd_theme; Collecting sphinx_rtd_theme; ...; Successfully installed sphinx-rtd-theme-0.2.4; $ cd docs; $ make html. The Python code in this module supports:. * Interfacing to the correct backend for CPython or PyPy.; * Pythonizations (TBD). Cppyy-backend; -------------. The ``cppyy-backend`` module contains two areas:. * A patched copy of cling; * Wrapper code. Package structure; -----------------; .. _package-structure:. There are four PyPA packages involved in a full installation, with the; following structure::. (A) _cppyy (PyPy); / \; (1) cppyy (3) cppyy-backend -- (4) cppyy-cling; \ /; (2) CPyCppyy (CPython). The user-facing package is always ``cppyy`` (1).; It is used to select the other (versioned) required packages, based on the; python interpreter for which it is being installed. Below (1) follows a bifurcation based on interpreter.; This is needed for functionality and performance: for CPython, there is the; CPyCppyy package (2).; It is written in C++, makes use of the Python C-API, and installs as a Python; extension module.; For PyPy, there is the builtin module ``_cppyy`` (A).; This is not a PyPA package.; It is written in RPython as it needs access to low-level pointers, JIT hints,; and the ``_cffi_backend`` backend module (itself builtin). Shared again across interpreters is the backend, which is split in a small; wrapper (3) and a large package that contains Cling/LLVM (4).; The former is still under development and expected to be updated frequently.; It is small enough to download and build very quickly.; The latter, howe",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/packages.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/packages.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/packages.rst:1226,Deployability,install,installed,1226,"elsewhere. However, it does; contain the docs for all of the modules, which are built using; Sphinx: http://www.sphinx-doc.org/en/stable/ and published to; http://cppyy.readthedocs.io/en/latest/index.html using a webhook. To create; the docs::. $ pip install sphinx_rtd_theme; Collecting sphinx_rtd_theme; ...; Successfully installed sphinx-rtd-theme-0.2.4; $ cd docs; $ make html. The Python code in this module supports:. * Interfacing to the correct backend for CPython or PyPy.; * Pythonizations (TBD). Cppyy-backend; -------------. The ``cppyy-backend`` module contains two areas:. * A patched copy of cling; * Wrapper code. Package structure; -----------------; .. _package-structure:. There are four PyPA packages involved in a full installation, with the; following structure::. (A) _cppyy (PyPy); / \; (1) cppyy (3) cppyy-backend -- (4) cppyy-cling; \ /; (2) CPyCppyy (CPython). The user-facing package is always ``cppyy`` (1).; It is used to select the other (versioned) required packages, based on the; python interpreter for which it is being installed. Below (1) follows a bifurcation based on interpreter.; This is needed for functionality and performance: for CPython, there is the; CPyCppyy package (2).; It is written in C++, makes use of the Python C-API, and installs as a Python; extension module.; For PyPy, there is the builtin module ``_cppyy`` (A).; This is not a PyPA package.; It is written in RPython as it needs access to low-level pointers, JIT hints,; and the ``_cffi_backend`` backend module (itself builtin). Shared again across interpreters is the backend, which is split in a small; wrapper (3) and a large package that contains Cling/LLVM (4).; The former is still under development and expected to be updated frequently.; It is small enough to download and build very quickly.; The latter, however, takes a long time to build, but since it is very stable,; splitting it off allows the creation of binary wheels that need updating; only infrequently (expected about ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/packages.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/packages.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/packages.rst:1449,Deployability,install,installs,1449,"://www.sphinx-doc.org/en/stable/ and published to; http://cppyy.readthedocs.io/en/latest/index.html using a webhook. To create; the docs::. $ pip install sphinx_rtd_theme; Collecting sphinx_rtd_theme; ...; Successfully installed sphinx-rtd-theme-0.2.4; $ cd docs; $ make html. The Python code in this module supports:. * Interfacing to the correct backend for CPython or PyPy.; * Pythonizations (TBD). Cppyy-backend; -------------. The ``cppyy-backend`` module contains two areas:. * A patched copy of cling; * Wrapper code. Package structure; -----------------; .. _package-structure:. There are four PyPA packages involved in a full installation, with the; following structure::. (A) _cppyy (PyPy); / \; (1) cppyy (3) cppyy-backend -- (4) cppyy-cling; \ /; (2) CPyCppyy (CPython). The user-facing package is always ``cppyy`` (1).; It is used to select the other (versioned) required packages, based on the; python interpreter for which it is being installed. Below (1) follows a bifurcation based on interpreter.; This is needed for functionality and performance: for CPython, there is the; CPyCppyy package (2).; It is written in C++, makes use of the Python C-API, and installs as a Python; extension module.; For PyPy, there is the builtin module ``_cppyy`` (A).; This is not a PyPA package.; It is written in RPython as it needs access to low-level pointers, JIT hints,; and the ``_cffi_backend`` backend module (itself builtin). Shared again across interpreters is the backend, which is split in a small; wrapper (3) and a large package that contains Cling/LLVM (4).; The former is still under development and expected to be updated frequently.; It is small enough to download and build very quickly.; The latter, however, takes a long time to build, but since it is very stable,; splitting it off allows the creation of binary wheels that need updating; only infrequently (expected about twice a year). All code is publicly available; see the; :doc:`section on repositories <repositories>`.; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/packages.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/packages.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/packages.rst:1908,Deployability,update,updated,1908,"://www.sphinx-doc.org/en/stable/ and published to; http://cppyy.readthedocs.io/en/latest/index.html using a webhook. To create; the docs::. $ pip install sphinx_rtd_theme; Collecting sphinx_rtd_theme; ...; Successfully installed sphinx-rtd-theme-0.2.4; $ cd docs; $ make html. The Python code in this module supports:. * Interfacing to the correct backend for CPython or PyPy.; * Pythonizations (TBD). Cppyy-backend; -------------. The ``cppyy-backend`` module contains two areas:. * A patched copy of cling; * Wrapper code. Package structure; -----------------; .. _package-structure:. There are four PyPA packages involved in a full installation, with the; following structure::. (A) _cppyy (PyPy); / \; (1) cppyy (3) cppyy-backend -- (4) cppyy-cling; \ /; (2) CPyCppyy (CPython). The user-facing package is always ``cppyy`` (1).; It is used to select the other (versioned) required packages, based on the; python interpreter for which it is being installed. Below (1) follows a bifurcation based on interpreter.; This is needed for functionality and performance: for CPython, there is the; CPyCppyy package (2).; It is written in C++, makes use of the Python C-API, and installs as a Python; extension module.; For PyPy, there is the builtin module ``_cppyy`` (A).; This is not a PyPA package.; It is written in RPython as it needs access to low-level pointers, JIT hints,; and the ``_cffi_backend`` backend module (itself builtin). Shared again across interpreters is the backend, which is split in a small; wrapper (3) and a large package that contains Cling/LLVM (4).; The former is still under development and expected to be updated frequently.; It is small enough to download and build very quickly.; The latter, however, takes a long time to build, but since it is very stable,; splitting it off allows the creation of binary wheels that need updating; only infrequently (expected about twice a year). All code is publicly available; see the; :doc:`section on repositories <repositories>`.; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/packages.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/packages.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/packages.rst:1788,Integrability,wrap,wrapper,1788,"://www.sphinx-doc.org/en/stable/ and published to; http://cppyy.readthedocs.io/en/latest/index.html using a webhook. To create; the docs::. $ pip install sphinx_rtd_theme; Collecting sphinx_rtd_theme; ...; Successfully installed sphinx-rtd-theme-0.2.4; $ cd docs; $ make html. The Python code in this module supports:. * Interfacing to the correct backend for CPython or PyPy.; * Pythonizations (TBD). Cppyy-backend; -------------. The ``cppyy-backend`` module contains two areas:. * A patched copy of cling; * Wrapper code. Package structure; -----------------; .. _package-structure:. There are four PyPA packages involved in a full installation, with the; following structure::. (A) _cppyy (PyPy); / \; (1) cppyy (3) cppyy-backend -- (4) cppyy-cling; \ /; (2) CPyCppyy (CPython). The user-facing package is always ``cppyy`` (1).; It is used to select the other (versioned) required packages, based on the; python interpreter for which it is being installed. Below (1) follows a bifurcation based on interpreter.; This is needed for functionality and performance: for CPython, there is the; CPyCppyy package (2).; It is written in C++, makes use of the Python C-API, and installs as a Python; extension module.; For PyPy, there is the builtin module ``_cppyy`` (A).; This is not a PyPA package.; It is written in RPython as it needs access to low-level pointers, JIT hints,; and the ``_cffi_backend`` backend module (itself builtin). Shared again across interpreters is the backend, which is split in a small; wrapper (3) and a large package that contains Cling/LLVM (4).; The former is still under development and expected to be updated frequently.; It is small enough to download and build very quickly.; The latter, however, takes a long time to build, but since it is very stable,; splitting it off allows the creation of binary wheels that need updating; only infrequently (expected about twice a year). All code is publicly available; see the; :doc:`section on repositories <repositories>`.; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/packages.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/packages.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/packages.rst:1329,Performance,perform,performance,1329,"://www.sphinx-doc.org/en/stable/ and published to; http://cppyy.readthedocs.io/en/latest/index.html using a webhook. To create; the docs::. $ pip install sphinx_rtd_theme; Collecting sphinx_rtd_theme; ...; Successfully installed sphinx-rtd-theme-0.2.4; $ cd docs; $ make html. The Python code in this module supports:. * Interfacing to the correct backend for CPython or PyPy.; * Pythonizations (TBD). Cppyy-backend; -------------. The ``cppyy-backend`` module contains two areas:. * A patched copy of cling; * Wrapper code. Package structure; -----------------; .. _package-structure:. There are four PyPA packages involved in a full installation, with the; following structure::. (A) _cppyy (PyPy); / \; (1) cppyy (3) cppyy-backend -- (4) cppyy-cling; \ /; (2) CPyCppyy (CPython). The user-facing package is always ``cppyy`` (1).; It is used to select the other (versioned) required packages, based on the; python interpreter for which it is being installed. Below (1) follows a bifurcation based on interpreter.; This is needed for functionality and performance: for CPython, there is the; CPyCppyy package (2).; It is written in C++, makes use of the Python C-API, and installs as a Python; extension module.; For PyPy, there is the builtin module ``_cppyy`` (A).; This is not a PyPA package.; It is written in RPython as it needs access to low-level pointers, JIT hints,; and the ``_cffi_backend`` backend module (itself builtin). Shared again across interpreters is the backend, which is split in a small; wrapper (3) and a large package that contains Cling/LLVM (4).; The former is still under development and expected to be updated frequently.; It is small enough to download and build very quickly.; The latter, however, takes a long time to build, but since it is very stable,; splitting it off allows the creation of binary wheels that need updating; only infrequently (expected about twice a year). All code is publicly available; see the; :doc:`section on repositories <repositories>`.; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/packages.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/packages.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/packages.rst:1611,Security,access,access,1611,"://www.sphinx-doc.org/en/stable/ and published to; http://cppyy.readthedocs.io/en/latest/index.html using a webhook. To create; the docs::. $ pip install sphinx_rtd_theme; Collecting sphinx_rtd_theme; ...; Successfully installed sphinx-rtd-theme-0.2.4; $ cd docs; $ make html. The Python code in this module supports:. * Interfacing to the correct backend for CPython or PyPy.; * Pythonizations (TBD). Cppyy-backend; -------------. The ``cppyy-backend`` module contains two areas:. * A patched copy of cling; * Wrapper code. Package structure; -----------------; .. _package-structure:. There are four PyPA packages involved in a full installation, with the; following structure::. (A) _cppyy (PyPy); / \; (1) cppyy (3) cppyy-backend -- (4) cppyy-cling; \ /; (2) CPyCppyy (CPython). The user-facing package is always ``cppyy`` (1).; It is used to select the other (versioned) required packages, based on the; python interpreter for which it is being installed. Below (1) follows a bifurcation based on interpreter.; This is needed for functionality and performance: for CPython, there is the; CPyCppyy package (2).; It is written in C++, makes use of the Python C-API, and installs as a Python; extension module.; For PyPy, there is the builtin module ``_cppyy`` (A).; This is not a PyPA package.; It is written in RPython as it needs access to low-level pointers, JIT hints,; and the ``_cffi_backend`` backend module (itself builtin). Shared again across interpreters is the backend, which is split in a small; wrapper (3) and a large package that contains Cling/LLVM (4).; The former is still under development and expected to be updated frequently.; It is small enough to download and build very quickly.; The latter, however, takes a long time to build, but since it is very stable,; splitting it off allows the creation of binary wheels that need updating; only infrequently (expected about twice a year). All code is publicly available; see the; :doc:`section on repositories <repositories>`.; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/packages.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/packages.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst:173,Availability,avail,available,173,".. _philosophy:. Philosophy; ==========. .. toctree::; :hidden:. As a Python-C++ language binder, cppyy has several unique features: it fills; gaps and covers use cases not available through other binders.; This document explains some of the design choices made and the thinking; behind the implementations of those features.; It's categorized as ""philosophy"" because a lot of it is open to; interpretation.; Its main purpose is simply to help you decide whether cppyy covers your use; cases and binding requirements, before committing any time to; :ref:`trying it out <starting>`. Run-time v.s. compile-time; --------------------------. What performs better, run-time or compile-time?; The obvious answer is compile-time: see the performance differences between; C++ and Python, for example.; Obvious, but completely wrong, however.; In fact, when it comes to Python, it is even the `wrong question.`. Everything in Python is run-time: modules, classes, functions, etc. are all; run-time constructs.; A Python module that defines a class is a set of instructions to the Python; interpreter that lead to the construction of the desired class object.; A C/C++ extension module that defines a class does the same thing by calling; a succession of Python interpreter Application Programming Interfaces (APIs;; the exact same that Python uses itself internally).; If you use a compile-time binder such as `SWIG`_ or `pybind11`_ to bind a C++; class, then what gets compiled is the series of API calls necessary to; construct a Python-side equivalent at `run-time` (when the module gets; loaded), not the Python class object.; In short, whether a binding is created at ""compile-time"" or at run-time has; no measurable bearing on performance. What does affect performance is the overhead to cross the language barrier.; This consists of unboxing Python objects to extract or convert the underlying; objects or data to something that matches what C++ expects; overload; resolution based on the unboxed argume",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst:6715,Availability,avail,available,6715,"g to Cling), all automatic parsers suffer from the problem that; the bindings produced have a strong ""C++ look-and-feel"" and that choices need; to be made in cases that can be bound in different, equally valid, ways.; As an example of the latter, consider the return of an ``std::vector``:; should this be automatically converted to a Python ``list``?; Doing so is more ""pythonic"", but incurs a significant overhead, and no; automatic choice will satisfy all cases: user input is needed. The typical way to solve these issues, is to provide an intermediate language; where corner cases can be brushed up, code can be made more Python friendly,; and design choices can be resolved.; Unfortunately, learning an intermediate language is quite an investment in; time and effort.; With cppyy, however, no such extra language is needed: using Cling, C++ code; can be embedded and JIT-ed for the same purpose.; In particular, cppyy can handle `boxed` Python objects and the full Python; C-API is available through Cling, allowing complete manual control where; necessary, and all within a single code base.; Similarly, a more pythonistic look-and-feel can be achieved in Python itself.; As a rule, Python is always the best place, far more so than any intermediate; language, to do Python-thingies.; Since all bound proxies are normal Python classes, functions, etc., Python's; introspection (and regular expressions engine) can be used to provide rule; based improvements in a way similar to the use of directives in an; intermediate language. On a practical note, it's often said that an automatic binder can provide; bindings to 95% of your code out-of-the-box, with only the remaining part; needing manual intervention.; This is broadly true, but realize that that 5% contains the most difficult; cases and is where 20-30% of the effort would have gone in case the bindings; were done fully manually.; It is therefore important to consider what manual tools an automatic binder; offers and to make sure t",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst:8068,Availability,down,download,8068,") can be used to provide rule; based improvements in a way similar to the use of directives in an; intermediate language. On a practical note, it's often said that an automatic binder can provide; bindings to 95% of your code out-of-the-box, with only the remaining part; needing manual intervention.; This is broadly true, but realize that that 5% contains the most difficult; cases and is where 20-30% of the effort would have gone in case the bindings; were done fully manually.; It is therefore important to consider what manual tools an automatic binder; offers and to make sure they fit your work style and needs, because you are; going to spend a significant amount of time with them. `LLVM dependency`; -----------------. cppyy depends on `LLVM`_, through Cling.; LLVM is properly internalized, so that it doesn't conflict with other uses;; and in particular it is fine to mix `Numba`_ and cppyy code.; It does mean a download cost of about 20MB for the binary wheel (exact size; differs per platform) on installation, and additional `primarily initial`; memory overheads at run-time.; Whether this is onerous depends strongly not only on the application, but; also on the rest of the software stack. The initial cost of loading cppyy, and thus starting the Cling interpreter,; is about 45MB (platform dependent).; Initial uses of standard (e.g. STL) C++ results in deserialization of the; precompiled header at another eventual total cost of about 25MB (again,; platform dependent).; The actual bindings of course also carry overheads.; As a rule of thumb, you should budget for ~100MB all-in for the overhead; caused by the bindings. Other binders do not have this initial memory overhead, but do of course; occur an overhead per module, class, function, etc.; At scale, however, cppyy has some advantages: all binding is lazy (including; the option of automatic loading), standard classes are never duplicated, and; there is no additional ""per-module"" overhead.; Thus, eventually (depending",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst:9680,Availability,avail,available,9680,"ings. Other binders do not have this initial memory overhead, but do of course; occur an overhead per module, class, function, etc.; At scale, however, cppyy has some advantages: all binding is lazy (including; the option of automatic loading), standard classes are never duplicated, and; there is no additional ""per-module"" overhead.; Thus, eventually (depending on the number of classes bound, across how many; modules, what use fraction, etc.), this initial cost is recouped when; compared to other binders.; As a rule of thumb, if about 10% of classes are used, it takes several; hundreds of bound classes before the cppyy-approach is beneficial.; In High Energy Physics, from which it originated, cppyy is regularly used in; software stacks of many thousands of classes, where this advantage is very; important. `Distributing headers`; ----------------------. cppyy requires C/C++ headers to be available at run-time, which was never a; problem in the developer-centric world from which it originated: software; always had supported C++ APIs already, made available through header files,; and Python simply piggy-backed onto those.; JIT-ing code in those headers, which potentially picked up system headers; that were configured differently, was thus also never a problem.; Or rather, the same problem exists for C++, and configuration for C++ to; resolve potential issues translates transparently to Python. There are only two alternatives: precompile headers into LLVM bitcode and; distribute those or provide a restricted set of headers.; Precompiled headers (and modules) were never designed to be portable and; relocatable, however, thus that may not be the panacea it seems.; A restricted set of headers is some work, but cppyy can operate on abstract; interface classes just fine (including Python-side cross-inheritance). `Large deployment`; ------------------. The single biggest headache in maintaining an installation of Python; extension modules is that Python patch releases can bre",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst:9841,Availability,avail,available,9841,"ings. Other binders do not have this initial memory overhead, but do of course; occur an overhead per module, class, function, etc.; At scale, however, cppyy has some advantages: all binding is lazy (including; the option of automatic loading), standard classes are never duplicated, and; there is no additional ""per-module"" overhead.; Thus, eventually (depending on the number of classes bound, across how many; modules, what use fraction, etc.), this initial cost is recouped when; compared to other binders.; As a rule of thumb, if about 10% of classes are used, it takes several; hundreds of bound classes before the cppyy-approach is beneficial.; In High Energy Physics, from which it originated, cppyy is regularly used in; software stacks of many thousands of classes, where this advantage is very; important. `Distributing headers`; ----------------------. cppyy requires C/C++ headers to be available at run-time, which was never a; problem in the developer-centric world from which it originated: software; always had supported C++ APIs already, made available through header files,; and Python simply piggy-backed onto those.; JIT-ing code in those headers, which potentially picked up system headers; that were configured differently, was thus also never a problem.; Or rather, the same problem exists for C++, and configuration for C++ to; resolve potential issues translates transparently to Python. There are only two alternatives: precompile headers into LLVM bitcode and; distribute those or provide a restricted set of headers.; Precompiled headers (and modules) were never designed to be portable and; relocatable, however, thus that may not be the panacea it seems.; A restricted set of headers is some work, but cppyy can operate on abstract; interface classes just fine (including Python-side cross-inheritance). `Large deployment`; ------------------. The single biggest headache in maintaining an installation of Python; extension modules is that Python patch releases can bre",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst:8155,Deployability,install,installation,8155,") can be used to provide rule; based improvements in a way similar to the use of directives in an; intermediate language. On a practical note, it's often said that an automatic binder can provide; bindings to 95% of your code out-of-the-box, with only the remaining part; needing manual intervention.; This is broadly true, but realize that that 5% contains the most difficult; cases and is where 20-30% of the effort would have gone in case the bindings; were done fully manually.; It is therefore important to consider what manual tools an automatic binder; offers and to make sure they fit your work style and needs, because you are; going to spend a significant amount of time with them. `LLVM dependency`; -----------------. cppyy depends on `LLVM`_, through Cling.; LLVM is properly internalized, so that it doesn't conflict with other uses;; and in particular it is fine to mix `Numba`_ and cppyy code.; It does mean a download cost of about 20MB for the binary wheel (exact size; differs per platform) on installation, and additional `primarily initial`; memory overheads at run-time.; Whether this is onerous depends strongly not only on the application, but; also on the rest of the software stack. The initial cost of loading cppyy, and thus starting the Cling interpreter,; is about 45MB (platform dependent).; Initial uses of standard (e.g. STL) C++ results in deserialization of the; precompiled header at another eventual total cost of about 25MB (again,; platform dependent).; The actual bindings of course also carry overheads.; As a rule of thumb, you should budget for ~100MB all-in for the overhead; caused by the bindings. Other binders do not have this initial memory overhead, but do of course; occur an overhead per module, class, function, etc.; At scale, however, cppyy has some advantages: all binding is lazy (including; the option of automatic loading), standard classes are never duplicated, and; there is no additional ""per-module"" overhead.; Thus, eventually (depending",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst:10107,Deployability,configurat,configuration,10107,"ntually (depending on the number of classes bound, across how many; modules, what use fraction, etc.), this initial cost is recouped when; compared to other binders.; As a rule of thumb, if about 10% of classes are used, it takes several; hundreds of bound classes before the cppyy-approach is beneficial.; In High Energy Physics, from which it originated, cppyy is regularly used in; software stacks of many thousands of classes, where this advantage is very; important. `Distributing headers`; ----------------------. cppyy requires C/C++ headers to be available at run-time, which was never a; problem in the developer-centric world from which it originated: software; always had supported C++ APIs already, made available through header files,; and Python simply piggy-backed onto those.; JIT-ing code in those headers, which potentially picked up system headers; that were configured differently, was thus also never a problem.; Or rather, the same problem exists for C++, and configuration for C++ to; resolve potential issues translates transparently to Python. There are only two alternatives: precompile headers into LLVM bitcode and; distribute those or provide a restricted set of headers.; Precompiled headers (and modules) were never designed to be portable and; relocatable, however, thus that may not be the panacea it seems.; A restricted set of headers is some work, but cppyy can operate on abstract; interface classes just fine (including Python-side cross-inheritance). `Large deployment`; ------------------. The single biggest headache in maintaining an installation of Python; extension modules is that Python patch releases can break them.; The two typical solutions are to either restrict the choice of Python; interpreter and version that are supported (common in HPC) or to provide; binaries (wheels) for a large range of different interpreters and versions; (as e.g. done for conda). In the case of cppyy, only CPython/CPyCppyy and PyPy/_cppyy (an internal; module) depend",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst:10622,Deployability,deploy,deployment,10622,"---------. cppyy requires C/C++ headers to be available at run-time, which was never a; problem in the developer-centric world from which it originated: software; always had supported C++ APIs already, made available through header files,; and Python simply piggy-backed onto those.; JIT-ing code in those headers, which potentially picked up system headers; that were configured differently, was thus also never a problem.; Or rather, the same problem exists for C++, and configuration for C++ to; resolve potential issues translates transparently to Python. There are only two alternatives: precompile headers into LLVM bitcode and; distribute those or provide a restricted set of headers.; Precompiled headers (and modules) were never designed to be portable and; relocatable, however, thus that may not be the panacea it seems.; A restricted set of headers is some work, but cppyy can operate on abstract; interface classes just fine (including Python-side cross-inheritance). `Large deployment`; ------------------. The single biggest headache in maintaining an installation of Python; extension modules is that Python patch releases can break them.; The two typical solutions are to either restrict the choice of Python; interpreter and version that are supported (common in HPC) or to provide; binaries (wheels) for a large range of different interpreters and versions; (as e.g. done for conda). In the case of cppyy, only CPython/CPyCppyy and PyPy/_cppyy (an internal; module) depend on the Python interpreter (see:; :ref:`Package Structure <package-structure>`).; The user-facing ``cppyy`` module is pure Python and the backend (Cling) is; Python-independent.; Most importantly, since all bindings are generated at run-time, there are no; extension modules to regenerate and/or recompile. Thus, the end-user only needs to rebuild/reinstall CPyCppyy for each relevant; version of Python (and nothing extra is needed for PyPy) to switch Python; versions and/or interpreter.; The rest of the so",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst:10701,Deployability,install,installation,10701," problem in the developer-centric world from which it originated: software; always had supported C++ APIs already, made available through header files,; and Python simply piggy-backed onto those.; JIT-ing code in those headers, which potentially picked up system headers; that were configured differently, was thus also never a problem.; Or rather, the same problem exists for C++, and configuration for C++ to; resolve potential issues translates transparently to Python. There are only two alternatives: precompile headers into LLVM bitcode and; distribute those or provide a restricted set of headers.; Precompiled headers (and modules) were never designed to be portable and; relocatable, however, thus that may not be the panacea it seems.; A restricted set of headers is some work, but cppyy can operate on abstract; interface classes just fine (including Python-side cross-inheritance). `Large deployment`; ------------------. The single biggest headache in maintaining an installation of Python; extension modules is that Python patch releases can break them.; The two typical solutions are to either restrict the choice of Python; interpreter and version that are supported (common in HPC) or to provide; binaries (wheels) for a large range of different interpreters and versions; (as e.g. done for conda). In the case of cppyy, only CPython/CPyCppyy and PyPy/_cppyy (an internal; module) depend on the Python interpreter (see:; :ref:`Package Structure <package-structure>`).; The user-facing ``cppyy`` module is pure Python and the backend (Cling) is; Python-independent.; Most importantly, since all bindings are generated at run-time, there are no; extension modules to regenerate and/or recompile. Thus, the end-user only needs to rebuild/reinstall CPyCppyy for each relevant; version of Python (and nothing extra is needed for PyPy) to switch Python; versions and/or interpreter.; The rest of the software stack remains completely unchanged.; Only if Cling in cppyy's backend is updated",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst:10758,Deployability,patch,patch,10758," problem in the developer-centric world from which it originated: software; always had supported C++ APIs already, made available through header files,; and Python simply piggy-backed onto those.; JIT-ing code in those headers, which potentially picked up system headers; that were configured differently, was thus also never a problem.; Or rather, the same problem exists for C++, and configuration for C++ to; resolve potential issues translates transparently to Python. There are only two alternatives: precompile headers into LLVM bitcode and; distribute those or provide a restricted set of headers.; Precompiled headers (and modules) were never designed to be portable and; relocatable, however, thus that may not be the panacea it seems.; A restricted set of headers is some work, but cppyy can operate on abstract; interface classes just fine (including Python-side cross-inheritance). `Large deployment`; ------------------. The single biggest headache in maintaining an installation of Python; extension modules is that Python patch releases can break them.; The two typical solutions are to either restrict the choice of Python; interpreter and version that are supported (common in HPC) or to provide; binaries (wheels) for a large range of different interpreters and versions; (as e.g. done for conda). In the case of cppyy, only CPython/CPyCppyy and PyPy/_cppyy (an internal; module) depend on the Python interpreter (see:; :ref:`Package Structure <package-structure>`).; The user-facing ``cppyy`` module is pure Python and the backend (Cling) is; Python-independent.; Most importantly, since all bindings are generated at run-time, there are no; extension modules to regenerate and/or recompile. Thus, the end-user only needs to rebuild/reinstall CPyCppyy for each relevant; version of Python (and nothing extra is needed for PyPy) to switch Python; versions and/or interpreter.; The rest of the software stack remains completely unchanged.; Only if Cling in cppyy's backend is updated",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst:10764,Deployability,release,releases,10764," problem in the developer-centric world from which it originated: software; always had supported C++ APIs already, made available through header files,; and Python simply piggy-backed onto those.; JIT-ing code in those headers, which potentially picked up system headers; that were configured differently, was thus also never a problem.; Or rather, the same problem exists for C++, and configuration for C++ to; resolve potential issues translates transparently to Python. There are only two alternatives: precompile headers into LLVM bitcode and; distribute those or provide a restricted set of headers.; Precompiled headers (and modules) were never designed to be portable and; relocatable, however, thus that may not be the panacea it seems.; A restricted set of headers is some work, but cppyy can operate on abstract; interface classes just fine (including Python-side cross-inheritance). `Large deployment`; ------------------. The single biggest headache in maintaining an installation of Python; extension modules is that Python patch releases can break them.; The two typical solutions are to either restrict the choice of Python; interpreter and version that are supported (common in HPC) or to provide; binaries (wheels) for a large range of different interpreters and versions; (as e.g. done for conda). In the case of cppyy, only CPython/CPyCppyy and PyPy/_cppyy (an internal; module) depend on the Python interpreter (see:; :ref:`Package Structure <package-structure>`).; The user-facing ``cppyy`` module is pure Python and the backend (Cling) is; Python-independent.; Most importantly, since all bindings are generated at run-time, there are no; extension modules to regenerate and/or recompile. Thus, the end-user only needs to rebuild/reinstall CPyCppyy for each relevant; version of Python (and nothing extra is needed for PyPy) to switch Python; versions and/or interpreter.; The rest of the software stack remains completely unchanged.; Only if Cling in cppyy's backend is updated",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst:11714,Deployability,update,updated,11714,"ts for C++, and configuration for C++ to; resolve potential issues translates transparently to Python. There are only two alternatives: precompile headers into LLVM bitcode and; distribute those or provide a restricted set of headers.; Precompiled headers (and modules) were never designed to be portable and; relocatable, however, thus that may not be the panacea it seems.; A restricted set of headers is some work, but cppyy can operate on abstract; interface classes just fine (including Python-side cross-inheritance). `Large deployment`; ------------------. The single biggest headache in maintaining an installation of Python; extension modules is that Python patch releases can break them.; The two typical solutions are to either restrict the choice of Python; interpreter and version that are supported (common in HPC) or to provide; binaries (wheels) for a large range of different interpreters and versions; (as e.g. done for conda). In the case of cppyy, only CPython/CPyCppyy and PyPy/_cppyy (an internal; module) depend on the Python interpreter (see:; :ref:`Package Structure <package-structure>`).; The user-facing ``cppyy`` module is pure Python and the backend (Cling) is; Python-independent.; Most importantly, since all bindings are generated at run-time, there are no; extension modules to regenerate and/or recompile. Thus, the end-user only needs to rebuild/reinstall CPyCppyy for each relevant; version of Python (and nothing extra is needed for PyPy) to switch Python; versions and/or interpreter.; The rest of the software stack remains completely unchanged.; Only if Cling in cppyy's backend is updated, which happens infrequently, and; non-standard precompiled headers or modules are used, do these need to be; rebuild in full. .. _`SWIG`: http://swig.org/; .. _`pybind11`: https://pybind11.readthedocs.io/en/stable/; .. _`PyPy`: https://www.pypy.org/; .. _`CINT`: https://en.wikipedia.org/wiki/CINT; .. _`LLVM`: https://llvm.org/; .. _`Numba`: http://numba.pydata.org/; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst:3024,Integrability,depend,depend,3024,"and finally; the actual dispatch.; As a practical matter, overload resolution is the most costly part, followed; by the unboxing and conversion.; Best performance is achieved by specialization of the paths through the; run-time: recognize early the case at hand and select an optimized path.; For that reason, `PyPy`_ is so fast: JIT-ed traces operate on unboxed objects; and resolved overloads are baked into the trace, incurring no further cost.; Similarly, this is why pybind11 is so slow: its code generation is the C++; compiler's template engine, so complex path selection and specialization is; very hard to do in a performance-portable way. In cppyy, a great deal of attention has gone into built-in specialization; paths, which drives its performance.; For example, basic inheritance sequentially lines up classes, whereas; multiple (virtual) inheritance usually requires thunks.; Thus, when calling base class methods on a derived instance, the latter; requires offset calculations that depend on that instance, whereas the former; has fixed offsets fully determined by the class definitions themselves.; By labeling classes appropriately, single inheritance classes (by far the; most common case) do not incur the overhead in PyPy's JIT-ed traces that is; otherwise unavoidable for multiple virtual inheritance.; As another example, consider that the C++ standard does not allow modifying; a ``std::vector`` while looping over it, whereas Python has no such; restriction, complicating loops.; Thus, cppyy has specialized ``std::vector`` iteration for both PyPy and; CPython, easily outperforming looping over an equivalent numpy array. In CPython, the performance of `non-overloaded` function calls depends; greatly on the Python interpreter's internal specializations; and Python3; has many specializations specific to basic extension modules (C function; pointer calls), gaining a performance boost of more than 30% over Python2.; Only since Python3.8 is there also better support for clo",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst:3737,Integrability,depend,depends,3737,"equentially lines up classes, whereas; multiple (virtual) inheritance usually requires thunks.; Thus, when calling base class methods on a derived instance, the latter; requires offset calculations that depend on that instance, whereas the former; has fixed offsets fully determined by the class definitions themselves.; By labeling classes appropriately, single inheritance classes (by far the; most common case) do not incur the overhead in PyPy's JIT-ed traces that is; otherwise unavoidable for multiple virtual inheritance.; As another example, consider that the C++ standard does not allow modifying; a ``std::vector`` while looping over it, whereas Python has no such; restriction, complicating loops.; Thus, cppyy has specialized ``std::vector`` iteration for both PyPy and; CPython, easily outperforming looping over an equivalent numpy array. In CPython, the performance of `non-overloaded` function calls depends; greatly on the Python interpreter's internal specializations; and Python3; has many specializations specific to basic extension modules (C function; pointer calls), gaining a performance boost of more than 30% over Python2.; Only since Python3.8 is there also better support for closure objects (vector; calls) as cppyy uses, to short-cut through the interpreter's own overhead. As a practical consideration, whether a binder performs well on code that you; care about, depends `entirely` on whether it has the relevant specializations; for your most performance-sensitive use cases.; The only way to know for sure is to write a test application and measure, but; a binder that provides more specializations, or makes it easy to add your; own, is more likely to deliver. `Manual v.s. automatic`; -----------------------. Python is, today, one of the most popular programming languages and has a; rich and mature eco-system around it.; But when the project that became cppyy started in the field of High Energy; Physics (HEP), Python usage was non-existent there.; As a Python",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst:4216,Integrability,depend,depends,4216,"on case) do not incur the overhead in PyPy's JIT-ed traces that is; otherwise unavoidable for multiple virtual inheritance.; As another example, consider that the C++ standard does not allow modifying; a ``std::vector`` while looping over it, whereas Python has no such; restriction, complicating loops.; Thus, cppyy has specialized ``std::vector`` iteration for both PyPy and; CPython, easily outperforming looping over an equivalent numpy array. In CPython, the performance of `non-overloaded` function calls depends; greatly on the Python interpreter's internal specializations; and Python3; has many specializations specific to basic extension modules (C function; pointer calls), gaining a performance boost of more than 30% over Python2.; Only since Python3.8 is there also better support for closure objects (vector; calls) as cppyy uses, to short-cut through the interpreter's own overhead. As a practical consideration, whether a binder performs well on code that you; care about, depends `entirely` on whether it has the relevant specializations; for your most performance-sensitive use cases.; The only way to know for sure is to write a test application and measure, but; a binder that provides more specializations, or makes it easy to add your; own, is more likely to deliver. `Manual v.s. automatic`; -----------------------. Python is, today, one of the most popular programming languages and has a; rich and mature eco-system around it.; But when the project that became cppyy started in the field of High Energy; Physics (HEP), Python usage was non-existent there.; As a Python user to work in this predominantly C++ environment, you had to; bring your own bindings, thus automatic was the only way to go.; Binders such as SWIG, SIP (or even boost.python with Pyste) all had the fatal; assumption that you were providing Python bindings to your `own` C++ code,; and that you were thus able to modify those (many) areas of the C++ codes; that their parsers could not handle.; The `CIN",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst:7840,Integrability,depend,dependency,7840,"stic look-and-feel can be achieved in Python itself.; As a rule, Python is always the best place, far more so than any intermediate; language, to do Python-thingies.; Since all bound proxies are normal Python classes, functions, etc., Python's; introspection (and regular expressions engine) can be used to provide rule; based improvements in a way similar to the use of directives in an; intermediate language. On a practical note, it's often said that an automatic binder can provide; bindings to 95% of your code out-of-the-box, with only the remaining part; needing manual intervention.; This is broadly true, but realize that that 5% contains the most difficult; cases and is where 20-30% of the effort would have gone in case the bindings; were done fully manually.; It is therefore important to consider what manual tools an automatic binder; offers and to make sure they fit your work style and needs, because you are; going to spend a significant amount of time with them. `LLVM dependency`; -----------------. cppyy depends on `LLVM`_, through Cling.; LLVM is properly internalized, so that it doesn't conflict with other uses;; and in particular it is fine to mix `Numba`_ and cppyy code.; It does mean a download cost of about 20MB for the binary wheel (exact size; differs per platform) on installation, and additional `primarily initial`; memory overheads at run-time.; Whether this is onerous depends strongly not only on the application, but; also on the rest of the software stack. The initial cost of loading cppyy, and thus starting the Cling interpreter,; is about 45MB (platform dependent).; Initial uses of standard (e.g. STL) C++ results in deserialization of the; precompiled header at another eventual total cost of about 25MB (again,; platform dependent).; The actual bindings of course also carry overheads.; As a rule of thumb, you should budget for ~100MB all-in for the overhead; caused by the bindings. Other binders do not have this initial memory overhead, but do of ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst:7878,Integrability,depend,depends,7878,"ython itself.; As a rule, Python is always the best place, far more so than any intermediate; language, to do Python-thingies.; Since all bound proxies are normal Python classes, functions, etc., Python's; introspection (and regular expressions engine) can be used to provide rule; based improvements in a way similar to the use of directives in an; intermediate language. On a practical note, it's often said that an automatic binder can provide; bindings to 95% of your code out-of-the-box, with only the remaining part; needing manual intervention.; This is broadly true, but realize that that 5% contains the most difficult; cases and is where 20-30% of the effort would have gone in case the bindings; were done fully manually.; It is therefore important to consider what manual tools an automatic binder; offers and to make sure they fit your work style and needs, because you are; going to spend a significant amount of time with them. `LLVM dependency`; -----------------. cppyy depends on `LLVM`_, through Cling.; LLVM is properly internalized, so that it doesn't conflict with other uses;; and in particular it is fine to mix `Numba`_ and cppyy code.; It does mean a download cost of about 20MB for the binary wheel (exact size; differs per platform) on installation, and additional `primarily initial`; memory overheads at run-time.; Whether this is onerous depends strongly not only on the application, but; also on the rest of the software stack. The initial cost of loading cppyy, and thus starting the Cling interpreter,; is about 45MB (platform dependent).; Initial uses of standard (e.g. STL) C++ results in deserialization of the; precompiled header at another eventual total cost of about 25MB (again,; platform dependent).; The actual bindings of course also carry overheads.; As a rule of thumb, you should budget for ~100MB all-in for the overhead; caused by the bindings. Other binders do not have this initial memory overhead, but do of course; occur an overhead per module, cl",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst:8260,Integrability,depend,depends,8260,"ten said that an automatic binder can provide; bindings to 95% of your code out-of-the-box, with only the remaining part; needing manual intervention.; This is broadly true, but realize that that 5% contains the most difficult; cases and is where 20-30% of the effort would have gone in case the bindings; were done fully manually.; It is therefore important to consider what manual tools an automatic binder; offers and to make sure they fit your work style and needs, because you are; going to spend a significant amount of time with them. `LLVM dependency`; -----------------. cppyy depends on `LLVM`_, through Cling.; LLVM is properly internalized, so that it doesn't conflict with other uses;; and in particular it is fine to mix `Numba`_ and cppyy code.; It does mean a download cost of about 20MB for the binary wheel (exact size; differs per platform) on installation, and additional `primarily initial`; memory overheads at run-time.; Whether this is onerous depends strongly not only on the application, but; also on the rest of the software stack. The initial cost of loading cppyy, and thus starting the Cling interpreter,; is about 45MB (platform dependent).; Initial uses of standard (e.g. STL) C++ results in deserialization of the; precompiled header at another eventual total cost of about 25MB (again,; platform dependent).; The actual bindings of course also carry overheads.; As a rule of thumb, you should budget for ~100MB all-in for the overhead; caused by the bindings. Other binders do not have this initial memory overhead, but do of course; occur an overhead per module, class, function, etc.; At scale, however, cppyy has some advantages: all binding is lazy (including; the option of automatic loading), standard classes are never duplicated, and; there is no additional ""per-module"" overhead.; Thus, eventually (depending on the number of classes bound, across how many; modules, what use fraction, etc.), this initial cost is recouped when; compared to other binders.; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst:8452,Integrability,depend,dependent,8452,"g part; needing manual intervention.; This is broadly true, but realize that that 5% contains the most difficult; cases and is where 20-30% of the effort would have gone in case the bindings; were done fully manually.; It is therefore important to consider what manual tools an automatic binder; offers and to make sure they fit your work style and needs, because you are; going to spend a significant amount of time with them. `LLVM dependency`; -----------------. cppyy depends on `LLVM`_, through Cling.; LLVM is properly internalized, so that it doesn't conflict with other uses;; and in particular it is fine to mix `Numba`_ and cppyy code.; It does mean a download cost of about 20MB for the binary wheel (exact size; differs per platform) on installation, and additional `primarily initial`; memory overheads at run-time.; Whether this is onerous depends strongly not only on the application, but; also on the rest of the software stack. The initial cost of loading cppyy, and thus starting the Cling interpreter,; is about 45MB (platform dependent).; Initial uses of standard (e.g. STL) C++ results in deserialization of the; precompiled header at another eventual total cost of about 25MB (again,; platform dependent).; The actual bindings of course also carry overheads.; As a rule of thumb, you should budget for ~100MB all-in for the overhead; caused by the bindings. Other binders do not have this initial memory overhead, but do of course; occur an overhead per module, class, function, etc.; At scale, however, cppyy has some advantages: all binding is lazy (including; the option of automatic loading), standard classes are never duplicated, and; there is no additional ""per-module"" overhead.; Thus, eventually (depending on the number of classes bound, across how many; modules, what use fraction, etc.), this initial cost is recouped when; compared to other binders.; As a rule of thumb, if about 10% of classes are used, it takes several; hundreds of bound classes before the cppyy-",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst:8622,Integrability,depend,dependent,8622,"d have gone in case the bindings; were done fully manually.; It is therefore important to consider what manual tools an automatic binder; offers and to make sure they fit your work style and needs, because you are; going to spend a significant amount of time with them. `LLVM dependency`; -----------------. cppyy depends on `LLVM`_, through Cling.; LLVM is properly internalized, so that it doesn't conflict with other uses;; and in particular it is fine to mix `Numba`_ and cppyy code.; It does mean a download cost of about 20MB for the binary wheel (exact size; differs per platform) on installation, and additional `primarily initial`; memory overheads at run-time.; Whether this is onerous depends strongly not only on the application, but; also on the rest of the software stack. The initial cost of loading cppyy, and thus starting the Cling interpreter,; is about 45MB (platform dependent).; Initial uses of standard (e.g. STL) C++ results in deserialization of the; precompiled header at another eventual total cost of about 25MB (again,; platform dependent).; The actual bindings of course also carry overheads.; As a rule of thumb, you should budget for ~100MB all-in for the overhead; caused by the bindings. Other binders do not have this initial memory overhead, but do of course; occur an overhead per module, class, function, etc.; At scale, however, cppyy has some advantages: all binding is lazy (including; the option of automatic loading), standard classes are never duplicated, and; there is no additional ""per-module"" overhead.; Thus, eventually (depending on the number of classes bound, across how many; modules, what use fraction, etc.), this initial cost is recouped when; compared to other binders.; As a rule of thumb, if about 10% of classes are used, it takes several; hundreds of bound classes before the cppyy-approach is beneficial.; In High Energy Physics, from which it originated, cppyy is regularly used in; software stacks of many thousands of classes, where th",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst:9134,Integrability,depend,depending,9134,"and additional `primarily initial`; memory overheads at run-time.; Whether this is onerous depends strongly not only on the application, but; also on the rest of the software stack. The initial cost of loading cppyy, and thus starting the Cling interpreter,; is about 45MB (platform dependent).; Initial uses of standard (e.g. STL) C++ results in deserialization of the; precompiled header at another eventual total cost of about 25MB (again,; platform dependent).; The actual bindings of course also carry overheads.; As a rule of thumb, you should budget for ~100MB all-in for the overhead; caused by the bindings. Other binders do not have this initial memory overhead, but do of course; occur an overhead per module, class, function, etc.; At scale, however, cppyy has some advantages: all binding is lazy (including; the option of automatic loading), standard classes are never duplicated, and; there is no additional ""per-module"" overhead.; Thus, eventually (depending on the number of classes bound, across how many; modules, what use fraction, etc.), this initial cost is recouped when; compared to other binders.; As a rule of thumb, if about 10% of classes are used, it takes several; hundreds of bound classes before the cppyy-approach is beneficial.; In High Energy Physics, from which it originated, cppyy is regularly used in; software stacks of many thousands of classes, where this advantage is very; important. `Distributing headers`; ----------------------. cppyy requires C/C++ headers to be available at run-time, which was never a; problem in the developer-centric world from which it originated: software; always had supported C++ APIs already, made available through header files,; and Python simply piggy-backed onto those.; JIT-ing code in those headers, which potentially picked up system headers; that were configured differently, was thus also never a problem.; Or rather, the same problem exists for C++, and configuration for C++ to; resolve potential issues translates t",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst:10544,Integrability,interface,interface,10544,"ands of classes, where this advantage is very; important. `Distributing headers`; ----------------------. cppyy requires C/C++ headers to be available at run-time, which was never a; problem in the developer-centric world from which it originated: software; always had supported C++ APIs already, made available through header files,; and Python simply piggy-backed onto those.; JIT-ing code in those headers, which potentially picked up system headers; that were configured differently, was thus also never a problem.; Or rather, the same problem exists for C++, and configuration for C++ to; resolve potential issues translates transparently to Python. There are only two alternatives: precompile headers into LLVM bitcode and; distribute those or provide a restricted set of headers.; Precompiled headers (and modules) were never designed to be portable and; relocatable, however, thus that may not be the panacea it seems.; A restricted set of headers is some work, but cppyy can operate on abstract; interface classes just fine (including Python-side cross-inheritance). `Large deployment`; ------------------. The single biggest headache in maintaining an installation of Python; extension modules is that Python patch releases can break them.; The two typical solutions are to either restrict the choice of Python; interpreter and version that are supported (common in HPC) or to provide; binaries (wheels) for a large range of different interpreters and versions; (as e.g. done for conda). In the case of cppyy, only CPython/CPyCppyy and PyPy/_cppyy (an internal; module) depend on the Python interpreter (see:; :ref:`Package Structure <package-structure>`).; The user-facing ``cppyy`` module is pure Python and the backend (Cling) is; Python-independent.; Most importantly, since all bindings are generated at run-time, there are no; extension modules to regenerate and/or recompile. Thus, the end-user only needs to rebuild/reinstall CPyCppyy for each relevant; version of Python (and nothin",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst:11119,Integrability,depend,depend,11119,"ts for C++, and configuration for C++ to; resolve potential issues translates transparently to Python. There are only two alternatives: precompile headers into LLVM bitcode and; distribute those or provide a restricted set of headers.; Precompiled headers (and modules) were never designed to be portable and; relocatable, however, thus that may not be the panacea it seems.; A restricted set of headers is some work, but cppyy can operate on abstract; interface classes just fine (including Python-side cross-inheritance). `Large deployment`; ------------------. The single biggest headache in maintaining an installation of Python; extension modules is that Python patch releases can break them.; The two typical solutions are to either restrict the choice of Python; interpreter and version that are supported (common in HPC) or to provide; binaries (wheels) for a large range of different interpreters and versions; (as e.g. done for conda). In the case of cppyy, only CPython/CPyCppyy and PyPy/_cppyy (an internal; module) depend on the Python interpreter (see:; :ref:`Package Structure <package-structure>`).; The user-facing ``cppyy`` module is pure Python and the backend (Cling) is; Python-independent.; Most importantly, since all bindings are generated at run-time, there are no; extension modules to regenerate and/or recompile. Thus, the end-user only needs to rebuild/reinstall CPyCppyy for each relevant; version of Python (and nothing extra is needed for PyPy) to switch Python; versions and/or interpreter.; The rest of the software stack remains completely unchanged.; Only if Cling in cppyy's backend is updated, which happens infrequently, and; non-standard precompiled headers or modules are used, do these need to be; rebuild in full. .. _`SWIG`: http://swig.org/; .. _`pybind11`: https://pybind11.readthedocs.io/en/stable/; .. _`PyPy`: https://www.pypy.org/; .. _`CINT`: https://en.wikipedia.org/wiki/CINT; .. _`LLVM`: https://llvm.org/; .. _`Numba`: http://numba.pydata.org/; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst:2662,Modifiability,portab,portable,2662,"le gets; loaded), not the Python class object.; In short, whether a binding is created at ""compile-time"" or at run-time has; no measurable bearing on performance. What does affect performance is the overhead to cross the language barrier.; This consists of unboxing Python objects to extract or convert the underlying; objects or data to something that matches what C++ expects; overload; resolution based on the unboxed arguments; offset calculations; and finally; the actual dispatch.; As a practical matter, overload resolution is the most costly part, followed; by the unboxing and conversion.; Best performance is achieved by specialization of the paths through the; run-time: recognize early the case at hand and select an optimized path.; For that reason, `PyPy`_ is so fast: JIT-ed traces operate on unboxed objects; and resolved overloads are baked into the trace, incurring no further cost.; Similarly, this is why pybind11 is so slow: its code generation is the C++; compiler's template engine, so complex path selection and specialization is; very hard to do in a performance-portable way. In cppyy, a great deal of attention has gone into built-in specialization; paths, which drives its performance.; For example, basic inheritance sequentially lines up classes, whereas; multiple (virtual) inheritance usually requires thunks.; Thus, when calling base class methods on a derived instance, the latter; requires offset calculations that depend on that instance, whereas the former; has fixed offsets fully determined by the class definitions themselves.; By labeling classes appropriately, single inheritance classes (by far the; most common case) do not incur the overhead in PyPy's JIT-ed traces that is; otherwise unavoidable for multiple virtual inheritance.; As another example, consider that the C++ standard does not allow modifying; a ``std::vector`` while looping over it, whereas Python has no such; restriction, complicating loops.; Thus, cppyy has specialized ``std::vector`` ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst:2808,Modifiability,inherit,inheritance,2808,"cts to extract or convert the underlying; objects or data to something that matches what C++ expects; overload; resolution based on the unboxed arguments; offset calculations; and finally; the actual dispatch.; As a practical matter, overload resolution is the most costly part, followed; by the unboxing and conversion.; Best performance is achieved by specialization of the paths through the; run-time: recognize early the case at hand and select an optimized path.; For that reason, `PyPy`_ is so fast: JIT-ed traces operate on unboxed objects; and resolved overloads are baked into the trace, incurring no further cost.; Similarly, this is why pybind11 is so slow: its code generation is the C++; compiler's template engine, so complex path selection and specialization is; very hard to do in a performance-portable way. In cppyy, a great deal of attention has gone into built-in specialization; paths, which drives its performance.; For example, basic inheritance sequentially lines up classes, whereas; multiple (virtual) inheritance usually requires thunks.; Thus, when calling base class methods on a derived instance, the latter; requires offset calculations that depend on that instance, whereas the former; has fixed offsets fully determined by the class definitions themselves.; By labeling classes appropriately, single inheritance classes (by far the; most common case) do not incur the overhead in PyPy's JIT-ed traces that is; otherwise unavoidable for multiple virtual inheritance.; As another example, consider that the C++ standard does not allow modifying; a ``std::vector`` while looping over it, whereas Python has no such; restriction, complicating loops.; Thus, cppyy has specialized ``std::vector`` iteration for both PyPy and; CPython, easily outperforming looping over an equivalent numpy array. In CPython, the performance of `non-overloaded` function calls depends; greatly on the Python interpreter's internal specializations; and Python3; has many specializations speci",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst:2879,Modifiability,inherit,inheritance,2879,"cts to extract or convert the underlying; objects or data to something that matches what C++ expects; overload; resolution based on the unboxed arguments; offset calculations; and finally; the actual dispatch.; As a practical matter, overload resolution is the most costly part, followed; by the unboxing and conversion.; Best performance is achieved by specialization of the paths through the; run-time: recognize early the case at hand and select an optimized path.; For that reason, `PyPy`_ is so fast: JIT-ed traces operate on unboxed objects; and resolved overloads are baked into the trace, incurring no further cost.; Similarly, this is why pybind11 is so slow: its code generation is the C++; compiler's template engine, so complex path selection and specialization is; very hard to do in a performance-portable way. In cppyy, a great deal of attention has gone into built-in specialization; paths, which drives its performance.; For example, basic inheritance sequentially lines up classes, whereas; multiple (virtual) inheritance usually requires thunks.; Thus, when calling base class methods on a derived instance, the latter; requires offset calculations that depend on that instance, whereas the former; has fixed offsets fully determined by the class definitions themselves.; By labeling classes appropriately, single inheritance classes (by far the; most common case) do not incur the overhead in PyPy's JIT-ed traces that is; otherwise unavoidable for multiple virtual inheritance.; As another example, consider that the C++ standard does not allow modifying; a ``std::vector`` while looping over it, whereas Python has no such; restriction, complicating loops.; Thus, cppyy has specialized ``std::vector`` iteration for both PyPy and; CPython, easily outperforming looping over an equivalent numpy array. In CPython, the performance of `non-overloaded` function calls depends; greatly on the Python interpreter's internal specializations; and Python3; has many specializations speci",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst:3184,Modifiability,inherit,inheritance,3184,"; run-time: recognize early the case at hand and select an optimized path.; For that reason, `PyPy`_ is so fast: JIT-ed traces operate on unboxed objects; and resolved overloads are baked into the trace, incurring no further cost.; Similarly, this is why pybind11 is so slow: its code generation is the C++; compiler's template engine, so complex path selection and specialization is; very hard to do in a performance-portable way. In cppyy, a great deal of attention has gone into built-in specialization; paths, which drives its performance.; For example, basic inheritance sequentially lines up classes, whereas; multiple (virtual) inheritance usually requires thunks.; Thus, when calling base class methods on a derived instance, the latter; requires offset calculations that depend on that instance, whereas the former; has fixed offsets fully determined by the class definitions themselves.; By labeling classes appropriately, single inheritance classes (by far the; most common case) do not incur the overhead in PyPy's JIT-ed traces that is; otherwise unavoidable for multiple virtual inheritance.; As another example, consider that the C++ standard does not allow modifying; a ``std::vector`` while looping over it, whereas Python has no such; restriction, complicating loops.; Thus, cppyy has specialized ``std::vector`` iteration for both PyPy and; CPython, easily outperforming looping over an equivalent numpy array. In CPython, the performance of `non-overloaded` function calls depends; greatly on the Python interpreter's internal specializations; and Python3; has many specializations specific to basic extension modules (C function; pointer calls), gaining a performance boost of more than 30% over Python2.; Only since Python3.8 is there also better support for closure objects (vector; calls) as cppyy uses, to short-cut through the interpreter's own overhead. As a practical consideration, whether a binder performs well on code that you; care about, depends `entirely` on whether",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst:3337,Modifiability,inherit,inheritance,3337,"; run-time: recognize early the case at hand and select an optimized path.; For that reason, `PyPy`_ is so fast: JIT-ed traces operate on unboxed objects; and resolved overloads are baked into the trace, incurring no further cost.; Similarly, this is why pybind11 is so slow: its code generation is the C++; compiler's template engine, so complex path selection and specialization is; very hard to do in a performance-portable way. In cppyy, a great deal of attention has gone into built-in specialization; paths, which drives its performance.; For example, basic inheritance sequentially lines up classes, whereas; multiple (virtual) inheritance usually requires thunks.; Thus, when calling base class methods on a derived instance, the latter; requires offset calculations that depend on that instance, whereas the former; has fixed offsets fully determined by the class definitions themselves.; By labeling classes appropriately, single inheritance classes (by far the; most common case) do not incur the overhead in PyPy's JIT-ed traces that is; otherwise unavoidable for multiple virtual inheritance.; As another example, consider that the C++ standard does not allow modifying; a ``std::vector`` while looping over it, whereas Python has no such; restriction, complicating loops.; Thus, cppyy has specialized ``std::vector`` iteration for both PyPy and; CPython, easily outperforming looping over an equivalent numpy array. In CPython, the performance of `non-overloaded` function calls depends; greatly on the Python interpreter's internal specializations; and Python3; has many specializations specific to basic extension modules (C function; pointer calls), gaining a performance boost of more than 30% over Python2.; Only since Python3.8 is there also better support for closure objects (vector; calls) as cppyy uses, to short-cut through the interpreter's own overhead. As a practical consideration, whether a binder performs well on code that you; care about, depends `entirely` on whether",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst:10003,Modifiability,config,configured,10003,"ing; the option of automatic loading), standard classes are never duplicated, and; there is no additional ""per-module"" overhead.; Thus, eventually (depending on the number of classes bound, across how many; modules, what use fraction, etc.), this initial cost is recouped when; compared to other binders.; As a rule of thumb, if about 10% of classes are used, it takes several; hundreds of bound classes before the cppyy-approach is beneficial.; In High Energy Physics, from which it originated, cppyy is regularly used in; software stacks of many thousands of classes, where this advantage is very; important. `Distributing headers`; ----------------------. cppyy requires C/C++ headers to be available at run-time, which was never a; problem in the developer-centric world from which it originated: software; always had supported C++ APIs already, made available through header files,; and Python simply piggy-backed onto those.; JIT-ing code in those headers, which potentially picked up system headers; that were configured differently, was thus also never a problem.; Or rather, the same problem exists for C++, and configuration for C++ to; resolve potential issues translates transparently to Python. There are only two alternatives: precompile headers into LLVM bitcode and; distribute those or provide a restricted set of headers.; Precompiled headers (and modules) were never designed to be portable and; relocatable, however, thus that may not be the panacea it seems.; A restricted set of headers is some work, but cppyy can operate on abstract; interface classes just fine (including Python-side cross-inheritance). `Large deployment`; ------------------. The single biggest headache in maintaining an installation of Python; extension modules is that Python patch releases can break them.; The two typical solutions are to either restrict the choice of Python; interpreter and version that are supported (common in HPC) or to provide; binaries (wheels) for a large range of different int",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst:10107,Modifiability,config,configuration,10107,"ntually (depending on the number of classes bound, across how many; modules, what use fraction, etc.), this initial cost is recouped when; compared to other binders.; As a rule of thumb, if about 10% of classes are used, it takes several; hundreds of bound classes before the cppyy-approach is beneficial.; In High Energy Physics, from which it originated, cppyy is regularly used in; software stacks of many thousands of classes, where this advantage is very; important. `Distributing headers`; ----------------------. cppyy requires C/C++ headers to be available at run-time, which was never a; problem in the developer-centric world from which it originated: software; always had supported C++ APIs already, made available through header files,; and Python simply piggy-backed onto those.; JIT-ing code in those headers, which potentially picked up system headers; that were configured differently, was thus also never a problem.; Or rather, the same problem exists for C++, and configuration for C++ to; resolve potential issues translates transparently to Python. There are only two alternatives: precompile headers into LLVM bitcode and; distribute those or provide a restricted set of headers.; Precompiled headers (and modules) were never designed to be portable and; relocatable, however, thus that may not be the panacea it seems.; A restricted set of headers is some work, but cppyy can operate on abstract; interface classes just fine (including Python-side cross-inheritance). `Large deployment`; ------------------. The single biggest headache in maintaining an installation of Python; extension modules is that Python patch releases can break them.; The two typical solutions are to either restrict the choice of Python; interpreter and version that are supported (common in HPC) or to provide; binaries (wheels) for a large range of different interpreters and versions; (as e.g. done for conda). In the case of cppyy, only CPython/CPyCppyy and PyPy/_cppyy (an internal; module) depend",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst:10387,Modifiability,portab,portable,10387,"e the cppyy-approach is beneficial.; In High Energy Physics, from which it originated, cppyy is regularly used in; software stacks of many thousands of classes, where this advantage is very; important. `Distributing headers`; ----------------------. cppyy requires C/C++ headers to be available at run-time, which was never a; problem in the developer-centric world from which it originated: software; always had supported C++ APIs already, made available through header files,; and Python simply piggy-backed onto those.; JIT-ing code in those headers, which potentially picked up system headers; that were configured differently, was thus also never a problem.; Or rather, the same problem exists for C++, and configuration for C++ to; resolve potential issues translates transparently to Python. There are only two alternatives: precompile headers into LLVM bitcode and; distribute those or provide a restricted set of headers.; Precompiled headers (and modules) were never designed to be portable and; relocatable, however, thus that may not be the panacea it seems.; A restricted set of headers is some work, but cppyy can operate on abstract; interface classes just fine (including Python-side cross-inheritance). `Large deployment`; ------------------. The single biggest headache in maintaining an installation of Python; extension modules is that Python patch releases can break them.; The two typical solutions are to either restrict the choice of Python; interpreter and version that are supported (common in HPC) or to provide; binaries (wheels) for a large range of different interpreters and versions; (as e.g. done for conda). In the case of cppyy, only CPython/CPyCppyy and PyPy/_cppyy (an internal; module) depend on the Python interpreter (see:; :ref:`Package Structure <package-structure>`).; The user-facing ``cppyy`` module is pure Python and the backend (Cling) is; Python-independent.; Most importantly, since all bindings are generated at run-time, there are no; extension mod",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst:10601,Modifiability,inherit,inheritance,10601,"ands of classes, where this advantage is very; important. `Distributing headers`; ----------------------. cppyy requires C/C++ headers to be available at run-time, which was never a; problem in the developer-centric world from which it originated: software; always had supported C++ APIs already, made available through header files,; and Python simply piggy-backed onto those.; JIT-ing code in those headers, which potentially picked up system headers; that were configured differently, was thus also never a problem.; Or rather, the same problem exists for C++, and configuration for C++ to; resolve potential issues translates transparently to Python. There are only two alternatives: precompile headers into LLVM bitcode and; distribute those or provide a restricted set of headers.; Precompiled headers (and modules) were never designed to be portable and; relocatable, however, thus that may not be the panacea it seems.; A restricted set of headers is some work, but cppyy can operate on abstract; interface classes just fine (including Python-side cross-inheritance). `Large deployment`; ------------------. The single biggest headache in maintaining an installation of Python; extension modules is that Python patch releases can break them.; The two typical solutions are to either restrict the choice of Python; interpreter and version that are supported (common in HPC) or to provide; binaries (wheels) for a large range of different interpreters and versions; (as e.g. done for conda). In the case of cppyy, only CPython/CPyCppyy and PyPy/_cppyy (an internal; module) depend on the Python interpreter (see:; :ref:`Package Structure <package-structure>`).; The user-facing ``cppyy`` module is pure Python and the backend (Cling) is; Python-independent.; Most importantly, since all bindings are generated at run-time, there are no; extension modules to regenerate and/or recompile. Thus, the end-user only needs to rebuild/reinstall CPyCppyy for each relevant; version of Python (and nothin",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst:643,Performance,perform,performs,643,".. _philosophy:. Philosophy; ==========. .. toctree::; :hidden:. As a Python-C++ language binder, cppyy has several unique features: it fills; gaps and covers use cases not available through other binders.; This document explains some of the design choices made and the thinking; behind the implementations of those features.; It's categorized as ""philosophy"" because a lot of it is open to; interpretation.; Its main purpose is simply to help you decide whether cppyy covers your use; cases and binding requirements, before committing any time to; :ref:`trying it out <starting>`. Run-time v.s. compile-time; --------------------------. What performs better, run-time or compile-time?; The obvious answer is compile-time: see the performance differences between; C++ and Python, for example.; Obvious, but completely wrong, however.; In fact, when it comes to Python, it is even the `wrong question.`. Everything in Python is run-time: modules, classes, functions, etc. are all; run-time constructs.; A Python module that defines a class is a set of instructions to the Python; interpreter that lead to the construction of the desired class object.; A C/C++ extension module that defines a class does the same thing by calling; a succession of Python interpreter Application Programming Interfaces (APIs;; the exact same that Python uses itself internally).; If you use a compile-time binder such as `SWIG`_ or `pybind11`_ to bind a C++; class, then what gets compiled is the series of API calls necessary to; construct a Python-side equivalent at `run-time` (when the module gets; loaded), not the Python class object.; In short, whether a binding is created at ""compile-time"" or at run-time has; no measurable bearing on performance. What does affect performance is the overhead to cross the language barrier.; This consists of unboxing Python objects to extract or convert the underlying; objects or data to something that matches what C++ expects; overload; resolution based on the unboxed argume",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst:731,Performance,perform,performance,731,".. _philosophy:. Philosophy; ==========. .. toctree::; :hidden:. As a Python-C++ language binder, cppyy has several unique features: it fills; gaps and covers use cases not available through other binders.; This document explains some of the design choices made and the thinking; behind the implementations of those features.; It's categorized as ""philosophy"" because a lot of it is open to; interpretation.; Its main purpose is simply to help you decide whether cppyy covers your use; cases and binding requirements, before committing any time to; :ref:`trying it out <starting>`. Run-time v.s. compile-time; --------------------------. What performs better, run-time or compile-time?; The obvious answer is compile-time: see the performance differences between; C++ and Python, for example.; Obvious, but completely wrong, however.; In fact, when it comes to Python, it is even the `wrong question.`. Everything in Python is run-time: modules, classes, functions, etc. are all; run-time constructs.; A Python module that defines a class is a set of instructions to the Python; interpreter that lead to the construction of the desired class object.; A C/C++ extension module that defines a class does the same thing by calling; a succession of Python interpreter Application Programming Interfaces (APIs;; the exact same that Python uses itself internally).; If you use a compile-time binder such as `SWIG`_ or `pybind11`_ to bind a C++; class, then what gets compiled is the series of API calls necessary to; construct a Python-side equivalent at `run-time` (when the module gets; loaded), not the Python class object.; In short, whether a binding is created at ""compile-time"" or at run-time has; no measurable bearing on performance. What does affect performance is the overhead to cross the language barrier.; This consists of unboxing Python objects to extract or convert the underlying; objects or data to something that matches what C++ expects; overload; resolution based on the unboxed argume",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst:1583,Performance,load,loaded,1583,"es and binding requirements, before committing any time to; :ref:`trying it out <starting>`. Run-time v.s. compile-time; --------------------------. What performs better, run-time or compile-time?; The obvious answer is compile-time: see the performance differences between; C++ and Python, for example.; Obvious, but completely wrong, however.; In fact, when it comes to Python, it is even the `wrong question.`. Everything in Python is run-time: modules, classes, functions, etc. are all; run-time constructs.; A Python module that defines a class is a set of instructions to the Python; interpreter that lead to the construction of the desired class object.; A C/C++ extension module that defines a class does the same thing by calling; a succession of Python interpreter Application Programming Interfaces (APIs;; the exact same that Python uses itself internally).; If you use a compile-time binder such as `SWIG`_ or `pybind11`_ to bind a C++; class, then what gets compiled is the series of API calls necessary to; construct a Python-side equivalent at `run-time` (when the module gets; loaded), not the Python class object.; In short, whether a binding is created at ""compile-time"" or at run-time has; no measurable bearing on performance. What does affect performance is the overhead to cross the language barrier.; This consists of unboxing Python objects to extract or convert the underlying; objects or data to something that matches what C++ expects; overload; resolution based on the unboxed arguments; offset calculations; and finally; the actual dispatch.; As a practical matter, overload resolution is the most costly part, followed; by the unboxing and conversion.; Best performance is achieved by specialization of the paths through the; run-time: recognize early the case at hand and select an optimized path.; For that reason, `PyPy`_ is so fast: JIT-ed traces operate on unboxed objects; and resolved overloads are baked into the trace, incurring no further cost.; Similarly, th",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst:1724,Performance,perform,performance,1724,"e-time?; The obvious answer is compile-time: see the performance differences between; C++ and Python, for example.; Obvious, but completely wrong, however.; In fact, when it comes to Python, it is even the `wrong question.`. Everything in Python is run-time: modules, classes, functions, etc. are all; run-time constructs.; A Python module that defines a class is a set of instructions to the Python; interpreter that lead to the construction of the desired class object.; A C/C++ extension module that defines a class does the same thing by calling; a succession of Python interpreter Application Programming Interfaces (APIs;; the exact same that Python uses itself internally).; If you use a compile-time binder such as `SWIG`_ or `pybind11`_ to bind a C++; class, then what gets compiled is the series of API calls necessary to; construct a Python-side equivalent at `run-time` (when the module gets; loaded), not the Python class object.; In short, whether a binding is created at ""compile-time"" or at run-time has; no measurable bearing on performance. What does affect performance is the overhead to cross the language barrier.; This consists of unboxing Python objects to extract or convert the underlying; objects or data to something that matches what C++ expects; overload; resolution based on the unboxed arguments; offset calculations; and finally; the actual dispatch.; As a practical matter, overload resolution is the most costly part, followed; by the unboxing and conversion.; Best performance is achieved by specialization of the paths through the; run-time: recognize early the case at hand and select an optimized path.; For that reason, `PyPy`_ is so fast: JIT-ed traces operate on unboxed objects; and resolved overloads are baked into the trace, incurring no further cost.; Similarly, this is why pybind11 is so slow: its code generation is the C++; compiler's template engine, so complex path selection and specialization is; very hard to do in a performance-portable way. In",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst:1754,Performance,perform,performance,1754,"thon, for example.; Obvious, but completely wrong, however.; In fact, when it comes to Python, it is even the `wrong question.`. Everything in Python is run-time: modules, classes, functions, etc. are all; run-time constructs.; A Python module that defines a class is a set of instructions to the Python; interpreter that lead to the construction of the desired class object.; A C/C++ extension module that defines a class does the same thing by calling; a succession of Python interpreter Application Programming Interfaces (APIs;; the exact same that Python uses itself internally).; If you use a compile-time binder such as `SWIG`_ or `pybind11`_ to bind a C++; class, then what gets compiled is the series of API calls necessary to; construct a Python-side equivalent at `run-time` (when the module gets; loaded), not the Python class object.; In short, whether a binding is created at ""compile-time"" or at run-time has; no measurable bearing on performance. What does affect performance is the overhead to cross the language barrier.; This consists of unboxing Python objects to extract or convert the underlying; objects or data to something that matches what C++ expects; overload; resolution based on the unboxed arguments; offset calculations; and finally; the actual dispatch.; As a practical matter, overload resolution is the most costly part, followed; by the unboxing and conversion.; Best performance is achieved by specialization of the paths through the; run-time: recognize early the case at hand and select an optimized path.; For that reason, `PyPy`_ is so fast: JIT-ed traces operate on unboxed objects; and resolved overloads are baked into the trace, incurring no further cost.; Similarly, this is why pybind11 is so slow: its code generation is the C++; compiler's template engine, so complex path selection and specialization is; very hard to do in a performance-portable way. In cppyy, a great deal of attention has gone into built-in specialization; paths, which drives its",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst:2178,Performance,perform,performance,2178," Python interpreter Application Programming Interfaces (APIs;; the exact same that Python uses itself internally).; If you use a compile-time binder such as `SWIG`_ or `pybind11`_ to bind a C++; class, then what gets compiled is the series of API calls necessary to; construct a Python-side equivalent at `run-time` (when the module gets; loaded), not the Python class object.; In short, whether a binding is created at ""compile-time"" or at run-time has; no measurable bearing on performance. What does affect performance is the overhead to cross the language barrier.; This consists of unboxing Python objects to extract or convert the underlying; objects or data to something that matches what C++ expects; overload; resolution based on the unboxed arguments; offset calculations; and finally; the actual dispatch.; As a practical matter, overload resolution is the most costly part, followed; by the unboxing and conversion.; Best performance is achieved by specialization of the paths through the; run-time: recognize early the case at hand and select an optimized path.; For that reason, `PyPy`_ is so fast: JIT-ed traces operate on unboxed objects; and resolved overloads are baked into the trace, incurring no further cost.; Similarly, this is why pybind11 is so slow: its code generation is the C++; compiler's template engine, so complex path selection and specialization is; very hard to do in a performance-portable way. In cppyy, a great deal of attention has gone into built-in specialization; paths, which drives its performance.; For example, basic inheritance sequentially lines up classes, whereas; multiple (virtual) inheritance usually requires thunks.; Thus, when calling base class methods on a derived instance, the latter; requires offset calculations that depend on that instance, whereas the former; has fixed offsets fully determined by the class definitions themselves.; By labeling classes appropriately, single inheritance classes (by far the; most common case) do not inc",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst:2303,Performance,optimiz,optimized,2303," Python interpreter Application Programming Interfaces (APIs;; the exact same that Python uses itself internally).; If you use a compile-time binder such as `SWIG`_ or `pybind11`_ to bind a C++; class, then what gets compiled is the series of API calls necessary to; construct a Python-side equivalent at `run-time` (when the module gets; loaded), not the Python class object.; In short, whether a binding is created at ""compile-time"" or at run-time has; no measurable bearing on performance. What does affect performance is the overhead to cross the language barrier.; This consists of unboxing Python objects to extract or convert the underlying; objects or data to something that matches what C++ expects; overload; resolution based on the unboxed arguments; offset calculations; and finally; the actual dispatch.; As a practical matter, overload resolution is the most costly part, followed; by the unboxing and conversion.; Best performance is achieved by specialization of the paths through the; run-time: recognize early the case at hand and select an optimized path.; For that reason, `PyPy`_ is so fast: JIT-ed traces operate on unboxed objects; and resolved overloads are baked into the trace, incurring no further cost.; Similarly, this is why pybind11 is so slow: its code generation is the C++; compiler's template engine, so complex path selection and specialization is; very hard to do in a performance-portable way. In cppyy, a great deal of attention has gone into built-in specialization; paths, which drives its performance.; For example, basic inheritance sequentially lines up classes, whereas; multiple (virtual) inheritance usually requires thunks.; Thus, when calling base class methods on a derived instance, the latter; requires offset calculations that depend on that instance, whereas the former; has fixed offsets fully determined by the class definitions themselves.; By labeling classes appropriately, single inheritance classes (by far the; most common case) do not inc",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst:2650,Performance,perform,performance-portable,2650,"le gets; loaded), not the Python class object.; In short, whether a binding is created at ""compile-time"" or at run-time has; no measurable bearing on performance. What does affect performance is the overhead to cross the language barrier.; This consists of unboxing Python objects to extract or convert the underlying; objects or data to something that matches what C++ expects; overload; resolution based on the unboxed arguments; offset calculations; and finally; the actual dispatch.; As a practical matter, overload resolution is the most costly part, followed; by the unboxing and conversion.; Best performance is achieved by specialization of the paths through the; run-time: recognize early the case at hand and select an optimized path.; For that reason, `PyPy`_ is so fast: JIT-ed traces operate on unboxed objects; and resolved overloads are baked into the trace, incurring no further cost.; Similarly, this is why pybind11 is so slow: its code generation is the C++; compiler's template engine, so complex path selection and specialization is; very hard to do in a performance-portable way. In cppyy, a great deal of attention has gone into built-in specialization; paths, which drives its performance.; For example, basic inheritance sequentially lines up classes, whereas; multiple (virtual) inheritance usually requires thunks.; Thus, when calling base class methods on a derived instance, the latter; requires offset calculations that depend on that instance, whereas the former; has fixed offsets fully determined by the class definitions themselves.; By labeling classes appropriately, single inheritance classes (by far the; most common case) do not incur the overhead in PyPy's JIT-ed traces that is; otherwise unavoidable for multiple virtual inheritance.; As another example, consider that the C++ standard does not allow modifying; a ``std::vector`` while looping over it, whereas Python has no such; restriction, complicating loops.; Thus, cppyy has specialized ``std::vector`` ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst:2775,Performance,perform,performance,2775,"ance. What does affect performance is the overhead to cross the language barrier.; This consists of unboxing Python objects to extract or convert the underlying; objects or data to something that matches what C++ expects; overload; resolution based on the unboxed arguments; offset calculations; and finally; the actual dispatch.; As a practical matter, overload resolution is the most costly part, followed; by the unboxing and conversion.; Best performance is achieved by specialization of the paths through the; run-time: recognize early the case at hand and select an optimized path.; For that reason, `PyPy`_ is so fast: JIT-ed traces operate on unboxed objects; and resolved overloads are baked into the trace, incurring no further cost.; Similarly, this is why pybind11 is so slow: its code generation is the C++; compiler's template engine, so complex path selection and specialization is; very hard to do in a performance-portable way. In cppyy, a great deal of attention has gone into built-in specialization; paths, which drives its performance.; For example, basic inheritance sequentially lines up classes, whereas; multiple (virtual) inheritance usually requires thunks.; Thus, when calling base class methods on a derived instance, the latter; requires offset calculations that depend on that instance, whereas the former; has fixed offsets fully determined by the class definitions themselves.; By labeling classes appropriately, single inheritance classes (by far the; most common case) do not incur the overhead in PyPy's JIT-ed traces that is; otherwise unavoidable for multiple virtual inheritance.; As another example, consider that the C++ standard does not allow modifying; a ``std::vector`` while looping over it, whereas Python has no such; restriction, complicating loops.; Thus, cppyy has specialized ``std::vector`` iteration for both PyPy and; CPython, easily outperforming looping over an equivalent numpy array. In CPython, the performance of `non-overloaded` function ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst:3690,Performance,perform,performance,3690,"equentially lines up classes, whereas; multiple (virtual) inheritance usually requires thunks.; Thus, when calling base class methods on a derived instance, the latter; requires offset calculations that depend on that instance, whereas the former; has fixed offsets fully determined by the class definitions themselves.; By labeling classes appropriately, single inheritance classes (by far the; most common case) do not incur the overhead in PyPy's JIT-ed traces that is; otherwise unavoidable for multiple virtual inheritance.; As another example, consider that the C++ standard does not allow modifying; a ``std::vector`` while looping over it, whereas Python has no such; restriction, complicating loops.; Thus, cppyy has specialized ``std::vector`` iteration for both PyPy and; CPython, easily outperforming looping over an equivalent numpy array. In CPython, the performance of `non-overloaded` function calls depends; greatly on the Python interpreter's internal specializations; and Python3; has many specializations specific to basic extension modules (C function; pointer calls), gaining a performance boost of more than 30% over Python2.; Only since Python3.8 is there also better support for closure objects (vector; calls) as cppyy uses, to short-cut through the interpreter's own overhead. As a practical consideration, whether a binder performs well on code that you; care about, depends `entirely` on whether it has the relevant specializations; for your most performance-sensitive use cases.; The only way to know for sure is to write a test application and measure, but; a binder that provides more specializations, or makes it easy to add your; own, is more likely to deliver. `Manual v.s. automatic`; -----------------------. Python is, today, one of the most popular programming languages and has a; rich and mature eco-system around it.; But when the project that became cppyy started in the field of High Energy; Physics (HEP), Python usage was non-existent there.; As a Python",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst:3921,Performance,perform,performance,3921,"equentially lines up classes, whereas; multiple (virtual) inheritance usually requires thunks.; Thus, when calling base class methods on a derived instance, the latter; requires offset calculations that depend on that instance, whereas the former; has fixed offsets fully determined by the class definitions themselves.; By labeling classes appropriately, single inheritance classes (by far the; most common case) do not incur the overhead in PyPy's JIT-ed traces that is; otherwise unavoidable for multiple virtual inheritance.; As another example, consider that the C++ standard does not allow modifying; a ``std::vector`` while looping over it, whereas Python has no such; restriction, complicating loops.; Thus, cppyy has specialized ``std::vector`` iteration for both PyPy and; CPython, easily outperforming looping over an equivalent numpy array. In CPython, the performance of `non-overloaded` function calls depends; greatly on the Python interpreter's internal specializations; and Python3; has many specializations specific to basic extension modules (C function; pointer calls), gaining a performance boost of more than 30% over Python2.; Only since Python3.8 is there also better support for closure objects (vector; calls) as cppyy uses, to short-cut through the interpreter's own overhead. As a practical consideration, whether a binder performs well on code that you; care about, depends `entirely` on whether it has the relevant specializations; for your most performance-sensitive use cases.; The only way to know for sure is to write a test application and measure, but; a binder that provides more specializations, or makes it easy to add your; own, is more likely to deliver. `Manual v.s. automatic`; -----------------------. Python is, today, one of the most popular programming languages and has a; rich and mature eco-system around it.; But when the project that became cppyy started in the field of High Energy; Physics (HEP), Python usage was non-existent there.; As a Python",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst:4172,Performance,perform,performs,4172,"on case) do not incur the overhead in PyPy's JIT-ed traces that is; otherwise unavoidable for multiple virtual inheritance.; As another example, consider that the C++ standard does not allow modifying; a ``std::vector`` while looping over it, whereas Python has no such; restriction, complicating loops.; Thus, cppyy has specialized ``std::vector`` iteration for both PyPy and; CPython, easily outperforming looping over an equivalent numpy array. In CPython, the performance of `non-overloaded` function calls depends; greatly on the Python interpreter's internal specializations; and Python3; has many specializations specific to basic extension modules (C function; pointer calls), gaining a performance boost of more than 30% over Python2.; Only since Python3.8 is there also better support for closure objects (vector; calls) as cppyy uses, to short-cut through the interpreter's own overhead. As a practical consideration, whether a binder performs well on code that you; care about, depends `entirely` on whether it has the relevant specializations; for your most performance-sensitive use cases.; The only way to know for sure is to write a test application and measure, but; a binder that provides more specializations, or makes it easy to add your; own, is more likely to deliver. `Manual v.s. automatic`; -----------------------. Python is, today, one of the most popular programming languages and has a; rich and mature eco-system around it.; But when the project that became cppyy started in the field of High Energy; Physics (HEP), Python usage was non-existent there.; As a Python user to work in this predominantly C++ environment, you had to; bring your own bindings, thus automatic was the only way to go.; Binders such as SWIG, SIP (or even boost.python with Pyste) all had the fatal; assumption that you were providing Python bindings to your `own` C++ code,; and that you were thus able to modify those (many) areas of the C++ codes; that their parsers could not handle.; The `CIN",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst:4297,Performance,perform,performance-sensitive,4297,"on case) do not incur the overhead in PyPy's JIT-ed traces that is; otherwise unavoidable for multiple virtual inheritance.; As another example, consider that the C++ standard does not allow modifying; a ``std::vector`` while looping over it, whereas Python has no such; restriction, complicating loops.; Thus, cppyy has specialized ``std::vector`` iteration for both PyPy and; CPython, easily outperforming looping over an equivalent numpy array. In CPython, the performance of `non-overloaded` function calls depends; greatly on the Python interpreter's internal specializations; and Python3; has many specializations specific to basic extension modules (C function; pointer calls), gaining a performance boost of more than 30% over Python2.; Only since Python3.8 is there also better support for closure objects (vector; calls) as cppyy uses, to short-cut through the interpreter's own overhead. As a practical consideration, whether a binder performs well on code that you; care about, depends `entirely` on whether it has the relevant specializations; for your most performance-sensitive use cases.; The only way to know for sure is to write a test application and measure, but; a binder that provides more specializations, or makes it easy to add your; own, is more likely to deliver. `Manual v.s. automatic`; -----------------------. Python is, today, one of the most popular programming languages and has a; rich and mature eco-system around it.; But when the project that became cppyy started in the field of High Energy; Physics (HEP), Python usage was non-existent there.; As a Python user to work in this predominantly C++ environment, you had to; bring your own bindings, thus automatic was the only way to go.; Binders such as SWIG, SIP (or even boost.python with Pyste) all had the fatal; assumption that you were providing Python bindings to your `own` C++ code,; and that you were thus able to modify those (many) areas of the C++ codes; that their parsers could not handle.; The `CIN",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst:8371,Performance,load,loading,8371,"g part; needing manual intervention.; This is broadly true, but realize that that 5% contains the most difficult; cases and is where 20-30% of the effort would have gone in case the bindings; were done fully manually.; It is therefore important to consider what manual tools an automatic binder; offers and to make sure they fit your work style and needs, because you are; going to spend a significant amount of time with them. `LLVM dependency`; -----------------. cppyy depends on `LLVM`_, through Cling.; LLVM is properly internalized, so that it doesn't conflict with other uses;; and in particular it is fine to mix `Numba`_ and cppyy code.; It does mean a download cost of about 20MB for the binary wheel (exact size; differs per platform) on installation, and additional `primarily initial`; memory overheads at run-time.; Whether this is onerous depends strongly not only on the application, but; also on the rest of the software stack. The initial cost of loading cppyy, and thus starting the Cling interpreter,; is about 45MB (platform dependent).; Initial uses of standard (e.g. STL) C++ results in deserialization of the; precompiled header at another eventual total cost of about 25MB (again,; platform dependent).; The actual bindings of course also carry overheads.; As a rule of thumb, you should budget for ~100MB all-in for the overhead; caused by the bindings. Other binders do not have this initial memory overhead, but do of course; occur an overhead per module, class, function, etc.; At scale, however, cppyy has some advantages: all binding is lazy (including; the option of automatic loading), standard classes are never duplicated, and; there is no additional ""per-module"" overhead.; Thus, eventually (depending on the number of classes bound, across how many; modules, what use fraction, etc.), this initial cost is recouped when; compared to other binders.; As a rule of thumb, if about 10% of classes are used, it takes several; hundreds of bound classes before the cppyy-",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst:9015,Performance,load,loading,9015,"is fine to mix `Numba`_ and cppyy code.; It does mean a download cost of about 20MB for the binary wheel (exact size; differs per platform) on installation, and additional `primarily initial`; memory overheads at run-time.; Whether this is onerous depends strongly not only on the application, but; also on the rest of the software stack. The initial cost of loading cppyy, and thus starting the Cling interpreter,; is about 45MB (platform dependent).; Initial uses of standard (e.g. STL) C++ results in deserialization of the; precompiled header at another eventual total cost of about 25MB (again,; platform dependent).; The actual bindings of course also carry overheads.; As a rule of thumb, you should budget for ~100MB all-in for the overhead; caused by the bindings. Other binders do not have this initial memory overhead, but do of course; occur an overhead per module, class, function, etc.; At scale, however, cppyy has some advantages: all binding is lazy (including; the option of automatic loading), standard classes are never duplicated, and; there is no additional ""per-module"" overhead.; Thus, eventually (depending on the number of classes bound, across how many; modules, what use fraction, etc.), this initial cost is recouped when; compared to other binders.; As a rule of thumb, if about 10% of classes are used, it takes several; hundreds of bound classes before the cppyy-approach is beneficial.; In High Energy Physics, from which it originated, cppyy is regularly used in; software stacks of many thousands of classes, where this advantage is very; important. `Distributing headers`; ----------------------. cppyy requires C/C++ headers to be available at run-time, which was never a; problem in the developer-centric world from which it originated: software; always had supported C++ APIs already, made available through header files,; and Python simply piggy-backed onto those.; JIT-ing code in those headers, which potentially picked up system headers; that were configured",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst:4375,Testability,test,test,4375,"ying; a ``std::vector`` while looping over it, whereas Python has no such; restriction, complicating loops.; Thus, cppyy has specialized ``std::vector`` iteration for both PyPy and; CPython, easily outperforming looping over an equivalent numpy array. In CPython, the performance of `non-overloaded` function calls depends; greatly on the Python interpreter's internal specializations; and Python3; has many specializations specific to basic extension modules (C function; pointer calls), gaining a performance boost of more than 30% over Python2.; Only since Python3.8 is there also better support for closure objects (vector; calls) as cppyy uses, to short-cut through the interpreter's own overhead. As a practical consideration, whether a binder performs well on code that you; care about, depends `entirely` on whether it has the relevant specializations; for your most performance-sensitive use cases.; The only way to know for sure is to write a test application and measure, but; a binder that provides more specializations, or makes it easy to add your; own, is more likely to deliver. `Manual v.s. automatic`; -----------------------. Python is, today, one of the most popular programming languages and has a; rich and mature eco-system around it.; But when the project that became cppyy started in the field of High Energy; Physics (HEP), Python usage was non-existent there.; As a Python user to work in this predominantly C++ environment, you had to; bring your own bindings, thus automatic was the only way to go.; Binders such as SWIG, SIP (or even boost.python with Pyste) all had the fatal; assumption that you were providing Python bindings to your `own` C++ code,; and that you were thus able to modify those (many) areas of the C++ codes; that their parsers could not handle.; The `CINT`_ interpreter was already well established in HEP, however, and; although it, too, had many limitations, C++ developers took care not to write; code that it could not parse.; In particular, sinc",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst:429,Usability,simpl,simply,429,".. _philosophy:. Philosophy; ==========. .. toctree::; :hidden:. As a Python-C++ language binder, cppyy has several unique features: it fills; gaps and covers use cases not available through other binders.; This document explains some of the design choices made and the thinking; behind the implementations of those features.; It's categorized as ""philosophy"" because a lot of it is open to; interpretation.; Its main purpose is simply to help you decide whether cppyy covers your use; cases and binding requirements, before committing any time to; :ref:`trying it out <starting>`. Run-time v.s. compile-time; --------------------------. What performs better, run-time or compile-time?; The obvious answer is compile-time: see the performance differences between; C++ and Python, for example.; Obvious, but completely wrong, however.; In fact, when it comes to Python, it is even the `wrong question.`. Everything in Python is run-time: modules, classes, functions, etc. are all; run-time constructs.; A Python module that defines a class is a set of instructions to the Python; interpreter that lead to the construction of the desired class object.; A C/C++ extension module that defines a class does the same thing by calling; a succession of Python interpreter Application Programming Interfaces (APIs;; the exact same that Python uses itself internally).; If you use a compile-time binder such as `SWIG`_ or `pybind11`_ to bind a C++; class, then what gets compiled is the series of API calls necessary to; construct a Python-side equivalent at `run-time` (when the module gets; loaded), not the Python class object.; In short, whether a binding is created at ""compile-time"" or at run-time has; no measurable bearing on performance. What does affect performance is the overhead to cross the language barrier.; This consists of unboxing Python objects to extract or convert the underlying; objects or data to something that matches what C++ expects; overload; resolution based on the unboxed argume",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst:6423,Usability,learn,learning,6423,"l data classes as needed for; analysis were parsable by CINT and consequently, by using CINT for the; bindings, at the very least one could run any analysis in Python.; This was key. Besides not being able to parse some code (a problem that's history for cppyy; since moving to Cling), all automatic parsers suffer from the problem that; the bindings produced have a strong ""C++ look-and-feel"" and that choices need; to be made in cases that can be bound in different, equally valid, ways.; As an example of the latter, consider the return of an ``std::vector``:; should this be automatically converted to a Python ``list``?; Doing so is more ""pythonic"", but incurs a significant overhead, and no; automatic choice will satisfy all cases: user input is needed. The typical way to solve these issues, is to provide an intermediate language; where corner cases can be brushed up, code can be made more Python friendly,; and design choices can be resolved.; Unfortunately, learning an intermediate language is quite an investment in; time and effort.; With cppyy, however, no such extra language is needed: using Cling, C++ code; can be embedded and JIT-ed for the same purpose.; In particular, cppyy can handle `boxed` Python objects and the full Python; C-API is available through Cling, allowing complete manual control where; necessary, and all within a single code base.; Similarly, a more pythonistic look-and-feel can be achieved in Python itself.; As a rule, Python is always the best place, far more so than any intermediate; language, to do Python-thingies.; Since all bound proxies are normal Python classes, functions, etc., Python's; introspection (and regular expressions engine) can be used to provide rule; based improvements in a way similar to the use of directives in an; intermediate language. On a practical note, it's often said that an automatic binder can provide; bindings to 95% of your code out-of-the-box, with only the remaining part; needing manual intervention.; This is b",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst:9885,Usability,simpl,simply,9885,"ings. Other binders do not have this initial memory overhead, but do of course; occur an overhead per module, class, function, etc.; At scale, however, cppyy has some advantages: all binding is lazy (including; the option of automatic loading), standard classes are never duplicated, and; there is no additional ""per-module"" overhead.; Thus, eventually (depending on the number of classes bound, across how many; modules, what use fraction, etc.), this initial cost is recouped when; compared to other binders.; As a rule of thumb, if about 10% of classes are used, it takes several; hundreds of bound classes before the cppyy-approach is beneficial.; In High Energy Physics, from which it originated, cppyy is regularly used in; software stacks of many thousands of classes, where this advantage is very; important. `Distributing headers`; ----------------------. cppyy requires C/C++ headers to be available at run-time, which was never a; problem in the developer-centric world from which it originated: software; always had supported C++ APIs already, made available through header files,; and Python simply piggy-backed onto those.; JIT-ing code in those headers, which potentially picked up system headers; that were configured differently, was thus also never a problem.; Or rather, the same problem exists for C++, and configuration for C++ to; resolve potential issues translates transparently to Python. There are only two alternatives: precompile headers into LLVM bitcode and; distribute those or provide a restricted set of headers.; Precompiled headers (and modules) were never designed to be portable and; relocatable, however, thus that may not be the panacea it seems.; A restricted set of headers is some work, but cppyy can operate on abstract; interface classes just fine (including Python-side cross-inheritance). `Large deployment`; ------------------. The single biggest headache in maintaining an installation of Python; extension modules is that Python patch releases can bre",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/philosophy.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/python.rst:158,Performance,load,loaded,158,".. _python:. Python; ======. The C++ code used for the examples below can be found; :doc:`here <cppyy_features_header>`, and it is assumed that that code is; loaded at the start of any session.; Download it, save it under the name ``features.h``, and load it:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('features.h'); >>>. `PyObject`; ----------. Arguments and return types of ``PyObject*`` can be used, and passed on to; CPython API calls (or through ``cpyext`` in PyPy). `Doc strings`; -------------. The documentation string of a method or function contains the C++; arguments and return types of all overloads of that name, as applicable.; Example:. .. code-block:: python. >>> from cppyy.gbl import Concrete; >>> print Concrete.array_method.__doc__; void Concrete::array_method(int* ad, int size); void Concrete::array_method(double* ad, int size); >>>. `Help`; ------. Bound C++ class is first-class Python and can thus be inspected like any; Python objects can.; For example, we can ask for ``help()``:. .. code-block:: python. >>> help(Concrete); Help on class Concrete in module gbl:. class Concrete(Abstract); | Method resolution order:; | Concrete; | Abstract; | CPPInstance; | __builtin__.object; |; | Methods defined here:; |; | __assign__(self, const Concrete&); | Concrete& Concrete::operator=(const Concrete&); |; | __init__(self, *args); | Concrete::Concrete(int n = 42); | Concrete::Concrete(const Concrete&); |; etc. .... ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/python.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/python.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/python.rst:251,Performance,load,load,251,".. _python:. Python; ======. The C++ code used for the examples below can be found; :doc:`here <cppyy_features_header>`, and it is assumed that that code is; loaded at the start of any session.; Download it, save it under the name ``features.h``, and load it:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('features.h'); >>>. `PyObject`; ----------. Arguments and return types of ``PyObject*`` can be used, and passed on to; CPython API calls (or through ``cpyext`` in PyPy). `Doc strings`; -------------. The documentation string of a method or function contains the C++; arguments and return types of all overloads of that name, as applicable.; Example:. .. code-block:: python. >>> from cppyy.gbl import Concrete; >>> print Concrete.array_method.__doc__; void Concrete::array_method(int* ad, int size); void Concrete::array_method(double* ad, int size); >>>. `Help`; ------. Bound C++ class is first-class Python and can thus be inspected like any; Python objects can.; For example, we can ask for ``help()``:. .. code-block:: python. >>> help(Concrete); Help on class Concrete in module gbl:. class Concrete(Abstract); | Method resolution order:; | Concrete; | Abstract; | CPPInstance; | __builtin__.object; |; | Methods defined here:; |; | __assign__(self, const Concrete&); | Concrete& Concrete::operator=(const Concrete&); |; | __init__(self, *args); | Concrete::Concrete(int n = 42); | Concrete::Concrete(const Concrete&); |; etc. .... ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/python.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/python.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/pythonizations.rst:1466,Deployability,install,installation,1466," ""the C++ way""):. .. code-block:: python. >>> from cppyy.gbl import std; >>> m = std.map[int, int](); >>> for i in range(10):; ... m[i] = i*2; ...; >>> b = m.begin(); >>> while b != m.end():; ... print(b.__deref__().second, end=' '); ... b.__preinc__(); ...; 0 2 4 6 8 10 12 14 16 18 ; >>> . Yes, that is perfectly functional, but it is also very clunky.; Contrast this to the (automatic) pythonization:. .. code-block:: python. >>> for key, value in m:; ... print(value, end=' '); ...; 0 2 4 6 8 10 12 14 16 18; >>>. Such a pythonization can be written completely in Python using the bound C++; methods, with no intermediate language necessary.; Since it is written on abstract features, there is also only one such; pythonization that works for all STL map instantiations. Python callbacks; ----------------. Since bound C++ entities are fully functional Python ones, pythonization can; be done explicitly in an end-user facing Python module.; However, that would prevent lazy installation of pythonizations, so instead a; callback mechanism is provided. A callback is a function or callable object taking two arguments: the Python; proxy class to be pythonized and its C++ name.; The latter is provided to allow easy filtering.; This callback is then installed through ``cppyy.py.add_pythonization`` and; ideally only for the relevant namespace (installing callbacks for classes in; the global namespace is supported, but beware of name clashes). Pythonization is most effective of well-structured C++ libraries that have; idiomatic behaviors.; It is then straightforward to use Python reflection to write rules.; For example, consider this callback that looks for the conventional C++; function ``GetLength`` and replaces it with Python's ``__len__``:. .. code-block:: python. >>> import cppyy; >>>; >>> def replace_getlength(klass, name):; ... try:; ... klass.__len__ = klass.__dict__['GetLength']; ... del klass.GetLength; ... except KeyError:; ... pass; ...; >>> cppyy.py.add_pythonization(rep",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/pythonizations.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/pythonizations.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/pythonizations.rst:1741,Deployability,install,installed,1741,"..; 0 2 4 6 8 10 12 14 16 18 ; >>> . Yes, that is perfectly functional, but it is also very clunky.; Contrast this to the (automatic) pythonization:. .. code-block:: python. >>> for key, value in m:; ... print(value, end=' '); ...; 0 2 4 6 8 10 12 14 16 18; >>>. Such a pythonization can be written completely in Python using the bound C++; methods, with no intermediate language necessary.; Since it is written on abstract features, there is also only one such; pythonization that works for all STL map instantiations. Python callbacks; ----------------. Since bound C++ entities are fully functional Python ones, pythonization can; be done explicitly in an end-user facing Python module.; However, that would prevent lazy installation of pythonizations, so instead a; callback mechanism is provided. A callback is a function or callable object taking two arguments: the Python; proxy class to be pythonized and its C++ name.; The latter is provided to allow easy filtering.; This callback is then installed through ``cppyy.py.add_pythonization`` and; ideally only for the relevant namespace (installing callbacks for classes in; the global namespace is supported, but beware of name clashes). Pythonization is most effective of well-structured C++ libraries that have; idiomatic behaviors.; It is then straightforward to use Python reflection to write rules.; For example, consider this callback that looks for the conventional C++; function ``GetLength`` and replaces it with Python's ``__len__``:. .. code-block:: python. >>> import cppyy; >>>; >>> def replace_getlength(klass, name):; ... try:; ... klass.__len__ = klass.__dict__['GetLength']; ... del klass.GetLength; ... except KeyError:; ... pass; ...; >>> cppyy.py.add_pythonization(replace_getlength, 'MyNamespace'); >>>; >>> cppyy.cppdef(""""""; ... namespace MyNamespace {; ... class MyClass {; ... public:; ... MyClass(int i) : fInt(i) {}; ... int GetLength() { return fInt; }; ... ; ... private:; ... int fInt;; ... };; ... }""""""); True; >>",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/pythonizations.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/pythonizations.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/pythonizations.rst:1836,Deployability,install,installing,1836,"his to the (automatic) pythonization:. .. code-block:: python. >>> for key, value in m:; ... print(value, end=' '); ...; 0 2 4 6 8 10 12 14 16 18; >>>. Such a pythonization can be written completely in Python using the bound C++; methods, with no intermediate language necessary.; Since it is written on abstract features, there is also only one such; pythonization that works for all STL map instantiations. Python callbacks; ----------------. Since bound C++ entities are fully functional Python ones, pythonization can; be done explicitly in an end-user facing Python module.; However, that would prevent lazy installation of pythonizations, so instead a; callback mechanism is provided. A callback is a function or callable object taking two arguments: the Python; proxy class to be pythonized and its C++ name.; The latter is provided to allow easy filtering.; This callback is then installed through ``cppyy.py.add_pythonization`` and; ideally only for the relevant namespace (installing callbacks for classes in; the global namespace is supported, but beware of name clashes). Pythonization is most effective of well-structured C++ libraries that have; idiomatic behaviors.; It is then straightforward to use Python reflection to write rules.; For example, consider this callback that looks for the conventional C++; function ``GetLength`` and replaces it with Python's ``__len__``:. .. code-block:: python. >>> import cppyy; >>>; >>> def replace_getlength(klass, name):; ... try:; ... klass.__len__ = klass.__dict__['GetLength']; ... del klass.GetLength; ... except KeyError:; ... pass; ...; >>> cppyy.py.add_pythonization(replace_getlength, 'MyNamespace'); >>>; >>> cppyy.cppdef(""""""; ... namespace MyNamespace {; ... class MyClass {; ... public:; ... MyClass(int i) : fInt(i) {}; ... int GetLength() { return fInt; }; ... ; ... private:; ... int fInt;; ... };; ... }""""""); True; >>> m = cppyy.gbl.MyNamespace.MyClass(42); >>> len(m); 42; >>> m.GetLength(); Traceback (most recent call last):;",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/pythonizations.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/pythonizations.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/pythonizations.rst:4016,Integrability,protocol,protocols,4016," no attribute 'GetLength'; >>>. The deletion of ``GetLength`` method with ``del`` can be omitted; if both ``MyClass.GetLength`` and ``MyClass.__len__`` should be valid. C++ callbacks; -------------. If you are familiar with the Python C-API, it may sometimes be beneficial to; add unique optimizations to your C++ classes to be picked up by the; pythonization layer.; There are two conventional function that cppyy will look for (no registration; of callbacks needed):. .. code-block:: C++. static void __cppyy_explicit_pythonize__(PyObject* klass, const std::string&);. which is called *only* for the class that declares it.; And:. .. code-block:: C++. static void __cppyy_pythonize__(PyObject* klass, const std::string&);. which is also called for all derived classes. Just as with the Python callbacks, the first argument will be the Python; class proxy, the second the C++ name, for easy filtering.; When called, cppyy will be completely finished with the class proxy, so any; and all changes are fair game, including the low-level ones such as the replacement of; iteration or buffer protocols. An example pythonization replacing ``MyClass.GetLength`` method with Python's ``__len__``; done with the C++ callbacks:. .. code-block:: python. >>> import cppyy; >>> ; >>> cppyy.cppdef(""""""; ... #include <Python.h>; ...; ... namespace MyNamespace {; ... class MyClass {; ... public:; ... MyClass(int i) : fInt(i) {}; ... int GetLength() { return fInt; }; ... ; ... private:; ... int fInt;; ... ; ... // pythonizations; ... public:; ... static void __cppyy_pythonize__(PyObject* klass, const std::string&){; ... auto cppName = ""GetLength"";; ... auto pythonizationName = ""__len__"";; ... auto* methodObject = PyObject_GetAttrString(klass, cppName);; ... PyObject_SetAttrString(klass, pythonizationName, methodObject);; ... Py_DECREF(methodObject);; ... PyObject_DelAttrString(klass, cppName);; ... }; ... };; ... }""""""); True ; >>> m = cppyy.gbl.MyNamespace.MyClass(42); >>> len(m); 42; >>> m.GetLength();",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/pythonizations.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/pythonizations.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/pythonizations.rst:3215,Performance,optimiz,optimizations,3215,"ces it with Python's ``__len__``:. .. code-block:: python. >>> import cppyy; >>>; >>> def replace_getlength(klass, name):; ... try:; ... klass.__len__ = klass.__dict__['GetLength']; ... del klass.GetLength; ... except KeyError:; ... pass; ...; >>> cppyy.py.add_pythonization(replace_getlength, 'MyNamespace'); >>>; >>> cppyy.cppdef(""""""; ... namespace MyNamespace {; ... class MyClass {; ... public:; ... MyClass(int i) : fInt(i) {}; ... int GetLength() { return fInt; }; ... ; ... private:; ... int fInt;; ... };; ... }""""""); True; >>> m = cppyy.gbl.MyNamespace.MyClass(42); >>> len(m); 42; >>> m.GetLength(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; AttributeError: 'MyClass' object has no attribute 'GetLength'; >>>. The deletion of ``GetLength`` method with ``del`` can be omitted; if both ``MyClass.GetLength`` and ``MyClass.__len__`` should be valid. C++ callbacks; -------------. If you are familiar with the Python C-API, it may sometimes be beneficial to; add unique optimizations to your C++ classes to be picked up by the; pythonization layer.; There are two conventional function that cppyy will look for (no registration; of callbacks needed):. .. code-block:: C++. static void __cppyy_explicit_pythonize__(PyObject* klass, const std::string&);. which is called *only* for the class that declares it.; And:. .. code-block:: C++. static void __cppyy_pythonize__(PyObject* klass, const std::string&);. which is also called for all derived classes. Just as with the Python callbacks, the first argument will be the Python; class proxy, the second the C++ name, for easy filtering.; When called, cppyy will be completely finished with the class proxy, so any; and all changes are fair game, including the low-level ones such as the replacement of; iteration or buffer protocols. An example pythonization replacing ``MyClass.GetLength`` method with Python's ``__len__``; done with the C++ callbacks:. .. code-block:: python. >>> import cppyy; >>> ; >>> cppyy.cpp",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/pythonizations.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/pythonizations.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst:1297,Availability,down,downstream,1297,"cause of this layering and because it leverages several existing packages; through reuse, the relevant codes are contained across a number of; repositories. * Frontend, cppyy: https://github.com/wlav/cppyy; * CPython (v2/v3) intermediate: https://github.com/wlav/CPyCppyy; * PyPy intermediate (module _cppyy): https://foss.heptapod.net/pypy; * Backend, cppyy: https://github.com/wlav/cppyy-backend. The backend repo contains both the cppyy-cling (under ""cling"") and; cppyy-backend (under ""clingwrapper"") packages. .. _building_from_source:. Building from source; --------------------. Except for cppyy-cling, the structure in the repositories follows a normal; PyPA package and they are thus ready to build with `setuptools`_: simply; clone the package and either run ``python setup.py``, or use ``pip``. It is highly recommended to follow the dependency chain when manually; upgrading packages individually (i.e. ``cppyy-cling``, ``cppyy-backend``,; ``CPyCppyy`` if on CPython, and then finally ``cppyy``), because upstream; packages expose headers that are used by the ones downstream.; Of course, if only building for a patch/point release, there is no need to; re-install the full chain (or follow the order).; Always run the local updates from the package directories (i.e. where the; ``setup.py`` file is located), as some tools rely on the package structure. The ``STDCXX`` envar can be used to control the C++ standard version; use; ``MAKE`` to change the ``make`` command; and ``MAKE_NPROCS`` to control the; maximum number of parallel jobs.; Compilation of the backend, which contains a customized version of; Clang/LLVM, can take a long time, so by default the setup script will use all; cores (x2 if hyperthreading is enabled). On MS Windows, some temporary path names may be too long, causing the build to; fail.; To resolve this issue, point the ``TMP`` and ``TEMP`` envars to an existing; directory with a short name before the build:; For example::. > set TMP=C:\TMP; > set TEMP=C:\TM",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst:3359,Availability,down,downloads,3359,"Clang.; Consider therefore for a moment your reasons for building from source: there; being no pre-built wheel for the platform that you're interested in or simply; needing the latest version from the repository; or perhaps you are planning; to develop/modify the sources. If the former, clone the repository, check out a specific tagged release as; needed, then run the following steps to add Cling and build a wheel.; Once built, install the wheel as appropriate::. $ git clone https://github.com/wlav/cppyy-backend.git; $ cd cppyy-backend/cling; $ python setup.py egg_info; $ python create_src_directory.py; $ python setup.py bdist_wheel; $ python -m pip install dist/cppyy_cling-* --upgrade. .. note::; ``cppyy-cling`` wheels do not depend on the Python interpreter and can; thus be re-used for any version of Python or PyPy. The ``egg_info`` setup command is needed for ``create_src_directory.py`` to; find the right version.; That script in turn downloads the proper release from `upstream`_, trims and; patches it,; and installs the result in the ""src"" directory.; When done, the structure of ``cppyy-cling`` looks again like a PyPA package; and can be used/installed as expected, here done with ``pip``. By default, the setup script will use all cores (x2 if hyperthreading is; enabled).; You can change this behavior by setting the ``MAKE_NPROCS`` envar to the; desired number of allowable sub jobs. If on the other hand you are building from source to develop/modify; ``cppyy-cling``, consider using the ``cmake`` interface.; The first installation will still be just as slow, but subsequent builds can; be incremental and thus much faster.; For this use, first install the latest version from a pre-built wheel, which; will setup the proper directory structure, then use cmake to build and; install the latest or modified version of ``cppyy-cling`` into that::. $ python -m pip install cppyy-cling; $ git clone https://github.com/wlav/cppyy-backend.git; $ cd cppyy-backend/cling; $ python ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst:5951,Availability,avail,available,5951,"packages/cppyy_backend` in the virtual environment or other; installation location.; Adjust other options (esp. ``CMAKE_CXX_STANDARD``) as needed.; For the build command, adjust the ``cmake`` command as appropriate for your; favorite, or platform-specific, build system and/or use ``cmake --build``; instead of ``make`` directly.; See the `cmake documentation`_ for details. Next up is ``cppyy-backend`` (cppyy-backend, subdirectory ""clingwrapper""; omit; the first step if you already cloned the repo for ``cppyy-cling``)::. $ git clone https://github.com/wlav/cppyy-backend.git; $ cd cppyy-backend/clingwrapper; $ python -m pip install . --upgrade --no-use-pep517 --no-deps. Note the use of ``--no-use-pep517``, which prevents ``pip`` from needlessly; going out to pypi.org and creating a local ""clean"" build environment from the; cached or remote wheels.; Instead, by skipping PEP 517, the local installation will be used.; This is imperative if there was a change in public headers or if the version; of ``cppyy-cling`` was locally updated and is thus not available on PyPI. Upgrading ``CPyCppyy`` (if on CPython; it's not needed for PyPy) and ``cppyy``; is very similar::. $ git clone https://github.com/wlav/CPyCppyy.git; $ cd CPyCppyy; $ python -m pip install . --upgrade --no-use-pep517 --no-deps. Just like ``cppyy-cling``, ``CPyCppyy`` has ``cmake`` scripts which are the; recommended way for development, as incremental builds are faster::. $ mkdir build; $ cmake ../CPyCppyy; $ make -j <N>. then simply point the ``PYTHONPATH`` envar to the `build` directory above to; pick up the local `cppyy.so` module. Finally, the top-level package ``cppyy``::. $ git clone https://github.com/wlav/cppyy.git; $ cd cppyy; $ python -m pip install . --upgrade --no-deps. Please see the `pip documentation`_ for more options, such as developer mode. .. _`setuptools`: https://setuptools.readthedocs.io/; .. _`upstream`: https://root.cern.ch/download/; .. _`cmake documentation`: https://cmake.org/; .. _`pi",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst:6828,Availability,down,download,6828,"vironment or other; installation location.; Adjust other options (esp. ``CMAKE_CXX_STANDARD``) as needed.; For the build command, adjust the ``cmake`` command as appropriate for your; favorite, or platform-specific, build system and/or use ``cmake --build``; instead of ``make`` directly.; See the `cmake documentation`_ for details. Next up is ``cppyy-backend`` (cppyy-backend, subdirectory ""clingwrapper""; omit; the first step if you already cloned the repo for ``cppyy-cling``)::. $ git clone https://github.com/wlav/cppyy-backend.git; $ cd cppyy-backend/clingwrapper; $ python -m pip install . --upgrade --no-use-pep517 --no-deps. Note the use of ``--no-use-pep517``, which prevents ``pip`` from needlessly; going out to pypi.org and creating a local ""clean"" build environment from the; cached or remote wheels.; Instead, by skipping PEP 517, the local installation will be used.; This is imperative if there was a change in public headers or if the version; of ``cppyy-cling`` was locally updated and is thus not available on PyPI. Upgrading ``CPyCppyy`` (if on CPython; it's not needed for PyPy) and ``cppyy``; is very similar::. $ git clone https://github.com/wlav/CPyCppyy.git; $ cd CPyCppyy; $ python -m pip install . --upgrade --no-use-pep517 --no-deps. Just like ``cppyy-cling``, ``CPyCppyy`` has ``cmake`` scripts which are the; recommended way for development, as incremental builds are faster::. $ mkdir build; $ cmake ../CPyCppyy; $ make -j <N>. then simply point the ``PYTHONPATH`` envar to the `build` directory above to; pick up the local `cppyy.so` module. Finally, the top-level package ``cppyy``::. $ git clone https://github.com/wlav/cppyy.git; $ cd cppyy; $ python -m pip install . --upgrade --no-deps. Please see the `pip documentation`_ for more options, such as developer mode. .. _`setuptools`: https://setuptools.readthedocs.io/; .. _`upstream`: https://root.cern.ch/download/; .. _`cmake documentation`: https://cmake.org/; .. _`pip documentation`: https://pip.pypa.io/; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst:1344,Deployability,patch,patch,1344,"ories. * Frontend, cppyy: https://github.com/wlav/cppyy; * CPython (v2/v3) intermediate: https://github.com/wlav/CPyCppyy; * PyPy intermediate (module _cppyy): https://foss.heptapod.net/pypy; * Backend, cppyy: https://github.com/wlav/cppyy-backend. The backend repo contains both the cppyy-cling (under ""cling"") and; cppyy-backend (under ""clingwrapper"") packages. .. _building_from_source:. Building from source; --------------------. Except for cppyy-cling, the structure in the repositories follows a normal; PyPA package and they are thus ready to build with `setuptools`_: simply; clone the package and either run ``python setup.py``, or use ``pip``. It is highly recommended to follow the dependency chain when manually; upgrading packages individually (i.e. ``cppyy-cling``, ``cppyy-backend``,; ``CPyCppyy`` if on CPython, and then finally ``cppyy``), because upstream; packages expose headers that are used by the ones downstream.; Of course, if only building for a patch/point release, there is no need to; re-install the full chain (or follow the order).; Always run the local updates from the package directories (i.e. where the; ``setup.py`` file is located), as some tools rely on the package structure. The ``STDCXX`` envar can be used to control the C++ standard version; use; ``MAKE`` to change the ``make`` command; and ``MAKE_NPROCS`` to control the; maximum number of parallel jobs.; Compilation of the backend, which contains a customized version of; Clang/LLVM, can take a long time, so by default the setup script will use all; cores (x2 if hyperthreading is enabled). On MS Windows, some temporary path names may be too long, causing the build to; fail.; To resolve this issue, point the ``TMP`` and ``TEMP`` envars to an existing; directory with a short name before the build:; For example::. > set TMP=C:\TMP; > set TEMP=C:\TMP. The first package to build is ``cppyy-cling``.; It may take a long time, especially on a laptop (Mac ARM being a notable; exception), since Cling c",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst:1356,Deployability,release,release,1356,"ories. * Frontend, cppyy: https://github.com/wlav/cppyy; * CPython (v2/v3) intermediate: https://github.com/wlav/CPyCppyy; * PyPy intermediate (module _cppyy): https://foss.heptapod.net/pypy; * Backend, cppyy: https://github.com/wlav/cppyy-backend. The backend repo contains both the cppyy-cling (under ""cling"") and; cppyy-backend (under ""clingwrapper"") packages. .. _building_from_source:. Building from source; --------------------. Except for cppyy-cling, the structure in the repositories follows a normal; PyPA package and they are thus ready to build with `setuptools`_: simply; clone the package and either run ``python setup.py``, or use ``pip``. It is highly recommended to follow the dependency chain when manually; upgrading packages individually (i.e. ``cppyy-cling``, ``cppyy-backend``,; ``CPyCppyy`` if on CPython, and then finally ``cppyy``), because upstream; packages expose headers that are used by the ones downstream.; Of course, if only building for a patch/point release, there is no need to; re-install the full chain (or follow the order).; Always run the local updates from the package directories (i.e. where the; ``setup.py`` file is located), as some tools rely on the package structure. The ``STDCXX`` envar can be used to control the C++ standard version; use; ``MAKE`` to change the ``make`` command; and ``MAKE_NPROCS`` to control the; maximum number of parallel jobs.; Compilation of the backend, which contains a customized version of; Clang/LLVM, can take a long time, so by default the setup script will use all; cores (x2 if hyperthreading is enabled). On MS Windows, some temporary path names may be too long, causing the build to; fail.; To resolve this issue, point the ``TMP`` and ``TEMP`` envars to an existing; directory with a short name before the build:; For example::. > set TMP=C:\TMP; > set TEMP=C:\TMP. The first package to build is ``cppyy-cling``.; It may take a long time, especially on a laptop (Mac ARM being a notable; exception), since Cling c",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst:1389,Deployability,install,install,1389,"ories. * Frontend, cppyy: https://github.com/wlav/cppyy; * CPython (v2/v3) intermediate: https://github.com/wlav/CPyCppyy; * PyPy intermediate (module _cppyy): https://foss.heptapod.net/pypy; * Backend, cppyy: https://github.com/wlav/cppyy-backend. The backend repo contains both the cppyy-cling (under ""cling"") and; cppyy-backend (under ""clingwrapper"") packages. .. _building_from_source:. Building from source; --------------------. Except for cppyy-cling, the structure in the repositories follows a normal; PyPA package and they are thus ready to build with `setuptools`_: simply; clone the package and either run ``python setup.py``, or use ``pip``. It is highly recommended to follow the dependency chain when manually; upgrading packages individually (i.e. ``cppyy-cling``, ``cppyy-backend``,; ``CPyCppyy`` if on CPython, and then finally ``cppyy``), because upstream; packages expose headers that are used by the ones downstream.; Of course, if only building for a patch/point release, there is no need to; re-install the full chain (or follow the order).; Always run the local updates from the package directories (i.e. where the; ``setup.py`` file is located), as some tools rely on the package structure. The ``STDCXX`` envar can be used to control the C++ standard version; use; ``MAKE`` to change the ``make`` command; and ``MAKE_NPROCS`` to control the; maximum number of parallel jobs.; Compilation of the backend, which contains a customized version of; Clang/LLVM, can take a long time, so by default the setup script will use all; cores (x2 if hyperthreading is enabled). On MS Windows, some temporary path names may be too long, causing the build to; fail.; To resolve this issue, point the ``TMP`` and ``TEMP`` envars to an existing; directory with a short name before the build:; For example::. > set TMP=C:\TMP; > set TEMP=C:\TMP. The first package to build is ``cppyy-cling``.; It may take a long time, especially on a laptop (Mac ARM being a notable; exception), since Cling c",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst:1457,Deployability,update,updates,1457,"://github.com/wlav/CPyCppyy; * PyPy intermediate (module _cppyy): https://foss.heptapod.net/pypy; * Backend, cppyy: https://github.com/wlav/cppyy-backend. The backend repo contains both the cppyy-cling (under ""cling"") and; cppyy-backend (under ""clingwrapper"") packages. .. _building_from_source:. Building from source; --------------------. Except for cppyy-cling, the structure in the repositories follows a normal; PyPA package and they are thus ready to build with `setuptools`_: simply; clone the package and either run ``python setup.py``, or use ``pip``. It is highly recommended to follow the dependency chain when manually; upgrading packages individually (i.e. ``cppyy-cling``, ``cppyy-backend``,; ``CPyCppyy`` if on CPython, and then finally ``cppyy``), because upstream; packages expose headers that are used by the ones downstream.; Of course, if only building for a patch/point release, there is no need to; re-install the full chain (or follow the order).; Always run the local updates from the package directories (i.e. where the; ``setup.py`` file is located), as some tools rely on the package structure. The ``STDCXX`` envar can be used to control the C++ standard version; use; ``MAKE`` to change the ``make`` command; and ``MAKE_NPROCS`` to control the; maximum number of parallel jobs.; Compilation of the backend, which contains a customized version of; Clang/LLVM, can take a long time, so by default the setup script will use all; cores (x2 if hyperthreading is enabled). On MS Windows, some temporary path names may be too long, causing the build to; fail.; To resolve this issue, point the ``TMP`` and ``TEMP`` envars to an existing; directory with a short name before the build:; For example::. > set TMP=C:\TMP; > set TEMP=C:\TMP. The first package to build is ``cppyy-cling``.; It may take a long time, especially on a laptop (Mac ARM being a notable; exception), since Cling comes with a builtin version of LLVM/Clang.; Consider therefore for a moment your reasons for bu",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst:2745,Deployability,release,release,2745,"r of parallel jobs.; Compilation of the backend, which contains a customized version of; Clang/LLVM, can take a long time, so by default the setup script will use all; cores (x2 if hyperthreading is enabled). On MS Windows, some temporary path names may be too long, causing the build to; fail.; To resolve this issue, point the ``TMP`` and ``TEMP`` envars to an existing; directory with a short name before the build:; For example::. > set TMP=C:\TMP; > set TEMP=C:\TMP. The first package to build is ``cppyy-cling``.; It may take a long time, especially on a laptop (Mac ARM being a notable; exception), since Cling comes with a builtin version of LLVM/Clang.; Consider therefore for a moment your reasons for building from source: there; being no pre-built wheel for the platform that you're interested in or simply; needing the latest version from the repository; or perhaps you are planning; to develop/modify the sources. If the former, clone the repository, check out a specific tagged release as; needed, then run the following steps to add Cling and build a wheel.; Once built, install the wheel as appropriate::. $ git clone https://github.com/wlav/cppyy-backend.git; $ cd cppyy-backend/cling; $ python setup.py egg_info; $ python create_src_directory.py; $ python setup.py bdist_wheel; $ python -m pip install dist/cppyy_cling-* --upgrade. .. note::; ``cppyy-cling`` wheels do not depend on the Python interpreter and can; thus be re-used for any version of Python or PyPy. The ``egg_info`` setup command is needed for ``create_src_directory.py`` to; find the right version.; That script in turn downloads the proper release from `upstream`_, trims and; patches it,; and installs the result in the ""src"" directory.; When done, the structure of ``cppyy-cling`` looks again like a PyPA package; and can be used/installed as expected, here done with ``pip``. By default, the setup script will use all cores (x2 if hyperthreading is; enabled).; You can change this behavior by setting the ``MA",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst:2839,Deployability,install,install,2839,"VM, can take a long time, so by default the setup script will use all; cores (x2 if hyperthreading is enabled). On MS Windows, some temporary path names may be too long, causing the build to; fail.; To resolve this issue, point the ``TMP`` and ``TEMP`` envars to an existing; directory with a short name before the build:; For example::. > set TMP=C:\TMP; > set TEMP=C:\TMP. The first package to build is ``cppyy-cling``.; It may take a long time, especially on a laptop (Mac ARM being a notable; exception), since Cling comes with a builtin version of LLVM/Clang.; Consider therefore for a moment your reasons for building from source: there; being no pre-built wheel for the platform that you're interested in or simply; needing the latest version from the repository; or perhaps you are planning; to develop/modify the sources. If the former, clone the repository, check out a specific tagged release as; needed, then run the following steps to add Cling and build a wheel.; Once built, install the wheel as appropriate::. $ git clone https://github.com/wlav/cppyy-backend.git; $ cd cppyy-backend/cling; $ python setup.py egg_info; $ python create_src_directory.py; $ python setup.py bdist_wheel; $ python -m pip install dist/cppyy_cling-* --upgrade. .. note::; ``cppyy-cling`` wheels do not depend on the Python interpreter and can; thus be re-used for any version of Python or PyPy. The ``egg_info`` setup command is needed for ``create_src_directory.py`` to; find the right version.; That script in turn downloads the proper release from `upstream`_, trims and; patches it,; and installs the result in the ""src"" directory.; When done, the structure of ``cppyy-cling`` looks again like a PyPA package; and can be used/installed as expected, here done with ``pip``. By default, the setup script will use all cores (x2 if hyperthreading is; enabled).; You can change this behavior by setting the ``MAKE_NPROCS`` envar to the; desired number of allowable sub jobs. If on the other hand you are build",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst:3065,Deployability,install,install,3065,"ue, point the ``TMP`` and ``TEMP`` envars to an existing; directory with a short name before the build:; For example::. > set TMP=C:\TMP; > set TEMP=C:\TMP. The first package to build is ``cppyy-cling``.; It may take a long time, especially on a laptop (Mac ARM being a notable; exception), since Cling comes with a builtin version of LLVM/Clang.; Consider therefore for a moment your reasons for building from source: there; being no pre-built wheel for the platform that you're interested in or simply; needing the latest version from the repository; or perhaps you are planning; to develop/modify the sources. If the former, clone the repository, check out a specific tagged release as; needed, then run the following steps to add Cling and build a wheel.; Once built, install the wheel as appropriate::. $ git clone https://github.com/wlav/cppyy-backend.git; $ cd cppyy-backend/cling; $ python setup.py egg_info; $ python create_src_directory.py; $ python setup.py bdist_wheel; $ python -m pip install dist/cppyy_cling-* --upgrade. .. note::; ``cppyy-cling`` wheels do not depend on the Python interpreter and can; thus be re-used for any version of Python or PyPy. The ``egg_info`` setup command is needed for ``create_src_directory.py`` to; find the right version.; That script in turn downloads the proper release from `upstream`_, trims and; patches it,; and installs the result in the ""src"" directory.; When done, the structure of ``cppyy-cling`` looks again like a PyPA package; and can be used/installed as expected, here done with ``pip``. By default, the setup script will use all cores (x2 if hyperthreading is; enabled).; You can change this behavior by setting the ``MAKE_NPROCS`` envar to the; desired number of allowable sub jobs. If on the other hand you are building from source to develop/modify; ``cppyy-cling``, consider using the ``cmake`` interface.; The first installation will still be just as slow, but subsequent builds can; be incremental and thus much faster.; For this ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst:3094,Deployability,upgrade,upgrade,3094,"ue, point the ``TMP`` and ``TEMP`` envars to an existing; directory with a short name before the build:; For example::. > set TMP=C:\TMP; > set TEMP=C:\TMP. The first package to build is ``cppyy-cling``.; It may take a long time, especially on a laptop (Mac ARM being a notable; exception), since Cling comes with a builtin version of LLVM/Clang.; Consider therefore for a moment your reasons for building from source: there; being no pre-built wheel for the platform that you're interested in or simply; needing the latest version from the repository; or perhaps you are planning; to develop/modify the sources. If the former, clone the repository, check out a specific tagged release as; needed, then run the following steps to add Cling and build a wheel.; Once built, install the wheel as appropriate::. $ git clone https://github.com/wlav/cppyy-backend.git; $ cd cppyy-backend/cling; $ python setup.py egg_info; $ python create_src_directory.py; $ python setup.py bdist_wheel; $ python -m pip install dist/cppyy_cling-* --upgrade. .. note::; ``cppyy-cling`` wheels do not depend on the Python interpreter and can; thus be re-used for any version of Python or PyPy. The ``egg_info`` setup command is needed for ``create_src_directory.py`` to; find the right version.; That script in turn downloads the proper release from `upstream`_, trims and; patches it,; and installs the result in the ""src"" directory.; When done, the structure of ``cppyy-cling`` looks again like a PyPA package; and can be used/installed as expected, here done with ``pip``. By default, the setup script will use all cores (x2 if hyperthreading is; enabled).; You can change this behavior by setting the ``MAKE_NPROCS`` envar to the; desired number of allowable sub jobs. If on the other hand you are building from source to develop/modify; ``cppyy-cling``, consider using the ``cmake`` interface.; The first installation will still be just as slow, but subsequent builds can; be incremental and thus much faster.; For this ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst:3380,Deployability,release,release,3380,"Clang.; Consider therefore for a moment your reasons for building from source: there; being no pre-built wheel for the platform that you're interested in or simply; needing the latest version from the repository; or perhaps you are planning; to develop/modify the sources. If the former, clone the repository, check out a specific tagged release as; needed, then run the following steps to add Cling and build a wheel.; Once built, install the wheel as appropriate::. $ git clone https://github.com/wlav/cppyy-backend.git; $ cd cppyy-backend/cling; $ python setup.py egg_info; $ python create_src_directory.py; $ python setup.py bdist_wheel; $ python -m pip install dist/cppyy_cling-* --upgrade. .. note::; ``cppyy-cling`` wheels do not depend on the Python interpreter and can; thus be re-used for any version of Python or PyPy. The ``egg_info`` setup command is needed for ``create_src_directory.py`` to; find the right version.; That script in turn downloads the proper release from `upstream`_, trims and; patches it,; and installs the result in the ""src"" directory.; When done, the structure of ``cppyy-cling`` looks again like a PyPA package; and can be used/installed as expected, here done with ``pip``. By default, the setup script will use all cores (x2 if hyperthreading is; enabled).; You can change this behavior by setting the ``MAKE_NPROCS`` envar to the; desired number of allowable sub jobs. If on the other hand you are building from source to develop/modify; ``cppyy-cling``, consider using the ``cmake`` interface.; The first installation will still be just as slow, but subsequent builds can; be incremental and thus much faster.; For this use, first install the latest version from a pre-built wheel, which; will setup the proper directory structure, then use cmake to build and; install the latest or modified version of ``cppyy-cling`` into that::. $ python -m pip install cppyy-cling; $ git clone https://github.com/wlav/cppyy-backend.git; $ cd cppyy-backend/cling; $ python ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst:3417,Deployability,patch,patches,3417,"Clang.; Consider therefore for a moment your reasons for building from source: there; being no pre-built wheel for the platform that you're interested in or simply; needing the latest version from the repository; or perhaps you are planning; to develop/modify the sources. If the former, clone the repository, check out a specific tagged release as; needed, then run the following steps to add Cling and build a wheel.; Once built, install the wheel as appropriate::. $ git clone https://github.com/wlav/cppyy-backend.git; $ cd cppyy-backend/cling; $ python setup.py egg_info; $ python create_src_directory.py; $ python setup.py bdist_wheel; $ python -m pip install dist/cppyy_cling-* --upgrade. .. note::; ``cppyy-cling`` wheels do not depend on the Python interpreter and can; thus be re-used for any version of Python or PyPy. The ``egg_info`` setup command is needed for ``create_src_directory.py`` to; find the right version.; That script in turn downloads the proper release from `upstream`_, trims and; patches it,; and installs the result in the ""src"" directory.; When done, the structure of ``cppyy-cling`` looks again like a PyPA package; and can be used/installed as expected, here done with ``pip``. By default, the setup script will use all cores (x2 if hyperthreading is; enabled).; You can change this behavior by setting the ``MAKE_NPROCS`` envar to the; desired number of allowable sub jobs. If on the other hand you are building from source to develop/modify; ``cppyy-cling``, consider using the ``cmake`` interface.; The first installation will still be just as slow, but subsequent builds can; be incremental and thus much faster.; For this use, first install the latest version from a pre-built wheel, which; will setup the proper directory structure, then use cmake to build and; install the latest or modified version of ``cppyy-cling`` into that::. $ python -m pip install cppyy-cling; $ git clone https://github.com/wlav/cppyy-backend.git; $ cd cppyy-backend/cling; $ python ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst:3434,Deployability,install,installs,3434,"Clang.; Consider therefore for a moment your reasons for building from source: there; being no pre-built wheel for the platform that you're interested in or simply; needing the latest version from the repository; or perhaps you are planning; to develop/modify the sources. If the former, clone the repository, check out a specific tagged release as; needed, then run the following steps to add Cling and build a wheel.; Once built, install the wheel as appropriate::. $ git clone https://github.com/wlav/cppyy-backend.git; $ cd cppyy-backend/cling; $ python setup.py egg_info; $ python create_src_directory.py; $ python setup.py bdist_wheel; $ python -m pip install dist/cppyy_cling-* --upgrade. .. note::; ``cppyy-cling`` wheels do not depend on the Python interpreter and can; thus be re-used for any version of Python or PyPy. The ``egg_info`` setup command is needed for ``create_src_directory.py`` to; find the right version.; That script in turn downloads the proper release from `upstream`_, trims and; patches it,; and installs the result in the ""src"" directory.; When done, the structure of ``cppyy-cling`` looks again like a PyPA package; and can be used/installed as expected, here done with ``pip``. By default, the setup script will use all cores (x2 if hyperthreading is; enabled).; You can change this behavior by setting the ``MAKE_NPROCS`` envar to the; desired number of allowable sub jobs. If on the other hand you are building from source to develop/modify; ``cppyy-cling``, consider using the ``cmake`` interface.; The first installation will still be just as slow, but subsequent builds can; be incremental and thus much faster.; For this use, first install the latest version from a pre-built wheel, which; will setup the proper directory structure, then use cmake to build and; install the latest or modified version of ``cppyy-cling`` into that::. $ python -m pip install cppyy-cling; $ git clone https://github.com/wlav/cppyy-backend.git; $ cd cppyy-backend/cling; $ python ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst:3572,Deployability,install,installed,3572,"interested in or simply; needing the latest version from the repository; or perhaps you are planning; to develop/modify the sources. If the former, clone the repository, check out a specific tagged release as; needed, then run the following steps to add Cling and build a wheel.; Once built, install the wheel as appropriate::. $ git clone https://github.com/wlav/cppyy-backend.git; $ cd cppyy-backend/cling; $ python setup.py egg_info; $ python create_src_directory.py; $ python setup.py bdist_wheel; $ python -m pip install dist/cppyy_cling-* --upgrade. .. note::; ``cppyy-cling`` wheels do not depend on the Python interpreter and can; thus be re-used for any version of Python or PyPy. The ``egg_info`` setup command is needed for ``create_src_directory.py`` to; find the right version.; That script in turn downloads the proper release from `upstream`_, trims and; patches it,; and installs the result in the ""src"" directory.; When done, the structure of ``cppyy-cling`` looks again like a PyPA package; and can be used/installed as expected, here done with ``pip``. By default, the setup script will use all cores (x2 if hyperthreading is; enabled).; You can change this behavior by setting the ``MAKE_NPROCS`` envar to the; desired number of allowable sub jobs. If on the other hand you are building from source to develop/modify; ``cppyy-cling``, consider using the ``cmake`` interface.; The first installation will still be just as slow, but subsequent builds can; be incremental and thus much faster.; For this use, first install the latest version from a pre-built wheel, which; will setup the proper directory structure, then use cmake to build and; install the latest or modified version of ``cppyy-cling`` into that::. $ python -m pip install cppyy-cling; $ git clone https://github.com/wlav/cppyy-backend.git; $ cd cppyy-backend/cling; $ python setup.py egg_info; $ python create_src_directory.py; $ mkdir dev; $ cd dev; $ cmake ../src -Wno-dev -DCMAKE_CXX_STANDARD=17 -DLLVM_ENABLE_EH=",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst:3953,Deployability,install,installation,3953,"_src_directory.py; $ python setup.py bdist_wheel; $ python -m pip install dist/cppyy_cling-* --upgrade. .. note::; ``cppyy-cling`` wheels do not depend on the Python interpreter and can; thus be re-used for any version of Python or PyPy. The ``egg_info`` setup command is needed for ``create_src_directory.py`` to; find the right version.; That script in turn downloads the proper release from `upstream`_, trims and; patches it,; and installs the result in the ""src"" directory.; When done, the structure of ``cppyy-cling`` looks again like a PyPA package; and can be used/installed as expected, here done with ``pip``. By default, the setup script will use all cores (x2 if hyperthreading is; enabled).; You can change this behavior by setting the ``MAKE_NPROCS`` envar to the; desired number of allowable sub jobs. If on the other hand you are building from source to develop/modify; ``cppyy-cling``, consider using the ``cmake`` interface.; The first installation will still be just as slow, but subsequent builds can; be incremental and thus much faster.; For this use, first install the latest version from a pre-built wheel, which; will setup the proper directory structure, then use cmake to build and; install the latest or modified version of ``cppyy-cling`` into that::. $ python -m pip install cppyy-cling; $ git clone https://github.com/wlav/cppyy-backend.git; $ cd cppyy-backend/cling; $ python setup.py egg_info; $ python create_src_directory.py; $ mkdir dev; $ cd dev; $ cmake ../src -Wno-dev -DCMAKE_CXX_STANDARD=17 -DLLVM_ENABLE_EH=0 -DLLVM_ENABLE_RTTI=0 -DLLVM_ENABLE_TERMINFO=0 -DLLVM_ENABLE_ASSERTIONS=0 -Dminimal=ON -Druntime_cxxmodules=OFF -Dbuiltin_zlib=ON -Dbuiltin_cling=ON -DCMAKE_BUILD_TYPE=RelWithDebInfo -DCMAKE_INSTALL_PREFIX=<path to environment python site-packages>; $ make -j <N> install. where the ``cmake`` command needs to be given the full path to; `site-packages/cppyy_backend` in the virtual environment or other; installation location.; Adjust other options (",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst:4079,Deployability,install,install,4079,"erpreter and can; thus be re-used for any version of Python or PyPy. The ``egg_info`` setup command is needed for ``create_src_directory.py`` to; find the right version.; That script in turn downloads the proper release from `upstream`_, trims and; patches it,; and installs the result in the ""src"" directory.; When done, the structure of ``cppyy-cling`` looks again like a PyPA package; and can be used/installed as expected, here done with ``pip``. By default, the setup script will use all cores (x2 if hyperthreading is; enabled).; You can change this behavior by setting the ``MAKE_NPROCS`` envar to the; desired number of allowable sub jobs. If on the other hand you are building from source to develop/modify; ``cppyy-cling``, consider using the ``cmake`` interface.; The first installation will still be just as slow, but subsequent builds can; be incremental and thus much faster.; For this use, first install the latest version from a pre-built wheel, which; will setup the proper directory structure, then use cmake to build and; install the latest or modified version of ``cppyy-cling`` into that::. $ python -m pip install cppyy-cling; $ git clone https://github.com/wlav/cppyy-backend.git; $ cd cppyy-backend/cling; $ python setup.py egg_info; $ python create_src_directory.py; $ mkdir dev; $ cd dev; $ cmake ../src -Wno-dev -DCMAKE_CXX_STANDARD=17 -DLLVM_ENABLE_EH=0 -DLLVM_ENABLE_RTTI=0 -DLLVM_ENABLE_TERMINFO=0 -DLLVM_ENABLE_ASSERTIONS=0 -Dminimal=ON -Druntime_cxxmodules=OFF -Dbuiltin_zlib=ON -Dbuiltin_cling=ON -DCMAKE_BUILD_TYPE=RelWithDebInfo -DCMAKE_INSTALL_PREFIX=<path to environment python site-packages>; $ make -j <N> install. where the ``cmake`` command needs to be given the full path to; `site-packages/cppyy_backend` in the virtual environment or other; installation location.; Adjust other options (esp. ``CMAKE_CXX_STANDARD``) as needed.; For the build command, adjust the ``cmake`` command as appropriate for your; favorite, or platform-specific, build system and/or",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst:4209,Deployability,install,install,4209,"erpreter and can; thus be re-used for any version of Python or PyPy. The ``egg_info`` setup command is needed for ``create_src_directory.py`` to; find the right version.; That script in turn downloads the proper release from `upstream`_, trims and; patches it,; and installs the result in the ""src"" directory.; When done, the structure of ``cppyy-cling`` looks again like a PyPA package; and can be used/installed as expected, here done with ``pip``. By default, the setup script will use all cores (x2 if hyperthreading is; enabled).; You can change this behavior by setting the ``MAKE_NPROCS`` envar to the; desired number of allowable sub jobs. If on the other hand you are building from source to develop/modify; ``cppyy-cling``, consider using the ``cmake`` interface.; The first installation will still be just as slow, but subsequent builds can; be incremental and thus much faster.; For this use, first install the latest version from a pre-built wheel, which; will setup the proper directory structure, then use cmake to build and; install the latest or modified version of ``cppyy-cling`` into that::. $ python -m pip install cppyy-cling; $ git clone https://github.com/wlav/cppyy-backend.git; $ cd cppyy-backend/cling; $ python setup.py egg_info; $ python create_src_directory.py; $ mkdir dev; $ cd dev; $ cmake ../src -Wno-dev -DCMAKE_CXX_STANDARD=17 -DLLVM_ENABLE_EH=0 -DLLVM_ENABLE_RTTI=0 -DLLVM_ENABLE_TERMINFO=0 -DLLVM_ENABLE_ASSERTIONS=0 -Dminimal=ON -Druntime_cxxmodules=OFF -Dbuiltin_zlib=ON -Dbuiltin_cling=ON -DCMAKE_BUILD_TYPE=RelWithDebInfo -DCMAKE_INSTALL_PREFIX=<path to environment python site-packages>; $ make -j <N> install. where the ``cmake`` command needs to be given the full path to; `site-packages/cppyy_backend` in the virtual environment or other; installation location.; Adjust other options (esp. ``CMAKE_CXX_STANDARD``) as needed.; For the build command, adjust the ``cmake`` command as appropriate for your; favorite, or platform-specific, build system and/or",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst:4296,Deployability,install,install,4296,"o; find the right version.; That script in turn downloads the proper release from `upstream`_, trims and; patches it,; and installs the result in the ""src"" directory.; When done, the structure of ``cppyy-cling`` looks again like a PyPA package; and can be used/installed as expected, here done with ``pip``. By default, the setup script will use all cores (x2 if hyperthreading is; enabled).; You can change this behavior by setting the ``MAKE_NPROCS`` envar to the; desired number of allowable sub jobs. If on the other hand you are building from source to develop/modify; ``cppyy-cling``, consider using the ``cmake`` interface.; The first installation will still be just as slow, but subsequent builds can; be incremental and thus much faster.; For this use, first install the latest version from a pre-built wheel, which; will setup the proper directory structure, then use cmake to build and; install the latest or modified version of ``cppyy-cling`` into that::. $ python -m pip install cppyy-cling; $ git clone https://github.com/wlav/cppyy-backend.git; $ cd cppyy-backend/cling; $ python setup.py egg_info; $ python create_src_directory.py; $ mkdir dev; $ cd dev; $ cmake ../src -Wno-dev -DCMAKE_CXX_STANDARD=17 -DLLVM_ENABLE_EH=0 -DLLVM_ENABLE_RTTI=0 -DLLVM_ENABLE_TERMINFO=0 -DLLVM_ENABLE_ASSERTIONS=0 -Dminimal=ON -Druntime_cxxmodules=OFF -Dbuiltin_zlib=ON -Dbuiltin_cling=ON -DCMAKE_BUILD_TYPE=RelWithDebInfo -DCMAKE_INSTALL_PREFIX=<path to environment python site-packages>; $ make -j <N> install. where the ``cmake`` command needs to be given the full path to; `site-packages/cppyy_backend` in the virtual environment or other; installation location.; Adjust other options (esp. ``CMAKE_CXX_STANDARD``) as needed.; For the build command, adjust the ``cmake`` command as appropriate for your; favorite, or platform-specific, build system and/or use ``cmake --build``; instead of ``make`` directly.; See the `cmake documentation`_ for details. Next up is ``cppyy-backend`` (cppyy-backend, ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst:4813,Deployability,install,install,4813,"all cores (x2 if hyperthreading is; enabled).; You can change this behavior by setting the ``MAKE_NPROCS`` envar to the; desired number of allowable sub jobs. If on the other hand you are building from source to develop/modify; ``cppyy-cling``, consider using the ``cmake`` interface.; The first installation will still be just as slow, but subsequent builds can; be incremental and thus much faster.; For this use, first install the latest version from a pre-built wheel, which; will setup the proper directory structure, then use cmake to build and; install the latest or modified version of ``cppyy-cling`` into that::. $ python -m pip install cppyy-cling; $ git clone https://github.com/wlav/cppyy-backend.git; $ cd cppyy-backend/cling; $ python setup.py egg_info; $ python create_src_directory.py; $ mkdir dev; $ cd dev; $ cmake ../src -Wno-dev -DCMAKE_CXX_STANDARD=17 -DLLVM_ENABLE_EH=0 -DLLVM_ENABLE_RTTI=0 -DLLVM_ENABLE_TERMINFO=0 -DLLVM_ENABLE_ASSERTIONS=0 -Dminimal=ON -Druntime_cxxmodules=OFF -Dbuiltin_zlib=ON -Dbuiltin_cling=ON -DCMAKE_BUILD_TYPE=RelWithDebInfo -DCMAKE_INSTALL_PREFIX=<path to environment python site-packages>; $ make -j <N> install. where the ``cmake`` command needs to be given the full path to; `site-packages/cppyy_backend` in the virtual environment or other; installation location.; Adjust other options (esp. ``CMAKE_CXX_STANDARD``) as needed.; For the build command, adjust the ``cmake`` command as appropriate for your; favorite, or platform-specific, build system and/or use ``cmake --build``; instead of ``make`` directly.; See the `cmake documentation`_ for details. Next up is ``cppyy-backend`` (cppyy-backend, subdirectory ""clingwrapper""; omit; the first step if you already cloned the repo for ``cppyy-cling``)::. $ git clone https://github.com/wlav/cppyy-backend.git; $ cd cppyy-backend/clingwrapper; $ python -m pip install . --upgrade --no-use-pep517 --no-deps. Note the use of ``--no-use-pep517``, which prevents ``pip`` from needlessly; going out to",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst:4953,Deployability,install,installation,4953,"``, consider using the ``cmake`` interface.; The first installation will still be just as slow, but subsequent builds can; be incremental and thus much faster.; For this use, first install the latest version from a pre-built wheel, which; will setup the proper directory structure, then use cmake to build and; install the latest or modified version of ``cppyy-cling`` into that::. $ python -m pip install cppyy-cling; $ git clone https://github.com/wlav/cppyy-backend.git; $ cd cppyy-backend/cling; $ python setup.py egg_info; $ python create_src_directory.py; $ mkdir dev; $ cd dev; $ cmake ../src -Wno-dev -DCMAKE_CXX_STANDARD=17 -DLLVM_ENABLE_EH=0 -DLLVM_ENABLE_RTTI=0 -DLLVM_ENABLE_TERMINFO=0 -DLLVM_ENABLE_ASSERTIONS=0 -Dminimal=ON -Druntime_cxxmodules=OFF -Dbuiltin_zlib=ON -Dbuiltin_cling=ON -DCMAKE_BUILD_TYPE=RelWithDebInfo -DCMAKE_INSTALL_PREFIX=<path to environment python site-packages>; $ make -j <N> install. where the ``cmake`` command needs to be given the full path to; `site-packages/cppyy_backend` in the virtual environment or other; installation location.; Adjust other options (esp. ``CMAKE_CXX_STANDARD``) as needed.; For the build command, adjust the ``cmake`` command as appropriate for your; favorite, or platform-specific, build system and/or use ``cmake --build``; instead of ``make`` directly.; See the `cmake documentation`_ for details. Next up is ``cppyy-backend`` (cppyy-backend, subdirectory ""clingwrapper""; omit; the first step if you already cloned the repo for ``cppyy-cling``)::. $ git clone https://github.com/wlav/cppyy-backend.git; $ cd cppyy-backend/clingwrapper; $ python -m pip install . --upgrade --no-use-pep517 --no-deps. Note the use of ``--no-use-pep517``, which prevents ``pip`` from needlessly; going out to pypi.org and creating a local ""clean"" build environment from the; cached or remote wheels.; Instead, by skipping PEP 517, the local installation will be used.; This is imperative if there was a change in public headers or if the version; of",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst:5521,Deployability,install,install,5521,"-Wno-dev -DCMAKE_CXX_STANDARD=17 -DLLVM_ENABLE_EH=0 -DLLVM_ENABLE_RTTI=0 -DLLVM_ENABLE_TERMINFO=0 -DLLVM_ENABLE_ASSERTIONS=0 -Dminimal=ON -Druntime_cxxmodules=OFF -Dbuiltin_zlib=ON -Dbuiltin_cling=ON -DCMAKE_BUILD_TYPE=RelWithDebInfo -DCMAKE_INSTALL_PREFIX=<path to environment python site-packages>; $ make -j <N> install. where the ``cmake`` command needs to be given the full path to; `site-packages/cppyy_backend` in the virtual environment or other; installation location.; Adjust other options (esp. ``CMAKE_CXX_STANDARD``) as needed.; For the build command, adjust the ``cmake`` command as appropriate for your; favorite, or platform-specific, build system and/or use ``cmake --build``; instead of ``make`` directly.; See the `cmake documentation`_ for details. Next up is ``cppyy-backend`` (cppyy-backend, subdirectory ""clingwrapper""; omit; the first step if you already cloned the repo for ``cppyy-cling``)::. $ git clone https://github.com/wlav/cppyy-backend.git; $ cd cppyy-backend/clingwrapper; $ python -m pip install . --upgrade --no-use-pep517 --no-deps. Note the use of ``--no-use-pep517``, which prevents ``pip`` from needlessly; going out to pypi.org and creating a local ""clean"" build environment from the; cached or remote wheels.; Instead, by skipping PEP 517, the local installation will be used.; This is imperative if there was a change in public headers or if the version; of ``cppyy-cling`` was locally updated and is thus not available on PyPI. Upgrading ``CPyCppyy`` (if on CPython; it's not needed for PyPy) and ``cppyy``; is very similar::. $ git clone https://github.com/wlav/CPyCppyy.git; $ cd CPyCppyy; $ python -m pip install . --upgrade --no-use-pep517 --no-deps. Just like ``cppyy-cling``, ``CPyCppyy`` has ``cmake`` scripts which are the; recommended way for development, as incremental builds are faster::. $ mkdir build; $ cmake ../CPyCppyy; $ make -j <N>. then simply point the ``PYTHONPATH`` envar to the `build` directory above to; pick up the local `cppyy.so",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst:5533,Deployability,upgrade,upgrade,5533,"0 -DLLVM_ENABLE_RTTI=0 -DLLVM_ENABLE_TERMINFO=0 -DLLVM_ENABLE_ASSERTIONS=0 -Dminimal=ON -Druntime_cxxmodules=OFF -Dbuiltin_zlib=ON -Dbuiltin_cling=ON -DCMAKE_BUILD_TYPE=RelWithDebInfo -DCMAKE_INSTALL_PREFIX=<path to environment python site-packages>; $ make -j <N> install. where the ``cmake`` command needs to be given the full path to; `site-packages/cppyy_backend` in the virtual environment or other; installation location.; Adjust other options (esp. ``CMAKE_CXX_STANDARD``) as needed.; For the build command, adjust the ``cmake`` command as appropriate for your; favorite, or platform-specific, build system and/or use ``cmake --build``; instead of ``make`` directly.; See the `cmake documentation`_ for details. Next up is ``cppyy-backend`` (cppyy-backend, subdirectory ""clingwrapper""; omit; the first step if you already cloned the repo for ``cppyy-cling``)::. $ git clone https://github.com/wlav/cppyy-backend.git; $ cd cppyy-backend/clingwrapper; $ python -m pip install . --upgrade --no-use-pep517 --no-deps. Note the use of ``--no-use-pep517``, which prevents ``pip`` from needlessly; going out to pypi.org and creating a local ""clean"" build environment from the; cached or remote wheels.; Instead, by skipping PEP 517, the local installation will be used.; This is imperative if there was a change in public headers or if the version; of ``cppyy-cling`` was locally updated and is thus not available on PyPI. Upgrading ``CPyCppyy`` (if on CPython; it's not needed for PyPy) and ``cppyy``; is very similar::. $ git clone https://github.com/wlav/CPyCppyy.git; $ cd CPyCppyy; $ python -m pip install . --upgrade --no-use-pep517 --no-deps. Just like ``cppyy-cling``, ``CPyCppyy`` has ``cmake`` scripts which are the; recommended way for development, as incremental builds are faster::. $ mkdir build; $ cmake ../CPyCppyy; $ make -j <N>. then simply point the ``PYTHONPATH`` envar to the `build` directory above to; pick up the local `cppyy.so` module. Finally, the top-level package ``cppyy``",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst:5790,Deployability,install,installation,5790," site-packages>; $ make -j <N> install. where the ``cmake`` command needs to be given the full path to; `site-packages/cppyy_backend` in the virtual environment or other; installation location.; Adjust other options (esp. ``CMAKE_CXX_STANDARD``) as needed.; For the build command, adjust the ``cmake`` command as appropriate for your; favorite, or platform-specific, build system and/or use ``cmake --build``; instead of ``make`` directly.; See the `cmake documentation`_ for details. Next up is ``cppyy-backend`` (cppyy-backend, subdirectory ""clingwrapper""; omit; the first step if you already cloned the repo for ``cppyy-cling``)::. $ git clone https://github.com/wlav/cppyy-backend.git; $ cd cppyy-backend/clingwrapper; $ python -m pip install . --upgrade --no-use-pep517 --no-deps. Note the use of ``--no-use-pep517``, which prevents ``pip`` from needlessly; going out to pypi.org and creating a local ""clean"" build environment from the; cached or remote wheels.; Instead, by skipping PEP 517, the local installation will be used.; This is imperative if there was a change in public headers or if the version; of ``cppyy-cling`` was locally updated and is thus not available on PyPI. Upgrading ``CPyCppyy`` (if on CPython; it's not needed for PyPy) and ``cppyy``; is very similar::. $ git clone https://github.com/wlav/CPyCppyy.git; $ cd CPyCppyy; $ python -m pip install . --upgrade --no-use-pep517 --no-deps. Just like ``cppyy-cling``, ``CPyCppyy`` has ``cmake`` scripts which are the; recommended way for development, as incremental builds are faster::. $ mkdir build; $ cmake ../CPyCppyy; $ make -j <N>. then simply point the ``PYTHONPATH`` envar to the `build` directory above to; pick up the local `cppyy.so` module. Finally, the top-level package ``cppyy``::. $ git clone https://github.com/wlav/cppyy.git; $ cd cppyy; $ python -m pip install . --upgrade --no-deps. Please see the `pip documentation`_ for more options, such as developer mode. .. _`setuptools`: https://setuptools.readthed",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst:5927,Deployability,update,updated,5927,"packages/cppyy_backend` in the virtual environment or other; installation location.; Adjust other options (esp. ``CMAKE_CXX_STANDARD``) as needed.; For the build command, adjust the ``cmake`` command as appropriate for your; favorite, or platform-specific, build system and/or use ``cmake --build``; instead of ``make`` directly.; See the `cmake documentation`_ for details. Next up is ``cppyy-backend`` (cppyy-backend, subdirectory ""clingwrapper""; omit; the first step if you already cloned the repo for ``cppyy-cling``)::. $ git clone https://github.com/wlav/cppyy-backend.git; $ cd cppyy-backend/clingwrapper; $ python -m pip install . --upgrade --no-use-pep517 --no-deps. Note the use of ``--no-use-pep517``, which prevents ``pip`` from needlessly; going out to pypi.org and creating a local ""clean"" build environment from the; cached or remote wheels.; Instead, by skipping PEP 517, the local installation will be used.; This is imperative if there was a change in public headers or if the version; of ``cppyy-cling`` was locally updated and is thus not available on PyPI. Upgrading ``CPyCppyy`` (if on CPython; it's not needed for PyPy) and ``cppyy``; is very similar::. $ git clone https://github.com/wlav/CPyCppyy.git; $ cd CPyCppyy; $ python -m pip install . --upgrade --no-use-pep517 --no-deps. Just like ``cppyy-cling``, ``CPyCppyy`` has ``cmake`` scripts which are the; recommended way for development, as incremental builds are faster::. $ mkdir build; $ cmake ../CPyCppyy; $ make -j <N>. then simply point the ``PYTHONPATH`` envar to the `build` directory above to; pick up the local `cppyy.so` module. Finally, the top-level package ``cppyy``::. $ git clone https://github.com/wlav/cppyy.git; $ cd cppyy; $ python -m pip install . --upgrade --no-deps. Please see the `pip documentation`_ for more options, such as developer mode. .. _`setuptools`: https://setuptools.readthedocs.io/; .. _`upstream`: https://root.cern.ch/download/; .. _`cmake documentation`: https://cmake.org/; .. _`pi",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst:6150,Deployability,install,install,6150,"vironment or other; installation location.; Adjust other options (esp. ``CMAKE_CXX_STANDARD``) as needed.; For the build command, adjust the ``cmake`` command as appropriate for your; favorite, or platform-specific, build system and/or use ``cmake --build``; instead of ``make`` directly.; See the `cmake documentation`_ for details. Next up is ``cppyy-backend`` (cppyy-backend, subdirectory ""clingwrapper""; omit; the first step if you already cloned the repo for ``cppyy-cling``)::. $ git clone https://github.com/wlav/cppyy-backend.git; $ cd cppyy-backend/clingwrapper; $ python -m pip install . --upgrade --no-use-pep517 --no-deps. Note the use of ``--no-use-pep517``, which prevents ``pip`` from needlessly; going out to pypi.org and creating a local ""clean"" build environment from the; cached or remote wheels.; Instead, by skipping PEP 517, the local installation will be used.; This is imperative if there was a change in public headers or if the version; of ``cppyy-cling`` was locally updated and is thus not available on PyPI. Upgrading ``CPyCppyy`` (if on CPython; it's not needed for PyPy) and ``cppyy``; is very similar::. $ git clone https://github.com/wlav/CPyCppyy.git; $ cd CPyCppyy; $ python -m pip install . --upgrade --no-use-pep517 --no-deps. Just like ``cppyy-cling``, ``CPyCppyy`` has ``cmake`` scripts which are the; recommended way for development, as incremental builds are faster::. $ mkdir build; $ cmake ../CPyCppyy; $ make -j <N>. then simply point the ``PYTHONPATH`` envar to the `build` directory above to; pick up the local `cppyy.so` module. Finally, the top-level package ``cppyy``::. $ git clone https://github.com/wlav/cppyy.git; $ cd cppyy; $ python -m pip install . --upgrade --no-deps. Please see the `pip documentation`_ for more options, such as developer mode. .. _`setuptools`: https://setuptools.readthedocs.io/; .. _`upstream`: https://root.cern.ch/download/; .. _`cmake documentation`: https://cmake.org/; .. _`pip documentation`: https://pip.pypa.io/; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst:6162,Deployability,upgrade,upgrade,6162,"vironment or other; installation location.; Adjust other options (esp. ``CMAKE_CXX_STANDARD``) as needed.; For the build command, adjust the ``cmake`` command as appropriate for your; favorite, or platform-specific, build system and/or use ``cmake --build``; instead of ``make`` directly.; See the `cmake documentation`_ for details. Next up is ``cppyy-backend`` (cppyy-backend, subdirectory ""clingwrapper""; omit; the first step if you already cloned the repo for ``cppyy-cling``)::. $ git clone https://github.com/wlav/cppyy-backend.git; $ cd cppyy-backend/clingwrapper; $ python -m pip install . --upgrade --no-use-pep517 --no-deps. Note the use of ``--no-use-pep517``, which prevents ``pip`` from needlessly; going out to pypi.org and creating a local ""clean"" build environment from the; cached or remote wheels.; Instead, by skipping PEP 517, the local installation will be used.; This is imperative if there was a change in public headers or if the version; of ``cppyy-cling`` was locally updated and is thus not available on PyPI. Upgrading ``CPyCppyy`` (if on CPython; it's not needed for PyPy) and ``cppyy``; is very similar::. $ git clone https://github.com/wlav/CPyCppyy.git; $ cd CPyCppyy; $ python -m pip install . --upgrade --no-use-pep517 --no-deps. Just like ``cppyy-cling``, ``CPyCppyy`` has ``cmake`` scripts which are the; recommended way for development, as incremental builds are faster::. $ mkdir build; $ cmake ../CPyCppyy; $ make -j <N>. then simply point the ``PYTHONPATH`` envar to the `build` directory above to; pick up the local `cppyy.so` module. Finally, the top-level package ``cppyy``::. $ git clone https://github.com/wlav/cppyy.git; $ cd cppyy; $ python -m pip install . --upgrade --no-deps. Please see the `pip documentation`_ for more options, such as developer mode. .. _`setuptools`: https://setuptools.readthedocs.io/; .. _`upstream`: https://root.cern.ch/download/; .. _`cmake documentation`: https://cmake.org/; .. _`pip documentation`: https://pip.pypa.io/; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst:6628,Deployability,install,install,6628,"vironment or other; installation location.; Adjust other options (esp. ``CMAKE_CXX_STANDARD``) as needed.; For the build command, adjust the ``cmake`` command as appropriate for your; favorite, or platform-specific, build system and/or use ``cmake --build``; instead of ``make`` directly.; See the `cmake documentation`_ for details. Next up is ``cppyy-backend`` (cppyy-backend, subdirectory ""clingwrapper""; omit; the first step if you already cloned the repo for ``cppyy-cling``)::. $ git clone https://github.com/wlav/cppyy-backend.git; $ cd cppyy-backend/clingwrapper; $ python -m pip install . --upgrade --no-use-pep517 --no-deps. Note the use of ``--no-use-pep517``, which prevents ``pip`` from needlessly; going out to pypi.org and creating a local ""clean"" build environment from the; cached or remote wheels.; Instead, by skipping PEP 517, the local installation will be used.; This is imperative if there was a change in public headers or if the version; of ``cppyy-cling`` was locally updated and is thus not available on PyPI. Upgrading ``CPyCppyy`` (if on CPython; it's not needed for PyPy) and ``cppyy``; is very similar::. $ git clone https://github.com/wlav/CPyCppyy.git; $ cd CPyCppyy; $ python -m pip install . --upgrade --no-use-pep517 --no-deps. Just like ``cppyy-cling``, ``CPyCppyy`` has ``cmake`` scripts which are the; recommended way for development, as incremental builds are faster::. $ mkdir build; $ cmake ../CPyCppyy; $ make -j <N>. then simply point the ``PYTHONPATH`` envar to the `build` directory above to; pick up the local `cppyy.so` module. Finally, the top-level package ``cppyy``::. $ git clone https://github.com/wlav/cppyy.git; $ cd cppyy; $ python -m pip install . --upgrade --no-deps. Please see the `pip documentation`_ for more options, such as developer mode. .. _`setuptools`: https://setuptools.readthedocs.io/; .. _`upstream`: https://root.cern.ch/download/; .. _`cmake documentation`: https://cmake.org/; .. _`pip documentation`: https://pip.pypa.io/; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst:6640,Deployability,upgrade,upgrade,6640,"vironment or other; installation location.; Adjust other options (esp. ``CMAKE_CXX_STANDARD``) as needed.; For the build command, adjust the ``cmake`` command as appropriate for your; favorite, or platform-specific, build system and/or use ``cmake --build``; instead of ``make`` directly.; See the `cmake documentation`_ for details. Next up is ``cppyy-backend`` (cppyy-backend, subdirectory ""clingwrapper""; omit; the first step if you already cloned the repo for ``cppyy-cling``)::. $ git clone https://github.com/wlav/cppyy-backend.git; $ cd cppyy-backend/clingwrapper; $ python -m pip install . --upgrade --no-use-pep517 --no-deps. Note the use of ``--no-use-pep517``, which prevents ``pip`` from needlessly; going out to pypi.org and creating a local ""clean"" build environment from the; cached or remote wheels.; Instead, by skipping PEP 517, the local installation will be used.; This is imperative if there was a change in public headers or if the version; of ``cppyy-cling`` was locally updated and is thus not available on PyPI. Upgrading ``CPyCppyy`` (if on CPython; it's not needed for PyPy) and ``cppyy``; is very similar::. $ git clone https://github.com/wlav/CPyCppyy.git; $ cd CPyCppyy; $ python -m pip install . --upgrade --no-use-pep517 --no-deps. Just like ``cppyy-cling``, ``CPyCppyy`` has ``cmake`` scripts which are the; recommended way for development, as incremental builds are faster::. $ mkdir build; $ cmake ../CPyCppyy; $ make -j <N>. then simply point the ``PYTHONPATH`` envar to the `build` directory above to; pick up the local `cppyy.so` module. Finally, the top-level package ``cppyy``::. $ git clone https://github.com/wlav/cppyy.git; $ cd cppyy; $ python -m pip install . --upgrade --no-deps. Please see the `pip documentation`_ for more options, such as developer mode. .. _`setuptools`: https://setuptools.readthedocs.io/; .. _`upstream`: https://root.cern.ch/download/; .. _`cmake documentation`: https://cmake.org/; .. _`pip documentation`: https://pip.pypa.io/; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst:133,Integrability,depend,dependent,133,".. _repositories:. Repositories; ============. The ``cppyy`` module is a frontend that requires an intermediate (Python; interpreter dependent) layer, and a backend (see; :ref:`Package Structure <package-structure>`).; Because of this layering and because it leverages several existing packages; through reuse, the relevant codes are contained across a number of; repositories. * Frontend, cppyy: https://github.com/wlav/cppyy; * CPython (v2/v3) intermediate: https://github.com/wlav/CPyCppyy; * PyPy intermediate (module _cppyy): https://foss.heptapod.net/pypy; * Backend, cppyy: https://github.com/wlav/cppyy-backend. The backend repo contains both the cppyy-cling (under ""cling"") and; cppyy-backend (under ""clingwrapper"") packages. .. _building_from_source:. Building from source; --------------------. Except for cppyy-cling, the structure in the repositories follows a normal; PyPA package and they are thus ready to build with `setuptools`_: simply; clone the package and either run ``python setup.py``, or use ``pip``. It is highly recommended to follow the dependency chain when manually; upgrading packages individually (i.e. ``cppyy-cling``, ``cppyy-backend``,; ``CPyCppyy`` if on CPython, and then finally ``cppyy``), because upstream; packages expose headers that are used by the ones downstream.; Of course, if only building for a patch/point release, there is no need to; re-install the full chain (or follow the order).; Always run the local updates from the package directories (i.e. where the; ``setup.py`` file is located), as some tools rely on the package structure. The ``STDCXX`` envar can be used to control the C++ standard version; use; ``MAKE`` to change the ``make`` command; and ``MAKE_NPROCS`` to control the; maximum number of parallel jobs.; Compilation of the backend, which contains a customized version of; Clang/LLVM, can take a long time, so by default the setup script will use all; cores (x2 if hyperthreading is enabled). On MS Windows, some temporary path names",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst:1065,Integrability,depend,dependency,1065,"end that requires an intermediate (Python; interpreter dependent) layer, and a backend (see; :ref:`Package Structure <package-structure>`).; Because of this layering and because it leverages several existing packages; through reuse, the relevant codes are contained across a number of; repositories. * Frontend, cppyy: https://github.com/wlav/cppyy; * CPython (v2/v3) intermediate: https://github.com/wlav/CPyCppyy; * PyPy intermediate (module _cppyy): https://foss.heptapod.net/pypy; * Backend, cppyy: https://github.com/wlav/cppyy-backend. The backend repo contains both the cppyy-cling (under ""cling"") and; cppyy-backend (under ""clingwrapper"") packages. .. _building_from_source:. Building from source; --------------------. Except for cppyy-cling, the structure in the repositories follows a normal; PyPA package and they are thus ready to build with `setuptools`_: simply; clone the package and either run ``python setup.py``, or use ``pip``. It is highly recommended to follow the dependency chain when manually; upgrading packages individually (i.e. ``cppyy-cling``, ``cppyy-backend``,; ``CPyCppyy`` if on CPython, and then finally ``cppyy``), because upstream; packages expose headers that are used by the ones downstream.; Of course, if only building for a patch/point release, there is no need to; re-install the full chain (or follow the order).; Always run the local updates from the package directories (i.e. where the; ``setup.py`` file is located), as some tools rely on the package structure. The ``STDCXX`` envar can be used to control the C++ standard version; use; ``MAKE`` to change the ``make`` command; and ``MAKE_NPROCS`` to control the; maximum number of parallel jobs.; Compilation of the backend, which contains a customized version of; Clang/LLVM, can take a long time, so by default the setup script will use all; cores (x2 if hyperthreading is enabled). On MS Windows, some temporary path names may be too long, causing the build to; fail.; To resolve this issue, point th",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst:3144,Integrability,depend,depend,3144,"; For example::. > set TMP=C:\TMP; > set TEMP=C:\TMP. The first package to build is ``cppyy-cling``.; It may take a long time, especially on a laptop (Mac ARM being a notable; exception), since Cling comes with a builtin version of LLVM/Clang.; Consider therefore for a moment your reasons for building from source: there; being no pre-built wheel for the platform that you're interested in or simply; needing the latest version from the repository; or perhaps you are planning; to develop/modify the sources. If the former, clone the repository, check out a specific tagged release as; needed, then run the following steps to add Cling and build a wheel.; Once built, install the wheel as appropriate::. $ git clone https://github.com/wlav/cppyy-backend.git; $ cd cppyy-backend/cling; $ python setup.py egg_info; $ python create_src_directory.py; $ python setup.py bdist_wheel; $ python -m pip install dist/cppyy_cling-* --upgrade. .. note::; ``cppyy-cling`` wheels do not depend on the Python interpreter and can; thus be re-used for any version of Python or PyPy. The ``egg_info`` setup command is needed for ``create_src_directory.py`` to; find the right version.; That script in turn downloads the proper release from `upstream`_, trims and; patches it,; and installs the result in the ""src"" directory.; When done, the structure of ``cppyy-cling`` looks again like a PyPA package; and can be used/installed as expected, here done with ``pip``. By default, the setup script will use all cores (x2 if hyperthreading is; enabled).; You can change this behavior by setting the ``MAKE_NPROCS`` envar to the; desired number of allowable sub jobs. If on the other hand you are building from source to develop/modify; ``cppyy-cling``, consider using the ``cmake`` interface.; The first installation will still be just as slow, but subsequent builds can; be incremental and thus much faster.; For this use, first install the latest version from a pre-built wheel, which; will setup the proper directory st",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst:3931,Integrability,interface,interface,3931,"it clone https://github.com/wlav/cppyy-backend.git; $ cd cppyy-backend/cling; $ python setup.py egg_info; $ python create_src_directory.py; $ python setup.py bdist_wheel; $ python -m pip install dist/cppyy_cling-* --upgrade. .. note::; ``cppyy-cling`` wheels do not depend on the Python interpreter and can; thus be re-used for any version of Python or PyPy. The ``egg_info`` setup command is needed for ``create_src_directory.py`` to; find the right version.; That script in turn downloads the proper release from `upstream`_, trims and; patches it,; and installs the result in the ""src"" directory.; When done, the structure of ``cppyy-cling`` looks again like a PyPA package; and can be used/installed as expected, here done with ``pip``. By default, the setup script will use all cores (x2 if hyperthreading is; enabled).; You can change this behavior by setting the ``MAKE_NPROCS`` envar to the; desired number of allowable sub jobs. If on the other hand you are building from source to develop/modify; ``cppyy-cling``, consider using the ``cmake`` interface.; The first installation will still be just as slow, but subsequent builds can; be incremental and thus much faster.; For this use, first install the latest version from a pre-built wheel, which; will setup the proper directory structure, then use cmake to build and; install the latest or modified version of ``cppyy-cling`` into that::. $ python -m pip install cppyy-cling; $ git clone https://github.com/wlav/cppyy-backend.git; $ cd cppyy-backend/cling; $ python setup.py egg_info; $ python create_src_directory.py; $ mkdir dev; $ cd dev; $ cmake ../src -Wno-dev -DCMAKE_CXX_STANDARD=17 -DLLVM_ENABLE_EH=0 -DLLVM_ENABLE_RTTI=0 -DLLVM_ENABLE_TERMINFO=0 -DLLVM_ENABLE_ASSERTIONS=0 -Dminimal=ON -Druntime_cxxmodules=OFF -Dbuiltin_zlib=ON -Dbuiltin_cling=ON -DCMAKE_BUILD_TYPE=RelWithDebInfo -DCMAKE_INSTALL_PREFIX=<path to environment python site-packages>; $ make -j <N> install. where the ``cmake`` command needs to be given the full p",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst:5724,Performance,cache,cached,5724,"_BUILD_TYPE=RelWithDebInfo -DCMAKE_INSTALL_PREFIX=<path to environment python site-packages>; $ make -j <N> install. where the ``cmake`` command needs to be given the full path to; `site-packages/cppyy_backend` in the virtual environment or other; installation location.; Adjust other options (esp. ``CMAKE_CXX_STANDARD``) as needed.; For the build command, adjust the ``cmake`` command as appropriate for your; favorite, or platform-specific, build system and/or use ``cmake --build``; instead of ``make`` directly.; See the `cmake documentation`_ for details. Next up is ``cppyy-backend`` (cppyy-backend, subdirectory ""clingwrapper""; omit; the first step if you already cloned the repo for ``cppyy-cling``)::. $ git clone https://github.com/wlav/cppyy-backend.git; $ cd cppyy-backend/clingwrapper; $ python -m pip install . --upgrade --no-use-pep517 --no-deps. Note the use of ``--no-use-pep517``, which prevents ``pip`` from needlessly; going out to pypi.org and creating a local ""clean"" build environment from the; cached or remote wheels.; Instead, by skipping PEP 517, the local installation will be used.; This is imperative if there was a change in public headers or if the version; of ``cppyy-cling`` was locally updated and is thus not available on PyPI. Upgrading ``CPyCppyy`` (if on CPython; it's not needed for PyPy) and ``cppyy``; is very similar::. $ git clone https://github.com/wlav/CPyCppyy.git; $ cd CPyCppyy; $ python -m pip install . --upgrade --no-use-pep517 --no-deps. Just like ``cppyy-cling``, ``CPyCppyy`` has ``cmake`` scripts which are the; recommended way for development, as incremental builds are faster::. $ mkdir build; $ cmake ../CPyCppyy; $ make -j <N>. then simply point the ``PYTHONPATH`` envar to the `build` directory above to; pick up the local `cppyy.so` module. Finally, the top-level package ``cppyy``::. $ git clone https://github.com/wlav/cppyy.git; $ cd cppyy; $ python -m pip install . --upgrade --no-deps. Please see the `pip documentation`_ for more op",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst:1256,Security,expose,expose,1256,"cause of this layering and because it leverages several existing packages; through reuse, the relevant codes are contained across a number of; repositories. * Frontend, cppyy: https://github.com/wlav/cppyy; * CPython (v2/v3) intermediate: https://github.com/wlav/CPyCppyy; * PyPy intermediate (module _cppyy): https://foss.heptapod.net/pypy; * Backend, cppyy: https://github.com/wlav/cppyy-backend. The backend repo contains both the cppyy-cling (under ""cling"") and; cppyy-backend (under ""clingwrapper"") packages. .. _building_from_source:. Building from source; --------------------. Except for cppyy-cling, the structure in the repositories follows a normal; PyPA package and they are thus ready to build with `setuptools`_: simply; clone the package and either run ``python setup.py``, or use ``pip``. It is highly recommended to follow the dependency chain when manually; upgrading packages individually (i.e. ``cppyy-cling``, ``cppyy-backend``,; ``CPyCppyy`` if on CPython, and then finally ``cppyy``), because upstream; packages expose headers that are used by the ones downstream.; Of course, if only building for a patch/point release, there is no need to; re-install the full chain (or follow the order).; Always run the local updates from the package directories (i.e. where the; ``setup.py`` file is located), as some tools rely on the package structure. The ``STDCXX`` envar can be used to control the C++ standard version; use; ``MAKE`` to change the ``make`` command; and ``MAKE_NPROCS`` to control the; maximum number of parallel jobs.; Compilation of the backend, which contains a customized version of; Clang/LLVM, can take a long time, so by default the setup script will use all; cores (x2 if hyperthreading is enabled). On MS Windows, some temporary path names may be too long, causing the build to; fail.; To resolve this issue, point the ``TMP`` and ``TEMP`` envars to an existing; directory with a short name before the build:; For example::. > set TMP=C:\TMP; > set TEMP=C:\TM",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst:948,Usability,simpl,simply,948,".. _repositories:. Repositories; ============. The ``cppyy`` module is a frontend that requires an intermediate (Python; interpreter dependent) layer, and a backend (see; :ref:`Package Structure <package-structure>`).; Because of this layering and because it leverages several existing packages; through reuse, the relevant codes are contained across a number of; repositories. * Frontend, cppyy: https://github.com/wlav/cppyy; * CPython (v2/v3) intermediate: https://github.com/wlav/CPyCppyy; * PyPy intermediate (module _cppyy): https://foss.heptapod.net/pypy; * Backend, cppyy: https://github.com/wlav/cppyy-backend. The backend repo contains both the cppyy-cling (under ""cling"") and; cppyy-backend (under ""clingwrapper"") packages. .. _building_from_source:. Building from source; --------------------. Except for cppyy-cling, the structure in the repositories follows a normal; PyPA package and they are thus ready to build with `setuptools`_: simply; clone the package and either run ``python setup.py``, or use ``pip``. It is highly recommended to follow the dependency chain when manually; upgrading packages individually (i.e. ``cppyy-cling``, ``cppyy-backend``,; ``CPyCppyy`` if on CPython, and then finally ``cppyy``), because upstream; packages expose headers that are used by the ones downstream.; Of course, if only building for a patch/point release, there is no need to; re-install the full chain (or follow the order).; Always run the local updates from the package directories (i.e. where the; ``setup.py`` file is located), as some tools rely on the package structure. The ``STDCXX`` envar can be used to control the C++ standard version; use; ``MAKE`` to change the ``make`` command; and ``MAKE_NPROCS`` to control the; maximum number of parallel jobs.; Compilation of the backend, which contains a customized version of; Clang/LLVM, can take a long time, so by default the setup script will use all; cores (x2 if hyperthreading is enabled). On MS Windows, some temporary path names",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst:2564,Usability,simpl,simply,2564,"ome tools rely on the package structure. The ``STDCXX`` envar can be used to control the C++ standard version; use; ``MAKE`` to change the ``make`` command; and ``MAKE_NPROCS`` to control the; maximum number of parallel jobs.; Compilation of the backend, which contains a customized version of; Clang/LLVM, can take a long time, so by default the setup script will use all; cores (x2 if hyperthreading is enabled). On MS Windows, some temporary path names may be too long, causing the build to; fail.; To resolve this issue, point the ``TMP`` and ``TEMP`` envars to an existing; directory with a short name before the build:; For example::. > set TMP=C:\TMP; > set TEMP=C:\TMP. The first package to build is ``cppyy-cling``.; It may take a long time, especially on a laptop (Mac ARM being a notable; exception), since Cling comes with a builtin version of LLVM/Clang.; Consider therefore for a moment your reasons for building from source: there; being no pre-built wheel for the platform that you're interested in or simply; needing the latest version from the repository; or perhaps you are planning; to develop/modify the sources. If the former, clone the repository, check out a specific tagged release as; needed, then run the following steps to add Cling and build a wheel.; Once built, install the wheel as appropriate::. $ git clone https://github.com/wlav/cppyy-backend.git; $ cd cppyy-backend/cling; $ python setup.py egg_info; $ python create_src_directory.py; $ python setup.py bdist_wheel; $ python -m pip install dist/cppyy_cling-* --upgrade. .. note::; ``cppyy-cling`` wheels do not depend on the Python interpreter and can; thus be re-used for any version of Python or PyPy. The ``egg_info`` setup command is needed for ``create_src_directory.py`` to; find the right version.; That script in turn downloads the proper release from `upstream`_, trims and; patches it,; and installs the result in the ""src"" directory.; When done, the structure of ``cppyy-cling`` looks again like a PyPA",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst:6399,Usability,simpl,simply,6399,"vironment or other; installation location.; Adjust other options (esp. ``CMAKE_CXX_STANDARD``) as needed.; For the build command, adjust the ``cmake`` command as appropriate for your; favorite, or platform-specific, build system and/or use ``cmake --build``; instead of ``make`` directly.; See the `cmake documentation`_ for details. Next up is ``cppyy-backend`` (cppyy-backend, subdirectory ""clingwrapper""; omit; the first step if you already cloned the repo for ``cppyy-cling``)::. $ git clone https://github.com/wlav/cppyy-backend.git; $ cd cppyy-backend/clingwrapper; $ python -m pip install . --upgrade --no-use-pep517 --no-deps. Note the use of ``--no-use-pep517``, which prevents ``pip`` from needlessly; going out to pypi.org and creating a local ""clean"" build environment from the; cached or remote wheels.; Instead, by skipping PEP 517, the local installation will be used.; This is imperative if there was a change in public headers or if the version; of ``cppyy-cling`` was locally updated and is thus not available on PyPI. Upgrading ``CPyCppyy`` (if on CPython; it's not needed for PyPy) and ``cppyy``; is very similar::. $ git clone https://github.com/wlav/CPyCppyy.git; $ cd CPyCppyy; $ python -m pip install . --upgrade --no-use-pep517 --no-deps. Just like ``cppyy-cling``, ``CPyCppyy`` has ``cmake`` scripts which are the; recommended way for development, as incremental builds are faster::. $ mkdir build; $ cmake ../CPyCppyy; $ make -j <N>. then simply point the ``PYTHONPATH`` envar to the `build` directory above to; pick up the local `cppyy.so` module. Finally, the top-level package ``cppyy``::. $ git clone https://github.com/wlav/cppyy.git; $ cd cppyy; $ python -m pip install . --upgrade --no-deps. Please see the `pip documentation`_ for more options, such as developer mode. .. _`setuptools`: https://setuptools.readthedocs.io/; .. _`upstream`: https://root.cern.ch/download/; .. _`cmake documentation`: https://cmake.org/; .. _`pip documentation`: https://pip.pypa.io/; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/repositories.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/starting.rst:1439,Availability,avail,available,1439,"iles for automatic, lazy, loading.; You can, however, get very far with just the basics and it may even be; completely sufficient for small packages with fewer classes. cppyy works by parsing C++ definitions through ``cling``, generating tiny; wrapper codes to honor compile-time features and create standardized; interfaces, then compiling/linking those wrappers with the ``clang`` JIT.; It thus requires only those two ingredients: *C++ definitions* and; *linker symbols*.; All cppyy uses, the basic and the more advanced, are variations on the; theme of bringing these two together at the point of use. Definitions typically live in header files and symbols in libraries.; Headers can be loaded with ``cppyy.include`` and libraries with the; ``cppyy.load_library`` call.; Loading the header is sufficient to start exploring, with ``cppyy.gbl`` the; starting point of all things C++, while the linker symbols are only needed at ; the point of first use. Here is an example using the `zlib`_ library, which is likely available on; your system:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('zlib.h') # bring in C++ definitions; >>> cppyy.load_library('libz') # load linker symbols; >>> cppyy.gbl.zlibVersion() # use a zlib API; '1.2.11'; >>>. Since header files can include other header files, it is easy to aggregate; all relevant ones into a single header to include.; If there are project-specific include paths, you can add those paths through; ``cppyy.add_include_path``.; If a header is C-only and not set for use with C++, use ``cppyy.c_include``,; which adds ``extern ""C""`` around the header. Library files can be aggregated by linking all relevant ones to a single; library to load.; Using the linker for this purpose allows regular system features such as; ``rpath`` and envars such as ``LD_LIBRARY_PATH`` to be applied as usual.; Note that any mechanism that exposes the library symbols will work.; For example, you could also use the standard module ``ctypes`` through; ``",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/starting.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/starting.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/starting.rst:2641,Availability,avail,available,2641,"ker symbols*.; All cppyy uses, the basic and the more advanced, are variations on the; theme of bringing these two together at the point of use. Definitions typically live in header files and symbols in libraries.; Headers can be loaded with ``cppyy.include`` and libraries with the; ``cppyy.load_library`` call.; Loading the header is sufficient to start exploring, with ``cppyy.gbl`` the; starting point of all things C++, while the linker symbols are only needed at ; the point of first use. Here is an example using the `zlib`_ library, which is likely available on; your system:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('zlib.h') # bring in C++ definitions; >>> cppyy.load_library('libz') # load linker symbols; >>> cppyy.gbl.zlibVersion() # use a zlib API; '1.2.11'; >>>. Since header files can include other header files, it is easy to aggregate; all relevant ones into a single header to include.; If there are project-specific include paths, you can add those paths through; ``cppyy.add_include_path``.; If a header is C-only and not set for use with C++, use ``cppyy.c_include``,; which adds ``extern ""C""`` around the header. Library files can be aggregated by linking all relevant ones to a single; library to load.; Using the linker for this purpose allows regular system features such as; ``rpath`` and envars such as ``LD_LIBRARY_PATH`` to be applied as usual.; Note that any mechanism that exposes the library symbols will work.; For example, you could also use the standard module ``ctypes`` through; ``ctypes.CDLL`` with the ``ctypes.RTLD_GLOBAL`` option. To explore, start from ``cppyy.gbl`` to access your namespaces, classes,; functions, etc., etc. directly; or use python's ``dir`` (or tab-completion); to see what is available.; Use python's ``help`` to see list the methods and data members of classes and; see the interfaces of functions. Now try this out for some of your own headers, libraries, and APIs!. .. _`zlib`: https://en.wikipedia.org/wiki/Zlib; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/starting.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/starting.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/starting.rst:301,Energy Efficiency,reduce,reduced,301,".. _starting:. Trying it out; =============. This is a basic guide to try cppyy and see whether it works for you.; Large code bases will benefit from more advanced features such as; :doc:`pythonizations <pythonizations>` for a cleaner interface to clients;; precompiled modules for faster parsing and reduced memory usage;; "":ref:`dictionaries <dictionaries>`"" to package locations and manage; dependencies; and mapping files for automatic, lazy, loading.; You can, however, get very far with just the basics and it may even be; completely sufficient for small packages with fewer classes. cppyy works by parsing C++ definitions through ``cling``, generating tiny; wrapper codes to honor compile-time features and create standardized; interfaces, then compiling/linking those wrappers with the ``clang`` JIT.; It thus requires only those two ingredients: *C++ definitions* and; *linker symbols*.; All cppyy uses, the basic and the more advanced, are variations on the; theme of bringing these two together at the point of use. Definitions typically live in header files and symbols in libraries.; Headers can be loaded with ``cppyy.include`` and libraries with the; ``cppyy.load_library`` call.; Loading the header is sufficient to start exploring, with ``cppyy.gbl`` the; starting point of all things C++, while the linker symbols are only needed at ; the point of first use. Here is an example using the `zlib`_ library, which is likely available on; your system:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('zlib.h') # bring in C++ definitions; >>> cppyy.load_library('libz') # load linker symbols; >>> cppyy.gbl.zlibVersion() # use a zlib API; '1.2.11'; >>>. Since header files can include other header files, it is easy to aggregate; all relevant ones into a single header to include.; If there are project-specific include paths, you can add those paths through; ``cppyy.add_include_path``.; If a header is C-only and not set for use with C++, use ``cppyy.c_include``,; which ad",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/starting.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/starting.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/starting.rst:235,Integrability,interface,interface,235,".. _starting:. Trying it out; =============. This is a basic guide to try cppyy and see whether it works for you.; Large code bases will benefit from more advanced features such as; :doc:`pythonizations <pythonizations>` for a cleaner interface to clients;; precompiled modules for faster parsing and reduced memory usage;; "":ref:`dictionaries <dictionaries>`"" to package locations and manage; dependencies; and mapping files for automatic, lazy, loading.; You can, however, get very far with just the basics and it may even be; completely sufficient for small packages with fewer classes. cppyy works by parsing C++ definitions through ``cling``, generating tiny; wrapper codes to honor compile-time features and create standardized; interfaces, then compiling/linking those wrappers with the ``clang`` JIT.; It thus requires only those two ingredients: *C++ definitions* and; *linker symbols*.; All cppyy uses, the basic and the more advanced, are variations on the; theme of bringing these two together at the point of use. Definitions typically live in header files and symbols in libraries.; Headers can be loaded with ``cppyy.include`` and libraries with the; ``cppyy.load_library`` call.; Loading the header is sufficient to start exploring, with ``cppyy.gbl`` the; starting point of all things C++, while the linker symbols are only needed at ; the point of first use. Here is an example using the `zlib`_ library, which is likely available on; your system:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('zlib.h') # bring in C++ definitions; >>> cppyy.load_library('libz') # load linker symbols; >>> cppyy.gbl.zlibVersion() # use a zlib API; '1.2.11'; >>>. Since header files can include other header files, it is easy to aggregate; all relevant ones into a single header to include.; If there are project-specific include paths, you can add those paths through; ``cppyy.add_include_path``.; If a header is C-only and not set for use with C++, use ``cppyy.c_include``,; which ad",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/starting.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/starting.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/starting.rst:394,Integrability,depend,dependencies,394,".. _starting:. Trying it out; =============. This is a basic guide to try cppyy and see whether it works for you.; Large code bases will benefit from more advanced features such as; :doc:`pythonizations <pythonizations>` for a cleaner interface to clients;; precompiled modules for faster parsing and reduced memory usage;; "":ref:`dictionaries <dictionaries>`"" to package locations and manage; dependencies; and mapping files for automatic, lazy, loading.; You can, however, get very far with just the basics and it may even be; completely sufficient for small packages with fewer classes. cppyy works by parsing C++ definitions through ``cling``, generating tiny; wrapper codes to honor compile-time features and create standardized; interfaces, then compiling/linking those wrappers with the ``clang`` JIT.; It thus requires only those two ingredients: *C++ definitions* and; *linker symbols*.; All cppyy uses, the basic and the more advanced, are variations on the; theme of bringing these two together at the point of use. Definitions typically live in header files and symbols in libraries.; Headers can be loaded with ``cppyy.include`` and libraries with the; ``cppyy.load_library`` call.; Loading the header is sufficient to start exploring, with ``cppyy.gbl`` the; starting point of all things C++, while the linker symbols are only needed at ; the point of first use. Here is an example using the `zlib`_ library, which is likely available on; your system:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('zlib.h') # bring in C++ definitions; >>> cppyy.load_library('libz') # load linker symbols; >>> cppyy.gbl.zlibVersion() # use a zlib API; '1.2.11'; >>>. Since header files can include other header files, it is easy to aggregate; all relevant ones into a single header to include.; If there are project-specific include paths, you can add those paths through; ``cppyy.add_include_path``.; If a header is C-only and not set for use with C++, use ``cppyy.c_include``,; which ad",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/starting.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/starting.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/starting.rst:665,Integrability,wrap,wrapper,665,".. _starting:. Trying it out; =============. This is a basic guide to try cppyy and see whether it works for you.; Large code bases will benefit from more advanced features such as; :doc:`pythonizations <pythonizations>` for a cleaner interface to clients;; precompiled modules for faster parsing and reduced memory usage;; "":ref:`dictionaries <dictionaries>`"" to package locations and manage; dependencies; and mapping files for automatic, lazy, loading.; You can, however, get very far with just the basics and it may even be; completely sufficient for small packages with fewer classes. cppyy works by parsing C++ definitions through ``cling``, generating tiny; wrapper codes to honor compile-time features and create standardized; interfaces, then compiling/linking those wrappers with the ``clang`` JIT.; It thus requires only those two ingredients: *C++ definitions* and; *linker symbols*.; All cppyy uses, the basic and the more advanced, are variations on the; theme of bringing these two together at the point of use. Definitions typically live in header files and symbols in libraries.; Headers can be loaded with ``cppyy.include`` and libraries with the; ``cppyy.load_library`` call.; Loading the header is sufficient to start exploring, with ``cppyy.gbl`` the; starting point of all things C++, while the linker symbols are only needed at ; the point of first use. Here is an example using the `zlib`_ library, which is likely available on; your system:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('zlib.h') # bring in C++ definitions; >>> cppyy.load_library('libz') # load linker symbols; >>> cppyy.gbl.zlibVersion() # use a zlib API; '1.2.11'; >>>. Since header files can include other header files, it is easy to aggregate; all relevant ones into a single header to include.; If there are project-specific include paths, you can add those paths through; ``cppyy.add_include_path``.; If a header is C-only and not set for use with C++, use ``cppyy.c_include``,; which ad",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/starting.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/starting.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/starting.rst:735,Integrability,interface,interfaces,735,".. _starting:. Trying it out; =============. This is a basic guide to try cppyy and see whether it works for you.; Large code bases will benefit from more advanced features such as; :doc:`pythonizations <pythonizations>` for a cleaner interface to clients;; precompiled modules for faster parsing and reduced memory usage;; "":ref:`dictionaries <dictionaries>`"" to package locations and manage; dependencies; and mapping files for automatic, lazy, loading.; You can, however, get very far with just the basics and it may even be; completely sufficient for small packages with fewer classes. cppyy works by parsing C++ definitions through ``cling``, generating tiny; wrapper codes to honor compile-time features and create standardized; interfaces, then compiling/linking those wrappers with the ``clang`` JIT.; It thus requires only those two ingredients: *C++ definitions* and; *linker symbols*.; All cppyy uses, the basic and the more advanced, are variations on the; theme of bringing these two together at the point of use. Definitions typically live in header files and symbols in libraries.; Headers can be loaded with ``cppyy.include`` and libraries with the; ``cppyy.load_library`` call.; Loading the header is sufficient to start exploring, with ``cppyy.gbl`` the; starting point of all things C++, while the linker symbols are only needed at ; the point of first use. Here is an example using the `zlib`_ library, which is likely available on; your system:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('zlib.h') # bring in C++ definitions; >>> cppyy.load_library('libz') # load linker symbols; >>> cppyy.gbl.zlibVersion() # use a zlib API; '1.2.11'; >>>. Since header files can include other header files, it is easy to aggregate; all relevant ones into a single header to include.; If there are project-specific include paths, you can add those paths through; ``cppyy.add_include_path``.; If a header is C-only and not set for use with C++, use ``cppyy.c_include``,; which ad",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/starting.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/starting.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/starting.rst:776,Integrability,wrap,wrappers,776,".. _starting:. Trying it out; =============. This is a basic guide to try cppyy and see whether it works for you.; Large code bases will benefit from more advanced features such as; :doc:`pythonizations <pythonizations>` for a cleaner interface to clients;; precompiled modules for faster parsing and reduced memory usage;; "":ref:`dictionaries <dictionaries>`"" to package locations and manage; dependencies; and mapping files for automatic, lazy, loading.; You can, however, get very far with just the basics and it may even be; completely sufficient for small packages with fewer classes. cppyy works by parsing C++ definitions through ``cling``, generating tiny; wrapper codes to honor compile-time features and create standardized; interfaces, then compiling/linking those wrappers with the ``clang`` JIT.; It thus requires only those two ingredients: *C++ definitions* and; *linker symbols*.; All cppyy uses, the basic and the more advanced, are variations on the; theme of bringing these two together at the point of use. Definitions typically live in header files and symbols in libraries.; Headers can be loaded with ``cppyy.include`` and libraries with the; ``cppyy.load_library`` call.; Loading the header is sufficient to start exploring, with ``cppyy.gbl`` the; starting point of all things C++, while the linker symbols are only needed at ; the point of first use. Here is an example using the `zlib`_ library, which is likely available on; your system:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('zlib.h') # bring in C++ definitions; >>> cppyy.load_library('libz') # load linker symbols; >>> cppyy.gbl.zlibVersion() # use a zlib API; '1.2.11'; >>>. Since header files can include other header files, it is easy to aggregate; all relevant ones into a single header to include.; If there are project-specific include paths, you can add those paths through; ``cppyy.add_include_path``.; If a header is C-only and not set for use with C++, use ``cppyy.c_include``,; which ad",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/starting.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/starting.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/starting.rst:2740,Integrability,interface,interfaces,2740,"ker symbols*.; All cppyy uses, the basic and the more advanced, are variations on the; theme of bringing these two together at the point of use. Definitions typically live in header files and symbols in libraries.; Headers can be loaded with ``cppyy.include`` and libraries with the; ``cppyy.load_library`` call.; Loading the header is sufficient to start exploring, with ``cppyy.gbl`` the; starting point of all things C++, while the linker symbols are only needed at ; the point of first use. Here is an example using the `zlib`_ library, which is likely available on; your system:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('zlib.h') # bring in C++ definitions; >>> cppyy.load_library('libz') # load linker symbols; >>> cppyy.gbl.zlibVersion() # use a zlib API; '1.2.11'; >>>. Since header files can include other header files, it is easy to aggregate; all relevant ones into a single header to include.; If there are project-specific include paths, you can add those paths through; ``cppyy.add_include_path``.; If a header is C-only and not set for use with C++, use ``cppyy.c_include``,; which adds ``extern ""C""`` around the header. Library files can be aggregated by linking all relevant ones to a single; library to load.; Using the linker for this purpose allows regular system features such as; ``rpath`` and envars such as ``LD_LIBRARY_PATH`` to be applied as usual.; Note that any mechanism that exposes the library symbols will work.; For example, you could also use the standard module ``ctypes`` through; ``ctypes.CDLL`` with the ``ctypes.RTLD_GLOBAL`` option. To explore, start from ``cppyy.gbl`` to access your namespaces, classes,; functions, etc., etc. directly; or use python's ``dir`` (or tab-completion); to see what is available.; Use python's ``help`` to see list the methods and data members of classes and; see the interfaces of functions. Now try this out for some of your own headers, libraries, and APIs!. .. _`zlib`: https://en.wikipedia.org/wiki/Zlib; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/starting.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/starting.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/starting.rst:447,Performance,load,loading,447,".. _starting:. Trying it out; =============. This is a basic guide to try cppyy and see whether it works for you.; Large code bases will benefit from more advanced features such as; :doc:`pythonizations <pythonizations>` for a cleaner interface to clients;; precompiled modules for faster parsing and reduced memory usage;; "":ref:`dictionaries <dictionaries>`"" to package locations and manage; dependencies; and mapping files for automatic, lazy, loading.; You can, however, get very far with just the basics and it may even be; completely sufficient for small packages with fewer classes. cppyy works by parsing C++ definitions through ``cling``, generating tiny; wrapper codes to honor compile-time features and create standardized; interfaces, then compiling/linking those wrappers with the ``clang`` JIT.; It thus requires only those two ingredients: *C++ definitions* and; *linker symbols*.; All cppyy uses, the basic and the more advanced, are variations on the; theme of bringing these two together at the point of use. Definitions typically live in header files and symbols in libraries.; Headers can be loaded with ``cppyy.include`` and libraries with the; ``cppyy.load_library`` call.; Loading the header is sufficient to start exploring, with ``cppyy.gbl`` the; starting point of all things C++, while the linker symbols are only needed at ; the point of first use. Here is an example using the `zlib`_ library, which is likely available on; your system:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('zlib.h') # bring in C++ definitions; >>> cppyy.load_library('libz') # load linker symbols; >>> cppyy.gbl.zlibVersion() # use a zlib API; '1.2.11'; >>>. Since header files can include other header files, it is easy to aggregate; all relevant ones into a single header to include.; If there are project-specific include paths, you can add those paths through; ``cppyy.add_include_path``.; If a header is C-only and not set for use with C++, use ``cppyy.c_include``,; which ad",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/starting.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/starting.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/starting.rst:1112,Performance,load,loaded,1112,"; Large code bases will benefit from more advanced features such as; :doc:`pythonizations <pythonizations>` for a cleaner interface to clients;; precompiled modules for faster parsing and reduced memory usage;; "":ref:`dictionaries <dictionaries>`"" to package locations and manage; dependencies; and mapping files for automatic, lazy, loading.; You can, however, get very far with just the basics and it may even be; completely sufficient for small packages with fewer classes. cppyy works by parsing C++ definitions through ``cling``, generating tiny; wrapper codes to honor compile-time features and create standardized; interfaces, then compiling/linking those wrappers with the ``clang`` JIT.; It thus requires only those two ingredients: *C++ definitions* and; *linker symbols*.; All cppyy uses, the basic and the more advanced, are variations on the; theme of bringing these two together at the point of use. Definitions typically live in header files and symbols in libraries.; Headers can be loaded with ``cppyy.include`` and libraries with the; ``cppyy.load_library`` call.; Loading the header is sufficient to start exploring, with ``cppyy.gbl`` the; starting point of all things C++, while the linker symbols are only needed at ; the point of first use. Here is an example using the `zlib`_ library, which is likely available on; your system:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('zlib.h') # bring in C++ definitions; >>> cppyy.load_library('libz') # load linker symbols; >>> cppyy.gbl.zlibVersion() # use a zlib API; '1.2.11'; >>>. Since header files can include other header files, it is easy to aggregate; all relevant ones into a single header to include.; If there are project-specific include paths, you can add those paths through; ``cppyy.add_include_path``.; If a header is C-only and not set for use with C++, use ``cppyy.c_include``,; which adds ``extern ""C""`` around the header. Library files can be aggregated by linking all relevant ones to a single; li",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/starting.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/starting.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/starting.rst:1598,Performance,load,load,1598,"by parsing C++ definitions through ``cling``, generating tiny; wrapper codes to honor compile-time features and create standardized; interfaces, then compiling/linking those wrappers with the ``clang`` JIT.; It thus requires only those two ingredients: *C++ definitions* and; *linker symbols*.; All cppyy uses, the basic and the more advanced, are variations on the; theme of bringing these two together at the point of use. Definitions typically live in header files and symbols in libraries.; Headers can be loaded with ``cppyy.include`` and libraries with the; ``cppyy.load_library`` call.; Loading the header is sufficient to start exploring, with ``cppyy.gbl`` the; starting point of all things C++, while the linker symbols are only needed at ; the point of first use. Here is an example using the `zlib`_ library, which is likely available on; your system:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('zlib.h') # bring in C++ definitions; >>> cppyy.load_library('libz') # load linker symbols; >>> cppyy.gbl.zlibVersion() # use a zlib API; '1.2.11'; >>>. Since header files can include other header files, it is easy to aggregate; all relevant ones into a single header to include.; If there are project-specific include paths, you can add those paths through; ``cppyy.add_include_path``.; If a header is C-only and not set for use with C++, use ``cppyy.c_include``,; which adds ``extern ""C""`` around the header. Library files can be aggregated by linking all relevant ones to a single; library to load.; Using the linker for this purpose allows regular system features such as; ``rpath`` and envars such as ``LD_LIBRARY_PATH`` to be applied as usual.; Note that any mechanism that exposes the library symbols will work.; For example, you could also use the standard module ``ctypes`` through; ``ctypes.CDLL`` with the ``ctypes.RTLD_GLOBAL`` option. To explore, start from ``cppyy.gbl`` to access your namespaces, classes,; functions, etc., etc. directly; or use python's ``dir",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/starting.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/starting.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/starting.rst:2123,Performance,load,load,2123,"ker symbols*.; All cppyy uses, the basic and the more advanced, are variations on the; theme of bringing these two together at the point of use. Definitions typically live in header files and symbols in libraries.; Headers can be loaded with ``cppyy.include`` and libraries with the; ``cppyy.load_library`` call.; Loading the header is sufficient to start exploring, with ``cppyy.gbl`` the; starting point of all things C++, while the linker symbols are only needed at ; the point of first use. Here is an example using the `zlib`_ library, which is likely available on; your system:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('zlib.h') # bring in C++ definitions; >>> cppyy.load_library('libz') # load linker symbols; >>> cppyy.gbl.zlibVersion() # use a zlib API; '1.2.11'; >>>. Since header files can include other header files, it is easy to aggregate; all relevant ones into a single header to include.; If there are project-specific include paths, you can add those paths through; ``cppyy.add_include_path``.; If a header is C-only and not set for use with C++, use ``cppyy.c_include``,; which adds ``extern ""C""`` around the header. Library files can be aggregated by linking all relevant ones to a single; library to load.; Using the linker for this purpose allows regular system features such as; ``rpath`` and envars such as ``LD_LIBRARY_PATH`` to be applied as usual.; Note that any mechanism that exposes the library symbols will work.; For example, you could also use the standard module ``ctypes`` through; ``ctypes.CDLL`` with the ``ctypes.RTLD_GLOBAL`` option. To explore, start from ``cppyy.gbl`` to access your namespaces, classes,; functions, etc., etc. directly; or use python's ``dir`` (or tab-completion); to see what is available.; Use python's ``help`` to see list the methods and data members of classes and; see the interfaces of functions. Now try this out for some of your own headers, libraries, and APIs!. .. _`zlib`: https://en.wikipedia.org/wiki/Zlib; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/starting.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/starting.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/starting.rst:2307,Security,expose,exposes,2307,"ker symbols*.; All cppyy uses, the basic and the more advanced, are variations on the; theme of bringing these two together at the point of use. Definitions typically live in header files and symbols in libraries.; Headers can be loaded with ``cppyy.include`` and libraries with the; ``cppyy.load_library`` call.; Loading the header is sufficient to start exploring, with ``cppyy.gbl`` the; starting point of all things C++, while the linker symbols are only needed at ; the point of first use. Here is an example using the `zlib`_ library, which is likely available on; your system:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('zlib.h') # bring in C++ definitions; >>> cppyy.load_library('libz') # load linker symbols; >>> cppyy.gbl.zlibVersion() # use a zlib API; '1.2.11'; >>>. Since header files can include other header files, it is easy to aggregate; all relevant ones into a single header to include.; If there are project-specific include paths, you can add those paths through; ``cppyy.add_include_path``.; If a header is C-only and not set for use with C++, use ``cppyy.c_include``,; which adds ``extern ""C""`` around the header. Library files can be aggregated by linking all relevant ones to a single; library to load.; Using the linker for this purpose allows regular system features such as; ``rpath`` and envars such as ``LD_LIBRARY_PATH`` to be applied as usual.; Note that any mechanism that exposes the library symbols will work.; For example, you could also use the standard module ``ctypes`` through; ``ctypes.CDLL`` with the ``ctypes.RTLD_GLOBAL`` option. To explore, start from ``cppyy.gbl`` to access your namespaces, classes,; functions, etc., etc. directly; or use python's ``dir`` (or tab-completion); to see what is available.; Use python's ``help`` to see list the methods and data members of classes and; see the interfaces of functions. Now try this out for some of your own headers, libraries, and APIs!. .. _`zlib`: https://en.wikipedia.org/wiki/Zlib; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/starting.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/starting.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/starting.rst:2515,Security,access,access,2515,"ker symbols*.; All cppyy uses, the basic and the more advanced, are variations on the; theme of bringing these two together at the point of use. Definitions typically live in header files and symbols in libraries.; Headers can be loaded with ``cppyy.include`` and libraries with the; ``cppyy.load_library`` call.; Loading the header is sufficient to start exploring, with ``cppyy.gbl`` the; starting point of all things C++, while the linker symbols are only needed at ; the point of first use. Here is an example using the `zlib`_ library, which is likely available on; your system:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('zlib.h') # bring in C++ definitions; >>> cppyy.load_library('libz') # load linker symbols; >>> cppyy.gbl.zlibVersion() # use a zlib API; '1.2.11'; >>>. Since header files can include other header files, it is easy to aggregate; all relevant ones into a single header to include.; If there are project-specific include paths, you can add those paths through; ``cppyy.add_include_path``.; If a header is C-only and not set for use with C++, use ``cppyy.c_include``,; which adds ``extern ""C""`` around the header. Library files can be aggregated by linking all relevant ones to a single; library to load.; Using the linker for this purpose allows regular system features such as; ``rpath`` and envars such as ``LD_LIBRARY_PATH`` to be applied as usual.; Note that any mechanism that exposes the library symbols will work.; For example, you could also use the standard module ``ctypes`` through; ``ctypes.CDLL`` with the ``ctypes.RTLD_GLOBAL`` option. To explore, start from ``cppyy.gbl`` to access your namespaces, classes,; functions, etc., etc. directly; or use python's ``dir`` (or tab-completion); to see what is available.; Use python's ``help`` to see list the methods and data members of classes and; see the interfaces of functions. Now try this out for some of your own headers, libraries, and APIs!. .. _`zlib`: https://en.wikipedia.org/wiki/Zlib; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/starting.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/starting.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/starting.rst:61,Usability,guid,guide,61,".. _starting:. Trying it out; =============. This is a basic guide to try cppyy and see whether it works for you.; Large code bases will benefit from more advanced features such as; :doc:`pythonizations <pythonizations>` for a cleaner interface to clients;; precompiled modules for faster parsing and reduced memory usage;; "":ref:`dictionaries <dictionaries>`"" to package locations and manage; dependencies; and mapping files for automatic, lazy, loading.; You can, however, get very far with just the basics and it may even be; completely sufficient for small packages with fewer classes. cppyy works by parsing C++ definitions through ``cling``, generating tiny; wrapper codes to honor compile-time features and create standardized; interfaces, then compiling/linking those wrappers with the ``clang`` JIT.; It thus requires only those two ingredients: *C++ definitions* and; *linker symbols*.; All cppyy uses, the basic and the more advanced, are variations on the; theme of bringing these two together at the point of use. Definitions typically live in header files and symbols in libraries.; Headers can be loaded with ``cppyy.include`` and libraries with the; ``cppyy.load_library`` call.; Loading the header is sufficient to start exploring, with ``cppyy.gbl`` the; starting point of all things C++, while the linker symbols are only needed at ; the point of first use. Here is an example using the `zlib`_ library, which is likely available on; your system:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('zlib.h') # bring in C++ definitions; >>> cppyy.load_library('libz') # load linker symbols; >>> cppyy.gbl.zlibVersion() # use a zlib API; '1.2.11'; >>>. Since header files can include other header files, it is easy to aggregate; all relevant ones into a single header to include.; If there are project-specific include paths, you can add those paths through; ``cppyy.add_include_path``.; If a header is C-only and not set for use with C++, use ``cppyy.c_include``,; which ad",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/starting.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/starting.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/stl.rst:745,Availability,avail,available,745,".. _stl:. STL; ===. Parts of the Standard Template Library (STL), in particular its container; types, are the de facto equivalent of Python's builtin types.; STL is written in C++ and Python bindings of it are fully functional as-is,; but are much more useful when pluggable into idiomatic expressions where; Python builtin containers are expected (e.g. in list contractions). There are two extremes to achieve such drop-in behavior: copy into Python; builtins, so that the Python-side always deals with true Python objects; or; adjust the C++ interfaces to be the same as their Python equivalents.; Neither is very satisfactory: the former is not because of the existence of; global/static variables and return-by-reference.; If only a copy is available, then expected modifications do not propagate.; Copying is also either slow (when copying every time) or memory intensive (if; the results are cached).; Filling out the interfaces may look more appealing, but all operations then; involve C++ function calls, which can be slower than the Python equivalents,; and C++-style error handling. Given that neither choice will satisfy all cases, ``cppyy`` aims to maximize; functionality and minimum surprises based on common use.; Thus, for example, ``std::vector`` grows a pythonistic ``__len__`` method,; but does not lose its C++ ``size`` method.; Passing a Python container through a const reference to a ``std::vector``; will trigger automatic conversion, but such an attempt through a non-const; reference will fail since a non-temporary C++ object is required [#f1]_ to; return any updates/changes. ``std::string`` is almost always converted to Python's ``str`` on function; returns (the exception is return-by-reference when assigning), but not when; its direct use is more likely such as in the case of (global) variables or; when iterating over a ``std::vector<std::string>``. The rest of this section shows examples of how STL containers can be used in; a natural, pythonistic, way. `std::vec",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/stl.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/stl.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/stl.rst:1077,Availability,error,error,1077,".. _stl:. STL; ===. Parts of the Standard Template Library (STL), in particular its container; types, are the de facto equivalent of Python's builtin types.; STL is written in C++ and Python bindings of it are fully functional as-is,; but are much more useful when pluggable into idiomatic expressions where; Python builtin containers are expected (e.g. in list contractions). There are two extremes to achieve such drop-in behavior: copy into Python; builtins, so that the Python-side always deals with true Python objects; or; adjust the C++ interfaces to be the same as their Python equivalents.; Neither is very satisfactory: the former is not because of the existence of; global/static variables and return-by-reference.; If only a copy is available, then expected modifications do not propagate.; Copying is also either slow (when copying every time) or memory intensive (if; the results are cached).; Filling out the interfaces may look more appealing, but all operations then; involve C++ function calls, which can be slower than the Python equivalents,; and C++-style error handling. Given that neither choice will satisfy all cases, ``cppyy`` aims to maximize; functionality and minimum surprises based on common use.; Thus, for example, ``std::vector`` grows a pythonistic ``__len__`` method,; but does not lose its C++ ``size`` method.; Passing a Python container through a const reference to a ``std::vector``; will trigger automatic conversion, but such an attempt through a non-const; reference will fail since a non-temporary C++ object is required [#f1]_ to; return any updates/changes. ``std::string`` is almost always converted to Python's ``str`` on function; returns (the exception is return-by-reference when assigning), but not when; its direct use is more likely such as in the case of (global) variables or; when iterating over a ``std::vector<std::string>``. The rest of this section shows examples of how STL containers can be used in; a natural, pythonistic, way. `std::vec",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/stl.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/stl.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/stl.rst:5927,Availability,avail,available,5927,"range(5)); 10; >>> cppyy.gbl.sumit2(range(6)); 16; >>> cppyy.gbl.sumit3(range(7)); 21; >>>. The temporary vector is created using the vector constructor taking an; ``std::initializer_list``, which is more flexible than constructing a; temporary vector and filling it: it allows the data in the container to be; implicitly converted (e.g. from ``int`` to ``double`` type, or from; pointer to derived to pointer to base class).; As a consequence, however, with STL containers being allowed where Python; containers are, this in turn means that you can pass e.g. an; ``std::vector<int>`` (or ``std::list<int>``) where a ``std::vector<double>``; is expected and a temporary is allowed:. .. code-block:: python. >>> cppyy.cppdef(""""""; ... double sumit4(const std::vector<double>& data) {; ... return std::accumulate(data.begin(), data.end(), 0);; ... }""""""); ...; True; >>> cppyy.gbl.sumit4(vector[int](range(7))); 21.0; >>>. Normal overload resolution rules continue to apply, however, thus if an; overload were available that takes an ``const std::vector<int>&``, it would; be preferred. When templates are involved, overload resolution is stricter, to ensure that; a better matching instantiation is preferred over an implicit conversion.; However, that does mean that as-is, C++ is actually more flexible: it has the; curly braces initializer syntax to explicitly infer an; ``std::initializer_list``, with no such equivalent in Python. Although in general this approach guarantees the intended result, it does put; some strictures on the Python side, requiring careful use of types.; However, an easily fixable error is preferable over an implicitly wrong; result.; Note the type of the init argument in the call resulting in an (attempted); implicit instantiation in the following example:. .. code-block:: python. >>> cppyy.cppdef(""""""; ... template<class T>; ... T sumit_T(const std::vector<T>& data, T init) {; ... return std::accumulate(data.begin(), data.end(), init);; ... }""""""); ...; True; >>> cp",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/stl.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/stl.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/stl.rst:6529,Availability,error,error,6529,"td::vector<double>``; is expected and a temporary is allowed:. .. code-block:: python. >>> cppyy.cppdef(""""""; ... double sumit4(const std::vector<double>& data) {; ... return std::accumulate(data.begin(), data.end(), 0);; ... }""""""); ...; True; >>> cppyy.gbl.sumit4(vector[int](range(7))); 21.0; >>>. Normal overload resolution rules continue to apply, however, thus if an; overload were available that takes an ``const std::vector<int>&``, it would; be preferred. When templates are involved, overload resolution is stricter, to ensure that; a better matching instantiation is preferred over an implicit conversion.; However, that does mean that as-is, C++ is actually more flexible: it has the; curly braces initializer syntax to explicitly infer an; ``std::initializer_list``, with no such equivalent in Python. Although in general this approach guarantees the intended result, it does put; some strictures on the Python side, requiring careful use of types.; However, an easily fixable error is preferable over an implicitly wrong; result.; Note the type of the init argument in the call resulting in an (attempted); implicit instantiation in the following example:. .. code-block:: python. >>> cppyy.cppdef(""""""; ... template<class T>; ... T sumit_T(const std::vector<T>& data, T init) {; ... return std::accumulate(data.begin(), data.end(), init);; ... }""""""); ...; True; >>> cppyy.gbl.sumit_T(vector['double'](range(7)), 0); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; TypeError: Template method resolution failed:; Failed to instantiate ""sumit_T(std::vector<double>&,int)""; Failed to instantiate ""sumit_T(std::vector<double>*,int)""; Failed to instantiate ""sumit_T(std::vector<double>,int)""; >>> cppyy.gbl.sumit_T(vector['double'](range(7)), 0.); 21.0; >>>. To be sure, the code is `too` strict in the simplistic example above, and; with a future version of Cling it should be possible to lift some of these; restrictions without causing incorrect results. `std::map`;",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/stl.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/stl.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/stl.rst:1587,Deployability,update,updates,1587,"ython-side always deals with true Python objects; or; adjust the C++ interfaces to be the same as their Python equivalents.; Neither is very satisfactory: the former is not because of the existence of; global/static variables and return-by-reference.; If only a copy is available, then expected modifications do not propagate.; Copying is also either slow (when copying every time) or memory intensive (if; the results are cached).; Filling out the interfaces may look more appealing, but all operations then; involve C++ function calls, which can be slower than the Python equivalents,; and C++-style error handling. Given that neither choice will satisfy all cases, ``cppyy`` aims to maximize; functionality and minimum surprises based on common use.; Thus, for example, ``std::vector`` grows a pythonistic ``__len__`` method,; but does not lose its C++ ``size`` method.; Passing a Python container through a const reference to a ``std::vector``; will trigger automatic conversion, but such an attempt through a non-const; reference will fail since a non-temporary C++ object is required [#f1]_ to; return any updates/changes. ``std::string`` is almost always converted to Python's ``str`` on function; returns (the exception is return-by-reference when assigning), but not when; its direct use is more likely such as in the case of (global) variables or; when iterating over a ``std::vector<std::string>``. The rest of this section shows examples of how STL containers can be used in; a natural, pythonistic, way. `std::vector`; -------------. A ``std::vector`` is the most commonly used C++ container type because it is; more efficient and performant than specialized types such as ``list`` and; ``map``, unless the number of elements gets very large.; Python has several similar types, from the builtin ``tuple`` and ``list``,; the ``array`` from builtin module ``array``, to ""as-good-as-builtin""; ``numpy.ndarray``.; A vector is more like the latter two in that it can contain only one type,; b",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/stl.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/stl.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/stl.rst:2105,Energy Efficiency,efficient,efficient,2105,"atisfy all cases, ``cppyy`` aims to maximize; functionality and minimum surprises based on common use.; Thus, for example, ``std::vector`` grows a pythonistic ``__len__`` method,; but does not lose its C++ ``size`` method.; Passing a Python container through a const reference to a ``std::vector``; will trigger automatic conversion, but such an attempt through a non-const; reference will fail since a non-temporary C++ object is required [#f1]_ to; return any updates/changes. ``std::string`` is almost always converted to Python's ``str`` on function; returns (the exception is return-by-reference when assigning), but not when; its direct use is more likely such as in the case of (global) variables or; when iterating over a ``std::vector<std::string>``. The rest of this section shows examples of how STL containers can be used in; a natural, pythonistic, way. `std::vector`; -------------. A ``std::vector`` is the most commonly used C++ container type because it is; more efficient and performant than specialized types such as ``list`` and; ``map``, unless the number of elements gets very large.; Python has several similar types, from the builtin ``tuple`` and ``list``,; the ``array`` from builtin module ``array``, to ""as-good-as-builtin""; ``numpy.ndarray``.; A vector is more like the latter two in that it can contain only one type,; but more like the former two in that it can contain objects.; In practice, it can interplay well with all these containers, but e.g.; efficiency and performance can differ significantly. A vector can be instantiated from any sequence, including generators, and; vectors of objects can be recursively constructed.; If the template type is to be inferred from the argument to the constructor,; the first element needs to be accessible, which precludes generators. .. code-block:: python. >>> from cppyy.gbl.std import vector, pair; >>> v = vector[int](range(10)) # from generator; >>> len(v); 10; >>> v = vector([x for x in range(10)]) # type inferred; >",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/stl.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/stl.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/stl.rst:4484,Energy Efficiency,efficient,efficient,4484,".. code-block:: python. >>> v += range(10, 20); >>> len(v); 20; >>>. Indexing and slicing of a vector follows the normal Python slicing rules;; printing a vector prints all its elements:. .. code-block:: python. >>> v[1]; 1; >>> v[-1]; 19; >>> v[-4:]; <cppyy.gbl.std.vector<int> object at 0x7f9051057650>; >>> print(v[-4:]); { 6, 7, 8, 9 }; >>>. The usual iteration operations work on vector, but the C++ rules still apply,; so a vector that is being iterated over can *not* be modified in the loop; body.; (On the plus side, this makes it much faster to iterate over a vector than,; say, a numpy ndarray.). .. code-block:: python. >>> for i in v[2:5]:; ... print(i); ...; 2; 3; 4; >>> 2 in v; True; >>> sum(v); 190; >>>. When a function takes a non-l-value (const-ref, move, or by-value) vector as; a parameter, another sequence can be used and cppyy will automatically; generate a temporary.; Typically, this will be faster than coding up such a temporary on the Python; side, but if the same sequence is used multiple times, creating a temporary; once and re-using it will be the most efficient approach.o. .. code-block:: python. >>> cppyy.cppdef(""""""; ... int sumit1(const std::vector<int>& data) {; ... return std::accumulate(data.begin(), data.end(), 0);; ... }; ... int sumit2(std::vector<int> data) {; ... return std::accumulate(data.begin(), data.end(), 0);; ... }; ... int sumit3(const std::vector<int>&& data) {; ... return std::accumulate(data.begin(), data.end(), 0);; ... }""""""); ...; True; >>> cppyy.gbl.sumit1(range(5)); 10; >>> cppyy.gbl.sumit2(range(6)); 16; >>> cppyy.gbl.sumit3(range(7)); 21; >>>. The temporary vector is created using the vector constructor taking an; ``std::initializer_list``, which is more flexible than constructing a; temporary vector and filling it: it allows the data in the container to be; implicitly converted (e.g. from ``int`` to ``double`` type, or from; pointer to derived to pointer to base class).; As a consequence, however, with STL containers b",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/stl.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/stl.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/stl.rst:362,Integrability,contract,contractions,362,".. _stl:. STL; ===. Parts of the Standard Template Library (STL), in particular its container; types, are the de facto equivalent of Python's builtin types.; STL is written in C++ and Python bindings of it are fully functional as-is,; but are much more useful when pluggable into idiomatic expressions where; Python builtin containers are expected (e.g. in list contractions). There are two extremes to achieve such drop-in behavior: copy into Python; builtins, so that the Python-side always deals with true Python objects; or; adjust the C++ interfaces to be the same as their Python equivalents.; Neither is very satisfactory: the former is not because of the existence of; global/static variables and return-by-reference.; If only a copy is available, then expected modifications do not propagate.; Copying is also either slow (when copying every time) or memory intensive (if; the results are cached).; Filling out the interfaces may look more appealing, but all operations then; involve C++ function calls, which can be slower than the Python equivalents,; and C++-style error handling. Given that neither choice will satisfy all cases, ``cppyy`` aims to maximize; functionality and minimum surprises based on common use.; Thus, for example, ``std::vector`` grows a pythonistic ``__len__`` method,; but does not lose its C++ ``size`` method.; Passing a Python container through a const reference to a ``std::vector``; will trigger automatic conversion, but such an attempt through a non-const; reference will fail since a non-temporary C++ object is required [#f1]_ to; return any updates/changes. ``std::string`` is almost always converted to Python's ``str`` on function; returns (the exception is return-by-reference when assigning), but not when; its direct use is more likely such as in the case of (global) variables or; when iterating over a ``std::vector<std::string>``. The rest of this section shows examples of how STL containers can be used in; a natural, pythonistic, way. `std::vec",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/stl.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/stl.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/stl.rst:544,Integrability,interface,interfaces,544,".. _stl:. STL; ===. Parts of the Standard Template Library (STL), in particular its container; types, are the de facto equivalent of Python's builtin types.; STL is written in C++ and Python bindings of it are fully functional as-is,; but are much more useful when pluggable into idiomatic expressions where; Python builtin containers are expected (e.g. in list contractions). There are two extremes to achieve such drop-in behavior: copy into Python; builtins, so that the Python-side always deals with true Python objects; or; adjust the C++ interfaces to be the same as their Python equivalents.; Neither is very satisfactory: the former is not because of the existence of; global/static variables and return-by-reference.; If only a copy is available, then expected modifications do not propagate.; Copying is also either slow (when copying every time) or memory intensive (if; the results are cached).; Filling out the interfaces may look more appealing, but all operations then; involve C++ function calls, which can be slower than the Python equivalents,; and C++-style error handling. Given that neither choice will satisfy all cases, ``cppyy`` aims to maximize; functionality and minimum surprises based on common use.; Thus, for example, ``std::vector`` grows a pythonistic ``__len__`` method,; but does not lose its C++ ``size`` method.; Passing a Python container through a const reference to a ``std::vector``; will trigger automatic conversion, but such an attempt through a non-const; reference will fail since a non-temporary C++ object is required [#f1]_ to; return any updates/changes. ``std::string`` is almost always converted to Python's ``str`` on function; returns (the exception is return-by-reference when assigning), but not when; its direct use is more likely such as in the case of (global) variables or; when iterating over a ``std::vector<std::string>``. The rest of this section shows examples of how STL containers can be used in; a natural, pythonistic, way. `std::vec",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/stl.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/stl.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/stl.rst:924,Integrability,interface,interfaces,924,".. _stl:. STL; ===. Parts of the Standard Template Library (STL), in particular its container; types, are the de facto equivalent of Python's builtin types.; STL is written in C++ and Python bindings of it are fully functional as-is,; but are much more useful when pluggable into idiomatic expressions where; Python builtin containers are expected (e.g. in list contractions). There are two extremes to achieve such drop-in behavior: copy into Python; builtins, so that the Python-side always deals with true Python objects; or; adjust the C++ interfaces to be the same as their Python equivalents.; Neither is very satisfactory: the former is not because of the existence of; global/static variables and return-by-reference.; If only a copy is available, then expected modifications do not propagate.; Copying is also either slow (when copying every time) or memory intensive (if; the results are cached).; Filling out the interfaces may look more appealing, but all operations then; involve C++ function calls, which can be slower than the Python equivalents,; and C++-style error handling. Given that neither choice will satisfy all cases, ``cppyy`` aims to maximize; functionality and minimum surprises based on common use.; Thus, for example, ``std::vector`` grows a pythonistic ``__len__`` method,; but does not lose its C++ ``size`` method.; Passing a Python container through a const reference to a ``std::vector``; will trigger automatic conversion, but such an attempt through a non-const; reference will fail since a non-temporary C++ object is required [#f1]_ to; return any updates/changes. ``std::string`` is almost always converted to Python's ``str`` on function; returns (the exception is return-by-reference when assigning), but not when; its direct use is more likely such as in the case of (global) variables or; when iterating over a ``std::vector<std::string>``. The rest of this section shows examples of how STL containers can be used in; a natural, pythonistic, way. `std::vec",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/stl.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/stl.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/stl.rst:691,Modifiability,variab,variables,691,".. _stl:. STL; ===. Parts of the Standard Template Library (STL), in particular its container; types, are the de facto equivalent of Python's builtin types.; STL is written in C++ and Python bindings of it are fully functional as-is,; but are much more useful when pluggable into idiomatic expressions where; Python builtin containers are expected (e.g. in list contractions). There are two extremes to achieve such drop-in behavior: copy into Python; builtins, so that the Python-side always deals with true Python objects; or; adjust the C++ interfaces to be the same as their Python equivalents.; Neither is very satisfactory: the former is not because of the existence of; global/static variables and return-by-reference.; If only a copy is available, then expected modifications do not propagate.; Copying is also either slow (when copying every time) or memory intensive (if; the results are cached).; Filling out the interfaces may look more appealing, but all operations then; involve C++ function calls, which can be slower than the Python equivalents,; and C++-style error handling. Given that neither choice will satisfy all cases, ``cppyy`` aims to maximize; functionality and minimum surprises based on common use.; Thus, for example, ``std::vector`` grows a pythonistic ``__len__`` method,; but does not lose its C++ ``size`` method.; Passing a Python container through a const reference to a ``std::vector``; will trigger automatic conversion, but such an attempt through a non-const; reference will fail since a non-temporary C++ object is required [#f1]_ to; return any updates/changes. ``std::string`` is almost always converted to Python's ``str`` on function; returns (the exception is return-by-reference when assigning), but not when; its direct use is more likely such as in the case of (global) variables or; when iterating over a ``std::vector<std::string>``. The rest of this section shows examples of how STL containers can be used in; a natural, pythonistic, way. `std::vec",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/stl.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/stl.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/stl.rst:1819,Modifiability,variab,variables,1819,"s available, then expected modifications do not propagate.; Copying is also either slow (when copying every time) or memory intensive (if; the results are cached).; Filling out the interfaces may look more appealing, but all operations then; involve C++ function calls, which can be slower than the Python equivalents,; and C++-style error handling. Given that neither choice will satisfy all cases, ``cppyy`` aims to maximize; functionality and minimum surprises based on common use.; Thus, for example, ``std::vector`` grows a pythonistic ``__len__`` method,; but does not lose its C++ ``size`` method.; Passing a Python container through a const reference to a ``std::vector``; will trigger automatic conversion, but such an attempt through a non-const; reference will fail since a non-temporary C++ object is required [#f1]_ to; return any updates/changes. ``std::string`` is almost always converted to Python's ``str`` on function; returns (the exception is return-by-reference when assigning), but not when; its direct use is more likely such as in the case of (global) variables or; when iterating over a ``std::vector<std::string>``. The rest of this section shows examples of how STL containers can be used in; a natural, pythonistic, way. `std::vector`; -------------. A ``std::vector`` is the most commonly used C++ container type because it is; more efficient and performant than specialized types such as ``list`` and; ``map``, unless the number of elements gets very large.; Python has several similar types, from the builtin ``tuple`` and ``list``,; the ``array`` from builtin module ``array``, to ""as-good-as-builtin""; ``numpy.ndarray``.; A vector is more like the latter two in that it can contain only one type,; but more like the former two in that it can contain objects.; In practice, it can interplay well with all these containers, but e.g.; efficiency and performance can differ significantly. A vector can be instantiated from any sequence, including generators, and; vectors ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/stl.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/stl.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/stl.rst:3296,Modifiability,extend,extend,3296,"`array``, to ""as-good-as-builtin""; ``numpy.ndarray``.; A vector is more like the latter two in that it can contain only one type,; but more like the former two in that it can contain objects.; In practice, it can interplay well with all these containers, but e.g.; efficiency and performance can differ significantly. A vector can be instantiated from any sequence, including generators, and; vectors of objects can be recursively constructed.; If the template type is to be inferred from the argument to the constructor,; the first element needs to be accessible, which precludes generators. .. code-block:: python. >>> from cppyy.gbl.std import vector, pair; >>> v = vector[int](range(10)) # from generator; >>> len(v); 10; >>> v = vector([x for x in range(10)]) # type inferred; >>> type(v); <class cppyy.gbl.std.vector<int> at 0x12d226f00>; >>> len(v); 10; >>> vp = vector[pair[int, int]](((1, 2), (3, 4))); >>> len(vp); 2; >>> vp[1][0]; 3; >>>. To extend a vector in-place with another sequence object, use ``+=``, just as; for Python's ``list``:. .. code-block:: python. >>> v += range(10, 20); >>> len(v); 20; >>>. Indexing and slicing of a vector follows the normal Python slicing rules;; printing a vector prints all its elements:. .. code-block:: python. >>> v[1]; 1; >>> v[-1]; 19; >>> v[-4:]; <cppyy.gbl.std.vector<int> object at 0x7f9051057650>; >>> print(v[-4:]); { 6, 7, 8, 9 }; >>>. The usual iteration operations work on vector, but the C++ rules still apply,; so a vector that is being iterated over can *not* be modified in the loop; body.; (On the plus side, this makes it much faster to iterate over a vector than,; say, a numpy ndarray.). .. code-block:: python. >>> for i in v[2:5]:; ... print(i); ...; 2; 3; 4; >>> 2 in v; True; >>> sum(v); 190; >>>. When a function takes a non-l-value (const-ref, move, or by-value) vector as; a parameter, another sequence can be used and cppyy will automatically; generate a temporary.; Typically, this will be faster than coding up such a ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/stl.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/stl.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/stl.rst:5126,Modifiability,flexible,flexible,5126,"takes a non-l-value (const-ref, move, or by-value) vector as; a parameter, another sequence can be used and cppyy will automatically; generate a temporary.; Typically, this will be faster than coding up such a temporary on the Python; side, but if the same sequence is used multiple times, creating a temporary; once and re-using it will be the most efficient approach.o. .. code-block:: python. >>> cppyy.cppdef(""""""; ... int sumit1(const std::vector<int>& data) {; ... return std::accumulate(data.begin(), data.end(), 0);; ... }; ... int sumit2(std::vector<int> data) {; ... return std::accumulate(data.begin(), data.end(), 0);; ... }; ... int sumit3(const std::vector<int>&& data) {; ... return std::accumulate(data.begin(), data.end(), 0);; ... }""""""); ...; True; >>> cppyy.gbl.sumit1(range(5)); 10; >>> cppyy.gbl.sumit2(range(6)); 16; >>> cppyy.gbl.sumit3(range(7)); 21; >>>. The temporary vector is created using the vector constructor taking an; ``std::initializer_list``, which is more flexible than constructing a; temporary vector and filling it: it allows the data in the container to be; implicitly converted (e.g. from ``int`` to ``double`` type, or from; pointer to derived to pointer to base class).; As a consequence, however, with STL containers being allowed where Python; containers are, this in turn means that you can pass e.g. an; ``std::vector<int>`` (or ``std::list<int>``) where a ``std::vector<double>``; is expected and a temporary is allowed:. .. code-block:: python. >>> cppyy.cppdef(""""""; ... double sumit4(const std::vector<double>& data) {; ... return std::accumulate(data.begin(), data.end(), 0);; ... }""""""); ...; True; >>> cppyy.gbl.sumit4(vector[int](range(7))); 21.0; >>>. Normal overload resolution rules continue to apply, however, thus if an; overload were available that takes an ``const std::vector<int>&``, it would; be preferred. When templates are involved, overload resolution is stricter, to ensure that; a better matching instantiation is preferred over an",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/stl.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/stl.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/stl.rst:6214,Modifiability,flexible,flexible,6214,"e.g. from ``int`` to ``double`` type, or from; pointer to derived to pointer to base class).; As a consequence, however, with STL containers being allowed where Python; containers are, this in turn means that you can pass e.g. an; ``std::vector<int>`` (or ``std::list<int>``) where a ``std::vector<double>``; is expected and a temporary is allowed:. .. code-block:: python. >>> cppyy.cppdef(""""""; ... double sumit4(const std::vector<double>& data) {; ... return std::accumulate(data.begin(), data.end(), 0);; ... }""""""); ...; True; >>> cppyy.gbl.sumit4(vector[int](range(7))); 21.0; >>>. Normal overload resolution rules continue to apply, however, thus if an; overload were available that takes an ``const std::vector<int>&``, it would; be preferred. When templates are involved, overload resolution is stricter, to ensure that; a better matching instantiation is preferred over an implicit conversion.; However, that does mean that as-is, C++ is actually more flexible: it has the; curly braces initializer syntax to explicitly infer an; ``std::initializer_list``, with no such equivalent in Python. Although in general this approach guarantees the intended result, it does put; some strictures on the Python side, requiring careful use of types.; However, an easily fixable error is preferable over an implicitly wrong; result.; Note the type of the init argument in the call resulting in an (attempted); implicit instantiation in the following example:. .. code-block:: python. >>> cppyy.cppdef(""""""; ... template<class T>; ... T sumit_T(const std::vector<T>& data, T init) {; ... return std::accumulate(data.begin(), data.end(), init);; ... }""""""); ...; True; >>> cppyy.gbl.sumit_T(vector['double'](range(7)), 0); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; TypeError: Template method resolution failed:; Failed to instantiate ""sumit_T(std::vector<double>&,int)""; Failed to instantiate ""sumit_T(std::vector<double>*,int)""; Failed to instantiate ""sumit_T(std::vector<doub",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/stl.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/stl.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/stl.rst:898,Performance,cache,cached,898,".. _stl:. STL; ===. Parts of the Standard Template Library (STL), in particular its container; types, are the de facto equivalent of Python's builtin types.; STL is written in C++ and Python bindings of it are fully functional as-is,; but are much more useful when pluggable into idiomatic expressions where; Python builtin containers are expected (e.g. in list contractions). There are two extremes to achieve such drop-in behavior: copy into Python; builtins, so that the Python-side always deals with true Python objects; or; adjust the C++ interfaces to be the same as their Python equivalents.; Neither is very satisfactory: the former is not because of the existence of; global/static variables and return-by-reference.; If only a copy is available, then expected modifications do not propagate.; Copying is also either slow (when copying every time) or memory intensive (if; the results are cached).; Filling out the interfaces may look more appealing, but all operations then; involve C++ function calls, which can be slower than the Python equivalents,; and C++-style error handling. Given that neither choice will satisfy all cases, ``cppyy`` aims to maximize; functionality and minimum surprises based on common use.; Thus, for example, ``std::vector`` grows a pythonistic ``__len__`` method,; but does not lose its C++ ``size`` method.; Passing a Python container through a const reference to a ``std::vector``; will trigger automatic conversion, but such an attempt through a non-const; reference will fail since a non-temporary C++ object is required [#f1]_ to; return any updates/changes. ``std::string`` is almost always converted to Python's ``str`` on function; returns (the exception is return-by-reference when assigning), but not when; its direct use is more likely such as in the case of (global) variables or; when iterating over a ``std::vector<std::string>``. The rest of this section shows examples of how STL containers can be used in; a natural, pythonistic, way. `std::vec",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/stl.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/stl.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/stl.rst:2119,Performance,perform,performant,2119,"atisfy all cases, ``cppyy`` aims to maximize; functionality and minimum surprises based on common use.; Thus, for example, ``std::vector`` grows a pythonistic ``__len__`` method,; but does not lose its C++ ``size`` method.; Passing a Python container through a const reference to a ``std::vector``; will trigger automatic conversion, but such an attempt through a non-const; reference will fail since a non-temporary C++ object is required [#f1]_ to; return any updates/changes. ``std::string`` is almost always converted to Python's ``str`` on function; returns (the exception is return-by-reference when assigning), but not when; its direct use is more likely such as in the case of (global) variables or; when iterating over a ``std::vector<std::string>``. The rest of this section shows examples of how STL containers can be used in; a natural, pythonistic, way. `std::vector`; -------------. A ``std::vector`` is the most commonly used C++ container type because it is; more efficient and performant than specialized types such as ``list`` and; ``map``, unless the number of elements gets very large.; Python has several similar types, from the builtin ``tuple`` and ``list``,; the ``array`` from builtin module ``array``, to ""as-good-as-builtin""; ``numpy.ndarray``.; A vector is more like the latter two in that it can contain only one type,; but more like the former two in that it can contain objects.; In practice, it can interplay well with all these containers, but e.g.; efficiency and performance can differ significantly. A vector can be instantiated from any sequence, including generators, and; vectors of objects can be recursively constructed.; If the template type is to be inferred from the argument to the constructor,; the first element needs to be accessible, which precludes generators. .. code-block:: python. >>> from cppyy.gbl.std import vector, pair; >>> v = vector[int](range(10)) # from generator; >>> len(v); 10; >>> v = vector([x for x in range(10)]) # type inferred; >",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/stl.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/stl.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/stl.rst:2623,Performance,perform,performance,2623,"ays converted to Python's ``str`` on function; returns (the exception is return-by-reference when assigning), but not when; its direct use is more likely such as in the case of (global) variables or; when iterating over a ``std::vector<std::string>``. The rest of this section shows examples of how STL containers can be used in; a natural, pythonistic, way. `std::vector`; -------------. A ``std::vector`` is the most commonly used C++ container type because it is; more efficient and performant than specialized types such as ``list`` and; ``map``, unless the number of elements gets very large.; Python has several similar types, from the builtin ``tuple`` and ``list``,; the ``array`` from builtin module ``array``, to ""as-good-as-builtin""; ``numpy.ndarray``.; A vector is more like the latter two in that it can contain only one type,; but more like the former two in that it can contain objects.; In practice, it can interplay well with all these containers, but e.g.; efficiency and performance can differ significantly. A vector can be instantiated from any sequence, including generators, and; vectors of objects can be recursively constructed.; If the template type is to be inferred from the argument to the constructor,; the first element needs to be accessible, which precludes generators. .. code-block:: python. >>> from cppyy.gbl.std import vector, pair; >>> v = vector[int](range(10)) # from generator; >>> len(v); 10; >>> v = vector([x for x in range(10)]) # type inferred; >>> type(v); <class cppyy.gbl.std.vector<int> at 0x12d226f00>; >>> len(v); 10; >>> vp = vector[pair[int, int]](((1, 2), (3, 4))); >>> len(vp); 2; >>> vp[1][0]; 3; >>>. To extend a vector in-place with another sequence object, use ``+=``, just as; for Python's ``list``:. .. code-block:: python. >>> v += range(10, 20); >>> len(v); 20; >>>. Indexing and slicing of a vector follows the normal Python slicing rules;; printing a vector prints all its elements:. .. code-block:: python. >>> v[1]; 1; >>> v[-1]; 1",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/stl.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/stl.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/stl.rst:2896,Security,access,accessible,2896,"::vector<std::string>``. The rest of this section shows examples of how STL containers can be used in; a natural, pythonistic, way. `std::vector`; -------------. A ``std::vector`` is the most commonly used C++ container type because it is; more efficient and performant than specialized types such as ``list`` and; ``map``, unless the number of elements gets very large.; Python has several similar types, from the builtin ``tuple`` and ``list``,; the ``array`` from builtin module ``array``, to ""as-good-as-builtin""; ``numpy.ndarray``.; A vector is more like the latter two in that it can contain only one type,; but more like the former two in that it can contain objects.; In practice, it can interplay well with all these containers, but e.g.; efficiency and performance can differ significantly. A vector can be instantiated from any sequence, including generators, and; vectors of objects can be recursively constructed.; If the template type is to be inferred from the argument to the constructor,; the first element needs to be accessible, which precludes generators. .. code-block:: python. >>> from cppyy.gbl.std import vector, pair; >>> v = vector[int](range(10)) # from generator; >>> len(v); 10; >>> v = vector([x for x in range(10)]) # type inferred; >>> type(v); <class cppyy.gbl.std.vector<int> at 0x12d226f00>; >>> len(v); 10; >>> vp = vector[pair[int, int]](((1, 2), (3, 4))); >>> len(vp); 2; >>> vp[1][0]; 3; >>>. To extend a vector in-place with another sequence object, use ``+=``, just as; for Python's ``list``:. .. code-block:: python. >>> v += range(10, 20); >>> len(v); 20; >>>. Indexing and slicing of a vector follows the normal Python slicing rules;; printing a vector prints all its elements:. .. code-block:: python. >>> v[1]; 1; >>> v[-1]; 19; >>> v[-4:]; <cppyy.gbl.std.vector<int> object at 0x7f9051057650>; >>> print(v[-4:]); { 6, 7, 8, 9 }; >>>. The usual iteration operations work on vector, but the C++ rules still apply,; so a vector that is being iterated over ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/stl.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/stl.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/stl.rst:8550,Security,access,access,8550,"trictions without causing incorrect results. `std::map`; ----------. C++'s ``map`` is an associative container similar to Python's ``dict``,; albeit one that has stronger type constraints.; A ``map`` can be instantiated from a ``dict`` (and types can be inferred) or; from a collection of ``pair`` mappings. .. code-block:: python. >>> from cppyy.gbl.std import map; >>> m = map[str, int](*(""one"", 1), (""two"", 2))) # type explicit, from pairs; >>> print(m); { ""one"" => 1, ""two"" => 2 }; >>> m = map({1: ""one"", 2: ""two""}) # type implicit, from dict; >>> type(m); <class cppyy.gbl.std.map<int,std::string> at 0x12d068d60>; >>> print(m); { 1 => ""one"", 2 => ""two"" }; >>>. `std::string`; -------------. Python's `str` is a unicode type since Python3, whereas ``std::string`` is; single-byte char-based.; Having the two correctly interact therefore deserves it's own; :doc:`chapter <strings>`. `std::tuple`; ------------. C++ ``tuple`` is supported but it should be noted that its use, and in; particular instantiating (heavily overloaded) ``get<>`` functions for member; access is inefficient.; They are really only meant for use when you have to pass a ``tuple`` to C++; code; and if returned from a C++ function, it is easier to simply unpack them.; In all other cases, prefer Python's builtin ``tuple``.; Example usage:. .. code-block:: python. >>> from cppyy.gbl.std import make_tuple, get; >>> t = make_tuple(1, '2', 5.); >>> print(t); <cppyy.gbl.std.tuple<int,std::string,double> object at 0x12033ee70>; >>> len(t); 3; >>> get[0](t) # access with templated std::get<>; 1; >>> get[1](t); b'2'; >>> get[2](t); 5.0; >>> a, b, c = t # unpack through iteration; >>> print(a, b, c); 1 2 5.0; >>>. .. rubric:: Footnotes. .. [#f1] The meaning of ""temporary"" differs between Python and C++: in a statement such as ``func(std.vector[int]((1, 2, 3)))``, there is no temporary as far as Python is concerned, even as there clearly is in the case of a similar statement in C++. Thus that call will succeed even if `",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/stl.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/stl.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/stl.rst:9020,Security,access,access,9020,"ults. `std::map`; ----------. C++'s ``map`` is an associative container similar to Python's ``dict``,; albeit one that has stronger type constraints.; A ``map`` can be instantiated from a ``dict`` (and types can be inferred) or; from a collection of ``pair`` mappings. .. code-block:: python. >>> from cppyy.gbl.std import map; >>> m = map[str, int](*(""one"", 1), (""two"", 2))) # type explicit, from pairs; >>> print(m); { ""one"" => 1, ""two"" => 2 }; >>> m = map({1: ""one"", 2: ""two""}) # type implicit, from dict; >>> type(m); <class cppyy.gbl.std.map<int,std::string> at 0x12d068d60>; >>> print(m); { 1 => ""one"", 2 => ""two"" }; >>>. `std::string`; -------------. Python's `str` is a unicode type since Python3, whereas ``std::string`` is; single-byte char-based.; Having the two correctly interact therefore deserves it's own; :doc:`chapter <strings>`. `std::tuple`; ------------. C++ ``tuple`` is supported but it should be noted that its use, and in; particular instantiating (heavily overloaded) ``get<>`` functions for member; access is inefficient.; They are really only meant for use when you have to pass a ``tuple`` to C++; code; and if returned from a C++ function, it is easier to simply unpack them.; In all other cases, prefer Python's builtin ``tuple``.; Example usage:. .. code-block:: python. >>> from cppyy.gbl.std import make_tuple, get; >>> t = make_tuple(1, '2', 5.); >>> print(t); <cppyy.gbl.std.tuple<int,std::string,double> object at 0x12033ee70>; >>> len(t); 3; >>> get[0](t) # access with templated std::get<>; 1; >>> get[1](t); b'2'; >>> get[2](t); 5.0; >>> a, b, c = t # unpack through iteration; >>> print(a, b, c); 1 2 5.0; >>>. .. rubric:: Footnotes. .. [#f1] The meaning of ""temporary"" differs between Python and C++: in a statement such as ``func(std.vector[int]((1, 2, 3)))``, there is no temporary as far as Python is concerned, even as there clearly is in the case of a similar statement in C++. Thus that call will succeed even if ``func`` takes a non-const reference.; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/stl.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/stl.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/stl.rst:7375,Usability,simpl,simplistic,7375,"ut; some strictures on the Python side, requiring careful use of types.; However, an easily fixable error is preferable over an implicitly wrong; result.; Note the type of the init argument in the call resulting in an (attempted); implicit instantiation in the following example:. .. code-block:: python. >>> cppyy.cppdef(""""""; ... template<class T>; ... T sumit_T(const std::vector<T>& data, T init) {; ... return std::accumulate(data.begin(), data.end(), init);; ... }""""""); ...; True; >>> cppyy.gbl.sumit_T(vector['double'](range(7)), 0); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; TypeError: Template method resolution failed:; Failed to instantiate ""sumit_T(std::vector<double>&,int)""; Failed to instantiate ""sumit_T(std::vector<double>*,int)""; Failed to instantiate ""sumit_T(std::vector<double>,int)""; >>> cppyy.gbl.sumit_T(vector['double'](range(7)), 0.); 21.0; >>>. To be sure, the code is `too` strict in the simplistic example above, and; with a future version of Cling it should be possible to lift some of these; restrictions without causing incorrect results. `std::map`; ----------. C++'s ``map`` is an associative container similar to Python's ``dict``,; albeit one that has stronger type constraints.; A ``map`` can be instantiated from a ``dict`` (and types can be inferred) or; from a collection of ``pair`` mappings. .. code-block:: python. >>> from cppyy.gbl.std import map; >>> m = map[str, int](*(""one"", 1), (""two"", 2))) # type explicit, from pairs; >>> print(m); { ""one"" => 1, ""two"" => 2 }; >>> m = map({1: ""one"", 2: ""two""}) # type implicit, from dict; >>> type(m); <class cppyy.gbl.std.map<int,std::string> at 0x12d068d60>; >>> print(m); { 1 => ""one"", 2 => ""two"" }; >>>. `std::string`; -------------. Python's `str` is a unicode type since Python3, whereas ``std::string`` is; single-byte char-based.; Having the two correctly interact therefore deserves it's own; :doc:`chapter <strings>`. `std::tuple`; ------------. C++ ``tuple`` is supported but",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/stl.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/stl.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/stl.rst:8710,Usability,simpl,simply,8710,"ults. `std::map`; ----------. C++'s ``map`` is an associative container similar to Python's ``dict``,; albeit one that has stronger type constraints.; A ``map`` can be instantiated from a ``dict`` (and types can be inferred) or; from a collection of ``pair`` mappings. .. code-block:: python. >>> from cppyy.gbl.std import map; >>> m = map[str, int](*(""one"", 1), (""two"", 2))) # type explicit, from pairs; >>> print(m); { ""one"" => 1, ""two"" => 2 }; >>> m = map({1: ""one"", 2: ""two""}) # type implicit, from dict; >>> type(m); <class cppyy.gbl.std.map<int,std::string> at 0x12d068d60>; >>> print(m); { 1 => ""one"", 2 => ""two"" }; >>>. `std::string`; -------------. Python's `str` is a unicode type since Python3, whereas ``std::string`` is; single-byte char-based.; Having the two correctly interact therefore deserves it's own; :doc:`chapter <strings>`. `std::tuple`; ------------. C++ ``tuple`` is supported but it should be noted that its use, and in; particular instantiating (heavily overloaded) ``get<>`` functions for member; access is inefficient.; They are really only meant for use when you have to pass a ``tuple`` to C++; code; and if returned from a C++ function, it is easier to simply unpack them.; In all other cases, prefer Python's builtin ``tuple``.; Example usage:. .. code-block:: python. >>> from cppyy.gbl.std import make_tuple, get; >>> t = make_tuple(1, '2', 5.); >>> print(t); <cppyy.gbl.std.tuple<int,std::string,double> object at 0x12033ee70>; >>> len(t); 3; >>> get[0](t) # access with templated std::get<>; 1; >>> get[1](t); b'2'; >>> get[2](t); 5.0; >>> a, b, c = t # unpack through iteration; >>> print(a, b, c); 1 2 5.0; >>>. .. rubric:: Footnotes. .. [#f1] The meaning of ""temporary"" differs between Python and C++: in a statement such as ``func(std.vector[int]((1, 2, 3)))``, there is no temporary as far as Python is concerned, even as there clearly is in the case of a similar statement in C++. Thus that call will succeed even if ``func`` takes a non-const reference.; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/stl.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/stl.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/stl.rst:9395,Usability,clear,clearly,9395,"ults. `std::map`; ----------. C++'s ``map`` is an associative container similar to Python's ``dict``,; albeit one that has stronger type constraints.; A ``map`` can be instantiated from a ``dict`` (and types can be inferred) or; from a collection of ``pair`` mappings. .. code-block:: python. >>> from cppyy.gbl.std import map; >>> m = map[str, int](*(""one"", 1), (""two"", 2))) # type explicit, from pairs; >>> print(m); { ""one"" => 1, ""two"" => 2 }; >>> m = map({1: ""one"", 2: ""two""}) # type implicit, from dict; >>> type(m); <class cppyy.gbl.std.map<int,std::string> at 0x12d068d60>; >>> print(m); { 1 => ""one"", 2 => ""two"" }; >>>. `std::string`; -------------. Python's `str` is a unicode type since Python3, whereas ``std::string`` is; single-byte char-based.; Having the two correctly interact therefore deserves it's own; :doc:`chapter <strings>`. `std::tuple`; ------------. C++ ``tuple`` is supported but it should be noted that its use, and in; particular instantiating (heavily overloaded) ``get<>`` functions for member; access is inefficient.; They are really only meant for use when you have to pass a ``tuple`` to C++; code; and if returned from a C++ function, it is easier to simply unpack them.; In all other cases, prefer Python's builtin ``tuple``.; Example usage:. .. code-block:: python. >>> from cppyy.gbl.std import make_tuple, get; >>> t = make_tuple(1, '2', 5.); >>> print(t); <cppyy.gbl.std.tuple<int,std::string,double> object at 0x12033ee70>; >>> len(t); 3; >>> get[0](t) # access with templated std::get<>; 1; >>> get[1](t); b'2'; >>> get[2](t); 5.0; >>> a, b, c = t # unpack through iteration; >>> print(a, b, c); 1 2 5.0; >>>. .. rubric:: Footnotes. .. [#f1] The meaning of ""temporary"" differs between Python and C++: in a statement such as ``func(std.vector[int]((1, 2, 3)))``, there is no temporary as far as Python is concerned, even as there clearly is in the case of a similar statement in C++. Thus that call will succeed even if ``func`` takes a non-const reference.; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/stl.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/stl.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/strings.rst:3654,Energy Efficiency,allocate,allocated,3654,"requires the unicode object to be encoded and by default,; UTF-8 is chosen.; This will give the expected result if all characters in the ``str`` are from; the ASCII set, but otherwise it is recommend to encode on the Python side and; pass the resulting ``bytes`` object instead. `std::wstring`; """""""""""""""""""""""""""". C++'s ""wide"" string, ``std::wstring``, is based on ``wchar_t``, a character; type that is not particularly portable as it can be 2 or 4 bytes in size,; depending on the platform.; cppyy supports ``std::wstring`` directly, using the ``wchar_t`` array; conversions provided by Python's C-API. `const char*`; """""""""""""""""""""""""". The C representation of text, ``const char*``, is problematic for two; reasons: it does not express ownership; and its length is implicit, namely up; to the first occurrence of ``'\0'``.; The first can, up to an extent, be ameliorated: there are a range of cases; where ownership can be inferred.; In particular, if the C string is set from a Python ``str``, it is the latter; that owns the memory and the bound proxy of the former that in turn owns the; (unconverted) ``str`` instance.; However, if the ``const char*``'s memory is allocated in C/C++, memory; management is by necessity fully manual.; Length, on the other hand, can only be known in the case of a fixed array.; However even then, the more common case is to use the fixed array as a; buffer, with the actual string still only extending up to the ``'\0'`` char,; so that is assumed.; (C++'s ``std::string`` suffers from none of these issues and should always be; preferred when you have a choice.). `char*`; """""""""""""". The C representation of a character array, ``char*``, has all the problems of; ``const char*``, but in addition is often used as ""data array of 8-bit int"". `character types`; """""""""""""""""""""""""""""""""". cppyy directly supports the following character types, both as single; variables and in array form: ``char``, ``signed char``, ``unsigned char``,; ``wchar_t``, ``char16_t``, and ``char32_t``. ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/strings.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/strings.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/strings.rst:2953,Integrability,depend,depending,2953," 42} # dict filled with str; >>> d[cppyy.gbl.gs] # drop-in use of std::string -> str; 42; >>>. To handle codecs other than UTF-8, the ``std::string`` pythonization adds a; ``decode`` method, with the same signature as the equivalent method of; ``bytes``.; If it is known that a specific C++ function always returns an ``std::string``; representing unicode with a codec other than UTF-8, it can in turn be; explicitly pythonized to do the conversion with that codec. `std::string_view`; """""""""""""""""""""""""""""""""""". It is possible to construct a (char-based) ``std::string_view`` from a Python; ``str``, but it requires the unicode object to be encoded and by default,; UTF-8 is chosen.; This will give the expected result if all characters in the ``str`` are from; the ASCII set, but otherwise it is recommend to encode on the Python side and; pass the resulting ``bytes`` object instead. `std::wstring`; """""""""""""""""""""""""""". C++'s ""wide"" string, ``std::wstring``, is based on ``wchar_t``, a character; type that is not particularly portable as it can be 2 or 4 bytes in size,; depending on the platform.; cppyy supports ``std::wstring`` directly, using the ``wchar_t`` array; conversions provided by Python's C-API. `const char*`; """""""""""""""""""""""""". The C representation of text, ``const char*``, is problematic for two; reasons: it does not express ownership; and its length is implicit, namely up; to the first occurrence of ``'\0'``.; The first can, up to an extent, be ameliorated: there are a range of cases; where ownership can be inferred.; In particular, if the C string is set from a Python ``str``, it is the latter; that owns the memory and the bound proxy of the former that in turn owns the; (unconverted) ``str`` instance.; However, if the ``const char*``'s memory is allocated in C/C++, memory; management is by necessity fully manual.; Length, on the other hand, can only be known in the case of a fixed array.; However even then, the more common case is to use the fixed array as a; buffer, with the a",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/strings.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/strings.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/strings.rst:1510,Modifiability,variab,variables,1510,"but are also fully supported. `std::string`; """""""""""""""""""""""""". The C++ core type ``std::string`` is considered the equivalent of Python's; ``str``, even as purely implementation-wise, it is more akin to ``bytes``:; as a practical matter, a C++ programmer would use ``std::string`` where a; Python developer would use ``str`` (and vice versa), not ``bytes``. A Python ``str`` is unicode, however, whereas an ``std::string`` is character; based, thus conversions require encoding or decoding.; To allow for different encodings, ``cppyy`` defers implicit conversions; between the two types until forced, at which point it will default to seeing; ``std::string`` as ASCII based and ``str`` to use the UTF-8 codec.; To support this, the bound ``std::string`` has been pythonized to allow it to; be a drop-in for a range of uses as appropriate within the local context. In particular, it is sometimes necessary (e.g. for function arguments that; take a non-const reference or a pointer to non-const ``std::string``; variables), to use an actual ``std::string`` instance to allow in-place; modifications.; The pythonizations then allow their use where ``str`` is expected.; For example:. .. code-block:: python. >>> cppyy.cppexec(""std::string gs;""); True; >>> cppyy.gbl.gs = ""hello""; >>> type(cppyy.gbl.gs) # C++ std::string type; <class cppyy.gbl.std.string at 0x7fbb02a89880>; >>> d = {""hello"": 42} # dict filled with str; >>> d[cppyy.gbl.gs] # drop-in use of std::string -> str; 42; >>>. To handle codecs other than UTF-8, the ``std::string`` pythonization adds a; ``decode`` method, with the same signature as the equivalent method of; ``bytes``.; If it is known that a specific C++ function always returns an ``std::string``; representing unicode with a codec other than UTF-8, it can in turn be; explicitly pythonized to do the conversion with that codec. `std::string_view`; """""""""""""""""""""""""""""""""""". It is possible to construct a (char-based) ``std::string_view`` from a Python; ``str``, but it requires the u",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/strings.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/strings.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/strings.rst:2908,Modifiability,portab,portable,2908," 42} # dict filled with str; >>> d[cppyy.gbl.gs] # drop-in use of std::string -> str; 42; >>>. To handle codecs other than UTF-8, the ``std::string`` pythonization adds a; ``decode`` method, with the same signature as the equivalent method of; ``bytes``.; If it is known that a specific C++ function always returns an ``std::string``; representing unicode with a codec other than UTF-8, it can in turn be; explicitly pythonized to do the conversion with that codec. `std::string_view`; """""""""""""""""""""""""""""""""""". It is possible to construct a (char-based) ``std::string_view`` from a Python; ``str``, but it requires the unicode object to be encoded and by default,; UTF-8 is chosen.; This will give the expected result if all characters in the ``str`` are from; the ASCII set, but otherwise it is recommend to encode on the Python side and; pass the resulting ``bytes`` object instead. `std::wstring`; """""""""""""""""""""""""""". C++'s ""wide"" string, ``std::wstring``, is based on ``wchar_t``, a character; type that is not particularly portable as it can be 2 or 4 bytes in size,; depending on the platform.; cppyy supports ``std::wstring`` directly, using the ``wchar_t`` array; conversions provided by Python's C-API. `const char*`; """""""""""""""""""""""""". The C representation of text, ``const char*``, is problematic for two; reasons: it does not express ownership; and its length is implicit, namely up; to the first occurrence of ``'\0'``.; The first can, up to an extent, be ameliorated: there are a range of cases; where ownership can be inferred.; In particular, if the C string is set from a Python ``str``, it is the latter; that owns the memory and the bound proxy of the former that in turn owns the; (unconverted) ``str`` instance.; However, if the ``const char*``'s memory is allocated in C/C++, memory; management is by necessity fully manual.; Length, on the other hand, can only be known in the case of a fixed array.; However even then, the more common case is to use the fixed array as a; buffer, with the a",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/strings.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/strings.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/strings.rst:3914,Modifiability,extend,extending,3914,"requires the unicode object to be encoded and by default,; UTF-8 is chosen.; This will give the expected result if all characters in the ``str`` are from; the ASCII set, but otherwise it is recommend to encode on the Python side and; pass the resulting ``bytes`` object instead. `std::wstring`; """""""""""""""""""""""""""". C++'s ""wide"" string, ``std::wstring``, is based on ``wchar_t``, a character; type that is not particularly portable as it can be 2 or 4 bytes in size,; depending on the platform.; cppyy supports ``std::wstring`` directly, using the ``wchar_t`` array; conversions provided by Python's C-API. `const char*`; """""""""""""""""""""""""". The C representation of text, ``const char*``, is problematic for two; reasons: it does not express ownership; and its length is implicit, namely up; to the first occurrence of ``'\0'``.; The first can, up to an extent, be ameliorated: there are a range of cases; where ownership can be inferred.; In particular, if the C string is set from a Python ``str``, it is the latter; that owns the memory and the bound proxy of the former that in turn owns the; (unconverted) ``str`` instance.; However, if the ``const char*``'s memory is allocated in C/C++, memory; management is by necessity fully manual.; Length, on the other hand, can only be known in the case of a fixed array.; However even then, the more common case is to use the fixed array as a; buffer, with the actual string still only extending up to the ``'\0'`` char,; so that is assumed.; (C++'s ``std::string`` suffers from none of these issues and should always be; preferred when you have a choice.). `char*`; """""""""""""". The C representation of a character array, ``char*``, has all the problems of; ``const char*``, but in addition is often used as ""data array of 8-bit int"". `character types`; """""""""""""""""""""""""""""""""". cppyy directly supports the following character types, both as single; variables and in array form: ``char``, ``signed char``, ``unsigned char``,; ``wchar_t``, ``char16_t``, and ``char32_t``. ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/strings.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/strings.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/strings.rst:4369,Modifiability,variab,variables,4369,"requires the unicode object to be encoded and by default,; UTF-8 is chosen.; This will give the expected result if all characters in the ``str`` are from; the ASCII set, but otherwise it is recommend to encode on the Python side and; pass the resulting ``bytes`` object instead. `std::wstring`; """""""""""""""""""""""""""". C++'s ""wide"" string, ``std::wstring``, is based on ``wchar_t``, a character; type that is not particularly portable as it can be 2 or 4 bytes in size,; depending on the platform.; cppyy supports ``std::wstring`` directly, using the ``wchar_t`` array; conversions provided by Python's C-API. `const char*`; """""""""""""""""""""""""". The C representation of text, ``const char*``, is problematic for two; reasons: it does not express ownership; and its length is implicit, namely up; to the first occurrence of ``'\0'``.; The first can, up to an extent, be ameliorated: there are a range of cases; where ownership can be inferred.; In particular, if the C string is set from a Python ``str``, it is the latter; that owns the memory and the bound proxy of the former that in turn owns the; (unconverted) ``str`` instance.; However, if the ``const char*``'s memory is allocated in C/C++, memory; management is by necessity fully manual.; Length, on the other hand, can only be known in the case of a fixed array.; However even then, the more common case is to use the fixed array as a; buffer, with the actual string still only extending up to the ``'\0'`` char,; so that is assumed.; (C++'s ``std::string`` suffers from none of these issues and should always be; preferred when you have a choice.). `char*`; """""""""""""". The C representation of a character array, ``char*``, has all the problems of; ``const char*``, but in addition is often used as ""data array of 8-bit int"". `character types`; """""""""""""""""""""""""""""""""". cppyy directly supports the following character types, both as single; variables and in array form: ``char``, ``signed char``, ``unsigned char``,; ``wchar_t``, ``char16_t``, and ``char32_t``. ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/strings.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/strings.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/testing.rst:343,Deployability,install,install,343,".. _testing:. Test suite; ==========. The cppyy tests live in the top-level cppyy package, can be run for; both CPython and PyPy, and exercises the full setup, including the backend.; Most tests are standalone and can be run independently, with a few exceptions; in the template tests (see file ``test_templates.py``). To run the tests, first install cppyy by any usual means, then clone the; cppyy repo, and enter the ``test`` directory::. $ git clone https://github.com/wlav/cppyy.git; $ cd cppyy/test. Next, build the dictionaries, the manner of which depends on your platform.; On Linux or MacOS-X, run ``make``::. $ make all. On Windows, run the dictionary building script::. $ python make_dict_win32.py all. Next, make sure you have `pytest`_ installed, for example with ``pip``::. $ python -m pip install pytest. and finally run the tests::. $ python -m pytest -sv. On Linux and MacOS-X, all tests should succeed.; On MS Windows 32bit there are 4 failing tests, on 64bit there are 5 still; failing. .. _`pytest`: https://docs.pytest.org/en/latest/; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/testing.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/testing.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/testing.rst:749,Deployability,install,installed,749,".. _testing:. Test suite; ==========. The cppyy tests live in the top-level cppyy package, can be run for; both CPython and PyPy, and exercises the full setup, including the backend.; Most tests are standalone and can be run independently, with a few exceptions; in the template tests (see file ``test_templates.py``). To run the tests, first install cppyy by any usual means, then clone the; cppyy repo, and enter the ``test`` directory::. $ git clone https://github.com/wlav/cppyy.git; $ cd cppyy/test. Next, build the dictionaries, the manner of which depends on your platform.; On Linux or MacOS-X, run ``make``::. $ make all. On Windows, run the dictionary building script::. $ python make_dict_win32.py all. Next, make sure you have `pytest`_ installed, for example with ``pip``::. $ python -m pip install pytest. and finally run the tests::. $ python -m pytest -sv. On Linux and MacOS-X, all tests should succeed.; On MS Windows 32bit there are 4 failing tests, on 64bit there are 5 still; failing. .. _`pytest`: https://docs.pytest.org/en/latest/; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/testing.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/testing.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/testing.rst:804,Deployability,install,install,804,".. _testing:. Test suite; ==========. The cppyy tests live in the top-level cppyy package, can be run for; both CPython and PyPy, and exercises the full setup, including the backend.; Most tests are standalone and can be run independently, with a few exceptions; in the template tests (see file ``test_templates.py``). To run the tests, first install cppyy by any usual means, then clone the; cppyy repo, and enter the ``test`` directory::. $ git clone https://github.com/wlav/cppyy.git; $ cd cppyy/test. Next, build the dictionaries, the manner of which depends on your platform.; On Linux or MacOS-X, run ``make``::. $ make all. On Windows, run the dictionary building script::. $ python make_dict_win32.py all. Next, make sure you have `pytest`_ installed, for example with ``pip``::. $ python -m pip install pytest. and finally run the tests::. $ python -m pytest -sv. On Linux and MacOS-X, all tests should succeed.; On MS Windows 32bit there are 4 failing tests, on 64bit there are 5 still; failing. .. _`pytest`: https://docs.pytest.org/en/latest/; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/testing.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/testing.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/testing.rst:555,Integrability,depend,depends,555,".. _testing:. Test suite; ==========. The cppyy tests live in the top-level cppyy package, can be run for; both CPython and PyPy, and exercises the full setup, including the backend.; Most tests are standalone and can be run independently, with a few exceptions; in the template tests (see file ``test_templates.py``). To run the tests, first install cppyy by any usual means, then clone the; cppyy repo, and enter the ``test`` directory::. $ git clone https://github.com/wlav/cppyy.git; $ cd cppyy/test. Next, build the dictionaries, the manner of which depends on your platform.; On Linux or MacOS-X, run ``make``::. $ make all. On Windows, run the dictionary building script::. $ python make_dict_win32.py all. Next, make sure you have `pytest`_ installed, for example with ``pip``::. $ python -m pip install pytest. and finally run the tests::. $ python -m pytest -sv. On Linux and MacOS-X, all tests should succeed.; On MS Windows 32bit there are 4 failing tests, on 64bit there are 5 still; failing. .. _`pytest`: https://docs.pytest.org/en/latest/; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/testing.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/testing.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/testing.rst:48,Testability,test,tests,48,".. _testing:. Test suite; ==========. The cppyy tests live in the top-level cppyy package, can be run for; both CPython and PyPy, and exercises the full setup, including the backend.; Most tests are standalone and can be run independently, with a few exceptions; in the template tests (see file ``test_templates.py``). To run the tests, first install cppyy by any usual means, then clone the; cppyy repo, and enter the ``test`` directory::. $ git clone https://github.com/wlav/cppyy.git; $ cd cppyy/test. Next, build the dictionaries, the manner of which depends on your platform.; On Linux or MacOS-X, run ``make``::. $ make all. On Windows, run the dictionary building script::. $ python make_dict_win32.py all. Next, make sure you have `pytest`_ installed, for example with ``pip``::. $ python -m pip install pytest. and finally run the tests::. $ python -m pytest -sv. On Linux and MacOS-X, all tests should succeed.; On MS Windows 32bit there are 4 failing tests, on 64bit there are 5 still; failing. .. _`pytest`: https://docs.pytest.org/en/latest/; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/testing.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/testing.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/testing.rst:189,Testability,test,tests,189,".. _testing:. Test suite; ==========. The cppyy tests live in the top-level cppyy package, can be run for; both CPython and PyPy, and exercises the full setup, including the backend.; Most tests are standalone and can be run independently, with a few exceptions; in the template tests (see file ``test_templates.py``). To run the tests, first install cppyy by any usual means, then clone the; cppyy repo, and enter the ``test`` directory::. $ git clone https://github.com/wlav/cppyy.git; $ cd cppyy/test. Next, build the dictionaries, the manner of which depends on your platform.; On Linux or MacOS-X, run ``make``::. $ make all. On Windows, run the dictionary building script::. $ python make_dict_win32.py all. Next, make sure you have `pytest`_ installed, for example with ``pip``::. $ python -m pip install pytest. and finally run the tests::. $ python -m pytest -sv. On Linux and MacOS-X, all tests should succeed.; On MS Windows 32bit there are 4 failing tests, on 64bit there are 5 still; failing. .. _`pytest`: https://docs.pytest.org/en/latest/; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/testing.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/testing.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/testing.rst:279,Testability,test,tests,279,".. _testing:. Test suite; ==========. The cppyy tests live in the top-level cppyy package, can be run for; both CPython and PyPy, and exercises the full setup, including the backend.; Most tests are standalone and can be run independently, with a few exceptions; in the template tests (see file ``test_templates.py``). To run the tests, first install cppyy by any usual means, then clone the; cppyy repo, and enter the ``test`` directory::. $ git clone https://github.com/wlav/cppyy.git; $ cd cppyy/test. Next, build the dictionaries, the manner of which depends on your platform.; On Linux or MacOS-X, run ``make``::. $ make all. On Windows, run the dictionary building script::. $ python make_dict_win32.py all. Next, make sure you have `pytest`_ installed, for example with ``pip``::. $ python -m pip install pytest. and finally run the tests::. $ python -m pytest -sv. On Linux and MacOS-X, all tests should succeed.; On MS Windows 32bit there are 4 failing tests, on 64bit there are 5 still; failing. .. _`pytest`: https://docs.pytest.org/en/latest/; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/testing.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/testing.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/testing.rst:330,Testability,test,tests,330,".. _testing:. Test suite; ==========. The cppyy tests live in the top-level cppyy package, can be run for; both CPython and PyPy, and exercises the full setup, including the backend.; Most tests are standalone and can be run independently, with a few exceptions; in the template tests (see file ``test_templates.py``). To run the tests, first install cppyy by any usual means, then clone the; cppyy repo, and enter the ``test`` directory::. $ git clone https://github.com/wlav/cppyy.git; $ cd cppyy/test. Next, build the dictionaries, the manner of which depends on your platform.; On Linux or MacOS-X, run ``make``::. $ make all. On Windows, run the dictionary building script::. $ python make_dict_win32.py all. Next, make sure you have `pytest`_ installed, for example with ``pip``::. $ python -m pip install pytest. and finally run the tests::. $ python -m pytest -sv. On Linux and MacOS-X, all tests should succeed.; On MS Windows 32bit there are 4 failing tests, on 64bit there are 5 still; failing. .. _`pytest`: https://docs.pytest.org/en/latest/; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/testing.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/testing.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/testing.rst:421,Testability,test,test,421,".. _testing:. Test suite; ==========. The cppyy tests live in the top-level cppyy package, can be run for; both CPython and PyPy, and exercises the full setup, including the backend.; Most tests are standalone and can be run independently, with a few exceptions; in the template tests (see file ``test_templates.py``). To run the tests, first install cppyy by any usual means, then clone the; cppyy repo, and enter the ``test`` directory::. $ git clone https://github.com/wlav/cppyy.git; $ cd cppyy/test. Next, build the dictionaries, the manner of which depends on your platform.; On Linux or MacOS-X, run ``make``::. $ make all. On Windows, run the dictionary building script::. $ python make_dict_win32.py all. Next, make sure you have `pytest`_ installed, for example with ``pip``::. $ python -m pip install pytest. and finally run the tests::. $ python -m pytest -sv. On Linux and MacOS-X, all tests should succeed.; On MS Windows 32bit there are 4 failing tests, on 64bit there are 5 still; failing. .. _`pytest`: https://docs.pytest.org/en/latest/; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/testing.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/testing.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/testing.rst:499,Testability,test,test,499,".. _testing:. Test suite; ==========. The cppyy tests live in the top-level cppyy package, can be run for; both CPython and PyPy, and exercises the full setup, including the backend.; Most tests are standalone and can be run independently, with a few exceptions; in the template tests (see file ``test_templates.py``). To run the tests, first install cppyy by any usual means, then clone the; cppyy repo, and enter the ``test`` directory::. $ git clone https://github.com/wlav/cppyy.git; $ cd cppyy/test. Next, build the dictionaries, the manner of which depends on your platform.; On Linux or MacOS-X, run ``make``::. $ make all. On Windows, run the dictionary building script::. $ python make_dict_win32.py all. Next, make sure you have `pytest`_ installed, for example with ``pip``::. $ python -m pip install pytest. and finally run the tests::. $ python -m pytest -sv. On Linux and MacOS-X, all tests should succeed.; On MS Windows 32bit there are 4 failing tests, on 64bit there are 5 still; failing. .. _`pytest`: https://docs.pytest.org/en/latest/; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/testing.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/testing.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/testing.rst:840,Testability,test,tests,840,".. _testing:. Test suite; ==========. The cppyy tests live in the top-level cppyy package, can be run for; both CPython and PyPy, and exercises the full setup, including the backend.; Most tests are standalone and can be run independently, with a few exceptions; in the template tests (see file ``test_templates.py``). To run the tests, first install cppyy by any usual means, then clone the; cppyy repo, and enter the ``test`` directory::. $ git clone https://github.com/wlav/cppyy.git; $ cd cppyy/test. Next, build the dictionaries, the manner of which depends on your platform.; On Linux or MacOS-X, run ``make``::. $ make all. On Windows, run the dictionary building script::. $ python make_dict_win32.py all. Next, make sure you have `pytest`_ installed, for example with ``pip``::. $ python -m pip install pytest. and finally run the tests::. $ python -m pytest -sv. On Linux and MacOS-X, all tests should succeed.; On MS Windows 32bit there are 4 failing tests, on 64bit there are 5 still; failing. .. _`pytest`: https://docs.pytest.org/en/latest/; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/testing.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/testing.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/testing.rst:899,Testability,test,tests,899,".. _testing:. Test suite; ==========. The cppyy tests live in the top-level cppyy package, can be run for; both CPython and PyPy, and exercises the full setup, including the backend.; Most tests are standalone and can be run independently, with a few exceptions; in the template tests (see file ``test_templates.py``). To run the tests, first install cppyy by any usual means, then clone the; cppyy repo, and enter the ``test`` directory::. $ git clone https://github.com/wlav/cppyy.git; $ cd cppyy/test. Next, build the dictionaries, the manner of which depends on your platform.; On Linux or MacOS-X, run ``make``::. $ make all. On Windows, run the dictionary building script::. $ python make_dict_win32.py all. Next, make sure you have `pytest`_ installed, for example with ``pip``::. $ python -m pip install pytest. and finally run the tests::. $ python -m pytest -sv. On Linux and MacOS-X, all tests should succeed.; On MS Windows 32bit there are 4 failing tests, on 64bit there are 5 still; failing. .. _`pytest`: https://docs.pytest.org/en/latest/; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/testing.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/testing.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/testing.rst:962,Testability,test,tests,962,".. _testing:. Test suite; ==========. The cppyy tests live in the top-level cppyy package, can be run for; both CPython and PyPy, and exercises the full setup, including the backend.; Most tests are standalone and can be run independently, with a few exceptions; in the template tests (see file ``test_templates.py``). To run the tests, first install cppyy by any usual means, then clone the; cppyy repo, and enter the ``test`` directory::. $ git clone https://github.com/wlav/cppyy.git; $ cd cppyy/test. Next, build the dictionaries, the manner of which depends on your platform.; On Linux or MacOS-X, run ``make``::. $ make all. On Windows, run the dictionary building script::. $ python make_dict_win32.py all. Next, make sure you have `pytest`_ installed, for example with ``pip``::. $ python -m pip install pytest. and finally run the tests::. $ python -m pytest -sv. On Linux and MacOS-X, all tests should succeed.; On MS Windows 32bit there are 4 failing tests, on 64bit there are 5 still; failing. .. _`pytest`: https://docs.pytest.org/en/latest/; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/testing.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/testing.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst:1215,Availability,avail,available,1215,"ocumentation makes use of these helpers throughout, so they are listed; here first, but their documentation is more conveniently accessible through; the Python interpreter itself, using the ``help()`` function::. $ python; >>> import cppyy; >>> help(cppyy). `Loading C++`; -------------. C++ code can be loaded as text to be JITed, or be compiled ahead of time and; supplied in the form of a shared library.; In the latter case, C++ headers need to be loaded as well to declare; classes, functions, and variables to Cling.; Instead of headers, pre-compiled code can be used; in particular all of the; standard C++ headers and several system headers are pre-compiled at startup.; cppyy provides the following helpers to load C++ code:. * ``cppdef``: direct access to the interpreter.; This function accepts C++ declarations as a string and JITs them (bindings; are not created until actual use).; The code is loaded into the global scope, thus any previously loaded code; is available from one ``cppdef`` call to the next, as are all standard; C++ headers that have been loaded through pre-compiled headers.; Example::. >>> cppyy.cppdef(r""""""\; ... void hello() {; ... std::cout << ""Hello, World!"" << std::endl;; ... }""""""); True; >>> cppyy.gbl.hello(); Hello, World!; >>> . * ``cppexec``: direct access to the interpreter.; This function accepts C++ statements as a string, JITs and executes them.; Just like ``cppdef``, execution is in the global scope and all previously; loaded code is available.; If the statements are declarations, the effect is the same as ``cppdef``,; but ``cppexec`` also accepts executable lines.; Example::. >>> cppyy.cppexec(r""""""std::string hello = ""Hello, World!"";""""""); True; >>> cppyy.cppexec(""std::cout << hello << std::endl;""); Hello, World!; True; >>> . * ``include``: load declarations into the interpreter.; This function accepts C++ declarations from a file, typically a header.; Files are located through include paths given to the Cling.; Example::. >>> cppyy.incl",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst:1728,Availability,avail,available,1728,"to be loaded as well to declare; classes, functions, and variables to Cling.; Instead of headers, pre-compiled code can be used; in particular all of the; standard C++ headers and several system headers are pre-compiled at startup.; cppyy provides the following helpers to load C++ code:. * ``cppdef``: direct access to the interpreter.; This function accepts C++ declarations as a string and JITs them (bindings; are not created until actual use).; The code is loaded into the global scope, thus any previously loaded code; is available from one ``cppdef`` call to the next, as are all standard; C++ headers that have been loaded through pre-compiled headers.; Example::. >>> cppyy.cppdef(r""""""\; ... void hello() {; ... std::cout << ""Hello, World!"" << std::endl;; ... }""""""); True; >>> cppyy.gbl.hello(); Hello, World!; >>> . * ``cppexec``: direct access to the interpreter.; This function accepts C++ statements as a string, JITs and executes them.; Just like ``cppdef``, execution is in the global scope and all previously; loaded code is available.; If the statements are declarations, the effect is the same as ``cppdef``,; but ``cppexec`` also accepts executable lines.; Example::. >>> cppyy.cppexec(r""""""std::string hello = ""Hello, World!"";""""""); True; >>> cppyy.cppexec(""std::cout << hello << std::endl;""); Hello, World!; True; >>> . * ``include``: load declarations into the interpreter.; This function accepts C++ declarations from a file, typically a header.; Files are located through include paths given to the Cling.; Example::. >>> cppyy.include(""vector"") # equivalent to ""#include <vector>""; True; >>> . * ``c_include``: load declarations into the interpreter.; This function accepts C++ declarations from a file, typically a header.; Name mangling is an important difference between C and C++ code.; The use of ``c_include`` instead of ``include`` prevents mangling. * ``load_library``: load compiled C++ into the interpreter.; This function takes the name of a shared library and loads",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst:3237,Availability,error,error,3237,"tor>""; True; >>> . * ``c_include``: load declarations into the interpreter.; This function accepts C++ declarations from a file, typically a header.; Name mangling is an important difference between C and C++ code.; The use of ``c_include`` instead of ``include`` prevents mangling. * ``load_library``: load compiled C++ into the interpreter.; This function takes the name of a shared library and loads it into current; process, exposing all external symbols to Cling.; Libraries are located through load paths given to Cling, either through the; ""-L"" compiler flag or the dynamic search path environment variable (system; dependent).; Any method that brings symbols into the process (including normal linking,; e.g. when embedding Python in a C++ application) is suitable to expose; symbols.; An alternative for ``load_library`` is for example ``ctypes.CDLL``, but; that function does not respect dynamic load paths on all platforms. If a compilation error occurs during JITing of C++ code in any of the above; helpers, a Python ``SyntaxError`` exception is raised.; If a compilation warning occurs, a Python warning is issued. `Configuring Cling`; -------------------. It is often convenient to add additional search paths for Cling to find; headers and libraries when loading a module (Python does not have standard; locations to place headers and libraries, but their locations can usually; be inferred from the location of the module, i.e. it's ``__file__``; attribute).; cppyy provides the following two helpers:. * ``add_include_path``: add additional paths for Cling to look for headers. * ``add_library_path``: add additional paths for Cling to look for libraries. Both functions accept either a string (a single path) or a list (for adding; multiple paths).; Paths are allowed to be relative, but absolute paths are recommended. `C++ language`; --------------. Some C++ compilation-time features have no Python equivalent.; Instead, convenience functions are provided:. * ``sizeof``: takes ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst:4607,Availability,avail,available,4607,"e for ``load_library`` is for example ``ctypes.CDLL``, but; that function does not respect dynamic load paths on all platforms. If a compilation error occurs during JITing of C++ code in any of the above; helpers, a Python ``SyntaxError`` exception is raised.; If a compilation warning occurs, a Python warning is issued. `Configuring Cling`; -------------------. It is often convenient to add additional search paths for Cling to find; headers and libraries when loading a module (Python does not have standard; locations to place headers and libraries, but their locations can usually; be inferred from the location of the module, i.e. it's ``__file__``; attribute).; cppyy provides the following two helpers:. * ``add_include_path``: add additional paths for Cling to look for headers. * ``add_library_path``: add additional paths for Cling to look for libraries. Both functions accept either a string (a single path) or a list (for adding; multiple paths).; Paths are allowed to be relative, but absolute paths are recommended. `C++ language`; --------------. Some C++ compilation-time features have no Python equivalent.; Instead, convenience functions are provided:. * ``sizeof``: takes a proxied C++ type or its name as a string and returns; the storage size (in units of ``char``). * ``typeid``: takes a proxied C++ type or its name as a string and returns; the the C++ runtime type information (RTTI). * ``nullptr``: C++ ``NULL``. `Preprocessor`; --------------. Preprocessor macro's (``#define``) are not available on the Python side,; because there is no type information available for them.; They are, however, often used for constant data (e.g. flags or numbers; note; that modern C++ recommends the use of ``const`` and ``constexpr`` instead).; Within limits, macro's representing constant data are accessible through the; ``macro`` helper function.; Example::. >>> import cppyy; >>> cppyy.cppdef('#define HELLO ""Hello, World!""'); True; >>> cppyy.macro(""HELLO""); 'Hello, World!'; >>> . ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst:4675,Availability,avail,available,4675,"e for ``load_library`` is for example ``ctypes.CDLL``, but; that function does not respect dynamic load paths on all platforms. If a compilation error occurs during JITing of C++ code in any of the above; helpers, a Python ``SyntaxError`` exception is raised.; If a compilation warning occurs, a Python warning is issued. `Configuring Cling`; -------------------. It is often convenient to add additional search paths for Cling to find; headers and libraries when loading a module (Python does not have standard; locations to place headers and libraries, but their locations can usually; be inferred from the location of the module, i.e. it's ``__file__``; attribute).; cppyy provides the following two helpers:. * ``add_include_path``: add additional paths for Cling to look for headers. * ``add_library_path``: add additional paths for Cling to look for libraries. Both functions accept either a string (a single path) or a list (for adding; multiple paths).; Paths are allowed to be relative, but absolute paths are recommended. `C++ language`; --------------. Some C++ compilation-time features have no Python equivalent.; Instead, convenience functions are provided:. * ``sizeof``: takes a proxied C++ type or its name as a string and returns; the storage size (in units of ``char``). * ``typeid``: takes a proxied C++ type or its name as a string and returns; the the C++ runtime type information (RTTI). * ``nullptr``: C++ ``NULL``. `Preprocessor`; --------------. Preprocessor macro's (``#define``) are not available on the Python side,; because there is no type information available for them.; They are, however, often used for constant data (e.g. flags or numbers; note; that modern C++ recommends the use of ``const`` and ``constexpr`` instead).; Within limits, macro's representing constant data are accessible through the; ``macro`` helper function.; Example::. >>> import cppyy; >>> cppyy.cppdef('#define HELLO ""Hello, World!""'); True; >>> cppyy.macro(""HELLO""); 'Hello, World!'; >>> . ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst:2908,Integrability,depend,dependent,2908,"accepts executable lines.; Example::. >>> cppyy.cppexec(r""""""std::string hello = ""Hello, World!"";""""""); True; >>> cppyy.cppexec(""std::cout << hello << std::endl;""); Hello, World!; True; >>> . * ``include``: load declarations into the interpreter.; This function accepts C++ declarations from a file, typically a header.; Files are located through include paths given to the Cling.; Example::. >>> cppyy.include(""vector"") # equivalent to ""#include <vector>""; True; >>> . * ``c_include``: load declarations into the interpreter.; This function accepts C++ declarations from a file, typically a header.; Name mangling is an important difference between C and C++ code.; The use of ``c_include`` instead of ``include`` prevents mangling. * ``load_library``: load compiled C++ into the interpreter.; This function takes the name of a shared library and loads it into current; process, exposing all external symbols to Cling.; Libraries are located through load paths given to Cling, either through the; ""-L"" compiler flag or the dynamic search path environment variable (system; dependent).; Any method that brings symbols into the process (including normal linking,; e.g. when embedding Python in a C++ application) is suitable to expose; symbols.; An alternative for ``load_library`` is for example ``ctypes.CDLL``, but; that function does not respect dynamic load paths on all platforms. If a compilation error occurs during JITing of C++ code in any of the above; helpers, a Python ``SyntaxError`` exception is raised.; If a compilation warning occurs, a Python warning is issued. `Configuring Cling`; -------------------. It is often convenient to add additional search paths for Cling to find; headers and libraries when loading a module (Python does not have standard; locations to place headers and libraries, but their locations can usually; be inferred from the location of the module, i.e. it's ``__file__``; attribute).; cppyy provides the following two helpers:. * ``add_include_path``: add add",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst:744,Modifiability,variab,variables,744,".. _toplevel:. Top Level; =========. cppyy provides a couple of helper functions at the module level that provide; (direct) access to the Cling interpreter (any C++ code is always accessed; through the global namespace ``cppyy.gbl``).; The documentation makes use of these helpers throughout, so they are listed; here first, but their documentation is more conveniently accessible through; the Python interpreter itself, using the ``help()`` function::. $ python; >>> import cppyy; >>> help(cppyy). `Loading C++`; -------------. C++ code can be loaded as text to be JITed, or be compiled ahead of time and; supplied in the form of a shared library.; In the latter case, C++ headers need to be loaded as well to declare; classes, functions, and variables to Cling.; Instead of headers, pre-compiled code can be used; in particular all of the; standard C++ headers and several system headers are pre-compiled at startup.; cppyy provides the following helpers to load C++ code:. * ``cppdef``: direct access to the interpreter.; This function accepts C++ declarations as a string and JITs them (bindings; are not created until actual use).; The code is loaded into the global scope, thus any previously loaded code; is available from one ``cppdef`` call to the next, as are all standard; C++ headers that have been loaded through pre-compiled headers.; Example::. >>> cppyy.cppdef(r""""""\; ... void hello() {; ... std::cout << ""Hello, World!"" << std::endl;; ... }""""""); True; >>> cppyy.gbl.hello(); Hello, World!; >>> . * ``cppexec``: direct access to the interpreter.; This function accepts C++ statements as a string, JITs and executes them.; Just like ``cppdef``, execution is in the global scope and all previously; loaded code is available.; If the statements are declarations, the effect is the same as ``cppdef``,; but ``cppexec`` also accepts executable lines.; Example::. >>> cppyy.cppexec(r""""""std::string hello = ""Hello, World!"";""""""); True; >>> cppyy.cppexec(""std::cout << hello << std::endl;""); He",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst:2890,Modifiability,variab,variable,2890,"accepts executable lines.; Example::. >>> cppyy.cppexec(r""""""std::string hello = ""Hello, World!"";""""""); True; >>> cppyy.cppexec(""std::cout << hello << std::endl;""); Hello, World!; True; >>> . * ``include``: load declarations into the interpreter.; This function accepts C++ declarations from a file, typically a header.; Files are located through include paths given to the Cling.; Example::. >>> cppyy.include(""vector"") # equivalent to ""#include <vector>""; True; >>> . * ``c_include``: load declarations into the interpreter.; This function accepts C++ declarations from a file, typically a header.; Name mangling is an important difference between C and C++ code.; The use of ``c_include`` instead of ``include`` prevents mangling. * ``load_library``: load compiled C++ into the interpreter.; This function takes the name of a shared library and loads it into current; process, exposing all external symbols to Cling.; Libraries are located through load paths given to Cling, either through the; ""-L"" compiler flag or the dynamic search path environment variable (system; dependent).; Any method that brings symbols into the process (including normal linking,; e.g. when embedding Python in a C++ application) is suitable to expose; symbols.; An alternative for ``load_library`` is for example ``ctypes.CDLL``, but; that function does not respect dynamic load paths on all platforms. If a compilation error occurs during JITing of C++ code in any of the above; helpers, a Python ``SyntaxError`` exception is raised.; If a compilation warning occurs, a Python warning is issued. `Configuring Cling`; -------------------. It is often convenient to add additional search paths for Cling to find; headers and libraries when loading a module (Python does not have standard; locations to place headers and libraries, but their locations can usually; be inferred from the location of the module, i.e. it's ``__file__``; attribute).; cppyy provides the following two helpers:. * ``add_include_path``: add add",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst:545,Performance,load,loaded,545,".. _toplevel:. Top Level; =========. cppyy provides a couple of helper functions at the module level that provide; (direct) access to the Cling interpreter (any C++ code is always accessed; through the global namespace ``cppyy.gbl``).; The documentation makes use of these helpers throughout, so they are listed; here first, but their documentation is more conveniently accessible through; the Python interpreter itself, using the ``help()`` function::. $ python; >>> import cppyy; >>> help(cppyy). `Loading C++`; -------------. C++ code can be loaded as text to be JITed, or be compiled ahead of time and; supplied in the form of a shared library.; In the latter case, C++ headers need to be loaded as well to declare; classes, functions, and variables to Cling.; Instead of headers, pre-compiled code can be used; in particular all of the; standard C++ headers and several system headers are pre-compiled at startup.; cppyy provides the following helpers to load C++ code:. * ``cppdef``: direct access to the interpreter.; This function accepts C++ declarations as a string and JITs them (bindings; are not created until actual use).; The code is loaded into the global scope, thus any previously loaded code; is available from one ``cppdef`` call to the next, as are all standard; C++ headers that have been loaded through pre-compiled headers.; Example::. >>> cppyy.cppdef(r""""""\; ... void hello() {; ... std::cout << ""Hello, World!"" << std::endl;; ... }""""""); True; >>> cppyy.gbl.hello(); Hello, World!; >>> . * ``cppexec``: direct access to the interpreter.; This function accepts C++ statements as a string, JITs and executes them.; Just like ``cppdef``, execution is in the global scope and all previously; loaded code is available.; If the statements are declarations, the effect is the same as ``cppdef``,; but ``cppexec`` also accepts executable lines.; Example::. >>> cppyy.cppexec(r""""""std::string hello = ""Hello, World!"";""""""); True; >>> cppyy.cppexec(""std::cout << hello << std::endl;""); He",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst:693,Performance,load,loaded,693,".. _toplevel:. Top Level; =========. cppyy provides a couple of helper functions at the module level that provide; (direct) access to the Cling interpreter (any C++ code is always accessed; through the global namespace ``cppyy.gbl``).; The documentation makes use of these helpers throughout, so they are listed; here first, but their documentation is more conveniently accessible through; the Python interpreter itself, using the ``help()`` function::. $ python; >>> import cppyy; >>> help(cppyy). `Loading C++`; -------------. C++ code can be loaded as text to be JITed, or be compiled ahead of time and; supplied in the form of a shared library.; In the latter case, C++ headers need to be loaded as well to declare; classes, functions, and variables to Cling.; Instead of headers, pre-compiled code can be used; in particular all of the; standard C++ headers and several system headers are pre-compiled at startup.; cppyy provides the following helpers to load C++ code:. * ``cppdef``: direct access to the interpreter.; This function accepts C++ declarations as a string and JITs them (bindings; are not created until actual use).; The code is loaded into the global scope, thus any previously loaded code; is available from one ``cppdef`` call to the next, as are all standard; C++ headers that have been loaded through pre-compiled headers.; Example::. >>> cppyy.cppdef(r""""""\; ... void hello() {; ... std::cout << ""Hello, World!"" << std::endl;; ... }""""""); True; >>> cppyy.gbl.hello(); Hello, World!; >>> . * ``cppexec``: direct access to the interpreter.; This function accepts C++ statements as a string, JITs and executes them.; Just like ``cppdef``, execution is in the global scope and all previously; loaded code is available.; If the statements are declarations, the effect is the same as ``cppdef``,; but ``cppexec`` also accepts executable lines.; Example::. >>> cppyy.cppexec(r""""""std::string hello = ""Hello, World!"";""""""); True; >>> cppyy.cppexec(""std::cout << hello << std::endl;""); He",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst:960,Performance,load,load,960,".. _toplevel:. Top Level; =========. cppyy provides a couple of helper functions at the module level that provide; (direct) access to the Cling interpreter (any C++ code is always accessed; through the global namespace ``cppyy.gbl``).; The documentation makes use of these helpers throughout, so they are listed; here first, but their documentation is more conveniently accessible through; the Python interpreter itself, using the ``help()`` function::. $ python; >>> import cppyy; >>> help(cppyy). `Loading C++`; -------------. C++ code can be loaded as text to be JITed, or be compiled ahead of time and; supplied in the form of a shared library.; In the latter case, C++ headers need to be loaded as well to declare; classes, functions, and variables to Cling.; Instead of headers, pre-compiled code can be used; in particular all of the; standard C++ headers and several system headers are pre-compiled at startup.; cppyy provides the following helpers to load C++ code:. * ``cppdef``: direct access to the interpreter.; This function accepts C++ declarations as a string and JITs them (bindings; are not created until actual use).; The code is loaded into the global scope, thus any previously loaded code; is available from one ``cppdef`` call to the next, as are all standard; C++ headers that have been loaded through pre-compiled headers.; Example::. >>> cppyy.cppdef(r""""""\; ... void hello() {; ... std::cout << ""Hello, World!"" << std::endl;; ... }""""""); True; >>> cppyy.gbl.hello(); Hello, World!; >>> . * ``cppexec``: direct access to the interpreter.; This function accepts C++ statements as a string, JITs and executes them.; Just like ``cppdef``, execution is in the global scope and all previously; loaded code is available.; If the statements are declarations, the effect is the same as ``cppdef``,; but ``cppexec`` also accepts executable lines.; Example::. >>> cppyy.cppexec(r""""""std::string hello = ""Hello, World!"";""""""); True; >>> cppyy.cppexec(""std::cout << hello << std::endl;""); He",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst:1149,Performance,load,loaded,1149,"ocumentation makes use of these helpers throughout, so they are listed; here first, but their documentation is more conveniently accessible through; the Python interpreter itself, using the ``help()`` function::. $ python; >>> import cppyy; >>> help(cppyy). `Loading C++`; -------------. C++ code can be loaded as text to be JITed, or be compiled ahead of time and; supplied in the form of a shared library.; In the latter case, C++ headers need to be loaded as well to declare; classes, functions, and variables to Cling.; Instead of headers, pre-compiled code can be used; in particular all of the; standard C++ headers and several system headers are pre-compiled at startup.; cppyy provides the following helpers to load C++ code:. * ``cppdef``: direct access to the interpreter.; This function accepts C++ declarations as a string and JITs them (bindings; are not created until actual use).; The code is loaded into the global scope, thus any previously loaded code; is available from one ``cppdef`` call to the next, as are all standard; C++ headers that have been loaded through pre-compiled headers.; Example::. >>> cppyy.cppdef(r""""""\; ... void hello() {; ... std::cout << ""Hello, World!"" << std::endl;; ... }""""""); True; >>> cppyy.gbl.hello(); Hello, World!; >>> . * ``cppexec``: direct access to the interpreter.; This function accepts C++ statements as a string, JITs and executes them.; Just like ``cppdef``, execution is in the global scope and all previously; loaded code is available.; If the statements are declarations, the effect is the same as ``cppdef``,; but ``cppexec`` also accepts executable lines.; Example::. >>> cppyy.cppexec(r""""""std::string hello = ""Hello, World!"";""""""); True; >>> cppyy.cppexec(""std::cout << hello << std::endl;""); Hello, World!; True; >>> . * ``include``: load declarations into the interpreter.; This function accepts C++ declarations from a file, typically a header.; Files are located through include paths given to the Cling.; Example::. >>> cppyy.incl",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst:1199,Performance,load,loaded,1199,"ocumentation makes use of these helpers throughout, so they are listed; here first, but their documentation is more conveniently accessible through; the Python interpreter itself, using the ``help()`` function::. $ python; >>> import cppyy; >>> help(cppyy). `Loading C++`; -------------. C++ code can be loaded as text to be JITed, or be compiled ahead of time and; supplied in the form of a shared library.; In the latter case, C++ headers need to be loaded as well to declare; classes, functions, and variables to Cling.; Instead of headers, pre-compiled code can be used; in particular all of the; standard C++ headers and several system headers are pre-compiled at startup.; cppyy provides the following helpers to load C++ code:. * ``cppdef``: direct access to the interpreter.; This function accepts C++ declarations as a string and JITs them (bindings; are not created until actual use).; The code is loaded into the global scope, thus any previously loaded code; is available from one ``cppdef`` call to the next, as are all standard; C++ headers that have been loaded through pre-compiled headers.; Example::. >>> cppyy.cppdef(r""""""\; ... void hello() {; ... std::cout << ""Hello, World!"" << std::endl;; ... }""""""); True; >>> cppyy.gbl.hello(); Hello, World!; >>> . * ``cppexec``: direct access to the interpreter.; This function accepts C++ statements as a string, JITs and executes them.; Just like ``cppdef``, execution is in the global scope and all previously; loaded code is available.; If the statements are declarations, the effect is the same as ``cppdef``,; but ``cppexec`` also accepts executable lines.; Example::. >>> cppyy.cppexec(r""""""std::string hello = ""Hello, World!"";""""""); True; >>> cppyy.cppexec(""std::cout << hello << std::endl;""); Hello, World!; True; >>> . * ``include``: load declarations into the interpreter.; This function accepts C++ declarations from a file, typically a header.; Files are located through include paths given to the Cling.; Example::. >>> cppyy.incl",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst:1311,Performance,load,loaded,1311,"ocumentation makes use of these helpers throughout, so they are listed; here first, but their documentation is more conveniently accessible through; the Python interpreter itself, using the ``help()`` function::. $ python; >>> import cppyy; >>> help(cppyy). `Loading C++`; -------------. C++ code can be loaded as text to be JITed, or be compiled ahead of time and; supplied in the form of a shared library.; In the latter case, C++ headers need to be loaded as well to declare; classes, functions, and variables to Cling.; Instead of headers, pre-compiled code can be used; in particular all of the; standard C++ headers and several system headers are pre-compiled at startup.; cppyy provides the following helpers to load C++ code:. * ``cppdef``: direct access to the interpreter.; This function accepts C++ declarations as a string and JITs them (bindings; are not created until actual use).; The code is loaded into the global scope, thus any previously loaded code; is available from one ``cppdef`` call to the next, as are all standard; C++ headers that have been loaded through pre-compiled headers.; Example::. >>> cppyy.cppdef(r""""""\; ... void hello() {; ... std::cout << ""Hello, World!"" << std::endl;; ... }""""""); True; >>> cppyy.gbl.hello(); Hello, World!; >>> . * ``cppexec``: direct access to the interpreter.; This function accepts C++ statements as a string, JITs and executes them.; Just like ``cppdef``, execution is in the global scope and all previously; loaded code is available.; If the statements are declarations, the effect is the same as ``cppdef``,; but ``cppexec`` also accepts executable lines.; Example::. >>> cppyy.cppexec(r""""""std::string hello = ""Hello, World!"";""""""); True; >>> cppyy.cppexec(""std::cout << hello << std::endl;""); Hello, World!; True; >>> . * ``include``: load declarations into the interpreter.; This function accepts C++ declarations from a file, typically a header.; Files are located through include paths given to the Cling.; Example::. >>> cppyy.incl",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst:1713,Performance,load,loaded,1713,"to be loaded as well to declare; classes, functions, and variables to Cling.; Instead of headers, pre-compiled code can be used; in particular all of the; standard C++ headers and several system headers are pre-compiled at startup.; cppyy provides the following helpers to load C++ code:. * ``cppdef``: direct access to the interpreter.; This function accepts C++ declarations as a string and JITs them (bindings; are not created until actual use).; The code is loaded into the global scope, thus any previously loaded code; is available from one ``cppdef`` call to the next, as are all standard; C++ headers that have been loaded through pre-compiled headers.; Example::. >>> cppyy.cppdef(r""""""\; ... void hello() {; ... std::cout << ""Hello, World!"" << std::endl;; ... }""""""); True; >>> cppyy.gbl.hello(); Hello, World!; >>> . * ``cppexec``: direct access to the interpreter.; This function accepts C++ statements as a string, JITs and executes them.; Just like ``cppdef``, execution is in the global scope and all previously; loaded code is available.; If the statements are declarations, the effect is the same as ``cppdef``,; but ``cppexec`` also accepts executable lines.; Example::. >>> cppyy.cppexec(r""""""std::string hello = ""Hello, World!"";""""""); True; >>> cppyy.cppexec(""std::cout << hello << std::endl;""); Hello, World!; True; >>> . * ``include``: load declarations into the interpreter.; This function accepts C++ declarations from a file, typically a header.; Files are located through include paths given to the Cling.; Example::. >>> cppyy.include(""vector"") # equivalent to ""#include <vector>""; True; >>> . * ``c_include``: load declarations into the interpreter.; This function accepts C++ declarations from a file, typically a header.; Name mangling is an important difference between C and C++ code.; The use of ``c_include`` instead of ``include`` prevents mangling. * ``load_library``: load compiled C++ into the interpreter.; This function takes the name of a shared library and loads",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst:2041,Performance,load,load,2041,"eclarations as a string and JITs them (bindings; are not created until actual use).; The code is loaded into the global scope, thus any previously loaded code; is available from one ``cppdef`` call to the next, as are all standard; C++ headers that have been loaded through pre-compiled headers.; Example::. >>> cppyy.cppdef(r""""""\; ... void hello() {; ... std::cout << ""Hello, World!"" << std::endl;; ... }""""""); True; >>> cppyy.gbl.hello(); Hello, World!; >>> . * ``cppexec``: direct access to the interpreter.; This function accepts C++ statements as a string, JITs and executes them.; Just like ``cppdef``, execution is in the global scope and all previously; loaded code is available.; If the statements are declarations, the effect is the same as ``cppdef``,; but ``cppexec`` also accepts executable lines.; Example::. >>> cppyy.cppexec(r""""""std::string hello = ""Hello, World!"";""""""); True; >>> cppyy.cppexec(""std::cout << hello << std::endl;""); Hello, World!; True; >>> . * ``include``: load declarations into the interpreter.; This function accepts C++ declarations from a file, typically a header.; Files are located through include paths given to the Cling.; Example::. >>> cppyy.include(""vector"") # equivalent to ""#include <vector>""; True; >>> . * ``c_include``: load declarations into the interpreter.; This function accepts C++ declarations from a file, typically a header.; Name mangling is an important difference between C and C++ code.; The use of ``c_include`` instead of ``include`` prevents mangling. * ``load_library``: load compiled C++ into the interpreter.; This function takes the name of a shared library and loads it into current; process, exposing all external symbols to Cling.; Libraries are located through load paths given to Cling, either through the; ""-L"" compiler flag or the dynamic search path environment variable (system; dependent).; Any method that brings symbols into the process (including normal linking,; e.g. when embedding Python in a C++ application) is suit",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst:2321,Performance,load,load,2321,"ompiled headers.; Example::. >>> cppyy.cppdef(r""""""\; ... void hello() {; ... std::cout << ""Hello, World!"" << std::endl;; ... }""""""); True; >>> cppyy.gbl.hello(); Hello, World!; >>> . * ``cppexec``: direct access to the interpreter.; This function accepts C++ statements as a string, JITs and executes them.; Just like ``cppdef``, execution is in the global scope and all previously; loaded code is available.; If the statements are declarations, the effect is the same as ``cppdef``,; but ``cppexec`` also accepts executable lines.; Example::. >>> cppyy.cppexec(r""""""std::string hello = ""Hello, World!"";""""""); True; >>> cppyy.cppexec(""std::cout << hello << std::endl;""); Hello, World!; True; >>> . * ``include``: load declarations into the interpreter.; This function accepts C++ declarations from a file, typically a header.; Files are located through include paths given to the Cling.; Example::. >>> cppyy.include(""vector"") # equivalent to ""#include <vector>""; True; >>> . * ``c_include``: load declarations into the interpreter.; This function accepts C++ declarations from a file, typically a header.; Name mangling is an important difference between C and C++ code.; The use of ``c_include`` instead of ``include`` prevents mangling. * ``load_library``: load compiled C++ into the interpreter.; This function takes the name of a shared library and loads it into current; process, exposing all external symbols to Cling.; Libraries are located through load paths given to Cling, either through the; ""-L"" compiler flag or the dynamic search path environment variable (system; dependent).; Any method that brings symbols into the process (including normal linking,; e.g. when embedding Python in a C++ application) is suitable to expose; symbols.; An alternative for ``load_library`` is for example ``ctypes.CDLL``, but; that function does not respect dynamic load paths on all platforms. If a compilation error occurs during JITing of C++ code in any of the above; helpers, a Python ``SyntaxError`` e",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst:2588,Performance,load,load,2588,"ts as a string, JITs and executes them.; Just like ``cppdef``, execution is in the global scope and all previously; loaded code is available.; If the statements are declarations, the effect is the same as ``cppdef``,; but ``cppexec`` also accepts executable lines.; Example::. >>> cppyy.cppexec(r""""""std::string hello = ""Hello, World!"";""""""); True; >>> cppyy.cppexec(""std::cout << hello << std::endl;""); Hello, World!; True; >>> . * ``include``: load declarations into the interpreter.; This function accepts C++ declarations from a file, typically a header.; Files are located through include paths given to the Cling.; Example::. >>> cppyy.include(""vector"") # equivalent to ""#include <vector>""; True; >>> . * ``c_include``: load declarations into the interpreter.; This function accepts C++ declarations from a file, typically a header.; Name mangling is an important difference between C and C++ code.; The use of ``c_include`` instead of ``include`` prevents mangling. * ``load_library``: load compiled C++ into the interpreter.; This function takes the name of a shared library and loads it into current; process, exposing all external symbols to Cling.; Libraries are located through load paths given to Cling, either through the; ""-L"" compiler flag or the dynamic search path environment variable (system; dependent).; Any method that brings symbols into the process (including normal linking,; e.g. when embedding Python in a C++ application) is suitable to expose; symbols.; An alternative for ``load_library`` is for example ``ctypes.CDLL``, but; that function does not respect dynamic load paths on all platforms. If a compilation error occurs during JITing of C++ code in any of the above; helpers, a Python ``SyntaxError`` exception is raised.; If a compilation warning occurs, a Python warning is issued. `Configuring Cling`; -------------------. It is often convenient to add additional search paths for Cling to find; headers and libraries when loading a module (Python does not have st",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst:2682,Performance,load,loads,2682,"pe and all previously; loaded code is available.; If the statements are declarations, the effect is the same as ``cppdef``,; but ``cppexec`` also accepts executable lines.; Example::. >>> cppyy.cppexec(r""""""std::string hello = ""Hello, World!"";""""""); True; >>> cppyy.cppexec(""std::cout << hello << std::endl;""); Hello, World!; True; >>> . * ``include``: load declarations into the interpreter.; This function accepts C++ declarations from a file, typically a header.; Files are located through include paths given to the Cling.; Example::. >>> cppyy.include(""vector"") # equivalent to ""#include <vector>""; True; >>> . * ``c_include``: load declarations into the interpreter.; This function accepts C++ declarations from a file, typically a header.; Name mangling is an important difference between C and C++ code.; The use of ``c_include`` instead of ``include`` prevents mangling. * ``load_library``: load compiled C++ into the interpreter.; This function takes the name of a shared library and loads it into current; process, exposing all external symbols to Cling.; Libraries are located through load paths given to Cling, either through the; ""-L"" compiler flag or the dynamic search path environment variable (system; dependent).; Any method that brings symbols into the process (including normal linking,; e.g. when embedding Python in a C++ application) is suitable to expose; symbols.; An alternative for ``load_library`` is for example ``ctypes.CDLL``, but; that function does not respect dynamic load paths on all platforms. If a compilation error occurs during JITing of C++ code in any of the above; helpers, a Python ``SyntaxError`` exception is raised.; If a compilation warning occurs, a Python warning is issued. `Configuring Cling`; -------------------. It is often convenient to add additional search paths for Cling to find; headers and libraries when loading a module (Python does not have standard; locations to place headers and libraries, but their locations can usually; be inferre",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst:2785,Performance,load,load,2785,"accepts executable lines.; Example::. >>> cppyy.cppexec(r""""""std::string hello = ""Hello, World!"";""""""); True; >>> cppyy.cppexec(""std::cout << hello << std::endl;""); Hello, World!; True; >>> . * ``include``: load declarations into the interpreter.; This function accepts C++ declarations from a file, typically a header.; Files are located through include paths given to the Cling.; Example::. >>> cppyy.include(""vector"") # equivalent to ""#include <vector>""; True; >>> . * ``c_include``: load declarations into the interpreter.; This function accepts C++ declarations from a file, typically a header.; Name mangling is an important difference between C and C++ code.; The use of ``c_include`` instead of ``include`` prevents mangling. * ``load_library``: load compiled C++ into the interpreter.; This function takes the name of a shared library and loads it into current; process, exposing all external symbols to Cling.; Libraries are located through load paths given to Cling, either through the; ""-L"" compiler flag or the dynamic search path environment variable (system; dependent).; Any method that brings symbols into the process (including normal linking,; e.g. when embedding Python in a C++ application) is suitable to expose; symbols.; An alternative for ``load_library`` is for example ``ctypes.CDLL``, but; that function does not respect dynamic load paths on all platforms. If a compilation error occurs during JITing of C++ code in any of the above; helpers, a Python ``SyntaxError`` exception is raised.; If a compilation warning occurs, a Python warning is issued. `Configuring Cling`; -------------------. It is often convenient to add additional search paths for Cling to find; headers and libraries when loading a module (Python does not have standard; locations to place headers and libraries, but their locations can usually; be inferred from the location of the module, i.e. it's ``__file__``; attribute).; cppyy provides the following two helpers:. * ``add_include_path``: add add",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst:3191,Performance,load,load,3191,"h include paths given to the Cling.; Example::. >>> cppyy.include(""vector"") # equivalent to ""#include <vector>""; True; >>> . * ``c_include``: load declarations into the interpreter.; This function accepts C++ declarations from a file, typically a header.; Name mangling is an important difference between C and C++ code.; The use of ``c_include`` instead of ``include`` prevents mangling. * ``load_library``: load compiled C++ into the interpreter.; This function takes the name of a shared library and loads it into current; process, exposing all external symbols to Cling.; Libraries are located through load paths given to Cling, either through the; ""-L"" compiler flag or the dynamic search path environment variable (system; dependent).; Any method that brings symbols into the process (including normal linking,; e.g. when embedding Python in a C++ application) is suitable to expose; symbols.; An alternative for ``load_library`` is for example ``ctypes.CDLL``, but; that function does not respect dynamic load paths on all platforms. If a compilation error occurs during JITing of C++ code in any of the above; helpers, a Python ``SyntaxError`` exception is raised.; If a compilation warning occurs, a Python warning is issued. `Configuring Cling`; -------------------. It is often convenient to add additional search paths for Cling to find; headers and libraries when loading a module (Python does not have standard; locations to place headers and libraries, but their locations can usually; be inferred from the location of the module, i.e. it's ``__file__``; attribute).; cppyy provides the following two helpers:. * ``add_include_path``: add additional paths for Cling to look for headers. * ``add_library_path``: add additional paths for Cling to look for libraries. Both functions accept either a string (a single path) or a list (for adding; multiple paths).; Paths are allowed to be relative, but absolute paths are recommended. `C++ language`; --------------. Some C++ compilation-ti",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst:3556,Performance,load,loading,3556,"d compiled C++ into the interpreter.; This function takes the name of a shared library and loads it into current; process, exposing all external symbols to Cling.; Libraries are located through load paths given to Cling, either through the; ""-L"" compiler flag or the dynamic search path environment variable (system; dependent).; Any method that brings symbols into the process (including normal linking,; e.g. when embedding Python in a C++ application) is suitable to expose; symbols.; An alternative for ``load_library`` is for example ``ctypes.CDLL``, but; that function does not respect dynamic load paths on all platforms. If a compilation error occurs during JITing of C++ code in any of the above; helpers, a Python ``SyntaxError`` exception is raised.; If a compilation warning occurs, a Python warning is issued. `Configuring Cling`; -------------------. It is often convenient to add additional search paths for Cling to find; headers and libraries when loading a module (Python does not have standard; locations to place headers and libraries, but their locations can usually; be inferred from the location of the module, i.e. it's ``__file__``; attribute).; cppyy provides the following two helpers:. * ``add_include_path``: add additional paths for Cling to look for headers. * ``add_library_path``: add additional paths for Cling to look for libraries. Both functions accept either a string (a single path) or a list (for adding; multiple paths).; Paths are allowed to be relative, but absolute paths are recommended. `C++ language`; --------------. Some C++ compilation-time features have no Python equivalent.; Instead, convenience functions are provided:. * ``sizeof``: takes a proxied C++ type or its name as a string and returns; the storage size (in units of ``char``). * ``typeid``: takes a proxied C++ type or its name as a string and returns; the the C++ runtime type information (RTTI). * ``nullptr``: C++ ``NULL``. `Preprocessor`; --------------. Preprocessor macro's (``#de",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst:124,Security,access,access,124,".. _toplevel:. Top Level; =========. cppyy provides a couple of helper functions at the module level that provide; (direct) access to the Cling interpreter (any C++ code is always accessed; through the global namespace ``cppyy.gbl``).; The documentation makes use of these helpers throughout, so they are listed; here first, but their documentation is more conveniently accessible through; the Python interpreter itself, using the ``help()`` function::. $ python; >>> import cppyy; >>> help(cppyy). `Loading C++`; -------------. C++ code can be loaded as text to be JITed, or be compiled ahead of time and; supplied in the form of a shared library.; In the latter case, C++ headers need to be loaded as well to declare; classes, functions, and variables to Cling.; Instead of headers, pre-compiled code can be used; in particular all of the; standard C++ headers and several system headers are pre-compiled at startup.; cppyy provides the following helpers to load C++ code:. * ``cppdef``: direct access to the interpreter.; This function accepts C++ declarations as a string and JITs them (bindings; are not created until actual use).; The code is loaded into the global scope, thus any previously loaded code; is available from one ``cppdef`` call to the next, as are all standard; C++ headers that have been loaded through pre-compiled headers.; Example::. >>> cppyy.cppdef(r""""""\; ... void hello() {; ... std::cout << ""Hello, World!"" << std::endl;; ... }""""""); True; >>> cppyy.gbl.hello(); Hello, World!; >>> . * ``cppexec``: direct access to the interpreter.; This function accepts C++ statements as a string, JITs and executes them.; Just like ``cppdef``, execution is in the global scope and all previously; loaded code is available.; If the statements are declarations, the effect is the same as ``cppdef``,; but ``cppexec`` also accepts executable lines.; Example::. >>> cppyy.cppexec(r""""""std::string hello = ""Hello, World!"";""""""); True; >>> cppyy.cppexec(""std::cout << hello << std::endl;""); He",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst:180,Security,access,accessed,180,".. _toplevel:. Top Level; =========. cppyy provides a couple of helper functions at the module level that provide; (direct) access to the Cling interpreter (any C++ code is always accessed; through the global namespace ``cppyy.gbl``).; The documentation makes use of these helpers throughout, so they are listed; here first, but their documentation is more conveniently accessible through; the Python interpreter itself, using the ``help()`` function::. $ python; >>> import cppyy; >>> help(cppyy). `Loading C++`; -------------. C++ code can be loaded as text to be JITed, or be compiled ahead of time and; supplied in the form of a shared library.; In the latter case, C++ headers need to be loaded as well to declare; classes, functions, and variables to Cling.; Instead of headers, pre-compiled code can be used; in particular all of the; standard C++ headers and several system headers are pre-compiled at startup.; cppyy provides the following helpers to load C++ code:. * ``cppdef``: direct access to the interpreter.; This function accepts C++ declarations as a string and JITs them (bindings; are not created until actual use).; The code is loaded into the global scope, thus any previously loaded code; is available from one ``cppdef`` call to the next, as are all standard; C++ headers that have been loaded through pre-compiled headers.; Example::. >>> cppyy.cppdef(r""""""\; ... void hello() {; ... std::cout << ""Hello, World!"" << std::endl;; ... }""""""); True; >>> cppyy.gbl.hello(); Hello, World!; >>> . * ``cppexec``: direct access to the interpreter.; This function accepts C++ statements as a string, JITs and executes them.; Just like ``cppdef``, execution is in the global scope and all previously; loaded code is available.; If the statements are declarations, the effect is the same as ``cppdef``,; but ``cppexec`` also accepts executable lines.; Example::. >>> cppyy.cppexec(r""""""std::string hello = ""Hello, World!"";""""""); True; >>> cppyy.cppexec(""std::cout << hello << std::endl;""); He",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst:370,Security,access,accessible,370,".. _toplevel:. Top Level; =========. cppyy provides a couple of helper functions at the module level that provide; (direct) access to the Cling interpreter (any C++ code is always accessed; through the global namespace ``cppyy.gbl``).; The documentation makes use of these helpers throughout, so they are listed; here first, but their documentation is more conveniently accessible through; the Python interpreter itself, using the ``help()`` function::. $ python; >>> import cppyy; >>> help(cppyy). `Loading C++`; -------------. C++ code can be loaded as text to be JITed, or be compiled ahead of time and; supplied in the form of a shared library.; In the latter case, C++ headers need to be loaded as well to declare; classes, functions, and variables to Cling.; Instead of headers, pre-compiled code can be used; in particular all of the; standard C++ headers and several system headers are pre-compiled at startup.; cppyy provides the following helpers to load C++ code:. * ``cppdef``: direct access to the interpreter.; This function accepts C++ declarations as a string and JITs them (bindings; are not created until actual use).; The code is loaded into the global scope, thus any previously loaded code; is available from one ``cppdef`` call to the next, as are all standard; C++ headers that have been loaded through pre-compiled headers.; Example::. >>> cppyy.cppdef(r""""""\; ... void hello() {; ... std::cout << ""Hello, World!"" << std::endl;; ... }""""""); True; >>> cppyy.gbl.hello(); Hello, World!; >>> . * ``cppexec``: direct access to the interpreter.; This function accepts C++ statements as a string, JITs and executes them.; Just like ``cppdef``, execution is in the global scope and all previously; loaded code is available.; If the statements are declarations, the effect is the same as ``cppdef``,; but ``cppexec`` also accepts executable lines.; Example::. >>> cppyy.cppexec(r""""""std::string hello = ""Hello, World!"";""""""); True; >>> cppyy.cppexec(""std::cout << hello << std::endl;""); He",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst:997,Security,access,access,997,".. _toplevel:. Top Level; =========. cppyy provides a couple of helper functions at the module level that provide; (direct) access to the Cling interpreter (any C++ code is always accessed; through the global namespace ``cppyy.gbl``).; The documentation makes use of these helpers throughout, so they are listed; here first, but their documentation is more conveniently accessible through; the Python interpreter itself, using the ``help()`` function::. $ python; >>> import cppyy; >>> help(cppyy). `Loading C++`; -------------. C++ code can be loaded as text to be JITed, or be compiled ahead of time and; supplied in the form of a shared library.; In the latter case, C++ headers need to be loaded as well to declare; classes, functions, and variables to Cling.; Instead of headers, pre-compiled code can be used; in particular all of the; standard C++ headers and several system headers are pre-compiled at startup.; cppyy provides the following helpers to load C++ code:. * ``cppdef``: direct access to the interpreter.; This function accepts C++ declarations as a string and JITs them (bindings; are not created until actual use).; The code is loaded into the global scope, thus any previously loaded code; is available from one ``cppdef`` call to the next, as are all standard; C++ headers that have been loaded through pre-compiled headers.; Example::. >>> cppyy.cppdef(r""""""\; ... void hello() {; ... std::cout << ""Hello, World!"" << std::endl;; ... }""""""); True; >>> cppyy.gbl.hello(); Hello, World!; >>> . * ``cppexec``: direct access to the interpreter.; This function accepts C++ statements as a string, JITs and executes them.; Just like ``cppdef``, execution is in the global scope and all previously; loaded code is available.; If the statements are declarations, the effect is the same as ``cppdef``,; but ``cppexec`` also accepts executable lines.; Example::. >>> cppyy.cppexec(r""""""std::string hello = ""Hello, World!"";""""""); True; >>> cppyy.cppexec(""std::cout << hello << std::endl;""); He",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst:1535,Security,access,access,1535,"e can be loaded as text to be JITed, or be compiled ahead of time and; supplied in the form of a shared library.; In the latter case, C++ headers need to be loaded as well to declare; classes, functions, and variables to Cling.; Instead of headers, pre-compiled code can be used; in particular all of the; standard C++ headers and several system headers are pre-compiled at startup.; cppyy provides the following helpers to load C++ code:. * ``cppdef``: direct access to the interpreter.; This function accepts C++ declarations as a string and JITs them (bindings; are not created until actual use).; The code is loaded into the global scope, thus any previously loaded code; is available from one ``cppdef`` call to the next, as are all standard; C++ headers that have been loaded through pre-compiled headers.; Example::. >>> cppyy.cppdef(r""""""\; ... void hello() {; ... std::cout << ""Hello, World!"" << std::endl;; ... }""""""); True; >>> cppyy.gbl.hello(); Hello, World!; >>> . * ``cppexec``: direct access to the interpreter.; This function accepts C++ statements as a string, JITs and executes them.; Just like ``cppdef``, execution is in the global scope and all previously; loaded code is available.; If the statements are declarations, the effect is the same as ``cppdef``,; but ``cppexec`` also accepts executable lines.; Example::. >>> cppyy.cppexec(r""""""std::string hello = ""Hello, World!"";""""""); True; >>> cppyy.cppexec(""std::cout << hello << std::endl;""); Hello, World!; True; >>> . * ``include``: load declarations into the interpreter.; This function accepts C++ declarations from a file, typically a header.; Files are located through include paths given to the Cling.; Example::. >>> cppyy.include(""vector"") # equivalent to ""#include <vector>""; True; >>> . * ``c_include``: load declarations into the interpreter.; This function accepts C++ declarations from a file, typically a header.; Name mangling is an important difference between C and C++ code.; The use of ``c_include`` instead of ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst:3061,Security,expose,expose,3061,": load declarations into the interpreter.; This function accepts C++ declarations from a file, typically a header.; Files are located through include paths given to the Cling.; Example::. >>> cppyy.include(""vector"") # equivalent to ""#include <vector>""; True; >>> . * ``c_include``: load declarations into the interpreter.; This function accepts C++ declarations from a file, typically a header.; Name mangling is an important difference between C and C++ code.; The use of ``c_include`` instead of ``include`` prevents mangling. * ``load_library``: load compiled C++ into the interpreter.; This function takes the name of a shared library and loads it into current; process, exposing all external symbols to Cling.; Libraries are located through load paths given to Cling, either through the; ""-L"" compiler flag or the dynamic search path environment variable (system; dependent).; Any method that brings symbols into the process (including normal linking,; e.g. when embedding Python in a C++ application) is suitable to expose; symbols.; An alternative for ``load_library`` is for example ``ctypes.CDLL``, but; that function does not respect dynamic load paths on all platforms. If a compilation error occurs during JITing of C++ code in any of the above; helpers, a Python ``SyntaxError`` exception is raised.; If a compilation warning occurs, a Python warning is issued. `Configuring Cling`; -------------------. It is often convenient to add additional search paths for Cling to find; headers and libraries when loading a module (Python does not have standard; locations to place headers and libraries, but their locations can usually; be inferred from the location of the module, i.e. it's ``__file__``; attribute).; cppyy provides the following two helpers:. * ``add_include_path``: add additional paths for Cling to look for headers. * ``add_library_path``: add additional paths for Cling to look for libraries. Both functions accept either a string (a single path) or a list (for adding; mul",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst:4905,Security,access,accessible,4905,"e for ``load_library`` is for example ``ctypes.CDLL``, but; that function does not respect dynamic load paths on all platforms. If a compilation error occurs during JITing of C++ code in any of the above; helpers, a Python ``SyntaxError`` exception is raised.; If a compilation warning occurs, a Python warning is issued. `Configuring Cling`; -------------------. It is often convenient to add additional search paths for Cling to find; headers and libraries when loading a module (Python does not have standard; locations to place headers and libraries, but their locations can usually; be inferred from the location of the module, i.e. it's ``__file__``; attribute).; cppyy provides the following two helpers:. * ``add_include_path``: add additional paths for Cling to look for headers. * ``add_library_path``: add additional paths for Cling to look for libraries. Both functions accept either a string (a single path) or a list (for adding; multiple paths).; Paths are allowed to be relative, but absolute paths are recommended. `C++ language`; --------------. Some C++ compilation-time features have no Python equivalent.; Instead, convenience functions are provided:. * ``sizeof``: takes a proxied C++ type or its name as a string and returns; the storage size (in units of ``char``). * ``typeid``: takes a proxied C++ type or its name as a string and returns; the the C++ runtime type information (RTTI). * ``nullptr``: C++ ``NULL``. `Preprocessor`; --------------. Preprocessor macro's (``#define``) are not available on the Python side,; because there is no type information available for them.; They are, however, often used for constant data (e.g. flags or numbers; note; that modern C++ recommends the use of ``const`` and ``constexpr`` instead).; Within limits, macro's representing constant data are accessible through the; ``macro`` helper function.; Example::. >>> import cppyy; >>> cppyy.cppdef('#define HELLO ""Hello, World!""'); True; >>> cppyy.macro(""HELLO""); 'Hello, World!'; >>> . ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/toplevel.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/type_conversions.rst:1393,Availability,avail,available,1393," any session.; Download it, save it under the name ``features.h``, and load it:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('features.h'); >>>. .. _sec-auto-casting-label:. `Auto-casting`; --------------. Object pointer returns from functions provide the most derived class known; (i.e. exposed in header files) in the hierarchy of the object being returned.; This is important to preserve object identity as well as to make casting,; a pure C++ feature after all, superfluous.; Example:. .. code-block:: python. >>> from cppyy.gbl import Abstract, Concrete; >>> c = Concrete(); >>> Concrete.show_autocast.__doc__; 'Abstract* Concrete::show_autocast()'; >>> d = c.show_autocast(); >>> type(d); <class '__main__.Concrete'>; >>>. As a consequence, if your C++ classes should only be used through their; interfaces, then no bindings should be provided to the concrete classes; (e.g. by excluding them using a :ref:`selection file <selection-files>`).; Otherwise, more functionality will be available in Python than in C++. Sometimes, however, full control over a cast is needed.; For example, if the instance is bound by another tool or even a 3rd party,; hand-written, extension library.; Assuming the object supports the ``PyCapsule`` or ``CObject`` abstraction,; then a C++-style reinterpret_cast (i.e. without implicitly taking offsets; into account), can be done by taking and rebinding the address of an; object:. .. code-block:: python. >>> from cppyy import addressof, bind_object; >>> e = bind_object(addressof(d), Abstract); >>> type(e); <class '__main__.Abstract'>; >>>. `Operators`; -----------. If conversion operators are defined in the C++ class and a Python equivalent; exists (i.e. all builtin integer and floating point types, as well as; ``bool``), then these will map onto those Python conversions.; Note that ``char*`` is mapped onto ``__str__``.; Example:. .. code-block:: python. >>> from cppyy.gbl import Concrete; >>> print(Concrete()); Hello operator const cha",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/type_conversions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/type_conversions.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/type_conversions.rst:2585,Availability,avail,available,2585," object being returned.; This is important to preserve object identity as well as to make casting,; a pure C++ feature after all, superfluous.; Example:. .. code-block:: python. >>> from cppyy.gbl import Abstract, Concrete; >>> c = Concrete(); >>> Concrete.show_autocast.__doc__; 'Abstract* Concrete::show_autocast()'; >>> d = c.show_autocast(); >>> type(d); <class '__main__.Concrete'>; >>>. As a consequence, if your C++ classes should only be used through their; interfaces, then no bindings should be provided to the concrete classes; (e.g. by excluding them using a :ref:`selection file <selection-files>`).; Otherwise, more functionality will be available in Python than in C++. Sometimes, however, full control over a cast is needed.; For example, if the instance is bound by another tool or even a 3rd party,; hand-written, extension library.; Assuming the object supports the ``PyCapsule`` or ``CObject`` abstraction,; then a C++-style reinterpret_cast (i.e. without implicitly taking offsets; into account), can be done by taking and rebinding the address of an; object:. .. code-block:: python. >>> from cppyy import addressof, bind_object; >>> e = bind_object(addressof(d), Abstract); >>> type(e); <class '__main__.Abstract'>; >>>. `Operators`; -----------. If conversion operators are defined in the C++ class and a Python equivalent; exists (i.e. all builtin integer and floating point types, as well as; ``bool``), then these will map onto those Python conversions.; Note that ``char*`` is mapped onto ``__str__``.; Example:. .. code-block:: python. >>> from cppyy.gbl import Concrete; >>> print(Concrete()); Hello operator const char*!; >>>. C++ code can overload conversion operators by providing methods in a class or; global functions.; Special care needs to be taken for the latter: first, make sure that they are; actually available in some header file.; Second, make sure that headers are loaded in the desired order.; I.e. that these global overloads are available before use. ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/type_conversions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/type_conversions.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/type_conversions.rst:2719,Availability,avail,available,2719," object being returned.; This is important to preserve object identity as well as to make casting,; a pure C++ feature after all, superfluous.; Example:. .. code-block:: python. >>> from cppyy.gbl import Abstract, Concrete; >>> c = Concrete(); >>> Concrete.show_autocast.__doc__; 'Abstract* Concrete::show_autocast()'; >>> d = c.show_autocast(); >>> type(d); <class '__main__.Concrete'>; >>>. As a consequence, if your C++ classes should only be used through their; interfaces, then no bindings should be provided to the concrete classes; (e.g. by excluding them using a :ref:`selection file <selection-files>`).; Otherwise, more functionality will be available in Python than in C++. Sometimes, however, full control over a cast is needed.; For example, if the instance is bound by another tool or even a 3rd party,; hand-written, extension library.; Assuming the object supports the ``PyCapsule`` or ``CObject`` abstraction,; then a C++-style reinterpret_cast (i.e. without implicitly taking offsets; into account), can be done by taking and rebinding the address of an; object:. .. code-block:: python. >>> from cppyy import addressof, bind_object; >>> e = bind_object(addressof(d), Abstract); >>> type(e); <class '__main__.Abstract'>; >>>. `Operators`; -----------. If conversion operators are defined in the C++ class and a Python equivalent; exists (i.e. all builtin integer and floating point types, as well as; ``bool``), then these will map onto those Python conversions.; Note that ``char*`` is mapped onto ``__str__``.; Example:. .. code-block:: python. >>> from cppyy.gbl import Concrete; >>> print(Concrete()); Hello operator const char*!; >>>. C++ code can overload conversion operators by providing methods in a class or; global functions.; Special care needs to be taken for the latter: first, make sure that they are; actually available in some header file.; Second, make sure that headers are loaded in the desired order.; I.e. that these global overloads are available before use. ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/type_conversions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/type_conversions.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/type_conversions.rst:1207,Integrability,interface,interfaces,1207,"perform explicit conversions. The C++ code used for the examples below can be found; :doc:`here <cppyy_features_header>`, and it is assumed that that code is; loaded at the start of any session.; Download it, save it under the name ``features.h``, and load it:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('features.h'); >>>. .. _sec-auto-casting-label:. `Auto-casting`; --------------. Object pointer returns from functions provide the most derived class known; (i.e. exposed in header files) in the hierarchy of the object being returned.; This is important to preserve object identity as well as to make casting,; a pure C++ feature after all, superfluous.; Example:. .. code-block:: python. >>> from cppyy.gbl import Abstract, Concrete; >>> c = Concrete(); >>> Concrete.show_autocast.__doc__; 'Abstract* Concrete::show_autocast()'; >>> d = c.show_autocast(); >>> type(d); <class '__main__.Concrete'>; >>>. As a consequence, if your C++ classes should only be used through their; interfaces, then no bindings should be provided to the concrete classes; (e.g. by excluding them using a :ref:`selection file <selection-files>`).; Otherwise, more functionality will be available in Python than in C++. Sometimes, however, full control over a cast is needed.; For example, if the instance is bound by another tool or even a 3rd party,; hand-written, extension library.; Assuming the object supports the ``PyCapsule`` or ``CObject`` abstraction,; then a C++-style reinterpret_cast (i.e. without implicitly taking offsets; into account), can be done by taking and rebinding the address of an; object:. .. code-block:: python. >>> from cppyy import addressof, bind_object; >>> e = bind_object(addressof(d), Abstract); >>> type(e); <class '__main__.Abstract'>; >>>. `Operators`; -----------. If conversion operators are defined in the C++ class and a Python equivalent; exists (i.e. all builtin integer and floating point types, as well as; ``bool``), then these will map onto those Python",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/type_conversions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/type_conversions.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/type_conversions.rst:208,Performance,perform,perform,208,".. _type_conversions:. Type conversions; ================. Most type conversions are done automatically, e.g. between Python ``str``; and C++ ``std::string`` and ``const char*``, but low-level APIs exist to; perform explicit conversions. The C++ code used for the examples below can be found; :doc:`here <cppyy_features_header>`, and it is assumed that that code is; loaded at the start of any session.; Download it, save it under the name ``features.h``, and load it:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('features.h'); >>>. .. _sec-auto-casting-label:. `Auto-casting`; --------------. Object pointer returns from functions provide the most derived class known; (i.e. exposed in header files) in the hierarchy of the object being returned.; This is important to preserve object identity as well as to make casting,; a pure C++ feature after all, superfluous.; Example:. .. code-block:: python. >>> from cppyy.gbl import Abstract, Concrete; >>> c = Concrete(); >>> Concrete.show_autocast.__doc__; 'Abstract* Concrete::show_autocast()'; >>> d = c.show_autocast(); >>> type(d); <class '__main__.Concrete'>; >>>. As a consequence, if your C++ classes should only be used through their; interfaces, then no bindings should be provided to the concrete classes; (e.g. by excluding them using a :ref:`selection file <selection-files>`).; Otherwise, more functionality will be available in Python than in C++. Sometimes, however, full control over a cast is needed.; For example, if the instance is bound by another tool or even a 3rd party,; hand-written, extension library.; Assuming the object supports the ``PyCapsule`` or ``CObject`` abstraction,; then a C++-style reinterpret_cast (i.e. without implicitly taking offsets; into account), can be done by taking and rebinding the address of an; object:. .. code-block:: python. >>> from cppyy import addressof, bind_object; >>> e = bind_object(addressof(d), Abstract); >>> type(e); <class '__main__.Abstract'>; >>>. `Operators`; ---",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/type_conversions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/type_conversions.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/type_conversions.rst:367,Performance,load,loaded,367,".. _type_conversions:. Type conversions; ================. Most type conversions are done automatically, e.g. between Python ``str``; and C++ ``std::string`` and ``const char*``, but low-level APIs exist to; perform explicit conversions. The C++ code used for the examples below can be found; :doc:`here <cppyy_features_header>`, and it is assumed that that code is; loaded at the start of any session.; Download it, save it under the name ``features.h``, and load it:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('features.h'); >>>. .. _sec-auto-casting-label:. `Auto-casting`; --------------. Object pointer returns from functions provide the most derived class known; (i.e. exposed in header files) in the hierarchy of the object being returned.; This is important to preserve object identity as well as to make casting,; a pure C++ feature after all, superfluous.; Example:. .. code-block:: python. >>> from cppyy.gbl import Abstract, Concrete; >>> c = Concrete(); >>> Concrete.show_autocast.__doc__; 'Abstract* Concrete::show_autocast()'; >>> d = c.show_autocast(); >>> type(d); <class '__main__.Concrete'>; >>>. As a consequence, if your C++ classes should only be used through their; interfaces, then no bindings should be provided to the concrete classes; (e.g. by excluding them using a :ref:`selection file <selection-files>`).; Otherwise, more functionality will be available in Python than in C++. Sometimes, however, full control over a cast is needed.; For example, if the instance is bound by another tool or even a 3rd party,; hand-written, extension library.; Assuming the object supports the ``PyCapsule`` or ``CObject`` abstraction,; then a C++-style reinterpret_cast (i.e. without implicitly taking offsets; into account), can be done by taking and rebinding the address of an; object:. .. code-block:: python. >>> from cppyy import addressof, bind_object; >>> e = bind_object(addressof(d), Abstract); >>> type(e); <class '__main__.Abstract'>; >>>. `Operators`; ---",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/type_conversions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/type_conversions.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/type_conversions.rst:460,Performance,load,load,460,".. _type_conversions:. Type conversions; ================. Most type conversions are done automatically, e.g. between Python ``str``; and C++ ``std::string`` and ``const char*``, but low-level APIs exist to; perform explicit conversions. The C++ code used for the examples below can be found; :doc:`here <cppyy_features_header>`, and it is assumed that that code is; loaded at the start of any session.; Download it, save it under the name ``features.h``, and load it:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('features.h'); >>>. .. _sec-auto-casting-label:. `Auto-casting`; --------------. Object pointer returns from functions provide the most derived class known; (i.e. exposed in header files) in the hierarchy of the object being returned.; This is important to preserve object identity as well as to make casting,; a pure C++ feature after all, superfluous.; Example:. .. code-block:: python. >>> from cppyy.gbl import Abstract, Concrete; >>> c = Concrete(); >>> Concrete.show_autocast.__doc__; 'Abstract* Concrete::show_autocast()'; >>> d = c.show_autocast(); >>> type(d); <class '__main__.Concrete'>; >>>. As a consequence, if your C++ classes should only be used through their; interfaces, then no bindings should be provided to the concrete classes; (e.g. by excluding them using a :ref:`selection file <selection-files>`).; Otherwise, more functionality will be available in Python than in C++. Sometimes, however, full control over a cast is needed.; For example, if the instance is bound by another tool or even a 3rd party,; hand-written, extension library.; Assuming the object supports the ``PyCapsule`` or ``CObject`` abstraction,; then a C++-style reinterpret_cast (i.e. without implicitly taking offsets; into account), can be done by taking and rebinding the address of an; object:. .. code-block:: python. >>> from cppyy import addressof, bind_object; >>> e = bind_object(addressof(d), Abstract); >>> type(e); <class '__main__.Abstract'>; >>>. `Operators`; ---",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/type_conversions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/type_conversions.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/type_conversions.rst:2652,Performance,load,loaded,2652," object being returned.; This is important to preserve object identity as well as to make casting,; a pure C++ feature after all, superfluous.; Example:. .. code-block:: python. >>> from cppyy.gbl import Abstract, Concrete; >>> c = Concrete(); >>> Concrete.show_autocast.__doc__; 'Abstract* Concrete::show_autocast()'; >>> d = c.show_autocast(); >>> type(d); <class '__main__.Concrete'>; >>>. As a consequence, if your C++ classes should only be used through their; interfaces, then no bindings should be provided to the concrete classes; (e.g. by excluding them using a :ref:`selection file <selection-files>`).; Otherwise, more functionality will be available in Python than in C++. Sometimes, however, full control over a cast is needed.; For example, if the instance is bound by another tool or even a 3rd party,; hand-written, extension library.; Assuming the object supports the ``PyCapsule`` or ``CObject`` abstraction,; then a C++-style reinterpret_cast (i.e. without implicitly taking offsets; into account), can be done by taking and rebinding the address of an; object:. .. code-block:: python. >>> from cppyy import addressof, bind_object; >>> e = bind_object(addressof(d), Abstract); >>> type(e); <class '__main__.Abstract'>; >>>. `Operators`; -----------. If conversion operators are defined in the C++ class and a Python equivalent; exists (i.e. all builtin integer and floating point types, as well as; ``bool``), then these will map onto those Python conversions.; Note that ``char*`` is mapped onto ``__str__``.; Example:. .. code-block:: python. >>> from cppyy.gbl import Concrete; >>> print(Concrete()); Hello operator const char*!; >>>. C++ code can overload conversion operators by providing methods in a class or; global functions.; Special care needs to be taken for the latter: first, make sure that they are; actually available in some header file.; Second, make sure that headers are loaded in the desired order.; I.e. that these global overloads are available before use. ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/type_conversions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/type_conversions.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/type_conversions.rst:693,Security,expose,exposed,693,".. _type_conversions:. Type conversions; ================. Most type conversions are done automatically, e.g. between Python ``str``; and C++ ``std::string`` and ``const char*``, but low-level APIs exist to; perform explicit conversions. The C++ code used for the examples below can be found; :doc:`here <cppyy_features_header>`, and it is assumed that that code is; loaded at the start of any session.; Download it, save it under the name ``features.h``, and load it:. .. code-block:: python. >>> import cppyy; >>> cppyy.include('features.h'); >>>. .. _sec-auto-casting-label:. `Auto-casting`; --------------. Object pointer returns from functions provide the most derived class known; (i.e. exposed in header files) in the hierarchy of the object being returned.; This is important to preserve object identity as well as to make casting,; a pure C++ feature after all, superfluous.; Example:. .. code-block:: python. >>> from cppyy.gbl import Abstract, Concrete; >>> c = Concrete(); >>> Concrete.show_autocast.__doc__; 'Abstract* Concrete::show_autocast()'; >>> d = c.show_autocast(); >>> type(d); <class '__main__.Concrete'>; >>>. As a consequence, if your C++ classes should only be used through their; interfaces, then no bindings should be provided to the concrete classes; (e.g. by excluding them using a :ref:`selection file <selection-files>`).; Otherwise, more functionality will be available in Python than in C++. Sometimes, however, full control over a cast is needed.; For example, if the instance is bound by another tool or even a 3rd party,; hand-written, extension library.; Assuming the object supports the ``PyCapsule`` or ``CObject`` abstraction,; then a C++-style reinterpret_cast (i.e. without implicitly taking offsets; into account), can be done by taking and rebinding the address of an; object:. .. code-block:: python. >>> from cppyy import addressof, bind_object; >>> e = bind_object(addressof(d), Abstract); >>> type(e); <class '__main__.Abstract'>; >>>. `Operators`; ---",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/type_conversions.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/type_conversions.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst:3788,Availability,robust,robustness,3788,"r bindings generation, lower memory; footprint, and isolation from preprocessor macros and compiler flags.; The use of modules is transparent, other than the requirement that they; need to be co-located with the compiled dictionary shared library. Optionally, the dictionary generation process also produces a mapping file,; which lists the libraries needed to load C++ classes on request (for details,; see the section on the class loader below). Structurally, you could have a single dictionary for a project as a whole,; but more likely a large project will have a pre-existing functional; decomposition that can be followed, with a dictionary per functional unit. Generation; ^^^^^^^^^^. There are two interfaces onto the same underlying dictionary generator:; ``rootcling`` and ``genreflex``.; The reason for having two is historic and they are not complete duplicates,; so one or the other may suit your preference better.; It is foreseen that both will be replaced once C++ modules become more; mainstream, as that will allow simplification and improved robustness. rootcling; """""""""""""""""". The first interface is called ``rootcling``::. $ rootcling; Usage: rootcling [-v][-v0-4] [-f] [out.cxx] [opts] file1.h[+][-][!] file2.h[+][-][!] ...[Linkdef.h]; For more extensive help type: /usr/local/lib/python2.7/dist-packages/cppyy_backend/bin/rootcling -h. Rather than providing command line options, the main steering of; ``rootcling`` behavior is done through; `#pragmas in a Linkdef.h <https://root.cern.ch/root/html/guides/users-guide/AddingaClass.html#the-linkdef.h-file>`_; file, with most pragmas dedicated to selecting/excluding (parts of) classes; and functions.; Additionally, the Linkdef.h file may contain preprocessor macros. The output consists of a dictionary file (to be compiled into a shared; library), a C++ module, and an optional mapping file, as described above. genreflex; """""""""""""""""". The second interface is called ``genreflex``::. $ genreflex; Generates dictionary sources and",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst:426,Deployability,install,installed,426,".. _utilities:. Utilities; =========. The ``cppyy-backend`` package brings in the following utilities to help; with repackaging and redistribution:. * cling-config: for compile time flags; * rootcling and genreflex: for dictionary generation; * cppyy-generator: part of the :doc:`CMake interface <cmake_interface>`. Compiler/linker flags; ---------------------. ``cling-config`` is a small utility to provide access to the as-installed; configuration, such as compiler/linker flags and installation directories, of; other components.; Usage examples::. $ cling-config --help; Usage: cling-config [--cflags] [--cppflags] [--cmake]; $ cling-config --cmake; /usr/local/lib/python2.7/dist-packages/cppyy_backend/cmake. .. _dictionaries:. Dictionaries; ------------. Loading header files or code directly into ``cling`` is fine for interactive; work and smaller packages, but large scale applications benefit from; pre-compiling code, using the automatic class loader, and packaging; dependencies in so-called ""dictionaries."". A `dictionary` is a generated C++ source file containing references to the; header locations used when building (and any additional locations provided),; a set of forward declarations to reduce the need of loading header files, and; a few I/O helper functions.; The name ""dictionary"" is historic: before ``cling`` was used, it contained; the complete generated C++ reflection information, whereas now that is; derived at run-time from the header files.; It is still possible to fully embed header files rather than only storing; their names and search locations, to make the dictionary more self-contained. After generating the dictionary, it should be compiled into a shared library.; This provides additional dependency control: by linking it directly with any; further libraries needed, you can use standard mechanisms such as ``rpath``; to locate those library dependencies.; Alternatively, you can add the additional libraries to load to the mapping; files of the class load",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst:437,Deployability,configurat,configuration,437,".. _utilities:. Utilities; =========. The ``cppyy-backend`` package brings in the following utilities to help; with repackaging and redistribution:. * cling-config: for compile time flags; * rootcling and genreflex: for dictionary generation; * cppyy-generator: part of the :doc:`CMake interface <cmake_interface>`. Compiler/linker flags; ---------------------. ``cling-config`` is a small utility to provide access to the as-installed; configuration, such as compiler/linker flags and installation directories, of; other components.; Usage examples::. $ cling-config --help; Usage: cling-config [--cflags] [--cppflags] [--cmake]; $ cling-config --cmake; /usr/local/lib/python2.7/dist-packages/cppyy_backend/cmake. .. _dictionaries:. Dictionaries; ------------. Loading header files or code directly into ``cling`` is fine for interactive; work and smaller packages, but large scale applications benefit from; pre-compiling code, using the automatic class loader, and packaging; dependencies in so-called ""dictionaries."". A `dictionary` is a generated C++ source file containing references to the; header locations used when building (and any additional locations provided),; a set of forward declarations to reduce the need of loading header files, and; a few I/O helper functions.; The name ""dictionary"" is historic: before ``cling`` was used, it contained; the complete generated C++ reflection information, whereas now that is; derived at run-time from the header files.; It is still possible to fully embed header files rather than only storing; their names and search locations, to make the dictionary more self-contained. After generating the dictionary, it should be compiled into a shared library.; This provides additional dependency control: by linking it directly with any; further libraries needed, you can use standard mechanisms such as ``rpath``; to locate those library dependencies.; Alternatively, you can add the additional libraries to load to the mapping; files of the class load",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst:486,Deployability,install,installation,486,".. _utilities:. Utilities; =========. The ``cppyy-backend`` package brings in the following utilities to help; with repackaging and redistribution:. * cling-config: for compile time flags; * rootcling and genreflex: for dictionary generation; * cppyy-generator: part of the :doc:`CMake interface <cmake_interface>`. Compiler/linker flags; ---------------------. ``cling-config`` is a small utility to provide access to the as-installed; configuration, such as compiler/linker flags and installation directories, of; other components.; Usage examples::. $ cling-config --help; Usage: cling-config [--cflags] [--cppflags] [--cmake]; $ cling-config --cmake; /usr/local/lib/python2.7/dist-packages/cppyy_backend/cmake. .. _dictionaries:. Dictionaries; ------------. Loading header files or code directly into ``cling`` is fine for interactive; work and smaller packages, but large scale applications benefit from; pre-compiling code, using the automatic class loader, and packaging; dependencies in so-called ""dictionaries."". A `dictionary` is a generated C++ source file containing references to the; header locations used when building (and any additional locations provided),; a set of forward declarations to reduce the need of loading header files, and; a few I/O helper functions.; The name ""dictionary"" is historic: before ``cling`` was used, it contained; the complete generated C++ reflection information, whereas now that is; derived at run-time from the header files.; It is still possible to fully embed header files rather than only storing; their names and search locations, to make the dictionary more self-contained. After generating the dictionary, it should be compiled into a shared library.; This provides additional dependency control: by linking it directly with any; further libraries needed, you can use standard mechanisms such as ``rpath``; to locate those library dependencies.; Alternatively, you can add the additional libraries to load to the mapping; files of the class load",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst:1209,Energy Efficiency,reduce,reduce,1209,"cling-config: for compile time flags; * rootcling and genreflex: for dictionary generation; * cppyy-generator: part of the :doc:`CMake interface <cmake_interface>`. Compiler/linker flags; ---------------------. ``cling-config`` is a small utility to provide access to the as-installed; configuration, such as compiler/linker flags and installation directories, of; other components.; Usage examples::. $ cling-config --help; Usage: cling-config [--cflags] [--cppflags] [--cmake]; $ cling-config --cmake; /usr/local/lib/python2.7/dist-packages/cppyy_backend/cmake. .. _dictionaries:. Dictionaries; ------------. Loading header files or code directly into ``cling`` is fine for interactive; work and smaller packages, but large scale applications benefit from; pre-compiling code, using the automatic class loader, and packaging; dependencies in so-called ""dictionaries."". A `dictionary` is a generated C++ source file containing references to the; header locations used when building (and any additional locations provided),; a set of forward declarations to reduce the need of loading header files, and; a few I/O helper functions.; The name ""dictionary"" is historic: before ``cling`` was used, it contained; the complete generated C++ reflection information, whereas now that is; derived at run-time from the header files.; It is still possible to fully embed header files rather than only storing; their names and search locations, to make the dictionary more self-contained. After generating the dictionary, it should be compiled into a shared library.; This provides additional dependency control: by linking it directly with any; further libraries needed, you can use standard mechanisms such as ``rpath``; to locate those library dependencies.; Alternatively, you can add the additional libraries to load to the mapping; files of the class loader (see below). .. note::. The JIT needs to resolve linker symbols in order to call them through; generated wrappers.; Thus, any classes, functions, an",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst:286,Integrability,interface,interface,286,".. _utilities:. Utilities; =========. The ``cppyy-backend`` package brings in the following utilities to help; with repackaging and redistribution:. * cling-config: for compile time flags; * rootcling and genreflex: for dictionary generation; * cppyy-generator: part of the :doc:`CMake interface <cmake_interface>`. Compiler/linker flags; ---------------------. ``cling-config`` is a small utility to provide access to the as-installed; configuration, such as compiler/linker flags and installation directories, of; other components.; Usage examples::. $ cling-config --help; Usage: cling-config [--cflags] [--cppflags] [--cmake]; $ cling-config --cmake; /usr/local/lib/python2.7/dist-packages/cppyy_backend/cmake. .. _dictionaries:. Dictionaries; ------------. Loading header files or code directly into ``cling`` is fine for interactive; work and smaller packages, but large scale applications benefit from; pre-compiling code, using the automatic class loader, and packaging; dependencies in so-called ""dictionaries."". A `dictionary` is a generated C++ source file containing references to the; header locations used when building (and any additional locations provided),; a set of forward declarations to reduce the need of loading header files, and; a few I/O helper functions.; The name ""dictionary"" is historic: before ``cling`` was used, it contained; the complete generated C++ reflection information, whereas now that is; derived at run-time from the header files.; It is still possible to fully embed header files rather than only storing; their names and search locations, to make the dictionary more self-contained. After generating the dictionary, it should be compiled into a shared library.; This provides additional dependency control: by linking it directly with any; further libraries needed, you can use standard mechanisms such as ``rpath``; to locate those library dependencies.; Alternatively, you can add the additional libraries to load to the mapping; files of the class load",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst:979,Integrability,depend,dependencies,979,".. _utilities:. Utilities; =========. The ``cppyy-backend`` package brings in the following utilities to help; with repackaging and redistribution:. * cling-config: for compile time flags; * rootcling and genreflex: for dictionary generation; * cppyy-generator: part of the :doc:`CMake interface <cmake_interface>`. Compiler/linker flags; ---------------------. ``cling-config`` is a small utility to provide access to the as-installed; configuration, such as compiler/linker flags and installation directories, of; other components.; Usage examples::. $ cling-config --help; Usage: cling-config [--cflags] [--cppflags] [--cmake]; $ cling-config --cmake; /usr/local/lib/python2.7/dist-packages/cppyy_backend/cmake. .. _dictionaries:. Dictionaries; ------------. Loading header files or code directly into ``cling`` is fine for interactive; work and smaller packages, but large scale applications benefit from; pre-compiling code, using the automatic class loader, and packaging; dependencies in so-called ""dictionaries."". A `dictionary` is a generated C++ source file containing references to the; header locations used when building (and any additional locations provided),; a set of forward declarations to reduce the need of loading header files, and; a few I/O helper functions.; The name ""dictionary"" is historic: before ``cling`` was used, it contained; the complete generated C++ reflection information, whereas now that is; derived at run-time from the header files.; It is still possible to fully embed header files rather than only storing; their names and search locations, to make the dictionary more self-contained. After generating the dictionary, it should be compiled into a shared library.; This provides additional dependency control: by linking it directly with any; further libraries needed, you can use standard mechanisms such as ``rpath``; to locate those library dependencies.; Alternatively, you can add the additional libraries to load to the mapping; files of the class load",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst:1733,Integrability,depend,dependency,1733,"o ``cling`` is fine for interactive; work and smaller packages, but large scale applications benefit from; pre-compiling code, using the automatic class loader, and packaging; dependencies in so-called ""dictionaries."". A `dictionary` is a generated C++ source file containing references to the; header locations used when building (and any additional locations provided),; a set of forward declarations to reduce the need of loading header files, and; a few I/O helper functions.; The name ""dictionary"" is historic: before ``cling`` was used, it contained; the complete generated C++ reflection information, whereas now that is; derived at run-time from the header files.; It is still possible to fully embed header files rather than only storing; their names and search locations, to make the dictionary more self-contained. After generating the dictionary, it should be compiled into a shared library.; This provides additional dependency control: by linking it directly with any; further libraries needed, you can use standard mechanisms such as ``rpath``; to locate those library dependencies.; Alternatively, you can add the additional libraries to load to the mapping; files of the class loader (see below). .. note::. The JIT needs to resolve linker symbols in order to call them through; generated wrappers.; Thus, any classes, functions, and data that will be used in Python need; to be exported.; This is the default behavior on Mac and Linux, but not on Windows.; On that platform, use ``__declspec(dllexport)`` to explicitly export the; classes and function you expect to call.; CMake has simple `support for exporting all`_ C++ symbols. In tandem with any dictionary, a pre-compiled module (.pcm) file will be; generated.; C++ modules are still on track for inclusion in the C++20 standard and most; modern C++ compilers, ``clang`` among them, already have implementations.; The benefits for cppyy include faster bindings generation, lower memory; footprint, and isolation from preproces",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst:1887,Integrability,depend,dependencies,1887,"o ``cling`` is fine for interactive; work and smaller packages, but large scale applications benefit from; pre-compiling code, using the automatic class loader, and packaging; dependencies in so-called ""dictionaries."". A `dictionary` is a generated C++ source file containing references to the; header locations used when building (and any additional locations provided),; a set of forward declarations to reduce the need of loading header files, and; a few I/O helper functions.; The name ""dictionary"" is historic: before ``cling`` was used, it contained; the complete generated C++ reflection information, whereas now that is; derived at run-time from the header files.; It is still possible to fully embed header files rather than only storing; their names and search locations, to make the dictionary more self-contained. After generating the dictionary, it should be compiled into a shared library.; This provides additional dependency control: by linking it directly with any; further libraries needed, you can use standard mechanisms such as ``rpath``; to locate those library dependencies.; Alternatively, you can add the additional libraries to load to the mapping; files of the class loader (see below). .. note::. The JIT needs to resolve linker symbols in order to call them through; generated wrappers.; Thus, any classes, functions, and data that will be used in Python need; to be exported.; This is the default behavior on Mac and Linux, but not on Windows.; On that platform, use ``__declspec(dllexport)`` to explicitly export the; classes and function you expect to call.; CMake has simple `support for exporting all`_ C++ symbols. In tandem with any dictionary, a pre-compiled module (.pcm) file will be; generated.; C++ modules are still on track for inclusion in the C++20 standard and most; modern C++ compilers, ``clang`` among them, already have implementations.; The benefits for cppyy include faster bindings generation, lower memory; footprint, and isolation from preproces",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst:2109,Integrability,wrap,wrappers,2109,"aining references to the; header locations used when building (and any additional locations provided),; a set of forward declarations to reduce the need of loading header files, and; a few I/O helper functions.; The name ""dictionary"" is historic: before ``cling`` was used, it contained; the complete generated C++ reflection information, whereas now that is; derived at run-time from the header files.; It is still possible to fully embed header files rather than only storing; their names and search locations, to make the dictionary more self-contained. After generating the dictionary, it should be compiled into a shared library.; This provides additional dependency control: by linking it directly with any; further libraries needed, you can use standard mechanisms such as ``rpath``; to locate those library dependencies.; Alternatively, you can add the additional libraries to load to the mapping; files of the class loader (see below). .. note::. The JIT needs to resolve linker symbols in order to call them through; generated wrappers.; Thus, any classes, functions, and data that will be used in Python need; to be exported.; This is the default behavior on Mac and Linux, but not on Windows.; On that platform, use ``__declspec(dllexport)`` to explicitly export the; classes and function you expect to call.; CMake has simple `support for exporting all`_ C++ symbols. In tandem with any dictionary, a pre-compiled module (.pcm) file will be; generated.; C++ modules are still on track for inclusion in the C++20 standard and most; modern C++ compilers, ``clang`` among them, already have implementations.; The benefits for cppyy include faster bindings generation, lower memory; footprint, and isolation from preprocessor macros and compiler flags.; The use of modules is transparent, other than the requirement that they; need to be co-located with the compiled dictionary shared library. Optionally, the dictionary generation process also produces a mapping file,; which lists the libra",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst:3433,Integrability,interface,interfaces,3433," dictionary, a pre-compiled module (.pcm) file will be; generated.; C++ modules are still on track for inclusion in the C++20 standard and most; modern C++ compilers, ``clang`` among them, already have implementations.; The benefits for cppyy include faster bindings generation, lower memory; footprint, and isolation from preprocessor macros and compiler flags.; The use of modules is transparent, other than the requirement that they; need to be co-located with the compiled dictionary shared library. Optionally, the dictionary generation process also produces a mapping file,; which lists the libraries needed to load C++ classes on request (for details,; see the section on the class loader below). Structurally, you could have a single dictionary for a project as a whole,; but more likely a large project will have a pre-existing functional; decomposition that can be followed, with a dictionary per functional unit. Generation; ^^^^^^^^^^. There are two interfaces onto the same underlying dictionary generator:; ``rootcling`` and ``genreflex``.; The reason for having two is historic and they are not complete duplicates,; so one or the other may suit your preference better.; It is foreseen that both will be replaced once C++ modules become more; mainstream, as that will allow simplification and improved robustness. rootcling; """""""""""""""""". The first interface is called ``rootcling``::. $ rootcling; Usage: rootcling [-v][-v0-4] [-f] [out.cxx] [opts] file1.h[+][-][!] file2.h[+][-][!] ...[Linkdef.h]; For more extensive help type: /usr/local/lib/python2.7/dist-packages/cppyy_backend/bin/rootcling -h. Rather than providing command line options, the main steering of; ``rootcling`` behavior is done through; `#pragmas in a Linkdef.h <https://root.cern.ch/root/html/guides/users-guide/AddingaClass.html#the-linkdef.h-file>`_; file, with most pragmas dedicated to selecting/excluding (parts of) classes; and functions.; Additionally, the Linkdef.h file may contain preprocessor macros. The o",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst:3832,Integrability,interface,interface,3832,"f modules is transparent, other than the requirement that they; need to be co-located with the compiled dictionary shared library. Optionally, the dictionary generation process also produces a mapping file,; which lists the libraries needed to load C++ classes on request (for details,; see the section on the class loader below). Structurally, you could have a single dictionary for a project as a whole,; but more likely a large project will have a pre-existing functional; decomposition that can be followed, with a dictionary per functional unit. Generation; ^^^^^^^^^^. There are two interfaces onto the same underlying dictionary generator:; ``rootcling`` and ``genreflex``.; The reason for having two is historic and they are not complete duplicates,; so one or the other may suit your preference better.; It is foreseen that both will be replaced once C++ modules become more; mainstream, as that will allow simplification and improved robustness. rootcling; """""""""""""""""". The first interface is called ``rootcling``::. $ rootcling; Usage: rootcling [-v][-v0-4] [-f] [out.cxx] [opts] file1.h[+][-][!] file2.h[+][-][!] ...[Linkdef.h]; For more extensive help type: /usr/local/lib/python2.7/dist-packages/cppyy_backend/bin/rootcling -h. Rather than providing command line options, the main steering of; ``rootcling`` behavior is done through; `#pragmas in a Linkdef.h <https://root.cern.ch/root/html/guides/users-guide/AddingaClass.html#the-linkdef.h-file>`_; file, with most pragmas dedicated to selecting/excluding (parts of) classes; and functions.; Additionally, the Linkdef.h file may contain preprocessor macros. The output consists of a dictionary file (to be compiled into a shared; library), a C++ module, and an optional mapping file, as described above. genreflex; """""""""""""""""". The second interface is called ``genreflex``::. $ genreflex; Generates dictionary sources and related ROOT pcm starting from an header.; Usage: genreflex headerfile.h [opts] [preproc. opts]; ... ``genreflex`` ha",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst:4645,Integrability,interface,interface,4645,"It is foreseen that both will be replaced once C++ modules become more; mainstream, as that will allow simplification and improved robustness. rootcling; """""""""""""""""". The first interface is called ``rootcling``::. $ rootcling; Usage: rootcling [-v][-v0-4] [-f] [out.cxx] [opts] file1.h[+][-][!] file2.h[+][-][!] ...[Linkdef.h]; For more extensive help type: /usr/local/lib/python2.7/dist-packages/cppyy_backend/bin/rootcling -h. Rather than providing command line options, the main steering of; ``rootcling`` behavior is done through; `#pragmas in a Linkdef.h <https://root.cern.ch/root/html/guides/users-guide/AddingaClass.html#the-linkdef.h-file>`_; file, with most pragmas dedicated to selecting/excluding (parts of) classes; and functions.; Additionally, the Linkdef.h file may contain preprocessor macros. The output consists of a dictionary file (to be compiled into a shared; library), a C++ module, and an optional mapping file, as described above. genreflex; """""""""""""""""". The second interface is called ``genreflex``::. $ genreflex; Generates dictionary sources and related ROOT pcm starting from an header.; Usage: genreflex headerfile.h [opts] [preproc. opts]; ... ``genreflex`` has a richer command line interface than ``rootcling`` as can; be seen from the full help message. .. _selection-files:. Selection/exclusion is driven through a `selection file`_ using an XML format; that allows both exact and pattern matching to namespace, class, enum,; function, and variable names. .. _`selection file`: https://linux.die.net/man/1/genreflex. Example; """""""""""""". Consider the following basic example code, living in a header ""MyClass.h"":. .. code-block:: C++. class MyClass {; public:; MyClass(int i) : fInt(i) {}; int get_int() { return fInt; }. private:; int fInt;; };. and a corresponding ""Linkdef.h"" file, selecting only ``MyClass``::. #ifdef __ROOTCLING__; #pragma link off all classes;; #pragma link off all functions;; #pragma link off all globals;; #pragma link off all typedef;. #pragma ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst:4869,Integrability,interface,interface,4869,"age: rootcling [-v][-v0-4] [-f] [out.cxx] [opts] file1.h[+][-][!] file2.h[+][-][!] ...[Linkdef.h]; For more extensive help type: /usr/local/lib/python2.7/dist-packages/cppyy_backend/bin/rootcling -h. Rather than providing command line options, the main steering of; ``rootcling`` behavior is done through; `#pragmas in a Linkdef.h <https://root.cern.ch/root/html/guides/users-guide/AddingaClass.html#the-linkdef.h-file>`_; file, with most pragmas dedicated to selecting/excluding (parts of) classes; and functions.; Additionally, the Linkdef.h file may contain preprocessor macros. The output consists of a dictionary file (to be compiled into a shared; library), a C++ module, and an optional mapping file, as described above. genreflex; """""""""""""""""". The second interface is called ``genreflex``::. $ genreflex; Generates dictionary sources and related ROOT pcm starting from an header.; Usage: genreflex headerfile.h [opts] [preproc. opts]; ... ``genreflex`` has a richer command line interface than ``rootcling`` as can; be seen from the full help message. .. _selection-files:. Selection/exclusion is driven through a `selection file`_ using an XML format; that allows both exact and pattern matching to namespace, class, enum,; function, and variable names. .. _`selection file`: https://linux.die.net/man/1/genreflex. Example; """""""""""""". Consider the following basic example code, living in a header ""MyClass.h"":. .. code-block:: C++. class MyClass {; public:; MyClass(int i) : fInt(i) {}; int get_int() { return fInt; }. private:; int fInt;; };. and a corresponding ""Linkdef.h"" file, selecting only ``MyClass``::. #ifdef __ROOTCLING__; #pragma link off all classes;; #pragma link off all functions;; #pragma link off all globals;; #pragma link off all typedef;. #pragma link C++ class MyClass;. #endif. For more pragmas, see the `rootcling manual`_.; E.g., a commonly useful pragma is one that selects all C++ entities that are; declared in a specific header file::. #pragma link C++ defined_in ""My",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst:4933,Integrability,message,message,4933,"age: rootcling [-v][-v0-4] [-f] [out.cxx] [opts] file1.h[+][-][!] file2.h[+][-][!] ...[Linkdef.h]; For more extensive help type: /usr/local/lib/python2.7/dist-packages/cppyy_backend/bin/rootcling -h. Rather than providing command line options, the main steering of; ``rootcling`` behavior is done through; `#pragmas in a Linkdef.h <https://root.cern.ch/root/html/guides/users-guide/AddingaClass.html#the-linkdef.h-file>`_; file, with most pragmas dedicated to selecting/excluding (parts of) classes; and functions.; Additionally, the Linkdef.h file may contain preprocessor macros. The output consists of a dictionary file (to be compiled into a shared; library), a C++ module, and an optional mapping file, as described above. genreflex; """""""""""""""""". The second interface is called ``genreflex``::. $ genreflex; Generates dictionary sources and related ROOT pcm starting from an header.; Usage: genreflex headerfile.h [opts] [preproc. opts]; ... ``genreflex`` has a richer command line interface than ``rootcling`` as can; be seen from the full help message. .. _selection-files:. Selection/exclusion is driven through a `selection file`_ using an XML format; that allows both exact and pattern matching to namespace, class, enum,; function, and variable names. .. _`selection file`: https://linux.die.net/man/1/genreflex. Example; """""""""""""". Consider the following basic example code, living in a header ""MyClass.h"":. .. code-block:: C++. class MyClass {; public:; MyClass(int i) : fInt(i) {}; int get_int() { return fInt; }. private:; int fInt;; };. and a corresponding ""Linkdef.h"" file, selecting only ``MyClass``::. #ifdef __ROOTCLING__; #pragma link off all classes;; #pragma link off all functions;; #pragma link off all globals;; #pragma link off all typedef;. #pragma link C++ class MyClass;. #endif. For more pragmas, see the `rootcling manual`_.; E.g., a commonly useful pragma is one that selects all C++ entities that are; declared in a specific header file::. #pragma link C++ defined_in ""My",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst:10052,Integrability,interface,interface,10052,"oading dictionaries is fine if this is hidden under the hood of; a Python package and thus transparently done on ``import``.; Otherwise, the automatic class loader is more convenient, as it allows direct; use without having to manually find and load dictionaries (assuming these are; locatable by the dynamic loader). The class loader utilizes so-called rootmap files, which by convention should; live alongside the dictionary shared library (and C++ module file).; These are simple text files, which map C++ entities (such as classes) to the; dictionaries and other libraries that need to be loaded for their use. With ``genreflex``, the mapping file can be automatically created with; ``--rootmap-lib=MyClassDict``, where ""MyClassDict"" is the name of the shared; library (without the extension) build from the dictionary file.; With ``rootcling``, create the same mapping file with; ``-rmf MyClassDict.rootmap -rml MyClassDict``.; It is necessary to provide the final library name explicitly, since it is; only in the separate linking step where these names are fixed and those names; may not match the default choice. With the mapping file in place, the above example can be rerun without; explicit loading of the dictionary:. .. code-block:: python. >>> import cppyy; >>> from cppyy.gbl import MyClass; >>> MyClass(42).get_int(); 42; >>>. .. _cppyy-generator:. Bindings collection; -------------------. ``cppyy-generator`` is a clang-based utility program which takes a set of C++; header files and generates a JSON output file describing the objects found in; them.; This output is intended to support more convenient access to a set of; cppyy-supported bindings::. $ cppyy-generator --help; usage: cppyy-generator [-h] [-v] [--flags FLAGS] [--libclang LIBCLANG]; output sources [sources ...]; ... This utility is mainly used as part of the; :doc:`CMake interface <cmake_interface>`. .. _`support for exporting all`: https://cmake.org/cmake/help/latest/prop_tgt/WINDOWS_EXPORT_ALL_SYMBOLS.html; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst:157,Modifiability,config,config,157,".. _utilities:. Utilities; =========. The ``cppyy-backend`` package brings in the following utilities to help; with repackaging and redistribution:. * cling-config: for compile time flags; * rootcling and genreflex: for dictionary generation; * cppyy-generator: part of the :doc:`CMake interface <cmake_interface>`. Compiler/linker flags; ---------------------. ``cling-config`` is a small utility to provide access to the as-installed; configuration, such as compiler/linker flags and installation directories, of; other components.; Usage examples::. $ cling-config --help; Usage: cling-config [--cflags] [--cppflags] [--cmake]; $ cling-config --cmake; /usr/local/lib/python2.7/dist-packages/cppyy_backend/cmake. .. _dictionaries:. Dictionaries; ------------. Loading header files or code directly into ``cling`` is fine for interactive; work and smaller packages, but large scale applications benefit from; pre-compiling code, using the automatic class loader, and packaging; dependencies in so-called ""dictionaries."". A `dictionary` is a generated C++ source file containing references to the; header locations used when building (and any additional locations provided),; a set of forward declarations to reduce the need of loading header files, and; a few I/O helper functions.; The name ""dictionary"" is historic: before ``cling`` was used, it contained; the complete generated C++ reflection information, whereas now that is; derived at run-time from the header files.; It is still possible to fully embed header files rather than only storing; their names and search locations, to make the dictionary more self-contained. After generating the dictionary, it should be compiled into a shared library.; This provides additional dependency control: by linking it directly with any; further libraries needed, you can use standard mechanisms such as ``rpath``; to locate those library dependencies.; Alternatively, you can add the additional libraries to load to the mapping; files of the class load",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst:370,Modifiability,config,config,370,".. _utilities:. Utilities; =========. The ``cppyy-backend`` package brings in the following utilities to help; with repackaging and redistribution:. * cling-config: for compile time flags; * rootcling and genreflex: for dictionary generation; * cppyy-generator: part of the :doc:`CMake interface <cmake_interface>`. Compiler/linker flags; ---------------------. ``cling-config`` is a small utility to provide access to the as-installed; configuration, such as compiler/linker flags and installation directories, of; other components.; Usage examples::. $ cling-config --help; Usage: cling-config [--cflags] [--cppflags] [--cmake]; $ cling-config --cmake; /usr/local/lib/python2.7/dist-packages/cppyy_backend/cmake. .. _dictionaries:. Dictionaries; ------------. Loading header files or code directly into ``cling`` is fine for interactive; work and smaller packages, but large scale applications benefit from; pre-compiling code, using the automatic class loader, and packaging; dependencies in so-called ""dictionaries."". A `dictionary` is a generated C++ source file containing references to the; header locations used when building (and any additional locations provided),; a set of forward declarations to reduce the need of loading header files, and; a few I/O helper functions.; The name ""dictionary"" is historic: before ``cling`` was used, it contained; the complete generated C++ reflection information, whereas now that is; derived at run-time from the header files.; It is still possible to fully embed header files rather than only storing; their names and search locations, to make the dictionary more self-contained. After generating the dictionary, it should be compiled into a shared library.; This provides additional dependency control: by linking it directly with any; further libraries needed, you can use standard mechanisms such as ``rpath``; to locate those library dependencies.; Alternatively, you can add the additional libraries to load to the mapping; files of the class load",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst:437,Modifiability,config,configuration,437,".. _utilities:. Utilities; =========. The ``cppyy-backend`` package brings in the following utilities to help; with repackaging and redistribution:. * cling-config: for compile time flags; * rootcling and genreflex: for dictionary generation; * cppyy-generator: part of the :doc:`CMake interface <cmake_interface>`. Compiler/linker flags; ---------------------. ``cling-config`` is a small utility to provide access to the as-installed; configuration, such as compiler/linker flags and installation directories, of; other components.; Usage examples::. $ cling-config --help; Usage: cling-config [--cflags] [--cppflags] [--cmake]; $ cling-config --cmake; /usr/local/lib/python2.7/dist-packages/cppyy_backend/cmake. .. _dictionaries:. Dictionaries; ------------. Loading header files or code directly into ``cling`` is fine for interactive; work and smaller packages, but large scale applications benefit from; pre-compiling code, using the automatic class loader, and packaging; dependencies in so-called ""dictionaries."". A `dictionary` is a generated C++ source file containing references to the; header locations used when building (and any additional locations provided),; a set of forward declarations to reduce the need of loading header files, and; a few I/O helper functions.; The name ""dictionary"" is historic: before ``cling`` was used, it contained; the complete generated C++ reflection information, whereas now that is; derived at run-time from the header files.; It is still possible to fully embed header files rather than only storing; their names and search locations, to make the dictionary more self-contained. After generating the dictionary, it should be compiled into a shared library.; This provides additional dependency control: by linking it directly with any; further libraries needed, you can use standard mechanisms such as ``rpath``; to locate those library dependencies.; Alternatively, you can add the additional libraries to load to the mapping; files of the class load",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst:561,Modifiability,config,config,561,".. _utilities:. Utilities; =========. The ``cppyy-backend`` package brings in the following utilities to help; with repackaging and redistribution:. * cling-config: for compile time flags; * rootcling and genreflex: for dictionary generation; * cppyy-generator: part of the :doc:`CMake interface <cmake_interface>`. Compiler/linker flags; ---------------------. ``cling-config`` is a small utility to provide access to the as-installed; configuration, such as compiler/linker flags and installation directories, of; other components.; Usage examples::. $ cling-config --help; Usage: cling-config [--cflags] [--cppflags] [--cmake]; $ cling-config --cmake; /usr/local/lib/python2.7/dist-packages/cppyy_backend/cmake. .. _dictionaries:. Dictionaries; ------------. Loading header files or code directly into ``cling`` is fine for interactive; work and smaller packages, but large scale applications benefit from; pre-compiling code, using the automatic class loader, and packaging; dependencies in so-called ""dictionaries."". A `dictionary` is a generated C++ source file containing references to the; header locations used when building (and any additional locations provided),; a set of forward declarations to reduce the need of loading header files, and; a few I/O helper functions.; The name ""dictionary"" is historic: before ``cling`` was used, it contained; the complete generated C++ reflection information, whereas now that is; derived at run-time from the header files.; It is still possible to fully embed header files rather than only storing; their names and search locations, to make the dictionary more self-contained. After generating the dictionary, it should be compiled into a shared library.; This provides additional dependency control: by linking it directly with any; further libraries needed, you can use standard mechanisms such as ``rpath``; to locate those library dependencies.; Alternatively, you can add the additional libraries to load to the mapping; files of the class load",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst:589,Modifiability,config,config,589,".. _utilities:. Utilities; =========. The ``cppyy-backend`` package brings in the following utilities to help; with repackaging and redistribution:. * cling-config: for compile time flags; * rootcling and genreflex: for dictionary generation; * cppyy-generator: part of the :doc:`CMake interface <cmake_interface>`. Compiler/linker flags; ---------------------. ``cling-config`` is a small utility to provide access to the as-installed; configuration, such as compiler/linker flags and installation directories, of; other components.; Usage examples::. $ cling-config --help; Usage: cling-config [--cflags] [--cppflags] [--cmake]; $ cling-config --cmake; /usr/local/lib/python2.7/dist-packages/cppyy_backend/cmake. .. _dictionaries:. Dictionaries; ------------. Loading header files or code directly into ``cling`` is fine for interactive; work and smaller packages, but large scale applications benefit from; pre-compiling code, using the automatic class loader, and packaging; dependencies in so-called ""dictionaries."". A `dictionary` is a generated C++ source file containing references to the; header locations used when building (and any additional locations provided),; a set of forward declarations to reduce the need of loading header files, and; a few I/O helper functions.; The name ""dictionary"" is historic: before ``cling`` was used, it contained; the complete generated C++ reflection information, whereas now that is; derived at run-time from the header files.; It is still possible to fully embed header files rather than only storing; their names and search locations, to make the dictionary more self-contained. After generating the dictionary, it should be compiled into a shared library.; This provides additional dependency control: by linking it directly with any; further libraries needed, you can use standard mechanisms such as ``rpath``; to locate those library dependencies.; Alternatively, you can add the additional libraries to load to the mapping; files of the class load",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst:639,Modifiability,config,config,639,".. _utilities:. Utilities; =========. The ``cppyy-backend`` package brings in the following utilities to help; with repackaging and redistribution:. * cling-config: for compile time flags; * rootcling and genreflex: for dictionary generation; * cppyy-generator: part of the :doc:`CMake interface <cmake_interface>`. Compiler/linker flags; ---------------------. ``cling-config`` is a small utility to provide access to the as-installed; configuration, such as compiler/linker flags and installation directories, of; other components.; Usage examples::. $ cling-config --help; Usage: cling-config [--cflags] [--cppflags] [--cmake]; $ cling-config --cmake; /usr/local/lib/python2.7/dist-packages/cppyy_backend/cmake. .. _dictionaries:. Dictionaries; ------------. Loading header files or code directly into ``cling`` is fine for interactive; work and smaller packages, but large scale applications benefit from; pre-compiling code, using the automatic class loader, and packaging; dependencies in so-called ""dictionaries."". A `dictionary` is a generated C++ source file containing references to the; header locations used when building (and any additional locations provided),; a set of forward declarations to reduce the need of loading header files, and; a few I/O helper functions.; The name ""dictionary"" is historic: before ``cling`` was used, it contained; the complete generated C++ reflection information, whereas now that is; derived at run-time from the header files.; It is still possible to fully embed header files rather than only storing; their names and search locations, to make the dictionary more self-contained. After generating the dictionary, it should be compiled into a shared library.; This provides additional dependency control: by linking it directly with any; further libraries needed, you can use standard mechanisms such as ``rpath``; to locate those library dependencies.; Alternatively, you can add the additional libraries to load to the mapping; files of the class load",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst:5129,Modifiability,variab,variable,5129,"ppyy_backend/bin/rootcling -h. Rather than providing command line options, the main steering of; ``rootcling`` behavior is done through; `#pragmas in a Linkdef.h <https://root.cern.ch/root/html/guides/users-guide/AddingaClass.html#the-linkdef.h-file>`_; file, with most pragmas dedicated to selecting/excluding (parts of) classes; and functions.; Additionally, the Linkdef.h file may contain preprocessor macros. The output consists of a dictionary file (to be compiled into a shared; library), a C++ module, and an optional mapping file, as described above. genreflex; """""""""""""""""". The second interface is called ``genreflex``::. $ genreflex; Generates dictionary sources and related ROOT pcm starting from an header.; Usage: genreflex headerfile.h [opts] [preproc. opts]; ... ``genreflex`` has a richer command line interface than ``rootcling`` as can; be seen from the full help message. .. _selection-files:. Selection/exclusion is driven through a `selection file`_ using an XML format; that allows both exact and pattern matching to namespace, class, enum,; function, and variable names. .. _`selection file`: https://linux.die.net/man/1/genreflex. Example; """""""""""""". Consider the following basic example code, living in a header ""MyClass.h"":. .. code-block:: C++. class MyClass {; public:; MyClass(int i) : fInt(i) {}; int get_int() { return fInt; }. private:; int fInt;; };. and a corresponding ""Linkdef.h"" file, selecting only ``MyClass``::. #ifdef __ROOTCLING__; #pragma link off all classes;; #pragma link off all functions;; #pragma link off all globals;; #pragma link off all typedef;. #pragma link C++ class MyClass;. #endif. For more pragmas, see the `rootcling manual`_.; E.g., a commonly useful pragma is one that selects all C++ entities that are; declared in a specific header file::. #pragma link C++ defined_in ""MyClass.h"";. Next, use ``rootcling`` to generate the dictionary (here:; ``MyClass_rflx.cxx``) and module files::. $ rootcling -f MyClass_rflx.cxx MyClass.h Linkdef.h. Alte",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst:6411,Modifiability,variab,variable,6411,"a corresponding ""Linkdef.h"" file, selecting only ``MyClass``::. #ifdef __ROOTCLING__; #pragma link off all classes;; #pragma link off all functions;; #pragma link off all globals;; #pragma link off all typedef;. #pragma link C++ class MyClass;. #endif. For more pragmas, see the `rootcling manual`_.; E.g., a commonly useful pragma is one that selects all C++ entities that are; declared in a specific header file::. #pragma link C++ defined_in ""MyClass.h"";. Next, use ``rootcling`` to generate the dictionary (here:; ``MyClass_rflx.cxx``) and module files::. $ rootcling -f MyClass_rflx.cxx MyClass.h Linkdef.h. Alternatively, define a ""myclass_selection.xml"" file::. <lcgdict>; <class name=""MyClass"" />; </lcgdict>. serving the same purpose as the Linkdef.h file above (in fact, ``rootcling``; accepts a ""selection.xml"" file in lieu of a ""Linkdef.h"").; For more tags, see the `selection file`_ documentation.; Commonly used are ``namespace``, ``function``, ``enum``, or ``variable``; instead of the ``class`` tag, and ``pattern`` instead of ``name`` with; wildcarding in the value string. Next, use ``genreflex`` to generate the dictionary (here:; ``MyClass_rflx.cxx``) and module files::. $ genreflex MyClass.h --selection=myclass_selection.xml -o MyClass_rflx.cxx. From here, compile and link the generated dictionary file with the project; and/or system specific options and libraries into a shared library, using; ``cling-config`` for the relevant cppyy compiler/linker flags.; (For work on MS Windows, this `helper script`_ may be useful.); To continue the example, assuming Linux::. $ g++ `cling-config --cppflags` -fPIC -O2 -shared MyClass_rflx.cxx -o MyClassDict.so. Instead of loading the header text into ``cling``, you can now load the; dictionary:. .. code-block:: python. >>> import cppyy; >>> cppyy.load_reflection_info('MyClassDict'); >>> cppyy.gbl.MyClass(42); <cppyy.gbl.MyClass object at 0x7ffb9f230950>; >>> print(_.get_int()); 42; >>>. and use the selected C++ entities as if th",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst:6865,Modifiability,config,config,6865,"re; declared in a specific header file::. #pragma link C++ defined_in ""MyClass.h"";. Next, use ``rootcling`` to generate the dictionary (here:; ``MyClass_rflx.cxx``) and module files::. $ rootcling -f MyClass_rflx.cxx MyClass.h Linkdef.h. Alternatively, define a ""myclass_selection.xml"" file::. <lcgdict>; <class name=""MyClass"" />; </lcgdict>. serving the same purpose as the Linkdef.h file above (in fact, ``rootcling``; accepts a ""selection.xml"" file in lieu of a ""Linkdef.h"").; For more tags, see the `selection file`_ documentation.; Commonly used are ``namespace``, ``function``, ``enum``, or ``variable``; instead of the ``class`` tag, and ``pattern`` instead of ``name`` with; wildcarding in the value string. Next, use ``genreflex`` to generate the dictionary (here:; ``MyClass_rflx.cxx``) and module files::. $ genreflex MyClass.h --selection=myclass_selection.xml -o MyClass_rflx.cxx. From here, compile and link the generated dictionary file with the project; and/or system specific options and libraries into a shared library, using; ``cling-config`` for the relevant cppyy compiler/linker flags.; (For work on MS Windows, this `helper script`_ may be useful.); To continue the example, assuming Linux::. $ g++ `cling-config --cppflags` -fPIC -O2 -shared MyClass_rflx.cxx -o MyClassDict.so. Instead of loading the header text into ``cling``, you can now load the; dictionary:. .. code-block:: python. >>> import cppyy; >>> cppyy.load_reflection_info('MyClassDict'); >>> cppyy.gbl.MyClass(42); <cppyy.gbl.MyClass object at 0x7ffb9f230950>; >>> print(_.get_int()); 42; >>>. and use the selected C++ entities as if the header was loaded. The dictionary shared library can be relocated, as long as it can be found; by the dynamic loader (e.g. through ``LD_LIBRARY_PATH``) and the header file; is fully embedded or still accessible (e.g. through a path added to; ``cppyy.add_include_path`` at run-time, or with ``-I`` to; ``rootcling``/``genreflex`` during build time).; When relocating the sha",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst:7041,Modifiability,config,config,7041,"vely, define a ""myclass_selection.xml"" file::. <lcgdict>; <class name=""MyClass"" />; </lcgdict>. serving the same purpose as the Linkdef.h file above (in fact, ``rootcling``; accepts a ""selection.xml"" file in lieu of a ""Linkdef.h"").; For more tags, see the `selection file`_ documentation.; Commonly used are ``namespace``, ``function``, ``enum``, or ``variable``; instead of the ``class`` tag, and ``pattern`` instead of ``name`` with; wildcarding in the value string. Next, use ``genreflex`` to generate the dictionary (here:; ``MyClass_rflx.cxx``) and module files::. $ genreflex MyClass.h --selection=myclass_selection.xml -o MyClass_rflx.cxx. From here, compile and link the generated dictionary file with the project; and/or system specific options and libraries into a shared library, using; ``cling-config`` for the relevant cppyy compiler/linker flags.; (For work on MS Windows, this `helper script`_ may be useful.); To continue the example, assuming Linux::. $ g++ `cling-config --cppflags` -fPIC -O2 -shared MyClass_rflx.cxx -o MyClassDict.so. Instead of loading the header text into ``cling``, you can now load the; dictionary:. .. code-block:: python. >>> import cppyy; >>> cppyy.load_reflection_info('MyClassDict'); >>> cppyy.gbl.MyClass(42); <cppyy.gbl.MyClass object at 0x7ffb9f230950>; >>> print(_.get_int()); 42; >>>. and use the selected C++ entities as if the header was loaded. The dictionary shared library can be relocated, as long as it can be found; by the dynamic loader (e.g. through ``LD_LIBRARY_PATH``) and the header file; is fully embedded or still accessible (e.g. through a path added to; ``cppyy.add_include_path`` at run-time, or with ``-I`` to; ``rootcling``/``genreflex`` during build time).; When relocating the shared library, move the .pcm with it.; Once support for C++ modules is fully fleshed out, access to the header file; will no longer be needed. .. _`rootcling manual`: https://root.cern.ch/root/html/guides/users-guide/AddingaClass.html#the-linkdef.h-",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst:956,Performance,load,loader,956,".. _utilities:. Utilities; =========. The ``cppyy-backend`` package brings in the following utilities to help; with repackaging and redistribution:. * cling-config: for compile time flags; * rootcling and genreflex: for dictionary generation; * cppyy-generator: part of the :doc:`CMake interface <cmake_interface>`. Compiler/linker flags; ---------------------. ``cling-config`` is a small utility to provide access to the as-installed; configuration, such as compiler/linker flags and installation directories, of; other components.; Usage examples::. $ cling-config --help; Usage: cling-config [--cflags] [--cppflags] [--cmake]; $ cling-config --cmake; /usr/local/lib/python2.7/dist-packages/cppyy_backend/cmake. .. _dictionaries:. Dictionaries; ------------. Loading header files or code directly into ``cling`` is fine for interactive; work and smaller packages, but large scale applications benefit from; pre-compiling code, using the automatic class loader, and packaging; dependencies in so-called ""dictionaries."". A `dictionary` is a generated C++ source file containing references to the; header locations used when building (and any additional locations provided),; a set of forward declarations to reduce the need of loading header files, and; a few I/O helper functions.; The name ""dictionary"" is historic: before ``cling`` was used, it contained; the complete generated C++ reflection information, whereas now that is; derived at run-time from the header files.; It is still possible to fully embed header files rather than only storing; their names and search locations, to make the dictionary more self-contained. After generating the dictionary, it should be compiled into a shared library.; This provides additional dependency control: by linking it directly with any; further libraries needed, you can use standard mechanisms such as ``rpath``; to locate those library dependencies.; Alternatively, you can add the additional libraries to load to the mapping; files of the class load",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst:1228,Performance,load,loading,1228,"cling-config: for compile time flags; * rootcling and genreflex: for dictionary generation; * cppyy-generator: part of the :doc:`CMake interface <cmake_interface>`. Compiler/linker flags; ---------------------. ``cling-config`` is a small utility to provide access to the as-installed; configuration, such as compiler/linker flags and installation directories, of; other components.; Usage examples::. $ cling-config --help; Usage: cling-config [--cflags] [--cppflags] [--cmake]; $ cling-config --cmake; /usr/local/lib/python2.7/dist-packages/cppyy_backend/cmake. .. _dictionaries:. Dictionaries; ------------. Loading header files or code directly into ``cling`` is fine for interactive; work and smaller packages, but large scale applications benefit from; pre-compiling code, using the automatic class loader, and packaging; dependencies in so-called ""dictionaries."". A `dictionary` is a generated C++ source file containing references to the; header locations used when building (and any additional locations provided),; a set of forward declarations to reduce the need of loading header files, and; a few I/O helper functions.; The name ""dictionary"" is historic: before ``cling`` was used, it contained; the complete generated C++ reflection information, whereas now that is; derived at run-time from the header files.; It is still possible to fully embed header files rather than only storing; their names and search locations, to make the dictionary more self-contained. After generating the dictionary, it should be compiled into a shared library.; This provides additional dependency control: by linking it directly with any; further libraries needed, you can use standard mechanisms such as ``rpath``; to locate those library dependencies.; Alternatively, you can add the additional libraries to load to the mapping; files of the class loader (see below). .. note::. The JIT needs to resolve linker symbols in order to call them through; generated wrappers.; Thus, any classes, functions, an",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst:1957,Performance,load,load,1957,"ader, and packaging; dependencies in so-called ""dictionaries."". A `dictionary` is a generated C++ source file containing references to the; header locations used when building (and any additional locations provided),; a set of forward declarations to reduce the need of loading header files, and; a few I/O helper functions.; The name ""dictionary"" is historic: before ``cling`` was used, it contained; the complete generated C++ reflection information, whereas now that is; derived at run-time from the header files.; It is still possible to fully embed header files rather than only storing; their names and search locations, to make the dictionary more self-contained. After generating the dictionary, it should be compiled into a shared library.; This provides additional dependency control: by linking it directly with any; further libraries needed, you can use standard mechanisms such as ``rpath``; to locate those library dependencies.; Alternatively, you can add the additional libraries to load to the mapping; files of the class loader (see below). .. note::. The JIT needs to resolve linker symbols in order to call them through; generated wrappers.; Thus, any classes, functions, and data that will be used in Python need; to be exported.; This is the default behavior on Mac and Linux, but not on Windows.; On that platform, use ``__declspec(dllexport)`` to explicitly export the; classes and function you expect to call.; CMake has simple `support for exporting all`_ C++ symbols. In tandem with any dictionary, a pre-compiled module (.pcm) file will be; generated.; C++ modules are still on track for inclusion in the C++20 standard and most; modern C++ compilers, ``clang`` among them, already have implementations.; The benefits for cppyy include faster bindings generation, lower memory; footprint, and isolation from preprocessor macros and compiler flags.; The use of modules is transparent, other than the requirement that they; need to be co-located with the compiled dictionary",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst:1997,Performance,load,loader,1997,"ader, and packaging; dependencies in so-called ""dictionaries."". A `dictionary` is a generated C++ source file containing references to the; header locations used when building (and any additional locations provided),; a set of forward declarations to reduce the need of loading header files, and; a few I/O helper functions.; The name ""dictionary"" is historic: before ``cling`` was used, it contained; the complete generated C++ reflection information, whereas now that is; derived at run-time from the header files.; It is still possible to fully embed header files rather than only storing; their names and search locations, to make the dictionary more self-contained. After generating the dictionary, it should be compiled into a shared library.; This provides additional dependency control: by linking it directly with any; further libraries needed, you can use standard mechanisms such as ``rpath``; to locate those library dependencies.; Alternatively, you can add the additional libraries to load to the mapping; files of the class loader (see below). .. note::. The JIT needs to resolve linker symbols in order to call them through; generated wrappers.; Thus, any classes, functions, and data that will be used in Python need; to be exported.; This is the default behavior on Mac and Linux, but not on Windows.; On that platform, use ``__declspec(dllexport)`` to explicitly export the; classes and function you expect to call.; CMake has simple `support for exporting all`_ C++ symbols. In tandem with any dictionary, a pre-compiled module (.pcm) file will be; generated.; C++ modules are still on track for inclusion in the C++20 standard and most; modern C++ compilers, ``clang`` among them, already have implementations.; The benefits for cppyy include faster bindings generation, lower memory; footprint, and isolation from preprocessor macros and compiler flags.; The use of modules is transparent, other than the requirement that they; need to be co-located with the compiled dictionary",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst:3088,Performance,load,load,3088,"er to call them through; generated wrappers.; Thus, any classes, functions, and data that will be used in Python need; to be exported.; This is the default behavior on Mac and Linux, but not on Windows.; On that platform, use ``__declspec(dllexport)`` to explicitly export the; classes and function you expect to call.; CMake has simple `support for exporting all`_ C++ symbols. In tandem with any dictionary, a pre-compiled module (.pcm) file will be; generated.; C++ modules are still on track for inclusion in the C++20 standard and most; modern C++ compilers, ``clang`` among them, already have implementations.; The benefits for cppyy include faster bindings generation, lower memory; footprint, and isolation from preprocessor macros and compiler flags.; The use of modules is transparent, other than the requirement that they; need to be co-located with the compiled dictionary shared library. Optionally, the dictionary generation process also produces a mapping file,; which lists the libraries needed to load C++ classes on request (for details,; see the section on the class loader below). Structurally, you could have a single dictionary for a project as a whole,; but more likely a large project will have a pre-existing functional; decomposition that can be followed, with a dictionary per functional unit. Generation; ^^^^^^^^^^. There are two interfaces onto the same underlying dictionary generator:; ``rootcling`` and ``genreflex``.; The reason for having two is historic and they are not complete duplicates,; so one or the other may suit your preference better.; It is foreseen that both will be replaced once C++ modules become more; mainstream, as that will allow simplification and improved robustness. rootcling; """""""""""""""""". The first interface is called ``rootcling``::. $ rootcling; Usage: rootcling [-v][-v0-4] [-f] [out.cxx] [opts] file1.h[+][-][!] file2.h[+][-][!] ...[Linkdef.h]; For more extensive help type: /usr/local/lib/python2.7/dist-packages/cppyy_backend/bin/root",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst:3160,Performance,load,loader,3160,"er to call them through; generated wrappers.; Thus, any classes, functions, and data that will be used in Python need; to be exported.; This is the default behavior on Mac and Linux, but not on Windows.; On that platform, use ``__declspec(dllexport)`` to explicitly export the; classes and function you expect to call.; CMake has simple `support for exporting all`_ C++ symbols. In tandem with any dictionary, a pre-compiled module (.pcm) file will be; generated.; C++ modules are still on track for inclusion in the C++20 standard and most; modern C++ compilers, ``clang`` among them, already have implementations.; The benefits for cppyy include faster bindings generation, lower memory; footprint, and isolation from preprocessor macros and compiler flags.; The use of modules is transparent, other than the requirement that they; need to be co-located with the compiled dictionary shared library. Optionally, the dictionary generation process also produces a mapping file,; which lists the libraries needed to load C++ classes on request (for details,; see the section on the class loader below). Structurally, you could have a single dictionary for a project as a whole,; but more likely a large project will have a pre-existing functional; decomposition that can be followed, with a dictionary per functional unit. Generation; ^^^^^^^^^^. There are two interfaces onto the same underlying dictionary generator:; ``rootcling`` and ``genreflex``.; The reason for having two is historic and they are not complete duplicates,; so one or the other may suit your preference better.; It is foreseen that both will be replaced once C++ modules become more; mainstream, as that will allow simplification and improved robustness. rootcling; """""""""""""""""". The first interface is called ``rootcling``::. $ rootcling; Usage: rootcling [-v][-v0-4] [-f] [out.cxx] [opts] file1.h[+][-][!] file2.h[+][-][!] ...[Linkdef.h]; For more extensive help type: /usr/local/lib/python2.7/dist-packages/cppyy_backend/bin/root",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst:7125,Performance,load,loading,7125,"erving the same purpose as the Linkdef.h file above (in fact, ``rootcling``; accepts a ""selection.xml"" file in lieu of a ""Linkdef.h"").; For more tags, see the `selection file`_ documentation.; Commonly used are ``namespace``, ``function``, ``enum``, or ``variable``; instead of the ``class`` tag, and ``pattern`` instead of ``name`` with; wildcarding in the value string. Next, use ``genreflex`` to generate the dictionary (here:; ``MyClass_rflx.cxx``) and module files::. $ genreflex MyClass.h --selection=myclass_selection.xml -o MyClass_rflx.cxx. From here, compile and link the generated dictionary file with the project; and/or system specific options and libraries into a shared library, using; ``cling-config`` for the relevant cppyy compiler/linker flags.; (For work on MS Windows, this `helper script`_ may be useful.); To continue the example, assuming Linux::. $ g++ `cling-config --cppflags` -fPIC -O2 -shared MyClass_rflx.cxx -o MyClassDict.so. Instead of loading the header text into ``cling``, you can now load the; dictionary:. .. code-block:: python. >>> import cppyy; >>> cppyy.load_reflection_info('MyClassDict'); >>> cppyy.gbl.MyClass(42); <cppyy.gbl.MyClass object at 0x7ffb9f230950>; >>> print(_.get_int()); 42; >>>. and use the selected C++ entities as if the header was loaded. The dictionary shared library can be relocated, as long as it can be found; by the dynamic loader (e.g. through ``LD_LIBRARY_PATH``) and the header file; is fully embedded or still accessible (e.g. through a path added to; ``cppyy.add_include_path`` at run-time, or with ``-I`` to; ``rootcling``/``genreflex`` during build time).; When relocating the shared library, move the .pcm with it.; Once support for C++ modules is fully fleshed out, access to the header file; will no longer be needed. .. _`rootcling manual`: https://root.cern.ch/root/html/guides/users-guide/AddingaClass.html#the-linkdef.h-file; .. _`helper script`: https://github.com/wlav/cppyy/blob/master/test/make_dict_win32.py. Cla",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst:7177,Performance,load,load,7177,"erving the same purpose as the Linkdef.h file above (in fact, ``rootcling``; accepts a ""selection.xml"" file in lieu of a ""Linkdef.h"").; For more tags, see the `selection file`_ documentation.; Commonly used are ``namespace``, ``function``, ``enum``, or ``variable``; instead of the ``class`` tag, and ``pattern`` instead of ``name`` with; wildcarding in the value string. Next, use ``genreflex`` to generate the dictionary (here:; ``MyClass_rflx.cxx``) and module files::. $ genreflex MyClass.h --selection=myclass_selection.xml -o MyClass_rflx.cxx. From here, compile and link the generated dictionary file with the project; and/or system specific options and libraries into a shared library, using; ``cling-config`` for the relevant cppyy compiler/linker flags.; (For work on MS Windows, this `helper script`_ may be useful.); To continue the example, assuming Linux::. $ g++ `cling-config --cppflags` -fPIC -O2 -shared MyClass_rflx.cxx -o MyClassDict.so. Instead of loading the header text into ``cling``, you can now load the; dictionary:. .. code-block:: python. >>> import cppyy; >>> cppyy.load_reflection_info('MyClassDict'); >>> cppyy.gbl.MyClass(42); <cppyy.gbl.MyClass object at 0x7ffb9f230950>; >>> print(_.get_int()); 42; >>>. and use the selected C++ entities as if the header was loaded. The dictionary shared library can be relocated, as long as it can be found; by the dynamic loader (e.g. through ``LD_LIBRARY_PATH``) and the header file; is fully embedded or still accessible (e.g. through a path added to; ``cppyy.add_include_path`` at run-time, or with ``-I`` to; ``rootcling``/``genreflex`` during build time).; When relocating the shared library, move the .pcm with it.; Once support for C++ modules is fully fleshed out, access to the header file; will no longer be needed. .. _`rootcling manual`: https://root.cern.ch/root/html/guides/users-guide/AddingaClass.html#the-linkdef.h-file; .. _`helper script`: https://github.com/wlav/cppyy/blob/master/test/make_dict_win32.py. Cla",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst:7450,Performance,load,loaded,7450,"stead of the ``class`` tag, and ``pattern`` instead of ``name`` with; wildcarding in the value string. Next, use ``genreflex`` to generate the dictionary (here:; ``MyClass_rflx.cxx``) and module files::. $ genreflex MyClass.h --selection=myclass_selection.xml -o MyClass_rflx.cxx. From here, compile and link the generated dictionary file with the project; and/or system specific options and libraries into a shared library, using; ``cling-config`` for the relevant cppyy compiler/linker flags.; (For work on MS Windows, this `helper script`_ may be useful.); To continue the example, assuming Linux::. $ g++ `cling-config --cppflags` -fPIC -O2 -shared MyClass_rflx.cxx -o MyClassDict.so. Instead of loading the header text into ``cling``, you can now load the; dictionary:. .. code-block:: python. >>> import cppyy; >>> cppyy.load_reflection_info('MyClassDict'); >>> cppyy.gbl.MyClass(42); <cppyy.gbl.MyClass object at 0x7ffb9f230950>; >>> print(_.get_int()); 42; >>>. and use the selected C++ entities as if the header was loaded. The dictionary shared library can be relocated, as long as it can be found; by the dynamic loader (e.g. through ``LD_LIBRARY_PATH``) and the header file; is fully embedded or still accessible (e.g. through a path added to; ``cppyy.add_include_path`` at run-time, or with ``-I`` to; ``rootcling``/``genreflex`` during build time).; When relocating the shared library, move the .pcm with it.; Once support for C++ modules is fully fleshed out, access to the header file; will no longer be needed. .. _`rootcling manual`: https://root.cern.ch/root/html/guides/users-guide/AddingaClass.html#the-linkdef.h-file; .. _`helper script`: https://github.com/wlav/cppyy/blob/master/test/make_dict_win32.py. Class loader; ^^^^^^^^^^^^. Explicitly loading dictionaries is fine if this is hidden under the hood of; a Python package and thus transparently done on ``import``.; Otherwise, the automatic class loader is more convenient, as it allows direct; use without having to manual",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst:7549,Performance,load,loader,7549,"n the value string. Next, use ``genreflex`` to generate the dictionary (here:; ``MyClass_rflx.cxx``) and module files::. $ genreflex MyClass.h --selection=myclass_selection.xml -o MyClass_rflx.cxx. From here, compile and link the generated dictionary file with the project; and/or system specific options and libraries into a shared library, using; ``cling-config`` for the relevant cppyy compiler/linker flags.; (For work on MS Windows, this `helper script`_ may be useful.); To continue the example, assuming Linux::. $ g++ `cling-config --cppflags` -fPIC -O2 -shared MyClass_rflx.cxx -o MyClassDict.so. Instead of loading the header text into ``cling``, you can now load the; dictionary:. .. code-block:: python. >>> import cppyy; >>> cppyy.load_reflection_info('MyClassDict'); >>> cppyy.gbl.MyClass(42); <cppyy.gbl.MyClass object at 0x7ffb9f230950>; >>> print(_.get_int()); 42; >>>. and use the selected C++ entities as if the header was loaded. The dictionary shared library can be relocated, as long as it can be found; by the dynamic loader (e.g. through ``LD_LIBRARY_PATH``) and the header file; is fully embedded or still accessible (e.g. through a path added to; ``cppyy.add_include_path`` at run-time, or with ``-I`` to; ``rootcling``/``genreflex`` during build time).; When relocating the shared library, move the .pcm with it.; Once support for C++ modules is fully fleshed out, access to the header file; will no longer be needed. .. _`rootcling manual`: https://root.cern.ch/root/html/guides/users-guide/AddingaClass.html#the-linkdef.h-file; .. _`helper script`: https://github.com/wlav/cppyy/blob/master/test/make_dict_win32.py. Class loader; ^^^^^^^^^^^^. Explicitly loading dictionaries is fine if this is hidden under the hood of; a Python package and thus transparently done on ``import``.; Otherwise, the automatic class loader is more convenient, as it allows direct; use without having to manually find and load dictionaries (assuming these are; locatable by the dynamic loader",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst:8159,Performance,load,loader,8159,"ou can now load the; dictionary:. .. code-block:: python. >>> import cppyy; >>> cppyy.load_reflection_info('MyClassDict'); >>> cppyy.gbl.MyClass(42); <cppyy.gbl.MyClass object at 0x7ffb9f230950>; >>> print(_.get_int()); 42; >>>. and use the selected C++ entities as if the header was loaded. The dictionary shared library can be relocated, as long as it can be found; by the dynamic loader (e.g. through ``LD_LIBRARY_PATH``) and the header file; is fully embedded or still accessible (e.g. through a path added to; ``cppyy.add_include_path`` at run-time, or with ``-I`` to; ``rootcling``/``genreflex`` during build time).; When relocating the shared library, move the .pcm with it.; Once support for C++ modules is fully fleshed out, access to the header file; will no longer be needed. .. _`rootcling manual`: https://root.cern.ch/root/html/guides/users-guide/AddingaClass.html#the-linkdef.h-file; .. _`helper script`: https://github.com/wlav/cppyy/blob/master/test/make_dict_win32.py. Class loader; ^^^^^^^^^^^^. Explicitly loading dictionaries is fine if this is hidden under the hood of; a Python package and thus transparently done on ``import``.; Otherwise, the automatic class loader is more convenient, as it allows direct; use without having to manually find and load dictionaries (assuming these are; locatable by the dynamic loader). The class loader utilizes so-called rootmap files, which by convention should; live alongside the dictionary shared library (and C++ module file).; These are simple text files, which map C++ entities (such as classes) to the; dictionaries and other libraries that need to be loaded for their use. With ``genreflex``, the mapping file can be automatically created with; ``--rootmap-lib=MyClassDict``, where ""MyClassDict"" is the name of the shared; library (without the extension) build from the dictionary file.; With ``rootcling``, create the same mapping file with; ``-rmf MyClassDict.rootmap -rml MyClassDict``.; It is necessary to provide the final lib",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst:8192,Performance,load,loading,8192,"pyy.load_reflection_info('MyClassDict'); >>> cppyy.gbl.MyClass(42); <cppyy.gbl.MyClass object at 0x7ffb9f230950>; >>> print(_.get_int()); 42; >>>. and use the selected C++ entities as if the header was loaded. The dictionary shared library can be relocated, as long as it can be found; by the dynamic loader (e.g. through ``LD_LIBRARY_PATH``) and the header file; is fully embedded or still accessible (e.g. through a path added to; ``cppyy.add_include_path`` at run-time, or with ``-I`` to; ``rootcling``/``genreflex`` during build time).; When relocating the shared library, move the .pcm with it.; Once support for C++ modules is fully fleshed out, access to the header file; will no longer be needed. .. _`rootcling manual`: https://root.cern.ch/root/html/guides/users-guide/AddingaClass.html#the-linkdef.h-file; .. _`helper script`: https://github.com/wlav/cppyy/blob/master/test/make_dict_win32.py. Class loader; ^^^^^^^^^^^^. Explicitly loading dictionaries is fine if this is hidden under the hood of; a Python package and thus transparently done on ``import``.; Otherwise, the automatic class loader is more convenient, as it allows direct; use without having to manually find and load dictionaries (assuming these are; locatable by the dynamic loader). The class loader utilizes so-called rootmap files, which by convention should; live alongside the dictionary shared library (and C++ module file).; These are simple text files, which map C++ entities (such as classes) to the; dictionaries and other libraries that need to be loaded for their use. With ``genreflex``, the mapping file can be automatically created with; ``--rootmap-lib=MyClassDict``, where ""MyClassDict"" is the name of the shared; library (without the extension) build from the dictionary file.; With ``rootcling``, create the same mapping file with; ``-rmf MyClassDict.rootmap -rml MyClassDict``.; It is necessary to provide the final library name explicitly, since it is; only in the separate linking step where these na",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst:8350,Performance,load,loader,8350,"ed C++ entities as if the header was loaded. The dictionary shared library can be relocated, as long as it can be found; by the dynamic loader (e.g. through ``LD_LIBRARY_PATH``) and the header file; is fully embedded or still accessible (e.g. through a path added to; ``cppyy.add_include_path`` at run-time, or with ``-I`` to; ``rootcling``/``genreflex`` during build time).; When relocating the shared library, move the .pcm with it.; Once support for C++ modules is fully fleshed out, access to the header file; will no longer be needed. .. _`rootcling manual`: https://root.cern.ch/root/html/guides/users-guide/AddingaClass.html#the-linkdef.h-file; .. _`helper script`: https://github.com/wlav/cppyy/blob/master/test/make_dict_win32.py. Class loader; ^^^^^^^^^^^^. Explicitly loading dictionaries is fine if this is hidden under the hood of; a Python package and thus transparently done on ``import``.; Otherwise, the automatic class loader is more convenient, as it allows direct; use without having to manually find and load dictionaries (assuming these are; locatable by the dynamic loader). The class loader utilizes so-called rootmap files, which by convention should; live alongside the dictionary shared library (and C++ module file).; These are simple text files, which map C++ entities (such as classes) to the; dictionaries and other libraries that need to be loaded for their use. With ``genreflex``, the mapping file can be automatically created with; ``--rootmap-lib=MyClassDict``, where ""MyClassDict"" is the name of the shared; library (without the extension) build from the dictionary file.; With ``rootcling``, create the same mapping file with; ``-rmf MyClassDict.rootmap -rml MyClassDict``.; It is necessary to provide the final library name explicitly, since it is; only in the separate linking step where these names are fixed and those names; may not match the default choice. With the mapping file in place, the above example can be rerun without; explicit loading of the dict",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst:8438,Performance,load,load,8438,"ed C++ entities as if the header was loaded. The dictionary shared library can be relocated, as long as it can be found; by the dynamic loader (e.g. through ``LD_LIBRARY_PATH``) and the header file; is fully embedded or still accessible (e.g. through a path added to; ``cppyy.add_include_path`` at run-time, or with ``-I`` to; ``rootcling``/``genreflex`` during build time).; When relocating the shared library, move the .pcm with it.; Once support for C++ modules is fully fleshed out, access to the header file; will no longer be needed. .. _`rootcling manual`: https://root.cern.ch/root/html/guides/users-guide/AddingaClass.html#the-linkdef.h-file; .. _`helper script`: https://github.com/wlav/cppyy/blob/master/test/make_dict_win32.py. Class loader; ^^^^^^^^^^^^. Explicitly loading dictionaries is fine if this is hidden under the hood of; a Python package and thus transparently done on ``import``.; Otherwise, the automatic class loader is more convenient, as it allows direct; use without having to manually find and load dictionaries (assuming these are; locatable by the dynamic loader). The class loader utilizes so-called rootmap files, which by convention should; live alongside the dictionary shared library (and C++ module file).; These are simple text files, which map C++ entities (such as classes) to the; dictionaries and other libraries that need to be loaded for their use. With ``genreflex``, the mapping file can be automatically created with; ``--rootmap-lib=MyClassDict``, where ""MyClassDict"" is the name of the shared; library (without the extension) build from the dictionary file.; With ``rootcling``, create the same mapping file with; ``-rmf MyClassDict.rootmap -rml MyClassDict``.; It is necessary to provide the final library name explicitly, since it is; only in the separate linking step where these names are fixed and those names; may not match the default choice. With the mapping file in place, the above example can be rerun without; explicit loading of the dict",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst:8502,Performance,load,loader,8502,"ed C++ entities as if the header was loaded. The dictionary shared library can be relocated, as long as it can be found; by the dynamic loader (e.g. through ``LD_LIBRARY_PATH``) and the header file; is fully embedded or still accessible (e.g. through a path added to; ``cppyy.add_include_path`` at run-time, or with ``-I`` to; ``rootcling``/``genreflex`` during build time).; When relocating the shared library, move the .pcm with it.; Once support for C++ modules is fully fleshed out, access to the header file; will no longer be needed. .. _`rootcling manual`: https://root.cern.ch/root/html/guides/users-guide/AddingaClass.html#the-linkdef.h-file; .. _`helper script`: https://github.com/wlav/cppyy/blob/master/test/make_dict_win32.py. Class loader; ^^^^^^^^^^^^. Explicitly loading dictionaries is fine if this is hidden under the hood of; a Python package and thus transparently done on ``import``.; Otherwise, the automatic class loader is more convenient, as it allows direct; use without having to manually find and load dictionaries (assuming these are; locatable by the dynamic loader). The class loader utilizes so-called rootmap files, which by convention should; live alongside the dictionary shared library (and C++ module file).; These are simple text files, which map C++ entities (such as classes) to the; dictionaries and other libraries that need to be loaded for their use. With ``genreflex``, the mapping file can be automatically created with; ``--rootmap-lib=MyClassDict``, where ""MyClassDict"" is the name of the shared; library (without the extension) build from the dictionary file.; With ``rootcling``, create the same mapping file with; ``-rmf MyClassDict.rootmap -rml MyClassDict``.; It is necessary to provide the final library name explicitly, since it is; only in the separate linking step where these names are fixed and those names; may not match the default choice. With the mapping file in place, the above example can be rerun without; explicit loading of the dict",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst:8521,Performance,load,loader,8521,"PATH``) and the header file; is fully embedded or still accessible (e.g. through a path added to; ``cppyy.add_include_path`` at run-time, or with ``-I`` to; ``rootcling``/``genreflex`` during build time).; When relocating the shared library, move the .pcm with it.; Once support for C++ modules is fully fleshed out, access to the header file; will no longer be needed. .. _`rootcling manual`: https://root.cern.ch/root/html/guides/users-guide/AddingaClass.html#the-linkdef.h-file; .. _`helper script`: https://github.com/wlav/cppyy/blob/master/test/make_dict_win32.py. Class loader; ^^^^^^^^^^^^. Explicitly loading dictionaries is fine if this is hidden under the hood of; a Python package and thus transparently done on ``import``.; Otherwise, the automatic class loader is more convenient, as it allows direct; use without having to manually find and load dictionaries (assuming these are; locatable by the dynamic loader). The class loader utilizes so-called rootmap files, which by convention should; live alongside the dictionary shared library (and C++ module file).; These are simple text files, which map C++ entities (such as classes) to the; dictionaries and other libraries that need to be loaded for their use. With ``genreflex``, the mapping file can be automatically created with; ``--rootmap-lib=MyClassDict``, where ""MyClassDict"" is the name of the shared; library (without the extension) build from the dictionary file.; With ``rootcling``, create the same mapping file with; ``-rmf MyClassDict.rootmap -rml MyClassDict``.; It is necessary to provide the final library name explicitly, since it is; only in the separate linking step where these names are fixed and those names; may not match the default choice. With the mapping file in place, the above example can be rerun without; explicit loading of the dictionary:. .. code-block:: python. >>> import cppyy; >>> from cppyy.gbl import MyClass; >>> MyClass(42).get_int(); 42; >>>. .. _cppyy-generator:. Bindings collection; -----",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst:8786,Performance,load,loaded,8786,"I`` to; ``rootcling``/``genreflex`` during build time).; When relocating the shared library, move the .pcm with it.; Once support for C++ modules is fully fleshed out, access to the header file; will no longer be needed. .. _`rootcling manual`: https://root.cern.ch/root/html/guides/users-guide/AddingaClass.html#the-linkdef.h-file; .. _`helper script`: https://github.com/wlav/cppyy/blob/master/test/make_dict_win32.py. Class loader; ^^^^^^^^^^^^. Explicitly loading dictionaries is fine if this is hidden under the hood of; a Python package and thus transparently done on ``import``.; Otherwise, the automatic class loader is more convenient, as it allows direct; use without having to manually find and load dictionaries (assuming these are; locatable by the dynamic loader). The class loader utilizes so-called rootmap files, which by convention should; live alongside the dictionary shared library (and C++ module file).; These are simple text files, which map C++ entities (such as classes) to the; dictionaries and other libraries that need to be loaded for their use. With ``genreflex``, the mapping file can be automatically created with; ``--rootmap-lib=MyClassDict``, where ""MyClassDict"" is the name of the shared; library (without the extension) build from the dictionary file.; With ``rootcling``, create the same mapping file with; ``-rmf MyClassDict.rootmap -rml MyClassDict``.; It is necessary to provide the final library name explicitly, since it is; only in the separate linking step where these names are fixed and those names; may not match the default choice. With the mapping file in place, the above example can be rerun without; explicit loading of the dictionary:. .. code-block:: python. >>> import cppyy; >>> from cppyy.gbl import MyClass; >>> MyClass(42).get_int(); 42; >>>. .. _cppyy-generator:. Bindings collection; -------------------. ``cppyy-generator`` is a clang-based utility program which takes a set of C++; header files and generates a JSON output file describ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst:9395,Performance,load,loading,9395,"oading dictionaries is fine if this is hidden under the hood of; a Python package and thus transparently done on ``import``.; Otherwise, the automatic class loader is more convenient, as it allows direct; use without having to manually find and load dictionaries (assuming these are; locatable by the dynamic loader). The class loader utilizes so-called rootmap files, which by convention should; live alongside the dictionary shared library (and C++ module file).; These are simple text files, which map C++ entities (such as classes) to the; dictionaries and other libraries that need to be loaded for their use. With ``genreflex``, the mapping file can be automatically created with; ``--rootmap-lib=MyClassDict``, where ""MyClassDict"" is the name of the shared; library (without the extension) build from the dictionary file.; With ``rootcling``, create the same mapping file with; ``-rmf MyClassDict.rootmap -rml MyClassDict``.; It is necessary to provide the final library name explicitly, since it is; only in the separate linking step where these names are fixed and those names; may not match the default choice. With the mapping file in place, the above example can be rerun without; explicit loading of the dictionary:. .. code-block:: python. >>> import cppyy; >>> from cppyy.gbl import MyClass; >>> MyClass(42).get_int(); 42; >>>. .. _cppyy-generator:. Bindings collection; -------------------. ``cppyy-generator`` is a clang-based utility program which takes a set of C++; header files and generates a JSON output file describing the objects found in; them.; This output is intended to support more convenient access to a set of; cppyy-supported bindings::. $ cppyy-generator --help; usage: cppyy-generator [-h] [-v] [--flags FLAGS] [--libclang LIBCLANG]; output sources [sources ...]; ... This utility is mainly used as part of the; :doc:`CMake interface <cmake_interface>`. .. _`support for exporting all`: https://cmake.org/cmake/help/latest/prop_tgt/WINDOWS_EXPORT_ALL_SYMBOLS.html; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst:409,Security,access,access,409,".. _utilities:. Utilities; =========. The ``cppyy-backend`` package brings in the following utilities to help; with repackaging and redistribution:. * cling-config: for compile time flags; * rootcling and genreflex: for dictionary generation; * cppyy-generator: part of the :doc:`CMake interface <cmake_interface>`. Compiler/linker flags; ---------------------. ``cling-config`` is a small utility to provide access to the as-installed; configuration, such as compiler/linker flags and installation directories, of; other components.; Usage examples::. $ cling-config --help; Usage: cling-config [--cflags] [--cppflags] [--cmake]; $ cling-config --cmake; /usr/local/lib/python2.7/dist-packages/cppyy_backend/cmake. .. _dictionaries:. Dictionaries; ------------. Loading header files or code directly into ``cling`` is fine for interactive; work and smaller packages, but large scale applications benefit from; pre-compiling code, using the automatic class loader, and packaging; dependencies in so-called ""dictionaries."". A `dictionary` is a generated C++ source file containing references to the; header locations used when building (and any additional locations provided),; a set of forward declarations to reduce the need of loading header files, and; a few I/O helper functions.; The name ""dictionary"" is historic: before ``cling`` was used, it contained; the complete generated C++ reflection information, whereas now that is; derived at run-time from the header files.; It is still possible to fully embed header files rather than only storing; their names and search locations, to make the dictionary more self-contained. After generating the dictionary, it should be compiled into a shared library.; This provides additional dependency control: by linking it directly with any; further libraries needed, you can use standard mechanisms such as ``rpath``; to locate those library dependencies.; Alternatively, you can add the additional libraries to load to the mapping; files of the class load",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst:7639,Security,access,accessible,7639,") and module files::. $ genreflex MyClass.h --selection=myclass_selection.xml -o MyClass_rflx.cxx. From here, compile and link the generated dictionary file with the project; and/or system specific options and libraries into a shared library, using; ``cling-config`` for the relevant cppyy compiler/linker flags.; (For work on MS Windows, this `helper script`_ may be useful.); To continue the example, assuming Linux::. $ g++ `cling-config --cppflags` -fPIC -O2 -shared MyClass_rflx.cxx -o MyClassDict.so. Instead of loading the header text into ``cling``, you can now load the; dictionary:. .. code-block:: python. >>> import cppyy; >>> cppyy.load_reflection_info('MyClassDict'); >>> cppyy.gbl.MyClass(42); <cppyy.gbl.MyClass object at 0x7ffb9f230950>; >>> print(_.get_int()); 42; >>>. and use the selected C++ entities as if the header was loaded. The dictionary shared library can be relocated, as long as it can be found; by the dynamic loader (e.g. through ``LD_LIBRARY_PATH``) and the header file; is fully embedded or still accessible (e.g. through a path added to; ``cppyy.add_include_path`` at run-time, or with ``-I`` to; ``rootcling``/``genreflex`` during build time).; When relocating the shared library, move the .pcm with it.; Once support for C++ modules is fully fleshed out, access to the header file; will no longer be needed. .. _`rootcling manual`: https://root.cern.ch/root/html/guides/users-guide/AddingaClass.html#the-linkdef.h-file; .. _`helper script`: https://github.com/wlav/cppyy/blob/master/test/make_dict_win32.py. Class loader; ^^^^^^^^^^^^. Explicitly loading dictionaries is fine if this is hidden under the hood of; a Python package and thus transparently done on ``import``.; Otherwise, the automatic class loader is more convenient, as it allows direct; use without having to manually find and load dictionaries (assuming these are; locatable by the dynamic loader). The class loader utilizes so-called rootmap files, which by convention should; live alongside th",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst:7900,Security,access,access,7900,"mpiler/linker flags.; (For work on MS Windows, this `helper script`_ may be useful.); To continue the example, assuming Linux::. $ g++ `cling-config --cppflags` -fPIC -O2 -shared MyClass_rflx.cxx -o MyClassDict.so. Instead of loading the header text into ``cling``, you can now load the; dictionary:. .. code-block:: python. >>> import cppyy; >>> cppyy.load_reflection_info('MyClassDict'); >>> cppyy.gbl.MyClass(42); <cppyy.gbl.MyClass object at 0x7ffb9f230950>; >>> print(_.get_int()); 42; >>>. and use the selected C++ entities as if the header was loaded. The dictionary shared library can be relocated, as long as it can be found; by the dynamic loader (e.g. through ``LD_LIBRARY_PATH``) and the header file; is fully embedded or still accessible (e.g. through a path added to; ``cppyy.add_include_path`` at run-time, or with ``-I`` to; ``rootcling``/``genreflex`` during build time).; When relocating the shared library, move the .pcm with it.; Once support for C++ modules is fully fleshed out, access to the header file; will no longer be needed. .. _`rootcling manual`: https://root.cern.ch/root/html/guides/users-guide/AddingaClass.html#the-linkdef.h-file; .. _`helper script`: https://github.com/wlav/cppyy/blob/master/test/make_dict_win32.py. Class loader; ^^^^^^^^^^^^. Explicitly loading dictionaries is fine if this is hidden under the hood of; a Python package and thus transparently done on ``import``.; Otherwise, the automatic class loader is more convenient, as it allows direct; use without having to manually find and load dictionaries (assuming these are; locatable by the dynamic loader). The class loader utilizes so-called rootmap files, which by convention should; live alongside the dictionary shared library (and C++ module file).; These are simple text files, which map C++ entities (such as classes) to the; dictionaries and other libraries that need to be loaded for their use. With ``genreflex``, the mapping file can be automatically created with; ``--rootmap-lib=MyCl",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst:9816,Security,access,access,9816,"oading dictionaries is fine if this is hidden under the hood of; a Python package and thus transparently done on ``import``.; Otherwise, the automatic class loader is more convenient, as it allows direct; use without having to manually find and load dictionaries (assuming these are; locatable by the dynamic loader). The class loader utilizes so-called rootmap files, which by convention should; live alongside the dictionary shared library (and C++ module file).; These are simple text files, which map C++ entities (such as classes) to the; dictionaries and other libraries that need to be loaded for their use. With ``genreflex``, the mapping file can be automatically created with; ``--rootmap-lib=MyClassDict``, where ""MyClassDict"" is the name of the shared; library (without the extension) build from the dictionary file.; With ``rootcling``, create the same mapping file with; ``-rmf MyClassDict.rootmap -rml MyClassDict``.; It is necessary to provide the final library name explicitly, since it is; only in the separate linking step where these names are fixed and those names; may not match the default choice. With the mapping file in place, the above example can be rerun without; explicit loading of the dictionary:. .. code-block:: python. >>> import cppyy; >>> from cppyy.gbl import MyClass; >>> MyClass(42).get_int(); 42; >>>. .. _cppyy-generator:. Bindings collection; -------------------. ``cppyy-generator`` is a clang-based utility program which takes a set of C++; header files and generates a JSON output file describing the objects found in; them.; This output is intended to support more convenient access to a set of; cppyy-supported bindings::. $ cppyy-generator --help; usage: cppyy-generator [-h] [-v] [--flags FLAGS] [--libclang LIBCLANG]; output sources [sources ...]; ... This utility is mainly used as part of the; :doc:`CMake interface <cmake_interface>`. .. _`support for exporting all`: https://cmake.org/cmake/help/latest/prop_tgt/WINDOWS_EXPORT_ALL_SYMBOLS.html; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst:8128,Testability,test,test,8128,"loading the header text into ``cling``, you can now load the; dictionary:. .. code-block:: python. >>> import cppyy; >>> cppyy.load_reflection_info('MyClassDict'); >>> cppyy.gbl.MyClass(42); <cppyy.gbl.MyClass object at 0x7ffb9f230950>; >>> print(_.get_int()); 42; >>>. and use the selected C++ entities as if the header was loaded. The dictionary shared library can be relocated, as long as it can be found; by the dynamic loader (e.g. through ``LD_LIBRARY_PATH``) and the header file; is fully embedded or still accessible (e.g. through a path added to; ``cppyy.add_include_path`` at run-time, or with ``-I`` to; ``rootcling``/``genreflex`` during build time).; When relocating the shared library, move the .pcm with it.; Once support for C++ modules is fully fleshed out, access to the header file; will no longer be needed. .. _`rootcling manual`: https://root.cern.ch/root/html/guides/users-guide/AddingaClass.html#the-linkdef.h-file; .. _`helper script`: https://github.com/wlav/cppyy/blob/master/test/make_dict_win32.py. Class loader; ^^^^^^^^^^^^. Explicitly loading dictionaries is fine if this is hidden under the hood of; a Python package and thus transparently done on ``import``.; Otherwise, the automatic class loader is more convenient, as it allows direct; use without having to manually find and load dictionaries (assuming these are; locatable by the dynamic loader). The class loader utilizes so-called rootmap files, which by convention should; live alongside the dictionary shared library (and C++ module file).; These are simple text files, which map C++ entities (such as classes) to the; dictionaries and other libraries that need to be loaded for their use. With ``genreflex``, the mapping file can be automatically created with; ``--rootmap-lib=MyClassDict``, where ""MyClassDict"" is the name of the shared; library (without the extension) build from the dictionary file.; With ``rootcling``, create the same mapping file with; ``-rmf MyClassDict.rootmap -rml MyClassDict``.;",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst:2404,Usability,simpl,simple,2404," that is; derived at run-time from the header files.; It is still possible to fully embed header files rather than only storing; their names and search locations, to make the dictionary more self-contained. After generating the dictionary, it should be compiled into a shared library.; This provides additional dependency control: by linking it directly with any; further libraries needed, you can use standard mechanisms such as ``rpath``; to locate those library dependencies.; Alternatively, you can add the additional libraries to load to the mapping; files of the class loader (see below). .. note::. The JIT needs to resolve linker symbols in order to call them through; generated wrappers.; Thus, any classes, functions, and data that will be used in Python need; to be exported.; This is the default behavior on Mac and Linux, but not on Windows.; On that platform, use ``__declspec(dllexport)`` to explicitly export the; classes and function you expect to call.; CMake has simple `support for exporting all`_ C++ symbols. In tandem with any dictionary, a pre-compiled module (.pcm) file will be; generated.; C++ modules are still on track for inclusion in the C++20 standard and most; modern C++ compilers, ``clang`` among them, already have implementations.; The benefits for cppyy include faster bindings generation, lower memory; footprint, and isolation from preprocessor macros and compiler flags.; The use of modules is transparent, other than the requirement that they; need to be co-located with the compiled dictionary shared library. Optionally, the dictionary generation process also produces a mapping file,; which lists the libraries needed to load C++ classes on request (for details,; see the section on the class loader below). Structurally, you could have a single dictionary for a project as a whole,; but more likely a large project will have a pre-existing functional; decomposition that can be followed, with a dictionary per functional unit. Generation; ^^^^^^^^^^. The",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst:3760,Usability,simpl,simplification,3760,"r bindings generation, lower memory; footprint, and isolation from preprocessor macros and compiler flags.; The use of modules is transparent, other than the requirement that they; need to be co-located with the compiled dictionary shared library. Optionally, the dictionary generation process also produces a mapping file,; which lists the libraries needed to load C++ classes on request (for details,; see the section on the class loader below). Structurally, you could have a single dictionary for a project as a whole,; but more likely a large project will have a pre-existing functional; decomposition that can be followed, with a dictionary per functional unit. Generation; ^^^^^^^^^^. There are two interfaces onto the same underlying dictionary generator:; ``rootcling`` and ``genreflex``.; The reason for having two is historic and they are not complete duplicates,; so one or the other may suit your preference better.; It is foreseen that both will be replaced once C++ modules become more; mainstream, as that will allow simplification and improved robustness. rootcling; """""""""""""""""". The first interface is called ``rootcling``::. $ rootcling; Usage: rootcling [-v][-v0-4] [-f] [out.cxx] [opts] file1.h[+][-][!] file2.h[+][-][!] ...[Linkdef.h]; For more extensive help type: /usr/local/lib/python2.7/dist-packages/cppyy_backend/bin/rootcling -h. Rather than providing command line options, the main steering of; ``rootcling`` behavior is done through; `#pragmas in a Linkdef.h <https://root.cern.ch/root/html/guides/users-guide/AddingaClass.html#the-linkdef.h-file>`_; file, with most pragmas dedicated to selecting/excluding (parts of) classes; and functions.; Additionally, the Linkdef.h file may contain preprocessor macros. The output consists of a dictionary file (to be compiled into a shared; library), a C++ module, and an optional mapping file, as described above. genreflex; """""""""""""""""". The second interface is called ``genreflex``::. $ genreflex; Generates dictionary sources and",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst:4247,Usability,guid,guides,4247,"ore likely a large project will have a pre-existing functional; decomposition that can be followed, with a dictionary per functional unit. Generation; ^^^^^^^^^^. There are two interfaces onto the same underlying dictionary generator:; ``rootcling`` and ``genreflex``.; The reason for having two is historic and they are not complete duplicates,; so one or the other may suit your preference better.; It is foreseen that both will be replaced once C++ modules become more; mainstream, as that will allow simplification and improved robustness. rootcling; """""""""""""""""". The first interface is called ``rootcling``::. $ rootcling; Usage: rootcling [-v][-v0-4] [-f] [out.cxx] [opts] file1.h[+][-][!] file2.h[+][-][!] ...[Linkdef.h]; For more extensive help type: /usr/local/lib/python2.7/dist-packages/cppyy_backend/bin/rootcling -h. Rather than providing command line options, the main steering of; ``rootcling`` behavior is done through; `#pragmas in a Linkdef.h <https://root.cern.ch/root/html/guides/users-guide/AddingaClass.html#the-linkdef.h-file>`_; file, with most pragmas dedicated to selecting/excluding (parts of) classes; and functions.; Additionally, the Linkdef.h file may contain preprocessor macros. The output consists of a dictionary file (to be compiled into a shared; library), a C++ module, and an optional mapping file, as described above. genreflex; """""""""""""""""". The second interface is called ``genreflex``::. $ genreflex; Generates dictionary sources and related ROOT pcm starting from an header.; Usage: genreflex headerfile.h [opts] [preproc. opts]; ... ``genreflex`` has a richer command line interface than ``rootcling`` as can; be seen from the full help message. .. _selection-files:. Selection/exclusion is driven through a `selection file`_ using an XML format; that allows both exact and pattern matching to namespace, class, enum,; function, and variable names. .. _`selection file`: https://linux.die.net/man/1/genreflex. Example; """""""""""""". Consider the following basic exam",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst:4260,Usability,guid,guide,4260,"ore likely a large project will have a pre-existing functional; decomposition that can be followed, with a dictionary per functional unit. Generation; ^^^^^^^^^^. There are two interfaces onto the same underlying dictionary generator:; ``rootcling`` and ``genreflex``.; The reason for having two is historic and they are not complete duplicates,; so one or the other may suit your preference better.; It is foreseen that both will be replaced once C++ modules become more; mainstream, as that will allow simplification and improved robustness. rootcling; """""""""""""""""". The first interface is called ``rootcling``::. $ rootcling; Usage: rootcling [-v][-v0-4] [-f] [out.cxx] [opts] file1.h[+][-][!] file2.h[+][-][!] ...[Linkdef.h]; For more extensive help type: /usr/local/lib/python2.7/dist-packages/cppyy_backend/bin/rootcling -h. Rather than providing command line options, the main steering of; ``rootcling`` behavior is done through; `#pragmas in a Linkdef.h <https://root.cern.ch/root/html/guides/users-guide/AddingaClass.html#the-linkdef.h-file>`_; file, with most pragmas dedicated to selecting/excluding (parts of) classes; and functions.; Additionally, the Linkdef.h file may contain preprocessor macros. The output consists of a dictionary file (to be compiled into a shared; library), a C++ module, and an optional mapping file, as described above. genreflex; """""""""""""""""". The second interface is called ``genreflex``::. $ genreflex; Generates dictionary sources and related ROOT pcm starting from an header.; Usage: genreflex headerfile.h [opts] [preproc. opts]; ... ``genreflex`` has a richer command line interface than ``rootcling`` as can; be seen from the full help message. .. _selection-files:. Selection/exclusion is driven through a `selection file`_ using an XML format; that allows both exact and pattern matching to namespace, class, enum,; function, and variable names. .. _`selection file`: https://linux.die.net/man/1/genreflex. Example; """""""""""""". Consider the following basic exam",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst:8008,Usability,guid,guides,8008,"g Linux::. $ g++ `cling-config --cppflags` -fPIC -O2 -shared MyClass_rflx.cxx -o MyClassDict.so. Instead of loading the header text into ``cling``, you can now load the; dictionary:. .. code-block:: python. >>> import cppyy; >>> cppyy.load_reflection_info('MyClassDict'); >>> cppyy.gbl.MyClass(42); <cppyy.gbl.MyClass object at 0x7ffb9f230950>; >>> print(_.get_int()); 42; >>>. and use the selected C++ entities as if the header was loaded. The dictionary shared library can be relocated, as long as it can be found; by the dynamic loader (e.g. through ``LD_LIBRARY_PATH``) and the header file; is fully embedded or still accessible (e.g. through a path added to; ``cppyy.add_include_path`` at run-time, or with ``-I`` to; ``rootcling``/``genreflex`` during build time).; When relocating the shared library, move the .pcm with it.; Once support for C++ modules is fully fleshed out, access to the header file; will no longer be needed. .. _`rootcling manual`: https://root.cern.ch/root/html/guides/users-guide/AddingaClass.html#the-linkdef.h-file; .. _`helper script`: https://github.com/wlav/cppyy/blob/master/test/make_dict_win32.py. Class loader; ^^^^^^^^^^^^. Explicitly loading dictionaries is fine if this is hidden under the hood of; a Python package and thus transparently done on ``import``.; Otherwise, the automatic class loader is more convenient, as it allows direct; use without having to manually find and load dictionaries (assuming these are; locatable by the dynamic loader). The class loader utilizes so-called rootmap files, which by convention should; live alongside the dictionary shared library (and C++ module file).; These are simple text files, which map C++ entities (such as classes) to the; dictionaries and other libraries that need to be loaded for their use. With ``genreflex``, the mapping file can be automatically created with; ``--rootmap-lib=MyClassDict``, where ""MyClassDict"" is the name of the shared; library (without the extension) build from the dictionary fi",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst:8021,Usability,guid,guide,8021,"g Linux::. $ g++ `cling-config --cppflags` -fPIC -O2 -shared MyClass_rflx.cxx -o MyClassDict.so. Instead of loading the header text into ``cling``, you can now load the; dictionary:. .. code-block:: python. >>> import cppyy; >>> cppyy.load_reflection_info('MyClassDict'); >>> cppyy.gbl.MyClass(42); <cppyy.gbl.MyClass object at 0x7ffb9f230950>; >>> print(_.get_int()); 42; >>>. and use the selected C++ entities as if the header was loaded. The dictionary shared library can be relocated, as long as it can be found; by the dynamic loader (e.g. through ``LD_LIBRARY_PATH``) and the header file; is fully embedded or still accessible (e.g. through a path added to; ``cppyy.add_include_path`` at run-time, or with ``-I`` to; ``rootcling``/``genreflex`` during build time).; When relocating the shared library, move the .pcm with it.; Once support for C++ modules is fully fleshed out, access to the header file; will no longer be needed. .. _`rootcling manual`: https://root.cern.ch/root/html/guides/users-guide/AddingaClass.html#the-linkdef.h-file; .. _`helper script`: https://github.com/wlav/cppyy/blob/master/test/make_dict_win32.py. Class loader; ^^^^^^^^^^^^. Explicitly loading dictionaries is fine if this is hidden under the hood of; a Python package and thus transparently done on ``import``.; Otherwise, the automatic class loader is more convenient, as it allows direct; use without having to manually find and load dictionaries (assuming these are; locatable by the dynamic loader). The class loader utilizes so-called rootmap files, which by convention should; live alongside the dictionary shared library (and C++ module file).; These are simple text files, which map C++ entities (such as classes) to the; dictionaries and other libraries that need to be loaded for their use. With ``genreflex``, the mapping file can be automatically created with; ``--rootmap-lib=MyClassDict``, where ""MyClassDict"" is the name of the shared; library (without the extension) build from the dictionary fi",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst:8669,Usability,simpl,simple,8669,"I`` to; ``rootcling``/``genreflex`` during build time).; When relocating the shared library, move the .pcm with it.; Once support for C++ modules is fully fleshed out, access to the header file; will no longer be needed. .. _`rootcling manual`: https://root.cern.ch/root/html/guides/users-guide/AddingaClass.html#the-linkdef.h-file; .. _`helper script`: https://github.com/wlav/cppyy/blob/master/test/make_dict_win32.py. Class loader; ^^^^^^^^^^^^. Explicitly loading dictionaries is fine if this is hidden under the hood of; a Python package and thus transparently done on ``import``.; Otherwise, the automatic class loader is more convenient, as it allows direct; use without having to manually find and load dictionaries (assuming these are; locatable by the dynamic loader). The class loader utilizes so-called rootmap files, which by convention should; live alongside the dictionary shared library (and C++ module file).; These are simple text files, which map C++ entities (such as classes) to the; dictionaries and other libraries that need to be loaded for their use. With ``genreflex``, the mapping file can be automatically created with; ``--rootmap-lib=MyClassDict``, where ""MyClassDict"" is the name of the shared; library (without the extension) build from the dictionary file.; With ``rootcling``, create the same mapping file with; ``-rmf MyClassDict.rootmap -rml MyClassDict``.; It is necessary to provide the final library name explicitly, since it is; only in the separate linking step where these names are fixed and those names; may not match the default choice. With the mapping file in place, the above example can be rerun without; explicit loading of the dictionary:. .. code-block:: python. >>> import cppyy; >>> from cppyy.gbl import MyClass; >>> MyClass(42).get_int(); 42; >>>. .. _cppyy-generator:. Bindings collection; -------------------. ``cppyy-generator`` is a clang-based utility program which takes a set of C++; header files and generates a JSON output file describ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy/doc/source/utilities.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy-backend/cling/README.rst:239,Availability,avail,available,239,"cppyy-cling; ===========. A repackaging of Cling, the LLVM-based interactive C++ interpreter, as a; library for use as the backend to cppyy. This version of Cling is patched for; improved performance and better use with Python. Wheels are available for the major platforms, but if you have to build from; source, building of LLVM will take a long time. By default, all cores will be; used, but it is also recommended to add the verbose flag to see progress:. $ python -m pip install --verbose cppyy-cling. For further details, see cppyy's installation instructions:; https://cppyy.readthedocs.io/en/latest/installation.html. Cling documentation is here:; https://root.cern.ch/cling. ----. Full cppyy documentation is here:; http://cppyy.readthedocs.io/. Change log:; https://cppyy.readthedocs.io/en/latest/changelog.html. Bug reports/feedback:; https://bitbucket.org/wlav/cppyy/issues?status=new&status=open; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy-backend/cling/README.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy-backend/cling/README.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy-backend/cling/README.rst:166,Deployability,patch,patched,166,"cppyy-cling; ===========. A repackaging of Cling, the LLVM-based interactive C++ interpreter, as a; library for use as the backend to cppyy. This version of Cling is patched for; improved performance and better use with Python. Wheels are available for the major platforms, but if you have to build from; source, building of LLVM will take a long time. By default, all cores will be; used, but it is also recommended to add the verbose flag to see progress:. $ python -m pip install --verbose cppyy-cling. For further details, see cppyy's installation instructions:; https://cppyy.readthedocs.io/en/latest/installation.html. Cling documentation is here:; https://root.cern.ch/cling. ----. Full cppyy documentation is here:; http://cppyy.readthedocs.io/. Change log:; https://cppyy.readthedocs.io/en/latest/changelog.html. Bug reports/feedback:; https://bitbucket.org/wlav/cppyy/issues?status=new&status=open; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy-backend/cling/README.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy-backend/cling/README.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy-backend/cling/README.rst:475,Deployability,install,install,475,"cppyy-cling; ===========. A repackaging of Cling, the LLVM-based interactive C++ interpreter, as a; library for use as the backend to cppyy. This version of Cling is patched for; improved performance and better use with Python. Wheels are available for the major platforms, but if you have to build from; source, building of LLVM will take a long time. By default, all cores will be; used, but it is also recommended to add the verbose flag to see progress:. $ python -m pip install --verbose cppyy-cling. For further details, see cppyy's installation instructions:; https://cppyy.readthedocs.io/en/latest/installation.html. Cling documentation is here:; https://root.cern.ch/cling. ----. Full cppyy documentation is here:; http://cppyy.readthedocs.io/. Change log:; https://cppyy.readthedocs.io/en/latest/changelog.html. Bug reports/feedback:; https://bitbucket.org/wlav/cppyy/issues?status=new&status=open; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy-backend/cling/README.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy-backend/cling/README.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy-backend/cling/README.rst:539,Deployability,install,installation,539,"cppyy-cling; ===========. A repackaging of Cling, the LLVM-based interactive C++ interpreter, as a; library for use as the backend to cppyy. This version of Cling is patched for; improved performance and better use with Python. Wheels are available for the major platforms, but if you have to build from; source, building of LLVM will take a long time. By default, all cores will be; used, but it is also recommended to add the verbose flag to see progress:. $ python -m pip install --verbose cppyy-cling. For further details, see cppyy's installation instructions:; https://cppyy.readthedocs.io/en/latest/installation.html. Cling documentation is here:; https://root.cern.ch/cling. ----. Full cppyy documentation is here:; http://cppyy.readthedocs.io/. Change log:; https://cppyy.readthedocs.io/en/latest/changelog.html. Bug reports/feedback:; https://bitbucket.org/wlav/cppyy/issues?status=new&status=open; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy-backend/cling/README.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy-backend/cling/README.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy-backend/cling/README.rst:606,Deployability,install,installation,606,"cppyy-cling; ===========. A repackaging of Cling, the LLVM-based interactive C++ interpreter, as a; library for use as the backend to cppyy. This version of Cling is patched for; improved performance and better use with Python. Wheels are available for the major platforms, but if you have to build from; source, building of LLVM will take a long time. By default, all cores will be; used, but it is also recommended to add the verbose flag to see progress:. $ python -m pip install --verbose cppyy-cling. For further details, see cppyy's installation instructions:; https://cppyy.readthedocs.io/en/latest/installation.html. Cling documentation is here:; https://root.cern.ch/cling. ----. Full cppyy documentation is here:; http://cppyy.readthedocs.io/. Change log:; https://cppyy.readthedocs.io/en/latest/changelog.html. Bug reports/feedback:; https://bitbucket.org/wlav/cppyy/issues?status=new&status=open; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy-backend/cling/README.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy-backend/cling/README.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy-backend/cling/README.rst:188,Performance,perform,performance,188,"cppyy-cling; ===========. A repackaging of Cling, the LLVM-based interactive C++ interpreter, as a; library for use as the backend to cppyy. This version of Cling is patched for; improved performance and better use with Python. Wheels are available for the major platforms, but if you have to build from; source, building of LLVM will take a long time. By default, all cores will be; used, but it is also recommended to add the verbose flag to see progress:. $ python -m pip install --verbose cppyy-cling. For further details, see cppyy's installation instructions:; https://cppyy.readthedocs.io/en/latest/installation.html. Cling documentation is here:; https://root.cern.ch/cling. ----. Full cppyy documentation is here:; http://cppyy.readthedocs.io/. Change log:; https://cppyy.readthedocs.io/en/latest/changelog.html. Bug reports/feedback:; https://bitbucket.org/wlav/cppyy/issues?status=new&status=open; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy-backend/cling/README.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy-backend/cling/README.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy-backend/cling/README.rst:761,Testability,log,log,761,"cppyy-cling; ===========. A repackaging of Cling, the LLVM-based interactive C++ interpreter, as a; library for use as the backend to cppyy. This version of Cling is patched for; improved performance and better use with Python. Wheels are available for the major platforms, but if you have to build from; source, building of LLVM will take a long time. By default, all cores will be; used, but it is also recommended to add the verbose flag to see progress:. $ python -m pip install --verbose cppyy-cling. For further details, see cppyy's installation instructions:; https://cppyy.readthedocs.io/en/latest/installation.html. Cling documentation is here:; https://root.cern.ch/cling. ----. Full cppyy documentation is here:; http://cppyy.readthedocs.io/. Change log:; https://cppyy.readthedocs.io/en/latest/changelog.html. Bug reports/feedback:; https://bitbucket.org/wlav/cppyy/issues?status=new&status=open; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy-backend/cling/README.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy-backend/cling/README.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy-backend/cling/README.rst:834,Usability,feedback,feedback,834,"cppyy-cling; ===========. A repackaging of Cling, the LLVM-based interactive C++ interpreter, as a; library for use as the backend to cppyy. This version of Cling is patched for; improved performance and better use with Python. Wheels are available for the major platforms, but if you have to build from; source, building of LLVM will take a long time. By default, all cores will be; used, but it is also recommended to add the verbose flag to see progress:. $ python -m pip install --verbose cppyy-cling. For further details, see cppyy's installation instructions:; https://cppyy.readthedocs.io/en/latest/installation.html. Cling documentation is here:; https://root.cern.ch/cling. ----. Full cppyy documentation is here:; http://cppyy.readthedocs.io/. Change log:; https://cppyy.readthedocs.io/en/latest/changelog.html. Bug reports/feedback:; https://bitbucket.org/wlav/cppyy/issues?status=new&status=open; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy-backend/cling/README.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy-backend/cling/README.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/README.rst:273,Deployability,install,install,273,"cppyy-backend; =============. C/C++ wrapper around Cling, the LLVM-based interactive C++ interpreter, for; use by cppyy, providing stable C and C++ Reflection APIs. The compilation of cppyy-backend is very fast, but it will pull in; cppyy-cling, which takes a long time to install if there is no matching wheel; for your platform, forcing a build from source. By default, all cores will be; used, but it is also recommended to add the verbose flag to see progress:. $ python -m pip install --verbose cppyy-backend. For further details, see cppyy's installation instructions:; https://cppyy.readthedocs.io/en/latest/installation.html. Cling documentation is here:; https://root.cern.ch/cling. ----. Find the cppyy documentation here:; http://cppyy.readthedocs.io. Change log:; https://cppyy.readthedocs.io/en/latest/changelog.html. Bug reports/feedback:; https://bitbucket.org/wlav/cppyy/issues?status=new&status=open; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy-backend/clingwrapper/README.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/README.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/README.rst:482,Deployability,install,install,482,"cppyy-backend; =============. C/C++ wrapper around Cling, the LLVM-based interactive C++ interpreter, for; use by cppyy, providing stable C and C++ Reflection APIs. The compilation of cppyy-backend is very fast, but it will pull in; cppyy-cling, which takes a long time to install if there is no matching wheel; for your platform, forcing a build from source. By default, all cores will be; used, but it is also recommended to add the verbose flag to see progress:. $ python -m pip install --verbose cppyy-backend. For further details, see cppyy's installation instructions:; https://cppyy.readthedocs.io/en/latest/installation.html. Cling documentation is here:; https://root.cern.ch/cling. ----. Find the cppyy documentation here:; http://cppyy.readthedocs.io. Change log:; https://cppyy.readthedocs.io/en/latest/changelog.html. Bug reports/feedback:; https://bitbucket.org/wlav/cppyy/issues?status=new&status=open; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy-backend/clingwrapper/README.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/README.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/README.rst:548,Deployability,install,installation,548,"cppyy-backend; =============. C/C++ wrapper around Cling, the LLVM-based interactive C++ interpreter, for; use by cppyy, providing stable C and C++ Reflection APIs. The compilation of cppyy-backend is very fast, but it will pull in; cppyy-cling, which takes a long time to install if there is no matching wheel; for your platform, forcing a build from source. By default, all cores will be; used, but it is also recommended to add the verbose flag to see progress:. $ python -m pip install --verbose cppyy-backend. For further details, see cppyy's installation instructions:; https://cppyy.readthedocs.io/en/latest/installation.html. Cling documentation is here:; https://root.cern.ch/cling. ----. Find the cppyy documentation here:; http://cppyy.readthedocs.io. Change log:; https://cppyy.readthedocs.io/en/latest/changelog.html. Bug reports/feedback:; https://bitbucket.org/wlav/cppyy/issues?status=new&status=open; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy-backend/clingwrapper/README.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/README.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/README.rst:615,Deployability,install,installation,615,"cppyy-backend; =============. C/C++ wrapper around Cling, the LLVM-based interactive C++ interpreter, for; use by cppyy, providing stable C and C++ Reflection APIs. The compilation of cppyy-backend is very fast, but it will pull in; cppyy-cling, which takes a long time to install if there is no matching wheel; for your platform, forcing a build from source. By default, all cores will be; used, but it is also recommended to add the verbose flag to see progress:. $ python -m pip install --verbose cppyy-backend. For further details, see cppyy's installation instructions:; https://cppyy.readthedocs.io/en/latest/installation.html. Cling documentation is here:; https://root.cern.ch/cling. ----. Find the cppyy documentation here:; http://cppyy.readthedocs.io. Change log:; https://cppyy.readthedocs.io/en/latest/changelog.html. Bug reports/feedback:; https://bitbucket.org/wlav/cppyy/issues?status=new&status=open; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy-backend/clingwrapper/README.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/README.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/README.rst:36,Integrability,wrap,wrapper,36,"cppyy-backend; =============. C/C++ wrapper around Cling, the LLVM-based interactive C++ interpreter, for; use by cppyy, providing stable C and C++ Reflection APIs. The compilation of cppyy-backend is very fast, but it will pull in; cppyy-cling, which takes a long time to install if there is no matching wheel; for your platform, forcing a build from source. By default, all cores will be; used, but it is also recommended to add the verbose flag to see progress:. $ python -m pip install --verbose cppyy-backend. For further details, see cppyy's installation instructions:; https://cppyy.readthedocs.io/en/latest/installation.html. Cling documentation is here:; https://root.cern.ch/cling. ----. Find the cppyy documentation here:; http://cppyy.readthedocs.io. Change log:; https://cppyy.readthedocs.io/en/latest/changelog.html. Bug reports/feedback:; https://bitbucket.org/wlav/cppyy/issues?status=new&status=open; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy-backend/clingwrapper/README.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/README.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/README.rst:770,Testability,log,log,770,"cppyy-backend; =============. C/C++ wrapper around Cling, the LLVM-based interactive C++ interpreter, for; use by cppyy, providing stable C and C++ Reflection APIs. The compilation of cppyy-backend is very fast, but it will pull in; cppyy-cling, which takes a long time to install if there is no matching wheel; for your platform, forcing a build from source. By default, all cores will be; used, but it is also recommended to add the verbose flag to see progress:. $ python -m pip install --verbose cppyy-backend. For further details, see cppyy's installation instructions:; https://cppyy.readthedocs.io/en/latest/installation.html. Cling documentation is here:; https://root.cern.ch/cling. ----. Find the cppyy documentation here:; http://cppyy.readthedocs.io. Change log:; https://cppyy.readthedocs.io/en/latest/changelog.html. Bug reports/feedback:; https://bitbucket.org/wlav/cppyy/issues?status=new&status=open; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy-backend/clingwrapper/README.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/README.rst
https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/README.rst:843,Usability,feedback,feedback,843,"cppyy-backend; =============. C/C++ wrapper around Cling, the LLVM-based interactive C++ interpreter, for; use by cppyy, providing stable C and C++ Reflection APIs. The compilation of cppyy-backend is very fast, but it will pull in; cppyy-cling, which takes a long time to install if there is no matching wheel; for your platform, forcing a build from source. By default, all cores will be; used, but it is also recommended to add the verbose flag to see progress:. $ python -m pip install --verbose cppyy-backend. For further details, see cppyy's installation instructions:; https://cppyy.readthedocs.io/en/latest/installation.html. Cling documentation is here:; https://root.cern.ch/cling. ----. Find the cppyy documentation here:; http://cppyy.readthedocs.io. Change log:; https://cppyy.readthedocs.io/en/latest/changelog.html. Bug reports/feedback:; https://bitbucket.org/wlav/cppyy/issues?status=new&status=open; ",MatchSource.DOCS,bindings/pyroot/cppyy/cppyy-backend/clingwrapper/README.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/bindings/pyroot/cppyy/cppyy-backend/clingwrapper/README.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/index.rst:633,Availability,down,download,633,"Cling interprets C++; ====================. .. figure:: images/fig1.jpeg. **Cling** is an interactive C++ interpreter built on top of `Clang; <https://clang.llvm.org/>`_ and `LLVM <https://llvm.org/>`_. It uses LLVM's; *Just-In-Time* (`JIT <https://en.wikipedia.org/wiki/Just-in-time_compilation>`_); compiler to provide a fast and optimized compilation pipeline. Cling uses the; `read-eval-print-loop; <https://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop>`_; (**REPL**) approach, making rapid application development in C++ possible,; avoiding the classic edit-compile-run-debug cycle approach. Cling's last release, download instructions, dependencies, and any other useful; information for developers can be found on `Cling's GitHub webpage; <https://github.com/vgvassilev/cling>`_. Find out more about **Interpreting C++** on the `Compiler Research Group; <https://compiler-research.org/>`_'s webpage.; . Table of Contents; -----------------. .. toctree::; :numbered:; ; chapters/background; chapters/interactivity; chapters/why_interpreting; chapters/implementation; chapters/REPL; chapters/grammar; chapters/applications; chapters/conclusion; chapters/references; . .. note::. This project is under active development.; Cling has its documentation hosted on Read the Docs. ",MatchSource.DOCS,interpreter/cling/docs/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/index.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/index.rst:354,Deployability,pipeline,pipeline,354,"Cling interprets C++; ====================. .. figure:: images/fig1.jpeg. **Cling** is an interactive C++ interpreter built on top of `Clang; <https://clang.llvm.org/>`_ and `LLVM <https://llvm.org/>`_. It uses LLVM's; *Just-In-Time* (`JIT <https://en.wikipedia.org/wiki/Just-in-time_compilation>`_); compiler to provide a fast and optimized compilation pipeline. Cling uses the; `read-eval-print-loop; <https://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop>`_; (**REPL**) approach, making rapid application development in C++ possible,; avoiding the classic edit-compile-run-debug cycle approach. Cling's last release, download instructions, dependencies, and any other useful; information for developers can be found on `Cling's GitHub webpage; <https://github.com/vgvassilev/cling>`_. Find out more about **Interpreting C++** on the `Compiler Research Group; <https://compiler-research.org/>`_'s webpage.; . Table of Contents; -----------------. .. toctree::; :numbered:; ; chapters/background; chapters/interactivity; chapters/why_interpreting; chapters/implementation; chapters/REPL; chapters/grammar; chapters/applications; chapters/conclusion; chapters/references; . .. note::. This project is under active development.; Cling has its documentation hosted on Read the Docs. ",MatchSource.DOCS,interpreter/cling/docs/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/index.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/index.rst:624,Deployability,release,release,624,"Cling interprets C++; ====================. .. figure:: images/fig1.jpeg. **Cling** is an interactive C++ interpreter built on top of `Clang; <https://clang.llvm.org/>`_ and `LLVM <https://llvm.org/>`_. It uses LLVM's; *Just-In-Time* (`JIT <https://en.wikipedia.org/wiki/Just-in-time_compilation>`_); compiler to provide a fast and optimized compilation pipeline. Cling uses the; `read-eval-print-loop; <https://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop>`_; (**REPL**) approach, making rapid application development in C++ possible,; avoiding the classic edit-compile-run-debug cycle approach. Cling's last release, download instructions, dependencies, and any other useful; information for developers can be found on `Cling's GitHub webpage; <https://github.com/vgvassilev/cling>`_. Find out more about **Interpreting C++** on the `Compiler Research Group; <https://compiler-research.org/>`_'s webpage.; . Table of Contents; -----------------. .. toctree::; :numbered:; ; chapters/background; chapters/interactivity; chapters/why_interpreting; chapters/implementation; chapters/REPL; chapters/grammar; chapters/applications; chapters/conclusion; chapters/references; . .. note::. This project is under active development.; Cling has its documentation hosted on Read the Docs. ",MatchSource.DOCS,interpreter/cling/docs/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/index.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/index.rst:656,Integrability,depend,dependencies,656,"Cling interprets C++; ====================. .. figure:: images/fig1.jpeg. **Cling** is an interactive C++ interpreter built on top of `Clang; <https://clang.llvm.org/>`_ and `LLVM <https://llvm.org/>`_. It uses LLVM's; *Just-In-Time* (`JIT <https://en.wikipedia.org/wiki/Just-in-time_compilation>`_); compiler to provide a fast and optimized compilation pipeline. Cling uses the; `read-eval-print-loop; <https://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop>`_; (**REPL**) approach, making rapid application development in C++ possible,; avoiding the classic edit-compile-run-debug cycle approach. Cling's last release, download instructions, dependencies, and any other useful; information for developers can be found on `Cling's GitHub webpage; <https://github.com/vgvassilev/cling>`_. Find out more about **Interpreting C++** on the `Compiler Research Group; <https://compiler-research.org/>`_'s webpage.; . Table of Contents; -----------------. .. toctree::; :numbered:; ; chapters/background; chapters/interactivity; chapters/why_interpreting; chapters/implementation; chapters/REPL; chapters/grammar; chapters/applications; chapters/conclusion; chapters/references; . .. note::. This project is under active development.; Cling has its documentation hosted on Read the Docs. ",MatchSource.DOCS,interpreter/cling/docs/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/index.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/index.rst:332,Performance,optimiz,optimized,332,"Cling interprets C++; ====================. .. figure:: images/fig1.jpeg. **Cling** is an interactive C++ interpreter built on top of `Clang; <https://clang.llvm.org/>`_ and `LLVM <https://llvm.org/>`_. It uses LLVM's; *Just-In-Time* (`JIT <https://en.wikipedia.org/wiki/Just-in-time_compilation>`_); compiler to provide a fast and optimized compilation pipeline. Cling uses the; `read-eval-print-loop; <https://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop>`_; (**REPL**) approach, making rapid application development in C++ possible,; avoiding the classic edit-compile-run-debug cycle approach. Cling's last release, download instructions, dependencies, and any other useful; information for developers can be found on `Cling's GitHub webpage; <https://github.com/vgvassilev/cling>`_. Find out more about **Interpreting C++** on the `Compiler Research Group; <https://compiler-research.org/>`_'s webpage.; . Table of Contents; -----------------. .. toctree::; :numbered:; ; chapters/background; chapters/interactivity; chapters/why_interpreting; chapters/implementation; chapters/REPL; chapters/grammar; chapters/applications; chapters/conclusion; chapters/references; . .. note::. This project is under active development.; Cling has its documentation hosted on Read the Docs. ",MatchSource.DOCS,interpreter/cling/docs/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/index.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/index.rst:551,Safety,avoid,avoiding,551,"Cling interprets C++; ====================. .. figure:: images/fig1.jpeg. **Cling** is an interactive C++ interpreter built on top of `Clang; <https://clang.llvm.org/>`_ and `LLVM <https://llvm.org/>`_. It uses LLVM's; *Just-In-Time* (`JIT <https://en.wikipedia.org/wiki/Just-in-time_compilation>`_); compiler to provide a fast and optimized compilation pipeline. Cling uses the; `read-eval-print-loop; <https://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop>`_; (**REPL**) approach, making rapid application development in C++ possible,; avoiding the classic edit-compile-run-debug cycle approach. Cling's last release, download instructions, dependencies, and any other useful; information for developers can be found on `Cling's GitHub webpage; <https://github.com/vgvassilev/cling>`_. Find out more about **Interpreting C++** on the `Compiler Research Group; <https://compiler-research.org/>`_'s webpage.; . Table of Contents; -----------------. .. toctree::; :numbered:; ; chapters/background; chapters/interactivity; chapters/why_interpreting; chapters/implementation; chapters/REPL; chapters/grammar; chapters/applications; chapters/conclusion; chapters/references; . .. note::. This project is under active development.; Cling has its documentation hosted on Read the Docs. ",MatchSource.DOCS,interpreter/cling/docs/index.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/index.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/applications.rst:3160,Deployability,install,installed,3160,"nerate C++ code; for computing derivatives of the function. It supports both forward-mode and; reverse-mode AD. 4. **Cling for live coding music and musical instruments:**. The artistic live coding community has been growing steadily since around the; year 2000. The Temporary Organisation for the Permanence of Live Art Programming; (TOPLAP) has been around since 2004, Algorave (algorithmic rave parties); recently celebrated its tenth birthday, and six editions of the International; Conference on Live Coding (ICLC) have been held. A great many live coding; systems have been developed during this time, many of them exhibiting exotic and; culturally specific features that professional software developers are mostly; unaware of. In this framework, Cling has been used as the basis for a C++ based; live coding synthesiser (`TinySpec-Cling; <https://github.com/nwoeanhinnogaehr/tinyspec-cling>`_). In another example,; Cling has been installed on a BeagleBoard to bring live coding to the Bela; interactive audio platform (`Using the Cling C++ Interpreter on the Bela; Platform; <https://gist.github.com/jarmitage/6e411ae8746c04d6ecbee1cbc1ebdcd4>`_). These; two examples show the potential mutual benefits for increased engagement between; the Cling community and the artistic live coding community. 5. **Clion:** The `CLion <https://www.jetbrains.com/clion/>`_ platform is a; Integrating Development Environment (`IDE; <https://en.wikipedia.org/wiki/Integrated_development_environment>`_) for C and; C++ by `JetBrains <https://www.jetbrains.com/>`_. It was developed with the aim; to enhance developer's productivity with a smart editor, code quality assurance,; automated refactorings and deep integration with the CMake build system. CLion; integrates Cling, which can be found by clicking on Tool. Cling enables; prototyping and learning C++ in CLion. You can find more information on `CLion's; building instructions; <https://www.jetbrains.com/help/clion/cling-integration.html#install-cli",MatchSource.DOCS,interpreter/cling/docs/chapters/applications.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/applications.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/applications.rst:3923,Deployability,integrat,integration,3923,"C++ code; for computing derivatives of the function. It supports both forward-mode and; reverse-mode AD. 4. **Cling for live coding music and musical instruments:**. The artistic live coding community has been growing steadily since around the; year 2000. The Temporary Organisation for the Permanence of Live Art Programming; (TOPLAP) has been around since 2004, Algorave (algorithmic rave parties); recently celebrated its tenth birthday, and six editions of the International; Conference on Live Coding (ICLC) have been held. A great many live coding; systems have been developed during this time, many of them exhibiting exotic and; culturally specific features that professional software developers are mostly; unaware of. In this framework, Cling has been used as the basis for a C++ based; live coding synthesiser (`TinySpec-Cling; <https://github.com/nwoeanhinnogaehr/tinyspec-cling>`_). In another example,; Cling has been installed on a BeagleBoard to bring live coding to the Bela; interactive audio platform (`Using the Cling C++ Interpreter on the Bela; Platform; <https://gist.github.com/jarmitage/6e411ae8746c04d6ecbee1cbc1ebdcd4>`_). These; two examples show the potential mutual benefits for increased engagement between; the Cling community and the artistic live coding community. 5. **Clion:** The `CLion <https://www.jetbrains.com/clion/>`_ platform is a; Integrating Development Environment (`IDE; <https://en.wikipedia.org/wiki/Integrated_development_environment>`_) for C and; C++ by `JetBrains <https://www.jetbrains.com/>`_. It was developed with the aim; to enhance developer's productivity with a smart editor, code quality assurance,; automated refactorings and deep integration with the CMake build system. CLion; integrates Cling, which can be found by clicking on Tool. Cling enables; prototyping and learning C++ in CLion. You can find more information on `CLion's; building instructions; <https://www.jetbrains.com/help/clion/cling-integration.html#install-cling>`_. ",MatchSource.DOCS,interpreter/cling/docs/chapters/applications.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/applications.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/applications.rst:3971,Deployability,integrat,integrates,3971,"C++ code; for computing derivatives of the function. It supports both forward-mode and; reverse-mode AD. 4. **Cling for live coding music and musical instruments:**. The artistic live coding community has been growing steadily since around the; year 2000. The Temporary Organisation for the Permanence of Live Art Programming; (TOPLAP) has been around since 2004, Algorave (algorithmic rave parties); recently celebrated its tenth birthday, and six editions of the International; Conference on Live Coding (ICLC) have been held. A great many live coding; systems have been developed during this time, many of them exhibiting exotic and; culturally specific features that professional software developers are mostly; unaware of. In this framework, Cling has been used as the basis for a C++ based; live coding synthesiser (`TinySpec-Cling; <https://github.com/nwoeanhinnogaehr/tinyspec-cling>`_). In another example,; Cling has been installed on a BeagleBoard to bring live coding to the Bela; interactive audio platform (`Using the Cling C++ Interpreter on the Bela; Platform; <https://gist.github.com/jarmitage/6e411ae8746c04d6ecbee1cbc1ebdcd4>`_). These; two examples show the potential mutual benefits for increased engagement between; the Cling community and the artistic live coding community. 5. **Clion:** The `CLion <https://www.jetbrains.com/clion/>`_ platform is a; Integrating Development Environment (`IDE; <https://en.wikipedia.org/wiki/Integrated_development_environment>`_) for C and; C++ by `JetBrains <https://www.jetbrains.com/>`_. It was developed with the aim; to enhance developer's productivity with a smart editor, code quality assurance,; automated refactorings and deep integration with the CMake build system. CLion; integrates Cling, which can be found by clicking on Tool. Cling enables; prototyping and learning C++ in CLion. You can find more information on `CLion's; building instructions; <https://www.jetbrains.com/help/clion/cling-integration.html#install-cling>`_. ",MatchSource.DOCS,interpreter/cling/docs/chapters/applications.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/applications.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/applications.rst:4193,Deployability,integrat,integration,4193,"C++ code; for computing derivatives of the function. It supports both forward-mode and; reverse-mode AD. 4. **Cling for live coding music and musical instruments:**. The artistic live coding community has been growing steadily since around the; year 2000. The Temporary Organisation for the Permanence of Live Art Programming; (TOPLAP) has been around since 2004, Algorave (algorithmic rave parties); recently celebrated its tenth birthday, and six editions of the International; Conference on Live Coding (ICLC) have been held. A great many live coding; systems have been developed during this time, many of them exhibiting exotic and; culturally specific features that professional software developers are mostly; unaware of. In this framework, Cling has been used as the basis for a C++ based; live coding synthesiser (`TinySpec-Cling; <https://github.com/nwoeanhinnogaehr/tinyspec-cling>`_). In another example,; Cling has been installed on a BeagleBoard to bring live coding to the Bela; interactive audio platform (`Using the Cling C++ Interpreter on the Bela; Platform; <https://gist.github.com/jarmitage/6e411ae8746c04d6ecbee1cbc1ebdcd4>`_). These; two examples show the potential mutual benefits for increased engagement between; the Cling community and the artistic live coding community. 5. **Clion:** The `CLion <https://www.jetbrains.com/clion/>`_ platform is a; Integrating Development Environment (`IDE; <https://en.wikipedia.org/wiki/Integrated_development_environment>`_) for C and; C++ by `JetBrains <https://www.jetbrains.com/>`_. It was developed with the aim; to enhance developer's productivity with a smart editor, code quality assurance,; automated refactorings and deep integration with the CMake build system. CLion; integrates Cling, which can be found by clicking on Tool. Cling enables; prototyping and learning C++ in CLion. You can find more information on `CLion's; building instructions; <https://www.jetbrains.com/help/clion/cling-integration.html#install-cling>`_. ",MatchSource.DOCS,interpreter/cling/docs/chapters/applications.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/applications.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/applications.rst:4210,Deployability,install,install-cling,4210,"C++ code; for computing derivatives of the function. It supports both forward-mode and; reverse-mode AD. 4. **Cling for live coding music and musical instruments:**. The artistic live coding community has been growing steadily since around the; year 2000. The Temporary Organisation for the Permanence of Live Art Programming; (TOPLAP) has been around since 2004, Algorave (algorithmic rave parties); recently celebrated its tenth birthday, and six editions of the International; Conference on Live Coding (ICLC) have been held. A great many live coding; systems have been developed during this time, many of them exhibiting exotic and; culturally specific features that professional software developers are mostly; unaware of. In this framework, Cling has been used as the basis for a C++ based; live coding synthesiser (`TinySpec-Cling; <https://github.com/nwoeanhinnogaehr/tinyspec-cling>`_). In another example,; Cling has been installed on a BeagleBoard to bring live coding to the Bela; interactive audio platform (`Using the Cling C++ Interpreter on the Bela; Platform; <https://gist.github.com/jarmitage/6e411ae8746c04d6ecbee1cbc1ebdcd4>`_). These; two examples show the potential mutual benefits for increased engagement between; the Cling community and the artistic live coding community. 5. **Clion:** The `CLion <https://www.jetbrains.com/clion/>`_ platform is a; Integrating Development Environment (`IDE; <https://en.wikipedia.org/wiki/Integrated_development_environment>`_) for C and; C++ by `JetBrains <https://www.jetbrains.com/>`_. It was developed with the aim; to enhance developer's productivity with a smart editor, code quality assurance,; automated refactorings and deep integration with the CMake build system. CLion; integrates Cling, which can be found by clicking on Tool. Cling enables; prototyping and learning C++ in CLion. You can find more information on `CLion's; building instructions; <https://www.jetbrains.com/help/clion/cling-integration.html#install-cling>`_. ",MatchSource.DOCS,interpreter/cling/docs/chapters/applications.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/applications.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/applications.rst:1303,Energy Efficiency,power,power,1303," to easily exchange ideas or; collaborate by sharing their analyses in a straight-forward and reproducible; way. Jupyter’s official C++ kernel(`Xeus-Cling; <https://github.com/jupyter-xeus/xeus-cling>`_) relies on Xeus, a C++; implementation of the kernel protocol, and Cling. Using C++ in the Jupyter; environment yields a different experience to C++ users. For example, Jupyter’s; visualization system can be used to render rich content such as images,; therefore bringing more interactivity into the Jupyter’s world. You can find; more information on `Xeus Cling's Read the Docs; <https://xeus-cling.readthedocs.io/en/latest/>`_ webpage. 2. **Interactive CUDA C++ with Cling:**. `CUDA <https://blogs.nvidia.com/blog/2012/09/10/what-is-cuda-2/>`_ is a platform; and Application Programming Interface (API) created by `NVIDIA; <https://www.nvidia.com/en-us/>`_. It controls `GPU; <https://en.wikipedia.org/wiki/Graphics_processing_unit>`_ (Graphical Processing; Unit) for parallel programming, enabling developers to harness the power of; graphic processing units (GPUs) to speed up applications. As an example,; `PIConGPU <https://github.com/ComputationalRadiationPhysics/picongpu>`_ is a; CUDA-based plasma physics application to solve the dynamics of a plasma by; computing the motion of electrons and ions in the plasma field. Interactive GPU; programming was made possible by extending Cling functionality to compile CUDA; C++ code. The new Cling-CUDA C++ can be used on Jupyter Notebook platform, and; enables big, interactive simulation with GPUs, easy GPU development and; debugging, and effective GPU programming learning. 3. **Clad:**. `Clad <https://compiler-research.org/clad/>`_ enables automatic differentiation; (AD) for C++. It was first developed as a plugin for Cling, and is now a plugin; for Clang compiler. Clad is based on source code transformation. Given C++; source code of a mathematical function, it can automatically generate C++ code; for computing derivatives of the fu",MatchSource.DOCS,interpreter/cling/docs/chapters/applications.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/applications.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/applications.rst:529,Integrability,protocol,protocol,529,"Applications; ------------. 1. **C++ in Jupyter Notebook - Xeus Cling:**. The `Jupyter Notebook <https://jupyter.org/>`_ technology allows users to create; and share documents that contain live code, equations, visualizations and; narrative text. It enables data scientists to easily exchange ideas or; collaborate by sharing their analyses in a straight-forward and reproducible; way. Jupyter’s official C++ kernel(`Xeus-Cling; <https://github.com/jupyter-xeus/xeus-cling>`_) relies on Xeus, a C++; implementation of the kernel protocol, and Cling. Using C++ in the Jupyter; environment yields a different experience to C++ users. For example, Jupyter’s; visualization system can be used to render rich content such as images,; therefore bringing more interactivity into the Jupyter’s world. You can find; more information on `Xeus Cling's Read the Docs; <https://xeus-cling.readthedocs.io/en/latest/>`_ webpage. 2. **Interactive CUDA C++ with Cling:**. `CUDA <https://blogs.nvidia.com/blog/2012/09/10/what-is-cuda-2/>`_ is a platform; and Application Programming Interface (API) created by `NVIDIA; <https://www.nvidia.com/en-us/>`_. It controls `GPU; <https://en.wikipedia.org/wiki/Graphics_processing_unit>`_ (Graphical Processing; Unit) for parallel programming, enabling developers to harness the power of; graphic processing units (GPUs) to speed up applications. As an example,; `PIConGPU <https://github.com/ComputationalRadiationPhysics/picongpu>`_ is a; CUDA-based plasma physics application to solve the dynamics of a plasma by; computing the motion of electrons and ions in the plasma field. Interactive GPU; programming was made possible by extending Cling functionality to compile CUDA; C++ code. The new Cling-CUDA C++ can be used on Jupyter Notebook platform, and; enables big, interactive simulation with GPUs, easy GPU development and; debugging, and effective GPU programming learning. 3. **Clad:**. `Clad <https://compiler-research.org/clad/>`_ enables automatic differentiation; ",MatchSource.DOCS,interpreter/cling/docs/chapters/applications.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/applications.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/applications.rst:3923,Integrability,integrat,integration,3923,"C++ code; for computing derivatives of the function. It supports both forward-mode and; reverse-mode AD. 4. **Cling for live coding music and musical instruments:**. The artistic live coding community has been growing steadily since around the; year 2000. The Temporary Organisation for the Permanence of Live Art Programming; (TOPLAP) has been around since 2004, Algorave (algorithmic rave parties); recently celebrated its tenth birthday, and six editions of the International; Conference on Live Coding (ICLC) have been held. A great many live coding; systems have been developed during this time, many of them exhibiting exotic and; culturally specific features that professional software developers are mostly; unaware of. In this framework, Cling has been used as the basis for a C++ based; live coding synthesiser (`TinySpec-Cling; <https://github.com/nwoeanhinnogaehr/tinyspec-cling>`_). In another example,; Cling has been installed on a BeagleBoard to bring live coding to the Bela; interactive audio platform (`Using the Cling C++ Interpreter on the Bela; Platform; <https://gist.github.com/jarmitage/6e411ae8746c04d6ecbee1cbc1ebdcd4>`_). These; two examples show the potential mutual benefits for increased engagement between; the Cling community and the artistic live coding community. 5. **Clion:** The `CLion <https://www.jetbrains.com/clion/>`_ platform is a; Integrating Development Environment (`IDE; <https://en.wikipedia.org/wiki/Integrated_development_environment>`_) for C and; C++ by `JetBrains <https://www.jetbrains.com/>`_. It was developed with the aim; to enhance developer's productivity with a smart editor, code quality assurance,; automated refactorings and deep integration with the CMake build system. CLion; integrates Cling, which can be found by clicking on Tool. Cling enables; prototyping and learning C++ in CLion. You can find more information on `CLion's; building instructions; <https://www.jetbrains.com/help/clion/cling-integration.html#install-cling>`_. ",MatchSource.DOCS,interpreter/cling/docs/chapters/applications.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/applications.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/applications.rst:3971,Integrability,integrat,integrates,3971,"C++ code; for computing derivatives of the function. It supports both forward-mode and; reverse-mode AD. 4. **Cling for live coding music and musical instruments:**. The artistic live coding community has been growing steadily since around the; year 2000. The Temporary Organisation for the Permanence of Live Art Programming; (TOPLAP) has been around since 2004, Algorave (algorithmic rave parties); recently celebrated its tenth birthday, and six editions of the International; Conference on Live Coding (ICLC) have been held. A great many live coding; systems have been developed during this time, many of them exhibiting exotic and; culturally specific features that professional software developers are mostly; unaware of. In this framework, Cling has been used as the basis for a C++ based; live coding synthesiser (`TinySpec-Cling; <https://github.com/nwoeanhinnogaehr/tinyspec-cling>`_). In another example,; Cling has been installed on a BeagleBoard to bring live coding to the Bela; interactive audio platform (`Using the Cling C++ Interpreter on the Bela; Platform; <https://gist.github.com/jarmitage/6e411ae8746c04d6ecbee1cbc1ebdcd4>`_). These; two examples show the potential mutual benefits for increased engagement between; the Cling community and the artistic live coding community. 5. **Clion:** The `CLion <https://www.jetbrains.com/clion/>`_ platform is a; Integrating Development Environment (`IDE; <https://en.wikipedia.org/wiki/Integrated_development_environment>`_) for C and; C++ by `JetBrains <https://www.jetbrains.com/>`_. It was developed with the aim; to enhance developer's productivity with a smart editor, code quality assurance,; automated refactorings and deep integration with the CMake build system. CLion; integrates Cling, which can be found by clicking on Tool. Cling enables; prototyping and learning C++ in CLion. You can find more information on `CLion's; building instructions; <https://www.jetbrains.com/help/clion/cling-integration.html#install-cling>`_. ",MatchSource.DOCS,interpreter/cling/docs/chapters/applications.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/applications.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/applications.rst:4193,Integrability,integrat,integration,4193,"C++ code; for computing derivatives of the function. It supports both forward-mode and; reverse-mode AD. 4. **Cling for live coding music and musical instruments:**. The artistic live coding community has been growing steadily since around the; year 2000. The Temporary Organisation for the Permanence of Live Art Programming; (TOPLAP) has been around since 2004, Algorave (algorithmic rave parties); recently celebrated its tenth birthday, and six editions of the International; Conference on Live Coding (ICLC) have been held. A great many live coding; systems have been developed during this time, many of them exhibiting exotic and; culturally specific features that professional software developers are mostly; unaware of. In this framework, Cling has been used as the basis for a C++ based; live coding synthesiser (`TinySpec-Cling; <https://github.com/nwoeanhinnogaehr/tinyspec-cling>`_). In another example,; Cling has been installed on a BeagleBoard to bring live coding to the Bela; interactive audio platform (`Using the Cling C++ Interpreter on the Bela; Platform; <https://gist.github.com/jarmitage/6e411ae8746c04d6ecbee1cbc1ebdcd4>`_). These; two examples show the potential mutual benefits for increased engagement between; the Cling community and the artistic live coding community. 5. **Clion:** The `CLion <https://www.jetbrains.com/clion/>`_ platform is a; Integrating Development Environment (`IDE; <https://en.wikipedia.org/wiki/Integrated_development_environment>`_) for C and; C++ by `JetBrains <https://www.jetbrains.com/>`_. It was developed with the aim; to enhance developer's productivity with a smart editor, code quality assurance,; automated refactorings and deep integration with the CMake build system. CLion; integrates Cling, which can be found by clicking on Tool. Cling enables; prototyping and learning C++ in CLion. You can find more information on `CLion's; building instructions; <https://www.jetbrains.com/help/clion/cling-integration.html#install-cling>`_. ",MatchSource.DOCS,interpreter/cling/docs/chapters/applications.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/applications.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/applications.rst:1655,Modifiability,extend,extending,1655,"isualization system can be used to render rich content such as images,; therefore bringing more interactivity into the Jupyter’s world. You can find; more information on `Xeus Cling's Read the Docs; <https://xeus-cling.readthedocs.io/en/latest/>`_ webpage. 2. **Interactive CUDA C++ with Cling:**. `CUDA <https://blogs.nvidia.com/blog/2012/09/10/what-is-cuda-2/>`_ is a platform; and Application Programming Interface (API) created by `NVIDIA; <https://www.nvidia.com/en-us/>`_. It controls `GPU; <https://en.wikipedia.org/wiki/Graphics_processing_unit>`_ (Graphical Processing; Unit) for parallel programming, enabling developers to harness the power of; graphic processing units (GPUs) to speed up applications. As an example,; `PIConGPU <https://github.com/ComputationalRadiationPhysics/picongpu>`_ is a; CUDA-based plasma physics application to solve the dynamics of a plasma by; computing the motion of electrons and ions in the plasma field. Interactive GPU; programming was made possible by extending Cling functionality to compile CUDA; C++ code. The new Cling-CUDA C++ can be used on Jupyter Notebook platform, and; enables big, interactive simulation with GPUs, easy GPU development and; debugging, and effective GPU programming learning. 3. **Clad:**. `Clad <https://compiler-research.org/clad/>`_ enables automatic differentiation; (AD) for C++. It was first developed as a plugin for Cling, and is now a plugin; for Clang compiler. Clad is based on source code transformation. Given C++; source code of a mathematical function, it can automatically generate C++ code; for computing derivatives of the function. It supports both forward-mode and; reverse-mode AD. 4. **Cling for live coding music and musical instruments:**. The artistic live coding community has been growing steadily since around the; year 2000. The Temporary Organisation for the Permanence of Live Art Programming; (TOPLAP) has been around since 2004, Algorave (algorithmic rave parties); recently celebrated its tenth",MatchSource.DOCS,interpreter/cling/docs/chapters/applications.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/applications.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/applications.rst:2043,Modifiability,plugin,plugin,2043,"ramming Interface (API) created by `NVIDIA; <https://www.nvidia.com/en-us/>`_. It controls `GPU; <https://en.wikipedia.org/wiki/Graphics_processing_unit>`_ (Graphical Processing; Unit) for parallel programming, enabling developers to harness the power of; graphic processing units (GPUs) to speed up applications. As an example,; `PIConGPU <https://github.com/ComputationalRadiationPhysics/picongpu>`_ is a; CUDA-based plasma physics application to solve the dynamics of a plasma by; computing the motion of electrons and ions in the plasma field. Interactive GPU; programming was made possible by extending Cling functionality to compile CUDA; C++ code. The new Cling-CUDA C++ can be used on Jupyter Notebook platform, and; enables big, interactive simulation with GPUs, easy GPU development and; debugging, and effective GPU programming learning. 3. **Clad:**. `Clad <https://compiler-research.org/clad/>`_ enables automatic differentiation; (AD) for C++. It was first developed as a plugin for Cling, and is now a plugin; for Clang compiler. Clad is based on source code transformation. Given C++; source code of a mathematical function, it can automatically generate C++ code; for computing derivatives of the function. It supports both forward-mode and; reverse-mode AD. 4. **Cling for live coding music and musical instruments:**. The artistic live coding community has been growing steadily since around the; year 2000. The Temporary Organisation for the Permanence of Live Art Programming; (TOPLAP) has been around since 2004, Algorave (algorithmic rave parties); recently celebrated its tenth birthday, and six editions of the International; Conference on Live Coding (ICLC) have been held. A great many live coding; systems have been developed during this time, many of them exhibiting exotic and; culturally specific features that professional software developers are mostly; unaware of. In this framework, Cling has been used as the basis for a C++ based; live coding synthesiser (`TinySpe",MatchSource.DOCS,interpreter/cling/docs/chapters/applications.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/applications.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/applications.rst:2074,Modifiability,plugin,plugin,2074,"ramming Interface (API) created by `NVIDIA; <https://www.nvidia.com/en-us/>`_. It controls `GPU; <https://en.wikipedia.org/wiki/Graphics_processing_unit>`_ (Graphical Processing; Unit) for parallel programming, enabling developers to harness the power of; graphic processing units (GPUs) to speed up applications. As an example,; `PIConGPU <https://github.com/ComputationalRadiationPhysics/picongpu>`_ is a; CUDA-based plasma physics application to solve the dynamics of a plasma by; computing the motion of electrons and ions in the plasma field. Interactive GPU; programming was made possible by extending Cling functionality to compile CUDA; C++ code. The new Cling-CUDA C++ can be used on Jupyter Notebook platform, and; enables big, interactive simulation with GPUs, easy GPU development and; debugging, and effective GPU programming learning. 3. **Clad:**. `Clad <https://compiler-research.org/clad/>`_ enables automatic differentiation; (AD) for C++. It was first developed as a plugin for Cling, and is now a plugin; for Clang compiler. Clad is based on source code transformation. Given C++; source code of a mathematical function, it can automatically generate C++ code; for computing derivatives of the function. It supports both forward-mode and; reverse-mode AD. 4. **Cling for live coding music and musical instruments:**. The artistic live coding community has been growing steadily since around the; year 2000. The Temporary Organisation for the Permanence of Live Art Programming; (TOPLAP) has been around since 2004, Algorave (algorithmic rave parties); recently celebrated its tenth birthday, and six editions of the International; Conference on Live Coding (ICLC) have been held. A great many live coding; systems have been developed during this time, many of them exhibiting exotic and; culturally specific features that professional software developers are mostly; unaware of. In this framework, Cling has been used as the basis for a C++ based; live coding synthesiser (`TinySpe",MatchSource.DOCS,interpreter/cling/docs/chapters/applications.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/applications.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/applications.rst:3812,Modifiability,enhance,enhance,3812,"C++ code; for computing derivatives of the function. It supports both forward-mode and; reverse-mode AD. 4. **Cling for live coding music and musical instruments:**. The artistic live coding community has been growing steadily since around the; year 2000. The Temporary Organisation for the Permanence of Live Art Programming; (TOPLAP) has been around since 2004, Algorave (algorithmic rave parties); recently celebrated its tenth birthday, and six editions of the International; Conference on Live Coding (ICLC) have been held. A great many live coding; systems have been developed during this time, many of them exhibiting exotic and; culturally specific features that professional software developers are mostly; unaware of. In this framework, Cling has been used as the basis for a C++ based; live coding synthesiser (`TinySpec-Cling; <https://github.com/nwoeanhinnogaehr/tinyspec-cling>`_). In another example,; Cling has been installed on a BeagleBoard to bring live coding to the Bela; interactive audio platform (`Using the Cling C++ Interpreter on the Bela; Platform; <https://gist.github.com/jarmitage/6e411ae8746c04d6ecbee1cbc1ebdcd4>`_). These; two examples show the potential mutual benefits for increased engagement between; the Cling community and the artistic live coding community. 5. **Clion:** The `CLion <https://www.jetbrains.com/clion/>`_ platform is a; Integrating Development Environment (`IDE; <https://en.wikipedia.org/wiki/Integrated_development_environment>`_) for C and; C++ by `JetBrains <https://www.jetbrains.com/>`_. It was developed with the aim; to enhance developer's productivity with a smart editor, code quality assurance,; automated refactorings and deep integration with the CMake build system. CLion; integrates Cling, which can be found by clicking on Tool. Cling enables; prototyping and learning C++ in CLion. You can find more information on `CLion's; building instructions; <https://www.jetbrains.com/help/clion/cling-integration.html#install-cling>`_. ",MatchSource.DOCS,interpreter/cling/docs/chapters/applications.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/applications.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/applications.rst:3901,Modifiability,refactor,refactorings,3901,"C++ code; for computing derivatives of the function. It supports both forward-mode and; reverse-mode AD. 4. **Cling for live coding music and musical instruments:**. The artistic live coding community has been growing steadily since around the; year 2000. The Temporary Organisation for the Permanence of Live Art Programming; (TOPLAP) has been around since 2004, Algorave (algorithmic rave parties); recently celebrated its tenth birthday, and six editions of the International; Conference on Live Coding (ICLC) have been held. A great many live coding; systems have been developed during this time, many of them exhibiting exotic and; culturally specific features that professional software developers are mostly; unaware of. In this framework, Cling has been used as the basis for a C++ based; live coding synthesiser (`TinySpec-Cling; <https://github.com/nwoeanhinnogaehr/tinyspec-cling>`_). In another example,; Cling has been installed on a BeagleBoard to bring live coding to the Bela; interactive audio platform (`Using the Cling C++ Interpreter on the Bela; Platform; <https://gist.github.com/jarmitage/6e411ae8746c04d6ecbee1cbc1ebdcd4>`_). These; two examples show the potential mutual benefits for increased engagement between; the Cling community and the artistic live coding community. 5. **Clion:** The `CLion <https://www.jetbrains.com/clion/>`_ platform is a; Integrating Development Environment (`IDE; <https://en.wikipedia.org/wiki/Integrated_development_environment>`_) for C and; C++ by `JetBrains <https://www.jetbrains.com/>`_. It was developed with the aim; to enhance developer's productivity with a smart editor, code quality assurance,; automated refactorings and deep integration with the CMake build system. CLion; integrates Cling, which can be found by clicking on Tool. Cling enables; prototyping and learning C++ in CLion. You can find more information on `CLion's; building instructions; <https://www.jetbrains.com/help/clion/cling-integration.html#install-cling>`_. ",MatchSource.DOCS,interpreter/cling/docs/chapters/applications.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/applications.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/applications.rst:1896,Usability,learn,learning,1896,"ore information on `Xeus Cling's Read the Docs; <https://xeus-cling.readthedocs.io/en/latest/>`_ webpage. 2. **Interactive CUDA C++ with Cling:**. `CUDA <https://blogs.nvidia.com/blog/2012/09/10/what-is-cuda-2/>`_ is a platform; and Application Programming Interface (API) created by `NVIDIA; <https://www.nvidia.com/en-us/>`_. It controls `GPU; <https://en.wikipedia.org/wiki/Graphics_processing_unit>`_ (Graphical Processing; Unit) for parallel programming, enabling developers to harness the power of; graphic processing units (GPUs) to speed up applications. As an example,; `PIConGPU <https://github.com/ComputationalRadiationPhysics/picongpu>`_ is a; CUDA-based plasma physics application to solve the dynamics of a plasma by; computing the motion of electrons and ions in the plasma field. Interactive GPU; programming was made possible by extending Cling functionality to compile CUDA; C++ code. The new Cling-CUDA C++ can be used on Jupyter Notebook platform, and; enables big, interactive simulation with GPUs, easy GPU development and; debugging, and effective GPU programming learning. 3. **Clad:**. `Clad <https://compiler-research.org/clad/>`_ enables automatic differentiation; (AD) for C++. It was first developed as a plugin for Cling, and is now a plugin; for Clang compiler. Clad is based on source code transformation. Given C++; source code of a mathematical function, it can automatically generate C++ code; for computing derivatives of the function. It supports both forward-mode and; reverse-mode AD. 4. **Cling for live coding music and musical instruments:**. The artistic live coding community has been growing steadily since around the; year 2000. The Temporary Organisation for the Permanence of Live Art Programming; (TOPLAP) has been around since 2004, Algorave (algorithmic rave parties); recently celebrated its tenth birthday, and six editions of the International; Conference on Live Coding (ICLC) have been held. A great many live coding; systems have been develop",MatchSource.DOCS,interpreter/cling/docs/chapters/applications.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/applications.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/applications.rst:4060,Usability,learn,learning,4060,"C++ code; for computing derivatives of the function. It supports both forward-mode and; reverse-mode AD. 4. **Cling for live coding music and musical instruments:**. The artistic live coding community has been growing steadily since around the; year 2000. The Temporary Organisation for the Permanence of Live Art Programming; (TOPLAP) has been around since 2004, Algorave (algorithmic rave parties); recently celebrated its tenth birthday, and six editions of the International; Conference on Live Coding (ICLC) have been held. A great many live coding; systems have been developed during this time, many of them exhibiting exotic and; culturally specific features that professional software developers are mostly; unaware of. In this framework, Cling has been used as the basis for a C++ based; live coding synthesiser (`TinySpec-Cling; <https://github.com/nwoeanhinnogaehr/tinyspec-cling>`_). In another example,; Cling has been installed on a BeagleBoard to bring live coding to the Bela; interactive audio platform (`Using the Cling C++ Interpreter on the Bela; Platform; <https://gist.github.com/jarmitage/6e411ae8746c04d6ecbee1cbc1ebdcd4>`_). These; two examples show the potential mutual benefits for increased engagement between; the Cling community and the artistic live coding community. 5. **Clion:** The `CLion <https://www.jetbrains.com/clion/>`_ platform is a; Integrating Development Environment (`IDE; <https://en.wikipedia.org/wiki/Integrated_development_environment>`_) for C and; C++ by `JetBrains <https://www.jetbrains.com/>`_. It was developed with the aim; to enhance developer's productivity with a smart editor, code quality assurance,; automated refactorings and deep integration with the CMake build system. CLion; integrates Cling, which can be found by clicking on Tool. Cling enables; prototyping and learning C++ in CLion. You can find more information on `CLion's; building instructions; <https://www.jetbrains.com/help/clion/cling-integration.html#install-cling>`_. ",MatchSource.DOCS,interpreter/cling/docs/chapters/applications.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/applications.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/background.rst:86,Deployability,release,released,86,"When and why was Cling developed?; ---------------------------------. Cling was first released in 2014 as the interactive, C++ interpreter in; ROOT. `ROOT <https://root.cern/>`_ is an open-source program written primarily; in C++, developed by research groups in high-energy physics including `CERN; <https://home.cern/>`_, `FERMILAB <https://www.fnal.gov/>`_ and `Princeton; <https://www.princeton.edu/>`_. ROOT is nowadays used by most high-energy; physics experiments. CERN is an European research organization that operates the; largest particle physics laboratory in the world. Its experiments collect; petabytes of data per year to be serialized, analyzed, and visualized as C++; objects. In this framework, Cling was developed with the aim to facilitate the; processing of scientific data in the field of high-energy physics . Cling is a; core component of ROOT: it provides essential functionality for the analysis of; vast amounts of very complex data produced by the experimental high-energy; physics community by enabling (1) interactive exploration in C++, (2) dynamic; interoperability (see `cppyy <https://cppyy.readthedocs.io/en/latest/>`_, an; automatic, runtime Python/C++ binder), and (3) rapid prototyping capabilities.; ",MatchSource.DOCS,interpreter/cling/docs/chapters/background.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/background.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/background.rst:268,Energy Efficiency,energy,energy,268,"When and why was Cling developed?; ---------------------------------. Cling was first released in 2014 as the interactive, C++ interpreter in; ROOT. `ROOT <https://root.cern/>`_ is an open-source program written primarily; in C++, developed by research groups in high-energy physics including `CERN; <https://home.cern/>`_, `FERMILAB <https://www.fnal.gov/>`_ and `Princeton; <https://www.princeton.edu/>`_. ROOT is nowadays used by most high-energy; physics experiments. CERN is an European research organization that operates the; largest particle physics laboratory in the world. Its experiments collect; petabytes of data per year to be serialized, analyzed, and visualized as C++; objects. In this framework, Cling was developed with the aim to facilitate the; processing of scientific data in the field of high-energy physics . Cling is a; core component of ROOT: it provides essential functionality for the analysis of; vast amounts of very complex data produced by the experimental high-energy; physics community by enabling (1) interactive exploration in C++, (2) dynamic; interoperability (see `cppyy <https://cppyy.readthedocs.io/en/latest/>`_, an; automatic, runtime Python/C++ binder), and (3) rapid prototyping capabilities.; ",MatchSource.DOCS,interpreter/cling/docs/chapters/background.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/background.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/background.rst:443,Energy Efficiency,energy,energy,443,"When and why was Cling developed?; ---------------------------------. Cling was first released in 2014 as the interactive, C++ interpreter in; ROOT. `ROOT <https://root.cern/>`_ is an open-source program written primarily; in C++, developed by research groups in high-energy physics including `CERN; <https://home.cern/>`_, `FERMILAB <https://www.fnal.gov/>`_ and `Princeton; <https://www.princeton.edu/>`_. ROOT is nowadays used by most high-energy; physics experiments. CERN is an European research organization that operates the; largest particle physics laboratory in the world. Its experiments collect; petabytes of data per year to be serialized, analyzed, and visualized as C++; objects. In this framework, Cling was developed with the aim to facilitate the; processing of scientific data in the field of high-energy physics . Cling is a; core component of ROOT: it provides essential functionality for the analysis of; vast amounts of very complex data produced by the experimental high-energy; physics community by enabling (1) interactive exploration in C++, (2) dynamic; interoperability (see `cppyy <https://cppyy.readthedocs.io/en/latest/>`_, an; automatic, runtime Python/C++ binder), and (3) rapid prototyping capabilities.; ",MatchSource.DOCS,interpreter/cling/docs/chapters/background.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/background.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/background.rst:817,Energy Efficiency,energy,energy,817,"When and why was Cling developed?; ---------------------------------. Cling was first released in 2014 as the interactive, C++ interpreter in; ROOT. `ROOT <https://root.cern/>`_ is an open-source program written primarily; in C++, developed by research groups in high-energy physics including `CERN; <https://home.cern/>`_, `FERMILAB <https://www.fnal.gov/>`_ and `Princeton; <https://www.princeton.edu/>`_. ROOT is nowadays used by most high-energy; physics experiments. CERN is an European research organization that operates the; largest particle physics laboratory in the world. Its experiments collect; petabytes of data per year to be serialized, analyzed, and visualized as C++; objects. In this framework, Cling was developed with the aim to facilitate the; processing of scientific data in the field of high-energy physics . Cling is a; core component of ROOT: it provides essential functionality for the analysis of; vast amounts of very complex data produced by the experimental high-energy; physics community by enabling (1) interactive exploration in C++, (2) dynamic; interoperability (see `cppyy <https://cppyy.readthedocs.io/en/latest/>`_, an; automatic, runtime Python/C++ binder), and (3) rapid prototyping capabilities.; ",MatchSource.DOCS,interpreter/cling/docs/chapters/background.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/background.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/background.rst:995,Energy Efficiency,energy,energy,995,"When and why was Cling developed?; ---------------------------------. Cling was first released in 2014 as the interactive, C++ interpreter in; ROOT. `ROOT <https://root.cern/>`_ is an open-source program written primarily; in C++, developed by research groups in high-energy physics including `CERN; <https://home.cern/>`_, `FERMILAB <https://www.fnal.gov/>`_ and `Princeton; <https://www.princeton.edu/>`_. ROOT is nowadays used by most high-energy; physics experiments. CERN is an European research organization that operates the; largest particle physics laboratory in the world. Its experiments collect; petabytes of data per year to be serialized, analyzed, and visualized as C++; objects. In this framework, Cling was developed with the aim to facilitate the; processing of scientific data in the field of high-energy physics . Cling is a; core component of ROOT: it provides essential functionality for the analysis of; vast amounts of very complex data produced by the experimental high-energy; physics community by enabling (1) interactive exploration in C++, (2) dynamic; interoperability (see `cppyy <https://cppyy.readthedocs.io/en/latest/>`_, an; automatic, runtime Python/C++ binder), and (3) rapid prototyping capabilities.; ",MatchSource.DOCS,interpreter/cling/docs/chapters/background.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/background.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/background.rst:1082,Integrability,interoperab,interoperability,1082,"When and why was Cling developed?; ---------------------------------. Cling was first released in 2014 as the interactive, C++ interpreter in; ROOT. `ROOT <https://root.cern/>`_ is an open-source program written primarily; in C++, developed by research groups in high-energy physics including `CERN; <https://home.cern/>`_, `FERMILAB <https://www.fnal.gov/>`_ and `Princeton; <https://www.princeton.edu/>`_. ROOT is nowadays used by most high-energy; physics experiments. CERN is an European research organization that operates the; largest particle physics laboratory in the world. Its experiments collect; petabytes of data per year to be serialized, analyzed, and visualized as C++; objects. In this framework, Cling was developed with the aim to facilitate the; processing of scientific data in the field of high-energy physics . Cling is a; core component of ROOT: it provides essential functionality for the analysis of; vast amounts of very complex data produced by the experimental high-energy; physics community by enabling (1) interactive exploration in C++, (2) dynamic; interoperability (see `cppyy <https://cppyy.readthedocs.io/en/latest/>`_, an; automatic, runtime Python/C++ binder), and (3) rapid prototyping capabilities.; ",MatchSource.DOCS,interpreter/cling/docs/chapters/background.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/background.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/conclusion.rst:152,Energy Efficiency,efficient,efficient,152,"Conclusion; ----------. Cling is not just an interpreter, and is not just a REPL: it is a C/C++; JIT-compiler that can be embedded to your software for efficient incremental; execution of C++. Cling allows you to decide how much you want to compile; statically and how much to defer for the target platform. Cling enables; reflection and introspection information in high-performance systems such as; ROOT, or Xeus Jupyter, where it provides efficient code for performance-critical; tasks where hot-spot regions can be annotated with specific optimization; levels. You ca find more information regarding Cling's internal architecture,; functionment, user-cases, and Cling's based project into the References Chapter.; ",MatchSource.DOCS,interpreter/cling/docs/chapters/conclusion.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/conclusion.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/conclusion.rst:442,Energy Efficiency,efficient,efficient,442,"Conclusion; ----------. Cling is not just an interpreter, and is not just a REPL: it is a C/C++; JIT-compiler that can be embedded to your software for efficient incremental; execution of C++. Cling allows you to decide how much you want to compile; statically and how much to defer for the target platform. Cling enables; reflection and introspection information in high-performance systems such as; ROOT, or Xeus Jupyter, where it provides efficient code for performance-critical; tasks where hot-spot regions can be annotated with specific optimization; levels. You ca find more information regarding Cling's internal architecture,; functionment, user-cases, and Cling's based project into the References Chapter.; ",MatchSource.DOCS,interpreter/cling/docs/chapters/conclusion.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/conclusion.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/conclusion.rst:372,Performance,perform,performance,372,"Conclusion; ----------. Cling is not just an interpreter, and is not just a REPL: it is a C/C++; JIT-compiler that can be embedded to your software for efficient incremental; execution of C++. Cling allows you to decide how much you want to compile; statically and how much to defer for the target platform. Cling enables; reflection and introspection information in high-performance systems such as; ROOT, or Xeus Jupyter, where it provides efficient code for performance-critical; tasks where hot-spot regions can be annotated with specific optimization; levels. You ca find more information regarding Cling's internal architecture,; functionment, user-cases, and Cling's based project into the References Chapter.; ",MatchSource.DOCS,interpreter/cling/docs/chapters/conclusion.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/conclusion.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/conclusion.rst:461,Performance,perform,performance-critical,461,"Conclusion; ----------. Cling is not just an interpreter, and is not just a REPL: it is a C/C++; JIT-compiler that can be embedded to your software for efficient incremental; execution of C++. Cling allows you to decide how much you want to compile; statically and how much to defer for the target platform. Cling enables; reflection and introspection information in high-performance systems such as; ROOT, or Xeus Jupyter, where it provides efficient code for performance-critical; tasks where hot-spot regions can be annotated with specific optimization; levels. You ca find more information regarding Cling's internal architecture,; functionment, user-cases, and Cling's based project into the References Chapter.; ",MatchSource.DOCS,interpreter/cling/docs/chapters/conclusion.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/conclusion.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/conclusion.rst:543,Performance,optimiz,optimization,543,"Conclusion; ----------. Cling is not just an interpreter, and is not just a REPL: it is a C/C++; JIT-compiler that can be embedded to your software for efficient incremental; execution of C++. Cling allows you to decide how much you want to compile; statically and how much to defer for the target platform. Cling enables; reflection and introspection information in high-performance systems such as; ROOT, or Xeus Jupyter, where it provides efficient code for performance-critical; tasks where hot-spot regions can be annotated with specific optimization; levels. You ca find more information regarding Cling's internal architecture,; functionment, user-cases, and Cling's based project into the References Chapter.; ",MatchSource.DOCS,interpreter/cling/docs/chapters/conclusion.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/conclusion.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/grammar.rst:621,Integrability,interface,interface,621,"Command Line; ============. Cling has its own command line, which looks like any other Unix shell. The; emacs-like command line editor is what we call interactive command line or; interactive shell. Once we start Cling it automatically includes several header files and its own; runtime universe. Thus it creates the minimal environment for the user to start. Grammar; -------. Cling is capable to parse everything that `Clang <https://clang.llvm.org/>`_ can; do. In addition, Cling can parse some interpreter-specific C++ extensions. Metaprocessor; -------------. Cling Metaprocessor provides convenient and easy to use interface for changing; the interpreter’s internal state or for executing handy commands. Cling provides; the following metaprocessor commands:. **syntax: .(command)**, where command is:. .. code:: bash. x filename.cxx; ; loads filename and calls void filename() if defined;. .. code:: bash. L library | filename.cxx; ; loads library or filename.cxx;. .. code:: bash. printAST; ; (DEBUG ONLY) shows the abstract syntax tree after each processed entity;. .. code:: bash. I path; ; adds an include path;. .. code:: bash. .@ . Cancels the multiline input;. .. code:: bash. .dynamicExtensions. Turns on cling's dynamic extensions. This in turn enables the dynamic lookup and; the late resolving of the identifier. With that option cling tries to heal the; compile-time failed lookups at runtime.; ",MatchSource.DOCS,interpreter/cling/docs/chapters/grammar.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/grammar.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/grammar.rst:843,Performance,load,loads,843,"Command Line; ============. Cling has its own command line, which looks like any other Unix shell. The; emacs-like command line editor is what we call interactive command line or; interactive shell. Once we start Cling it automatically includes several header files and its own; runtime universe. Thus it creates the minimal environment for the user to start. Grammar; -------. Cling is capable to parse everything that `Clang <https://clang.llvm.org/>`_ can; do. In addition, Cling can parse some interpreter-specific C++ extensions. Metaprocessor; -------------. Cling Metaprocessor provides convenient and easy to use interface for changing; the interpreter’s internal state or for executing handy commands. Cling provides; the following metaprocessor commands:. **syntax: .(command)**, where command is:. .. code:: bash. x filename.cxx; ; loads filename and calls void filename() if defined;. .. code:: bash. L library | filename.cxx; ; loads library or filename.cxx;. .. code:: bash. printAST; ; (DEBUG ONLY) shows the abstract syntax tree after each processed entity;. .. code:: bash. I path; ; adds an include path;. .. code:: bash. .@ . Cancels the multiline input;. .. code:: bash. .dynamicExtensions. Turns on cling's dynamic extensions. This in turn enables the dynamic lookup and; the late resolving of the identifier. With that option cling tries to heal the; compile-time failed lookups at runtime.; ",MatchSource.DOCS,interpreter/cling/docs/chapters/grammar.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/grammar.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/grammar.rst:941,Performance,load,loads,941,"Command Line; ============. Cling has its own command line, which looks like any other Unix shell. The; emacs-like command line editor is what we call interactive command line or; interactive shell. Once we start Cling it automatically includes several header files and its own; runtime universe. Thus it creates the minimal environment for the user to start. Grammar; -------. Cling is capable to parse everything that `Clang <https://clang.llvm.org/>`_ can; do. In addition, Cling can parse some interpreter-specific C++ extensions. Metaprocessor; -------------. Cling Metaprocessor provides convenient and easy to use interface for changing; the interpreter’s internal state or for executing handy commands. Cling provides; the following metaprocessor commands:. **syntax: .(command)**, where command is:. .. code:: bash. x filename.cxx; ; loads filename and calls void filename() if defined;. .. code:: bash. L library | filename.cxx; ; loads library or filename.cxx;. .. code:: bash. printAST; ; (DEBUG ONLY) shows the abstract syntax tree after each processed entity;. .. code:: bash. I path; ; adds an include path;. .. code:: bash. .@ . Cancels the multiline input;. .. code:: bash. .dynamicExtensions. Turns on cling's dynamic extensions. This in turn enables the dynamic lookup and; the late resolving of the identifier. With that option cling tries to heal the; compile-time failed lookups at runtime.; ",MatchSource.DOCS,interpreter/cling/docs/chapters/grammar.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/grammar.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/implementation.rst:666,Energy Efficiency,adapt,adapt,666,"Used Technology; ---------------. `LLVM <https://llvm.org/>`_ is a free, open-source compiler infrastructure under; the `Apache License 2.0 <https://www.apache.org/licenses/LICENSE-2.0>`_. It is; designed as a collection of tools including Front Ends parsers, Middle Ends; optimizers, and Back Ends to produce machine code out of those programs. `Clang <https://clang.llvm.org/>`_ is a front-end that uses a LLVM; license. Clang works by taking the source language (e.g. C++) and translating it; into an intermediate representation that is then received by the compiler back; end (i.e., the LLVM backend). Its library-based architecture makes it relatively; easy to adapt Clang and build new tools based on it. Cling inherits a number of; features from LLVM and Clang, such as: fast compiling and low memory use,; efficient C++ parsing, extremely clear and concise diagnostics, Just-In-Time; compilation, pluggable optimizers, and support for `GCC <https://gcc.gnu.org/>`_; extensions. Interpreters allow for exploration of software development at the rate of human; thought. Nevertheless, interpreter code can be slower than compiled code due to; the fact that translating code at run time adds to the overhead and therefore; causes the execution speed to be slower. This issue is overcome by exploiting; the *Just-In-Time* (`JIT; <https://en.wikipedia.org/wiki/Just-in-time_compilation>`_) compilation method,; which allows an efficient memory management (for example, by evaluating whether; a certain part of the source code is executed often, and then compile this part,; therefore reducing the overall execution time). With the JIT approach, the developer types the code in Cling's command; prompt. The input code is then lowered to Clang, where is compiled and; eventually transformed in order to attach specific behavior. Clang compiles then; the input into an AST representation, that is then lowered to LLVM IR, an; `intermediate language; <https://en.wikipedia.org/wiki/Common_Intermediate_L",MatchSource.DOCS,interpreter/cling/docs/chapters/implementation.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/implementation.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/implementation.rst:814,Energy Efficiency,efficient,efficient,814,"Used Technology; ---------------. `LLVM <https://llvm.org/>`_ is a free, open-source compiler infrastructure under; the `Apache License 2.0 <https://www.apache.org/licenses/LICENSE-2.0>`_. It is; designed as a collection of tools including Front Ends parsers, Middle Ends; optimizers, and Back Ends to produce machine code out of those programs. `Clang <https://clang.llvm.org/>`_ is a front-end that uses a LLVM; license. Clang works by taking the source language (e.g. C++) and translating it; into an intermediate representation that is then received by the compiler back; end (i.e., the LLVM backend). Its library-based architecture makes it relatively; easy to adapt Clang and build new tools based on it. Cling inherits a number of; features from LLVM and Clang, such as: fast compiling and low memory use,; efficient C++ parsing, extremely clear and concise diagnostics, Just-In-Time; compilation, pluggable optimizers, and support for `GCC <https://gcc.gnu.org/>`_; extensions. Interpreters allow for exploration of software development at the rate of human; thought. Nevertheless, interpreter code can be slower than compiled code due to; the fact that translating code at run time adds to the overhead and therefore; causes the execution speed to be slower. This issue is overcome by exploiting; the *Just-In-Time* (`JIT; <https://en.wikipedia.org/wiki/Just-in-time_compilation>`_) compilation method,; which allows an efficient memory management (for example, by evaluating whether; a certain part of the source code is executed often, and then compile this part,; therefore reducing the overall execution time). With the JIT approach, the developer types the code in Cling's command; prompt. The input code is then lowered to Clang, where is compiled and; eventually transformed in order to attach specific behavior. Clang compiles then; the input into an AST representation, that is then lowered to LLVM IR, an; `intermediate language; <https://en.wikipedia.org/wiki/Common_Intermediate_L",MatchSource.DOCS,interpreter/cling/docs/chapters/implementation.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/implementation.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/implementation.rst:1429,Energy Efficiency,efficient,efficient,1429,"lvm.org/>`_ is a front-end that uses a LLVM; license. Clang works by taking the source language (e.g. C++) and translating it; into an intermediate representation that is then received by the compiler back; end (i.e., the LLVM backend). Its library-based architecture makes it relatively; easy to adapt Clang and build new tools based on it. Cling inherits a number of; features from LLVM and Clang, such as: fast compiling and low memory use,; efficient C++ parsing, extremely clear and concise diagnostics, Just-In-Time; compilation, pluggable optimizers, and support for `GCC <https://gcc.gnu.org/>`_; extensions. Interpreters allow for exploration of software development at the rate of human; thought. Nevertheless, interpreter code can be slower than compiled code due to; the fact that translating code at run time adds to the overhead and therefore; causes the execution speed to be slower. This issue is overcome by exploiting; the *Just-In-Time* (`JIT; <https://en.wikipedia.org/wiki/Just-in-time_compilation>`_) compilation method,; which allows an efficient memory management (for example, by evaluating whether; a certain part of the source code is executed often, and then compile this part,; therefore reducing the overall execution time). With the JIT approach, the developer types the code in Cling's command; prompt. The input code is then lowered to Clang, where is compiled and; eventually transformed in order to attach specific behavior. Clang compiles then; the input into an AST representation, that is then lowered to LLVM IR, an; `intermediate language; <https://en.wikipedia.org/wiki/Common_Intermediate_Language>`_ that is not; understood by the computer. LLVM’s just-in-time compilation infrastructure; translates then the intermediate code into machine language (eg. Intel x86 or; NVPTX) when required for use. Cling's JIT compiler relies on LLVM's project; `ORC <https://llvm.org/docs/ORCv2.html>`_ (On Request Compilation) Application; Programming Interfaces (APIs).; ",MatchSource.DOCS,interpreter/cling/docs/chapters/implementation.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/implementation.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/implementation.rst:666,Modifiability,adapt,adapt,666,"Used Technology; ---------------. `LLVM <https://llvm.org/>`_ is a free, open-source compiler infrastructure under; the `Apache License 2.0 <https://www.apache.org/licenses/LICENSE-2.0>`_. It is; designed as a collection of tools including Front Ends parsers, Middle Ends; optimizers, and Back Ends to produce machine code out of those programs. `Clang <https://clang.llvm.org/>`_ is a front-end that uses a LLVM; license. Clang works by taking the source language (e.g. C++) and translating it; into an intermediate representation that is then received by the compiler back; end (i.e., the LLVM backend). Its library-based architecture makes it relatively; easy to adapt Clang and build new tools based on it. Cling inherits a number of; features from LLVM and Clang, such as: fast compiling and low memory use,; efficient C++ parsing, extremely clear and concise diagnostics, Just-In-Time; compilation, pluggable optimizers, and support for `GCC <https://gcc.gnu.org/>`_; extensions. Interpreters allow for exploration of software development at the rate of human; thought. Nevertheless, interpreter code can be slower than compiled code due to; the fact that translating code at run time adds to the overhead and therefore; causes the execution speed to be slower. This issue is overcome by exploiting; the *Just-In-Time* (`JIT; <https://en.wikipedia.org/wiki/Just-in-time_compilation>`_) compilation method,; which allows an efficient memory management (for example, by evaluating whether; a certain part of the source code is executed often, and then compile this part,; therefore reducing the overall execution time). With the JIT approach, the developer types the code in Cling's command; prompt. The input code is then lowered to Clang, where is compiled and; eventually transformed in order to attach specific behavior. Clang compiles then; the input into an AST representation, that is then lowered to LLVM IR, an; `intermediate language; <https://en.wikipedia.org/wiki/Common_Intermediate_L",MatchSource.DOCS,interpreter/cling/docs/chapters/implementation.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/implementation.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/implementation.rst:717,Modifiability,inherit,inherits,717,"Used Technology; ---------------. `LLVM <https://llvm.org/>`_ is a free, open-source compiler infrastructure under; the `Apache License 2.0 <https://www.apache.org/licenses/LICENSE-2.0>`_. It is; designed as a collection of tools including Front Ends parsers, Middle Ends; optimizers, and Back Ends to produce machine code out of those programs. `Clang <https://clang.llvm.org/>`_ is a front-end that uses a LLVM; license. Clang works by taking the source language (e.g. C++) and translating it; into an intermediate representation that is then received by the compiler back; end (i.e., the LLVM backend). Its library-based architecture makes it relatively; easy to adapt Clang and build new tools based on it. Cling inherits a number of; features from LLVM and Clang, such as: fast compiling and low memory use,; efficient C++ parsing, extremely clear and concise diagnostics, Just-In-Time; compilation, pluggable optimizers, and support for `GCC <https://gcc.gnu.org/>`_; extensions. Interpreters allow for exploration of software development at the rate of human; thought. Nevertheless, interpreter code can be slower than compiled code due to; the fact that translating code at run time adds to the overhead and therefore; causes the execution speed to be slower. This issue is overcome by exploiting; the *Just-In-Time* (`JIT; <https://en.wikipedia.org/wiki/Just-in-time_compilation>`_) compilation method,; which allows an efficient memory management (for example, by evaluating whether; a certain part of the source code is executed often, and then compile this part,; therefore reducing the overall execution time). With the JIT approach, the developer types the code in Cling's command; prompt. The input code is then lowered to Clang, where is compiled and; eventually transformed in order to attach specific behavior. Clang compiles then; the input into an AST representation, that is then lowered to LLVM IR, an; `intermediate language; <https://en.wikipedia.org/wiki/Common_Intermediate_L",MatchSource.DOCS,interpreter/cling/docs/chapters/implementation.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/implementation.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/implementation.rst:273,Performance,optimiz,optimizers,273,"Used Technology; ---------------. `LLVM <https://llvm.org/>`_ is a free, open-source compiler infrastructure under; the `Apache License 2.0 <https://www.apache.org/licenses/LICENSE-2.0>`_. It is; designed as a collection of tools including Front Ends parsers, Middle Ends; optimizers, and Back Ends to produce machine code out of those programs. `Clang <https://clang.llvm.org/>`_ is a front-end that uses a LLVM; license. Clang works by taking the source language (e.g. C++) and translating it; into an intermediate representation that is then received by the compiler back; end (i.e., the LLVM backend). Its library-based architecture makes it relatively; easy to adapt Clang and build new tools based on it. Cling inherits a number of; features from LLVM and Clang, such as: fast compiling and low memory use,; efficient C++ parsing, extremely clear and concise diagnostics, Just-In-Time; compilation, pluggable optimizers, and support for `GCC <https://gcc.gnu.org/>`_; extensions. Interpreters allow for exploration of software development at the rate of human; thought. Nevertheless, interpreter code can be slower than compiled code due to; the fact that translating code at run time adds to the overhead and therefore; causes the execution speed to be slower. This issue is overcome by exploiting; the *Just-In-Time* (`JIT; <https://en.wikipedia.org/wiki/Just-in-time_compilation>`_) compilation method,; which allows an efficient memory management (for example, by evaluating whether; a certain part of the source code is executed often, and then compile this part,; therefore reducing the overall execution time). With the JIT approach, the developer types the code in Cling's command; prompt. The input code is then lowered to Clang, where is compiled and; eventually transformed in order to attach specific behavior. Clang compiles then; the input into an AST representation, that is then lowered to LLVM IR, an; `intermediate language; <https://en.wikipedia.org/wiki/Common_Intermediate_L",MatchSource.DOCS,interpreter/cling/docs/chapters/implementation.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/implementation.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/implementation.rst:915,Performance,optimiz,optimizers,915,"Used Technology; ---------------. `LLVM <https://llvm.org/>`_ is a free, open-source compiler infrastructure under; the `Apache License 2.0 <https://www.apache.org/licenses/LICENSE-2.0>`_. It is; designed as a collection of tools including Front Ends parsers, Middle Ends; optimizers, and Back Ends to produce machine code out of those programs. `Clang <https://clang.llvm.org/>`_ is a front-end that uses a LLVM; license. Clang works by taking the source language (e.g. C++) and translating it; into an intermediate representation that is then received by the compiler back; end (i.e., the LLVM backend). Its library-based architecture makes it relatively; easy to adapt Clang and build new tools based on it. Cling inherits a number of; features from LLVM and Clang, such as: fast compiling and low memory use,; efficient C++ parsing, extremely clear and concise diagnostics, Just-In-Time; compilation, pluggable optimizers, and support for `GCC <https://gcc.gnu.org/>`_; extensions. Interpreters allow for exploration of software development at the rate of human; thought. Nevertheless, interpreter code can be slower than compiled code due to; the fact that translating code at run time adds to the overhead and therefore; causes the execution speed to be slower. This issue is overcome by exploiting; the *Just-In-Time* (`JIT; <https://en.wikipedia.org/wiki/Just-in-time_compilation>`_) compilation method,; which allows an efficient memory management (for example, by evaluating whether; a certain part of the source code is executed often, and then compile this part,; therefore reducing the overall execution time). With the JIT approach, the developer types the code in Cling's command; prompt. The input code is then lowered to Clang, where is compiled and; eventually transformed in order to attach specific behavior. Clang compiles then; the input into an AST representation, that is then lowered to LLVM IR, an; `intermediate language; <https://en.wikipedia.org/wiki/Common_Intermediate_L",MatchSource.DOCS,interpreter/cling/docs/chapters/implementation.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/implementation.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/implementation.rst:847,Usability,clear,clear,847,"Used Technology; ---------------. `LLVM <https://llvm.org/>`_ is a free, open-source compiler infrastructure under; the `Apache License 2.0 <https://www.apache.org/licenses/LICENSE-2.0>`_. It is; designed as a collection of tools including Front Ends parsers, Middle Ends; optimizers, and Back Ends to produce machine code out of those programs. `Clang <https://clang.llvm.org/>`_ is a front-end that uses a LLVM; license. Clang works by taking the source language (e.g. C++) and translating it; into an intermediate representation that is then received by the compiler back; end (i.e., the LLVM backend). Its library-based architecture makes it relatively; easy to adapt Clang and build new tools based on it. Cling inherits a number of; features from LLVM and Clang, such as: fast compiling and low memory use,; efficient C++ parsing, extremely clear and concise diagnostics, Just-In-Time; compilation, pluggable optimizers, and support for `GCC <https://gcc.gnu.org/>`_; extensions. Interpreters allow for exploration of software development at the rate of human; thought. Nevertheless, interpreter code can be slower than compiled code due to; the fact that translating code at run time adds to the overhead and therefore; causes the execution speed to be slower. This issue is overcome by exploiting; the *Just-In-Time* (`JIT; <https://en.wikipedia.org/wiki/Just-in-time_compilation>`_) compilation method,; which allows an efficient memory management (for example, by evaluating whether; a certain part of the source code is executed often, and then compile this part,; therefore reducing the overall execution time). With the JIT approach, the developer types the code in Cling's command; prompt. The input code is then lowered to Clang, where is compiled and; eventually transformed in order to attach specific behavior. Clang compiles then; the input into an AST representation, that is then lowered to LLVM IR, an; `intermediate language; <https://en.wikipedia.org/wiki/Common_Intermediate_L",MatchSource.DOCS,interpreter/cling/docs/chapters/implementation.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/implementation.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/interactivity.rst:2060,Availability,robust,robustness,2060,"esponds to a developers’ intuitions, allowing them to make changes in; their code, and to see the result of these changes without interrupting the; running program. Interactive programming gives programmers the freedom to; explore different scenarios while developing software, writing one expression; at a time, figuring out what to do next at each step, and enabling them to; quickly identify and fix bugs whenever they arise. As an example, the; High-Energy Physics community includes professionals with a variety of; backgrounds, including physicists, nuclear engineers, and software; engineers. Cling allows for interactive data analysis in `ROOT; <https://root.cern/>`_ by giving researchers a way to prototype their C++ code,; allowing them to tailor it to the particular scope of the analysis they want to; pursue on a particular set of data before being added to the main framework. **Interpreted language** is a way to achieve interactive programming. In; statically compiled language, all source code is converted into native machine; code and then executed by the processor before being run. An interpreted; language instead runs through source programs line by line, taking an; executable segment of source code, turning it into machine code, and then; executing it. With this approach, when a change is made by the programmer, the; interpreter will convey it without the need for the entire source code to be; manually compiled. Interpreted languages are flexible, and offer features like; dynamic typing and smaller program size. **Cling** is not an interpreter, it is a Just-In-Time (JIT) compiler that feels; like an interpreter, and allows C++, a language designed to be compiled, to be; interpreted. When using Cling, the programmer benefits from both the power of; C++ language, such as high-performance, robustness, fastness, efficiency,; versatility, and the capability of an interpreter, which allows for interactive; exploration and on-the-fly inspection of the source-code.; ",MatchSource.DOCS,interpreter/cling/docs/chapters/interactivity.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/interactivity.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/interactivity.rst:2010,Energy Efficiency,power,power,2010,"esponds to a developers’ intuitions, allowing them to make changes in; their code, and to see the result of these changes without interrupting the; running program. Interactive programming gives programmers the freedom to; explore different scenarios while developing software, writing one expression; at a time, figuring out what to do next at each step, and enabling them to; quickly identify and fix bugs whenever they arise. As an example, the; High-Energy Physics community includes professionals with a variety of; backgrounds, including physicists, nuclear engineers, and software; engineers. Cling allows for interactive data analysis in `ROOT; <https://root.cern/>`_ by giving researchers a way to prototype their C++ code,; allowing them to tailor it to the particular scope of the analysis they want to; pursue on a particular set of data before being added to the main framework. **Interpreted language** is a way to achieve interactive programming. In; statically compiled language, all source code is converted into native machine; code and then executed by the processor before being run. An interpreted; language instead runs through source programs line by line, taking an; executable segment of source code, turning it into machine code, and then; executing it. With this approach, when a change is made by the programmer, the; interpreter will convey it without the need for the entire source code to be; manually compiled. Interpreted languages are flexible, and offer features like; dynamic typing and smaller program size. **Cling** is not an interpreter, it is a Just-In-Time (JIT) compiler that feels; like an interpreter, and allows C++, a language designed to be compiled, to be; interpreted. When using Cling, the programmer benefits from both the power of; C++ language, such as high-performance, robustness, fastness, efficiency,; versatility, and the capability of an interpreter, which allows for interactive; exploration and on-the-fly inspection of the source-code.; ",MatchSource.DOCS,interpreter/cling/docs/chapters/interactivity.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/interactivity.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/interactivity.rst:1704,Modifiability,flexible,flexible,1704,"esponds to a developers’ intuitions, allowing them to make changes in; their code, and to see the result of these changes without interrupting the; running program. Interactive programming gives programmers the freedom to; explore different scenarios while developing software, writing one expression; at a time, figuring out what to do next at each step, and enabling them to; quickly identify and fix bugs whenever they arise. As an example, the; High-Energy Physics community includes professionals with a variety of; backgrounds, including physicists, nuclear engineers, and software; engineers. Cling allows for interactive data analysis in `ROOT; <https://root.cern/>`_ by giving researchers a way to prototype their C++ code,; allowing them to tailor it to the particular scope of the analysis they want to; pursue on a particular set of data before being added to the main framework. **Interpreted language** is a way to achieve interactive programming. In; statically compiled language, all source code is converted into native machine; code and then executed by the processor before being run. An interpreted; language instead runs through source programs line by line, taking an; executable segment of source code, turning it into machine code, and then; executing it. With this approach, when a change is made by the programmer, the; interpreter will convey it without the need for the entire source code to be; manually compiled. Interpreted languages are flexible, and offer features like; dynamic typing and smaller program size. **Cling** is not an interpreter, it is a Just-In-Time (JIT) compiler that feels; like an interpreter, and allows C++, a language designed to be compiled, to be; interpreted. When using Cling, the programmer benefits from both the power of; C++ language, such as high-performance, robustness, fastness, efficiency,; versatility, and the capability of an interpreter, which allows for interactive; exploration and on-the-fly inspection of the source-code.; ",MatchSource.DOCS,interpreter/cling/docs/chapters/interactivity.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/interactivity.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/interactivity.rst:2047,Performance,perform,performance,2047,"esponds to a developers’ intuitions, allowing them to make changes in; their code, and to see the result of these changes without interrupting the; running program. Interactive programming gives programmers the freedom to; explore different scenarios while developing software, writing one expression; at a time, figuring out what to do next at each step, and enabling them to; quickly identify and fix bugs whenever they arise. As an example, the; High-Energy Physics community includes professionals with a variety of; backgrounds, including physicists, nuclear engineers, and software; engineers. Cling allows for interactive data analysis in `ROOT; <https://root.cern/>`_ by giving researchers a way to prototype their C++ code,; allowing them to tailor it to the particular scope of the analysis they want to; pursue on a particular set of data before being added to the main framework. **Interpreted language** is a way to achieve interactive programming. In; statically compiled language, all source code is converted into native machine; code and then executed by the processor before being run. An interpreted; language instead runs through source programs line by line, taking an; executable segment of source code, turning it into machine code, and then; executing it. With this approach, when a change is made by the programmer, the; interpreter will convey it without the need for the entire source code to be; manually compiled. Interpreted languages are flexible, and offer features like; dynamic typing and smaller program size. **Cling** is not an interpreter, it is a Just-In-Time (JIT) compiler that feels; like an interpreter, and allows C++, a language designed to be compiled, to be; interpreted. When using Cling, the programmer benefits from both the power of; C++ language, such as high-performance, robustness, fastness, efficiency,; versatility, and the capability of an interpreter, which allows for interactive; exploration and on-the-fly inspection of the source-code.; ",MatchSource.DOCS,interpreter/cling/docs/chapters/interactivity.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/interactivity.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/interactivity.rst:260,Usability,intuit,intuitions,260,"Interactivity in C++ with Cling; -------------------------------. **Interactive programming** is a programming approach that allows developers to; change and modify the program as it runs. The final result is a program that; actively responds to a developers’ intuitions, allowing them to make changes in; their code, and to see the result of these changes without interrupting the; running program. Interactive programming gives programmers the freedom to; explore different scenarios while developing software, writing one expression; at a time, figuring out what to do next at each step, and enabling them to; quickly identify and fix bugs whenever they arise. As an example, the; High-Energy Physics community includes professionals with a variety of; backgrounds, including physicists, nuclear engineers, and software; engineers. Cling allows for interactive data analysis in `ROOT; <https://root.cern/>`_ by giving researchers a way to prototype their C++ code,; allowing them to tailor it to the particular scope of the analysis they want to; pursue on a particular set of data before being added to the main framework. **Interpreted language** is a way to achieve interactive programming. In; statically compiled language, all source code is converted into native machine; code and then executed by the processor before being run. An interpreted; language instead runs through source programs line by line, taking an; executable segment of source code, turning it into machine code, and then; executing it. With this approach, when a change is made by the programmer, the; interpreter will convey it without the need for the entire source code to be; manually compiled. Interpreted languages are flexible, and offer features like; dynamic typing and smaller program size. **Cling** is not an interpreter, it is a Just-In-Time (JIT) compiler that feels; like an interpreter, and allows C++, a language designed to be compiled, to be; interpreted. When using Cling, the programmer benefits from ",MatchSource.DOCS,interpreter/cling/docs/chapters/interactivity.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/interactivity.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst:805,Availability,error,errors,805,"Literature; =====. .. list-table:: What is Cling?; :widths: 25 25 50; :header-rows: 1. * - Link; - Info ; - Description; * - `Relaxing the One Definition Rule in Interpreted C++ <https://dl.acm.org/doi/10.1145/3377555.3377901>`_; - *Javier Lopez Gomez et al.*; ; 29th International Conference on Compiler Construction 2020; - This paper discusses how Cling enables redefinitions of C++ entities at the prompt, and the implications of interpreting C++ and the One Definition Rule (ODR) in C++; * - `Cling – The New Interactive Interpreter for ROOT 6 <https://iopscience.iop.org/article/10.1088/1742-6596/396/5/052071>`_; - *V Vasilev et al* 2012 J. Phys.: Conf. Ser. 396 052071; - This paper describes the link between Cling and ROOT. The concepts of REPL and JIT compilation. Cling’s methods for handling errors, expression evaluation, streaming out of execution results, runtime dynamism.; * - `Interactive, Introspected C++ at CERN <https://www.youtube.com/watch?v=K2KqEV866Ro>`_; - *V Vasilev*, CERN PH-SFT, 2013; - Vassil Vasilev (Princeton University) explains how Cling enables interactivity in C++, and illustrates the type introspection mechanism provided by the interpreter.; * - `Introducing Cling, a C++ Interpreter Based on Clang/LLVM <https://www.youtube.com/watch?v=f9Xfh8pv3Fs>`_; - *Axel Naumann* 2012 Googletechtalks; - Axel Naumann (CERN) discusses Cling’s most relevant features: abstract syntax tree (AST) production, wrapped functions, global initialization of a function, delay expression evaluation at runtime, and dynamic scopes.; * - `Creating Cling, an interactive interpreter interface <https://www.youtube.com/watch?v=BjmGOMJWeAo>`_; - *Axel Naumann* 2010 LLVM Developers’ meeting; - This presentation introduces Cling, an ahead-of-time compiler that extends C++ for ease of use as an interpreter.; . ; .. list-table:: Demos, tutorials, Cling’s ecosystem:; :widths: 25 25 50; :header-rows: 1. * - Link; - Info ; - Description; * - `Cling integration | CLion <https://www.je",MatchSource.DOCS,interpreter/cling/docs/chapters/references.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst:3772,Availability,error,error,3772,"d-just-interpreting-cpp/>`_; - *Vassil Vassilev* 2021 The LLVM Project Blog; - This blog page discusses how Cling enables template Instantiation on demand, language interoperability on demand, interpreter/compiler as a service, plugins extension.; * - `TinySpec-Cling <https://github.com/nwoeanhinnogaehr/tinyspec-cling>`_; - Noah Weninger 2020; - A tiny C++ live-coded overlap-add (re)synthesizer for Linux, which uses Cling to add REPL-like functionality for C++ code.; * - `Interactive C++ for Data Science <https://blog.llvm.org/posts/2020-12-21-interactive-cpp-for-data-science/>`_; - *Vassil Vassilev,* *David Lange,* *Simeon Ehrig,* *Sylvain Corlay* 2020 The LLVM Project Blog; - Cling enables eval-style programming for Data Science applications. Examples of ROOT and Xeus-Cling for data science are shown.; * - `Interactive C++ with Cling <https://blog.llvm.org/posts/2020-11-30-interactive-cpp-with-cling/>`_; - *Vassil Vassilev* 2020 The LLVM Project Blog; - This blog page briefly discusses the concept of interactive C++ by presenting Cling’s main features, such as wrapper functions, entity redefinition, error recovery. ; * - `Using the Cling C++ Interpreter on the Bela Platform <https://gist.github.com/jarmitage/6e411ae8746c04d6ecbee1cbc1ebdcd4>`_; - Jack Armitage 2019; - Cling has been installed on a BeagleBoard to bring live coding to the Bela interactive audio platform.; * - `Implementation of GlobalModuleIndex in ROOT and Cling <https://indico.cern.ch/event/840376/contributions/3525646/attachments/1895398/3127159/GSoC_Presentation__GMI.pdf>`_; - *Arpitha Raghunandan* 2012 Google Summer of Code GSoC; - GlobalModuleIndex can be used for improving ROOT’s and Cling’s performance ; * - `Example project using cling as library <https://github.com/root-project/cling/tree/master/tools/demo>`_; - *Axel Naumann* 2016 GitHub; - This video showcases how to use Cling as a library, and shows how to set up a simple CMake configuration that uses Cling.; * - `Cling C++ interpreter t",MatchSource.DOCS,interpreter/cling/docs/chapters/references.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst:3778,Availability,recover,recovery,3778,"d-just-interpreting-cpp/>`_; - *Vassil Vassilev* 2021 The LLVM Project Blog; - This blog page discusses how Cling enables template Instantiation on demand, language interoperability on demand, interpreter/compiler as a service, plugins extension.; * - `TinySpec-Cling <https://github.com/nwoeanhinnogaehr/tinyspec-cling>`_; - Noah Weninger 2020; - A tiny C++ live-coded overlap-add (re)synthesizer for Linux, which uses Cling to add REPL-like functionality for C++ code.; * - `Interactive C++ for Data Science <https://blog.llvm.org/posts/2020-12-21-interactive-cpp-for-data-science/>`_; - *Vassil Vassilev,* *David Lange,* *Simeon Ehrig,* *Sylvain Corlay* 2020 The LLVM Project Blog; - Cling enables eval-style programming for Data Science applications. Examples of ROOT and Xeus-Cling for data science are shown.; * - `Interactive C++ with Cling <https://blog.llvm.org/posts/2020-11-30-interactive-cpp-with-cling/>`_; - *Vassil Vassilev* 2020 The LLVM Project Blog; - This blog page briefly discusses the concept of interactive C++ by presenting Cling’s main features, such as wrapper functions, entity redefinition, error recovery. ; * - `Using the Cling C++ Interpreter on the Bela Platform <https://gist.github.com/jarmitage/6e411ae8746c04d6ecbee1cbc1ebdcd4>`_; - Jack Armitage 2019; - Cling has been installed on a BeagleBoard to bring live coding to the Bela interactive audio platform.; * - `Implementation of GlobalModuleIndex in ROOT and Cling <https://indico.cern.ch/event/840376/contributions/3525646/attachments/1895398/3127159/GSoC_Presentation__GMI.pdf>`_; - *Arpitha Raghunandan* 2012 Google Summer of Code GSoC; - GlobalModuleIndex can be used for improving ROOT’s and Cling’s performance ; * - `Example project using cling as library <https://github.com/root-project/cling/tree/master/tools/demo>`_; - *Axel Naumann* 2016 GitHub; - This video showcases how to use Cling as a library, and shows how to set up a simple CMake configuration that uses Cling.; * - `Cling C++ interpreter t",MatchSource.DOCS,interpreter/cling/docs/chapters/references.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst:1966,Deployability,integrat,integration,1966,"watch?v=K2KqEV866Ro>`_; - *V Vasilev*, CERN PH-SFT, 2013; - Vassil Vasilev (Princeton University) explains how Cling enables interactivity in C++, and illustrates the type introspection mechanism provided by the interpreter.; * - `Introducing Cling, a C++ Interpreter Based on Clang/LLVM <https://www.youtube.com/watch?v=f9Xfh8pv3Fs>`_; - *Axel Naumann* 2012 Googletechtalks; - Axel Naumann (CERN) discusses Cling’s most relevant features: abstract syntax tree (AST) production, wrapped functions, global initialization of a function, delay expression evaluation at runtime, and dynamic scopes.; * - `Creating Cling, an interactive interpreter interface <https://www.youtube.com/watch?v=BjmGOMJWeAo>`_; - *Axel Naumann* 2010 LLVM Developers’ meeting; - This presentation introduces Cling, an ahead-of-time compiler that extends C++ for ease of use as an interpreter.; . ; .. list-table:: Demos, tutorials, Cling’s ecosystem:; :widths: 25 25 50; :header-rows: 1. * - Link; - Info ; - Description; * - `Cling integration | CLion <https://www.jetbrains.com/help/clion/cling-integration.html#install-cling>`_; - 2022.2 Version; - CLion uses Cling to integrate the `Quick Documentation <https://www.jetbrains.com/help/clion/2022.2/viewing-inline-documentation.html>`_ popup by allowing you to view the value of the expressions evaluated at compile time.; * - `Interactive C++ for Data Science <https://www.youtube.com/watch?v=23E0S3miWB0&t=2716s>`_; - *Vassil Vassilev* 2021 CppCon (The C++ Conference); - In this video, the author discusses how Cling enables interactive C++ for Data Science projects. ; * - `Cling -- Beyond Just Interpreting C++ <https://blog.llvm.org/posts/2021-03-25-cling-beyond-just-interpreting-cpp/>`_; - *Vassil Vassilev* 2021 The LLVM Project Blog; - This blog page discusses how Cling enables template Instantiation on demand, language interoperability on demand, interpreter/compiler as a service, plugins extension.; * - `TinySpec-Cling <https://github.com/nwoeanhinnogaehr/ti",MatchSource.DOCS,interpreter/cling/docs/chapters/references.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst:2030,Deployability,integrat,integration,2030," Vasilev (Princeton University) explains how Cling enables interactivity in C++, and illustrates the type introspection mechanism provided by the interpreter.; * - `Introducing Cling, a C++ Interpreter Based on Clang/LLVM <https://www.youtube.com/watch?v=f9Xfh8pv3Fs>`_; - *Axel Naumann* 2012 Googletechtalks; - Axel Naumann (CERN) discusses Cling’s most relevant features: abstract syntax tree (AST) production, wrapped functions, global initialization of a function, delay expression evaluation at runtime, and dynamic scopes.; * - `Creating Cling, an interactive interpreter interface <https://www.youtube.com/watch?v=BjmGOMJWeAo>`_; - *Axel Naumann* 2010 LLVM Developers’ meeting; - This presentation introduces Cling, an ahead-of-time compiler that extends C++ for ease of use as an interpreter.; . ; .. list-table:: Demos, tutorials, Cling’s ecosystem:; :widths: 25 25 50; :header-rows: 1. * - Link; - Info ; - Description; * - `Cling integration | CLion <https://www.jetbrains.com/help/clion/cling-integration.html#install-cling>`_; - 2022.2 Version; - CLion uses Cling to integrate the `Quick Documentation <https://www.jetbrains.com/help/clion/2022.2/viewing-inline-documentation.html>`_ popup by allowing you to view the value of the expressions evaluated at compile time.; * - `Interactive C++ for Data Science <https://www.youtube.com/watch?v=23E0S3miWB0&t=2716s>`_; - *Vassil Vassilev* 2021 CppCon (The C++ Conference); - In this video, the author discusses how Cling enables interactive C++ for Data Science projects. ; * - `Cling -- Beyond Just Interpreting C++ <https://blog.llvm.org/posts/2021-03-25-cling-beyond-just-interpreting-cpp/>`_; - *Vassil Vassilev* 2021 The LLVM Project Blog; - This blog page discusses how Cling enables template Instantiation on demand, language interoperability on demand, interpreter/compiler as a service, plugins extension.; * - `TinySpec-Cling <https://github.com/nwoeanhinnogaehr/tinyspec-cling>`_; - Noah Weninger 2020; - A tiny C++ live-coded ove",MatchSource.DOCS,interpreter/cling/docs/chapters/references.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst:2047,Deployability,install,install-cling,2047,"explains how Cling enables interactivity in C++, and illustrates the type introspection mechanism provided by the interpreter.; * - `Introducing Cling, a C++ Interpreter Based on Clang/LLVM <https://www.youtube.com/watch?v=f9Xfh8pv3Fs>`_; - *Axel Naumann* 2012 Googletechtalks; - Axel Naumann (CERN) discusses Cling’s most relevant features: abstract syntax tree (AST) production, wrapped functions, global initialization of a function, delay expression evaluation at runtime, and dynamic scopes.; * - `Creating Cling, an interactive interpreter interface <https://www.youtube.com/watch?v=BjmGOMJWeAo>`_; - *Axel Naumann* 2010 LLVM Developers’ meeting; - This presentation introduces Cling, an ahead-of-time compiler that extends C++ for ease of use as an interpreter.; . ; .. list-table:: Demos, tutorials, Cling’s ecosystem:; :widths: 25 25 50; :header-rows: 1. * - Link; - Info ; - Description; * - `Cling integration | CLion <https://www.jetbrains.com/help/clion/cling-integration.html#install-cling>`_; - 2022.2 Version; - CLion uses Cling to integrate the `Quick Documentation <https://www.jetbrains.com/help/clion/2022.2/viewing-inline-documentation.html>`_ popup by allowing you to view the value of the expressions evaluated at compile time.; * - `Interactive C++ for Data Science <https://www.youtube.com/watch?v=23E0S3miWB0&t=2716s>`_; - *Vassil Vassilev* 2021 CppCon (The C++ Conference); - In this video, the author discusses how Cling enables interactive C++ for Data Science projects. ; * - `Cling -- Beyond Just Interpreting C++ <https://blog.llvm.org/posts/2021-03-25-cling-beyond-just-interpreting-cpp/>`_; - *Vassil Vassilev* 2021 The LLVM Project Blog; - This blog page discusses how Cling enables template Instantiation on demand, language interoperability on demand, interpreter/compiler as a service, plugins extension.; * - `TinySpec-Cling <https://github.com/nwoeanhinnogaehr/tinyspec-cling>`_; - Noah Weninger 2020; - A tiny C++ live-coded overlap-add (re)synthesizer for Li",MatchSource.DOCS,interpreter/cling/docs/chapters/references.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst:2105,Deployability,integrat,integrate,2105,"lustrates the type introspection mechanism provided by the interpreter.; * - `Introducing Cling, a C++ Interpreter Based on Clang/LLVM <https://www.youtube.com/watch?v=f9Xfh8pv3Fs>`_; - *Axel Naumann* 2012 Googletechtalks; - Axel Naumann (CERN) discusses Cling’s most relevant features: abstract syntax tree (AST) production, wrapped functions, global initialization of a function, delay expression evaluation at runtime, and dynamic scopes.; * - `Creating Cling, an interactive interpreter interface <https://www.youtube.com/watch?v=BjmGOMJWeAo>`_; - *Axel Naumann* 2010 LLVM Developers’ meeting; - This presentation introduces Cling, an ahead-of-time compiler that extends C++ for ease of use as an interpreter.; . ; .. list-table:: Demos, tutorials, Cling’s ecosystem:; :widths: 25 25 50; :header-rows: 1. * - Link; - Info ; - Description; * - `Cling integration | CLion <https://www.jetbrains.com/help/clion/cling-integration.html#install-cling>`_; - 2022.2 Version; - CLion uses Cling to integrate the `Quick Documentation <https://www.jetbrains.com/help/clion/2022.2/viewing-inline-documentation.html>`_ popup by allowing you to view the value of the expressions evaluated at compile time.; * - `Interactive C++ for Data Science <https://www.youtube.com/watch?v=23E0S3miWB0&t=2716s>`_; - *Vassil Vassilev* 2021 CppCon (The C++ Conference); - In this video, the author discusses how Cling enables interactive C++ for Data Science projects. ; * - `Cling -- Beyond Just Interpreting C++ <https://blog.llvm.org/posts/2021-03-25-cling-beyond-just-interpreting-cpp/>`_; - *Vassil Vassilev* 2021 The LLVM Project Blog; - This blog page discusses how Cling enables template Instantiation on demand, language interoperability on demand, interpreter/compiler as a service, plugins extension.; * - `TinySpec-Cling <https://github.com/nwoeanhinnogaehr/tinyspec-cling>`_; - Noah Weninger 2020; - A tiny C++ live-coded overlap-add (re)synthesizer for Linux, which uses Cling to add REPL-like functionality for",MatchSource.DOCS,interpreter/cling/docs/chapters/references.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst:3959,Deployability,install,installed,3959,"/tinyspec-cling>`_; - Noah Weninger 2020; - A tiny C++ live-coded overlap-add (re)synthesizer for Linux, which uses Cling to add REPL-like functionality for C++ code.; * - `Interactive C++ for Data Science <https://blog.llvm.org/posts/2020-12-21-interactive-cpp-for-data-science/>`_; - *Vassil Vassilev,* *David Lange,* *Simeon Ehrig,* *Sylvain Corlay* 2020 The LLVM Project Blog; - Cling enables eval-style programming for Data Science applications. Examples of ROOT and Xeus-Cling for data science are shown.; * - `Interactive C++ with Cling <https://blog.llvm.org/posts/2020-11-30-interactive-cpp-with-cling/>`_; - *Vassil Vassilev* 2020 The LLVM Project Blog; - This blog page briefly discusses the concept of interactive C++ by presenting Cling’s main features, such as wrapper functions, entity redefinition, error recovery. ; * - `Using the Cling C++ Interpreter on the Bela Platform <https://gist.github.com/jarmitage/6e411ae8746c04d6ecbee1cbc1ebdcd4>`_; - Jack Armitage 2019; - Cling has been installed on a BeagleBoard to bring live coding to the Bela interactive audio platform.; * - `Implementation of GlobalModuleIndex in ROOT and Cling <https://indico.cern.ch/event/840376/contributions/3525646/attachments/1895398/3127159/GSoC_Presentation__GMI.pdf>`_; - *Arpitha Raghunandan* 2012 Google Summer of Code GSoC; - GlobalModuleIndex can be used for improving ROOT’s and Cling’s performance ; * - `Example project using cling as library <https://github.com/root-project/cling/tree/master/tools/demo>`_; - *Axel Naumann* 2016 GitHub; - This video showcases how to use Cling as a library, and shows how to set up a simple CMake configuration that uses Cling.; * - `Cling C++ interpreter testdrive <https://www.youtube.com/watch?v=1IGTHusaJ18>`_; - *Mika* 2015 Youtube; - In this tutorial, a developer tries Cling for the first time by uploading a few simple C++ user-cases onto Cling, involving also the loading of external files; * - `Building an Order Book in C++ <https://www.youtube.com/w",MatchSource.DOCS,interpreter/cling/docs/chapters/references.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst:4594,Deployability,configurat,configuration,4594,"g/posts/2020-11-30-interactive-cpp-with-cling/>`_; - *Vassil Vassilev* 2020 The LLVM Project Blog; - This blog page briefly discusses the concept of interactive C++ by presenting Cling’s main features, such as wrapper functions, entity redefinition, error recovery. ; * - `Using the Cling C++ Interpreter on the Bela Platform <https://gist.github.com/jarmitage/6e411ae8746c04d6ecbee1cbc1ebdcd4>`_; - Jack Armitage 2019; - Cling has been installed on a BeagleBoard to bring live coding to the Bela interactive audio platform.; * - `Implementation of GlobalModuleIndex in ROOT and Cling <https://indico.cern.ch/event/840376/contributions/3525646/attachments/1895398/3127159/GSoC_Presentation__GMI.pdf>`_; - *Arpitha Raghunandan* 2012 Google Summer of Code GSoC; - GlobalModuleIndex can be used for improving ROOT’s and Cling’s performance ; * - `Example project using cling as library <https://github.com/root-project/cling/tree/master/tools/demo>`_; - *Axel Naumann* 2016 GitHub; - This video showcases how to use Cling as a library, and shows how to set up a simple CMake configuration that uses Cling.; * - `Cling C++ interpreter testdrive <https://www.youtube.com/watch?v=1IGTHusaJ18>`_; - *Mika* 2015 Youtube; - In this tutorial, a developer tries Cling for the first time by uploading a few simple C++ user-cases onto Cling, involving also the loading of external files; * - `Building an Order Book in C++ <https://www.youtube.com/watch?v=fxN4xEZvrxI>`_; - *Dimitri Nesteruk* 2015 Youtube; - This demo shows how to build a simple order book using C++, CLion, Google Test and, of course, Cling. ; * - `Cling C++ interpreter testdrive <https://www.youtube.com/watch?v=1IGTHusaJ18>`_; - Dimitri Nesteruk 2015 Youtube; - This tutorial describes Cling’s general features. You will learn how to start Cling on Ubuntu, how to write a simple expression (N=5, N++) and how to define a Class for calculating body mass index. ; * - `Cling Interactive OpenGL Demo <https://www.youtube.com/watch?v=eoIuqLNvzFs>",MatchSource.DOCS,interpreter/cling/docs/chapters/references.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst:6976,Energy Efficiency,adapt,adapted,6976,"; * - `Compiler Research - Calling C++ libraries from a D-written DSL: A cling/cppyy-based approach <https://www.youtube.com/watch?v=7teqrCNzrD8>`_; - *Alexandru Militaru* 2021 Compiler-Research Meeting; - This video presents D and C++ interoperability through SIL-Cling architecture. .. list-table:: Interactive CUDA C++ with Cling:; :widths: 25 25 50; :header-rows: 1. * - Link; - Info ; - Description; * - `Adding CUDA® Support to Cling: JIT Compile to GPUs <https://www.youtube.com/watch?v=XjjZRhiFDVs>`_; - *Simeon Ehrig* 2020 LLVM Developer Meeting; - Interactive CUDA-C++ through Cling is presented. Cling-CUDA architecture is discussed in detail, and an example of interactive simulation for laser plasma applications is shown. . .. list-table:: C++ in Jupyter Notebook - Xeus Cling:; :widths: 25 25 50; :header-rows: 1; ; * - Link; - Info ; - Description; * - `Interactive C++ code development using C++Explorer and GitHub Classroom for educational purposes <https://www.youtube.com/watch?v=HBgF2Yr0foA>`_; - *Patrick Diehl* 2020 Youtube; - C++Explorer is a novel teaching environment based on Jupyterhub and Cling, adapted to teaching C++ programming and source code management.; * - `Deep dive into the Xeus-based Cling kernel for Jupyter <https://www.youtube.com/watch?v=kx3wvKk4Qss>`_; - *Vassil Vassilev* 2021 Youtube; - Xeus-Cling is a Cling-based notebook kernel which delivers interactive C++. ; * - `Xeus-Cling: Run C++ code in Jupyter Notebook <https://www.youtube.com/watch?v=4fcKlJ_5QQk>`_ ; - *LearnOpenCV* 2019 Youtube; - In this demo, you will learn an example of C++ code in Jupyter Notebook using Xeus-Cling kernel. . .. list-table:: Clad:; :widths: 25 25 50; :header-rows: 1; ; * - Link; - Info ; - Description; * - `Clad: Automatic differentiation plugin for C++ <https://clad.readthedocs.io/en/latest/index.html>`_ ; - Read The Docs webpage; - Clad is a plugin for Cling. It allows to perform Automatic Differentiation (AD) on multivariate functions and functor objects. ",MatchSource.DOCS,interpreter/cling/docs/chapters/references.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst:1438,Integrability,wrap,wrapped,1438,"and the implications of interpreting C++ and the One Definition Rule (ODR) in C++; * - `Cling – The New Interactive Interpreter for ROOT 6 <https://iopscience.iop.org/article/10.1088/1742-6596/396/5/052071>`_; - *V Vasilev et al* 2012 J. Phys.: Conf. Ser. 396 052071; - This paper describes the link between Cling and ROOT. The concepts of REPL and JIT compilation. Cling’s methods for handling errors, expression evaluation, streaming out of execution results, runtime dynamism.; * - `Interactive, Introspected C++ at CERN <https://www.youtube.com/watch?v=K2KqEV866Ro>`_; - *V Vasilev*, CERN PH-SFT, 2013; - Vassil Vasilev (Princeton University) explains how Cling enables interactivity in C++, and illustrates the type introspection mechanism provided by the interpreter.; * - `Introducing Cling, a C++ Interpreter Based on Clang/LLVM <https://www.youtube.com/watch?v=f9Xfh8pv3Fs>`_; - *Axel Naumann* 2012 Googletechtalks; - Axel Naumann (CERN) discusses Cling’s most relevant features: abstract syntax tree (AST) production, wrapped functions, global initialization of a function, delay expression evaluation at runtime, and dynamic scopes.; * - `Creating Cling, an interactive interpreter interface <https://www.youtube.com/watch?v=BjmGOMJWeAo>`_; - *Axel Naumann* 2010 LLVM Developers’ meeting; - This presentation introduces Cling, an ahead-of-time compiler that extends C++ for ease of use as an interpreter.; . ; .. list-table:: Demos, tutorials, Cling’s ecosystem:; :widths: 25 25 50; :header-rows: 1. * - Link; - Info ; - Description; * - `Cling integration | CLion <https://www.jetbrains.com/help/clion/cling-integration.html#install-cling>`_; - 2022.2 Version; - CLion uses Cling to integrate the `Quick Documentation <https://www.jetbrains.com/help/clion/2022.2/viewing-inline-documentation.html>`_ popup by allowing you to view the value of the expressions evaluated at compile time.; * - `Interactive C++ for Data Science <https://www.youtube.com/watch?v=23E0S3miWB0&t=2716s>`_; - *Vass",MatchSource.DOCS,interpreter/cling/docs/chapters/references.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst:1603,Integrability,interface,interface,1603,"088/1742-6596/396/5/052071>`_; - *V Vasilev et al* 2012 J. Phys.: Conf. Ser. 396 052071; - This paper describes the link between Cling and ROOT. The concepts of REPL and JIT compilation. Cling’s methods for handling errors, expression evaluation, streaming out of execution results, runtime dynamism.; * - `Interactive, Introspected C++ at CERN <https://www.youtube.com/watch?v=K2KqEV866Ro>`_; - *V Vasilev*, CERN PH-SFT, 2013; - Vassil Vasilev (Princeton University) explains how Cling enables interactivity in C++, and illustrates the type introspection mechanism provided by the interpreter.; * - `Introducing Cling, a C++ Interpreter Based on Clang/LLVM <https://www.youtube.com/watch?v=f9Xfh8pv3Fs>`_; - *Axel Naumann* 2012 Googletechtalks; - Axel Naumann (CERN) discusses Cling’s most relevant features: abstract syntax tree (AST) production, wrapped functions, global initialization of a function, delay expression evaluation at runtime, and dynamic scopes.; * - `Creating Cling, an interactive interpreter interface <https://www.youtube.com/watch?v=BjmGOMJWeAo>`_; - *Axel Naumann* 2010 LLVM Developers’ meeting; - This presentation introduces Cling, an ahead-of-time compiler that extends C++ for ease of use as an interpreter.; . ; .. list-table:: Demos, tutorials, Cling’s ecosystem:; :widths: 25 25 50; :header-rows: 1. * - Link; - Info ; - Description; * - `Cling integration | CLion <https://www.jetbrains.com/help/clion/cling-integration.html#install-cling>`_; - 2022.2 Version; - CLion uses Cling to integrate the `Quick Documentation <https://www.jetbrains.com/help/clion/2022.2/viewing-inline-documentation.html>`_ popup by allowing you to view the value of the expressions evaluated at compile time.; * - `Interactive C++ for Data Science <https://www.youtube.com/watch?v=23E0S3miWB0&t=2716s>`_; - *Vassil Vassilev* 2021 CppCon (The C++ Conference); - In this video, the author discusses how Cling enables interactive C++ for Data Science projects. ; * - `Cling -- Beyond Just Inter",MatchSource.DOCS,interpreter/cling/docs/chapters/references.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst:1966,Integrability,integrat,integration,1966,"watch?v=K2KqEV866Ro>`_; - *V Vasilev*, CERN PH-SFT, 2013; - Vassil Vasilev (Princeton University) explains how Cling enables interactivity in C++, and illustrates the type introspection mechanism provided by the interpreter.; * - `Introducing Cling, a C++ Interpreter Based on Clang/LLVM <https://www.youtube.com/watch?v=f9Xfh8pv3Fs>`_; - *Axel Naumann* 2012 Googletechtalks; - Axel Naumann (CERN) discusses Cling’s most relevant features: abstract syntax tree (AST) production, wrapped functions, global initialization of a function, delay expression evaluation at runtime, and dynamic scopes.; * - `Creating Cling, an interactive interpreter interface <https://www.youtube.com/watch?v=BjmGOMJWeAo>`_; - *Axel Naumann* 2010 LLVM Developers’ meeting; - This presentation introduces Cling, an ahead-of-time compiler that extends C++ for ease of use as an interpreter.; . ; .. list-table:: Demos, tutorials, Cling’s ecosystem:; :widths: 25 25 50; :header-rows: 1. * - Link; - Info ; - Description; * - `Cling integration | CLion <https://www.jetbrains.com/help/clion/cling-integration.html#install-cling>`_; - 2022.2 Version; - CLion uses Cling to integrate the `Quick Documentation <https://www.jetbrains.com/help/clion/2022.2/viewing-inline-documentation.html>`_ popup by allowing you to view the value of the expressions evaluated at compile time.; * - `Interactive C++ for Data Science <https://www.youtube.com/watch?v=23E0S3miWB0&t=2716s>`_; - *Vassil Vassilev* 2021 CppCon (The C++ Conference); - In this video, the author discusses how Cling enables interactive C++ for Data Science projects. ; * - `Cling -- Beyond Just Interpreting C++ <https://blog.llvm.org/posts/2021-03-25-cling-beyond-just-interpreting-cpp/>`_; - *Vassil Vassilev* 2021 The LLVM Project Blog; - This blog page discusses how Cling enables template Instantiation on demand, language interoperability on demand, interpreter/compiler as a service, plugins extension.; * - `TinySpec-Cling <https://github.com/nwoeanhinnogaehr/ti",MatchSource.DOCS,interpreter/cling/docs/chapters/references.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst:2030,Integrability,integrat,integration,2030," Vasilev (Princeton University) explains how Cling enables interactivity in C++, and illustrates the type introspection mechanism provided by the interpreter.; * - `Introducing Cling, a C++ Interpreter Based on Clang/LLVM <https://www.youtube.com/watch?v=f9Xfh8pv3Fs>`_; - *Axel Naumann* 2012 Googletechtalks; - Axel Naumann (CERN) discusses Cling’s most relevant features: abstract syntax tree (AST) production, wrapped functions, global initialization of a function, delay expression evaluation at runtime, and dynamic scopes.; * - `Creating Cling, an interactive interpreter interface <https://www.youtube.com/watch?v=BjmGOMJWeAo>`_; - *Axel Naumann* 2010 LLVM Developers’ meeting; - This presentation introduces Cling, an ahead-of-time compiler that extends C++ for ease of use as an interpreter.; . ; .. list-table:: Demos, tutorials, Cling’s ecosystem:; :widths: 25 25 50; :header-rows: 1. * - Link; - Info ; - Description; * - `Cling integration | CLion <https://www.jetbrains.com/help/clion/cling-integration.html#install-cling>`_; - 2022.2 Version; - CLion uses Cling to integrate the `Quick Documentation <https://www.jetbrains.com/help/clion/2022.2/viewing-inline-documentation.html>`_ popup by allowing you to view the value of the expressions evaluated at compile time.; * - `Interactive C++ for Data Science <https://www.youtube.com/watch?v=23E0S3miWB0&t=2716s>`_; - *Vassil Vassilev* 2021 CppCon (The C++ Conference); - In this video, the author discusses how Cling enables interactive C++ for Data Science projects. ; * - `Cling -- Beyond Just Interpreting C++ <https://blog.llvm.org/posts/2021-03-25-cling-beyond-just-interpreting-cpp/>`_; - *Vassil Vassilev* 2021 The LLVM Project Blog; - This blog page discusses how Cling enables template Instantiation on demand, language interoperability on demand, interpreter/compiler as a service, plugins extension.; * - `TinySpec-Cling <https://github.com/nwoeanhinnogaehr/tinyspec-cling>`_; - Noah Weninger 2020; - A tiny C++ live-coded ove",MatchSource.DOCS,interpreter/cling/docs/chapters/references.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst:2105,Integrability,integrat,integrate,2105,"lustrates the type introspection mechanism provided by the interpreter.; * - `Introducing Cling, a C++ Interpreter Based on Clang/LLVM <https://www.youtube.com/watch?v=f9Xfh8pv3Fs>`_; - *Axel Naumann* 2012 Googletechtalks; - Axel Naumann (CERN) discusses Cling’s most relevant features: abstract syntax tree (AST) production, wrapped functions, global initialization of a function, delay expression evaluation at runtime, and dynamic scopes.; * - `Creating Cling, an interactive interpreter interface <https://www.youtube.com/watch?v=BjmGOMJWeAo>`_; - *Axel Naumann* 2010 LLVM Developers’ meeting; - This presentation introduces Cling, an ahead-of-time compiler that extends C++ for ease of use as an interpreter.; . ; .. list-table:: Demos, tutorials, Cling’s ecosystem:; :widths: 25 25 50; :header-rows: 1. * - Link; - Info ; - Description; * - `Cling integration | CLion <https://www.jetbrains.com/help/clion/cling-integration.html#install-cling>`_; - 2022.2 Version; - CLion uses Cling to integrate the `Quick Documentation <https://www.jetbrains.com/help/clion/2022.2/viewing-inline-documentation.html>`_ popup by allowing you to view the value of the expressions evaluated at compile time.; * - `Interactive C++ for Data Science <https://www.youtube.com/watch?v=23E0S3miWB0&t=2716s>`_; - *Vassil Vassilev* 2021 CppCon (The C++ Conference); - In this video, the author discusses how Cling enables interactive C++ for Data Science projects. ; * - `Cling -- Beyond Just Interpreting C++ <https://blog.llvm.org/posts/2021-03-25-cling-beyond-just-interpreting-cpp/>`_; - *Vassil Vassilev* 2021 The LLVM Project Blog; - This blog page discusses how Cling enables template Instantiation on demand, language interoperability on demand, interpreter/compiler as a service, plugins extension.; * - `TinySpec-Cling <https://github.com/nwoeanhinnogaehr/tinyspec-cling>`_; - Noah Weninger 2020; - A tiny C++ live-coded overlap-add (re)synthesizer for Linux, which uses Cling to add REPL-like functionality for",MatchSource.DOCS,interpreter/cling/docs/chapters/references.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst:2818,Integrability,interoperab,interoperability,2818,"time compiler that extends C++ for ease of use as an interpreter.; . ; .. list-table:: Demos, tutorials, Cling’s ecosystem:; :widths: 25 25 50; :header-rows: 1. * - Link; - Info ; - Description; * - `Cling integration | CLion <https://www.jetbrains.com/help/clion/cling-integration.html#install-cling>`_; - 2022.2 Version; - CLion uses Cling to integrate the `Quick Documentation <https://www.jetbrains.com/help/clion/2022.2/viewing-inline-documentation.html>`_ popup by allowing you to view the value of the expressions evaluated at compile time.; * - `Interactive C++ for Data Science <https://www.youtube.com/watch?v=23E0S3miWB0&t=2716s>`_; - *Vassil Vassilev* 2021 CppCon (The C++ Conference); - In this video, the author discusses how Cling enables interactive C++ for Data Science projects. ; * - `Cling -- Beyond Just Interpreting C++ <https://blog.llvm.org/posts/2021-03-25-cling-beyond-just-interpreting-cpp/>`_; - *Vassil Vassilev* 2021 The LLVM Project Blog; - This blog page discusses how Cling enables template Instantiation on demand, language interoperability on demand, interpreter/compiler as a service, plugins extension.; * - `TinySpec-Cling <https://github.com/nwoeanhinnogaehr/tinyspec-cling>`_; - Noah Weninger 2020; - A tiny C++ live-coded overlap-add (re)synthesizer for Linux, which uses Cling to add REPL-like functionality for C++ code.; * - `Interactive C++ for Data Science <https://blog.llvm.org/posts/2020-12-21-interactive-cpp-for-data-science/>`_; - *Vassil Vassilev,* *David Lange,* *Simeon Ehrig,* *Sylvain Corlay* 2020 The LLVM Project Blog; - Cling enables eval-style programming for Data Science applications. Examples of ROOT and Xeus-Cling for data science are shown.; * - `Interactive C++ with Cling <https://blog.llvm.org/posts/2020-11-30-interactive-cpp-with-cling/>`_; - *Vassil Vassilev* 2020 The LLVM Project Blog; - This blog page briefly discusses the concept of interactive C++ by presenting Cling’s main features, such as wrapper functions, entity re",MatchSource.DOCS,interpreter/cling/docs/chapters/references.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst:3732,Integrability,wrap,wrapper,3732,"d-just-interpreting-cpp/>`_; - *Vassil Vassilev* 2021 The LLVM Project Blog; - This blog page discusses how Cling enables template Instantiation on demand, language interoperability on demand, interpreter/compiler as a service, plugins extension.; * - `TinySpec-Cling <https://github.com/nwoeanhinnogaehr/tinyspec-cling>`_; - Noah Weninger 2020; - A tiny C++ live-coded overlap-add (re)synthesizer for Linux, which uses Cling to add REPL-like functionality for C++ code.; * - `Interactive C++ for Data Science <https://blog.llvm.org/posts/2020-12-21-interactive-cpp-for-data-science/>`_; - *Vassil Vassilev,* *David Lange,* *Simeon Ehrig,* *Sylvain Corlay* 2020 The LLVM Project Blog; - Cling enables eval-style programming for Data Science applications. Examples of ROOT and Xeus-Cling for data science are shown.; * - `Interactive C++ with Cling <https://blog.llvm.org/posts/2020-11-30-interactive-cpp-with-cling/>`_; - *Vassil Vassilev* 2020 The LLVM Project Blog; - This blog page briefly discusses the concept of interactive C++ by presenting Cling’s main features, such as wrapper functions, entity redefinition, error recovery. ; * - `Using the Cling C++ Interpreter on the Bela Platform <https://gist.github.com/jarmitage/6e411ae8746c04d6ecbee1cbc1ebdcd4>`_; - Jack Armitage 2019; - Cling has been installed on a BeagleBoard to bring live coding to the Bela interactive audio platform.; * - `Implementation of GlobalModuleIndex in ROOT and Cling <https://indico.cern.ch/event/840376/contributions/3525646/attachments/1895398/3127159/GSoC_Presentation__GMI.pdf>`_; - *Arpitha Raghunandan* 2012 Google Summer of Code GSoC; - GlobalModuleIndex can be used for improving ROOT’s and Cling’s performance ; * - `Example project using cling as library <https://github.com/root-project/cling/tree/master/tools/demo>`_; - *Axel Naumann* 2016 GitHub; - This video showcases how to use Cling as a library, and shows how to set up a simple CMake configuration that uses Cling.; * - `Cling C++ interpreter t",MatchSource.DOCS,interpreter/cling/docs/chapters/references.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst:6087,Integrability,interoperab,interoperability,6087,"le order book using C++, CLion, Google Test and, of course, Cling. ; * - `Cling C++ interpreter testdrive <https://www.youtube.com/watch?v=1IGTHusaJ18>`_; - Dimitri Nesteruk 2015 Youtube; - This tutorial describes Cling’s general features. You will learn how to start Cling on Ubuntu, how to write a simple expression (N=5, N++) and how to define a Class for calculating body mass index. ; * - `Cling Interactive OpenGL Demo <https://www.youtube.com/watch?v=eoIuqLNvzFs>`_; - *Alexander Penev* 2012 Youtube; - This demo shows how to use Cling for interactive OpenGL. A rotating triangle with changing color, a static figure, and a figure with light effects are created.; ; . .. list-table:: Language Interoperability with Cling:; :widths: 25 25 50; :header-rows: 1. * - Link; - Info ; - Description; * - `Compiler Research - Calling C++ libraries from a D-written DSL: A cling/cppyy-based approach <https://www.youtube.com/watch?v=7teqrCNzrD8>`_; - *Alexandru Militaru* 2021 Compiler-Research Meeting; - This video presents D and C++ interoperability through SIL-Cling architecture. .. list-table:: Interactive CUDA C++ with Cling:; :widths: 25 25 50; :header-rows: 1. * - Link; - Info ; - Description; * - `Adding CUDA® Support to Cling: JIT Compile to GPUs <https://www.youtube.com/watch?v=XjjZRhiFDVs>`_; - *Simeon Ehrig* 2020 LLVM Developer Meeting; - Interactive CUDA-C++ through Cling is presented. Cling-CUDA architecture is discussed in detail, and an example of interactive simulation for laser plasma applications is shown. . .. list-table:: C++ in Jupyter Notebook - Xeus Cling:; :widths: 25 25 50; :header-rows: 1; ; * - Link; - Info ; - Description; * - `Interactive C++ code development using C++Explorer and GitHub Classroom for educational purposes <https://www.youtube.com/watch?v=HBgF2Yr0foA>`_; - *Patrick Diehl* 2020 Youtube; - C++Explorer is a novel teaching environment based on Jupyterhub and Cling, adapted to teaching C++ programming and source code management.; * - `Deep div",MatchSource.DOCS,interpreter/cling/docs/chapters/references.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst:1779,Modifiability,extend,extends,1779,"OOT. The concepts of REPL and JIT compilation. Cling’s methods for handling errors, expression evaluation, streaming out of execution results, runtime dynamism.; * - `Interactive, Introspected C++ at CERN <https://www.youtube.com/watch?v=K2KqEV866Ro>`_; - *V Vasilev*, CERN PH-SFT, 2013; - Vassil Vasilev (Princeton University) explains how Cling enables interactivity in C++, and illustrates the type introspection mechanism provided by the interpreter.; * - `Introducing Cling, a C++ Interpreter Based on Clang/LLVM <https://www.youtube.com/watch?v=f9Xfh8pv3Fs>`_; - *Axel Naumann* 2012 Googletechtalks; - Axel Naumann (CERN) discusses Cling’s most relevant features: abstract syntax tree (AST) production, wrapped functions, global initialization of a function, delay expression evaluation at runtime, and dynamic scopes.; * - `Creating Cling, an interactive interpreter interface <https://www.youtube.com/watch?v=BjmGOMJWeAo>`_; - *Axel Naumann* 2010 LLVM Developers’ meeting; - This presentation introduces Cling, an ahead-of-time compiler that extends C++ for ease of use as an interpreter.; . ; .. list-table:: Demos, tutorials, Cling’s ecosystem:; :widths: 25 25 50; :header-rows: 1. * - Link; - Info ; - Description; * - `Cling integration | CLion <https://www.jetbrains.com/help/clion/cling-integration.html#install-cling>`_; - 2022.2 Version; - CLion uses Cling to integrate the `Quick Documentation <https://www.jetbrains.com/help/clion/2022.2/viewing-inline-documentation.html>`_ popup by allowing you to view the value of the expressions evaluated at compile time.; * - `Interactive C++ for Data Science <https://www.youtube.com/watch?v=23E0S3miWB0&t=2716s>`_; - *Vassil Vassilev* 2021 CppCon (The C++ Conference); - In this video, the author discusses how Cling enables interactive C++ for Data Science projects. ; * - `Cling -- Beyond Just Interpreting C++ <https://blog.llvm.org/posts/2021-03-25-cling-beyond-just-interpreting-cpp/>`_; - *Vassil Vassilev* 2021 The LLVM Project Blog; ",MatchSource.DOCS,interpreter/cling/docs/chapters/references.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst:2881,Modifiability,plugin,plugins,2881,"time compiler that extends C++ for ease of use as an interpreter.; . ; .. list-table:: Demos, tutorials, Cling’s ecosystem:; :widths: 25 25 50; :header-rows: 1. * - Link; - Info ; - Description; * - `Cling integration | CLion <https://www.jetbrains.com/help/clion/cling-integration.html#install-cling>`_; - 2022.2 Version; - CLion uses Cling to integrate the `Quick Documentation <https://www.jetbrains.com/help/clion/2022.2/viewing-inline-documentation.html>`_ popup by allowing you to view the value of the expressions evaluated at compile time.; * - `Interactive C++ for Data Science <https://www.youtube.com/watch?v=23E0S3miWB0&t=2716s>`_; - *Vassil Vassilev* 2021 CppCon (The C++ Conference); - In this video, the author discusses how Cling enables interactive C++ for Data Science projects. ; * - `Cling -- Beyond Just Interpreting C++ <https://blog.llvm.org/posts/2021-03-25-cling-beyond-just-interpreting-cpp/>`_; - *Vassil Vassilev* 2021 The LLVM Project Blog; - This blog page discusses how Cling enables template Instantiation on demand, language interoperability on demand, interpreter/compiler as a service, plugins extension.; * - `TinySpec-Cling <https://github.com/nwoeanhinnogaehr/tinyspec-cling>`_; - Noah Weninger 2020; - A tiny C++ live-coded overlap-add (re)synthesizer for Linux, which uses Cling to add REPL-like functionality for C++ code.; * - `Interactive C++ for Data Science <https://blog.llvm.org/posts/2020-12-21-interactive-cpp-for-data-science/>`_; - *Vassil Vassilev,* *David Lange,* *Simeon Ehrig,* *Sylvain Corlay* 2020 The LLVM Project Blog; - Cling enables eval-style programming for Data Science applications. Examples of ROOT and Xeus-Cling for data science are shown.; * - `Interactive C++ with Cling <https://blog.llvm.org/posts/2020-11-30-interactive-cpp-with-cling/>`_; - *Vassil Vassilev* 2020 The LLVM Project Blog; - This blog page briefly discusses the concept of interactive C++ by presenting Cling’s main features, such as wrapper functions, entity re",MatchSource.DOCS,interpreter/cling/docs/chapters/references.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst:4594,Modifiability,config,configuration,4594,"g/posts/2020-11-30-interactive-cpp-with-cling/>`_; - *Vassil Vassilev* 2020 The LLVM Project Blog; - This blog page briefly discusses the concept of interactive C++ by presenting Cling’s main features, such as wrapper functions, entity redefinition, error recovery. ; * - `Using the Cling C++ Interpreter on the Bela Platform <https://gist.github.com/jarmitage/6e411ae8746c04d6ecbee1cbc1ebdcd4>`_; - Jack Armitage 2019; - Cling has been installed on a BeagleBoard to bring live coding to the Bela interactive audio platform.; * - `Implementation of GlobalModuleIndex in ROOT and Cling <https://indico.cern.ch/event/840376/contributions/3525646/attachments/1895398/3127159/GSoC_Presentation__GMI.pdf>`_; - *Arpitha Raghunandan* 2012 Google Summer of Code GSoC; - GlobalModuleIndex can be used for improving ROOT’s and Cling’s performance ; * - `Example project using cling as library <https://github.com/root-project/cling/tree/master/tools/demo>`_; - *Axel Naumann* 2016 GitHub; - This video showcases how to use Cling as a library, and shows how to set up a simple CMake configuration that uses Cling.; * - `Cling C++ interpreter testdrive <https://www.youtube.com/watch?v=1IGTHusaJ18>`_; - *Mika* 2015 Youtube; - In this tutorial, a developer tries Cling for the first time by uploading a few simple C++ user-cases onto Cling, involving also the loading of external files; * - `Building an Order Book in C++ <https://www.youtube.com/watch?v=fxN4xEZvrxI>`_; - *Dimitri Nesteruk* 2015 Youtube; - This demo shows how to build a simple order book using C++, CLion, Google Test and, of course, Cling. ; * - `Cling C++ interpreter testdrive <https://www.youtube.com/watch?v=1IGTHusaJ18>`_; - Dimitri Nesteruk 2015 Youtube; - This tutorial describes Cling’s general features. You will learn how to start Cling on Ubuntu, how to write a simple expression (N=5, N++) and how to define a Class for calculating body mass index. ; * - `Cling Interactive OpenGL Demo <https://www.youtube.com/watch?v=eoIuqLNvzFs>",MatchSource.DOCS,interpreter/cling/docs/chapters/references.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst:6976,Modifiability,adapt,adapted,6976,"; * - `Compiler Research - Calling C++ libraries from a D-written DSL: A cling/cppyy-based approach <https://www.youtube.com/watch?v=7teqrCNzrD8>`_; - *Alexandru Militaru* 2021 Compiler-Research Meeting; - This video presents D and C++ interoperability through SIL-Cling architecture. .. list-table:: Interactive CUDA C++ with Cling:; :widths: 25 25 50; :header-rows: 1. * - Link; - Info ; - Description; * - `Adding CUDA® Support to Cling: JIT Compile to GPUs <https://www.youtube.com/watch?v=XjjZRhiFDVs>`_; - *Simeon Ehrig* 2020 LLVM Developer Meeting; - Interactive CUDA-C++ through Cling is presented. Cling-CUDA architecture is discussed in detail, and an example of interactive simulation for laser plasma applications is shown. . .. list-table:: C++ in Jupyter Notebook - Xeus Cling:; :widths: 25 25 50; :header-rows: 1; ; * - Link; - Info ; - Description; * - `Interactive C++ code development using C++Explorer and GitHub Classroom for educational purposes <https://www.youtube.com/watch?v=HBgF2Yr0foA>`_; - *Patrick Diehl* 2020 Youtube; - C++Explorer is a novel teaching environment based on Jupyterhub and Cling, adapted to teaching C++ programming and source code management.; * - `Deep dive into the Xeus-based Cling kernel for Jupyter <https://www.youtube.com/watch?v=kx3wvKk4Qss>`_; - *Vassil Vassilev* 2021 Youtube; - Xeus-Cling is a Cling-based notebook kernel which delivers interactive C++. ; * - `Xeus-Cling: Run C++ code in Jupyter Notebook <https://www.youtube.com/watch?v=4fcKlJ_5QQk>`_ ; - *LearnOpenCV* 2019 Youtube; - In this demo, you will learn an example of C++ code in Jupyter Notebook using Xeus-Cling kernel. . .. list-table:: Clad:; :widths: 25 25 50; :header-rows: 1; ; * - Link; - Info ; - Description; * - `Clad: Automatic differentiation plugin for C++ <https://clad.readthedocs.io/en/latest/index.html>`_ ; - Read The Docs webpage; - Clad is a plugin for Cling. It allows to perform Automatic Differentiation (AD) on multivariate functions and functor objects. ",MatchSource.DOCS,interpreter/cling/docs/chapters/references.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst:7627,Modifiability,plugin,plugin,7627,"; * - `Compiler Research - Calling C++ libraries from a D-written DSL: A cling/cppyy-based approach <https://www.youtube.com/watch?v=7teqrCNzrD8>`_; - *Alexandru Militaru* 2021 Compiler-Research Meeting; - This video presents D and C++ interoperability through SIL-Cling architecture. .. list-table:: Interactive CUDA C++ with Cling:; :widths: 25 25 50; :header-rows: 1. * - Link; - Info ; - Description; * - `Adding CUDA® Support to Cling: JIT Compile to GPUs <https://www.youtube.com/watch?v=XjjZRhiFDVs>`_; - *Simeon Ehrig* 2020 LLVM Developer Meeting; - Interactive CUDA-C++ through Cling is presented. Cling-CUDA architecture is discussed in detail, and an example of interactive simulation for laser plasma applications is shown. . .. list-table:: C++ in Jupyter Notebook - Xeus Cling:; :widths: 25 25 50; :header-rows: 1; ; * - Link; - Info ; - Description; * - `Interactive C++ code development using C++Explorer and GitHub Classroom for educational purposes <https://www.youtube.com/watch?v=HBgF2Yr0foA>`_; - *Patrick Diehl* 2020 Youtube; - C++Explorer is a novel teaching environment based on Jupyterhub and Cling, adapted to teaching C++ programming and source code management.; * - `Deep dive into the Xeus-based Cling kernel for Jupyter <https://www.youtube.com/watch?v=kx3wvKk4Qss>`_; - *Vassil Vassilev* 2021 Youtube; - Xeus-Cling is a Cling-based notebook kernel which delivers interactive C++. ; * - `Xeus-Cling: Run C++ code in Jupyter Notebook <https://www.youtube.com/watch?v=4fcKlJ_5QQk>`_ ; - *LearnOpenCV* 2019 Youtube; - In this demo, you will learn an example of C++ code in Jupyter Notebook using Xeus-Cling kernel. . .. list-table:: Clad:; :widths: 25 25 50; :header-rows: 1; ; * - Link; - Info ; - Description; * - `Clad: Automatic differentiation plugin for C++ <https://clad.readthedocs.io/en/latest/index.html>`_ ; - Read The Docs webpage; - Clad is a plugin for Cling. It allows to perform Automatic Differentiation (AD) on multivariate functions and functor objects. ",MatchSource.DOCS,interpreter/cling/docs/chapters/references.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst:7734,Modifiability,plugin,plugin,7734,"; * - `Compiler Research - Calling C++ libraries from a D-written DSL: A cling/cppyy-based approach <https://www.youtube.com/watch?v=7teqrCNzrD8>`_; - *Alexandru Militaru* 2021 Compiler-Research Meeting; - This video presents D and C++ interoperability through SIL-Cling architecture. .. list-table:: Interactive CUDA C++ with Cling:; :widths: 25 25 50; :header-rows: 1. * - Link; - Info ; - Description; * - `Adding CUDA® Support to Cling: JIT Compile to GPUs <https://www.youtube.com/watch?v=XjjZRhiFDVs>`_; - *Simeon Ehrig* 2020 LLVM Developer Meeting; - Interactive CUDA-C++ through Cling is presented. Cling-CUDA architecture is discussed in detail, and an example of interactive simulation for laser plasma applications is shown. . .. list-table:: C++ in Jupyter Notebook - Xeus Cling:; :widths: 25 25 50; :header-rows: 1; ; * - Link; - Info ; - Description; * - `Interactive C++ code development using C++Explorer and GitHub Classroom for educational purposes <https://www.youtube.com/watch?v=HBgF2Yr0foA>`_; - *Patrick Diehl* 2020 Youtube; - C++Explorer is a novel teaching environment based on Jupyterhub and Cling, adapted to teaching C++ programming and source code management.; * - `Deep dive into the Xeus-based Cling kernel for Jupyter <https://www.youtube.com/watch?v=kx3wvKk4Qss>`_; - *Vassil Vassilev* 2021 Youtube; - Xeus-Cling is a Cling-based notebook kernel which delivers interactive C++. ; * - `Xeus-Cling: Run C++ code in Jupyter Notebook <https://www.youtube.com/watch?v=4fcKlJ_5QQk>`_ ; - *LearnOpenCV* 2019 Youtube; - In this demo, you will learn an example of C++ code in Jupyter Notebook using Xeus-Cling kernel. . .. list-table:: Clad:; :widths: 25 25 50; :header-rows: 1; ; * - Link; - Info ; - Description; * - `Clad: Automatic differentiation plugin for C++ <https://clad.readthedocs.io/en/latest/index.html>`_ ; - Read The Docs webpage; - Clad is a plugin for Cling. It allows to perform Automatic Differentiation (AD) on multivariate functions and functor objects. ",MatchSource.DOCS,interpreter/cling/docs/chapters/references.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst:4347,Performance,perform,performance,4347,"LLVM Project Blog; - Cling enables eval-style programming for Data Science applications. Examples of ROOT and Xeus-Cling for data science are shown.; * - `Interactive C++ with Cling <https://blog.llvm.org/posts/2020-11-30-interactive-cpp-with-cling/>`_; - *Vassil Vassilev* 2020 The LLVM Project Blog; - This blog page briefly discusses the concept of interactive C++ by presenting Cling’s main features, such as wrapper functions, entity redefinition, error recovery. ; * - `Using the Cling C++ Interpreter on the Bela Platform <https://gist.github.com/jarmitage/6e411ae8746c04d6ecbee1cbc1ebdcd4>`_; - Jack Armitage 2019; - Cling has been installed on a BeagleBoard to bring live coding to the Bela interactive audio platform.; * - `Implementation of GlobalModuleIndex in ROOT and Cling <https://indico.cern.ch/event/840376/contributions/3525646/attachments/1895398/3127159/GSoC_Presentation__GMI.pdf>`_; - *Arpitha Raghunandan* 2012 Google Summer of Code GSoC; - GlobalModuleIndex can be used for improving ROOT’s and Cling’s performance ; * - `Example project using cling as library <https://github.com/root-project/cling/tree/master/tools/demo>`_; - *Axel Naumann* 2016 GitHub; - This video showcases how to use Cling as a library, and shows how to set up a simple CMake configuration that uses Cling.; * - `Cling C++ interpreter testdrive <https://www.youtube.com/watch?v=1IGTHusaJ18>`_; - *Mika* 2015 Youtube; - In this tutorial, a developer tries Cling for the first time by uploading a few simple C++ user-cases onto Cling, involving also the loading of external files; * - `Building an Order Book in C++ <https://www.youtube.com/watch?v=fxN4xEZvrxI>`_; - *Dimitri Nesteruk* 2015 Youtube; - This demo shows how to build a simple order book using C++, CLion, Google Test and, of course, Cling. ; * - `Cling C++ interpreter testdrive <https://www.youtube.com/watch?v=1IGTHusaJ18>`_; - Dimitri Nesteruk 2015 Youtube; - This tutorial describes Cling’s general features. You will learn how to star",MatchSource.DOCS,interpreter/cling/docs/chapters/references.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst:4870,Performance,load,loading,4870," Interpreter on the Bela Platform <https://gist.github.com/jarmitage/6e411ae8746c04d6ecbee1cbc1ebdcd4>`_; - Jack Armitage 2019; - Cling has been installed on a BeagleBoard to bring live coding to the Bela interactive audio platform.; * - `Implementation of GlobalModuleIndex in ROOT and Cling <https://indico.cern.ch/event/840376/contributions/3525646/attachments/1895398/3127159/GSoC_Presentation__GMI.pdf>`_; - *Arpitha Raghunandan* 2012 Google Summer of Code GSoC; - GlobalModuleIndex can be used for improving ROOT’s and Cling’s performance ; * - `Example project using cling as library <https://github.com/root-project/cling/tree/master/tools/demo>`_; - *Axel Naumann* 2016 GitHub; - This video showcases how to use Cling as a library, and shows how to set up a simple CMake configuration that uses Cling.; * - `Cling C++ interpreter testdrive <https://www.youtube.com/watch?v=1IGTHusaJ18>`_; - *Mika* 2015 Youtube; - In this tutorial, a developer tries Cling for the first time by uploading a few simple C++ user-cases onto Cling, involving also the loading of external files; * - `Building an Order Book in C++ <https://www.youtube.com/watch?v=fxN4xEZvrxI>`_; - *Dimitri Nesteruk* 2015 Youtube; - This demo shows how to build a simple order book using C++, CLion, Google Test and, of course, Cling. ; * - `Cling C++ interpreter testdrive <https://www.youtube.com/watch?v=1IGTHusaJ18>`_; - Dimitri Nesteruk 2015 Youtube; - This tutorial describes Cling’s general features. You will learn how to start Cling on Ubuntu, how to write a simple expression (N=5, N++) and how to define a Class for calculating body mass index. ; * - `Cling Interactive OpenGL Demo <https://www.youtube.com/watch?v=eoIuqLNvzFs>`_; - *Alexander Penev* 2012 Youtube; - This demo shows how to use Cling for interactive OpenGL. A rotating triangle with changing color, a static figure, and a figure with light effects are created.; ; . .. list-table:: Language Interoperability with Cling:; :widths: 25 25 50; :header-rows:",MatchSource.DOCS,interpreter/cling/docs/chapters/references.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst:7765,Performance,perform,perform,7765,"; * - `Compiler Research - Calling C++ libraries from a D-written DSL: A cling/cppyy-based approach <https://www.youtube.com/watch?v=7teqrCNzrD8>`_; - *Alexandru Militaru* 2021 Compiler-Research Meeting; - This video presents D and C++ interoperability through SIL-Cling architecture. .. list-table:: Interactive CUDA C++ with Cling:; :widths: 25 25 50; :header-rows: 1. * - Link; - Info ; - Description; * - `Adding CUDA® Support to Cling: JIT Compile to GPUs <https://www.youtube.com/watch?v=XjjZRhiFDVs>`_; - *Simeon Ehrig* 2020 LLVM Developer Meeting; - Interactive CUDA-C++ through Cling is presented. Cling-CUDA architecture is discussed in detail, and an example of interactive simulation for laser plasma applications is shown. . .. list-table:: C++ in Jupyter Notebook - Xeus Cling:; :widths: 25 25 50; :header-rows: 1; ; * - Link; - Info ; - Description; * - `Interactive C++ code development using C++Explorer and GitHub Classroom for educational purposes <https://www.youtube.com/watch?v=HBgF2Yr0foA>`_; - *Patrick Diehl* 2020 Youtube; - C++Explorer is a novel teaching environment based on Jupyterhub and Cling, adapted to teaching C++ programming and source code management.; * - `Deep dive into the Xeus-based Cling kernel for Jupyter <https://www.youtube.com/watch?v=kx3wvKk4Qss>`_; - *Vassil Vassilev* 2021 Youtube; - Xeus-Cling is a Cling-based notebook kernel which delivers interactive C++. ; * - `Xeus-Cling: Run C++ code in Jupyter Notebook <https://www.youtube.com/watch?v=4fcKlJ_5QQk>`_ ; - *LearnOpenCV* 2019 Youtube; - In this demo, you will learn an example of C++ code in Jupyter Notebook using Xeus-Cling kernel. . .. list-table:: Clad:; :widths: 25 25 50; :header-rows: 1; ; * - Link; - Info ; - Description; * - `Clad: Automatic differentiation plugin for C++ <https://clad.readthedocs.io/en/latest/index.html>`_ ; - Read The Docs webpage; - Clad is a plugin for Cling. It allows to perform Automatic Differentiation (AD) on multivariate functions and functor objects. ",MatchSource.DOCS,interpreter/cling/docs/chapters/references.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst:3778,Safety,recover,recovery,3778,"d-just-interpreting-cpp/>`_; - *Vassil Vassilev* 2021 The LLVM Project Blog; - This blog page discusses how Cling enables template Instantiation on demand, language interoperability on demand, interpreter/compiler as a service, plugins extension.; * - `TinySpec-Cling <https://github.com/nwoeanhinnogaehr/tinyspec-cling>`_; - Noah Weninger 2020; - A tiny C++ live-coded overlap-add (re)synthesizer for Linux, which uses Cling to add REPL-like functionality for C++ code.; * - `Interactive C++ for Data Science <https://blog.llvm.org/posts/2020-12-21-interactive-cpp-for-data-science/>`_; - *Vassil Vassilev,* *David Lange,* *Simeon Ehrig,* *Sylvain Corlay* 2020 The LLVM Project Blog; - Cling enables eval-style programming for Data Science applications. Examples of ROOT and Xeus-Cling for data science are shown.; * - `Interactive C++ with Cling <https://blog.llvm.org/posts/2020-11-30-interactive-cpp-with-cling/>`_; - *Vassil Vassilev* 2020 The LLVM Project Blog; - This blog page briefly discusses the concept of interactive C++ by presenting Cling’s main features, such as wrapper functions, entity redefinition, error recovery. ; * - `Using the Cling C++ Interpreter on the Bela Platform <https://gist.github.com/jarmitage/6e411ae8746c04d6ecbee1cbc1ebdcd4>`_; - Jack Armitage 2019; - Cling has been installed on a BeagleBoard to bring live coding to the Bela interactive audio platform.; * - `Implementation of GlobalModuleIndex in ROOT and Cling <https://indico.cern.ch/event/840376/contributions/3525646/attachments/1895398/3127159/GSoC_Presentation__GMI.pdf>`_; - *Arpitha Raghunandan* 2012 Google Summer of Code GSoC; - GlobalModuleIndex can be used for improving ROOT’s and Cling’s performance ; * - `Example project using cling as library <https://github.com/root-project/cling/tree/master/tools/demo>`_; - *Axel Naumann* 2016 GitHub; - This video showcases how to use Cling as a library, and shows how to set up a simple CMake configuration that uses Cling.; * - `Cling C++ interpreter t",MatchSource.DOCS,interpreter/cling/docs/chapters/references.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst:4653,Testability,test,testdrive,4653,"usses the concept of interactive C++ by presenting Cling’s main features, such as wrapper functions, entity redefinition, error recovery. ; * - `Using the Cling C++ Interpreter on the Bela Platform <https://gist.github.com/jarmitage/6e411ae8746c04d6ecbee1cbc1ebdcd4>`_; - Jack Armitage 2019; - Cling has been installed on a BeagleBoard to bring live coding to the Bela interactive audio platform.; * - `Implementation of GlobalModuleIndex in ROOT and Cling <https://indico.cern.ch/event/840376/contributions/3525646/attachments/1895398/3127159/GSoC_Presentation__GMI.pdf>`_; - *Arpitha Raghunandan* 2012 Google Summer of Code GSoC; - GlobalModuleIndex can be used for improving ROOT’s and Cling’s performance ; * - `Example project using cling as library <https://github.com/root-project/cling/tree/master/tools/demo>`_; - *Axel Naumann* 2016 GitHub; - This video showcases how to use Cling as a library, and shows how to set up a simple CMake configuration that uses Cling.; * - `Cling C++ interpreter testdrive <https://www.youtube.com/watch?v=1IGTHusaJ18>`_; - *Mika* 2015 Youtube; - In this tutorial, a developer tries Cling for the first time by uploading a few simple C++ user-cases onto Cling, involving also the loading of external files; * - `Building an Order Book in C++ <https://www.youtube.com/watch?v=fxN4xEZvrxI>`_; - *Dimitri Nesteruk* 2015 Youtube; - This demo shows how to build a simple order book using C++, CLion, Google Test and, of course, Cling. ; * - `Cling C++ interpreter testdrive <https://www.youtube.com/watch?v=1IGTHusaJ18>`_; - Dimitri Nesteruk 2015 Youtube; - This tutorial describes Cling’s general features. You will learn how to start Cling on Ubuntu, how to write a simple expression (N=5, N++) and how to define a Class for calculating body mass index. ; * - `Cling Interactive OpenGL Demo <https://www.youtube.com/watch?v=eoIuqLNvzFs>`_; - *Alexander Penev* 2012 Youtube; - This demo shows how to use Cling for interactive OpenGL. A rotating triangle with chang",MatchSource.DOCS,interpreter/cling/docs/chapters/references.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst:5149,Testability,test,testdrive,5149,"ontributions/3525646/attachments/1895398/3127159/GSoC_Presentation__GMI.pdf>`_; - *Arpitha Raghunandan* 2012 Google Summer of Code GSoC; - GlobalModuleIndex can be used for improving ROOT’s and Cling’s performance ; * - `Example project using cling as library <https://github.com/root-project/cling/tree/master/tools/demo>`_; - *Axel Naumann* 2016 GitHub; - This video showcases how to use Cling as a library, and shows how to set up a simple CMake configuration that uses Cling.; * - `Cling C++ interpreter testdrive <https://www.youtube.com/watch?v=1IGTHusaJ18>`_; - *Mika* 2015 Youtube; - In this tutorial, a developer tries Cling for the first time by uploading a few simple C++ user-cases onto Cling, involving also the loading of external files; * - `Building an Order Book in C++ <https://www.youtube.com/watch?v=fxN4xEZvrxI>`_; - *Dimitri Nesteruk* 2015 Youtube; - This demo shows how to build a simple order book using C++, CLion, Google Test and, of course, Cling. ; * - `Cling C++ interpreter testdrive <https://www.youtube.com/watch?v=1IGTHusaJ18>`_; - Dimitri Nesteruk 2015 Youtube; - This tutorial describes Cling’s general features. You will learn how to start Cling on Ubuntu, how to write a simple expression (N=5, N++) and how to define a Class for calculating body mass index. ; * - `Cling Interactive OpenGL Demo <https://www.youtube.com/watch?v=eoIuqLNvzFs>`_; - *Alexander Penev* 2012 Youtube; - This demo shows how to use Cling for interactive OpenGL. A rotating triangle with changing color, a static figure, and a figure with light effects are created.; ; . .. list-table:: Language Interoperability with Cling:; :widths: 25 25 50; :header-rows: 1. * - Link; - Info ; - Description; * - `Compiler Research - Calling C++ libraries from a D-written DSL: A cling/cppyy-based approach <https://www.youtube.com/watch?v=7teqrCNzrD8>`_; - *Alexandru Militaru* 2021 Compiler-Research Meeting; - This video presents D and C++ interoperability through SIL-Cling architecture. .. list-ta",MatchSource.DOCS,interpreter/cling/docs/chapters/references.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst:4581,Usability,simpl,simple,4581,"g/posts/2020-11-30-interactive-cpp-with-cling/>`_; - *Vassil Vassilev* 2020 The LLVM Project Blog; - This blog page briefly discusses the concept of interactive C++ by presenting Cling’s main features, such as wrapper functions, entity redefinition, error recovery. ; * - `Using the Cling C++ Interpreter on the Bela Platform <https://gist.github.com/jarmitage/6e411ae8746c04d6ecbee1cbc1ebdcd4>`_; - Jack Armitage 2019; - Cling has been installed on a BeagleBoard to bring live coding to the Bela interactive audio platform.; * - `Implementation of GlobalModuleIndex in ROOT and Cling <https://indico.cern.ch/event/840376/contributions/3525646/attachments/1895398/3127159/GSoC_Presentation__GMI.pdf>`_; - *Arpitha Raghunandan* 2012 Google Summer of Code GSoC; - GlobalModuleIndex can be used for improving ROOT’s and Cling’s performance ; * - `Example project using cling as library <https://github.com/root-project/cling/tree/master/tools/demo>`_; - *Axel Naumann* 2016 GitHub; - This video showcases how to use Cling as a library, and shows how to set up a simple CMake configuration that uses Cling.; * - `Cling C++ interpreter testdrive <https://www.youtube.com/watch?v=1IGTHusaJ18>`_; - *Mika* 2015 Youtube; - In this tutorial, a developer tries Cling for the first time by uploading a few simple C++ user-cases onto Cling, involving also the loading of external files; * - `Building an Order Book in C++ <https://www.youtube.com/watch?v=fxN4xEZvrxI>`_; - *Dimitri Nesteruk* 2015 Youtube; - This demo shows how to build a simple order book using C++, CLion, Google Test and, of course, Cling. ; * - `Cling C++ interpreter testdrive <https://www.youtube.com/watch?v=1IGTHusaJ18>`_; - Dimitri Nesteruk 2015 Youtube; - This tutorial describes Cling’s general features. You will learn how to start Cling on Ubuntu, how to write a simple expression (N=5, N++) and how to define a Class for calculating body mass index. ; * - `Cling Interactive OpenGL Demo <https://www.youtube.com/watch?v=eoIuqLNvzFs>",MatchSource.DOCS,interpreter/cling/docs/chapters/references.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst:4817,Usability,simpl,simple,4817," Interpreter on the Bela Platform <https://gist.github.com/jarmitage/6e411ae8746c04d6ecbee1cbc1ebdcd4>`_; - Jack Armitage 2019; - Cling has been installed on a BeagleBoard to bring live coding to the Bela interactive audio platform.; * - `Implementation of GlobalModuleIndex in ROOT and Cling <https://indico.cern.ch/event/840376/contributions/3525646/attachments/1895398/3127159/GSoC_Presentation__GMI.pdf>`_; - *Arpitha Raghunandan* 2012 Google Summer of Code GSoC; - GlobalModuleIndex can be used for improving ROOT’s and Cling’s performance ; * - `Example project using cling as library <https://github.com/root-project/cling/tree/master/tools/demo>`_; - *Axel Naumann* 2016 GitHub; - This video showcases how to use Cling as a library, and shows how to set up a simple CMake configuration that uses Cling.; * - `Cling C++ interpreter testdrive <https://www.youtube.com/watch?v=1IGTHusaJ18>`_; - *Mika* 2015 Youtube; - In this tutorial, a developer tries Cling for the first time by uploading a few simple C++ user-cases onto Cling, involving also the loading of external files; * - `Building an Order Book in C++ <https://www.youtube.com/watch?v=fxN4xEZvrxI>`_; - *Dimitri Nesteruk* 2015 Youtube; - This demo shows how to build a simple order book using C++, CLion, Google Test and, of course, Cling. ; * - `Cling C++ interpreter testdrive <https://www.youtube.com/watch?v=1IGTHusaJ18>`_; - Dimitri Nesteruk 2015 Youtube; - This tutorial describes Cling’s general features. You will learn how to start Cling on Ubuntu, how to write a simple expression (N=5, N++) and how to define a Class for calculating body mass index. ; * - `Cling Interactive OpenGL Demo <https://www.youtube.com/watch?v=eoIuqLNvzFs>`_; - *Alexander Penev* 2012 Youtube; - This demo shows how to use Cling for interactive OpenGL. A rotating triangle with changing color, a static figure, and a figure with light effects are created.; ; . .. list-table:: Language Interoperability with Cling:; :widths: 25 25 50; :header-rows:",MatchSource.DOCS,interpreter/cling/docs/chapters/references.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst:5049,Usability,simpl,simple,5049," platform.; * - `Implementation of GlobalModuleIndex in ROOT and Cling <https://indico.cern.ch/event/840376/contributions/3525646/attachments/1895398/3127159/GSoC_Presentation__GMI.pdf>`_; - *Arpitha Raghunandan* 2012 Google Summer of Code GSoC; - GlobalModuleIndex can be used for improving ROOT’s and Cling’s performance ; * - `Example project using cling as library <https://github.com/root-project/cling/tree/master/tools/demo>`_; - *Axel Naumann* 2016 GitHub; - This video showcases how to use Cling as a library, and shows how to set up a simple CMake configuration that uses Cling.; * - `Cling C++ interpreter testdrive <https://www.youtube.com/watch?v=1IGTHusaJ18>`_; - *Mika* 2015 Youtube; - In this tutorial, a developer tries Cling for the first time by uploading a few simple C++ user-cases onto Cling, involving also the loading of external files; * - `Building an Order Book in C++ <https://www.youtube.com/watch?v=fxN4xEZvrxI>`_; - *Dimitri Nesteruk* 2015 Youtube; - This demo shows how to build a simple order book using C++, CLion, Google Test and, of course, Cling. ; * - `Cling C++ interpreter testdrive <https://www.youtube.com/watch?v=1IGTHusaJ18>`_; - Dimitri Nesteruk 2015 Youtube; - This tutorial describes Cling’s general features. You will learn how to start Cling on Ubuntu, how to write a simple expression (N=5, N++) and how to define a Class for calculating body mass index. ; * - `Cling Interactive OpenGL Demo <https://www.youtube.com/watch?v=eoIuqLNvzFs>`_; - *Alexander Penev* 2012 Youtube; - This demo shows how to use Cling for interactive OpenGL. A rotating triangle with changing color, a static figure, and a figure with light effects are created.; ; . .. list-table:: Language Interoperability with Cling:; :widths: 25 25 50; :header-rows: 1. * - Link; - Info ; - Description; * - `Compiler Research - Calling C++ libraries from a D-written DSL: A cling/cppyy-based approach <https://www.youtube.com/watch?v=7teqrCNzrD8>`_; - *Alexandru Militaru* 2021 Compiler",MatchSource.DOCS,interpreter/cling/docs/chapters/references.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst:5302,Usability,learn,learn,5302,"Example project using cling as library <https://github.com/root-project/cling/tree/master/tools/demo>`_; - *Axel Naumann* 2016 GitHub; - This video showcases how to use Cling as a library, and shows how to set up a simple CMake configuration that uses Cling.; * - `Cling C++ interpreter testdrive <https://www.youtube.com/watch?v=1IGTHusaJ18>`_; - *Mika* 2015 Youtube; - In this tutorial, a developer tries Cling for the first time by uploading a few simple C++ user-cases onto Cling, involving also the loading of external files; * - `Building an Order Book in C++ <https://www.youtube.com/watch?v=fxN4xEZvrxI>`_; - *Dimitri Nesteruk* 2015 Youtube; - This demo shows how to build a simple order book using C++, CLion, Google Test and, of course, Cling. ; * - `Cling C++ interpreter testdrive <https://www.youtube.com/watch?v=1IGTHusaJ18>`_; - Dimitri Nesteruk 2015 Youtube; - This tutorial describes Cling’s general features. You will learn how to start Cling on Ubuntu, how to write a simple expression (N=5, N++) and how to define a Class for calculating body mass index. ; * - `Cling Interactive OpenGL Demo <https://www.youtube.com/watch?v=eoIuqLNvzFs>`_; - *Alexander Penev* 2012 Youtube; - This demo shows how to use Cling for interactive OpenGL. A rotating triangle with changing color, a static figure, and a figure with light effects are created.; ; . .. list-table:: Language Interoperability with Cling:; :widths: 25 25 50; :header-rows: 1. * - Link; - Info ; - Description; * - `Compiler Research - Calling C++ libraries from a D-written DSL: A cling/cppyy-based approach <https://www.youtube.com/watch?v=7teqrCNzrD8>`_; - *Alexandru Militaru* 2021 Compiler-Research Meeting; - This video presents D and C++ interoperability through SIL-Cling architecture. .. list-table:: Interactive CUDA C++ with Cling:; :widths: 25 25 50; :header-rows: 1. * - Link; - Info ; - Description; * - `Adding CUDA® Support to Cling: JIT Compile to GPUs <https://www.youtube.com/watch?v=XjjZRhiFDVs>`_; - *Si",MatchSource.DOCS,interpreter/cling/docs/chapters/references.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst:5353,Usability,simpl,simple,5353,"Example project using cling as library <https://github.com/root-project/cling/tree/master/tools/demo>`_; - *Axel Naumann* 2016 GitHub; - This video showcases how to use Cling as a library, and shows how to set up a simple CMake configuration that uses Cling.; * - `Cling C++ interpreter testdrive <https://www.youtube.com/watch?v=1IGTHusaJ18>`_; - *Mika* 2015 Youtube; - In this tutorial, a developer tries Cling for the first time by uploading a few simple C++ user-cases onto Cling, involving also the loading of external files; * - `Building an Order Book in C++ <https://www.youtube.com/watch?v=fxN4xEZvrxI>`_; - *Dimitri Nesteruk* 2015 Youtube; - This demo shows how to build a simple order book using C++, CLion, Google Test and, of course, Cling. ; * - `Cling C++ interpreter testdrive <https://www.youtube.com/watch?v=1IGTHusaJ18>`_; - Dimitri Nesteruk 2015 Youtube; - This tutorial describes Cling’s general features. You will learn how to start Cling on Ubuntu, how to write a simple expression (N=5, N++) and how to define a Class for calculating body mass index. ; * - `Cling Interactive OpenGL Demo <https://www.youtube.com/watch?v=eoIuqLNvzFs>`_; - *Alexander Penev* 2012 Youtube; - This demo shows how to use Cling for interactive OpenGL. A rotating triangle with changing color, a static figure, and a figure with light effects are created.; ; . .. list-table:: Language Interoperability with Cling:; :widths: 25 25 50; :header-rows: 1. * - Link; - Info ; - Description; * - `Compiler Research - Calling C++ libraries from a D-written DSL: A cling/cppyy-based approach <https://www.youtube.com/watch?v=7teqrCNzrD8>`_; - *Alexandru Militaru* 2021 Compiler-Research Meeting; - This video presents D and C++ interoperability through SIL-Cling architecture. .. list-table:: Interactive CUDA C++ with Cling:; :widths: 25 25 50; :header-rows: 1. * - Link; - Info ; - Description; * - `Adding CUDA® Support to Cling: JIT Compile to GPUs <https://www.youtube.com/watch?v=XjjZRhiFDVs>`_; - *Si",MatchSource.DOCS,interpreter/cling/docs/chapters/references.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst:7419,Usability,learn,learn,7419,"; * - `Compiler Research - Calling C++ libraries from a D-written DSL: A cling/cppyy-based approach <https://www.youtube.com/watch?v=7teqrCNzrD8>`_; - *Alexandru Militaru* 2021 Compiler-Research Meeting; - This video presents D and C++ interoperability through SIL-Cling architecture. .. list-table:: Interactive CUDA C++ with Cling:; :widths: 25 25 50; :header-rows: 1. * - Link; - Info ; - Description; * - `Adding CUDA® Support to Cling: JIT Compile to GPUs <https://www.youtube.com/watch?v=XjjZRhiFDVs>`_; - *Simeon Ehrig* 2020 LLVM Developer Meeting; - Interactive CUDA-C++ through Cling is presented. Cling-CUDA architecture is discussed in detail, and an example of interactive simulation for laser plasma applications is shown. . .. list-table:: C++ in Jupyter Notebook - Xeus Cling:; :widths: 25 25 50; :header-rows: 1; ; * - Link; - Info ; - Description; * - `Interactive C++ code development using C++Explorer and GitHub Classroom for educational purposes <https://www.youtube.com/watch?v=HBgF2Yr0foA>`_; - *Patrick Diehl* 2020 Youtube; - C++Explorer is a novel teaching environment based on Jupyterhub and Cling, adapted to teaching C++ programming and source code management.; * - `Deep dive into the Xeus-based Cling kernel for Jupyter <https://www.youtube.com/watch?v=kx3wvKk4Qss>`_; - *Vassil Vassilev* 2021 Youtube; - Xeus-Cling is a Cling-based notebook kernel which delivers interactive C++. ; * - `Xeus-Cling: Run C++ code in Jupyter Notebook <https://www.youtube.com/watch?v=4fcKlJ_5QQk>`_ ; - *LearnOpenCV* 2019 Youtube; - In this demo, you will learn an example of C++ code in Jupyter Notebook using Xeus-Cling kernel. . .. list-table:: Clad:; :widths: 25 25 50; :header-rows: 1; ; * - Link; - Info ; - Description; * - `Clad: Automatic differentiation plugin for C++ <https://clad.readthedocs.io/en/latest/index.html>`_ ; - Read The Docs webpage; - Clad is a plugin for Cling. It allows to perform Automatic Differentiation (AD) on multivariate functions and functor objects. ",MatchSource.DOCS,interpreter/cling/docs/chapters/references.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/references.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/REPL.rst:1054,Availability,recover,recovery,1054,"Cling is (also, but not only) REPL; -----------------------------------. A `read-eval-print-loop <https://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop>`_; (**REPL**) is an interactive programming environment that takes user inputs,; executes them, and returns the result to the user. In order to enable; interactivity in C++, Cling provides several extensions to the C++ language:. 1. **Defining functions in the global scope:** Cling redefines expressions at a; global level. C++ provides limited support for this, Cling possesses the; necessary semantics to re-define code while the program is running,; minimizing the impedance mismatch between the **REPL** and the C++ codebase,; and allowing for a seamlessly interactive programing experience. 2. **Allows for implementation of commands** that provide information about the; current state of the environment. e.g., has an `Application Programming; Interface <https://en.wikipedia.org/wiki/API>`_ (**API**) to provide; information about the current state of the environment. 3. **Error recovery:** Cling has an efficient error recovery system which allows; it to handle the errors made by the user without restarting or having to redo; everything from the beginning. 4. **Tight feedback loop:** It provides feedback about the results of the; developer’s choices that is both accurate and fast. 5. **Facilitates debugging:** The programmer can inspect the printed result; before deciding what expression to provide for the next line of code.; ",MatchSource.DOCS,interpreter/cling/docs/chapters/REPL.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/REPL.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/REPL.rst:1089,Availability,error,error,1089,"Cling is (also, but not only) REPL; -----------------------------------. A `read-eval-print-loop <https://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop>`_; (**REPL**) is an interactive programming environment that takes user inputs,; executes them, and returns the result to the user. In order to enable; interactivity in C++, Cling provides several extensions to the C++ language:. 1. **Defining functions in the global scope:** Cling redefines expressions at a; global level. C++ provides limited support for this, Cling possesses the; necessary semantics to re-define code while the program is running,; minimizing the impedance mismatch between the **REPL** and the C++ codebase,; and allowing for a seamlessly interactive programing experience. 2. **Allows for implementation of commands** that provide information about the; current state of the environment. e.g., has an `Application Programming; Interface <https://en.wikipedia.org/wiki/API>`_ (**API**) to provide; information about the current state of the environment. 3. **Error recovery:** Cling has an efficient error recovery system which allows; it to handle the errors made by the user without restarting or having to redo; everything from the beginning. 4. **Tight feedback loop:** It provides feedback about the results of the; developer’s choices that is both accurate and fast. 5. **Facilitates debugging:** The programmer can inspect the printed result; before deciding what expression to provide for the next line of code.; ",MatchSource.DOCS,interpreter/cling/docs/chapters/REPL.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/REPL.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/REPL.rst:1095,Availability,recover,recovery,1095,"Cling is (also, but not only) REPL; -----------------------------------. A `read-eval-print-loop <https://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop>`_; (**REPL**) is an interactive programming environment that takes user inputs,; executes them, and returns the result to the user. In order to enable; interactivity in C++, Cling provides several extensions to the C++ language:. 1. **Defining functions in the global scope:** Cling redefines expressions at a; global level. C++ provides limited support for this, Cling possesses the; necessary semantics to re-define code while the program is running,; minimizing the impedance mismatch between the **REPL** and the C++ codebase,; and allowing for a seamlessly interactive programing experience. 2. **Allows for implementation of commands** that provide information about the; current state of the environment. e.g., has an `Application Programming; Interface <https://en.wikipedia.org/wiki/API>`_ (**API**) to provide; information about the current state of the environment. 3. **Error recovery:** Cling has an efficient error recovery system which allows; it to handle the errors made by the user without restarting or having to redo; everything from the beginning. 4. **Tight feedback loop:** It provides feedback about the results of the; developer’s choices that is both accurate and fast. 5. **Facilitates debugging:** The programmer can inspect the printed result; before deciding what expression to provide for the next line of code.; ",MatchSource.DOCS,interpreter/cling/docs/chapters/REPL.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/REPL.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/REPL.rst:1142,Availability,error,errors,1142,"Cling is (also, but not only) REPL; -----------------------------------. A `read-eval-print-loop <https://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop>`_; (**REPL**) is an interactive programming environment that takes user inputs,; executes them, and returns the result to the user. In order to enable; interactivity in C++, Cling provides several extensions to the C++ language:. 1. **Defining functions in the global scope:** Cling redefines expressions at a; global level. C++ provides limited support for this, Cling possesses the; necessary semantics to re-define code while the program is running,; minimizing the impedance mismatch between the **REPL** and the C++ codebase,; and allowing for a seamlessly interactive programing experience. 2. **Allows for implementation of commands** that provide information about the; current state of the environment. e.g., has an `Application Programming; Interface <https://en.wikipedia.org/wiki/API>`_ (**API**) to provide; information about the current state of the environment. 3. **Error recovery:** Cling has an efficient error recovery system which allows; it to handle the errors made by the user without restarting or having to redo; everything from the beginning. 4. **Tight feedback loop:** It provides feedback about the results of the; developer’s choices that is both accurate and fast. 5. **Facilitates debugging:** The programmer can inspect the printed result; before deciding what expression to provide for the next line of code.; ",MatchSource.DOCS,interpreter/cling/docs/chapters/REPL.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/REPL.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/REPL.rst:1079,Energy Efficiency,efficient,efficient,1079,"Cling is (also, but not only) REPL; -----------------------------------. A `read-eval-print-loop <https://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop>`_; (**REPL**) is an interactive programming environment that takes user inputs,; executes them, and returns the result to the user. In order to enable; interactivity in C++, Cling provides several extensions to the C++ language:. 1. **Defining functions in the global scope:** Cling redefines expressions at a; global level. C++ provides limited support for this, Cling possesses the; necessary semantics to re-define code while the program is running,; minimizing the impedance mismatch between the **REPL** and the C++ codebase,; and allowing for a seamlessly interactive programing experience. 2. **Allows for implementation of commands** that provide information about the; current state of the environment. e.g., has an `Application Programming; Interface <https://en.wikipedia.org/wiki/API>`_ (**API**) to provide; information about the current state of the environment. 3. **Error recovery:** Cling has an efficient error recovery system which allows; it to handle the errors made by the user without restarting or having to redo; everything from the beginning. 4. **Tight feedback loop:** It provides feedback about the results of the; developer’s choices that is both accurate and fast. 5. **Facilitates debugging:** The programmer can inspect the printed result; before deciding what expression to provide for the next line of code.; ",MatchSource.DOCS,interpreter/cling/docs/chapters/REPL.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/REPL.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/REPL.rst:1054,Safety,recover,recovery,1054,"Cling is (also, but not only) REPL; -----------------------------------. A `read-eval-print-loop <https://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop>`_; (**REPL**) is an interactive programming environment that takes user inputs,; executes them, and returns the result to the user. In order to enable; interactivity in C++, Cling provides several extensions to the C++ language:. 1. **Defining functions in the global scope:** Cling redefines expressions at a; global level. C++ provides limited support for this, Cling possesses the; necessary semantics to re-define code while the program is running,; minimizing the impedance mismatch between the **REPL** and the C++ codebase,; and allowing for a seamlessly interactive programing experience. 2. **Allows for implementation of commands** that provide information about the; current state of the environment. e.g., has an `Application Programming; Interface <https://en.wikipedia.org/wiki/API>`_ (**API**) to provide; information about the current state of the environment. 3. **Error recovery:** Cling has an efficient error recovery system which allows; it to handle the errors made by the user without restarting or having to redo; everything from the beginning. 4. **Tight feedback loop:** It provides feedback about the results of the; developer’s choices that is both accurate and fast. 5. **Facilitates debugging:** The programmer can inspect the printed result; before deciding what expression to provide for the next line of code.; ",MatchSource.DOCS,interpreter/cling/docs/chapters/REPL.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/REPL.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/REPL.rst:1095,Safety,recover,recovery,1095,"Cling is (also, but not only) REPL; -----------------------------------. A `read-eval-print-loop <https://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop>`_; (**REPL**) is an interactive programming environment that takes user inputs,; executes them, and returns the result to the user. In order to enable; interactivity in C++, Cling provides several extensions to the C++ language:. 1. **Defining functions in the global scope:** Cling redefines expressions at a; global level. C++ provides limited support for this, Cling possesses the; necessary semantics to re-define code while the program is running,; minimizing the impedance mismatch between the **REPL** and the C++ codebase,; and allowing for a seamlessly interactive programing experience. 2. **Allows for implementation of commands** that provide information about the; current state of the environment. e.g., has an `Application Programming; Interface <https://en.wikipedia.org/wiki/API>`_ (**API**) to provide; information about the current state of the environment. 3. **Error recovery:** Cling has an efficient error recovery system which allows; it to handle the errors made by the user without restarting or having to redo; everything from the beginning. 4. **Tight feedback loop:** It provides feedback about the results of the; developer’s choices that is both accurate and fast. 5. **Facilitates debugging:** The programmer can inspect the printed result; before deciding what expression to provide for the next line of code.; ",MatchSource.DOCS,interpreter/cling/docs/chapters/REPL.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/REPL.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/REPL.rst:1246,Usability,feedback,feedback,1246,"Cling is (also, but not only) REPL; -----------------------------------. A `read-eval-print-loop <https://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop>`_; (**REPL**) is an interactive programming environment that takes user inputs,; executes them, and returns the result to the user. In order to enable; interactivity in C++, Cling provides several extensions to the C++ language:. 1. **Defining functions in the global scope:** Cling redefines expressions at a; global level. C++ provides limited support for this, Cling possesses the; necessary semantics to re-define code while the program is running,; minimizing the impedance mismatch between the **REPL** and the C++ codebase,; and allowing for a seamlessly interactive programing experience. 2. **Allows for implementation of commands** that provide information about the; current state of the environment. e.g., has an `Application Programming; Interface <https://en.wikipedia.org/wiki/API>`_ (**API**) to provide; information about the current state of the environment. 3. **Error recovery:** Cling has an efficient error recovery system which allows; it to handle the errors made by the user without restarting or having to redo; everything from the beginning. 4. **Tight feedback loop:** It provides feedback about the results of the; developer’s choices that is both accurate and fast. 5. **Facilitates debugging:** The programmer can inspect the printed result; before deciding what expression to provide for the next line of code.; ",MatchSource.DOCS,interpreter/cling/docs/chapters/REPL.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/REPL.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/REPL.rst:1275,Usability,feedback,feedback,1275,"Cling is (also, but not only) REPL; -----------------------------------. A `read-eval-print-loop <https://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop>`_; (**REPL**) is an interactive programming environment that takes user inputs,; executes them, and returns the result to the user. In order to enable; interactivity in C++, Cling provides several extensions to the C++ language:. 1. **Defining functions in the global scope:** Cling redefines expressions at a; global level. C++ provides limited support for this, Cling possesses the; necessary semantics to re-define code while the program is running,; minimizing the impedance mismatch between the **REPL** and the C++ codebase,; and allowing for a seamlessly interactive programing experience. 2. **Allows for implementation of commands** that provide information about the; current state of the environment. e.g., has an `Application Programming; Interface <https://en.wikipedia.org/wiki/API>`_ (**API**) to provide; information about the current state of the environment. 3. **Error recovery:** Cling has an efficient error recovery system which allows; it to handle the errors made by the user without restarting or having to redo; everything from the beginning. 4. **Tight feedback loop:** It provides feedback about the results of the; developer’s choices that is both accurate and fast. 5. **Facilitates debugging:** The programmer can inspect the printed result; before deciding what expression to provide for the next line of code.; ",MatchSource.DOCS,interpreter/cling/docs/chapters/REPL.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/REPL.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/why_interpreting.rst:877,Deployability,configurat,configuration,877,"Why interpreting C++ with Cling?; -----------------------------------. 1. **Learning C++:**; ; One use case of Cling is to aid the C++ learning process. Offering imediate; feedback the user can easily get familiar with the structures and spelling of; the language. 2. **Creating scripts:**; ; The power of an interpreter lays as well in the compactness and ease of; repeatedly running a small snippet of code - aka a script. This can be done in; Cling by inserting the bash-like style line:. .. code:: bash; ; #!/usr/bin/cling; ; 3. **Rapid Application Development (RAD):**. Cling can be used successfully for Rapid Application Development allowing for; prototyping and proofs of concept taking advantage of dynamicity and feedback; during the implementation process. 4. **Runtime-Generated Code**. Sometime it's convenient to create code as a reaction to input; (user/network/configuration). Runtime-generated code can interface with C++; libraries. 5. **Embedding Cling:**. The functionality of an application can be enriched by embedding Cling. To embed; Cling, the main program has to be provided. One of the things this main program; has to do is initialize the Cling interpreter. There are optional calls to pass; command line arguments to Cling. Afterwards, you can call the interpreter from; any anywhere within the application. For compilation and linkage the application needs the path to the Clang and LLVM; libraries and the invocation is order dependent since the linker cannot do; backward searches. .. code:: bash. g++ embedcling.cxx -std=c++11 -L/usr/local/lib; -lclingInterpreter -lclingUtils ; -lclangFrontend -lclangSerialization -lclangParse -lclangSema ; -lclangAnalysis -lclangEdit -lclangLex -lclangDriver -lclangCodeGen ; -lclangBasic -lclangAST ; `llvm-config ; --libs bitwriter mcjit orcjit native option ; ipo profiledata instrumentation objcarcopts` ; -lz -pthread -ldl -ltinfo ; -o embedcling; . Embedding Cling requires the creation of the interpreter. Optionally compile",MatchSource.DOCS,interpreter/cling/docs/chapters/why_interpreting.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/why_interpreting.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/why_interpreting.rst:297,Energy Efficiency,power,power,297,"Why interpreting C++ with Cling?; -----------------------------------. 1. **Learning C++:**; ; One use case of Cling is to aid the C++ learning process. Offering imediate; feedback the user can easily get familiar with the structures and spelling of; the language. 2. **Creating scripts:**; ; The power of an interpreter lays as well in the compactness and ease of; repeatedly running a small snippet of code - aka a script. This can be done in; Cling by inserting the bash-like style line:. .. code:: bash; ; #!/usr/bin/cling; ; 3. **Rapid Application Development (RAD):**. Cling can be used successfully for Rapid Application Development allowing for; prototyping and proofs of concept taking advantage of dynamicity and feedback; during the implementation process. 4. **Runtime-Generated Code**. Sometime it's convenient to create code as a reaction to input; (user/network/configuration). Runtime-generated code can interface with C++; libraries. 5. **Embedding Cling:**. The functionality of an application can be enriched by embedding Cling. To embed; Cling, the main program has to be provided. One of the things this main program; has to do is initialize the Cling interpreter. There are optional calls to pass; command line arguments to Cling. Afterwards, you can call the interpreter from; any anywhere within the application. For compilation and linkage the application needs the path to the Clang and LLVM; libraries and the invocation is order dependent since the linker cannot do; backward searches. .. code:: bash. g++ embedcling.cxx -std=c++11 -L/usr/local/lib; -lclingInterpreter -lclingUtils ; -lclangFrontend -lclangSerialization -lclangParse -lclangSema ; -lclangAnalysis -lclangEdit -lclangLex -lclangDriver -lclangCodeGen ; -lclangBasic -lclangAST ; `llvm-config ; --libs bitwriter mcjit orcjit native option ; ipo profiledata instrumentation objcarcopts` ; -lz -pthread -ldl -ltinfo ; -o embedcling; . Embedding Cling requires the creation of the interpreter. Optionally compile",MatchSource.DOCS,interpreter/cling/docs/chapters/why_interpreting.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/why_interpreting.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/why_interpreting.rst:920,Integrability,interface,interface,920,"Why interpreting C++ with Cling?; -----------------------------------. 1. **Learning C++:**; ; One use case of Cling is to aid the C++ learning process. Offering imediate; feedback the user can easily get familiar with the structures and spelling of; the language. 2. **Creating scripts:**; ; The power of an interpreter lays as well in the compactness and ease of; repeatedly running a small snippet of code - aka a script. This can be done in; Cling by inserting the bash-like style line:. .. code:: bash; ; #!/usr/bin/cling; ; 3. **Rapid Application Development (RAD):**. Cling can be used successfully for Rapid Application Development allowing for; prototyping and proofs of concept taking advantage of dynamicity and feedback; during the implementation process. 4. **Runtime-Generated Code**. Sometime it's convenient to create code as a reaction to input; (user/network/configuration). Runtime-generated code can interface with C++; libraries. 5. **Embedding Cling:**. The functionality of an application can be enriched by embedding Cling. To embed; Cling, the main program has to be provided. One of the things this main program; has to do is initialize the Cling interpreter. There are optional calls to pass; command line arguments to Cling. Afterwards, you can call the interpreter from; any anywhere within the application. For compilation and linkage the application needs the path to the Clang and LLVM; libraries and the invocation is order dependent since the linker cannot do; backward searches. .. code:: bash. g++ embedcling.cxx -std=c++11 -L/usr/local/lib; -lclingInterpreter -lclingUtils ; -lclangFrontend -lclangSerialization -lclangParse -lclangSema ; -lclangAnalysis -lclangEdit -lclangLex -lclangDriver -lclangCodeGen ; -lclangBasic -lclangAST ; `llvm-config ; --libs bitwriter mcjit orcjit native option ; ipo profiledata instrumentation objcarcopts` ; -lz -pthread -ldl -ltinfo ; -o embedcling; . Embedding Cling requires the creation of the interpreter. Optionally compile",MatchSource.DOCS,interpreter/cling/docs/chapters/why_interpreting.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/why_interpreting.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/why_interpreting.rst:1457,Integrability,depend,dependent,1457," This can be done in; Cling by inserting the bash-like style line:. .. code:: bash; ; #!/usr/bin/cling; ; 3. **Rapid Application Development (RAD):**. Cling can be used successfully for Rapid Application Development allowing for; prototyping and proofs of concept taking advantage of dynamicity and feedback; during the implementation process. 4. **Runtime-Generated Code**. Sometime it's convenient to create code as a reaction to input; (user/network/configuration). Runtime-generated code can interface with C++; libraries. 5. **Embedding Cling:**. The functionality of an application can be enriched by embedding Cling. To embed; Cling, the main program has to be provided. One of the things this main program; has to do is initialize the Cling interpreter. There are optional calls to pass; command line arguments to Cling. Afterwards, you can call the interpreter from; any anywhere within the application. For compilation and linkage the application needs the path to the Clang and LLVM; libraries and the invocation is order dependent since the linker cannot do; backward searches. .. code:: bash. g++ embedcling.cxx -std=c++11 -L/usr/local/lib; -lclingInterpreter -lclingUtils ; -lclangFrontend -lclangSerialization -lclangParse -lclangSema ; -lclangAnalysis -lclangEdit -lclangLex -lclangDriver -lclangCodeGen ; -lclangBasic -lclangAST ; `llvm-config ; --libs bitwriter mcjit orcjit native option ; ipo profiledata instrumentation objcarcopts` ; -lz -pthread -ldl -ltinfo ; -o embedcling; . Embedding Cling requires the creation of the interpreter. Optionally compiler; arguments and the resource directory of LLVM can be passed. An example is the; following:. .. code:: bash. #include ""cling/Interpreter/Interpreter.h"". int main(int argc, char** argv) {; const char* LLVMRESDIR = ""/usr/local/""; //path to llvm resource directory; cling::Interpreter interp(argc, argv, LLVMRESDIR);. interp.declare(""int p=0;"");; }; ; A more complete example could be found in `<tools/demo/cling-demo.cpp>`_.;",MatchSource.DOCS,interpreter/cling/docs/chapters/why_interpreting.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/why_interpreting.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/why_interpreting.rst:877,Modifiability,config,configuration,877,"Why interpreting C++ with Cling?; -----------------------------------. 1. **Learning C++:**; ; One use case of Cling is to aid the C++ learning process. Offering imediate; feedback the user can easily get familiar with the structures and spelling of; the language. 2. **Creating scripts:**; ; The power of an interpreter lays as well in the compactness and ease of; repeatedly running a small snippet of code - aka a script. This can be done in; Cling by inserting the bash-like style line:. .. code:: bash; ; #!/usr/bin/cling; ; 3. **Rapid Application Development (RAD):**. Cling can be used successfully for Rapid Application Development allowing for; prototyping and proofs of concept taking advantage of dynamicity and feedback; during the implementation process. 4. **Runtime-Generated Code**. Sometime it's convenient to create code as a reaction to input; (user/network/configuration). Runtime-generated code can interface with C++; libraries. 5. **Embedding Cling:**. The functionality of an application can be enriched by embedding Cling. To embed; Cling, the main program has to be provided. One of the things this main program; has to do is initialize the Cling interpreter. There are optional calls to pass; command line arguments to Cling. Afterwards, you can call the interpreter from; any anywhere within the application. For compilation and linkage the application needs the path to the Clang and LLVM; libraries and the invocation is order dependent since the linker cannot do; backward searches. .. code:: bash. g++ embedcling.cxx -std=c++11 -L/usr/local/lib; -lclingInterpreter -lclingUtils ; -lclangFrontend -lclangSerialization -lclangParse -lclangSema ; -lclangAnalysis -lclangEdit -lclangLex -lclangDriver -lclangCodeGen ; -lclangBasic -lclangAST ; `llvm-config ; --libs bitwriter mcjit orcjit native option ; ipo profiledata instrumentation objcarcopts` ; -lz -pthread -ldl -ltinfo ; -o embedcling; . Embedding Cling requires the creation of the interpreter. Optionally compile",MatchSource.DOCS,interpreter/cling/docs/chapters/why_interpreting.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/why_interpreting.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/why_interpreting.rst:1778,Modifiability,config,config,1778,"his can be done in; Cling by inserting the bash-like style line:. .. code:: bash; ; #!/usr/bin/cling; ; 3. **Rapid Application Development (RAD):**. Cling can be used successfully for Rapid Application Development allowing for; prototyping and proofs of concept taking advantage of dynamicity and feedback; during the implementation process. 4. **Runtime-Generated Code**. Sometime it's convenient to create code as a reaction to input; (user/network/configuration). Runtime-generated code can interface with C++; libraries. 5. **Embedding Cling:**. The functionality of an application can be enriched by embedding Cling. To embed; Cling, the main program has to be provided. One of the things this main program; has to do is initialize the Cling interpreter. There are optional calls to pass; command line arguments to Cling. Afterwards, you can call the interpreter from; any anywhere within the application. For compilation and linkage the application needs the path to the Clang and LLVM; libraries and the invocation is order dependent since the linker cannot do; backward searches. .. code:: bash. g++ embedcling.cxx -std=c++11 -L/usr/local/lib; -lclingInterpreter -lclingUtils ; -lclangFrontend -lclangSerialization -lclangParse -lclangSema ; -lclangAnalysis -lclangEdit -lclangLex -lclangDriver -lclangCodeGen ; -lclangBasic -lclangAST ; `llvm-config ; --libs bitwriter mcjit orcjit native option ; ipo profiledata instrumentation objcarcopts` ; -lz -pthread -ldl -ltinfo ; -o embedcling; . Embedding Cling requires the creation of the interpreter. Optionally compiler; arguments and the resource directory of LLVM can be passed. An example is the; following:. .. code:: bash. #include ""cling/Interpreter/Interpreter.h"". int main(int argc, char** argv) {; const char* LLVMRESDIR = ""/usr/local/""; //path to llvm resource directory; cling::Interpreter interp(argc, argv, LLVMRESDIR);. interp.declare(""int p=0;"");; }; ; A more complete example could be found in `<tools/demo/cling-demo.cpp>`_.; ",MatchSource.DOCS,interpreter/cling/docs/chapters/why_interpreting.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/why_interpreting.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/why_interpreting.rst:135,Usability,learn,learning,135,"Why interpreting C++ with Cling?; -----------------------------------. 1. **Learning C++:**; ; One use case of Cling is to aid the C++ learning process. Offering imediate; feedback the user can easily get familiar with the structures and spelling of; the language. 2. **Creating scripts:**; ; The power of an interpreter lays as well in the compactness and ease of; repeatedly running a small snippet of code - aka a script. This can be done in; Cling by inserting the bash-like style line:. .. code:: bash; ; #!/usr/bin/cling; ; 3. **Rapid Application Development (RAD):**. Cling can be used successfully for Rapid Application Development allowing for; prototyping and proofs of concept taking advantage of dynamicity and feedback; during the implementation process. 4. **Runtime-Generated Code**. Sometime it's convenient to create code as a reaction to input; (user/network/configuration). Runtime-generated code can interface with C++; libraries. 5. **Embedding Cling:**. The functionality of an application can be enriched by embedding Cling. To embed; Cling, the main program has to be provided. One of the things this main program; has to do is initialize the Cling interpreter. There are optional calls to pass; command line arguments to Cling. Afterwards, you can call the interpreter from; any anywhere within the application. For compilation and linkage the application needs the path to the Clang and LLVM; libraries and the invocation is order dependent since the linker cannot do; backward searches. .. code:: bash. g++ embedcling.cxx -std=c++11 -L/usr/local/lib; -lclingInterpreter -lclingUtils ; -lclangFrontend -lclangSerialization -lclangParse -lclangSema ; -lclangAnalysis -lclangEdit -lclangLex -lclangDriver -lclangCodeGen ; -lclangBasic -lclangAST ; `llvm-config ; --libs bitwriter mcjit orcjit native option ; ipo profiledata instrumentation objcarcopts` ; -lz -pthread -ldl -ltinfo ; -o embedcling; . Embedding Cling requires the creation of the interpreter. Optionally compile",MatchSource.DOCS,interpreter/cling/docs/chapters/why_interpreting.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/why_interpreting.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/why_interpreting.rst:172,Usability,feedback,feedback,172,"Why interpreting C++ with Cling?; -----------------------------------. 1. **Learning C++:**; ; One use case of Cling is to aid the C++ learning process. Offering imediate; feedback the user can easily get familiar with the structures and spelling of; the language. 2. **Creating scripts:**; ; The power of an interpreter lays as well in the compactness and ease of; repeatedly running a small snippet of code - aka a script. This can be done in; Cling by inserting the bash-like style line:. .. code:: bash; ; #!/usr/bin/cling; ; 3. **Rapid Application Development (RAD):**. Cling can be used successfully for Rapid Application Development allowing for; prototyping and proofs of concept taking advantage of dynamicity and feedback; during the implementation process. 4. **Runtime-Generated Code**. Sometime it's convenient to create code as a reaction to input; (user/network/configuration). Runtime-generated code can interface with C++; libraries. 5. **Embedding Cling:**. The functionality of an application can be enriched by embedding Cling. To embed; Cling, the main program has to be provided. One of the things this main program; has to do is initialize the Cling interpreter. There are optional calls to pass; command line arguments to Cling. Afterwards, you can call the interpreter from; any anywhere within the application. For compilation and linkage the application needs the path to the Clang and LLVM; libraries and the invocation is order dependent since the linker cannot do; backward searches. .. code:: bash. g++ embedcling.cxx -std=c++11 -L/usr/local/lib; -lclingInterpreter -lclingUtils ; -lclangFrontend -lclangSerialization -lclangParse -lclangSema ; -lclangAnalysis -lclangEdit -lclangLex -lclangDriver -lclangCodeGen ; -lclangBasic -lclangAST ; `llvm-config ; --libs bitwriter mcjit orcjit native option ; ipo profiledata instrumentation objcarcopts` ; -lz -pthread -ldl -ltinfo ; -o embedcling; . Embedding Cling requires the creation of the interpreter. Optionally compile",MatchSource.DOCS,interpreter/cling/docs/chapters/why_interpreting.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/why_interpreting.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/why_interpreting.rst:723,Usability,feedback,feedback,723,"Why interpreting C++ with Cling?; -----------------------------------. 1. **Learning C++:**; ; One use case of Cling is to aid the C++ learning process. Offering imediate; feedback the user can easily get familiar with the structures and spelling of; the language. 2. **Creating scripts:**; ; The power of an interpreter lays as well in the compactness and ease of; repeatedly running a small snippet of code - aka a script. This can be done in; Cling by inserting the bash-like style line:. .. code:: bash; ; #!/usr/bin/cling; ; 3. **Rapid Application Development (RAD):**. Cling can be used successfully for Rapid Application Development allowing for; prototyping and proofs of concept taking advantage of dynamicity and feedback; during the implementation process. 4. **Runtime-Generated Code**. Sometime it's convenient to create code as a reaction to input; (user/network/configuration). Runtime-generated code can interface with C++; libraries. 5. **Embedding Cling:**. The functionality of an application can be enriched by embedding Cling. To embed; Cling, the main program has to be provided. One of the things this main program; has to do is initialize the Cling interpreter. There are optional calls to pass; command line arguments to Cling. Afterwards, you can call the interpreter from; any anywhere within the application. For compilation and linkage the application needs the path to the Clang and LLVM; libraries and the invocation is order dependent since the linker cannot do; backward searches. .. code:: bash. g++ embedcling.cxx -std=c++11 -L/usr/local/lib; -lclingInterpreter -lclingUtils ; -lclangFrontend -lclangSerialization -lclangParse -lclangSema ; -lclangAnalysis -lclangEdit -lclangLex -lclangDriver -lclangCodeGen ; -lclangBasic -lclangAST ; `llvm-config ; --libs bitwriter mcjit orcjit native option ; ipo profiledata instrumentation objcarcopts` ; -lz -pthread -ldl -ltinfo ; -o embedcling; . Embedding Cling requires the creation of the interpreter. Optionally compile",MatchSource.DOCS,interpreter/cling/docs/chapters/why_interpreting.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/cling/docs/chapters/why_interpreting.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/CodeOwners.rst:3178,Availability,mask,maskray,3178,"hkeane (GitHub). Debug information; ~~~~~~~~~~~~~~~~~; | Adrian Prantl; | aprantl\@apple.com (email), aprantl (Phabricator), adrian-prantl (GitHub). | David Blaikie; | dblaikie\@gmail.com (email), dblaikie (Phabricator), dwblaikie (GitHub). | Eric Christopher; | echristo\@gmail.com (email), echristo (Phabricator), echristo (GitHub). Exception handling; ~~~~~~~~~~~~~~~~~~; | Anton Korobeynikov; | anton\@korobeynikov.info (email), asl (Phabricator), asl (GitHub). Clang static analyzer; ~~~~~~~~~~~~~~~~~~~~~; | Artem Dergachev; | adergachev\@apple.com (email), NoQ (Phabricator), haoNoQ (GitHub). | Gábor Horváth; | xazax.hun\@gmail.com (email), xazax.hun (Phabricator), Xazax-hun (GitHub). Compiler options; ~~~~~~~~~~~~~~~~; | Jan Svoboda; | jan_svoboda\@apple.com (email), jansvoboda11 (Phabricator), jansvoboda11 (GitHub). OpenBSD driver; ~~~~~~~~~~~~~~; | Brad Smith; | brad\@comstyle.com (email), brad (Phabricator), brad0 (GitHub). Driver parts not covered by someone else; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~; | Fangrui Song; | maskray\@google.com (email), MaskRay (Phabricator), MaskRay (GitHub). Tools; -----; These code owners are responsible for user-facing tools under the Clang; umbrella or components used to support such tools. Tooling library; ~~~~~~~~~~~~~~~; | Manuel Klimek; | klimek\@google.com (email), klimek (Phabricator), r4nt (GitHub). clang-format; ~~~~~~~~~~~~; | MyDeveloperDay; | mydeveloperday\@gmail.com (email), MyDeveloperDay (Phabricator), MyDeveloperDay (GitHub). | Owen Pan; | owenpiano\@gmail.com (email), owenpan (Phabricator), owenca (GitHub). ABIs; ----; The following people are responsible for decisions involving ABI. Itanium ABI; ~~~~~~~~~~~; | John McCall; | rjmccall\@apple.com (email), rjmccall (Phabricator), rjmccall (GitHub). Microsoft ABI; ~~~~~~~~~~~~~; | Reid Kleckner; | rnk\@google.com (email), rnk (Phabricator), rnk (GitHub). ARM EABI; ~~~~~~~~; | Anton Korobeynikov; | anton\@korobeynikov.info (email), asl (Phabricator), asl (GitHub)",MatchSource.DOCS,interpreter/llvm-project/clang/CodeOwners.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/CodeOwners.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/CodeOwners.rst:4826,Deployability,integrat,integration,4826,"l\@apple.com (email), rjmccall (Phabricator), rjmccall (GitHub). Microsoft ABI; ~~~~~~~~~~~~~; | Reid Kleckner; | rnk\@google.com (email), rnk (Phabricator), rnk (GitHub). ARM EABI; ~~~~~~~~; | Anton Korobeynikov; | anton\@korobeynikov.info (email), asl (Phabricator), asl (GitHub). Compiler-Wide Topics; --------------------; The following people are responsible for functionality that does not fit into; a single part of the compiler, but instead span multiple components within the; compiler. Attributes; ~~~~~~~~~~; | Erich Keane; | ekeane\@nvidia.com (email), ErichKeane (Phabricator), erichkeane (GitHub). Inline assembly; ~~~~~~~~~~~~~~~; | Eric Christopher; | echristo\@gmail.com (email), echristo (Phabricator), echristo (GitHub). Text encodings; ~~~~~~~~~~~~~~; | Tom Honermann; | tom\@honermann.net (email), tahonermann (Phabricator), tahonermann (GitHub). | Corentin Jabot; | corentin.jabot\@gmail.com (email), cor3ntin (Phabricator), cor3ntin (GitHub). CMake integration; ~~~~~~~~~~~~~~~~~; | Petr Hosek; | phosek\@google.com (email), phosek (Phabricator), petrhosek (GitHub). | John Ericson; | git\@johnericson.me (email), Ericson2314 (Phabricator), Ericson2314 (GitHub). General Windows support; ~~~~~~~~~~~~~~~~~~~~~~~; | Reid Kleckner; | rnk\@google.com (email), rnk (Phabricator), rnk (GitHub). Incremental compilation, REPLs, clang-repl; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~; | Vassil Vassilev; | Vassil.Vassilev\@cern.ch (email), v.g.vassilev (Phabricator), vgvassilev (GitHub). Standards Conformance; ---------------------; The following people are responsible for validating that changes are conforming; to a relevant standard. Contact them for questions about how to interpret a; standard, when fixing standards bugs, or when implementing a new standard feature. C conformance; ~~~~~~~~~~~~~; | Aaron Ballman; | aaron\@aaronballman.com (email), aaron.ballman (Phabricator), AaronBallman (GitHub), AaronBallman (Discourse), aaronballman (Discord), AaronBallman (IRC). C++ ",MatchSource.DOCS,interpreter/llvm-project/clang/CodeOwners.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/CodeOwners.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/CodeOwners.rst:4826,Integrability,integrat,integration,4826,"l\@apple.com (email), rjmccall (Phabricator), rjmccall (GitHub). Microsoft ABI; ~~~~~~~~~~~~~; | Reid Kleckner; | rnk\@google.com (email), rnk (Phabricator), rnk (GitHub). ARM EABI; ~~~~~~~~; | Anton Korobeynikov; | anton\@korobeynikov.info (email), asl (Phabricator), asl (GitHub). Compiler-Wide Topics; --------------------; The following people are responsible for functionality that does not fit into; a single part of the compiler, but instead span multiple components within the; compiler. Attributes; ~~~~~~~~~~; | Erich Keane; | ekeane\@nvidia.com (email), ErichKeane (Phabricator), erichkeane (GitHub). Inline assembly; ~~~~~~~~~~~~~~~; | Eric Christopher; | echristo\@gmail.com (email), echristo (Phabricator), echristo (GitHub). Text encodings; ~~~~~~~~~~~~~~; | Tom Honermann; | tom\@honermann.net (email), tahonermann (Phabricator), tahonermann (GitHub). | Corentin Jabot; | corentin.jabot\@gmail.com (email), cor3ntin (Phabricator), cor3ntin (GitHub). CMake integration; ~~~~~~~~~~~~~~~~~; | Petr Hosek; | phosek\@google.com (email), phosek (Phabricator), petrhosek (GitHub). | John Ericson; | git\@johnericson.me (email), Ericson2314 (Phabricator), Ericson2314 (GitHub). General Windows support; ~~~~~~~~~~~~~~~~~~~~~~~; | Reid Kleckner; | rnk\@google.com (email), rnk (Phabricator), rnk (GitHub). Incremental compilation, REPLs, clang-repl; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~; | Vassil Vassilev; | Vassil.Vassilev\@cern.ch (email), v.g.vassilev (Phabricator), vgvassilev (GitHub). Standards Conformance; ---------------------; The following people are responsible for validating that changes are conforming; to a relevant standard. Contact them for questions about how to interpret a; standard, when fixing standards bugs, or when implementing a new standard feature. C conformance; ~~~~~~~~~~~~~; | Aaron Ballman; | aaron\@aaronballman.com (email), aaron.ballman (Phabricator), AaronBallman (GitHub), AaronBallman (Discourse), aaronballman (Discord), AaronBallman (IRC). C++ ",MatchSource.DOCS,interpreter/llvm-project/clang/CodeOwners.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/CodeOwners.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/CodeOwners.rst:6667,Performance,perform,performing,6667,"rnk (Phabricator), rnk (GitHub). Incremental compilation, REPLs, clang-repl; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~; | Vassil Vassilev; | Vassil.Vassilev\@cern.ch (email), v.g.vassilev (Phabricator), vgvassilev (GitHub). Standards Conformance; ---------------------; The following people are responsible for validating that changes are conforming; to a relevant standard. Contact them for questions about how to interpret a; standard, when fixing standards bugs, or when implementing a new standard feature. C conformance; ~~~~~~~~~~~~~; | Aaron Ballman; | aaron\@aaronballman.com (email), aaron.ballman (Phabricator), AaronBallman (GitHub), AaronBallman (Discourse), aaronballman (Discord), AaronBallman (IRC). C++ conformance; ~~~~~~~~~~~~~~~; | Hubert Tong; | hubert.reinterpretcast\@gmail.com (email), hubert.reinterpretcast (Phabricator), hubert-reinterpretcast (GitHub). Objective-C/C++ conformance; ~~~~~~~~~~~~~~~~~~~~~~~~~~~; | John McCall; | rjmccall\@apple.com (email), rjmccall (Phabricator), rjmccall (GitHub). OpenMP conformance; ~~~~~~~~~~~~~~~~~~; | Alexey Bataev; | a.bataev\@hotmail.com (email), ABataev (Phabricator), alexey-bataev (GitHub). OpenCL conformance; ~~~~~~~~~~~~~~~~~~; | Anastasia Stulova; | anastasia\@compiler-experts.com (email), Anastasia (Phabricator), AnastasiaStulova (GitHub). SYCL conformance; ~~~~~~~~~~~~~~~~; | Alexey Bader; | alexey.bader\@intel.com (email), bader (Phabricator), bader (GitHub). Former Code Owners; ==================; The following people have graciously spent time performing code ownership; responsibilities but are no longer active in that role. Thank you for all your; help with the success of the project!. Emeritus owners; ---------------; | Doug Gregor (dgregor\@apple.com); | Richard Smith (richard\@metafoo.co.uk). Former component owners; -----------------------; | Chandler Carruth (chandlerc\@gmail.com, chandlerc\@google.com) -- CMake, library layering; | Devin Coughlin (dcoughlin\@apple.com) -- Clang static analyzer; ",MatchSource.DOCS,interpreter/llvm-project/clang/CodeOwners.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/CodeOwners.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/CodeOwners.rst:5446,Security,validat,validating,5446,"abricator), erichkeane (GitHub). Inline assembly; ~~~~~~~~~~~~~~~; | Eric Christopher; | echristo\@gmail.com (email), echristo (Phabricator), echristo (GitHub). Text encodings; ~~~~~~~~~~~~~~; | Tom Honermann; | tom\@honermann.net (email), tahonermann (Phabricator), tahonermann (GitHub). | Corentin Jabot; | corentin.jabot\@gmail.com (email), cor3ntin (Phabricator), cor3ntin (GitHub). CMake integration; ~~~~~~~~~~~~~~~~~; | Petr Hosek; | phosek\@google.com (email), phosek (Phabricator), petrhosek (GitHub). | John Ericson; | git\@johnericson.me (email), Ericson2314 (Phabricator), Ericson2314 (GitHub). General Windows support; ~~~~~~~~~~~~~~~~~~~~~~~; | Reid Kleckner; | rnk\@google.com (email), rnk (Phabricator), rnk (GitHub). Incremental compilation, REPLs, clang-repl; ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~; | Vassil Vassilev; | Vassil.Vassilev\@cern.ch (email), v.g.vassilev (Phabricator), vgvassilev (GitHub). Standards Conformance; ---------------------; The following people are responsible for validating that changes are conforming; to a relevant standard. Contact them for questions about how to interpret a; standard, when fixing standards bugs, or when implementing a new standard feature. C conformance; ~~~~~~~~~~~~~; | Aaron Ballman; | aaron\@aaronballman.com (email), aaron.ballman (Phabricator), AaronBallman (GitHub), AaronBallman (Discourse), aaronballman (Discord), AaronBallman (IRC). C++ conformance; ~~~~~~~~~~~~~~~; | Hubert Tong; | hubert.reinterpretcast\@gmail.com (email), hubert.reinterpretcast (Phabricator), hubert-reinterpretcast (GitHub). Objective-C/C++ conformance; ~~~~~~~~~~~~~~~~~~~~~~~~~~~; | John McCall; | rjmccall\@apple.com (email), rjmccall (Phabricator), rjmccall (GitHub). OpenMP conformance; ~~~~~~~~~~~~~~~~~~; | Alexey Bataev; | a.bataev\@hotmail.com (email), ABataev (Phabricator), alexey-bataev (GitHub). OpenCL conformance; ~~~~~~~~~~~~~~~~~~; | Anastasia Stulova; | anastasia\@compiler-experts.com (email), Anastasia (Phabricator), Anasta",MatchSource.DOCS,interpreter/llvm-project/clang/CodeOwners.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/CodeOwners.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/cmake/README.rst:634,Availability,down,downstream,634,"=======================; LLVM Common CMake Utils; =======================. What goes here; --------------. These are CMake modules to be shared between LLVM projects strictly at build; time. In other words, they must not be included from an installed CMake module,; such as the ``Add*.cmake`` ones. Modules that are reachable from installed; modules should instead go in ``${project}/cmake/modules`` of the most upstream; project that uses them. The advantage of not putting these modules in an existing location like; ``llvm/cmake/modules`` is two-fold:. - Since they are not installed, we don't have to worry about any out-of-tree; downstream usage, and thus there is no need for stability. - Since they are available as part of the source at build-time, we don't have; to do the usual stand-alone vs combined-build dances, avoiding much; complexity. How to use; ----------. For tools, please do:. .. code-block:: cmake. if(NOT DEFINED LLVM_COMMON_CMAKE_UTILS); set(LLVM_COMMON_CMAKE_UTILS ${CMAKE_CURRENT_SOURCE_DIR}/../cmake); endif(). # Add path for custom modules.; list(INSERT CMAKE_MODULE_PATH 0; # project-specific module dirs first; ""${LLVM_COMMON_CMAKE_UTILS}/Modules""; ). Notes:. - The ``if(NOT DEFINED ...)`` guard is there because in combined builds, LLVM; will set this variable. This is useful for legacy builds where projects are; found in ``llvm/tools`` instead. - ``INSERT ... 0`` ensures these new entries are prepended to the front of the; module path, so nothing might shadow them by mistake. For runtime libs, we skip the ``if(NOT DEFINED`` part:. .. code-block:: cmake. set(LLVM_COMMON_CMAKE_UTILS ${CMAKE_CURRENT_SOURCE_DIR}/../cmake). ... # same as before. If ``llvm/tools`` legacy-style combined builds are deprecated, we should then; skip it everywhere, bringing the tools and runtimes boilerplate back in line.; ",MatchSource.DOCS,interpreter/llvm-project/cmake/README.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/cmake/README.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/cmake/README.rst:710,Availability,avail,available,710,"=======================; LLVM Common CMake Utils; =======================. What goes here; --------------. These are CMake modules to be shared between LLVM projects strictly at build; time. In other words, they must not be included from an installed CMake module,; such as the ``Add*.cmake`` ones. Modules that are reachable from installed; modules should instead go in ``${project}/cmake/modules`` of the most upstream; project that uses them. The advantage of not putting these modules in an existing location like; ``llvm/cmake/modules`` is two-fold:. - Since they are not installed, we don't have to worry about any out-of-tree; downstream usage, and thus there is no need for stability. - Since they are available as part of the source at build-time, we don't have; to do the usual stand-alone vs combined-build dances, avoiding much; complexity. How to use; ----------. For tools, please do:. .. code-block:: cmake. if(NOT DEFINED LLVM_COMMON_CMAKE_UTILS); set(LLVM_COMMON_CMAKE_UTILS ${CMAKE_CURRENT_SOURCE_DIR}/../cmake); endif(). # Add path for custom modules.; list(INSERT CMAKE_MODULE_PATH 0; # project-specific module dirs first; ""${LLVM_COMMON_CMAKE_UTILS}/Modules""; ). Notes:. - The ``if(NOT DEFINED ...)`` guard is there because in combined builds, LLVM; will set this variable. This is useful for legacy builds where projects are; found in ``llvm/tools`` instead. - ``INSERT ... 0`` ensures these new entries are prepended to the front of the; module path, so nothing might shadow them by mistake. For runtime libs, we skip the ``if(NOT DEFINED`` part:. .. code-block:: cmake. set(LLVM_COMMON_CMAKE_UTILS ${CMAKE_CURRENT_SOURCE_DIR}/../cmake). ... # same as before. If ``llvm/tools`` legacy-style combined builds are deprecated, we should then; skip it everywhere, bringing the tools and runtimes boilerplate back in line.; ",MatchSource.DOCS,interpreter/llvm-project/cmake/README.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/cmake/README.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/cmake/README.rst:241,Deployability,install,installed,241,"=======================; LLVM Common CMake Utils; =======================. What goes here; --------------. These are CMake modules to be shared between LLVM projects strictly at build; time. In other words, they must not be included from an installed CMake module,; such as the ``Add*.cmake`` ones. Modules that are reachable from installed; modules should instead go in ``${project}/cmake/modules`` of the most upstream; project that uses them. The advantage of not putting these modules in an existing location like; ``llvm/cmake/modules`` is two-fold:. - Since they are not installed, we don't have to worry about any out-of-tree; downstream usage, and thus there is no need for stability. - Since they are available as part of the source at build-time, we don't have; to do the usual stand-alone vs combined-build dances, avoiding much; complexity. How to use; ----------. For tools, please do:. .. code-block:: cmake. if(NOT DEFINED LLVM_COMMON_CMAKE_UTILS); set(LLVM_COMMON_CMAKE_UTILS ${CMAKE_CURRENT_SOURCE_DIR}/../cmake); endif(). # Add path for custom modules.; list(INSERT CMAKE_MODULE_PATH 0; # project-specific module dirs first; ""${LLVM_COMMON_CMAKE_UTILS}/Modules""; ). Notes:. - The ``if(NOT DEFINED ...)`` guard is there because in combined builds, LLVM; will set this variable. This is useful for legacy builds where projects are; found in ``llvm/tools`` instead. - ``INSERT ... 0`` ensures these new entries are prepended to the front of the; module path, so nothing might shadow them by mistake. For runtime libs, we skip the ``if(NOT DEFINED`` part:. .. code-block:: cmake. set(LLVM_COMMON_CMAKE_UTILS ${CMAKE_CURRENT_SOURCE_DIR}/../cmake). ... # same as before. If ``llvm/tools`` legacy-style combined builds are deprecated, we should then; skip it everywhere, bringing the tools and runtimes boilerplate back in line.; ",MatchSource.DOCS,interpreter/llvm-project/cmake/README.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/cmake/README.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/cmake/README.rst:331,Deployability,install,installed,331,"=======================; LLVM Common CMake Utils; =======================. What goes here; --------------. These are CMake modules to be shared between LLVM projects strictly at build; time. In other words, they must not be included from an installed CMake module,; such as the ``Add*.cmake`` ones. Modules that are reachable from installed; modules should instead go in ``${project}/cmake/modules`` of the most upstream; project that uses them. The advantage of not putting these modules in an existing location like; ``llvm/cmake/modules`` is two-fold:. - Since they are not installed, we don't have to worry about any out-of-tree; downstream usage, and thus there is no need for stability. - Since they are available as part of the source at build-time, we don't have; to do the usual stand-alone vs combined-build dances, avoiding much; complexity. How to use; ----------. For tools, please do:. .. code-block:: cmake. if(NOT DEFINED LLVM_COMMON_CMAKE_UTILS); set(LLVM_COMMON_CMAKE_UTILS ${CMAKE_CURRENT_SOURCE_DIR}/../cmake); endif(). # Add path for custom modules.; list(INSERT CMAKE_MODULE_PATH 0; # project-specific module dirs first; ""${LLVM_COMMON_CMAKE_UTILS}/Modules""; ). Notes:. - The ``if(NOT DEFINED ...)`` guard is there because in combined builds, LLVM; will set this variable. This is useful for legacy builds where projects are; found in ``llvm/tools`` instead. - ``INSERT ... 0`` ensures these new entries are prepended to the front of the; module path, so nothing might shadow them by mistake. For runtime libs, we skip the ``if(NOT DEFINED`` part:. .. code-block:: cmake. set(LLVM_COMMON_CMAKE_UTILS ${CMAKE_CURRENT_SOURCE_DIR}/../cmake). ... # same as before. If ``llvm/tools`` legacy-style combined builds are deprecated, we should then; skip it everywhere, bringing the tools and runtimes boilerplate back in line.; ",MatchSource.DOCS,interpreter/llvm-project/cmake/README.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/cmake/README.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/cmake/README.rst:577,Deployability,install,installed,577,"=======================; LLVM Common CMake Utils; =======================. What goes here; --------------. These are CMake modules to be shared between LLVM projects strictly at build; time. In other words, they must not be included from an installed CMake module,; such as the ``Add*.cmake`` ones. Modules that are reachable from installed; modules should instead go in ``${project}/cmake/modules`` of the most upstream; project that uses them. The advantage of not putting these modules in an existing location like; ``llvm/cmake/modules`` is two-fold:. - Since they are not installed, we don't have to worry about any out-of-tree; downstream usage, and thus there is no need for stability. - Since they are available as part of the source at build-time, we don't have; to do the usual stand-alone vs combined-build dances, avoiding much; complexity. How to use; ----------. For tools, please do:. .. code-block:: cmake. if(NOT DEFINED LLVM_COMMON_CMAKE_UTILS); set(LLVM_COMMON_CMAKE_UTILS ${CMAKE_CURRENT_SOURCE_DIR}/../cmake); endif(). # Add path for custom modules.; list(INSERT CMAKE_MODULE_PATH 0; # project-specific module dirs first; ""${LLVM_COMMON_CMAKE_UTILS}/Modules""; ). Notes:. - The ``if(NOT DEFINED ...)`` guard is there because in combined builds, LLVM; will set this variable. This is useful for legacy builds where projects are; found in ``llvm/tools`` instead. - ``INSERT ... 0`` ensures these new entries are prepended to the front of the; module path, so nothing might shadow them by mistake. For runtime libs, we skip the ``if(NOT DEFINED`` part:. .. code-block:: cmake. set(LLVM_COMMON_CMAKE_UTILS ${CMAKE_CURRENT_SOURCE_DIR}/../cmake). ... # same as before. If ``llvm/tools`` legacy-style combined builds are deprecated, we should then; skip it everywhere, bringing the tools and runtimes boilerplate back in line.; ",MatchSource.DOCS,interpreter/llvm-project/cmake/README.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/cmake/README.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/cmake/README.rst:1285,Modifiability,variab,variable,1285,"=======================; LLVM Common CMake Utils; =======================. What goes here; --------------. These are CMake modules to be shared between LLVM projects strictly at build; time. In other words, they must not be included from an installed CMake module,; such as the ``Add*.cmake`` ones. Modules that are reachable from installed; modules should instead go in ``${project}/cmake/modules`` of the most upstream; project that uses them. The advantage of not putting these modules in an existing location like; ``llvm/cmake/modules`` is two-fold:. - Since they are not installed, we don't have to worry about any out-of-tree; downstream usage, and thus there is no need for stability. - Since they are available as part of the source at build-time, we don't have; to do the usual stand-alone vs combined-build dances, avoiding much; complexity. How to use; ----------. For tools, please do:. .. code-block:: cmake. if(NOT DEFINED LLVM_COMMON_CMAKE_UTILS); set(LLVM_COMMON_CMAKE_UTILS ${CMAKE_CURRENT_SOURCE_DIR}/../cmake); endif(). # Add path for custom modules.; list(INSERT CMAKE_MODULE_PATH 0; # project-specific module dirs first; ""${LLVM_COMMON_CMAKE_UTILS}/Modules""; ). Notes:. - The ``if(NOT DEFINED ...)`` guard is there because in combined builds, LLVM; will set this variable. This is useful for legacy builds where projects are; found in ``llvm/tools`` instead. - ``INSERT ... 0`` ensures these new entries are prepended to the front of the; module path, so nothing might shadow them by mistake. For runtime libs, we skip the ``if(NOT DEFINED`` part:. .. code-block:: cmake. set(LLVM_COMMON_CMAKE_UTILS ${CMAKE_CURRENT_SOURCE_DIR}/../cmake). ... # same as before. If ``llvm/tools`` legacy-style combined builds are deprecated, we should then; skip it everywhere, bringing the tools and runtimes boilerplate back in line.; ",MatchSource.DOCS,interpreter/llvm-project/cmake/README.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/cmake/README.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/cmake/README.rst:826,Safety,avoid,avoiding,826,"=======================; LLVM Common CMake Utils; =======================. What goes here; --------------. These are CMake modules to be shared between LLVM projects strictly at build; time. In other words, they must not be included from an installed CMake module,; such as the ``Add*.cmake`` ones. Modules that are reachable from installed; modules should instead go in ``${project}/cmake/modules`` of the most upstream; project that uses them. The advantage of not putting these modules in an existing location like; ``llvm/cmake/modules`` is two-fold:. - Since they are not installed, we don't have to worry about any out-of-tree; downstream usage, and thus there is no need for stability. - Since they are available as part of the source at build-time, we don't have; to do the usual stand-alone vs combined-build dances, avoiding much; complexity. How to use; ----------. For tools, please do:. .. code-block:: cmake. if(NOT DEFINED LLVM_COMMON_CMAKE_UTILS); set(LLVM_COMMON_CMAKE_UTILS ${CMAKE_CURRENT_SOURCE_DIR}/../cmake); endif(). # Add path for custom modules.; list(INSERT CMAKE_MODULE_PATH 0; # project-specific module dirs first; ""${LLVM_COMMON_CMAKE_UTILS}/Modules""; ). Notes:. - The ``if(NOT DEFINED ...)`` guard is there because in combined builds, LLVM; will set this variable. This is useful for legacy builds where projects are; found in ``llvm/tools`` instead. - ``INSERT ... 0`` ensures these new entries are prepended to the front of the; module path, so nothing might shadow them by mistake. For runtime libs, we skip the ``if(NOT DEFINED`` part:. .. code-block:: cmake. set(LLVM_COMMON_CMAKE_UTILS ${CMAKE_CURRENT_SOURCE_DIR}/../cmake). ... # same as before. If ``llvm/tools`` legacy-style combined builds are deprecated, we should then; skip it everywhere, bringing the tools and runtimes boilerplate back in line.; ",MatchSource.DOCS,interpreter/llvm-project/cmake/README.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/cmake/README.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:140,Availability,error,error,140,"================; AddressSanitizer; ================. .. contents::; :local:. Introduction; ============. AddressSanitizer is a fast memory error detector. It consists of a compiler; instrumentation module and a run-time library. The tool can detect the; following types of bugs:. * Out-of-bounds accesses to heap, stack and globals; * Use-after-free; * Use-after-return (clang flag ``-fsanitize-address-use-after-return=(never|runtime|always)`` default: ``runtime``); * Enable with: ``ASAN_OPTIONS=detect_stack_use_after_return=1`` (already enabled on Linux).; * Disable with: ``ASAN_OPTIONS=detect_stack_use_after_return=0``.; * Use-after-scope (clang flag ``-fsanitize-address-use-after-scope``); * Double-free, invalid free; * Memory leaks (experimental). Typical slowdown introduced by AddressSanitizer is **2x**. How to build; ============. Build LLVM/Clang with `CMake <https://llvm.org/docs/CMake.html>` and enable; the ``compiler-rt`` runtime. An example CMake configuration that will allow; for the use/testing of AddressSanitizer:. .. code-block:: console. $ cmake -DCMAKE_BUILD_TYPE=Release -DLLVM_ENABLE_PROJECTS=""clang"" -DLLVM_ENABLE_RUNTIMES=""compiler-rt"" <path to source>/llvm. Usage; =====. Simply compile and link your program with ``-fsanitize=address`` flag. The; AddressSanitizer run-time library should be linked to the final executable, so; make sure to use ``clang`` (not ``ld``) for the final link step. When linking; shared libraries, the AddressSanitizer run-time is not linked, so; ``-Wl,-z,defs`` may cause link errors (don't use it with AddressSanitizer). To; get a reasonable performance add ``-O1`` or higher. To get nicer stack traces; in error messages add ``-fno-omit-frame-pointer``. To get perfect stack traces; you may need to disable inlining (just use ``-O1``) and tail call elimination; (``-fno-optimize-sibling-calls``). .. code-block:: console. % cat example_UseAfterFree.cc; int main(int argc, char **argv) {; int *array = new int[100];; delete [] array;; r",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:1541,Availability,error,errors,1541,"stack_use_after_return=1`` (already enabled on Linux).; * Disable with: ``ASAN_OPTIONS=detect_stack_use_after_return=0``.; * Use-after-scope (clang flag ``-fsanitize-address-use-after-scope``); * Double-free, invalid free; * Memory leaks (experimental). Typical slowdown introduced by AddressSanitizer is **2x**. How to build; ============. Build LLVM/Clang with `CMake <https://llvm.org/docs/CMake.html>` and enable; the ``compiler-rt`` runtime. An example CMake configuration that will allow; for the use/testing of AddressSanitizer:. .. code-block:: console. $ cmake -DCMAKE_BUILD_TYPE=Release -DLLVM_ENABLE_PROJECTS=""clang"" -DLLVM_ENABLE_RUNTIMES=""compiler-rt"" <path to source>/llvm. Usage; =====. Simply compile and link your program with ``-fsanitize=address`` flag. The; AddressSanitizer run-time library should be linked to the final executable, so; make sure to use ``clang`` (not ``ld``) for the final link step. When linking; shared libraries, the AddressSanitizer run-time is not linked, so; ``-Wl,-z,defs`` may cause link errors (don't use it with AddressSanitizer). To; get a reasonable performance add ``-O1`` or higher. To get nicer stack traces; in error messages add ``-fno-omit-frame-pointer``. To get perfect stack traces; you may need to disable inlining (just use ``-O1``) and tail call elimination; (``-fno-optimize-sibling-calls``). .. code-block:: console. % cat example_UseAfterFree.cc; int main(int argc, char **argv) {; int *array = new int[100];; delete [] array;; return array[argc]; // BOOM; }. # Compile and link; % clang++ -O1 -g -fsanitize=address -fno-omit-frame-pointer example_UseAfterFree.cc. or:. .. code-block:: console. # Compile; % clang++ -O1 -g -fsanitize=address -fno-omit-frame-pointer -c example_UseAfterFree.cc; # Link; % clang++ -g -fsanitize=address example_UseAfterFree.o. If a bug is detected, the program will print an error message to stderr and; exit with a non-zero exit code. AddressSanitizer exits on the first detected error.; This is by desi",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:1672,Availability,error,error,1672,"use-after-scope``); * Double-free, invalid free; * Memory leaks (experimental). Typical slowdown introduced by AddressSanitizer is **2x**. How to build; ============. Build LLVM/Clang with `CMake <https://llvm.org/docs/CMake.html>` and enable; the ``compiler-rt`` runtime. An example CMake configuration that will allow; for the use/testing of AddressSanitizer:. .. code-block:: console. $ cmake -DCMAKE_BUILD_TYPE=Release -DLLVM_ENABLE_PROJECTS=""clang"" -DLLVM_ENABLE_RUNTIMES=""compiler-rt"" <path to source>/llvm. Usage; =====. Simply compile and link your program with ``-fsanitize=address`` flag. The; AddressSanitizer run-time library should be linked to the final executable, so; make sure to use ``clang`` (not ``ld``) for the final link step. When linking; shared libraries, the AddressSanitizer run-time is not linked, so; ``-Wl,-z,defs`` may cause link errors (don't use it with AddressSanitizer). To; get a reasonable performance add ``-O1`` or higher. To get nicer stack traces; in error messages add ``-fno-omit-frame-pointer``. To get perfect stack traces; you may need to disable inlining (just use ``-O1``) and tail call elimination; (``-fno-optimize-sibling-calls``). .. code-block:: console. % cat example_UseAfterFree.cc; int main(int argc, char **argv) {; int *array = new int[100];; delete [] array;; return array[argc]; // BOOM; }. # Compile and link; % clang++ -O1 -g -fsanitize=address -fno-omit-frame-pointer example_UseAfterFree.cc. or:. .. code-block:: console. # Compile; % clang++ -O1 -g -fsanitize=address -fno-omit-frame-pointer -c example_UseAfterFree.cc; # Link; % clang++ -g -fsanitize=address example_UseAfterFree.o. If a bug is detected, the program will print an error message to stderr and; exit with a non-zero exit code. AddressSanitizer exits on the first detected error.; This is by design:. * This approach allows AddressSanitizer to produce faster and smaller generated code; (both by ~5%).; * Fixing bugs becomes unavoidable. AddressSanitizer does not produ",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:2378,Availability,error,error,2378,"clang`` (not ``ld``) for the final link step. When linking; shared libraries, the AddressSanitizer run-time is not linked, so; ``-Wl,-z,defs`` may cause link errors (don't use it with AddressSanitizer). To; get a reasonable performance add ``-O1`` or higher. To get nicer stack traces; in error messages add ``-fno-omit-frame-pointer``. To get perfect stack traces; you may need to disable inlining (just use ``-O1``) and tail call elimination; (``-fno-optimize-sibling-calls``). .. code-block:: console. % cat example_UseAfterFree.cc; int main(int argc, char **argv) {; int *array = new int[100];; delete [] array;; return array[argc]; // BOOM; }. # Compile and link; % clang++ -O1 -g -fsanitize=address -fno-omit-frame-pointer example_UseAfterFree.cc. or:. .. code-block:: console. # Compile; % clang++ -O1 -g -fsanitize=address -fno-omit-frame-pointer -c example_UseAfterFree.cc; # Link; % clang++ -g -fsanitize=address example_UseAfterFree.o. If a bug is detected, the program will print an error message to stderr and; exit with a non-zero exit code. AddressSanitizer exits on the first detected error.; This is by design:. * This approach allows AddressSanitizer to produce faster and smaller generated code; (both by ~5%).; * Fixing bugs becomes unavoidable. AddressSanitizer does not produce; false alarms. Once a memory corruption occurs, the program is in an inconsistent; state, which could lead to confusing results and potentially misleading; subsequent reports. If your process is sandboxed and you are running on OS X 10.10 or earlier, you; will need to set ``DYLD_INSERT_LIBRARIES`` environment variable and point it to; the ASan library that is packaged with the compiler used to build the; executable. (You can find the library by searching for dynamic libraries with; ``asan`` in their name.) If the environment variable is not set, the process will; try to re-exec. Also keep in mind that when moving the executable to another machine,; the ASan library will also need to be copied",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:2484,Availability,error,error,2484," AddressSanitizer run-time is not linked, so; ``-Wl,-z,defs`` may cause link errors (don't use it with AddressSanitizer). To; get a reasonable performance add ``-O1`` or higher. To get nicer stack traces; in error messages add ``-fno-omit-frame-pointer``. To get perfect stack traces; you may need to disable inlining (just use ``-O1``) and tail call elimination; (``-fno-optimize-sibling-calls``). .. code-block:: console. % cat example_UseAfterFree.cc; int main(int argc, char **argv) {; int *array = new int[100];; delete [] array;; return array[argc]; // BOOM; }. # Compile and link; % clang++ -O1 -g -fsanitize=address -fno-omit-frame-pointer example_UseAfterFree.cc. or:. .. code-block:: console. # Compile; % clang++ -O1 -g -fsanitize=address -fno-omit-frame-pointer -c example_UseAfterFree.cc; # Link; % clang++ -g -fsanitize=address example_UseAfterFree.o. If a bug is detected, the program will print an error message to stderr and; exit with a non-zero exit code. AddressSanitizer exits on the first detected error.; This is by design:. * This approach allows AddressSanitizer to produce faster and smaller generated code; (both by ~5%).; * Fixing bugs becomes unavoidable. AddressSanitizer does not produce; false alarms. Once a memory corruption occurs, the program is in an inconsistent; state, which could lead to confusing results and potentially misleading; subsequent reports. If your process is sandboxed and you are running on OS X 10.10 or earlier, you; will need to set ``DYLD_INSERT_LIBRARIES`` environment variable and point it to; the ASan library that is packaged with the compiler used to build the; executable. (You can find the library by searching for dynamic libraries with; ``asan`` in their name.) If the environment variable is not set, the process will; try to re-exec. Also keep in mind that when moving the executable to another machine,; the ASan library will also need to be copied over. Symbolizing the Reports; =========================. To make AddressSaniti",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:5835,Availability,avail,available,5835,"se-after-free on address 0x7f7ddab8c084 at pc 0x403c8c bp 0x7fff87fb82d0 sp 0x7fff87fb82c8; READ of size 4 at 0x7f7ddab8c084 thread T0; #0 0x403c8c in main example_UseAfterFree.cc:4; #1 0x7f7ddabcac4d in __libc_start_main ??:0; ... Note that on macOS you may need to run ``dsymutil`` on your binary to have the; file\:line info in the AddressSanitizer reports. Additional Checks; =================. Initialization order checking; -----------------------------. AddressSanitizer can optionally detect dynamic initialization order problems,; when initialization of globals defined in one translation unit uses; globals defined in another translation unit. To enable this check at runtime,; you should set environment variable; ``ASAN_OPTIONS=check_initialization_order=1``. Note that this option is not supported on macOS. Stack Use After Return (UAR); ----------------------------. AddressSanitizer can optionally detect stack use after return problems.; This is available by default, or explicitly; (``-fsanitize-address-use-after-return=runtime``).; To disable this check at runtime, set the environment variable; ``ASAN_OPTIONS=detect_stack_use_after_return=0``. Enabling this check (``-fsanitize-address-use-after-return=always``) will; reduce code size. The code size may be reduced further by completely; eliminating this check (``-fsanitize-address-use-after-return=never``). To summarize: ``-fsanitize-address-use-after-return=<mode>``; * ``never``: Completely disables detection of UAR errors (reduces code size).; * ``runtime``: Adds the code for detection, but it can be disable via the; runtime environment (``ASAN_OPTIONS=detect_stack_use_after_return=0``).; * ``always``: Enables detection of UAR errors in all cases. (reduces code; size, but not as much as ``never``). Memory leak detection; ---------------------. For more information on leak detector in AddressSanitizer, see; :doc:`LeakSanitizer`. The leak detection is turned on by default on Linux,; and can be enabled using ``ASAN_",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:6367,Availability,error,errors,6367,"--------. AddressSanitizer can optionally detect dynamic initialization order problems,; when initialization of globals defined in one translation unit uses; globals defined in another translation unit. To enable this check at runtime,; you should set environment variable; ``ASAN_OPTIONS=check_initialization_order=1``. Note that this option is not supported on macOS. Stack Use After Return (UAR); ----------------------------. AddressSanitizer can optionally detect stack use after return problems.; This is available by default, or explicitly; (``-fsanitize-address-use-after-return=runtime``).; To disable this check at runtime, set the environment variable; ``ASAN_OPTIONS=detect_stack_use_after_return=0``. Enabling this check (``-fsanitize-address-use-after-return=always``) will; reduce code size. The code size may be reduced further by completely; eliminating this check (``-fsanitize-address-use-after-return=never``). To summarize: ``-fsanitize-address-use-after-return=<mode>``; * ``never``: Completely disables detection of UAR errors (reduces code size).; * ``runtime``: Adds the code for detection, but it can be disable via the; runtime environment (``ASAN_OPTIONS=detect_stack_use_after_return=0``).; * ``always``: Enables detection of UAR errors in all cases. (reduces code; size, but not as much as ``never``). Memory leak detection; ---------------------. For more information on leak detector in AddressSanitizer, see; :doc:`LeakSanitizer`. The leak detection is turned on by default on Linux,; and can be enabled using ``ASAN_OPTIONS=detect_leaks=1`` on macOS;; however, it is not yet supported on other platforms. Issue Suppression; =================. AddressSanitizer is not expected to produce false positives. If you see one,; look again; most likely it is a true positive!. Suppressing Reports in External Libraries; -----------------------------------------; Runtime interposition allows AddressSanitizer to find bugs in code that is; not being recompiled. If you run in",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:6583,Availability,error,errors,6583,"set environment variable; ``ASAN_OPTIONS=check_initialization_order=1``. Note that this option is not supported on macOS. Stack Use After Return (UAR); ----------------------------. AddressSanitizer can optionally detect stack use after return problems.; This is available by default, or explicitly; (``-fsanitize-address-use-after-return=runtime``).; To disable this check at runtime, set the environment variable; ``ASAN_OPTIONS=detect_stack_use_after_return=0``. Enabling this check (``-fsanitize-address-use-after-return=always``) will; reduce code size. The code size may be reduced further by completely; eliminating this check (``-fsanitize-address-use-after-return=never``). To summarize: ``-fsanitize-address-use-after-return=<mode>``; * ``never``: Completely disables detection of UAR errors (reduces code size).; * ``runtime``: Adds the code for detection, but it can be disable via the; runtime environment (``ASAN_OPTIONS=detect_stack_use_after_return=0``).; * ``always``: Enables detection of UAR errors in all cases. (reduces code; size, but not as much as ``never``). Memory leak detection; ---------------------. For more information on leak detector in AddressSanitizer, see; :doc:`LeakSanitizer`. The leak detection is turned on by default on Linux,; and can be enabled using ``ASAN_OPTIONS=detect_leaks=1`` on macOS;; however, it is not yet supported on other platforms. Issue Suppression; =================. AddressSanitizer is not expected to produce false positives. If you see one,; look again; most likely it is a true positive!. Suppressing Reports in External Libraries; -----------------------------------------; Runtime interposition allows AddressSanitizer to find bugs in code that is; not being recompiled. If you run into an issue in external libraries, we; recommend immediately reporting it to the library maintainer so that it; gets addressed. However, you can use the following suppression mechanism; to unblock yourself and continue on with the testing. This supp",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:7725,Availability,error,errors,7725,"eakSanitizer`. The leak detection is turned on by default on Linux,; and can be enabled using ``ASAN_OPTIONS=detect_leaks=1`` on macOS;; however, it is not yet supported on other platforms. Issue Suppression; =================. AddressSanitizer is not expected to produce false positives. If you see one,; look again; most likely it is a true positive!. Suppressing Reports in External Libraries; -----------------------------------------; Runtime interposition allows AddressSanitizer to find bugs in code that is; not being recompiled. If you run into an issue in external libraries, we; recommend immediately reporting it to the library maintainer so that it; gets addressed. However, you can use the following suppression mechanism; to unblock yourself and continue on with the testing. This suppression; mechanism should only be used for suppressing issues in external code; it; does not work on code recompiled with AddressSanitizer. To suppress errors; in external libraries, set the ``ASAN_OPTIONS`` environment variable to point; to a suppression file. You can either specify the full path to the file or the; path of the file relative to the location of your executable. .. code-block:: bash. ASAN_OPTIONS=suppressions=MyASan.supp. Use the following format to specify the names of the functions or libraries; you want to suppress. You can see these in the error report. Remember that; the narrower the scope of the suppression, the more bugs you will be able to; catch. .. code-block:: bash. interceptor_via_fun:NameOfCFunctionToSuppress; interceptor_via_fun:-[ClassName objCMethodToSuppress:]; interceptor_via_lib:NameOfTheLibraryToSuppress. Conditional Compilation with ``__has_feature(address_sanitizer)``; -----------------------------------------------------------------. In some cases one may need to execute different code depending on whether; AddressSanitizer is enabled.; :ref:`\_\_has\_feature <langext-__has_feature-__has_extension>` can be used for; this purpose. .. code-block",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:8139,Availability,error,error,8139,"essing Reports in External Libraries; -----------------------------------------; Runtime interposition allows AddressSanitizer to find bugs in code that is; not being recompiled. If you run into an issue in external libraries, we; recommend immediately reporting it to the library maintainer so that it; gets addressed. However, you can use the following suppression mechanism; to unblock yourself and continue on with the testing. This suppression; mechanism should only be used for suppressing issues in external code; it; does not work on code recompiled with AddressSanitizer. To suppress errors; in external libraries, set the ``ASAN_OPTIONS`` environment variable to point; to a suppression file. You can either specify the full path to the file or the; path of the file relative to the location of your executable. .. code-block:: bash. ASAN_OPTIONS=suppressions=MyASan.supp. Use the following format to specify the names of the functions or libraries; you want to suppress. You can see these in the error report. Remember that; the narrower the scope of the suppression, the more bugs you will be able to; catch. .. code-block:: bash. interceptor_via_fun:NameOfCFunctionToSuppress; interceptor_via_fun:-[ClassName objCMethodToSuppress:]; interceptor_via_lib:NameOfTheLibraryToSuppress. Conditional Compilation with ``__has_feature(address_sanitizer)``; -----------------------------------------------------------------. In some cases one may need to execute different code depending on whether; AddressSanitizer is enabled.; :ref:`\_\_has\_feature <langext-__has_feature-__has_extension>` can be used for; this purpose. .. code-block:: c. #if defined(__has_feature); # if __has_feature(address_sanitizer); // code that builds only under AddressSanitizer; # endif; #endif. Disabling Instrumentation with ``__attribute__((no_sanitize(""address"")))``; --------------------------------------------------------------------------. Some code should not be instrumented by AddressSanitizer. One may use",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:10075,Availability,error,error,10075,"---------------------. Some code should not be instrumented by AddressSanitizer. One may use; the attribute ``__attribute__((no_sanitize(""address"")))`` (which has; deprecated synonyms `no_sanitize_address` and; `no_address_safety_analysis`) to disable instrumentation of a; particular function. This attribute may not be supported by other; compilers, so we suggest to use it together with; ``__has_feature(address_sanitizer)``. The same attribute used on a global variable prevents AddressSanitizer; from adding redzones around it and detecting out of bounds accesses. AddressSanitizer also supports; ``__attribute__((disable_sanitizer_instrumentation))``. This attribute; works similar to ``__attribute__((no_sanitize(""address"")))``, but it also; prevents instrumentation performed by other sanitizers. Suppressing Errors in Recompiled Code (Ignorelist); --------------------------------------------------. AddressSanitizer supports ``src`` and ``fun`` entity types in; :doc:`SanitizerSpecialCaseList`, that can be used to suppress error reports; in the specified source files or functions. Additionally, AddressSanitizer; introduces ``global`` and ``type`` entity types that can be used to; suppress error reports for out-of-bound access to globals with certain; names and types (you may only specify class or struct types). You may use an ``init`` category to suppress reports about initialization-order; problems happening in certain source files or with certain global variables. .. code-block:: bash. # Suppress error reports for code in a file or in a function:; src:bad_file.cpp; # Ignore all functions with names containing MyFooBar:; fun:*MyFooBar*; # Disable out-of-bound checks for global:; global:bad_array; # Disable out-of-bound checks for global instances of a given class ...; type:Namespace::BadClassName; # ... or a given struct. Use wildcard to deal with anonymous namespace.; type:Namespace2::*::BadStructName; # Disable initialization-order checks for globals:; global:bad_init",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:10244,Availability,error,error,10244,"; `no_address_safety_analysis`) to disable instrumentation of a; particular function. This attribute may not be supported by other; compilers, so we suggest to use it together with; ``__has_feature(address_sanitizer)``. The same attribute used on a global variable prevents AddressSanitizer; from adding redzones around it and detecting out of bounds accesses. AddressSanitizer also supports; ``__attribute__((disable_sanitizer_instrumentation))``. This attribute; works similar to ``__attribute__((no_sanitize(""address"")))``, but it also; prevents instrumentation performed by other sanitizers. Suppressing Errors in Recompiled Code (Ignorelist); --------------------------------------------------. AddressSanitizer supports ``src`` and ``fun`` entity types in; :doc:`SanitizerSpecialCaseList`, that can be used to suppress error reports; in the specified source files or functions. Additionally, AddressSanitizer; introduces ``global`` and ``type`` entity types that can be used to; suppress error reports for out-of-bound access to globals with certain; names and types (you may only specify class or struct types). You may use an ``init`` category to suppress reports about initialization-order; problems happening in certain source files or with certain global variables. .. code-block:: bash. # Suppress error reports for code in a file or in a function:; src:bad_file.cpp; # Ignore all functions with names containing MyFooBar:; fun:*MyFooBar*; # Disable out-of-bound checks for global:; global:bad_array; # Disable out-of-bound checks for global instances of a given class ...; type:Namespace::BadClassName; # ... or a given struct. Use wildcard to deal with anonymous namespace.; type:Namespace2::*::BadStructName; # Disable initialization-order checks for globals:; global:bad_init_global=init; type:*BadInitClassSubstring*=init; src:bad/init/files/*=init. Suppressing memory leaks; ------------------------. Memory leak reports produced by :doc:`LeakSanitizer` (if it is run as a part; of A",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:10560,Availability,error,error,10560," out of bounds accesses. AddressSanitizer also supports; ``__attribute__((disable_sanitizer_instrumentation))``. This attribute; works similar to ``__attribute__((no_sanitize(""address"")))``, but it also; prevents instrumentation performed by other sanitizers. Suppressing Errors in Recompiled Code (Ignorelist); --------------------------------------------------. AddressSanitizer supports ``src`` and ``fun`` entity types in; :doc:`SanitizerSpecialCaseList`, that can be used to suppress error reports; in the specified source files or functions. Additionally, AddressSanitizer; introduces ``global`` and ``type`` entity types that can be used to; suppress error reports for out-of-bound access to globals with certain; names and types (you may only specify class or struct types). You may use an ``init`` category to suppress reports about initialization-order; problems happening in certain source files or with certain global variables. .. code-block:: bash. # Suppress error reports for code in a file or in a function:; src:bad_file.cpp; # Ignore all functions with names containing MyFooBar:; fun:*MyFooBar*; # Disable out-of-bound checks for global:; global:bad_array; # Disable out-of-bound checks for global instances of a given class ...; type:Namespace::BadClassName; # ... or a given struct. Use wildcard to deal with anonymous namespace.; type:Namespace2::*::BadStructName; # Disable initialization-order checks for globals:; global:bad_init_global=init; type:*BadInitClassSubstring*=init; src:bad/init/files/*=init. Suppressing memory leaks; ------------------------. Memory leak reports produced by :doc:`LeakSanitizer` (if it is run as a part; of AddressSanitizer) can be suppressed by a separate file passed as. .. code-block:: bash. LSAN_OPTIONS=suppressions=MyLSan.supp. which contains lines of the form `leak:<pattern>`. Memory leak will be; suppressed if pattern matches any function name, source file name, or; library name in the symbolized stack trace of the leak report. See;",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:970,Deployability,configurat,configuration,970,"================; AddressSanitizer; ================. .. contents::; :local:. Introduction; ============. AddressSanitizer is a fast memory error detector. It consists of a compiler; instrumentation module and a run-time library. The tool can detect the; following types of bugs:. * Out-of-bounds accesses to heap, stack and globals; * Use-after-free; * Use-after-return (clang flag ``-fsanitize-address-use-after-return=(never|runtime|always)`` default: ``runtime``); * Enable with: ``ASAN_OPTIONS=detect_stack_use_after_return=1`` (already enabled on Linux).; * Disable with: ``ASAN_OPTIONS=detect_stack_use_after_return=0``.; * Use-after-scope (clang flag ``-fsanitize-address-use-after-scope``); * Double-free, invalid free; * Memory leaks (experimental). Typical slowdown introduced by AddressSanitizer is **2x**. How to build; ============. Build LLVM/Clang with `CMake <https://llvm.org/docs/CMake.html>` and enable; the ``compiler-rt`` runtime. An example CMake configuration that will allow; for the use/testing of AddressSanitizer:. .. code-block:: console. $ cmake -DCMAKE_BUILD_TYPE=Release -DLLVM_ENABLE_PROJECTS=""clang"" -DLLVM_ENABLE_RUNTIMES=""compiler-rt"" <path to source>/llvm. Usage; =====. Simply compile and link your program with ``-fsanitize=address`` flag. The; AddressSanitizer run-time library should be linked to the final executable, so; make sure to use ``clang`` (not ``ld``) for the final link step. When linking; shared libraries, the AddressSanitizer run-time is not linked, so; ``-Wl,-z,defs`` may cause link errors (don't use it with AddressSanitizer). To; get a reasonable performance add ``-O1`` or higher. To get nicer stack traces; in error messages add ``-fno-omit-frame-pointer``. To get perfect stack traces; you may need to disable inlining (just use ``-O1``) and tail call elimination; (``-fno-optimize-sibling-calls``). .. code-block:: console. % cat example_UseAfterFree.cc; int main(int argc, char **argv) {; int *array = new int[100];; delete [] array;; r",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:13195,Deployability,integrat,integrated,13195,"ame, source file name, or; library name in the symbolized stack trace of the leak report. See; `full documentation; <https://github.com/google/sanitizers/wiki/AddressSanitizerLeakSanitizer#suppressions>`_; for more details. Code generation control; =======================. Instrumentation code outlining; ------------------------------. By default AddressSanitizer inlines the instrumentation code to improve the; run-time performance, which leads to increased binary size. Using the; (clang flag ``-fsanitize-address-outline-instrumentation` default: ``false``); flag forces all code instrumentation to be outlined, which reduces the size; of the generated code, but also reduces the run-time performance. Limitations; ===========. * AddressSanitizer uses more real memory than a native run. Exact overhead; depends on the allocations sizes. The smaller the allocations you make the; bigger the overhead is.; * AddressSanitizer uses more stack memory. We have seen up to 3x increase.; * On 64-bit platforms AddressSanitizer maps (but not reserves) 16+ Terabytes of; virtual address space. This means that tools like ``ulimit`` may not work as; usually expected.; * Static linking of executables is not supported. Supported Platforms; ===================. AddressSanitizer is supported on:. * Linux i386/x86\_64 (tested on Ubuntu 12.04); * macOS 10.7 - 10.11 (i386/x86\_64); * iOS Simulator; * Android ARM; * NetBSD i386/x86\_64; * FreeBSD i386/x86\_64 (tested on FreeBSD 11-current); * Windows 8.1+ (i386/x86\_64). Ports to various other platforms are in progress. Current Status; ==============. AddressSanitizer is fully functional on supported platforms starting from LLVM; 3.1. The test suite is integrated into CMake build and can be run with ``make; check-asan`` command. The Windows port is functional and is used by Chrome and Firefox, but it is not; as well supported as the other ports. More Information; ================. `<https://github.com/google/sanitizers/wiki/AddressSanitizer>`_; ",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:4282,Energy Efficiency,allocate,allocated,4282,"utable to another machine,; the ASan library will also need to be copied over. Symbolizing the Reports; =========================. To make AddressSanitizer symbolize its output; you need to set the ``ASAN_SYMBOLIZER_PATH`` environment variable to point to; the ``llvm-symbolizer`` binary (or make sure ``llvm-symbolizer`` is in your; ``$PATH``):. .. code-block:: console. % ASAN_SYMBOLIZER_PATH=/usr/local/bin/llvm-symbolizer ./a.out; ==9442== ERROR: AddressSanitizer heap-use-after-free on address 0x7f7ddab8c084 at pc 0x403c8c bp 0x7fff87fb82d0 sp 0x7fff87fb82c8; READ of size 4 at 0x7f7ddab8c084 thread T0; #0 0x403c8c in main example_UseAfterFree.cc:4; #1 0x7f7ddabcac4d in __libc_start_main ??:0; 0x7f7ddab8c084 is located 4 bytes inside of 400-byte region [0x7f7ddab8c080,0x7f7ddab8c210); freed by thread T0 here:; #0 0x404704 in operator delete[](void*) ??:0; #1 0x403c53 in main example_UseAfterFree.cc:4; #2 0x7f7ddabcac4d in __libc_start_main ??:0; previously allocated by thread T0 here:; #0 0x404544 in operator new[](unsigned long) ??:0; #1 0x403c43 in main example_UseAfterFree.cc:2; #2 0x7f7ddabcac4d in __libc_start_main ??:0; ==9442== ABORTING. If that does not work for you (e.g. your process is sandboxed), you can use a; separate script to symbolize the result offline (online symbolization can be; force disabled by setting ``ASAN_OPTIONS=symbolize=0``):. .. code-block:: console. % ASAN_OPTIONS=symbolize=0 ./a.out 2> log; % projects/compiler-rt/lib/asan/scripts/asan_symbolize.py / < log | c++filt; ==9442== ERROR: AddressSanitizer heap-use-after-free on address 0x7f7ddab8c084 at pc 0x403c8c bp 0x7fff87fb82d0 sp 0x7fff87fb82c8; READ of size 4 at 0x7f7ddab8c084 thread T0; #0 0x403c8c in main example_UseAfterFree.cc:4; #1 0x7f7ddabcac4d in __libc_start_main ??:0; ... Note that on macOS you may need to run ``dsymutil`` on your binary to have the; file\:line info in the AddressSanitizer reports. Additional Checks; =================. Initialization order checking; ---------",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:6113,Energy Efficiency,reduce,reduce,6113,"_start_main ??:0; ... Note that on macOS you may need to run ``dsymutil`` on your binary to have the; file\:line info in the AddressSanitizer reports. Additional Checks; =================. Initialization order checking; -----------------------------. AddressSanitizer can optionally detect dynamic initialization order problems,; when initialization of globals defined in one translation unit uses; globals defined in another translation unit. To enable this check at runtime,; you should set environment variable; ``ASAN_OPTIONS=check_initialization_order=1``. Note that this option is not supported on macOS. Stack Use After Return (UAR); ----------------------------. AddressSanitizer can optionally detect stack use after return problems.; This is available by default, or explicitly; (``-fsanitize-address-use-after-return=runtime``).; To disable this check at runtime, set the environment variable; ``ASAN_OPTIONS=detect_stack_use_after_return=0``. Enabling this check (``-fsanitize-address-use-after-return=always``) will; reduce code size. The code size may be reduced further by completely; eliminating this check (``-fsanitize-address-use-after-return=never``). To summarize: ``-fsanitize-address-use-after-return=<mode>``; * ``never``: Completely disables detection of UAR errors (reduces code size).; * ``runtime``: Adds the code for detection, but it can be disable via the; runtime environment (``ASAN_OPTIONS=detect_stack_use_after_return=0``).; * ``always``: Enables detection of UAR errors in all cases. (reduces code; size, but not as much as ``never``). Memory leak detection; ---------------------. For more information on leak detector in AddressSanitizer, see; :doc:`LeakSanitizer`. The leak detection is turned on by default on Linux,; and can be enabled using ``ASAN_OPTIONS=detect_leaks=1`` on macOS;; however, it is not yet supported on other platforms. Issue Suppression; =================. AddressSanitizer is not expected to produce false positives. If you see one,; look ",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:6152,Energy Efficiency,reduce,reduced,6152,"ine info in the AddressSanitizer reports. Additional Checks; =================. Initialization order checking; -----------------------------. AddressSanitizer can optionally detect dynamic initialization order problems,; when initialization of globals defined in one translation unit uses; globals defined in another translation unit. To enable this check at runtime,; you should set environment variable; ``ASAN_OPTIONS=check_initialization_order=1``. Note that this option is not supported on macOS. Stack Use After Return (UAR); ----------------------------. AddressSanitizer can optionally detect stack use after return problems.; This is available by default, or explicitly; (``-fsanitize-address-use-after-return=runtime``).; To disable this check at runtime, set the environment variable; ``ASAN_OPTIONS=detect_stack_use_after_return=0``. Enabling this check (``-fsanitize-address-use-after-return=always``) will; reduce code size. The code size may be reduced further by completely; eliminating this check (``-fsanitize-address-use-after-return=never``). To summarize: ``-fsanitize-address-use-after-return=<mode>``; * ``never``: Completely disables detection of UAR errors (reduces code size).; * ``runtime``: Adds the code for detection, but it can be disable via the; runtime environment (``ASAN_OPTIONS=detect_stack_use_after_return=0``).; * ``always``: Enables detection of UAR errors in all cases. (reduces code; size, but not as much as ``never``). Memory leak detection; ---------------------. For more information on leak detector in AddressSanitizer, see; :doc:`LeakSanitizer`. The leak detection is turned on by default on Linux,; and can be enabled using ``ASAN_OPTIONS=detect_leaks=1`` on macOS;; however, it is not yet supported on other platforms. Issue Suppression; =================. AddressSanitizer is not expected to produce false positives. If you see one,; look again; most likely it is a true positive!. Suppressing Reports in External Libraries; ----------------------",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:6375,Energy Efficiency,reduce,reduces,6375,"--------. AddressSanitizer can optionally detect dynamic initialization order problems,; when initialization of globals defined in one translation unit uses; globals defined in another translation unit. To enable this check at runtime,; you should set environment variable; ``ASAN_OPTIONS=check_initialization_order=1``. Note that this option is not supported on macOS. Stack Use After Return (UAR); ----------------------------. AddressSanitizer can optionally detect stack use after return problems.; This is available by default, or explicitly; (``-fsanitize-address-use-after-return=runtime``).; To disable this check at runtime, set the environment variable; ``ASAN_OPTIONS=detect_stack_use_after_return=0``. Enabling this check (``-fsanitize-address-use-after-return=always``) will; reduce code size. The code size may be reduced further by completely; eliminating this check (``-fsanitize-address-use-after-return=never``). To summarize: ``-fsanitize-address-use-after-return=<mode>``; * ``never``: Completely disables detection of UAR errors (reduces code size).; * ``runtime``: Adds the code for detection, but it can be disable via the; runtime environment (``ASAN_OPTIONS=detect_stack_use_after_return=0``).; * ``always``: Enables detection of UAR errors in all cases. (reduces code; size, but not as much as ``never``). Memory leak detection; ---------------------. For more information on leak detector in AddressSanitizer, see; :doc:`LeakSanitizer`. The leak detection is turned on by default on Linux,; and can be enabled using ``ASAN_OPTIONS=detect_leaks=1`` on macOS;; however, it is not yet supported on other platforms. Issue Suppression; =================. AddressSanitizer is not expected to produce false positives. If you see one,; look again; most likely it is a true positive!. Suppressing Reports in External Libraries; -----------------------------------------; Runtime interposition allows AddressSanitizer to find bugs in code that is; not being recompiled. If you run in",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:6605,Energy Efficiency,reduce,reduces,6605,"tion_order=1``. Note that this option is not supported on macOS. Stack Use After Return (UAR); ----------------------------. AddressSanitizer can optionally detect stack use after return problems.; This is available by default, or explicitly; (``-fsanitize-address-use-after-return=runtime``).; To disable this check at runtime, set the environment variable; ``ASAN_OPTIONS=detect_stack_use_after_return=0``. Enabling this check (``-fsanitize-address-use-after-return=always``) will; reduce code size. The code size may be reduced further by completely; eliminating this check (``-fsanitize-address-use-after-return=never``). To summarize: ``-fsanitize-address-use-after-return=<mode>``; * ``never``: Completely disables detection of UAR errors (reduces code size).; * ``runtime``: Adds the code for detection, but it can be disable via the; runtime environment (``ASAN_OPTIONS=detect_stack_use_after_return=0``).; * ``always``: Enables detection of UAR errors in all cases. (reduces code; size, but not as much as ``never``). Memory leak detection; ---------------------. For more information on leak detector in AddressSanitizer, see; :doc:`LeakSanitizer`. The leak detection is turned on by default on Linux,; and can be enabled using ``ASAN_OPTIONS=detect_leaks=1`` on macOS;; however, it is not yet supported on other platforms. Issue Suppression; =================. AddressSanitizer is not expected to produce false positives. If you see one,; look again; most likely it is a true positive!. Suppressing Reports in External Libraries; -----------------------------------------; Runtime interposition allows AddressSanitizer to find bugs in code that is; not being recompiled. If you run into an issue in external libraries, we; recommend immediately reporting it to the library maintainer so that it; gets addressed. However, you can use the following suppression mechanism; to unblock yourself and continue on with the testing. This suppression; mechanism should only be used for suppressing i",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:12117,Energy Efficiency,reduce,reduces,12117,"=init; src:bad/init/files/*=init. Suppressing memory leaks; ------------------------. Memory leak reports produced by :doc:`LeakSanitizer` (if it is run as a part; of AddressSanitizer) can be suppressed by a separate file passed as. .. code-block:: bash. LSAN_OPTIONS=suppressions=MyLSan.supp. which contains lines of the form `leak:<pattern>`. Memory leak will be; suppressed if pattern matches any function name, source file name, or; library name in the symbolized stack trace of the leak report. See; `full documentation; <https://github.com/google/sanitizers/wiki/AddressSanitizerLeakSanitizer#suppressions>`_; for more details. Code generation control; =======================. Instrumentation code outlining; ------------------------------. By default AddressSanitizer inlines the instrumentation code to improve the; run-time performance, which leads to increased binary size. Using the; (clang flag ``-fsanitize-address-outline-instrumentation` default: ``false``); flag forces all code instrumentation to be outlined, which reduces the size; of the generated code, but also reduces the run-time performance. Limitations; ===========. * AddressSanitizer uses more real memory than a native run. Exact overhead; depends on the allocations sizes. The smaller the allocations you make the; bigger the overhead is.; * AddressSanitizer uses more stack memory. We have seen up to 3x increase.; * On 64-bit platforms AddressSanitizer maps (but not reserves) 16+ Terabytes of; virtual address space. This means that tools like ``ulimit`` may not work as; usually expected.; * Static linking of executables is not supported. Supported Platforms; ===================. AddressSanitizer is supported on:. * Linux i386/x86\_64 (tested on Ubuntu 12.04); * macOS 10.7 - 10.11 (i386/x86\_64); * iOS Simulator; * Android ARM; * NetBSD i386/x86\_64; * FreeBSD i386/x86\_64 (tested on FreeBSD 11-current); * Windows 8.1+ (i386/x86\_64). Ports to various other platforms are in progress. Current Status; ========",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:12167,Energy Efficiency,reduce,reduces,12167,"=init; src:bad/init/files/*=init. Suppressing memory leaks; ------------------------. Memory leak reports produced by :doc:`LeakSanitizer` (if it is run as a part; of AddressSanitizer) can be suppressed by a separate file passed as. .. code-block:: bash. LSAN_OPTIONS=suppressions=MyLSan.supp. which contains lines of the form `leak:<pattern>`. Memory leak will be; suppressed if pattern matches any function name, source file name, or; library name in the symbolized stack trace of the leak report. See; `full documentation; <https://github.com/google/sanitizers/wiki/AddressSanitizerLeakSanitizer#suppressions>`_; for more details. Code generation control; =======================. Instrumentation code outlining; ------------------------------. By default AddressSanitizer inlines the instrumentation code to improve the; run-time performance, which leads to increased binary size. Using the; (clang flag ``-fsanitize-address-outline-instrumentation` default: ``false``); flag forces all code instrumentation to be outlined, which reduces the size; of the generated code, but also reduces the run-time performance. Limitations; ===========. * AddressSanitizer uses more real memory than a native run. Exact overhead; depends on the allocations sizes. The smaller the allocations you make the; bigger the overhead is.; * AddressSanitizer uses more stack memory. We have seen up to 3x increase.; * On 64-bit platforms AddressSanitizer maps (but not reserves) 16+ Terabytes of; virtual address space. This means that tools like ``ulimit`` may not work as; usually expected.; * Static linking of executables is not supported. Supported Platforms; ===================. AddressSanitizer is supported on:. * Linux i386/x86\_64 (tested on Ubuntu 12.04); * macOS 10.7 - 10.11 (i386/x86\_64); * iOS Simulator; * Android ARM; * NetBSD i386/x86\_64; * FreeBSD i386/x86\_64 (tested on FreeBSD 11-current); * Windows 8.1+ (i386/x86\_64). Ports to various other platforms are in progress. Current Status; ========",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:1678,Integrability,message,messages,1678,"use-after-scope``); * Double-free, invalid free; * Memory leaks (experimental). Typical slowdown introduced by AddressSanitizer is **2x**. How to build; ============. Build LLVM/Clang with `CMake <https://llvm.org/docs/CMake.html>` and enable; the ``compiler-rt`` runtime. An example CMake configuration that will allow; for the use/testing of AddressSanitizer:. .. code-block:: console. $ cmake -DCMAKE_BUILD_TYPE=Release -DLLVM_ENABLE_PROJECTS=""clang"" -DLLVM_ENABLE_RUNTIMES=""compiler-rt"" <path to source>/llvm. Usage; =====. Simply compile and link your program with ``-fsanitize=address`` flag. The; AddressSanitizer run-time library should be linked to the final executable, so; make sure to use ``clang`` (not ``ld``) for the final link step. When linking; shared libraries, the AddressSanitizer run-time is not linked, so; ``-Wl,-z,defs`` may cause link errors (don't use it with AddressSanitizer). To; get a reasonable performance add ``-O1`` or higher. To get nicer stack traces; in error messages add ``-fno-omit-frame-pointer``. To get perfect stack traces; you may need to disable inlining (just use ``-O1``) and tail call elimination; (``-fno-optimize-sibling-calls``). .. code-block:: console. % cat example_UseAfterFree.cc; int main(int argc, char **argv) {; int *array = new int[100];; delete [] array;; return array[argc]; // BOOM; }. # Compile and link; % clang++ -O1 -g -fsanitize=address -fno-omit-frame-pointer example_UseAfterFree.cc. or:. .. code-block:: console. # Compile; % clang++ -O1 -g -fsanitize=address -fno-omit-frame-pointer -c example_UseAfterFree.cc; # Link; % clang++ -g -fsanitize=address example_UseAfterFree.o. If a bug is detected, the program will print an error message to stderr and; exit with a non-zero exit code. AddressSanitizer exits on the first detected error.; This is by design:. * This approach allows AddressSanitizer to produce faster and smaller generated code; (both by ~5%).; * Fixing bugs becomes unavoidable. AddressSanitizer does not produ",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:2384,Integrability,message,message,2384,"clang`` (not ``ld``) for the final link step. When linking; shared libraries, the AddressSanitizer run-time is not linked, so; ``-Wl,-z,defs`` may cause link errors (don't use it with AddressSanitizer). To; get a reasonable performance add ``-O1`` or higher. To get nicer stack traces; in error messages add ``-fno-omit-frame-pointer``. To get perfect stack traces; you may need to disable inlining (just use ``-O1``) and tail call elimination; (``-fno-optimize-sibling-calls``). .. code-block:: console. % cat example_UseAfterFree.cc; int main(int argc, char **argv) {; int *array = new int[100];; delete [] array;; return array[argc]; // BOOM; }. # Compile and link; % clang++ -O1 -g -fsanitize=address -fno-omit-frame-pointer example_UseAfterFree.cc. or:. .. code-block:: console. # Compile; % clang++ -O1 -g -fsanitize=address -fno-omit-frame-pointer -c example_UseAfterFree.cc; # Link; % clang++ -g -fsanitize=address example_UseAfterFree.o. If a bug is detected, the program will print an error message to stderr and; exit with a non-zero exit code. AddressSanitizer exits on the first detected error.; This is by design:. * This approach allows AddressSanitizer to produce faster and smaller generated code; (both by ~5%).; * Fixing bugs becomes unavoidable. AddressSanitizer does not produce; false alarms. Once a memory corruption occurs, the program is in an inconsistent; state, which could lead to confusing results and potentially misleading; subsequent reports. If your process is sandboxed and you are running on OS X 10.10 or earlier, you; will need to set ``DYLD_INSERT_LIBRARIES`` environment variable and point it to; the ASan library that is packaged with the compiler used to build the; executable. (You can find the library by searching for dynamic libraries with; ``asan`` in their name.) If the environment variable is not set, the process will; try to re-exec. Also keep in mind that when moving the executable to another machine,; the ASan library will also need to be copied",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:8613,Integrability,depend,depending,8613," for suppressing issues in external code; it; does not work on code recompiled with AddressSanitizer. To suppress errors; in external libraries, set the ``ASAN_OPTIONS`` environment variable to point; to a suppression file. You can either specify the full path to the file or the; path of the file relative to the location of your executable. .. code-block:: bash. ASAN_OPTIONS=suppressions=MyASan.supp. Use the following format to specify the names of the functions or libraries; you want to suppress. You can see these in the error report. Remember that; the narrower the scope of the suppression, the more bugs you will be able to; catch. .. code-block:: bash. interceptor_via_fun:NameOfCFunctionToSuppress; interceptor_via_fun:-[ClassName objCMethodToSuppress:]; interceptor_via_lib:NameOfTheLibraryToSuppress. Conditional Compilation with ``__has_feature(address_sanitizer)``; -----------------------------------------------------------------. In some cases one may need to execute different code depending on whether; AddressSanitizer is enabled.; :ref:`\_\_has\_feature <langext-__has_feature-__has_extension>` can be used for; this purpose. .. code-block:: c. #if defined(__has_feature); # if __has_feature(address_sanitizer); // code that builds only under AddressSanitizer; # endif; #endif. Disabling Instrumentation with ``__attribute__((no_sanitize(""address"")))``; --------------------------------------------------------------------------. Some code should not be instrumented by AddressSanitizer. One may use; the attribute ``__attribute__((no_sanitize(""address"")))`` (which has; deprecated synonyms `no_sanitize_address` and; `no_address_safety_analysis`) to disable instrumentation of a; particular function. This attribute may not be supported by other; compilers, so we suggest to use it together with; ``__has_feature(address_sanitizer)``. The same attribute used on a global variable prevents AddressSanitizer; from adding redzones around it and detecting out of bounds accesses. ",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:12303,Integrability,depend,depends,12303," as. .. code-block:: bash. LSAN_OPTIONS=suppressions=MyLSan.supp. which contains lines of the form `leak:<pattern>`. Memory leak will be; suppressed if pattern matches any function name, source file name, or; library name in the symbolized stack trace of the leak report. See; `full documentation; <https://github.com/google/sanitizers/wiki/AddressSanitizerLeakSanitizer#suppressions>`_; for more details. Code generation control; =======================. Instrumentation code outlining; ------------------------------. By default AddressSanitizer inlines the instrumentation code to improve the; run-time performance, which leads to increased binary size. Using the; (clang flag ``-fsanitize-address-outline-instrumentation` default: ``false``); flag forces all code instrumentation to be outlined, which reduces the size; of the generated code, but also reduces the run-time performance. Limitations; ===========. * AddressSanitizer uses more real memory than a native run. Exact overhead; depends on the allocations sizes. The smaller the allocations you make the; bigger the overhead is.; * AddressSanitizer uses more stack memory. We have seen up to 3x increase.; * On 64-bit platforms AddressSanitizer maps (but not reserves) 16+ Terabytes of; virtual address space. This means that tools like ``ulimit`` may not work as; usually expected.; * Static linking of executables is not supported. Supported Platforms; ===================. AddressSanitizer is supported on:. * Linux i386/x86\_64 (tested on Ubuntu 12.04); * macOS 10.7 - 10.11 (i386/x86\_64); * iOS Simulator; * Android ARM; * NetBSD i386/x86\_64; * FreeBSD i386/x86\_64 (tested on FreeBSD 11-current); * Windows 8.1+ (i386/x86\_64). Ports to various other platforms are in progress. Current Status; ==============. AddressSanitizer is fully functional on supported platforms starting from LLVM; 3.1. The test suite is integrated into CMake build and can be run with ``make; check-asan`` command. The Windows port is functional and is ",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:13195,Integrability,integrat,integrated,13195,"ame, source file name, or; library name in the symbolized stack trace of the leak report. See; `full documentation; <https://github.com/google/sanitizers/wiki/AddressSanitizerLeakSanitizer#suppressions>`_; for more details. Code generation control; =======================. Instrumentation code outlining; ------------------------------. By default AddressSanitizer inlines the instrumentation code to improve the; run-time performance, which leads to increased binary size. Using the; (clang flag ``-fsanitize-address-outline-instrumentation` default: ``false``); flag forces all code instrumentation to be outlined, which reduces the size; of the generated code, but also reduces the run-time performance. Limitations; ===========. * AddressSanitizer uses more real memory than a native run. Exact overhead; depends on the allocations sizes. The smaller the allocations you make the; bigger the overhead is.; * AddressSanitizer uses more stack memory. We have seen up to 3x increase.; * On 64-bit platforms AddressSanitizer maps (but not reserves) 16+ Terabytes of; virtual address space. This means that tools like ``ulimit`` may not work as; usually expected.; * Static linking of executables is not supported. Supported Platforms; ===================. AddressSanitizer is supported on:. * Linux i386/x86\_64 (tested on Ubuntu 12.04); * macOS 10.7 - 10.11 (i386/x86\_64); * iOS Simulator; * Android ARM; * NetBSD i386/x86\_64; * FreeBSD i386/x86\_64 (tested on FreeBSD 11-current); * Windows 8.1+ (i386/x86\_64). Ports to various other platforms are in progress. Current Status; ==============. AddressSanitizer is fully functional on supported platforms starting from LLVM; 3.1. The test suite is integrated into CMake build and can be run with ``make; check-asan`` command. The Windows port is functional and is used by Chrome and Firefox, but it is not; as well supported as the other ports. More Information; ================. `<https://github.com/google/sanitizers/wiki/AddressSanitizer>`_; ",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:970,Modifiability,config,configuration,970,"================; AddressSanitizer; ================. .. contents::; :local:. Introduction; ============. AddressSanitizer is a fast memory error detector. It consists of a compiler; instrumentation module and a run-time library. The tool can detect the; following types of bugs:. * Out-of-bounds accesses to heap, stack and globals; * Use-after-free; * Use-after-return (clang flag ``-fsanitize-address-use-after-return=(never|runtime|always)`` default: ``runtime``); * Enable with: ``ASAN_OPTIONS=detect_stack_use_after_return=1`` (already enabled on Linux).; * Disable with: ``ASAN_OPTIONS=detect_stack_use_after_return=0``.; * Use-after-scope (clang flag ``-fsanitize-address-use-after-scope``); * Double-free, invalid free; * Memory leaks (experimental). Typical slowdown introduced by AddressSanitizer is **2x**. How to build; ============. Build LLVM/Clang with `CMake <https://llvm.org/docs/CMake.html>` and enable; the ``compiler-rt`` runtime. An example CMake configuration that will allow; for the use/testing of AddressSanitizer:. .. code-block:: console. $ cmake -DCMAKE_BUILD_TYPE=Release -DLLVM_ENABLE_PROJECTS=""clang"" -DLLVM_ENABLE_RUNTIMES=""compiler-rt"" <path to source>/llvm. Usage; =====. Simply compile and link your program with ``-fsanitize=address`` flag. The; AddressSanitizer run-time library should be linked to the final executable, so; make sure to use ``clang`` (not ``ld``) for the final link step. When linking; shared libraries, the AddressSanitizer run-time is not linked, so; ``-Wl,-z,defs`` may cause link errors (don't use it with AddressSanitizer). To; get a reasonable performance add ``-O1`` or higher. To get nicer stack traces; in error messages add ``-fno-omit-frame-pointer``. To get perfect stack traces; you may need to disable inlining (just use ``-O1``) and tail call elimination; (``-fno-optimize-sibling-calls``). .. code-block:: console. % cat example_UseAfterFree.cc; int main(int argc, char **argv) {; int *array = new int[100];; delete [] array;; r",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:2878,Modifiability,sandbox,sandboxed,2878,"% cat example_UseAfterFree.cc; int main(int argc, char **argv) {; int *array = new int[100];; delete [] array;; return array[argc]; // BOOM; }. # Compile and link; % clang++ -O1 -g -fsanitize=address -fno-omit-frame-pointer example_UseAfterFree.cc. or:. .. code-block:: console. # Compile; % clang++ -O1 -g -fsanitize=address -fno-omit-frame-pointer -c example_UseAfterFree.cc; # Link; % clang++ -g -fsanitize=address example_UseAfterFree.o. If a bug is detected, the program will print an error message to stderr and; exit with a non-zero exit code. AddressSanitizer exits on the first detected error.; This is by design:. * This approach allows AddressSanitizer to produce faster and smaller generated code; (both by ~5%).; * Fixing bugs becomes unavoidable. AddressSanitizer does not produce; false alarms. Once a memory corruption occurs, the program is in an inconsistent; state, which could lead to confusing results and potentially misleading; subsequent reports. If your process is sandboxed and you are running on OS X 10.10 or earlier, you; will need to set ``DYLD_INSERT_LIBRARIES`` environment variable and point it to; the ASan library that is packaged with the compiler used to build the; executable. (You can find the library by searching for dynamic libraries with; ``asan`` in their name.) If the environment variable is not set, the process will; try to re-exec. Also keep in mind that when moving the executable to another machine,; the ASan library will also need to be copied over. Symbolizing the Reports; =========================. To make AddressSanitizer symbolize its output; you need to set the ``ASAN_SYMBOLIZER_PATH`` environment variable to point to; the ``llvm-symbolizer`` binary (or make sure ``llvm-symbolizer`` is in your; ``$PATH``):. .. code-block:: console. % ASAN_SYMBOLIZER_PATH=/usr/local/bin/llvm-symbolizer ./a.out; ==9442== ERROR: AddressSanitizer heap-use-after-free on address 0x7f7ddab8c084 at pc 0x403c8c bp 0x7fff87fb82d0 sp 0x7fff87fb82c8; READ of siz",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:2994,Modifiability,variab,variable,2994,"ay[argc]; // BOOM; }. # Compile and link; % clang++ -O1 -g -fsanitize=address -fno-omit-frame-pointer example_UseAfterFree.cc. or:. .. code-block:: console. # Compile; % clang++ -O1 -g -fsanitize=address -fno-omit-frame-pointer -c example_UseAfterFree.cc; # Link; % clang++ -g -fsanitize=address example_UseAfterFree.o. If a bug is detected, the program will print an error message to stderr and; exit with a non-zero exit code. AddressSanitizer exits on the first detected error.; This is by design:. * This approach allows AddressSanitizer to produce faster and smaller generated code; (both by ~5%).; * Fixing bugs becomes unavoidable. AddressSanitizer does not produce; false alarms. Once a memory corruption occurs, the program is in an inconsistent; state, which could lead to confusing results and potentially misleading; subsequent reports. If your process is sandboxed and you are running on OS X 10.10 or earlier, you; will need to set ``DYLD_INSERT_LIBRARIES`` environment variable and point it to; the ASan library that is packaged with the compiler used to build the; executable. (You can find the library by searching for dynamic libraries with; ``asan`` in their name.) If the environment variable is not set, the process will; try to re-exec. Also keep in mind that when moving the executable to another machine,; the ASan library will also need to be copied over. Symbolizing the Reports; =========================. To make AddressSanitizer symbolize its output; you need to set the ``ASAN_SYMBOLIZER_PATH`` environment variable to point to; the ``llvm-symbolizer`` binary (or make sure ``llvm-symbolizer`` is in your; ``$PATH``):. .. code-block:: console. % ASAN_SYMBOLIZER_PATH=/usr/local/bin/llvm-symbolizer ./a.out; ==9442== ERROR: AddressSanitizer heap-use-after-free on address 0x7f7ddab8c084 at pc 0x403c8c bp 0x7fff87fb82d0 sp 0x7fff87fb82c8; READ of size 4 at 0x7f7ddab8c084 thread T0; #0 0x403c8c in main example_UseAfterFree.cc:4; #1 0x7f7ddabcac4d in __libc_start_main ??:",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:3214,Modifiability,variab,variable,3214,"pointer -c example_UseAfterFree.cc; # Link; % clang++ -g -fsanitize=address example_UseAfterFree.o. If a bug is detected, the program will print an error message to stderr and; exit with a non-zero exit code. AddressSanitizer exits on the first detected error.; This is by design:. * This approach allows AddressSanitizer to produce faster and smaller generated code; (both by ~5%).; * Fixing bugs becomes unavoidable. AddressSanitizer does not produce; false alarms. Once a memory corruption occurs, the program is in an inconsistent; state, which could lead to confusing results and potentially misleading; subsequent reports. If your process is sandboxed and you are running on OS X 10.10 or earlier, you; will need to set ``DYLD_INSERT_LIBRARIES`` environment variable and point it to; the ASan library that is packaged with the compiler used to build the; executable. (You can find the library by searching for dynamic libraries with; ``asan`` in their name.) If the environment variable is not set, the process will; try to re-exec. Also keep in mind that when moving the executable to another machine,; the ASan library will also need to be copied over. Symbolizing the Reports; =========================. To make AddressSanitizer symbolize its output; you need to set the ``ASAN_SYMBOLIZER_PATH`` environment variable to point to; the ``llvm-symbolizer`` binary (or make sure ``llvm-symbolizer`` is in your; ``$PATH``):. .. code-block:: console. % ASAN_SYMBOLIZER_PATH=/usr/local/bin/llvm-symbolizer ./a.out; ==9442== ERROR: AddressSanitizer heap-use-after-free on address 0x7f7ddab8c084 at pc 0x403c8c bp 0x7fff87fb82d0 sp 0x7fff87fb82c8; READ of size 4 at 0x7f7ddab8c084 thread T0; #0 0x403c8c in main example_UseAfterFree.cc:4; #1 0x7f7ddabcac4d in __libc_start_main ??:0; 0x7f7ddab8c084 is located 4 bytes inside of 400-byte region [0x7f7ddab8c080,0x7f7ddab8c210); freed by thread T0 here:; #0 0x404704 in operator delete[](void*) ??:0; #1 0x403c53 in main example_UseAfterFree.cc:4; #2 0x",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:3547,Modifiability,variab,variable,3547,"r to produce faster and smaller generated code; (both by ~5%).; * Fixing bugs becomes unavoidable. AddressSanitizer does not produce; false alarms. Once a memory corruption occurs, the program is in an inconsistent; state, which could lead to confusing results and potentially misleading; subsequent reports. If your process is sandboxed and you are running on OS X 10.10 or earlier, you; will need to set ``DYLD_INSERT_LIBRARIES`` environment variable and point it to; the ASan library that is packaged with the compiler used to build the; executable. (You can find the library by searching for dynamic libraries with; ``asan`` in their name.) If the environment variable is not set, the process will; try to re-exec. Also keep in mind that when moving the executable to another machine,; the ASan library will also need to be copied over. Symbolizing the Reports; =========================. To make AddressSanitizer symbolize its output; you need to set the ``ASAN_SYMBOLIZER_PATH`` environment variable to point to; the ``llvm-symbolizer`` binary (or make sure ``llvm-symbolizer`` is in your; ``$PATH``):. .. code-block:: console. % ASAN_SYMBOLIZER_PATH=/usr/local/bin/llvm-symbolizer ./a.out; ==9442== ERROR: AddressSanitizer heap-use-after-free on address 0x7f7ddab8c084 at pc 0x403c8c bp 0x7fff87fb82d0 sp 0x7fff87fb82c8; READ of size 4 at 0x7f7ddab8c084 thread T0; #0 0x403c8c in main example_UseAfterFree.cc:4; #1 0x7f7ddabcac4d in __libc_start_main ??:0; 0x7f7ddab8c084 is located 4 bytes inside of 400-byte region [0x7f7ddab8c080,0x7f7ddab8c210); freed by thread T0 here:; #0 0x404704 in operator delete[](void*) ??:0; #1 0x403c53 in main example_UseAfterFree.cc:4; #2 0x7f7ddabcac4d in __libc_start_main ??:0; previously allocated by thread T0 here:; #0 0x404544 in operator new[](unsigned long) ??:0; #1 0x403c43 in main example_UseAfterFree.cc:2; #2 0x7f7ddabcac4d in __libc_start_main ??:0; ==9442== ABORTING. If that does not work for you (e.g. your process is sandboxed), you can use ",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:4526,Modifiability,sandbox,sandboxed,4526,"y (or make sure ``llvm-symbolizer`` is in your; ``$PATH``):. .. code-block:: console. % ASAN_SYMBOLIZER_PATH=/usr/local/bin/llvm-symbolizer ./a.out; ==9442== ERROR: AddressSanitizer heap-use-after-free on address 0x7f7ddab8c084 at pc 0x403c8c bp 0x7fff87fb82d0 sp 0x7fff87fb82c8; READ of size 4 at 0x7f7ddab8c084 thread T0; #0 0x403c8c in main example_UseAfterFree.cc:4; #1 0x7f7ddabcac4d in __libc_start_main ??:0; 0x7f7ddab8c084 is located 4 bytes inside of 400-byte region [0x7f7ddab8c080,0x7f7ddab8c210); freed by thread T0 here:; #0 0x404704 in operator delete[](void*) ??:0; #1 0x403c53 in main example_UseAfterFree.cc:4; #2 0x7f7ddabcac4d in __libc_start_main ??:0; previously allocated by thread T0 here:; #0 0x404544 in operator new[](unsigned long) ??:0; #1 0x403c43 in main example_UseAfterFree.cc:2; #2 0x7f7ddabcac4d in __libc_start_main ??:0; ==9442== ABORTING. If that does not work for you (e.g. your process is sandboxed), you can use a; separate script to symbolize the result offline (online symbolization can be; force disabled by setting ``ASAN_OPTIONS=symbolize=0``):. .. code-block:: console. % ASAN_OPTIONS=symbolize=0 ./a.out 2> log; % projects/compiler-rt/lib/asan/scripts/asan_symbolize.py / < log | c++filt; ==9442== ERROR: AddressSanitizer heap-use-after-free on address 0x7f7ddab8c084 at pc 0x403c8c bp 0x7fff87fb82d0 sp 0x7fff87fb82c8; READ of size 4 at 0x7f7ddab8c084 thread T0; #0 0x403c8c in main example_UseAfterFree.cc:4; #1 0x7f7ddabcac4d in __libc_start_main ??:0; ... Note that on macOS you may need to run ``dsymutil`` on your binary to have the; file\:line info in the AddressSanitizer reports. Additional Checks; =================. Initialization order checking; -----------------------------. AddressSanitizer can optionally detect dynamic initialization order problems,; when initialization of globals defined in one translation unit uses; globals defined in another translation unit. To enable this check at runtime,; you should set environment variable; `",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:5588,Modifiability,variab,variable,5588," result offline (online symbolization can be; force disabled by setting ``ASAN_OPTIONS=symbolize=0``):. .. code-block:: console. % ASAN_OPTIONS=symbolize=0 ./a.out 2> log; % projects/compiler-rt/lib/asan/scripts/asan_symbolize.py / < log | c++filt; ==9442== ERROR: AddressSanitizer heap-use-after-free on address 0x7f7ddab8c084 at pc 0x403c8c bp 0x7fff87fb82d0 sp 0x7fff87fb82c8; READ of size 4 at 0x7f7ddab8c084 thread T0; #0 0x403c8c in main example_UseAfterFree.cc:4; #1 0x7f7ddabcac4d in __libc_start_main ??:0; ... Note that on macOS you may need to run ``dsymutil`` on your binary to have the; file\:line info in the AddressSanitizer reports. Additional Checks; =================. Initialization order checking; -----------------------------. AddressSanitizer can optionally detect dynamic initialization order problems,; when initialization of globals defined in one translation unit uses; globals defined in another translation unit. To enable this check at runtime,; you should set environment variable; ``ASAN_OPTIONS=check_initialization_order=1``. Note that this option is not supported on macOS. Stack Use After Return (UAR); ----------------------------. AddressSanitizer can optionally detect stack use after return problems.; This is available by default, or explicitly; (``-fsanitize-address-use-after-return=runtime``).; To disable this check at runtime, set the environment variable; ``ASAN_OPTIONS=detect_stack_use_after_return=0``. Enabling this check (``-fsanitize-address-use-after-return=always``) will; reduce code size. The code size may be reduced further by completely; eliminating this check (``-fsanitize-address-use-after-return=never``). To summarize: ``-fsanitize-address-use-after-return=<mode>``; * ``never``: Completely disables detection of UAR errors (reduces code size).; * ``runtime``: Adds the code for detection, but it can be disable via the; runtime environment (``ASAN_OPTIONS=detect_stack_use_after_return=0``).; * ``always``: Enables detection of UAR er",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:5978,Modifiability,variab,variable,5978," at 0x7f7ddab8c084 thread T0; #0 0x403c8c in main example_UseAfterFree.cc:4; #1 0x7f7ddabcac4d in __libc_start_main ??:0; ... Note that on macOS you may need to run ``dsymutil`` on your binary to have the; file\:line info in the AddressSanitizer reports. Additional Checks; =================. Initialization order checking; -----------------------------. AddressSanitizer can optionally detect dynamic initialization order problems,; when initialization of globals defined in one translation unit uses; globals defined in another translation unit. To enable this check at runtime,; you should set environment variable; ``ASAN_OPTIONS=check_initialization_order=1``. Note that this option is not supported on macOS. Stack Use After Return (UAR); ----------------------------. AddressSanitizer can optionally detect stack use after return problems.; This is available by default, or explicitly; (``-fsanitize-address-use-after-return=runtime``).; To disable this check at runtime, set the environment variable; ``ASAN_OPTIONS=detect_stack_use_after_return=0``. Enabling this check (``-fsanitize-address-use-after-return=always``) will; reduce code size. The code size may be reduced further by completely; eliminating this check (``-fsanitize-address-use-after-return=never``). To summarize: ``-fsanitize-address-use-after-return=<mode>``; * ``never``: Completely disables detection of UAR errors (reduces code size).; * ``runtime``: Adds the code for detection, but it can be disable via the; runtime environment (``ASAN_OPTIONS=detect_stack_use_after_return=0``).; * ``always``: Enables detection of UAR errors in all cases. (reduces code; size, but not as much as ``never``). Memory leak detection; ---------------------. For more information on leak detector in AddressSanitizer, see; :doc:`LeakSanitizer`. The leak detection is turned on by default on Linux,; and can be enabled using ``ASAN_OPTIONS=detect_leaks=1`` on macOS;; however, it is not yet supported on other platforms. Issue Suppression",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:7793,Modifiability,variab,variable,7793,"eakSanitizer`. The leak detection is turned on by default on Linux,; and can be enabled using ``ASAN_OPTIONS=detect_leaks=1`` on macOS;; however, it is not yet supported on other platforms. Issue Suppression; =================. AddressSanitizer is not expected to produce false positives. If you see one,; look again; most likely it is a true positive!. Suppressing Reports in External Libraries; -----------------------------------------; Runtime interposition allows AddressSanitizer to find bugs in code that is; not being recompiled. If you run into an issue in external libraries, we; recommend immediately reporting it to the library maintainer so that it; gets addressed. However, you can use the following suppression mechanism; to unblock yourself and continue on with the testing. This suppression; mechanism should only be used for suppressing issues in external code; it; does not work on code recompiled with AddressSanitizer. To suppress errors; in external libraries, set the ``ASAN_OPTIONS`` environment variable to point; to a suppression file. You can either specify the full path to the file or the; path of the file relative to the location of your executable. .. code-block:: bash. ASAN_OPTIONS=suppressions=MyASan.supp. Use the following format to specify the names of the functions or libraries; you want to suppress. You can see these in the error report. Remember that; the narrower the scope of the suppression, the more bugs you will be able to; catch. .. code-block:: bash. interceptor_via_fun:NameOfCFunctionToSuppress; interceptor_via_fun:-[ClassName objCMethodToSuppress:]; interceptor_via_lib:NameOfTheLibraryToSuppress. Conditional Compilation with ``__has_feature(address_sanitizer)``; -----------------------------------------------------------------. In some cases one may need to execute different code depending on whether; AddressSanitizer is enabled.; :ref:`\_\_has\_feature <langext-__has_feature-__has_extension>` can be used for; this purpose. .. code-block",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:9506,Modifiability,variab,variable,9506,"-------------------. In some cases one may need to execute different code depending on whether; AddressSanitizer is enabled.; :ref:`\_\_has\_feature <langext-__has_feature-__has_extension>` can be used for; this purpose. .. code-block:: c. #if defined(__has_feature); # if __has_feature(address_sanitizer); // code that builds only under AddressSanitizer; # endif; #endif. Disabling Instrumentation with ``__attribute__((no_sanitize(""address"")))``; --------------------------------------------------------------------------. Some code should not be instrumented by AddressSanitizer. One may use; the attribute ``__attribute__((no_sanitize(""address"")))`` (which has; deprecated synonyms `no_sanitize_address` and; `no_address_safety_analysis`) to disable instrumentation of a; particular function. This attribute may not be supported by other; compilers, so we suggest to use it together with; ``__has_feature(address_sanitizer)``. The same attribute used on a global variable prevents AddressSanitizer; from adding redzones around it and detecting out of bounds accesses. AddressSanitizer also supports; ``__attribute__((disable_sanitizer_instrumentation))``. This attribute; works similar to ``__attribute__((no_sanitize(""address"")))``, but it also; prevents instrumentation performed by other sanitizers. Suppressing Errors in Recompiled Code (Ignorelist); --------------------------------------------------. AddressSanitizer supports ``src`` and ``fun`` entity types in; :doc:`SanitizerSpecialCaseList`, that can be used to suppress error reports; in the specified source files or functions. Additionally, AddressSanitizer; introduces ``global`` and ``type`` entity types that can be used to; suppress error reports for out-of-bound access to globals with certain; names and types (you may only specify class or struct types). You may use an ``init`` category to suppress reports about initialization-order; problems happening in certain source files or with certain global variables. .. code-block",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:10516,Modifiability,variab,variables,10516,"(address_sanitizer)``. The same attribute used on a global variable prevents AddressSanitizer; from adding redzones around it and detecting out of bounds accesses. AddressSanitizer also supports; ``__attribute__((disable_sanitizer_instrumentation))``. This attribute; works similar to ``__attribute__((no_sanitize(""address"")))``, but it also; prevents instrumentation performed by other sanitizers. Suppressing Errors in Recompiled Code (Ignorelist); --------------------------------------------------. AddressSanitizer supports ``src`` and ``fun`` entity types in; :doc:`SanitizerSpecialCaseList`, that can be used to suppress error reports; in the specified source files or functions. Additionally, AddressSanitizer; introduces ``global`` and ``type`` entity types that can be used to; suppress error reports for out-of-bound access to globals with certain; names and types (you may only specify class or struct types). You may use an ``init`` category to suppress reports about initialization-order; problems happening in certain source files or with certain global variables. .. code-block:: bash. # Suppress error reports for code in a file or in a function:; src:bad_file.cpp; # Ignore all functions with names containing MyFooBar:; fun:*MyFooBar*; # Disable out-of-bound checks for global:; global:bad_array; # Disable out-of-bound checks for global instances of a given class ...; type:Namespace::BadClassName; # ... or a given struct. Use wildcard to deal with anonymous namespace.; type:Namespace2::*::BadStructName; # Disable initialization-order checks for globals:; global:bad_init_global=init; type:*BadInitClassSubstring*=init; src:bad/init/files/*=init. Suppressing memory leaks; ------------------------. Memory leak reports produced by :doc:`LeakSanitizer` (if it is run as a part; of AddressSanitizer) can be suppressed by a separate file passed as. .. code-block:: bash. LSAN_OPTIONS=suppressions=MyLSan.supp. which contains lines of the form `leak:<pattern>`. Memory leak will be",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:1607,Performance,perform,performance,1607,"er_return=0``.; * Use-after-scope (clang flag ``-fsanitize-address-use-after-scope``); * Double-free, invalid free; * Memory leaks (experimental). Typical slowdown introduced by AddressSanitizer is **2x**. How to build; ============. Build LLVM/Clang with `CMake <https://llvm.org/docs/CMake.html>` and enable; the ``compiler-rt`` runtime. An example CMake configuration that will allow; for the use/testing of AddressSanitizer:. .. code-block:: console. $ cmake -DCMAKE_BUILD_TYPE=Release -DLLVM_ENABLE_PROJECTS=""clang"" -DLLVM_ENABLE_RUNTIMES=""compiler-rt"" <path to source>/llvm. Usage; =====. Simply compile and link your program with ``-fsanitize=address`` flag. The; AddressSanitizer run-time library should be linked to the final executable, so; make sure to use ``clang`` (not ``ld``) for the final link step. When linking; shared libraries, the AddressSanitizer run-time is not linked, so; ``-Wl,-z,defs`` may cause link errors (don't use it with AddressSanitizer). To; get a reasonable performance add ``-O1`` or higher. To get nicer stack traces; in error messages add ``-fno-omit-frame-pointer``. To get perfect stack traces; you may need to disable inlining (just use ``-O1``) and tail call elimination; (``-fno-optimize-sibling-calls``). .. code-block:: console. % cat example_UseAfterFree.cc; int main(int argc, char **argv) {; int *array = new int[100];; delete [] array;; return array[argc]; // BOOM; }. # Compile and link; % clang++ -O1 -g -fsanitize=address -fno-omit-frame-pointer example_UseAfterFree.cc. or:. .. code-block:: console. # Compile; % clang++ -O1 -g -fsanitize=address -fno-omit-frame-pointer -c example_UseAfterFree.cc; # Link; % clang++ -g -fsanitize=address example_UseAfterFree.o. If a bug is detected, the program will print an error message to stderr and; exit with a non-zero exit code. AddressSanitizer exits on the first detected error.; This is by design:. * This approach allows AddressSanitizer to produce faster and smaller generated code; (both by ~5%).;",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:1836,Performance,optimiz,optimize-sibling-calls,1836," AddressSanitizer is **2x**. How to build; ============. Build LLVM/Clang with `CMake <https://llvm.org/docs/CMake.html>` and enable; the ``compiler-rt`` runtime. An example CMake configuration that will allow; for the use/testing of AddressSanitizer:. .. code-block:: console. $ cmake -DCMAKE_BUILD_TYPE=Release -DLLVM_ENABLE_PROJECTS=""clang"" -DLLVM_ENABLE_RUNTIMES=""compiler-rt"" <path to source>/llvm. Usage; =====. Simply compile and link your program with ``-fsanitize=address`` flag. The; AddressSanitizer run-time library should be linked to the final executable, so; make sure to use ``clang`` (not ``ld``) for the final link step. When linking; shared libraries, the AddressSanitizer run-time is not linked, so; ``-Wl,-z,defs`` may cause link errors (don't use it with AddressSanitizer). To; get a reasonable performance add ``-O1`` or higher. To get nicer stack traces; in error messages add ``-fno-omit-frame-pointer``. To get perfect stack traces; you may need to disable inlining (just use ``-O1``) and tail call elimination; (``-fno-optimize-sibling-calls``). .. code-block:: console. % cat example_UseAfterFree.cc; int main(int argc, char **argv) {; int *array = new int[100];; delete [] array;; return array[argc]; // BOOM; }. # Compile and link; % clang++ -O1 -g -fsanitize=address -fno-omit-frame-pointer example_UseAfterFree.cc. or:. .. code-block:: console. # Compile; % clang++ -O1 -g -fsanitize=address -fno-omit-frame-pointer -c example_UseAfterFree.cc; # Link; % clang++ -g -fsanitize=address example_UseAfterFree.o. If a bug is detected, the program will print an error message to stderr and; exit with a non-zero exit code. AddressSanitizer exits on the first detected error.; This is by design:. * This approach allows AddressSanitizer to produce faster and smaller generated code; (both by ~5%).; * Fixing bugs becomes unavoidable. AddressSanitizer does not produce; false alarms. Once a memory corruption occurs, the program is in an inconsistent; state, which could lead t",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:9815,Performance,perform,performed,9815,"ck:: c. #if defined(__has_feature); # if __has_feature(address_sanitizer); // code that builds only under AddressSanitizer; # endif; #endif. Disabling Instrumentation with ``__attribute__((no_sanitize(""address"")))``; --------------------------------------------------------------------------. Some code should not be instrumented by AddressSanitizer. One may use; the attribute ``__attribute__((no_sanitize(""address"")))`` (which has; deprecated synonyms `no_sanitize_address` and; `no_address_safety_analysis`) to disable instrumentation of a; particular function. This attribute may not be supported by other; compilers, so we suggest to use it together with; ``__has_feature(address_sanitizer)``. The same attribute used on a global variable prevents AddressSanitizer; from adding redzones around it and detecting out of bounds accesses. AddressSanitizer also supports; ``__attribute__((disable_sanitizer_instrumentation))``. This attribute; works similar to ``__attribute__((no_sanitize(""address"")))``, but it also; prevents instrumentation performed by other sanitizers. Suppressing Errors in Recompiled Code (Ignorelist); --------------------------------------------------. AddressSanitizer supports ``src`` and ``fun`` entity types in; :doc:`SanitizerSpecialCaseList`, that can be used to suppress error reports; in the specified source files or functions. Additionally, AddressSanitizer; introduces ``global`` and ``type`` entity types that can be used to; suppress error reports for out-of-bound access to globals with certain; names and types (you may only specify class or struct types). You may use an ``init`` category to suppress reports about initialization-order; problems happening in certain source files or with certain global variables. .. code-block:: bash. # Suppress error reports for code in a file or in a function:; src:bad_file.cpp; # Ignore all functions with names containing MyFooBar:; fun:*MyFooBar*; # Disable out-of-bound checks for global:; global:bad_array; # Disable",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:11917,Performance,perform,performance,11917,"dcard to deal with anonymous namespace.; type:Namespace2::*::BadStructName; # Disable initialization-order checks for globals:; global:bad_init_global=init; type:*BadInitClassSubstring*=init; src:bad/init/files/*=init. Suppressing memory leaks; ------------------------. Memory leak reports produced by :doc:`LeakSanitizer` (if it is run as a part; of AddressSanitizer) can be suppressed by a separate file passed as. .. code-block:: bash. LSAN_OPTIONS=suppressions=MyLSan.supp. which contains lines of the form `leak:<pattern>`. Memory leak will be; suppressed if pattern matches any function name, source file name, or; library name in the symbolized stack trace of the leak report. See; `full documentation; <https://github.com/google/sanitizers/wiki/AddressSanitizerLeakSanitizer#suppressions>`_; for more details. Code generation control; =======================. Instrumentation code outlining; ------------------------------. By default AddressSanitizer inlines the instrumentation code to improve the; run-time performance, which leads to increased binary size. Using the; (clang flag ``-fsanitize-address-outline-instrumentation` default: ``false``); flag forces all code instrumentation to be outlined, which reduces the size; of the generated code, but also reduces the run-time performance. Limitations; ===========. * AddressSanitizer uses more real memory than a native run. Exact overhead; depends on the allocations sizes. The smaller the allocations you make the; bigger the overhead is.; * AddressSanitizer uses more stack memory. We have seen up to 3x increase.; * On 64-bit platforms AddressSanitizer maps (but not reserves) 16+ Terabytes of; virtual address space. This means that tools like ``ulimit`` may not work as; usually expected.; * Static linking of executables is not supported. Supported Platforms; ===================. AddressSanitizer is supported on:. * Linux i386/x86\_64 (tested on Ubuntu 12.04); * macOS 10.7 - 10.11 (i386/x86\_64); * iOS Simulator; * Android ARM",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:12188,Performance,perform,performance,12188,"=init; src:bad/init/files/*=init. Suppressing memory leaks; ------------------------. Memory leak reports produced by :doc:`LeakSanitizer` (if it is run as a part; of AddressSanitizer) can be suppressed by a separate file passed as. .. code-block:: bash. LSAN_OPTIONS=suppressions=MyLSan.supp. which contains lines of the form `leak:<pattern>`. Memory leak will be; suppressed if pattern matches any function name, source file name, or; library name in the symbolized stack trace of the leak report. See; `full documentation; <https://github.com/google/sanitizers/wiki/AddressSanitizerLeakSanitizer#suppressions>`_; for more details. Code generation control; =======================. Instrumentation code outlining; ------------------------------. By default AddressSanitizer inlines the instrumentation code to improve the; run-time performance, which leads to increased binary size. Using the; (clang flag ``-fsanitize-address-outline-instrumentation` default: ``false``); flag forces all code instrumentation to be outlined, which reduces the size; of the generated code, but also reduces the run-time performance. Limitations; ===========. * AddressSanitizer uses more real memory than a native run. Exact overhead; depends on the allocations sizes. The smaller the allocations you make the; bigger the overhead is.; * AddressSanitizer uses more stack memory. We have seen up to 3x increase.; * On 64-bit platforms AddressSanitizer maps (but not reserves) 16+ Terabytes of; virtual address space. This means that tools like ``ulimit`` may not work as; usually expected.; * Static linking of executables is not supported. Supported Platforms; ===================. AddressSanitizer is supported on:. * Linux i386/x86\_64 (tested on Ubuntu 12.04); * macOS 10.7 - 10.11 (i386/x86\_64); * iOS Simulator; * Android ARM; * NetBSD i386/x86\_64; * FreeBSD i386/x86\_64 (tested on FreeBSD 11-current); * Windows 8.1+ (i386/x86\_64). Ports to various other platforms are in progress. Current Status; ========",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:146,Safety,detect,detector,146,"================; AddressSanitizer; ================. .. contents::; :local:. Introduction; ============. AddressSanitizer is a fast memory error detector. It consists of a compiler; instrumentation module and a run-time library. The tool can detect the; following types of bugs:. * Out-of-bounds accesses to heap, stack and globals; * Use-after-free; * Use-after-return (clang flag ``-fsanitize-address-use-after-return=(never|runtime|always)`` default: ``runtime``); * Enable with: ``ASAN_OPTIONS=detect_stack_use_after_return=1`` (already enabled on Linux).; * Disable with: ``ASAN_OPTIONS=detect_stack_use_after_return=0``.; * Use-after-scope (clang flag ``-fsanitize-address-use-after-scope``); * Double-free, invalid free; * Memory leaks (experimental). Typical slowdown introduced by AddressSanitizer is **2x**. How to build; ============. Build LLVM/Clang with `CMake <https://llvm.org/docs/CMake.html>` and enable; the ``compiler-rt`` runtime. An example CMake configuration that will allow; for the use/testing of AddressSanitizer:. .. code-block:: console. $ cmake -DCMAKE_BUILD_TYPE=Release -DLLVM_ENABLE_PROJECTS=""clang"" -DLLVM_ENABLE_RUNTIMES=""compiler-rt"" <path to source>/llvm. Usage; =====. Simply compile and link your program with ``-fsanitize=address`` flag. The; AddressSanitizer run-time library should be linked to the final executable, so; make sure to use ``clang`` (not ``ld``) for the final link step. When linking; shared libraries, the AddressSanitizer run-time is not linked, so; ``-Wl,-z,defs`` may cause link errors (don't use it with AddressSanitizer). To; get a reasonable performance add ``-O1`` or higher. To get nicer stack traces; in error messages add ``-fno-omit-frame-pointer``. To get perfect stack traces; you may need to disable inlining (just use ``-O1``) and tail call elimination; (``-fno-optimize-sibling-calls``). .. code-block:: console. % cat example_UseAfterFree.cc; int main(int argc, char **argv) {; int *array = new int[100];; delete [] array;; r",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:243,Safety,detect,detect,243,"================; AddressSanitizer; ================. .. contents::; :local:. Introduction; ============. AddressSanitizer is a fast memory error detector. It consists of a compiler; instrumentation module and a run-time library. The tool can detect the; following types of bugs:. * Out-of-bounds accesses to heap, stack and globals; * Use-after-free; * Use-after-return (clang flag ``-fsanitize-address-use-after-return=(never|runtime|always)`` default: ``runtime``); * Enable with: ``ASAN_OPTIONS=detect_stack_use_after_return=1`` (already enabled on Linux).; * Disable with: ``ASAN_OPTIONS=detect_stack_use_after_return=0``.; * Use-after-scope (clang flag ``-fsanitize-address-use-after-scope``); * Double-free, invalid free; * Memory leaks (experimental). Typical slowdown introduced by AddressSanitizer is **2x**. How to build; ============. Build LLVM/Clang with `CMake <https://llvm.org/docs/CMake.html>` and enable; the ``compiler-rt`` runtime. An example CMake configuration that will allow; for the use/testing of AddressSanitizer:. .. code-block:: console. $ cmake -DCMAKE_BUILD_TYPE=Release -DLLVM_ENABLE_PROJECTS=""clang"" -DLLVM_ENABLE_RUNTIMES=""compiler-rt"" <path to source>/llvm. Usage; =====. Simply compile and link your program with ``-fsanitize=address`` flag. The; AddressSanitizer run-time library should be linked to the final executable, so; make sure to use ``clang`` (not ``ld``) for the final link step. When linking; shared libraries, the AddressSanitizer run-time is not linked, so; ``-Wl,-z,defs`` may cause link errors (don't use it with AddressSanitizer). To; get a reasonable performance add ``-O1`` or higher. To get nicer stack traces; in error messages add ``-fno-omit-frame-pointer``. To get perfect stack traces; you may need to disable inlining (just use ``-O1``) and tail call elimination; (``-fno-optimize-sibling-calls``). .. code-block:: console. % cat example_UseAfterFree.cc; int main(int argc, char **argv) {; int *array = new int[100];; delete [] array;; r",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:2342,Safety,detect,detected,2342,"clang`` (not ``ld``) for the final link step. When linking; shared libraries, the AddressSanitizer run-time is not linked, so; ``-Wl,-z,defs`` may cause link errors (don't use it with AddressSanitizer). To; get a reasonable performance add ``-O1`` or higher. To get nicer stack traces; in error messages add ``-fno-omit-frame-pointer``. To get perfect stack traces; you may need to disable inlining (just use ``-O1``) and tail call elimination; (``-fno-optimize-sibling-calls``). .. code-block:: console. % cat example_UseAfterFree.cc; int main(int argc, char **argv) {; int *array = new int[100];; delete [] array;; return array[argc]; // BOOM; }. # Compile and link; % clang++ -O1 -g -fsanitize=address -fno-omit-frame-pointer example_UseAfterFree.cc. or:. .. code-block:: console. # Compile; % clang++ -O1 -g -fsanitize=address -fno-omit-frame-pointer -c example_UseAfterFree.cc; # Link; % clang++ -g -fsanitize=address example_UseAfterFree.o. If a bug is detected, the program will print an error message to stderr and; exit with a non-zero exit code. AddressSanitizer exits on the first detected error.; This is by design:. * This approach allows AddressSanitizer to produce faster and smaller generated code; (both by ~5%).; * Fixing bugs becomes unavoidable. AddressSanitizer does not produce; false alarms. Once a memory corruption occurs, the program is in an inconsistent; state, which could lead to confusing results and potentially misleading; subsequent reports. If your process is sandboxed and you are running on OS X 10.10 or earlier, you; will need to set ``DYLD_INSERT_LIBRARIES`` environment variable and point it to; the ASan library that is packaged with the compiler used to build the; executable. (You can find the library by searching for dynamic libraries with; ``asan`` in their name.) If the environment variable is not set, the process will; try to re-exec. Also keep in mind that when moving the executable to another machine,; the ASan library will also need to be copied",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:2475,Safety,detect,detected,2475," AddressSanitizer run-time is not linked, so; ``-Wl,-z,defs`` may cause link errors (don't use it with AddressSanitizer). To; get a reasonable performance add ``-O1`` or higher. To get nicer stack traces; in error messages add ``-fno-omit-frame-pointer``. To get perfect stack traces; you may need to disable inlining (just use ``-O1``) and tail call elimination; (``-fno-optimize-sibling-calls``). .. code-block:: console. % cat example_UseAfterFree.cc; int main(int argc, char **argv) {; int *array = new int[100];; delete [] array;; return array[argc]; // BOOM; }. # Compile and link; % clang++ -O1 -g -fsanitize=address -fno-omit-frame-pointer example_UseAfterFree.cc. or:. .. code-block:: console. # Compile; % clang++ -O1 -g -fsanitize=address -fno-omit-frame-pointer -c example_UseAfterFree.cc; # Link; % clang++ -g -fsanitize=address example_UseAfterFree.o. If a bug is detected, the program will print an error message to stderr and; exit with a non-zero exit code. AddressSanitizer exits on the first detected error.; This is by design:. * This approach allows AddressSanitizer to produce faster and smaller generated code; (both by ~5%).; * Fixing bugs becomes unavoidable. AddressSanitizer does not produce; false alarms. Once a memory corruption occurs, the program is in an inconsistent; state, which could lead to confusing results and potentially misleading; subsequent reports. If your process is sandboxed and you are running on OS X 10.10 or earlier, you; will need to set ``DYLD_INSERT_LIBRARIES`` environment variable and point it to; the ASan library that is packaged with the compiler used to build the; executable. (You can find the library by searching for dynamic libraries with; ``asan`` in their name.) If the environment variable is not set, the process will; try to re-exec. Also keep in mind that when moving the executable to another machine,; the ASan library will also need to be copied over. Symbolizing the Reports; =========================. To make AddressSaniti",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:5366,Safety,detect,detect,5366,"n __libc_start_main ??:0; ==9442== ABORTING. If that does not work for you (e.g. your process is sandboxed), you can use a; separate script to symbolize the result offline (online symbolization can be; force disabled by setting ``ASAN_OPTIONS=symbolize=0``):. .. code-block:: console. % ASAN_OPTIONS=symbolize=0 ./a.out 2> log; % projects/compiler-rt/lib/asan/scripts/asan_symbolize.py / < log | c++filt; ==9442== ERROR: AddressSanitizer heap-use-after-free on address 0x7f7ddab8c084 at pc 0x403c8c bp 0x7fff87fb82d0 sp 0x7fff87fb82c8; READ of size 4 at 0x7f7ddab8c084 thread T0; #0 0x403c8c in main example_UseAfterFree.cc:4; #1 0x7f7ddabcac4d in __libc_start_main ??:0; ... Note that on macOS you may need to run ``dsymutil`` on your binary to have the; file\:line info in the AddressSanitizer reports. Additional Checks; =================. Initialization order checking; -----------------------------. AddressSanitizer can optionally detect dynamic initialization order problems,; when initialization of globals defined in one translation unit uses; globals defined in another translation unit. To enable this check at runtime,; you should set environment variable; ``ASAN_OPTIONS=check_initialization_order=1``. Note that this option is not supported on macOS. Stack Use After Return (UAR); ----------------------------. AddressSanitizer can optionally detect stack use after return problems.; This is available by default, or explicitly; (``-fsanitize-address-use-after-return=runtime``).; To disable this check at runtime, set the environment variable; ``ASAN_OPTIONS=detect_stack_use_after_return=0``. Enabling this check (``-fsanitize-address-use-after-return=always``) will; reduce code size. The code size may be reduced further by completely; eliminating this check (``-fsanitize-address-use-after-return=never``). To summarize: ``-fsanitize-address-use-after-return=<mode>``; * ``never``: Completely disables detection of UAR errors (reduces code size).; * ``runtime``: Adds the code for d",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:5786,Safety,detect,detect,5786,"scripts/asan_symbolize.py / < log | c++filt; ==9442== ERROR: AddressSanitizer heap-use-after-free on address 0x7f7ddab8c084 at pc 0x403c8c bp 0x7fff87fb82d0 sp 0x7fff87fb82c8; READ of size 4 at 0x7f7ddab8c084 thread T0; #0 0x403c8c in main example_UseAfterFree.cc:4; #1 0x7f7ddabcac4d in __libc_start_main ??:0; ... Note that on macOS you may need to run ``dsymutil`` on your binary to have the; file\:line info in the AddressSanitizer reports. Additional Checks; =================. Initialization order checking; -----------------------------. AddressSanitizer can optionally detect dynamic initialization order problems,; when initialization of globals defined in one translation unit uses; globals defined in another translation unit. To enable this check at runtime,; you should set environment variable; ``ASAN_OPTIONS=check_initialization_order=1``. Note that this option is not supported on macOS. Stack Use After Return (UAR); ----------------------------. AddressSanitizer can optionally detect stack use after return problems.; This is available by default, or explicitly; (``-fsanitize-address-use-after-return=runtime``).; To disable this check at runtime, set the environment variable; ``ASAN_OPTIONS=detect_stack_use_after_return=0``. Enabling this check (``-fsanitize-address-use-after-return=always``) will; reduce code size. The code size may be reduced further by completely; eliminating this check (``-fsanitize-address-use-after-return=never``). To summarize: ``-fsanitize-address-use-after-return=<mode>``; * ``never``: Completely disables detection of UAR errors (reduces code size).; * ``runtime``: Adds the code for detection, but it can be disable via the; runtime environment (``ASAN_OPTIONS=detect_stack_use_after_return=0``).; * ``always``: Enables detection of UAR errors in all cases. (reduces code; size, but not as much as ``never``). Memory leak detection; ---------------------. For more information on leak detector in AddressSanitizer, see; :doc:`LeakSanitizer`. T",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:6350,Safety,detect,detection,6350,"--------. AddressSanitizer can optionally detect dynamic initialization order problems,; when initialization of globals defined in one translation unit uses; globals defined in another translation unit. To enable this check at runtime,; you should set environment variable; ``ASAN_OPTIONS=check_initialization_order=1``. Note that this option is not supported on macOS. Stack Use After Return (UAR); ----------------------------. AddressSanitizer can optionally detect stack use after return problems.; This is available by default, or explicitly; (``-fsanitize-address-use-after-return=runtime``).; To disable this check at runtime, set the environment variable; ``ASAN_OPTIONS=detect_stack_use_after_return=0``. Enabling this check (``-fsanitize-address-use-after-return=always``) will; reduce code size. The code size may be reduced further by completely; eliminating this check (``-fsanitize-address-use-after-return=never``). To summarize: ``-fsanitize-address-use-after-return=<mode>``; * ``never``: Completely disables detection of UAR errors (reduces code size).; * ``runtime``: Adds the code for detection, but it can be disable via the; runtime environment (``ASAN_OPTIONS=detect_stack_use_after_return=0``).; * ``always``: Enables detection of UAR errors in all cases. (reduces code; size, but not as much as ``never``). Memory leak detection; ---------------------. For more information on leak detector in AddressSanitizer, see; :doc:`LeakSanitizer`. The leak detection is turned on by default on Linux,; and can be enabled using ``ASAN_OPTIONS=detect_leaks=1`` on macOS;; however, it is not yet supported on other platforms. Issue Suppression; =================. AddressSanitizer is not expected to produce false positives. If you see one,; look again; most likely it is a true positive!. Suppressing Reports in External Libraries; -----------------------------------------; Runtime interposition allows AddressSanitizer to find bugs in code that is; not being recompiled. If you run in",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:6429,Safety,detect,detection,6429,"on unit uses; globals defined in another translation unit. To enable this check at runtime,; you should set environment variable; ``ASAN_OPTIONS=check_initialization_order=1``. Note that this option is not supported on macOS. Stack Use After Return (UAR); ----------------------------. AddressSanitizer can optionally detect stack use after return problems.; This is available by default, or explicitly; (``-fsanitize-address-use-after-return=runtime``).; To disable this check at runtime, set the environment variable; ``ASAN_OPTIONS=detect_stack_use_after_return=0``. Enabling this check (``-fsanitize-address-use-after-return=always``) will; reduce code size. The code size may be reduced further by completely; eliminating this check (``-fsanitize-address-use-after-return=never``). To summarize: ``-fsanitize-address-use-after-return=<mode>``; * ``never``: Completely disables detection of UAR errors (reduces code size).; * ``runtime``: Adds the code for detection, but it can be disable via the; runtime environment (``ASAN_OPTIONS=detect_stack_use_after_return=0``).; * ``always``: Enables detection of UAR errors in all cases. (reduces code; size, but not as much as ``never``). Memory leak detection; ---------------------. For more information on leak detector in AddressSanitizer, see; :doc:`LeakSanitizer`. The leak detection is turned on by default on Linux,; and can be enabled using ``ASAN_OPTIONS=detect_leaks=1`` on macOS;; however, it is not yet supported on other platforms. Issue Suppression; =================. AddressSanitizer is not expected to produce false positives. If you see one,; look again; most likely it is a true positive!. Suppressing Reports in External Libraries; -----------------------------------------; Runtime interposition allows AddressSanitizer to find bugs in code that is; not being recompiled. If you run into an issue in external libraries, we; recommend immediately reporting it to the library maintainer so that it; gets addressed. However, you can",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:6566,Safety,detect,detection,6566,"set environment variable; ``ASAN_OPTIONS=check_initialization_order=1``. Note that this option is not supported on macOS. Stack Use After Return (UAR); ----------------------------. AddressSanitizer can optionally detect stack use after return problems.; This is available by default, or explicitly; (``-fsanitize-address-use-after-return=runtime``).; To disable this check at runtime, set the environment variable; ``ASAN_OPTIONS=detect_stack_use_after_return=0``. Enabling this check (``-fsanitize-address-use-after-return=always``) will; reduce code size. The code size may be reduced further by completely; eliminating this check (``-fsanitize-address-use-after-return=never``). To summarize: ``-fsanitize-address-use-after-return=<mode>``; * ``never``: Completely disables detection of UAR errors (reduces code size).; * ``runtime``: Adds the code for detection, but it can be disable via the; runtime environment (``ASAN_OPTIONS=detect_stack_use_after_return=0``).; * ``always``: Enables detection of UAR errors in all cases. (reduces code; size, but not as much as ``never``). Memory leak detection; ---------------------. For more information on leak detector in AddressSanitizer, see; :doc:`LeakSanitizer`. The leak detection is turned on by default on Linux,; and can be enabled using ``ASAN_OPTIONS=detect_leaks=1`` on macOS;; however, it is not yet supported on other platforms. Issue Suppression; =================. AddressSanitizer is not expected to produce false positives. If you see one,; look again; most likely it is a true positive!. Suppressing Reports in External Libraries; -----------------------------------------; Runtime interposition allows AddressSanitizer to find bugs in code that is; not being recompiled. If you run into an issue in external libraries, we; recommend immediately reporting it to the library maintainer so that it; gets addressed. However, you can use the following suppression mechanism; to unblock yourself and continue on with the testing. This supp",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:6668,Safety,detect,detection,6668,"orted on macOS. Stack Use After Return (UAR); ----------------------------. AddressSanitizer can optionally detect stack use after return problems.; This is available by default, or explicitly; (``-fsanitize-address-use-after-return=runtime``).; To disable this check at runtime, set the environment variable; ``ASAN_OPTIONS=detect_stack_use_after_return=0``. Enabling this check (``-fsanitize-address-use-after-return=always``) will; reduce code size. The code size may be reduced further by completely; eliminating this check (``-fsanitize-address-use-after-return=never``). To summarize: ``-fsanitize-address-use-after-return=<mode>``; * ``never``: Completely disables detection of UAR errors (reduces code size).; * ``runtime``: Adds the code for detection, but it can be disable via the; runtime environment (``ASAN_OPTIONS=detect_stack_use_after_return=0``).; * ``always``: Enables detection of UAR errors in all cases. (reduces code; size, but not as much as ``never``). Memory leak detection; ---------------------. For more information on leak detector in AddressSanitizer, see; :doc:`LeakSanitizer`. The leak detection is turned on by default on Linux,; and can be enabled using ``ASAN_OPTIONS=detect_leaks=1`` on macOS;; however, it is not yet supported on other platforms. Issue Suppression; =================. AddressSanitizer is not expected to produce false positives. If you see one,; look again; most likely it is a true positive!. Suppressing Reports in External Libraries; -----------------------------------------; Runtime interposition allows AddressSanitizer to find bugs in code that is; not being recompiled. If you run into an issue in external libraries, we; recommend immediately reporting it to the library maintainer so that it; gets addressed. However, you can use the following suppression mechanism; to unblock yourself and continue on with the testing. This suppression; mechanism should only be used for suppressing issues in external code; it; does not work on code",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:6731,Safety,detect,detector,6731,"--------. AddressSanitizer can optionally detect stack use after return problems.; This is available by default, or explicitly; (``-fsanitize-address-use-after-return=runtime``).; To disable this check at runtime, set the environment variable; ``ASAN_OPTIONS=detect_stack_use_after_return=0``. Enabling this check (``-fsanitize-address-use-after-return=always``) will; reduce code size. The code size may be reduced further by completely; eliminating this check (``-fsanitize-address-use-after-return=never``). To summarize: ``-fsanitize-address-use-after-return=<mode>``; * ``never``: Completely disables detection of UAR errors (reduces code size).; * ``runtime``: Adds the code for detection, but it can be disable via the; runtime environment (``ASAN_OPTIONS=detect_stack_use_after_return=0``).; * ``always``: Enables detection of UAR errors in all cases. (reduces code; size, but not as much as ``never``). Memory leak detection; ---------------------. For more information on leak detector in AddressSanitizer, see; :doc:`LeakSanitizer`. The leak detection is turned on by default on Linux,; and can be enabled using ``ASAN_OPTIONS=detect_leaks=1`` on macOS;; however, it is not yet supported on other platforms. Issue Suppression; =================. AddressSanitizer is not expected to produce false positives. If you see one,; look again; most likely it is a true positive!. Suppressing Reports in External Libraries; -----------------------------------------; Runtime interposition allows AddressSanitizer to find bugs in code that is; not being recompiled. If you run into an issue in external libraries, we; recommend immediately reporting it to the library maintainer so that it; gets addressed. However, you can use the following suppression mechanism; to unblock yourself and continue on with the testing. This suppression; mechanism should only be used for suppressing issues in external code; it; does not work on code recompiled with AddressSanitizer. To suppress errors; in external",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:6797,Safety,detect,detection,6797,"`-fsanitize-address-use-after-return=runtime``).; To disable this check at runtime, set the environment variable; ``ASAN_OPTIONS=detect_stack_use_after_return=0``. Enabling this check (``-fsanitize-address-use-after-return=always``) will; reduce code size. The code size may be reduced further by completely; eliminating this check (``-fsanitize-address-use-after-return=never``). To summarize: ``-fsanitize-address-use-after-return=<mode>``; * ``never``: Completely disables detection of UAR errors (reduces code size).; * ``runtime``: Adds the code for detection, but it can be disable via the; runtime environment (``ASAN_OPTIONS=detect_stack_use_after_return=0``).; * ``always``: Enables detection of UAR errors in all cases. (reduces code; size, but not as much as ``never``). Memory leak detection; ---------------------. For more information on leak detector in AddressSanitizer, see; :doc:`LeakSanitizer`. The leak detection is turned on by default on Linux,; and can be enabled using ``ASAN_OPTIONS=detect_leaks=1`` on macOS;; however, it is not yet supported on other platforms. Issue Suppression; =================. AddressSanitizer is not expected to produce false positives. If you see one,; look again; most likely it is a true positive!. Suppressing Reports in External Libraries; -----------------------------------------; Runtime interposition allows AddressSanitizer to find bugs in code that is; not being recompiled. If you run into an issue in external libraries, we; recommend immediately reporting it to the library maintainer so that it; gets addressed. However, you can use the following suppression mechanism; to unblock yourself and continue on with the testing. This suppression; mechanism should only be used for suppressing issues in external code; it; does not work on code recompiled with AddressSanitizer. To suppress errors; in external libraries, set the ``ASAN_OPTIONS`` environment variable to point; to a suppression file. You can either specify the full path to ",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:9577,Safety,detect,detecting,9577,"-------------------. In some cases one may need to execute different code depending on whether; AddressSanitizer is enabled.; :ref:`\_\_has\_feature <langext-__has_feature-__has_extension>` can be used for; this purpose. .. code-block:: c. #if defined(__has_feature); # if __has_feature(address_sanitizer); // code that builds only under AddressSanitizer; # endif; #endif. Disabling Instrumentation with ``__attribute__((no_sanitize(""address"")))``; --------------------------------------------------------------------------. Some code should not be instrumented by AddressSanitizer. One may use; the attribute ``__attribute__((no_sanitize(""address"")))`` (which has; deprecated synonyms `no_sanitize_address` and; `no_address_safety_analysis`) to disable instrumentation of a; particular function. This attribute may not be supported by other; compilers, so we suggest to use it together with; ``__has_feature(address_sanitizer)``. The same attribute used on a global variable prevents AddressSanitizer; from adding redzones around it and detecting out of bounds accesses. AddressSanitizer also supports; ``__attribute__((disable_sanitizer_instrumentation))``. This attribute; works similar to ``__attribute__((no_sanitize(""address"")))``, but it also; prevents instrumentation performed by other sanitizers. Suppressing Errors in Recompiled Code (Ignorelist); --------------------------------------------------. AddressSanitizer supports ``src`` and ``fun`` entity types in; :doc:`SanitizerSpecialCaseList`, that can be used to suppress error reports; in the specified source files or functions. Additionally, AddressSanitizer; introduces ``global`` and ``type`` entity types that can be used to; suppress error reports for out-of-bound access to globals with certain; names and types (you may only specify class or struct types). You may use an ``init`` category to suppress reports about initialization-order; problems happening in certain source files or with certain global variables. .. code-block",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:297,Security,access,accesses,297,"================; AddressSanitizer; ================. .. contents::; :local:. Introduction; ============. AddressSanitizer is a fast memory error detector. It consists of a compiler; instrumentation module and a run-time library. The tool can detect the; following types of bugs:. * Out-of-bounds accesses to heap, stack and globals; * Use-after-free; * Use-after-return (clang flag ``-fsanitize-address-use-after-return=(never|runtime|always)`` default: ``runtime``); * Enable with: ``ASAN_OPTIONS=detect_stack_use_after_return=1`` (already enabled on Linux).; * Disable with: ``ASAN_OPTIONS=detect_stack_use_after_return=0``.; * Use-after-scope (clang flag ``-fsanitize-address-use-after-scope``); * Double-free, invalid free; * Memory leaks (experimental). Typical slowdown introduced by AddressSanitizer is **2x**. How to build; ============. Build LLVM/Clang with `CMake <https://llvm.org/docs/CMake.html>` and enable; the ``compiler-rt`` runtime. An example CMake configuration that will allow; for the use/testing of AddressSanitizer:. .. code-block:: console. $ cmake -DCMAKE_BUILD_TYPE=Release -DLLVM_ENABLE_PROJECTS=""clang"" -DLLVM_ENABLE_RUNTIMES=""compiler-rt"" <path to source>/llvm. Usage; =====. Simply compile and link your program with ``-fsanitize=address`` flag. The; AddressSanitizer run-time library should be linked to the final executable, so; make sure to use ``clang`` (not ``ld``) for the final link step. When linking; shared libraries, the AddressSanitizer run-time is not linked, so; ``-Wl,-z,defs`` may cause link errors (don't use it with AddressSanitizer). To; get a reasonable performance add ``-O1`` or higher. To get nicer stack traces; in error messages add ``-fno-omit-frame-pointer``. To get perfect stack traces; you may need to disable inlining (just use ``-O1``) and tail call elimination; (``-fno-optimize-sibling-calls``). .. code-block:: console. % cat example_UseAfterFree.cc; int main(int argc, char **argv) {; int *array = new int[100];; delete [] array;; r",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:9601,Security,access,accesses,9601,"-------------------. In some cases one may need to execute different code depending on whether; AddressSanitizer is enabled.; :ref:`\_\_has\_feature <langext-__has_feature-__has_extension>` can be used for; this purpose. .. code-block:: c. #if defined(__has_feature); # if __has_feature(address_sanitizer); // code that builds only under AddressSanitizer; # endif; #endif. Disabling Instrumentation with ``__attribute__((no_sanitize(""address"")))``; --------------------------------------------------------------------------. Some code should not be instrumented by AddressSanitizer. One may use; the attribute ``__attribute__((no_sanitize(""address"")))`` (which has; deprecated synonyms `no_sanitize_address` and; `no_address_safety_analysis`) to disable instrumentation of a; particular function. This attribute may not be supported by other; compilers, so we suggest to use it together with; ``__has_feature(address_sanitizer)``. The same attribute used on a global variable prevents AddressSanitizer; from adding redzones around it and detecting out of bounds accesses. AddressSanitizer also supports; ``__attribute__((disable_sanitizer_instrumentation))``. This attribute; works similar to ``__attribute__((no_sanitize(""address"")))``, but it also; prevents instrumentation performed by other sanitizers. Suppressing Errors in Recompiled Code (Ignorelist); --------------------------------------------------. AddressSanitizer supports ``src`` and ``fun`` entity types in; :doc:`SanitizerSpecialCaseList`, that can be used to suppress error reports; in the specified source files or functions. Additionally, AddressSanitizer; introduces ``global`` and ``type`` entity types that can be used to; suppress error reports for out-of-bound access to globals with certain; names and types (you may only specify class or struct types). You may use an ``init`` category to suppress reports about initialization-order; problems happening in certain source files or with certain global variables. .. code-block",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:9834,Security,sanitiz,sanitizers,9834,"ck:: c. #if defined(__has_feature); # if __has_feature(address_sanitizer); // code that builds only under AddressSanitizer; # endif; #endif. Disabling Instrumentation with ``__attribute__((no_sanitize(""address"")))``; --------------------------------------------------------------------------. Some code should not be instrumented by AddressSanitizer. One may use; the attribute ``__attribute__((no_sanitize(""address"")))`` (which has; deprecated synonyms `no_sanitize_address` and; `no_address_safety_analysis`) to disable instrumentation of a; particular function. This attribute may not be supported by other; compilers, so we suggest to use it together with; ``__has_feature(address_sanitizer)``. The same attribute used on a global variable prevents AddressSanitizer; from adding redzones around it and detecting out of bounds accesses. AddressSanitizer also supports; ``__attribute__((disable_sanitizer_instrumentation))``. This attribute; works similar to ``__attribute__((no_sanitize(""address"")))``, but it also; prevents instrumentation performed by other sanitizers. Suppressing Errors in Recompiled Code (Ignorelist); --------------------------------------------------. AddressSanitizer supports ``src`` and ``fun`` entity types in; :doc:`SanitizerSpecialCaseList`, that can be used to suppress error reports; in the specified source files or functions. Additionally, AddressSanitizer; introduces ``global`` and ``type`` entity types that can be used to; suppress error reports for out-of-bound access to globals with certain; names and types (you may only specify class or struct types). You may use an ``init`` category to suppress reports about initialization-order; problems happening in certain source files or with certain global variables. .. code-block:: bash. # Suppress error reports for code in a file or in a function:; src:bad_file.cpp; # Ignore all functions with names containing MyFooBar:; fun:*MyFooBar*; # Disable out-of-bound checks for global:; global:bad_array; # Disable",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:10275,Security,access,access,10275,"; `no_address_safety_analysis`) to disable instrumentation of a; particular function. This attribute may not be supported by other; compilers, so we suggest to use it together with; ``__has_feature(address_sanitizer)``. The same attribute used on a global variable prevents AddressSanitizer; from adding redzones around it and detecting out of bounds accesses. AddressSanitizer also supports; ``__attribute__((disable_sanitizer_instrumentation))``. This attribute; works similar to ``__attribute__((no_sanitize(""address"")))``, but it also; prevents instrumentation performed by other sanitizers. Suppressing Errors in Recompiled Code (Ignorelist); --------------------------------------------------. AddressSanitizer supports ``src`` and ``fun`` entity types in; :doc:`SanitizerSpecialCaseList`, that can be used to suppress error reports; in the specified source files or functions. Additionally, AddressSanitizer; introduces ``global`` and ``type`` entity types that can be used to; suppress error reports for out-of-bound access to globals with certain; names and types (you may only specify class or struct types). You may use an ``init`` category to suppress reports about initialization-order; problems happening in certain source files or with certain global variables. .. code-block:: bash. # Suppress error reports for code in a file or in a function:; src:bad_file.cpp; # Ignore all functions with names containing MyFooBar:; fun:*MyFooBar*; # Disable out-of-bound checks for global:; global:bad_array; # Disable out-of-bound checks for global instances of a given class ...; type:Namespace::BadClassName; # ... or a given struct. Use wildcard to deal with anonymous namespace.; type:Namespace2::*::BadStructName; # Disable initialization-order checks for globals:; global:bad_init_global=init; type:*BadInitClassSubstring*=init; src:bad/init/files/*=init. Suppressing memory leaks; ------------------------. Memory leak reports produced by :doc:`LeakSanitizer` (if it is run as a part; of A",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:11636,Security,sanitiz,sanitizers,11636,"ning MyFooBar:; fun:*MyFooBar*; # Disable out-of-bound checks for global:; global:bad_array; # Disable out-of-bound checks for global instances of a given class ...; type:Namespace::BadClassName; # ... or a given struct. Use wildcard to deal with anonymous namespace.; type:Namespace2::*::BadStructName; # Disable initialization-order checks for globals:; global:bad_init_global=init; type:*BadInitClassSubstring*=init; src:bad/init/files/*=init. Suppressing memory leaks; ------------------------. Memory leak reports produced by :doc:`LeakSanitizer` (if it is run as a part; of AddressSanitizer) can be suppressed by a separate file passed as. .. code-block:: bash. LSAN_OPTIONS=suppressions=MyLSan.supp. which contains lines of the form `leak:<pattern>`. Memory leak will be; suppressed if pattern matches any function name, source file name, or; library name in the symbolized stack trace of the leak report. See; `full documentation; <https://github.com/google/sanitizers/wiki/AddressSanitizerLeakSanitizer#suppressions>`_; for more details. Code generation control; =======================. Instrumentation code outlining; ------------------------------. By default AddressSanitizer inlines the instrumentation code to improve the; run-time performance, which leads to increased binary size. Using the; (clang flag ``-fsanitize-address-outline-instrumentation` default: ``false``); flag forces all code instrumentation to be outlined, which reduces the size; of the generated code, but also reduces the run-time performance. Limitations; ===========. * AddressSanitizer uses more real memory than a native run. Exact overhead; depends on the allocations sizes. The smaller the allocations you make the; bigger the overhead is.; * AddressSanitizer uses more stack memory. We have seen up to 3x increase.; * On 64-bit platforms AddressSanitizer maps (but not reserves) 16+ Terabytes of; virtual address space. This means that tools like ``ulimit`` may not work as; usually expected.; * Static link",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:13456,Security,sanitiz,sanitizers,13456,"ame, source file name, or; library name in the symbolized stack trace of the leak report. See; `full documentation; <https://github.com/google/sanitizers/wiki/AddressSanitizerLeakSanitizer#suppressions>`_; for more details. Code generation control; =======================. Instrumentation code outlining; ------------------------------. By default AddressSanitizer inlines the instrumentation code to improve the; run-time performance, which leads to increased binary size. Using the; (clang flag ``-fsanitize-address-outline-instrumentation` default: ``false``); flag forces all code instrumentation to be outlined, which reduces the size; of the generated code, but also reduces the run-time performance. Limitations; ===========. * AddressSanitizer uses more real memory than a native run. Exact overhead; depends on the allocations sizes. The smaller the allocations you make the; bigger the overhead is.; * AddressSanitizer uses more stack memory. We have seen up to 3x increase.; * On 64-bit platforms AddressSanitizer maps (but not reserves) 16+ Terabytes of; virtual address space. This means that tools like ``ulimit`` may not work as; usually expected.; * Static linking of executables is not supported. Supported Platforms; ===================. AddressSanitizer is supported on:. * Linux i386/x86\_64 (tested on Ubuntu 12.04); * macOS 10.7 - 10.11 (i386/x86\_64); * iOS Simulator; * Android ARM; * NetBSD i386/x86\_64; * FreeBSD i386/x86\_64 (tested on FreeBSD 11-current); * Windows 8.1+ (i386/x86\_64). Ports to various other platforms are in progress. Current Status; ==============. AddressSanitizer is fully functional on supported platforms starting from LLVM; 3.1. The test suite is integrated into CMake build and can be run with ``make; check-asan`` command. The Windows port is functional and is used by Chrome and Firefox, but it is not; as well supported as the other ports. More Information; ================. `<https://github.com/google/sanitizers/wiki/AddressSanitizer>`_; ",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:1013,Testability,test,testing,1013,"================; AddressSanitizer; ================. .. contents::; :local:. Introduction; ============. AddressSanitizer is a fast memory error detector. It consists of a compiler; instrumentation module and a run-time library. The tool can detect the; following types of bugs:. * Out-of-bounds accesses to heap, stack and globals; * Use-after-free; * Use-after-return (clang flag ``-fsanitize-address-use-after-return=(never|runtime|always)`` default: ``runtime``); * Enable with: ``ASAN_OPTIONS=detect_stack_use_after_return=1`` (already enabled on Linux).; * Disable with: ``ASAN_OPTIONS=detect_stack_use_after_return=0``.; * Use-after-scope (clang flag ``-fsanitize-address-use-after-scope``); * Double-free, invalid free; * Memory leaks (experimental). Typical slowdown introduced by AddressSanitizer is **2x**. How to build; ============. Build LLVM/Clang with `CMake <https://llvm.org/docs/CMake.html>` and enable; the ``compiler-rt`` runtime. An example CMake configuration that will allow; for the use/testing of AddressSanitizer:. .. code-block:: console. $ cmake -DCMAKE_BUILD_TYPE=Release -DLLVM_ENABLE_PROJECTS=""clang"" -DLLVM_ENABLE_RUNTIMES=""compiler-rt"" <path to source>/llvm. Usage; =====. Simply compile and link your program with ``-fsanitize=address`` flag. The; AddressSanitizer run-time library should be linked to the final executable, so; make sure to use ``clang`` (not ``ld``) for the final link step. When linking; shared libraries, the AddressSanitizer run-time is not linked, so; ``-Wl,-z,defs`` may cause link errors (don't use it with AddressSanitizer). To; get a reasonable performance add ``-O1`` or higher. To get nicer stack traces; in error messages add ``-fno-omit-frame-pointer``. To get perfect stack traces; you may need to disable inlining (just use ``-O1``) and tail call elimination; (``-fno-optimize-sibling-calls``). .. code-block:: console. % cat example_UseAfterFree.cc; int main(int argc, char **argv) {; int *array = new int[100];; delete [] array;; r",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:2878,Testability,sandbox,sandboxed,2878,"% cat example_UseAfterFree.cc; int main(int argc, char **argv) {; int *array = new int[100];; delete [] array;; return array[argc]; // BOOM; }. # Compile and link; % clang++ -O1 -g -fsanitize=address -fno-omit-frame-pointer example_UseAfterFree.cc. or:. .. code-block:: console. # Compile; % clang++ -O1 -g -fsanitize=address -fno-omit-frame-pointer -c example_UseAfterFree.cc; # Link; % clang++ -g -fsanitize=address example_UseAfterFree.o. If a bug is detected, the program will print an error message to stderr and; exit with a non-zero exit code. AddressSanitizer exits on the first detected error.; This is by design:. * This approach allows AddressSanitizer to produce faster and smaller generated code; (both by ~5%).; * Fixing bugs becomes unavoidable. AddressSanitizer does not produce; false alarms. Once a memory corruption occurs, the program is in an inconsistent; state, which could lead to confusing results and potentially misleading; subsequent reports. If your process is sandboxed and you are running on OS X 10.10 or earlier, you; will need to set ``DYLD_INSERT_LIBRARIES`` environment variable and point it to; the ASan library that is packaged with the compiler used to build the; executable. (You can find the library by searching for dynamic libraries with; ``asan`` in their name.) If the environment variable is not set, the process will; try to re-exec. Also keep in mind that when moving the executable to another machine,; the ASan library will also need to be copied over. Symbolizing the Reports; =========================. To make AddressSanitizer symbolize its output; you need to set the ``ASAN_SYMBOLIZER_PATH`` environment variable to point to; the ``llvm-symbolizer`` binary (or make sure ``llvm-symbolizer`` is in your; ``$PATH``):. .. code-block:: console. % ASAN_SYMBOLIZER_PATH=/usr/local/bin/llvm-symbolizer ./a.out; ==9442== ERROR: AddressSanitizer heap-use-after-free on address 0x7f7ddab8c084 at pc 0x403c8c bp 0x7fff87fb82d0 sp 0x7fff87fb82c8; READ of siz",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:4526,Testability,sandbox,sandboxed,4526,"y (or make sure ``llvm-symbolizer`` is in your; ``$PATH``):. .. code-block:: console. % ASAN_SYMBOLIZER_PATH=/usr/local/bin/llvm-symbolizer ./a.out; ==9442== ERROR: AddressSanitizer heap-use-after-free on address 0x7f7ddab8c084 at pc 0x403c8c bp 0x7fff87fb82d0 sp 0x7fff87fb82c8; READ of size 4 at 0x7f7ddab8c084 thread T0; #0 0x403c8c in main example_UseAfterFree.cc:4; #1 0x7f7ddabcac4d in __libc_start_main ??:0; 0x7f7ddab8c084 is located 4 bytes inside of 400-byte region [0x7f7ddab8c080,0x7f7ddab8c210); freed by thread T0 here:; #0 0x404704 in operator delete[](void*) ??:0; #1 0x403c53 in main example_UseAfterFree.cc:4; #2 0x7f7ddabcac4d in __libc_start_main ??:0; previously allocated by thread T0 here:; #0 0x404544 in operator new[](unsigned long) ??:0; #1 0x403c43 in main example_UseAfterFree.cc:2; #2 0x7f7ddabcac4d in __libc_start_main ??:0; ==9442== ABORTING. If that does not work for you (e.g. your process is sandboxed), you can use a; separate script to symbolize the result offline (online symbolization can be; force disabled by setting ``ASAN_OPTIONS=symbolize=0``):. .. code-block:: console. % ASAN_OPTIONS=symbolize=0 ./a.out 2> log; % projects/compiler-rt/lib/asan/scripts/asan_symbolize.py / < log | c++filt; ==9442== ERROR: AddressSanitizer heap-use-after-free on address 0x7f7ddab8c084 at pc 0x403c8c bp 0x7fff87fb82d0 sp 0x7fff87fb82c8; READ of size 4 at 0x7f7ddab8c084 thread T0; #0 0x403c8c in main example_UseAfterFree.cc:4; #1 0x7f7ddabcac4d in __libc_start_main ??:0; ... Note that on macOS you may need to run ``dsymutil`` on your binary to have the; file\:line info in the AddressSanitizer reports. Additional Checks; =================. Initialization order checking; -----------------------------. AddressSanitizer can optionally detect dynamic initialization order problems,; when initialization of globals defined in one translation unit uses; globals defined in another translation unit. To enable this check at runtime,; you should set environment variable; `",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:4752,Testability,log,log,4752,"r heap-use-after-free on address 0x7f7ddab8c084 at pc 0x403c8c bp 0x7fff87fb82d0 sp 0x7fff87fb82c8; READ of size 4 at 0x7f7ddab8c084 thread T0; #0 0x403c8c in main example_UseAfterFree.cc:4; #1 0x7f7ddabcac4d in __libc_start_main ??:0; 0x7f7ddab8c084 is located 4 bytes inside of 400-byte region [0x7f7ddab8c080,0x7f7ddab8c210); freed by thread T0 here:; #0 0x404704 in operator delete[](void*) ??:0; #1 0x403c53 in main example_UseAfterFree.cc:4; #2 0x7f7ddabcac4d in __libc_start_main ??:0; previously allocated by thread T0 here:; #0 0x404544 in operator new[](unsigned long) ??:0; #1 0x403c43 in main example_UseAfterFree.cc:2; #2 0x7f7ddabcac4d in __libc_start_main ??:0; ==9442== ABORTING. If that does not work for you (e.g. your process is sandboxed), you can use a; separate script to symbolize the result offline (online symbolization can be; force disabled by setting ``ASAN_OPTIONS=symbolize=0``):. .. code-block:: console. % ASAN_OPTIONS=symbolize=0 ./a.out 2> log; % projects/compiler-rt/lib/asan/scripts/asan_symbolize.py / < log | c++filt; ==9442== ERROR: AddressSanitizer heap-use-after-free on address 0x7f7ddab8c084 at pc 0x403c8c bp 0x7fff87fb82d0 sp 0x7fff87fb82c8; READ of size 4 at 0x7f7ddab8c084 thread T0; #0 0x403c8c in main example_UseAfterFree.cc:4; #1 0x7f7ddabcac4d in __libc_start_main ??:0; ... Note that on macOS you may need to run ``dsymutil`` on your binary to have the; file\:line info in the AddressSanitizer reports. Additional Checks; =================. Initialization order checking; -----------------------------. AddressSanitizer can optionally detect dynamic initialization order problems,; when initialization of globals defined in one translation unit uses; globals defined in another translation unit. To enable this check at runtime,; you should set environment variable; ``ASAN_OPTIONS=check_initialization_order=1``. Note that this option is not supported on macOS. Stack Use After Return (UAR); ----------------------------. AddressSanitizer can opti",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:4819,Testability,log,log,4819,"8c in main example_UseAfterFree.cc:4; #1 0x7f7ddabcac4d in __libc_start_main ??:0; 0x7f7ddab8c084 is located 4 bytes inside of 400-byte region [0x7f7ddab8c080,0x7f7ddab8c210); freed by thread T0 here:; #0 0x404704 in operator delete[](void*) ??:0; #1 0x403c53 in main example_UseAfterFree.cc:4; #2 0x7f7ddabcac4d in __libc_start_main ??:0; previously allocated by thread T0 here:; #0 0x404544 in operator new[](unsigned long) ??:0; #1 0x403c43 in main example_UseAfterFree.cc:2; #2 0x7f7ddabcac4d in __libc_start_main ??:0; ==9442== ABORTING. If that does not work for you (e.g. your process is sandboxed), you can use a; separate script to symbolize the result offline (online symbolization can be; force disabled by setting ``ASAN_OPTIONS=symbolize=0``):. .. code-block:: console. % ASAN_OPTIONS=symbolize=0 ./a.out 2> log; % projects/compiler-rt/lib/asan/scripts/asan_symbolize.py / < log | c++filt; ==9442== ERROR: AddressSanitizer heap-use-after-free on address 0x7f7ddab8c084 at pc 0x403c8c bp 0x7fff87fb82d0 sp 0x7fff87fb82c8; READ of size 4 at 0x7f7ddab8c084 thread T0; #0 0x403c8c in main example_UseAfterFree.cc:4; #1 0x7f7ddabcac4d in __libc_start_main ??:0; ... Note that on macOS you may need to run ``dsymutil`` on your binary to have the; file\:line info in the AddressSanitizer reports. Additional Checks; =================. Initialization order checking; -----------------------------. AddressSanitizer can optionally detect dynamic initialization order problems,; when initialization of globals defined in one translation unit uses; globals defined in another translation unit. To enable this check at runtime,; you should set environment variable; ``ASAN_OPTIONS=check_initialization_order=1``. Note that this option is not supported on macOS. Stack Use After Return (UAR); ----------------------------. AddressSanitizer can optionally detect stack use after return problems.; This is available by default, or explicitly; (``-fsanitize-address-use-after-return=runtime``).; To disa",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:7555,Testability,test,testing,7555,"detect_stack_use_after_return=0``).; * ``always``: Enables detection of UAR errors in all cases. (reduces code; size, but not as much as ``never``). Memory leak detection; ---------------------. For more information on leak detector in AddressSanitizer, see; :doc:`LeakSanitizer`. The leak detection is turned on by default on Linux,; and can be enabled using ``ASAN_OPTIONS=detect_leaks=1`` on macOS;; however, it is not yet supported on other platforms. Issue Suppression; =================. AddressSanitizer is not expected to produce false positives. If you see one,; look again; most likely it is a true positive!. Suppressing Reports in External Libraries; -----------------------------------------; Runtime interposition allows AddressSanitizer to find bugs in code that is; not being recompiled. If you run into an issue in external libraries, we; recommend immediately reporting it to the library maintainer so that it; gets addressed. However, you can use the following suppression mechanism; to unblock yourself and continue on with the testing. This suppression; mechanism should only be used for suppressing issues in external code; it; does not work on code recompiled with AddressSanitizer. To suppress errors; in external libraries, set the ``ASAN_OPTIONS`` environment variable to point; to a suppression file. You can either specify the full path to the file or the; path of the file relative to the location of your executable. .. code-block:: bash. ASAN_OPTIONS=suppressions=MyASan.supp. Use the following format to specify the names of the functions or libraries; you want to suppress. You can see these in the error report. Remember that; the narrower the scope of the suppression, the more bugs you will be able to; catch. .. code-block:: bash. interceptor_via_fun:NameOfCFunctionToSuppress; interceptor_via_fun:-[ClassName objCMethodToSuppress:]; interceptor_via_lib:NameOfTheLibraryToSuppress. Conditional Compilation with ``__has_feature(address_sanitizer)``; --------------",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:12807,Testability,test,tested,12807,"ame, source file name, or; library name in the symbolized stack trace of the leak report. See; `full documentation; <https://github.com/google/sanitizers/wiki/AddressSanitizerLeakSanitizer#suppressions>`_; for more details. Code generation control; =======================. Instrumentation code outlining; ------------------------------. By default AddressSanitizer inlines the instrumentation code to improve the; run-time performance, which leads to increased binary size. Using the; (clang flag ``-fsanitize-address-outline-instrumentation` default: ``false``); flag forces all code instrumentation to be outlined, which reduces the size; of the generated code, but also reduces the run-time performance. Limitations; ===========. * AddressSanitizer uses more real memory than a native run. Exact overhead; depends on the allocations sizes. The smaller the allocations you make the; bigger the overhead is.; * AddressSanitizer uses more stack memory. We have seen up to 3x increase.; * On 64-bit platforms AddressSanitizer maps (but not reserves) 16+ Terabytes of; virtual address space. This means that tools like ``ulimit`` may not work as; usually expected.; * Static linking of executables is not supported. Supported Platforms; ===================. AddressSanitizer is supported on:. * Linux i386/x86\_64 (tested on Ubuntu 12.04); * macOS 10.7 - 10.11 (i386/x86\_64); * iOS Simulator; * Android ARM; * NetBSD i386/x86\_64; * FreeBSD i386/x86\_64 (tested on FreeBSD 11-current); * Windows 8.1+ (i386/x86\_64). Ports to various other platforms are in progress. Current Status; ==============. AddressSanitizer is fully functional on supported platforms starting from LLVM; 3.1. The test suite is integrated into CMake build and can be run with ``make; check-asan`` command. The Windows port is functional and is used by Chrome and Firefox, but it is not; as well supported as the other ports. More Information; ================. `<https://github.com/google/sanitizers/wiki/AddressSanitizer>`_; ",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:12948,Testability,test,tested,12948,"ame, source file name, or; library name in the symbolized stack trace of the leak report. See; `full documentation; <https://github.com/google/sanitizers/wiki/AddressSanitizerLeakSanitizer#suppressions>`_; for more details. Code generation control; =======================. Instrumentation code outlining; ------------------------------. By default AddressSanitizer inlines the instrumentation code to improve the; run-time performance, which leads to increased binary size. Using the; (clang flag ``-fsanitize-address-outline-instrumentation` default: ``false``); flag forces all code instrumentation to be outlined, which reduces the size; of the generated code, but also reduces the run-time performance. Limitations; ===========. * AddressSanitizer uses more real memory than a native run. Exact overhead; depends on the allocations sizes. The smaller the allocations you make the; bigger the overhead is.; * AddressSanitizer uses more stack memory. We have seen up to 3x increase.; * On 64-bit platforms AddressSanitizer maps (but not reserves) 16+ Terabytes of; virtual address space. This means that tools like ``ulimit`` may not work as; usually expected.; * Static linking of executables is not supported. Supported Platforms; ===================. AddressSanitizer is supported on:. * Linux i386/x86\_64 (tested on Ubuntu 12.04); * macOS 10.7 - 10.11 (i386/x86\_64); * iOS Simulator; * Android ARM; * NetBSD i386/x86\_64; * FreeBSD i386/x86\_64 (tested on FreeBSD 11-current); * Windows 8.1+ (i386/x86\_64). Ports to various other platforms are in progress. Current Status; ==============. AddressSanitizer is fully functional on supported platforms starting from LLVM; 3.1. The test suite is integrated into CMake build and can be run with ``make; check-asan`` command. The Windows port is functional and is used by Chrome and Firefox, but it is not; as well supported as the other ports. More Information; ================. `<https://github.com/google/sanitizers/wiki/AddressSanitizer>`_; ",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst:13181,Testability,test,test,13181,"ame, source file name, or; library name in the symbolized stack trace of the leak report. See; `full documentation; <https://github.com/google/sanitizers/wiki/AddressSanitizerLeakSanitizer#suppressions>`_; for more details. Code generation control; =======================. Instrumentation code outlining; ------------------------------. By default AddressSanitizer inlines the instrumentation code to improve the; run-time performance, which leads to increased binary size. Using the; (clang flag ``-fsanitize-address-outline-instrumentation` default: ``false``); flag forces all code instrumentation to be outlined, which reduces the size; of the generated code, but also reduces the run-time performance. Limitations; ===========. * AddressSanitizer uses more real memory than a native run. Exact overhead; depends on the allocations sizes. The smaller the allocations you make the; bigger the overhead is.; * AddressSanitizer uses more stack memory. We have seen up to 3x increase.; * On 64-bit platforms AddressSanitizer maps (but not reserves) 16+ Terabytes of; virtual address space. This means that tools like ``ulimit`` may not work as; usually expected.; * Static linking of executables is not supported. Supported Platforms; ===================. AddressSanitizer is supported on:. * Linux i386/x86\_64 (tested on Ubuntu 12.04); * macOS 10.7 - 10.11 (i386/x86\_64); * iOS Simulator; * Android ARM; * NetBSD i386/x86\_64; * FreeBSD i386/x86\_64 (tested on FreeBSD 11-current); * Windows 8.1+ (i386/x86\_64). Ports to various other platforms are in progress. Current Status; ==============. AddressSanitizer is fully functional on supported platforms starting from LLVM; 3.1. The test suite is integrated into CMake build and can be run with ``make; check-asan`` command. The Windows port is functional and is used by Chrome and Firefox, but it is not; as well supported as the other ports. More Information; ================. `<https://github.com/google/sanitizers/wiki/AddressSanitizer>`_; ",MatchSource.DOCS,interpreter/llvm-project/clang/docs/AddressSanitizer.rst,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/tree/v6-32-06/interpreter/llvm-project/clang/docs/AddressSanitizer.rst
