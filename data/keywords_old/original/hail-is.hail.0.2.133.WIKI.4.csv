id,quality_attribute,keyword,matched_word,match_idx,sentence,source,filename,author,repo,version,wiki,url
https://hail.is/docs/0.2/_modules/hail/experimental/datasets.html:3467,Availability,avail,available,3467,"e`, or :class:`.BlockMatrix`; """""". valid_regions = {'us', 'us-central1', 'europe-west1'}; if region not in valid_regions:; raise ValueError(; f'Specify valid region parameter,'; f' received: region={region!r}.\n'; f'Valid region values are {valid_regions}.'; ). valid_clouds = {'gcp', 'aws'}; if cloud not in valid_clouds:; raise ValueError(; f'Specify valid cloud parameter,'; f' received: cloud={cloud!r}.\n'; f'Valid cloud platforms are {valid_clouds}.'; ). datasets = get_datasets_metadata(); names = set([dataset for dataset in datasets]); if name not in names:; raise ValueError(f'{name} is not a dataset available in the' f' repository.'). versions = set(dataset['version'] for dataset in datasets[name]['versions']); if version not in versions:; raise ValueError(; f'Version {version!r} not available for dataset' f' {name!r}.\n' f'Available versions: {versions}.'; ). reference_genomes = set(dataset['reference_genome'] for dataset in datasets[name]['versions']); if reference_genome not in reference_genomes:; raise ValueError(; f'Reference genome build {reference_genome!r} not'; f' available for dataset {name!r}.\n'; f'Available reference genome builds:'; f' {reference_genomes}.'; ). clouds = set(k for dataset in datasets[name]['versions'] for k in dataset['url'].keys()); if cloud not in clouds:; raise ValueError(f'Cloud platform {cloud!r} not available for dataset {name}.\nAvailable platforms: {clouds}.'). regions = set(k for dataset in datasets[name]['versions'] for k in dataset['url'][cloud].keys()); if region not in regions:; raise ValueError(; f'Region {region!r} not available for dataset'; f' {name!r} on cloud platform {cloud!r}.\n'; f'Available regions: {regions}.'; ). path = [; dataset['url'][cloud][region]; for dataset in datasets[name]['versions']; if all([dataset['version'] == version, dataset['reference_genome'] == reference_genome]); ]; assert len(path) == 1; path = path[0]; if path.startswith('s3://'):; try:; dataset = _read_dataset(path); except hl.utils.ja",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/datasets.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/datasets.html
https://hail.is/docs/0.2/_modules/hail/experimental/datasets.html:3734,Availability,avail,available,3734,"={region!r}.\n'; f'Valid region values are {valid_regions}.'; ). valid_clouds = {'gcp', 'aws'}; if cloud not in valid_clouds:; raise ValueError(; f'Specify valid cloud parameter,'; f' received: cloud={cloud!r}.\n'; f'Valid cloud platforms are {valid_clouds}.'; ). datasets = get_datasets_metadata(); names = set([dataset for dataset in datasets]); if name not in names:; raise ValueError(f'{name} is not a dataset available in the' f' repository.'). versions = set(dataset['version'] for dataset in datasets[name]['versions']); if version not in versions:; raise ValueError(; f'Version {version!r} not available for dataset' f' {name!r}.\n' f'Available versions: {versions}.'; ). reference_genomes = set(dataset['reference_genome'] for dataset in datasets[name]['versions']); if reference_genome not in reference_genomes:; raise ValueError(; f'Reference genome build {reference_genome!r} not'; f' available for dataset {name!r}.\n'; f'Available reference genome builds:'; f' {reference_genomes}.'; ). clouds = set(k for dataset in datasets[name]['versions'] for k in dataset['url'].keys()); if cloud not in clouds:; raise ValueError(f'Cloud platform {cloud!r} not available for dataset {name}.\nAvailable platforms: {clouds}.'). regions = set(k for dataset in datasets[name]['versions'] for k in dataset['url'][cloud].keys()); if region not in regions:; raise ValueError(; f'Region {region!r} not available for dataset'; f' {name!r} on cloud platform {cloud!r}.\n'; f'Available regions: {regions}.'; ). path = [; dataset['url'][cloud][region]; for dataset in datasets[name]['versions']; if all([dataset['version'] == version, dataset['reference_genome'] == reference_genome]); ]; assert len(path) == 1; path = path[0]; if path.startswith('s3://'):; try:; dataset = _read_dataset(path); except hl.utils.java.FatalError:; dataset = _read_dataset(path.replace('s3://', 's3a://')); else:; dataset = _read_dataset(path); return dataset. © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/datasets.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/datasets.html
https://hail.is/docs/0.2/_modules/hail/experimental/datasets.html:3967,Availability,avail,available,3967,"={region!r}.\n'; f'Valid region values are {valid_regions}.'; ). valid_clouds = {'gcp', 'aws'}; if cloud not in valid_clouds:; raise ValueError(; f'Specify valid cloud parameter,'; f' received: cloud={cloud!r}.\n'; f'Valid cloud platforms are {valid_clouds}.'; ). datasets = get_datasets_metadata(); names = set([dataset for dataset in datasets]); if name not in names:; raise ValueError(f'{name} is not a dataset available in the' f' repository.'). versions = set(dataset['version'] for dataset in datasets[name]['versions']); if version not in versions:; raise ValueError(; f'Version {version!r} not available for dataset' f' {name!r}.\n' f'Available versions: {versions}.'; ). reference_genomes = set(dataset['reference_genome'] for dataset in datasets[name]['versions']); if reference_genome not in reference_genomes:; raise ValueError(; f'Reference genome build {reference_genome!r} not'; f' available for dataset {name!r}.\n'; f'Available reference genome builds:'; f' {reference_genomes}.'; ). clouds = set(k for dataset in datasets[name]['versions'] for k in dataset['url'].keys()); if cloud not in clouds:; raise ValueError(f'Cloud platform {cloud!r} not available for dataset {name}.\nAvailable platforms: {clouds}.'). regions = set(k for dataset in datasets[name]['versions'] for k in dataset['url'][cloud].keys()); if region not in regions:; raise ValueError(; f'Region {region!r} not available for dataset'; f' {name!r} on cloud platform {cloud!r}.\n'; f'Available regions: {regions}.'; ). path = [; dataset['url'][cloud][region]; for dataset in datasets[name]['versions']; if all([dataset['version'] == version, dataset['reference_genome'] == reference_genome]); ]; assert len(path) == 1; path = path[0]; if path.startswith('s3://'):; try:; dataset = _read_dataset(path); except hl.utils.java.FatalError:; dataset = _read_dataset(path.replace('s3://', 's3a://')); else:; dataset = _read_dataset(path); return dataset. © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/datasets.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/datasets.html
https://hail.is/docs/0.2/_modules/hail/experimental/datasets.html:4542,Deployability,update,updated,4542,"={region!r}.\n'; f'Valid region values are {valid_regions}.'; ). valid_clouds = {'gcp', 'aws'}; if cloud not in valid_clouds:; raise ValueError(; f'Specify valid cloud parameter,'; f' received: cloud={cloud!r}.\n'; f'Valid cloud platforms are {valid_clouds}.'; ). datasets = get_datasets_metadata(); names = set([dataset for dataset in datasets]); if name not in names:; raise ValueError(f'{name} is not a dataset available in the' f' repository.'). versions = set(dataset['version'] for dataset in datasets[name]['versions']); if version not in versions:; raise ValueError(; f'Version {version!r} not available for dataset' f' {name!r}.\n' f'Available versions: {versions}.'; ). reference_genomes = set(dataset['reference_genome'] for dataset in datasets[name]['versions']); if reference_genome not in reference_genomes:; raise ValueError(; f'Reference genome build {reference_genome!r} not'; f' available for dataset {name!r}.\n'; f'Available reference genome builds:'; f' {reference_genomes}.'; ). clouds = set(k for dataset in datasets[name]['versions'] for k in dataset['url'].keys()); if cloud not in clouds:; raise ValueError(f'Cloud platform {cloud!r} not available for dataset {name}.\nAvailable platforms: {clouds}.'). regions = set(k for dataset in datasets[name]['versions'] for k in dataset['url'][cloud].keys()); if region not in regions:; raise ValueError(; f'Region {region!r} not available for dataset'; f' {name!r} on cloud platform {cloud!r}.\n'; f'Available regions: {regions}.'; ). path = [; dataset['url'][cloud][region]; for dataset in datasets[name]['versions']; if all([dataset['version'] == version, dataset['reference_genome'] == reference_genome]); ]; assert len(path) == 1; path = path[0]; if path.startswith('s3://'):; try:; dataset = _read_dataset(path); except hl.utils.java.FatalError:; dataset = _read_dataset(path.replace('s3://', 's3a://')); else:; dataset = _read_dataset(path); return dataset. © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/datasets.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/datasets.html
https://hail.is/docs/0.2/_modules/hail/experimental/datasets.html:1007,Performance,load,load,1007,"hail.experimental.datasets. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.experimental.datasets. Source code for hail.experimental.datasets; from typing import Optional, Union. import hail as hl; from hail.matrixtable import MatrixTable; from hail.table import Table. from .datasets_metadata import get_datasets_metadata. def _read_dataset(path: str) -> Union[Table, MatrixTable, hl.linalg.BlockMatrix]:; if path.endswith('.ht'):; return hl.read_table(path); elif path.endswith('.mt'):; return hl.read_matrix_table(path); elif path.endswith('.bm'):; return hl.linalg.BlockMatrix.read(path); raise ValueError(f'Invalid path: {path}. Can only load datasets with .ht, .mt, or .bm extensions.'). [docs]def load_dataset(; name: str, version: Optional[str], reference_genome: Optional[str], region: str = 'us-central1', cloud: str = 'gcp'; ) -> Union[Table, MatrixTable, hl.linalg.BlockMatrix]:; """"""Load a genetic dataset from Hail's repository. Example; -------; >>> # Load the gnomAD ""HGDP + 1000 Genomes"" dense MatrixTable with GRCh38 coordinates.; >>> mt = hl.experimental.load_dataset(name='gnomad_hgdp_1kg_subset_dense',; ... version='3.1.2',; ... reference_genome='GRCh38',; ... region='us-central1',; ... cloud='gcp'). Parameters; ----------; name : :class:`str`; Name of the dataset to load.; version : :class:`str`, optional; Version of the named dataset to load (see available versions in; documentation). Possibly ``None`` for some datasets.; reference_genome : :class:`str`, optional; Reference genome build, ``'GRCh37'`` or ``'GRCh38'``. Possibly ``None``; for some datasets.; region : :class:`str`; Specify region for bucket, ``'us'``, `",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/datasets.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/datasets.html
https://hail.is/docs/0.2/_modules/hail/experimental/datasets.html:1655,Performance,load,load,1655,"ort Table. from .datasets_metadata import get_datasets_metadata. def _read_dataset(path: str) -> Union[Table, MatrixTable, hl.linalg.BlockMatrix]:; if path.endswith('.ht'):; return hl.read_table(path); elif path.endswith('.mt'):; return hl.read_matrix_table(path); elif path.endswith('.bm'):; return hl.linalg.BlockMatrix.read(path); raise ValueError(f'Invalid path: {path}. Can only load datasets with .ht, .mt, or .bm extensions.'). [docs]def load_dataset(; name: str, version: Optional[str], reference_genome: Optional[str], region: str = 'us-central1', cloud: str = 'gcp'; ) -> Union[Table, MatrixTable, hl.linalg.BlockMatrix]:; """"""Load a genetic dataset from Hail's repository. Example; -------; >>> # Load the gnomAD ""HGDP + 1000 Genomes"" dense MatrixTable with GRCh38 coordinates.; >>> mt = hl.experimental.load_dataset(name='gnomad_hgdp_1kg_subset_dense',; ... version='3.1.2',; ... reference_genome='GRCh38',; ... region='us-central1',; ... cloud='gcp'). Parameters; ----------; name : :class:`str`; Name of the dataset to load.; version : :class:`str`, optional; Version of the named dataset to load (see available versions in; documentation). Possibly ``None`` for some datasets.; reference_genome : :class:`str`, optional; Reference genome build, ``'GRCh37'`` or ``'GRCh38'``. Possibly ``None``; for some datasets.; region : :class:`str`; Specify region for bucket, ``'us'``, ``'us-central1'``, or ``'europe-west1'``, (default is; ``'us-central1'``).; cloud : :class:`str`; Specify if using Google Cloud Platform or Amazon Web Services,; ``'gcp'`` or ``'aws'`` (default is ``'gcp'``). Note; ----; The ``'aws'`` `cloud` platform is currently only available for the ``'us'``; `region`. Returns; -------; :class:`.Table`, :class:`.MatrixTable`, or :class:`.BlockMatrix`; """""". valid_regions = {'us', 'us-central1', 'europe-west1'}; if region not in valid_regions:; raise ValueError(; f'Specify valid region parameter,'; f' received: region={region!r}.\n'; f'Valid region values are {valid_reg",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/datasets.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/datasets.html
https://hail.is/docs/0.2/_modules/hail/experimental/datasets.html:1728,Performance,load,load,1728,"> Union[Table, MatrixTable, hl.linalg.BlockMatrix]:; if path.endswith('.ht'):; return hl.read_table(path); elif path.endswith('.mt'):; return hl.read_matrix_table(path); elif path.endswith('.bm'):; return hl.linalg.BlockMatrix.read(path); raise ValueError(f'Invalid path: {path}. Can only load datasets with .ht, .mt, or .bm extensions.'). [docs]def load_dataset(; name: str, version: Optional[str], reference_genome: Optional[str], region: str = 'us-central1', cloud: str = 'gcp'; ) -> Union[Table, MatrixTable, hl.linalg.BlockMatrix]:; """"""Load a genetic dataset from Hail's repository. Example; -------; >>> # Load the gnomAD ""HGDP + 1000 Genomes"" dense MatrixTable with GRCh38 coordinates.; >>> mt = hl.experimental.load_dataset(name='gnomad_hgdp_1kg_subset_dense',; ... version='3.1.2',; ... reference_genome='GRCh38',; ... region='us-central1',; ... cloud='gcp'). Parameters; ----------; name : :class:`str`; Name of the dataset to load.; version : :class:`str`, optional; Version of the named dataset to load (see available versions in; documentation). Possibly ``None`` for some datasets.; reference_genome : :class:`str`, optional; Reference genome build, ``'GRCh37'`` or ``'GRCh38'``. Possibly ``None``; for some datasets.; region : :class:`str`; Specify region for bucket, ``'us'``, ``'us-central1'``, or ``'europe-west1'``, (default is; ``'us-central1'``).; cloud : :class:`str`; Specify if using Google Cloud Platform or Amazon Web Services,; ``'gcp'`` or ``'aws'`` (default is ``'gcp'``). Note; ----; The ``'aws'`` `cloud` platform is currently only available for the ``'us'``; `region`. Returns; -------; :class:`.Table`, :class:`.MatrixTable`, or :class:`.BlockMatrix`; """""". valid_regions = {'us', 'us-central1', 'europe-west1'}; if region not in valid_regions:; raise ValueError(; f'Specify valid region parameter,'; f' received: region={region!r}.\n'; f'Valid region values are {valid_regions}.'; ). valid_clouds = {'gcp', 'aws'}; if cloud not in valid_clouds:; raise ValueError(; f'",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/datasets.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/datasets.html
https://hail.is/docs/0.2/_modules/hail/experimental/datasets.html:4250,Testability,assert,assert,4250,"={region!r}.\n'; f'Valid region values are {valid_regions}.'; ). valid_clouds = {'gcp', 'aws'}; if cloud not in valid_clouds:; raise ValueError(; f'Specify valid cloud parameter,'; f' received: cloud={cloud!r}.\n'; f'Valid cloud platforms are {valid_clouds}.'; ). datasets = get_datasets_metadata(); names = set([dataset for dataset in datasets]); if name not in names:; raise ValueError(f'{name} is not a dataset available in the' f' repository.'). versions = set(dataset['version'] for dataset in datasets[name]['versions']); if version not in versions:; raise ValueError(; f'Version {version!r} not available for dataset' f' {name!r}.\n' f'Available versions: {versions}.'; ). reference_genomes = set(dataset['reference_genome'] for dataset in datasets[name]['versions']); if reference_genome not in reference_genomes:; raise ValueError(; f'Reference genome build {reference_genome!r} not'; f' available for dataset {name!r}.\n'; f'Available reference genome builds:'; f' {reference_genomes}.'; ). clouds = set(k for dataset in datasets[name]['versions'] for k in dataset['url'].keys()); if cloud not in clouds:; raise ValueError(f'Cloud platform {cloud!r} not available for dataset {name}.\nAvailable platforms: {clouds}.'). regions = set(k for dataset in datasets[name]['versions'] for k in dataset['url'][cloud].keys()); if region not in regions:; raise ValueError(; f'Region {region!r} not available for dataset'; f' {name!r} on cloud platform {cloud!r}.\n'; f'Available regions: {regions}.'; ). path = [; dataset['url'][cloud][region]; for dataset in datasets[name]['versions']; if all([dataset['version'] == version, dataset['reference_genome'] == reference_genome]); ]; assert len(path) == 1; path = path[0]; if path.startswith('s3://'):; try:; dataset = _read_dataset(path); except hl.utils.java.FatalError:; dataset = _read_dataset(path.replace('s3://', 's3a://')); else:; dataset = _read_dataset(path); return dataset. © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/datasets.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/datasets.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:2040,Availability,avail,available,2040,"rsion` has two constructors: :func:`.from_json` and; :func:`.get_region`. Parameters; ----------; url : :obj:`dict` or :obj:`str`; Nested dictionary of URLs containing key: value pairs, like; ``cloud: {region: url}`` if using :func:`.from_json` constructor,; or a string with the URL from appropriate region if using the; :func:`.get_region` constructor.; version : :obj:`str`, optional; String of dataset version, if not ``None``.; reference_genome : :obj:`str`, optional; String of dataset reference genome, if not ``None``.; """""". @staticmethod; def from_json(doc: dict, cloud: str) -> Optional['DatasetVersion']:; """"""Create :class:`.DatasetVersion` object from dictionary. Parameters; ----------; doc : :obj:`dict`; Dictionary containing url and version keys.; Value for url is a :obj:`dict` containing key: value pairs, like; ``cloud: {region: url}``.; cloud : :obj:`str`; Cloud platform to access dataset, either ``'gcp'`` or ``'aws'``. Returns; -------; :class:`.DatasetVersion` if available on cloud platform, else ``None``.; """"""; assert 'url' in doc, doc; assert 'version' in doc, doc; assert 'reference_genome' in doc, doc; if cloud in doc['url']:; return DatasetVersion(doc['url'][cloud], doc['version'], doc['reference_genome']); else:; return None. @staticmethod; def get_region(name: str, versions: List['DatasetVersion'], region: str) -> List['DatasetVersion']:; """"""Get versions of a :class:`.Dataset` in the specified region, if they; exist. Parameters; ----------; name : :obj:`str`; Name of dataset.; versions : :class:`list` of :class:`.DatasetVersion`; List of DatasetVersion objects where the value for :attr:`.url`; is a :obj:`dict` containing key: value pairs, like ``region: url``.; region : :obj:`str`; Region from which to access data, available regions given in; :attr:`hail.experimental.DB._valid_regions`. Returns; -------; available_versions : :class:`list` of :class:`.DatasetVersion`; List of available versions of a class:`.Dataset` for region.; """"""; available_version",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:2813,Availability,avail,available,2813,"sion keys.; Value for url is a :obj:`dict` containing key: value pairs, like; ``cloud: {region: url}``.; cloud : :obj:`str`; Cloud platform to access dataset, either ``'gcp'`` or ``'aws'``. Returns; -------; :class:`.DatasetVersion` if available on cloud platform, else ``None``.; """"""; assert 'url' in doc, doc; assert 'version' in doc, doc; assert 'reference_genome' in doc, doc; if cloud in doc['url']:; return DatasetVersion(doc['url'][cloud], doc['version'], doc['reference_genome']); else:; return None. @staticmethod; def get_region(name: str, versions: List['DatasetVersion'], region: str) -> List['DatasetVersion']:; """"""Get versions of a :class:`.Dataset` in the specified region, if they; exist. Parameters; ----------; name : :obj:`str`; Name of dataset.; versions : :class:`list` of :class:`.DatasetVersion`; List of DatasetVersion objects where the value for :attr:`.url`; is a :obj:`dict` containing key: value pairs, like ``region: url``.; region : :obj:`str`; Region from which to access data, available regions given in; :attr:`hail.experimental.DB._valid_regions`. Returns; -------; available_versions : :class:`list` of :class:`.DatasetVersion`; List of available versions of a class:`.Dataset` for region.; """"""; available_versions = []; for version in versions:; if version.in_region(name, region):; version.url = version.url[region]; available_versions.append(version); return available_versions. def __init__(self, url: Union[dict, str], version: Optional[str], reference_genome: Optional[str]):; self.url = url; self.version = version; self.reference_genome = reference_genome. def in_region(self, name: str, region: str) -> bool:; """"""Check if a :class:`.DatasetVersion` object is accessible in the; desired region. Parameters; ----------; name : :obj:`str`; Name of dataset.; region : :obj:`str`; Region from which to access data, available regions given in; :func:`hail.experimental.DB._valid_regions`. Returns; -------; valid_region : :obj:`bool`; Whether or not the dataset e",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:2976,Availability,avail,available,2976," or ``'aws'``. Returns; -------; :class:`.DatasetVersion` if available on cloud platform, else ``None``.; """"""; assert 'url' in doc, doc; assert 'version' in doc, doc; assert 'reference_genome' in doc, doc; if cloud in doc['url']:; return DatasetVersion(doc['url'][cloud], doc['version'], doc['reference_genome']); else:; return None. @staticmethod; def get_region(name: str, versions: List['DatasetVersion'], region: str) -> List['DatasetVersion']:; """"""Get versions of a :class:`.Dataset` in the specified region, if they; exist. Parameters; ----------; name : :obj:`str`; Name of dataset.; versions : :class:`list` of :class:`.DatasetVersion`; List of DatasetVersion objects where the value for :attr:`.url`; is a :obj:`dict` containing key: value pairs, like ``region: url``.; region : :obj:`str`; Region from which to access data, available regions given in; :attr:`hail.experimental.DB._valid_regions`. Returns; -------; available_versions : :class:`list` of :class:`.DatasetVersion`; List of available versions of a class:`.Dataset` for region.; """"""; available_versions = []; for version in versions:; if version.in_region(name, region):; version.url = version.url[region]; available_versions.append(version); return available_versions. def __init__(self, url: Union[dict, str], version: Optional[str], reference_genome: Optional[str]):; self.url = url; self.version = version; self.reference_genome = reference_genome. def in_region(self, name: str, region: str) -> bool:; """"""Check if a :class:`.DatasetVersion` object is accessible in the; desired region. Parameters; ----------; name : :obj:`str`; Name of dataset.; region : :obj:`str`; Region from which to access data, available regions given in; :func:`hail.experimental.DB._valid_regions`. Returns; -------; valid_region : :obj:`bool`; Whether or not the dataset exists in the specified region.; """"""; current_version = self.version; available_regions = [k for k in self.url.keys()]; valid_region = region in available_regions; if not valid",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:3658,Availability,avail,available,3658,"jects where the value for :attr:`.url`; is a :obj:`dict` containing key: value pairs, like ``region: url``.; region : :obj:`str`; Region from which to access data, available regions given in; :attr:`hail.experimental.DB._valid_regions`. Returns; -------; available_versions : :class:`list` of :class:`.DatasetVersion`; List of available versions of a class:`.Dataset` for region.; """"""; available_versions = []; for version in versions:; if version.in_region(name, region):; version.url = version.url[region]; available_versions.append(version); return available_versions. def __init__(self, url: Union[dict, str], version: Optional[str], reference_genome: Optional[str]):; self.url = url; self.version = version; self.reference_genome = reference_genome. def in_region(self, name: str, region: str) -> bool:; """"""Check if a :class:`.DatasetVersion` object is accessible in the; desired region. Parameters; ----------; name : :obj:`str`; Name of dataset.; region : :obj:`str`; Region from which to access data, available regions given in; :func:`hail.experimental.DB._valid_regions`. Returns; -------; valid_region : :obj:`bool`; Whether or not the dataset exists in the specified region.; """"""; current_version = self.version; available_regions = [k for k in self.url.keys()]; valid_region = region in available_regions; if not valid_region:; message = (; f'\nName: {name}\n'; f'Version: {current_version}\n'; f'This dataset exists but is not yet available in the'; f' {region} region bucket.\n'; f'Dataset is currently available in the'; f' {"", "".join(available_regions)} region bucket(s).\n'; f'Reach out to the Hail team at https://discuss.hail.is/'; f' to request this dataset in your region.'; ); warnings.warn(message, UserWarning, stacklevel=1); return valid_region. def maybe_index(self, indexer_key_expr: StructExpression, all_matches: bool) -> Optional[StructExpression]:; """"""Find the prefix of the given indexer expression that can index the; :class:`.DatasetVersion`, if it exists. Parameter",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:4094,Availability,avail,available,4094,".; """"""; available_versions = []; for version in versions:; if version.in_region(name, region):; version.url = version.url[region]; available_versions.append(version); return available_versions. def __init__(self, url: Union[dict, str], version: Optional[str], reference_genome: Optional[str]):; self.url = url; self.version = version; self.reference_genome = reference_genome. def in_region(self, name: str, region: str) -> bool:; """"""Check if a :class:`.DatasetVersion` object is accessible in the; desired region. Parameters; ----------; name : :obj:`str`; Name of dataset.; region : :obj:`str`; Region from which to access data, available regions given in; :func:`hail.experimental.DB._valid_regions`. Returns; -------; valid_region : :obj:`bool`; Whether or not the dataset exists in the specified region.; """"""; current_version = self.version; available_regions = [k for k in self.url.keys()]; valid_region = region in available_regions; if not valid_region:; message = (; f'\nName: {name}\n'; f'Version: {current_version}\n'; f'This dataset exists but is not yet available in the'; f' {region} region bucket.\n'; f'Dataset is currently available in the'; f' {"", "".join(available_regions)} region bucket(s).\n'; f'Reach out to the Hail team at https://discuss.hail.is/'; f' to request this dataset in your region.'; ); warnings.warn(message, UserWarning, stacklevel=1); return valid_region. def maybe_index(self, indexer_key_expr: StructExpression, all_matches: bool) -> Optional[StructExpression]:; """"""Find the prefix of the given indexer expression that can index the; :class:`.DatasetVersion`, if it exists. Parameters; ----------; indexer_key_expr : :class:`StructExpression`; Row key struct from relational object to be annotated.; all_matches : :obj:`bool`; ``True`` if `indexer_key_expr` key is not unique, indicated in; :attr:`.Dataset.key_properties` for each dataset. If ``True``, value; of `indexer_key_expr` is array of all matches. If ``False``, there; will only be single value of ex",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:4167,Availability,avail,available,4167,"_versions.append(version); return available_versions. def __init__(self, url: Union[dict, str], version: Optional[str], reference_genome: Optional[str]):; self.url = url; self.version = version; self.reference_genome = reference_genome. def in_region(self, name: str, region: str) -> bool:; """"""Check if a :class:`.DatasetVersion` object is accessible in the; desired region. Parameters; ----------; name : :obj:`str`; Name of dataset.; region : :obj:`str`; Region from which to access data, available regions given in; :func:`hail.experimental.DB._valid_regions`. Returns; -------; valid_region : :obj:`bool`; Whether or not the dataset exists in the specified region.; """"""; current_version = self.version; available_regions = [k for k in self.url.keys()]; valid_region = region in available_regions; if not valid_region:; message = (; f'\nName: {name}\n'; f'Version: {current_version}\n'; f'This dataset exists but is not yet available in the'; f' {region} region bucket.\n'; f'Dataset is currently available in the'; f' {"", "".join(available_regions)} region bucket(s).\n'; f'Reach out to the Hail team at https://discuss.hail.is/'; f' to request this dataset in your region.'; ); warnings.warn(message, UserWarning, stacklevel=1); return valid_region. def maybe_index(self, indexer_key_expr: StructExpression, all_matches: bool) -> Optional[StructExpression]:; """"""Find the prefix of the given indexer expression that can index the; :class:`.DatasetVersion`, if it exists. Parameters; ----------; indexer_key_expr : :class:`StructExpression`; Row key struct from relational object to be annotated.; all_matches : :obj:`bool`; ``True`` if `indexer_key_expr` key is not unique, indicated in; :attr:`.Dataset.key_properties` for each dataset. If ``True``, value; of `indexer_key_expr` is array of all matches. If ``False``, there; will only be single value of expression. Returns; -------; :class:`StructExpression`, optional; Struct of compatible indexed values, if they exist.; """"""; return hl.read_ta",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:6261,Availability,avail,available,6261,"s). class Dataset:; """"""Dataset object constructed from name, description, url, key_properties,; and versions specified in JSON configuration file or a provided :obj:`dict`; mapping dataset names to configurations. Parameters; ----------; name : :obj:`str`; Name of dataset.; description : :obj:`str`; Brief description of dataset.; url : :obj:`str`; Cloud URL to access dataset.; key_properties : :class:`set` of :obj:`str`; Set containing key property strings, if present. Valid properties; include ``'gene'`` and ``'unique'``.; versions : :class:`list` of :class:`.DatasetVersion`; List of :class:`.DatasetVersion` objects.; """""". @staticmethod; def from_name_and_json(name: str, doc: dict, region: str, cloud: str) -> Optional['Dataset']:; """"""Create :class:`.Dataset` object from dictionary. Parameters; ----------; name : :obj:`str`; Name of dataset.; doc : :obj:`dict`; Dictionary containing dataset description, url, key_properties, and; versions.; region : :obj:`str`; Region from which to access data, available regions given in; :func:`hail.experimental.DB._valid_regions`.; cloud : :obj:`str`; Cloud platform to access dataset, either ``'gcp'`` or ``'aws'``. Returns; -------; :class:`Dataset`, optional; If versions exist for region returns a :class:`.Dataset` object,; else ``None``.; """"""; assert 'annotation_db' in doc, doc; assert 'key_properties' in doc['annotation_db'], doc['annotation_db']; assert 'description' in doc, doc; assert 'url' in doc, doc; assert 'versions' in doc, doc; key_properties = set(x for x in doc['annotation_db']['key_properties'] if x is not None); versions = [; DatasetVersion.from_json(x, cloud); for x in doc['versions']; if DatasetVersion.from_json(x, cloud) is not None; ]; versions_in_region = DatasetVersion.get_region(name, versions, region); if versions_in_region:; return Dataset(name, doc['description'], doc['url'], key_properties, versions_in_region). def __init__(self, name: str, description: str, url: str, key_properties: Set[str], versions: Li",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:8699,Availability,avail,available,8699,"ression) -> StructExpression:; """"""Get index from compatible version of annotation dataset. Checks for compatible indexed values from each :class:`.DatasetVersion`; in :attr:`.Dataset.versions`, where `key_expr` is the row key struct; from the dataset to be annotated. Parameters; ----------; key_expr : :class:`.StructExpression`; Row key struct from relational object to be annotated. Returns; -------; :class:`.StructExpression`; Struct of compatible indexed values.; """"""; all_matches = 'unique' not in self.key_properties; compatible_indexed_values = [; (version.maybe_index(key_expr, all_matches), version.version); for version in self.versions; if version.maybe_index(key_expr, all_matches) is not None; ]; if len(compatible_indexed_values) == 0:; versions = [f'{(v.version, v.reference_genome)}' for v in self.versions]; raise ValueError(; f'Could not find compatible version of {self.name} for user'; f' dataset with key {key_expr.dtype}.\n'; f'This annotation dataset is available for the following'; f' versions and reference genome builds: {"", "".join(versions)}.'; ); else:; indexed_values = sorted(compatible_indexed_values, key=lambda x: x[1])[-1]. if len(compatible_indexed_values) > 1:; info(; f'index_compatible_version: More than one compatible version'; f' exists for annotation dataset: {self.name}. Rows have been'; f' annotated with version {indexed_values[1]}.'; ); return indexed_values[0]. [docs]class DB:; """"""An annotation database instance. This class facilitates the annotation of genetic datasets with variant annotations. It accepts; either an HTTP(S) URL to an Annotation DB configuration or a Python :obj:`dict` describing an; Annotation DB configuration. User must specify the `region` (aws: ``'us'``, gcp:; ``'us-central1'`` or ``'europe-west1'``) in which the cluster is running if connecting to the; default Hail Annotation DB. User must also specify the `cloud` platform that they are using; (``'gcp'`` or ``'aws'``). Parameters; ----------; region : :obj:`str`; Reg",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:10269,Availability,avail,available,10269," annotations. It accepts; either an HTTP(S) URL to an Annotation DB configuration or a Python :obj:`dict` describing an; Annotation DB configuration. User must specify the `region` (aws: ``'us'``, gcp:; ``'us-central1'`` or ``'europe-west1'``) in which the cluster is running if connecting to the; default Hail Annotation DB. User must also specify the `cloud` platform that they are using; (``'gcp'`` or ``'aws'``). Parameters; ----------; region : :obj:`str`; Region cluster is running in, either ``'us'``, ``'us-central1'``, or ``'europe-west1'``; (default is ``'us-central1'``).; cloud : :obj:`str`; Cloud platform, either ``'gcp'`` or ``'aws'`` (default is ``'gcp'``).; url : :obj:`str`, optional; Optional URL to annotation DB configuration, if using custom configuration; (default is ``None``).; config : :obj:`str`, optional; Optional :obj:`dict` describing an annotation DB configuration, if using; custom configuration (default is ``None``). Note; ----; The ``'aws'`` `cloud` platform is currently only available for the ``'us'``; `region`. Examples; --------; Create an annotation database connecting to the default Hail Annotation DB:. >>> db = hl.experimental.DB(region='us-central1', cloud='gcp'); """""". _valid_key_properties: ClassVar = {'gene', 'unique'}; _valid_regions: ClassVar = {'us', 'us-central1', 'europe-west1'}; _valid_clouds: ClassVar = {'gcp', 'aws'}; _valid_combinations: ClassVar = {('us', 'aws'), ('us-central1', 'gcp'), ('europe-west1', 'gcp')}. def __init__(; self,; *,; region: str = 'us-central1',; cloud: str = 'gcp',; url: Optional[str] = None,; config: Optional[dict] = None,; ):; if region not in DB._valid_regions:; raise ValueError(; f'Specify valid region parameter,'; f' received: region={region!r}.\n'; f'Valid regions are {DB._valid_regions}.'; ); if cloud not in DB._valid_clouds:; raise ValueError(; f'Specify valid cloud parameter,'; f' received: cloud={cloud!r}.\n'; f'Valid cloud platforms are {DB._valid_clouds}.'; ); if (region, cloud) not in DB._val",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:11325,Availability,avail,available,11325,"es; --------; Create an annotation database connecting to the default Hail Annotation DB:. >>> db = hl.experimental.DB(region='us-central1', cloud='gcp'); """""". _valid_key_properties: ClassVar = {'gene', 'unique'}; _valid_regions: ClassVar = {'us', 'us-central1', 'europe-west1'}; _valid_clouds: ClassVar = {'gcp', 'aws'}; _valid_combinations: ClassVar = {('us', 'aws'), ('us-central1', 'gcp'), ('europe-west1', 'gcp')}. def __init__(; self,; *,; region: str = 'us-central1',; cloud: str = 'gcp',; url: Optional[str] = None,; config: Optional[dict] = None,; ):; if region not in DB._valid_regions:; raise ValueError(; f'Specify valid region parameter,'; f' received: region={region!r}.\n'; f'Valid regions are {DB._valid_regions}.'; ); if cloud not in DB._valid_clouds:; raise ValueError(; f'Specify valid cloud parameter,'; f' received: cloud={cloud!r}.\n'; f'Valid cloud platforms are {DB._valid_clouds}.'; ); if (region, cloud) not in DB._valid_combinations:; raise ValueError(; f'The {region!r} region is not available for'; f' the {cloud!r} cloud platform. '; f'Valid region, cloud combinations are'; f' {DB._valid_combinations}.'; ); if config is not None and url is not None:; raise ValueError(; f'Only specify one of the parameters url and' f' config, received: url={url} and config={config}'; ); if config is None:; if url is None:; config = get_datasets_metadata(); else:; session = external_requests_client_session(); response = retry_response_returning_functions(session.get, url); config = response.json(); assert isinstance(config, dict); elif not isinstance(config, dict):; raise ValueError(f'expected a dict mapping dataset names to ' f'configurations, but found {config}'); config = {k: v for k, v in config.items() if 'annotation_db' in v}; self.region = region; self.cloud = cloud; self.url = url; self.config = config; self.__by_name = {; k: Dataset.from_name_and_json(k, v, region, cloud); for k, v in config.items(); if Dataset.from_name_and_json(k, v, region, cloud) is not None",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:12393,Availability,avail,available,12393,"rm. '; f'Valid region, cloud combinations are'; f' {DB._valid_combinations}.'; ); if config is not None and url is not None:; raise ValueError(; f'Only specify one of the parameters url and' f' config, received: url={url} and config={config}'; ); if config is None:; if url is None:; config = get_datasets_metadata(); else:; session = external_requests_client_session(); response = retry_response_returning_functions(session.get, url); config = response.json(); assert isinstance(config, dict); elif not isinstance(config, dict):; raise ValueError(f'expected a dict mapping dataset names to ' f'configurations, but found {config}'); config = {k: v for k, v in config.items() if 'annotation_db' in v}; self.region = region; self.cloud = cloud; self.url = url; self.config = config; self.__by_name = {; k: Dataset.from_name_and_json(k, v, region, cloud); for k, v in config.items(); if Dataset.from_name_and_json(k, v, region, cloud) is not None; }. @property; def available_datasets(self) -> List[str]:; """"""List of names of available annotation datasets. Returns; -------; :obj:`list`; List of available annotation datasets.; """"""; return sorted(self.__by_name.keys()). @staticmethod; def _row_lens(rel: Union[Table, MatrixTable]) -> Union[TableRows, MatrixRows]:; """"""Get row lens from relational object. Parameters; ----------; rel : :class:`Table` or :class:`MatrixTable`. Returns; -------; :class:`TableRows` or :class:`MatrixRows`; """"""; if isinstance(rel, MatrixTable):; return MatrixRows(rel); elif isinstance(rel, Table):; return TableRows(rel); else:; raise ValueError('annotation database can only annotate Hail' ' MatrixTable or Table'). def _dataset_by_name(self, name: str) -> Dataset:; """"""Retrieve :class:`Dataset` object by name. Parameters; ----------; name : :obj:`str`; Name of dataset. Returns; -------; :class:`Dataset`; """"""; if name not in self.__by_name:; raise ValueError(; f'{name} not found in annotation database,'; f' you may list all known dataset names'; f' with available_da",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:12463,Availability,avail,available,12463,"fig is not None and url is not None:; raise ValueError(; f'Only specify one of the parameters url and' f' config, received: url={url} and config={config}'; ); if config is None:; if url is None:; config = get_datasets_metadata(); else:; session = external_requests_client_session(); response = retry_response_returning_functions(session.get, url); config = response.json(); assert isinstance(config, dict); elif not isinstance(config, dict):; raise ValueError(f'expected a dict mapping dataset names to ' f'configurations, but found {config}'); config = {k: v for k, v in config.items() if 'annotation_db' in v}; self.region = region; self.cloud = cloud; self.url = url; self.config = config; self.__by_name = {; k: Dataset.from_name_and_json(k, v, region, cloud); for k, v in config.items(); if Dataset.from_name_and_json(k, v, region, cloud) is not None; }. @property; def available_datasets(self) -> List[str]:; """"""List of names of available annotation datasets. Returns; -------; :obj:`list`; List of available annotation datasets.; """"""; return sorted(self.__by_name.keys()). @staticmethod; def _row_lens(rel: Union[Table, MatrixTable]) -> Union[TableRows, MatrixRows]:; """"""Get row lens from relational object. Parameters; ----------; rel : :class:`Table` or :class:`MatrixTable`. Returns; -------; :class:`TableRows` or :class:`MatrixRows`; """"""; if isinstance(rel, MatrixTable):; return MatrixRows(rel); elif isinstance(rel, Table):; return TableRows(rel); else:; raise ValueError('annotation database can only annotate Hail' ' MatrixTable or Table'). def _dataset_by_name(self, name: str) -> Dataset:; """"""Retrieve :class:`Dataset` object by name. Parameters; ----------; name : :obj:`str`; Name of dataset. Returns; -------; :class:`Dataset`; """"""; if name not in self.__by_name:; raise ValueError(; f'{name} not found in annotation database,'; f' you may list all known dataset names'; f' with available_datasets'; ); return self.__by_name[name]. def _annotate_gene_name(self, rel: Union[TableR",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:14021,Availability,avail,available,14021,"rixTable or Table'). def _dataset_by_name(self, name: str) -> Dataset:; """"""Retrieve :class:`Dataset` object by name. Parameters; ----------; name : :obj:`str`; Name of dataset. Returns; -------; :class:`Dataset`; """"""; if name not in self.__by_name:; raise ValueError(; f'{name} not found in annotation database,'; f' you may list all known dataset names'; f' with available_datasets'; ); return self.__by_name[name]. def _annotate_gene_name(self, rel: Union[TableRows, MatrixRows]) -> Tuple[str, Union[TableRows, MatrixRows]]:; """"""Annotate row lens with gene name if annotation dataset is gene; keyed. Parameters; ----------; rel : :class:`TableRows` or :class:`MatrixRows`; Row lens of relational object to be annotated. Returns; -------; :class:`tuple`; """"""; gene_field = Env.get_uid(); gencode = self.__by_name['gencode'].index_compatible_version(rel.key); return gene_field, rel.annotate(**{gene_field: gencode.gene_name}). def _check_availability(self, names: Iterable) -> None:; """"""Check if datasets given in `names` are available in the annotation; database instance. Parameters; ----------; names : :obj:`iterable`; Names to check.; """"""; unavailable = [x for x in names if x not in self.__by_name.keys()]; if unavailable:; raise ValueError(f'datasets: {unavailable} not available' f' in the {self.region} region.'). [docs] @typecheck_method(rel=oneof(table_type, matrix_table_type), names=str); def annotate_rows_db(self, rel: Union[Table, MatrixTable], *names: str) -> Union[Table, MatrixTable]:; """"""Add annotations from datasets specified by name to a relational; object. List datasets with :attr:`~.available_datasets`. An interactive query builder is available in the; `Hail Annotation Database documentation; </docs/0.2/annotation_database_ui.html>`_. Examples; --------; Annotate a :class:`.MatrixTable` with ``gnomad_lof_metrics``:. >>> db = hl.experimental.DB(region='us-central1', cloud='gcp'); >>> mt = db.annotate_rows_db(mt, 'gnomad_lof_metrics') # doctest: +SKIP. Annotate a :clas",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:14272,Availability,avail,available,14272," ValueError(; f'{name} not found in annotation database,'; f' you may list all known dataset names'; f' with available_datasets'; ); return self.__by_name[name]. def _annotate_gene_name(self, rel: Union[TableRows, MatrixRows]) -> Tuple[str, Union[TableRows, MatrixRows]]:; """"""Annotate row lens with gene name if annotation dataset is gene; keyed. Parameters; ----------; rel : :class:`TableRows` or :class:`MatrixRows`; Row lens of relational object to be annotated. Returns; -------; :class:`tuple`; """"""; gene_field = Env.get_uid(); gencode = self.__by_name['gencode'].index_compatible_version(rel.key); return gene_field, rel.annotate(**{gene_field: gencode.gene_name}). def _check_availability(self, names: Iterable) -> None:; """"""Check if datasets given in `names` are available in the annotation; database instance. Parameters; ----------; names : :obj:`iterable`; Names to check.; """"""; unavailable = [x for x in names if x not in self.__by_name.keys()]; if unavailable:; raise ValueError(f'datasets: {unavailable} not available' f' in the {self.region} region.'). [docs] @typecheck_method(rel=oneof(table_type, matrix_table_type), names=str); def annotate_rows_db(self, rel: Union[Table, MatrixTable], *names: str) -> Union[Table, MatrixTable]:; """"""Add annotations from datasets specified by name to a relational; object. List datasets with :attr:`~.available_datasets`. An interactive query builder is available in the; `Hail Annotation Database documentation; </docs/0.2/annotation_database_ui.html>`_. Examples; --------; Annotate a :class:`.MatrixTable` with ``gnomad_lof_metrics``:. >>> db = hl.experimental.DB(region='us-central1', cloud='gcp'); >>> mt = db.annotate_rows_db(mt, 'gnomad_lof_metrics') # doctest: +SKIP. Annotate a :class:`.Table` with ``clinvar_gene_summary``, ``CADD``,; and ``DANN``:. >>> db = hl.experimental.DB(region='us-central1', cloud='gcp'); >>> ht = db.annotate_rows_db(ht, 'clinvar_gene_summary', 'CADD', 'DANN') # doctest: +SKIP. Notes; -----. If a dataset is g",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:14657,Availability,avail,available,14657,"ens of relational object to be annotated. Returns; -------; :class:`tuple`; """"""; gene_field = Env.get_uid(); gencode = self.__by_name['gencode'].index_compatible_version(rel.key); return gene_field, rel.annotate(**{gene_field: gencode.gene_name}). def _check_availability(self, names: Iterable) -> None:; """"""Check if datasets given in `names` are available in the annotation; database instance. Parameters; ----------; names : :obj:`iterable`; Names to check.; """"""; unavailable = [x for x in names if x not in self.__by_name.keys()]; if unavailable:; raise ValueError(f'datasets: {unavailable} not available' f' in the {self.region} region.'). [docs] @typecheck_method(rel=oneof(table_type, matrix_table_type), names=str); def annotate_rows_db(self, rel: Union[Table, MatrixTable], *names: str) -> Union[Table, MatrixTable]:; """"""Add annotations from datasets specified by name to a relational; object. List datasets with :attr:`~.available_datasets`. An interactive query builder is available in the; `Hail Annotation Database documentation; </docs/0.2/annotation_database_ui.html>`_. Examples; --------; Annotate a :class:`.MatrixTable` with ``gnomad_lof_metrics``:. >>> db = hl.experimental.DB(region='us-central1', cloud='gcp'); >>> mt = db.annotate_rows_db(mt, 'gnomad_lof_metrics') # doctest: +SKIP. Annotate a :class:`.Table` with ``clinvar_gene_summary``, ``CADD``,; and ``DANN``:. >>> db = hl.experimental.DB(region='us-central1', cloud='gcp'); >>> ht = db.annotate_rows_db(ht, 'clinvar_gene_summary', 'CADD', 'DANN') # doctest: +SKIP. Notes; -----. If a dataset is gene-keyed, the annotation will be a dictionary mapping; from gene name to the annotation value. There will be one entry for each; gene overlapping the given locus. If a dataset does not have unique rows for each key (consider the; ``gencode`` genes, which may overlap; and ``clinvar_variant_summary``,; which contains many overlapping multiple nucleotide variants), then the; result will be an array of annotation values, one ",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:5379,Deployability,configurat,configuration,5379,"rn(message, UserWarning, stacklevel=1); return valid_region. def maybe_index(self, indexer_key_expr: StructExpression, all_matches: bool) -> Optional[StructExpression]:; """"""Find the prefix of the given indexer expression that can index the; :class:`.DatasetVersion`, if it exists. Parameters; ----------; indexer_key_expr : :class:`StructExpression`; Row key struct from relational object to be annotated.; all_matches : :obj:`bool`; ``True`` if `indexer_key_expr` key is not unique, indicated in; :attr:`.Dataset.key_properties` for each dataset. If ``True``, value; of `indexer_key_expr` is array of all matches. If ``False``, there; will only be single value of expression. Returns; -------; :class:`StructExpression`, optional; Struct of compatible indexed values, if they exist.; """"""; return hl.read_table(self.url)._maybe_flexindex_table_by_expr(indexer_key_expr, all_matches=all_matches). class Dataset:; """"""Dataset object constructed from name, description, url, key_properties,; and versions specified in JSON configuration file or a provided :obj:`dict`; mapping dataset names to configurations. Parameters; ----------; name : :obj:`str`; Name of dataset.; description : :obj:`str`; Brief description of dataset.; url : :obj:`str`; Cloud URL to access dataset.; key_properties : :class:`set` of :obj:`str`; Set containing key property strings, if present. Valid properties; include ``'gene'`` and ``'unique'``.; versions : :class:`list` of :class:`.DatasetVersion`; List of :class:`.DatasetVersion` objects.; """""". @staticmethod; def from_name_and_json(name: str, doc: dict, region: str, cloud: str) -> Optional['Dataset']:; """"""Create :class:`.Dataset` object from dictionary. Parameters; ----------; name : :obj:`str`; Name of dataset.; doc : :obj:`dict`; Dictionary containing dataset description, url, key_properties, and; versions.; region : :obj:`str`; Region from which to access data, available regions given in; :func:`hail.experimental.DB._valid_regions`.; cloud : :obj:`str`; Cloud",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:5450,Deployability,configurat,configurations,5450,"rn(message, UserWarning, stacklevel=1); return valid_region. def maybe_index(self, indexer_key_expr: StructExpression, all_matches: bool) -> Optional[StructExpression]:; """"""Find the prefix of the given indexer expression that can index the; :class:`.DatasetVersion`, if it exists. Parameters; ----------; indexer_key_expr : :class:`StructExpression`; Row key struct from relational object to be annotated.; all_matches : :obj:`bool`; ``True`` if `indexer_key_expr` key is not unique, indicated in; :attr:`.Dataset.key_properties` for each dataset. If ``True``, value; of `indexer_key_expr` is array of all matches. If ``False``, there; will only be single value of expression. Returns; -------; :class:`StructExpression`, optional; Struct of compatible indexed values, if they exist.; """"""; return hl.read_table(self.url)._maybe_flexindex_table_by_expr(indexer_key_expr, all_matches=all_matches). class Dataset:; """"""Dataset object constructed from name, description, url, key_properties,; and versions specified in JSON configuration file or a provided :obj:`dict`; mapping dataset names to configurations. Parameters; ----------; name : :obj:`str`; Name of dataset.; description : :obj:`str`; Brief description of dataset.; url : :obj:`str`; Cloud URL to access dataset.; key_properties : :class:`set` of :obj:`str`; Set containing key property strings, if present. Valid properties; include ``'gene'`` and ``'unique'``.; versions : :class:`list` of :class:`.DatasetVersion`; List of :class:`.DatasetVersion` objects.; """""". @staticmethod; def from_name_and_json(name: str, doc: dict, region: str, cloud: str) -> Optional['Dataset']:; """"""Create :class:`.Dataset` object from dictionary. Parameters; ----------; name : :obj:`str`; Name of dataset.; doc : :obj:`dict`; Dictionary containing dataset description, url, key_properties, and; versions.; region : :obj:`str`; Region from which to access data, available regions given in; :func:`hail.experimental.DB._valid_regions`.; cloud : :obj:`str`; Cloud",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:9324,Deployability,configurat,configuration,9324,"); for version in self.versions; if version.maybe_index(key_expr, all_matches) is not None; ]; if len(compatible_indexed_values) == 0:; versions = [f'{(v.version, v.reference_genome)}' for v in self.versions]; raise ValueError(; f'Could not find compatible version of {self.name} for user'; f' dataset with key {key_expr.dtype}.\n'; f'This annotation dataset is available for the following'; f' versions and reference genome builds: {"", "".join(versions)}.'; ); else:; indexed_values = sorted(compatible_indexed_values, key=lambda x: x[1])[-1]. if len(compatible_indexed_values) > 1:; info(; f'index_compatible_version: More than one compatible version'; f' exists for annotation dataset: {self.name}. Rows have been'; f' annotated with version {indexed_values[1]}.'; ); return indexed_values[0]. [docs]class DB:; """"""An annotation database instance. This class facilitates the annotation of genetic datasets with variant annotations. It accepts; either an HTTP(S) URL to an Annotation DB configuration or a Python :obj:`dict` describing an; Annotation DB configuration. User must specify the `region` (aws: ``'us'``, gcp:; ``'us-central1'`` or ``'europe-west1'``) in which the cluster is running if connecting to the; default Hail Annotation DB. User must also specify the `cloud` platform that they are using; (``'gcp'`` or ``'aws'``). Parameters; ----------; region : :obj:`str`; Region cluster is running in, either ``'us'``, ``'us-central1'``, or ``'europe-west1'``; (default is ``'us-central1'``).; cloud : :obj:`str`; Cloud platform, either ``'gcp'`` or ``'aws'`` (default is ``'gcp'``).; url : :obj:`str`, optional; Optional URL to annotation DB configuration, if using custom configuration; (default is ``None``).; config : :obj:`str`, optional; Optional :obj:`dict` describing an annotation DB configuration, if using; custom configuration (default is ``None``). Note; ----; The ``'aws'`` `cloud` platform is currently only available for the ``'us'``; `region`. Examples; --------; Create an ",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:9391,Deployability,configurat,configuration,9391,"); for version in self.versions; if version.maybe_index(key_expr, all_matches) is not None; ]; if len(compatible_indexed_values) == 0:; versions = [f'{(v.version, v.reference_genome)}' for v in self.versions]; raise ValueError(; f'Could not find compatible version of {self.name} for user'; f' dataset with key {key_expr.dtype}.\n'; f'This annotation dataset is available for the following'; f' versions and reference genome builds: {"", "".join(versions)}.'; ); else:; indexed_values = sorted(compatible_indexed_values, key=lambda x: x[1])[-1]. if len(compatible_indexed_values) > 1:; info(; f'index_compatible_version: More than one compatible version'; f' exists for annotation dataset: {self.name}. Rows have been'; f' annotated with version {indexed_values[1]}.'; ); return indexed_values[0]. [docs]class DB:; """"""An annotation database instance. This class facilitates the annotation of genetic datasets with variant annotations. It accepts; either an HTTP(S) URL to an Annotation DB configuration or a Python :obj:`dict` describing an; Annotation DB configuration. User must specify the `region` (aws: ``'us'``, gcp:; ``'us-central1'`` or ``'europe-west1'``) in which the cluster is running if connecting to the; default Hail Annotation DB. User must also specify the `cloud` platform that they are using; (``'gcp'`` or ``'aws'``). Parameters; ----------; region : :obj:`str`; Region cluster is running in, either ``'us'``, ``'us-central1'``, or ``'europe-west1'``; (default is ``'us-central1'``).; cloud : :obj:`str`; Cloud platform, either ``'gcp'`` or ``'aws'`` (default is ``'gcp'``).; url : :obj:`str`, optional; Optional URL to annotation DB configuration, if using custom configuration; (default is ``None``).; config : :obj:`str`, optional; Optional :obj:`dict` describing an annotation DB configuration, if using; custom configuration (default is ``None``). Note; ----; The ``'aws'`` `cloud` platform is currently only available for the ``'us'``; `region`. Examples; --------; Create an ",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:9989,Deployability,configurat,configuration,9989," exists for annotation dataset: {self.name}. Rows have been'; f' annotated with version {indexed_values[1]}.'; ); return indexed_values[0]. [docs]class DB:; """"""An annotation database instance. This class facilitates the annotation of genetic datasets with variant annotations. It accepts; either an HTTP(S) URL to an Annotation DB configuration or a Python :obj:`dict` describing an; Annotation DB configuration. User must specify the `region` (aws: ``'us'``, gcp:; ``'us-central1'`` or ``'europe-west1'``) in which the cluster is running if connecting to the; default Hail Annotation DB. User must also specify the `cloud` platform that they are using; (``'gcp'`` or ``'aws'``). Parameters; ----------; region : :obj:`str`; Region cluster is running in, either ``'us'``, ``'us-central1'``, or ``'europe-west1'``; (default is ``'us-central1'``).; cloud : :obj:`str`; Cloud platform, either ``'gcp'`` or ``'aws'`` (default is ``'gcp'``).; url : :obj:`str`, optional; Optional URL to annotation DB configuration, if using custom configuration; (default is ``None``).; config : :obj:`str`, optional; Optional :obj:`dict` describing an annotation DB configuration, if using; custom configuration (default is ``None``). Note; ----; The ``'aws'`` `cloud` platform is currently only available for the ``'us'``; `region`. Examples; --------; Create an annotation database connecting to the default Hail Annotation DB:. >>> db = hl.experimental.DB(region='us-central1', cloud='gcp'); """""". _valid_key_properties: ClassVar = {'gene', 'unique'}; _valid_regions: ClassVar = {'us', 'us-central1', 'europe-west1'}; _valid_clouds: ClassVar = {'gcp', 'aws'}; _valid_combinations: ClassVar = {('us', 'aws'), ('us-central1', 'gcp'), ('europe-west1', 'gcp')}. def __init__(; self,; *,; region: str = 'us-central1',; cloud: str = 'gcp',; url: Optional[str] = None,; config: Optional[dict] = None,; ):; if region not in DB._valid_regions:; raise ValueError(; f'Specify valid region parameter,'; f' received: region={region",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:10020,Deployability,configurat,configuration,10020," exists for annotation dataset: {self.name}. Rows have been'; f' annotated with version {indexed_values[1]}.'; ); return indexed_values[0]. [docs]class DB:; """"""An annotation database instance. This class facilitates the annotation of genetic datasets with variant annotations. It accepts; either an HTTP(S) URL to an Annotation DB configuration or a Python :obj:`dict` describing an; Annotation DB configuration. User must specify the `region` (aws: ``'us'``, gcp:; ``'us-central1'`` or ``'europe-west1'``) in which the cluster is running if connecting to the; default Hail Annotation DB. User must also specify the `cloud` platform that they are using; (``'gcp'`` or ``'aws'``). Parameters; ----------; region : :obj:`str`; Region cluster is running in, either ``'us'``, ``'us-central1'``, or ``'europe-west1'``; (default is ``'us-central1'``).; cloud : :obj:`str`; Cloud platform, either ``'gcp'`` or ``'aws'`` (default is ``'gcp'``).; url : :obj:`str`, optional; Optional URL to annotation DB configuration, if using custom configuration; (default is ``None``).; config : :obj:`str`, optional; Optional :obj:`dict` describing an annotation DB configuration, if using; custom configuration (default is ``None``). Note; ----; The ``'aws'`` `cloud` platform is currently only available for the ``'us'``; `region`. Examples; --------; Create an annotation database connecting to the default Hail Annotation DB:. >>> db = hl.experimental.DB(region='us-central1', cloud='gcp'); """""". _valid_key_properties: ClassVar = {'gene', 'unique'}; _valid_regions: ClassVar = {'us', 'us-central1', 'europe-west1'}; _valid_clouds: ClassVar = {'gcp', 'aws'}; _valid_combinations: ClassVar = {('us', 'aws'), ('us-central1', 'gcp'), ('europe-west1', 'gcp')}. def __init__(; self,; *,; region: str = 'us-central1',; cloud: str = 'gcp',; url: Optional[str] = None,; config: Optional[dict] = None,; ):; if region not in DB._valid_regions:; raise ValueError(; f'Specify valid region parameter,'; f' received: region={region",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:10139,Deployability,configurat,configuration,10139," [docs]class DB:; """"""An annotation database instance. This class facilitates the annotation of genetic datasets with variant annotations. It accepts; either an HTTP(S) URL to an Annotation DB configuration or a Python :obj:`dict` describing an; Annotation DB configuration. User must specify the `region` (aws: ``'us'``, gcp:; ``'us-central1'`` or ``'europe-west1'``) in which the cluster is running if connecting to the; default Hail Annotation DB. User must also specify the `cloud` platform that they are using; (``'gcp'`` or ``'aws'``). Parameters; ----------; region : :obj:`str`; Region cluster is running in, either ``'us'``, ``'us-central1'``, or ``'europe-west1'``; (default is ``'us-central1'``).; cloud : :obj:`str`; Cloud platform, either ``'gcp'`` or ``'aws'`` (default is ``'gcp'``).; url : :obj:`str`, optional; Optional URL to annotation DB configuration, if using custom configuration; (default is ``None``).; config : :obj:`str`, optional; Optional :obj:`dict` describing an annotation DB configuration, if using; custom configuration (default is ``None``). Note; ----; The ``'aws'`` `cloud` platform is currently only available for the ``'us'``; `region`. Examples; --------; Create an annotation database connecting to the default Hail Annotation DB:. >>> db = hl.experimental.DB(region='us-central1', cloud='gcp'); """""". _valid_key_properties: ClassVar = {'gene', 'unique'}; _valid_regions: ClassVar = {'us', 'us-central1', 'europe-west1'}; _valid_clouds: ClassVar = {'gcp', 'aws'}; _valid_combinations: ClassVar = {('us', 'aws'), ('us-central1', 'gcp'), ('europe-west1', 'gcp')}. def __init__(; self,; *,; region: str = 'us-central1',; cloud: str = 'gcp',; url: Optional[str] = None,; config: Optional[dict] = None,; ):; if region not in DB._valid_regions:; raise ValueError(; f'Specify valid region parameter,'; f' received: region={region!r}.\n'; f'Valid regions are {DB._valid_regions}.'; ); if cloud not in DB._valid_clouds:; raise ValueError(; f'Specify valid cloud paramete",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:10171,Deployability,configurat,configuration,10171," [docs]class DB:; """"""An annotation database instance. This class facilitates the annotation of genetic datasets with variant annotations. It accepts; either an HTTP(S) URL to an Annotation DB configuration or a Python :obj:`dict` describing an; Annotation DB configuration. User must specify the `region` (aws: ``'us'``, gcp:; ``'us-central1'`` or ``'europe-west1'``) in which the cluster is running if connecting to the; default Hail Annotation DB. User must also specify the `cloud` platform that they are using; (``'gcp'`` or ``'aws'``). Parameters; ----------; region : :obj:`str`; Region cluster is running in, either ``'us'``, ``'us-central1'``, or ``'europe-west1'``; (default is ``'us-central1'``).; cloud : :obj:`str`; Cloud platform, either ``'gcp'`` or ``'aws'`` (default is ``'gcp'``).; url : :obj:`str`, optional; Optional URL to annotation DB configuration, if using custom configuration; (default is ``None``).; config : :obj:`str`, optional; Optional :obj:`dict` describing an annotation DB configuration, if using; custom configuration (default is ``None``). Note; ----; The ``'aws'`` `cloud` platform is currently only available for the ``'us'``; `region`. Examples; --------; Create an annotation database connecting to the default Hail Annotation DB:. >>> db = hl.experimental.DB(region='us-central1', cloud='gcp'); """""". _valid_key_properties: ClassVar = {'gene', 'unique'}; _valid_regions: ClassVar = {'us', 'us-central1', 'europe-west1'}; _valid_clouds: ClassVar = {'gcp', 'aws'}; _valid_combinations: ClassVar = {('us', 'aws'), ('us-central1', 'gcp'), ('europe-west1', 'gcp')}. def __init__(; self,; *,; region: str = 'us-central1',; cloud: str = 'gcp',; url: Optional[str] = None,; config: Optional[dict] = None,; ):; if region not in DB._valid_regions:; raise ValueError(; f'Specify valid region parameter,'; f' received: region={region!r}.\n'; f'Valid regions are {DB._valid_regions}.'; ); if cloud not in DB._valid_clouds:; raise ValueError(; f'Specify valid cloud paramete",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:11965,Deployability,configurat,configurations,11965,"f'Specify valid region parameter,'; f' received: region={region!r}.\n'; f'Valid regions are {DB._valid_regions}.'; ); if cloud not in DB._valid_clouds:; raise ValueError(; f'Specify valid cloud parameter,'; f' received: cloud={cloud!r}.\n'; f'Valid cloud platforms are {DB._valid_clouds}.'; ); if (region, cloud) not in DB._valid_combinations:; raise ValueError(; f'The {region!r} region is not available for'; f' the {cloud!r} cloud platform. '; f'Valid region, cloud combinations are'; f' {DB._valid_combinations}.'; ); if config is not None and url is not None:; raise ValueError(; f'Only specify one of the parameters url and' f' config, received: url={url} and config={config}'; ); if config is None:; if url is None:; config = get_datasets_metadata(); else:; session = external_requests_client_session(); response = retry_response_returning_functions(session.get, url); config = response.json(); assert isinstance(config, dict); elif not isinstance(config, dict):; raise ValueError(f'expected a dict mapping dataset names to ' f'configurations, but found {config}'); config = {k: v for k, v in config.items() if 'annotation_db' in v}; self.region = region; self.cloud = cloud; self.url = url; self.config = config; self.__by_name = {; k: Dataset.from_name_and_json(k, v, region, cloud); for k, v in config.items(); if Dataset.from_name_and_json(k, v, region, cloud) is not None; }. @property; def available_datasets(self) -> List[str]:; """"""List of names of available annotation datasets. Returns; -------; :obj:`list`; List of available annotation datasets.; """"""; return sorted(self.__by_name.keys()). @staticmethod; def _row_lens(rel: Union[Table, MatrixTable]) -> Union[TableRows, MatrixRows]:; """"""Get row lens from relational object. Parameters; ----------; rel : :class:`Table` or :class:`MatrixTable`. Returns; -------; :class:`TableRows` or :class:`MatrixRows`; """"""; if isinstance(rel, MatrixTable):; return MatrixRows(rel); elif isinstance(rel, Table):; return TableRows(rel); else:; rais",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:17249,Deployability,update,updated,17249,"ll be a dictionary mapping; from gene name to the annotation value. There will be one entry for each; gene overlapping the given locus. If a dataset does not have unique rows for each key (consider the; ``gencode`` genes, which may overlap; and ``clinvar_variant_summary``,; which contains many overlapping multiple nucleotide variants), then the; result will be an array of annotation values, one for each row. Parameters; ----------; rel : :class:`.MatrixTable` or :class:`.Table`; The relational object to which to add annotations.; names : varargs of :class:`str`; The names of the datasets with which to annotate `rel`. Returns; -------; :class:`.MatrixTable` or :class:`.Table`; The relational object `rel`, with the annotations from `names`; added.; """"""; rel = self._row_lens(rel); if len(set(names)) != len(names):; raise ValueError(f'cannot annotate same dataset twice,' f' please remove duplicates from: {names}'); self._check_availability(names); datasets = [self._dataset_by_name(name) for name in names]; if any(dataset.is_gene_keyed for dataset in datasets):; gene_field, rel = self._annotate_gene_name(rel); else:; gene_field = None; for dataset in datasets:; if dataset.is_gene_keyed:; genes = rel.select(gene_field).explode(gene_field); genes = genes.annotate(**{dataset.name: dataset.index_compatible_version(genes[gene_field])}); genes = genes.group_by(*genes.key).aggregate(**{; dataset.name: hl.dict(; hl.agg.filter(; hl.is_defined(genes[dataset.name]),; hl.agg.collect((genes[gene_field], genes[dataset.name])),; ); ); }); rel = rel.annotate(**{dataset.name: genes.index(rel.key)[dataset.name]}); else:; indexed_value = dataset.index_compatible_version(rel.key); if isinstance(indexed_value.dtype, hl.tstruct) and len(indexed_value.dtype) == 0:; indexed_value = hl.is_defined(indexed_value); rel = rel.annotate(**{dataset.name: indexed_value}); if gene_field:; rel = rel.drop(gene_field); return rel.unlens(). © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:3990,Integrability,message,message,3990,".; """"""; available_versions = []; for version in versions:; if version.in_region(name, region):; version.url = version.url[region]; available_versions.append(version); return available_versions. def __init__(self, url: Union[dict, str], version: Optional[str], reference_genome: Optional[str]):; self.url = url; self.version = version; self.reference_genome = reference_genome. def in_region(self, name: str, region: str) -> bool:; """"""Check if a :class:`.DatasetVersion` object is accessible in the; desired region. Parameters; ----------; name : :obj:`str`; Name of dataset.; region : :obj:`str`; Region from which to access data, available regions given in; :func:`hail.experimental.DB._valid_regions`. Returns; -------; valid_region : :obj:`bool`; Whether or not the dataset exists in the specified region.; """"""; current_version = self.version; available_regions = [k for k in self.url.keys()]; valid_region = region in available_regions; if not valid_region:; message = (; f'\nName: {name}\n'; f'Version: {current_version}\n'; f'This dataset exists but is not yet available in the'; f' {region} region bucket.\n'; f'Dataset is currently available in the'; f' {"", "".join(available_regions)} region bucket(s).\n'; f'Reach out to the Hail team at https://discuss.hail.is/'; f' to request this dataset in your region.'; ); warnings.warn(message, UserWarning, stacklevel=1); return valid_region. def maybe_index(self, indexer_key_expr: StructExpression, all_matches: bool) -> Optional[StructExpression]:; """"""Find the prefix of the given indexer expression that can index the; :class:`.DatasetVersion`, if it exists. Parameters; ----------; indexer_key_expr : :class:`StructExpression`; Row key struct from relational object to be annotated.; all_matches : :obj:`bool`; ``True`` if `indexer_key_expr` key is not unique, indicated in; :attr:`.Dataset.key_properties` for each dataset. If ``True``, value; of `indexer_key_expr` is array of all matches. If ``False``, there; will only be single value of ex",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:4363,Integrability,message,message,4363,"erence_genome. def in_region(self, name: str, region: str) -> bool:; """"""Check if a :class:`.DatasetVersion` object is accessible in the; desired region. Parameters; ----------; name : :obj:`str`; Name of dataset.; region : :obj:`str`; Region from which to access data, available regions given in; :func:`hail.experimental.DB._valid_regions`. Returns; -------; valid_region : :obj:`bool`; Whether or not the dataset exists in the specified region.; """"""; current_version = self.version; available_regions = [k for k in self.url.keys()]; valid_region = region in available_regions; if not valid_region:; message = (; f'\nName: {name}\n'; f'Version: {current_version}\n'; f'This dataset exists but is not yet available in the'; f' {region} region bucket.\n'; f'Dataset is currently available in the'; f' {"", "".join(available_regions)} region bucket(s).\n'; f'Reach out to the Hail team at https://discuss.hail.is/'; f' to request this dataset in your region.'; ); warnings.warn(message, UserWarning, stacklevel=1); return valid_region. def maybe_index(self, indexer_key_expr: StructExpression, all_matches: bool) -> Optional[StructExpression]:; """"""Find the prefix of the given indexer expression that can index the; :class:`.DatasetVersion`, if it exists. Parameters; ----------; indexer_key_expr : :class:`StructExpression`; Row key struct from relational object to be annotated.; all_matches : :obj:`bool`; ``True`` if `indexer_key_expr` key is not unique, indicated in; :attr:`.Dataset.key_properties` for each dataset. If ``True``, value; of `indexer_key_expr` is array of all matches. If ``False``, there; will only be single value of expression. Returns; -------; :class:`StructExpression`, optional; Struct of compatible indexed values, if they exist.; """"""; return hl.read_table(self.url)._maybe_flexindex_table_by_expr(indexer_key_expr, all_matches=all_matches). class Dataset:; """"""Dataset object constructed from name, description, url, key_properties,; and versions specified in JSON configurat",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:5379,Modifiability,config,configuration,5379,"rn(message, UserWarning, stacklevel=1); return valid_region. def maybe_index(self, indexer_key_expr: StructExpression, all_matches: bool) -> Optional[StructExpression]:; """"""Find the prefix of the given indexer expression that can index the; :class:`.DatasetVersion`, if it exists. Parameters; ----------; indexer_key_expr : :class:`StructExpression`; Row key struct from relational object to be annotated.; all_matches : :obj:`bool`; ``True`` if `indexer_key_expr` key is not unique, indicated in; :attr:`.Dataset.key_properties` for each dataset. If ``True``, value; of `indexer_key_expr` is array of all matches. If ``False``, there; will only be single value of expression. Returns; -------; :class:`StructExpression`, optional; Struct of compatible indexed values, if they exist.; """"""; return hl.read_table(self.url)._maybe_flexindex_table_by_expr(indexer_key_expr, all_matches=all_matches). class Dataset:; """"""Dataset object constructed from name, description, url, key_properties,; and versions specified in JSON configuration file or a provided :obj:`dict`; mapping dataset names to configurations. Parameters; ----------; name : :obj:`str`; Name of dataset.; description : :obj:`str`; Brief description of dataset.; url : :obj:`str`; Cloud URL to access dataset.; key_properties : :class:`set` of :obj:`str`; Set containing key property strings, if present. Valid properties; include ``'gene'`` and ``'unique'``.; versions : :class:`list` of :class:`.DatasetVersion`; List of :class:`.DatasetVersion` objects.; """""". @staticmethod; def from_name_and_json(name: str, doc: dict, region: str, cloud: str) -> Optional['Dataset']:; """"""Create :class:`.Dataset` object from dictionary. Parameters; ----------; name : :obj:`str`; Name of dataset.; doc : :obj:`dict`; Dictionary containing dataset description, url, key_properties, and; versions.; region : :obj:`str`; Region from which to access data, available regions given in; :func:`hail.experimental.DB._valid_regions`.; cloud : :obj:`str`; Cloud",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:5450,Modifiability,config,configurations,5450,"rn(message, UserWarning, stacklevel=1); return valid_region. def maybe_index(self, indexer_key_expr: StructExpression, all_matches: bool) -> Optional[StructExpression]:; """"""Find the prefix of the given indexer expression that can index the; :class:`.DatasetVersion`, if it exists. Parameters; ----------; indexer_key_expr : :class:`StructExpression`; Row key struct from relational object to be annotated.; all_matches : :obj:`bool`; ``True`` if `indexer_key_expr` key is not unique, indicated in; :attr:`.Dataset.key_properties` for each dataset. If ``True``, value; of `indexer_key_expr` is array of all matches. If ``False``, there; will only be single value of expression. Returns; -------; :class:`StructExpression`, optional; Struct of compatible indexed values, if they exist.; """"""; return hl.read_table(self.url)._maybe_flexindex_table_by_expr(indexer_key_expr, all_matches=all_matches). class Dataset:; """"""Dataset object constructed from name, description, url, key_properties,; and versions specified in JSON configuration file or a provided :obj:`dict`; mapping dataset names to configurations. Parameters; ----------; name : :obj:`str`; Name of dataset.; description : :obj:`str`; Brief description of dataset.; url : :obj:`str`; Cloud URL to access dataset.; key_properties : :class:`set` of :obj:`str`; Set containing key property strings, if present. Valid properties; include ``'gene'`` and ``'unique'``.; versions : :class:`list` of :class:`.DatasetVersion`; List of :class:`.DatasetVersion` objects.; """""". @staticmethod; def from_name_and_json(name: str, doc: dict, region: str, cloud: str) -> Optional['Dataset']:; """"""Create :class:`.Dataset` object from dictionary. Parameters; ----------; name : :obj:`str`; Name of dataset.; doc : :obj:`dict`; Dictionary containing dataset description, url, key_properties, and; versions.; region : :obj:`str`; Region from which to access data, available regions given in; :func:`hail.experimental.DB._valid_regions`.; cloud : :obj:`str`; Cloud",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:9324,Modifiability,config,configuration,9324,"); for version in self.versions; if version.maybe_index(key_expr, all_matches) is not None; ]; if len(compatible_indexed_values) == 0:; versions = [f'{(v.version, v.reference_genome)}' for v in self.versions]; raise ValueError(; f'Could not find compatible version of {self.name} for user'; f' dataset with key {key_expr.dtype}.\n'; f'This annotation dataset is available for the following'; f' versions and reference genome builds: {"", "".join(versions)}.'; ); else:; indexed_values = sorted(compatible_indexed_values, key=lambda x: x[1])[-1]. if len(compatible_indexed_values) > 1:; info(; f'index_compatible_version: More than one compatible version'; f' exists for annotation dataset: {self.name}. Rows have been'; f' annotated with version {indexed_values[1]}.'; ); return indexed_values[0]. [docs]class DB:; """"""An annotation database instance. This class facilitates the annotation of genetic datasets with variant annotations. It accepts; either an HTTP(S) URL to an Annotation DB configuration or a Python :obj:`dict` describing an; Annotation DB configuration. User must specify the `region` (aws: ``'us'``, gcp:; ``'us-central1'`` or ``'europe-west1'``) in which the cluster is running if connecting to the; default Hail Annotation DB. User must also specify the `cloud` platform that they are using; (``'gcp'`` or ``'aws'``). Parameters; ----------; region : :obj:`str`; Region cluster is running in, either ``'us'``, ``'us-central1'``, or ``'europe-west1'``; (default is ``'us-central1'``).; cloud : :obj:`str`; Cloud platform, either ``'gcp'`` or ``'aws'`` (default is ``'gcp'``).; url : :obj:`str`, optional; Optional URL to annotation DB configuration, if using custom configuration; (default is ``None``).; config : :obj:`str`, optional; Optional :obj:`dict` describing an annotation DB configuration, if using; custom configuration (default is ``None``). Note; ----; The ``'aws'`` `cloud` platform is currently only available for the ``'us'``; `region`. Examples; --------; Create an ",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:9391,Modifiability,config,configuration,9391,"); for version in self.versions; if version.maybe_index(key_expr, all_matches) is not None; ]; if len(compatible_indexed_values) == 0:; versions = [f'{(v.version, v.reference_genome)}' for v in self.versions]; raise ValueError(; f'Could not find compatible version of {self.name} for user'; f' dataset with key {key_expr.dtype}.\n'; f'This annotation dataset is available for the following'; f' versions and reference genome builds: {"", "".join(versions)}.'; ); else:; indexed_values = sorted(compatible_indexed_values, key=lambda x: x[1])[-1]. if len(compatible_indexed_values) > 1:; info(; f'index_compatible_version: More than one compatible version'; f' exists for annotation dataset: {self.name}. Rows have been'; f' annotated with version {indexed_values[1]}.'; ); return indexed_values[0]. [docs]class DB:; """"""An annotation database instance. This class facilitates the annotation of genetic datasets with variant annotations. It accepts; either an HTTP(S) URL to an Annotation DB configuration or a Python :obj:`dict` describing an; Annotation DB configuration. User must specify the `region` (aws: ``'us'``, gcp:; ``'us-central1'`` or ``'europe-west1'``) in which the cluster is running if connecting to the; default Hail Annotation DB. User must also specify the `cloud` platform that they are using; (``'gcp'`` or ``'aws'``). Parameters; ----------; region : :obj:`str`; Region cluster is running in, either ``'us'``, ``'us-central1'``, or ``'europe-west1'``; (default is ``'us-central1'``).; cloud : :obj:`str`; Cloud platform, either ``'gcp'`` or ``'aws'`` (default is ``'gcp'``).; url : :obj:`str`, optional; Optional URL to annotation DB configuration, if using custom configuration; (default is ``None``).; config : :obj:`str`, optional; Optional :obj:`dict` describing an annotation DB configuration, if using; custom configuration (default is ``None``). Note; ----; The ``'aws'`` `cloud` platform is currently only available for the ``'us'``; `region`. Examples; --------; Create an ",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:9989,Modifiability,config,configuration,9989," exists for annotation dataset: {self.name}. Rows have been'; f' annotated with version {indexed_values[1]}.'; ); return indexed_values[0]. [docs]class DB:; """"""An annotation database instance. This class facilitates the annotation of genetic datasets with variant annotations. It accepts; either an HTTP(S) URL to an Annotation DB configuration or a Python :obj:`dict` describing an; Annotation DB configuration. User must specify the `region` (aws: ``'us'``, gcp:; ``'us-central1'`` or ``'europe-west1'``) in which the cluster is running if connecting to the; default Hail Annotation DB. User must also specify the `cloud` platform that they are using; (``'gcp'`` or ``'aws'``). Parameters; ----------; region : :obj:`str`; Region cluster is running in, either ``'us'``, ``'us-central1'``, or ``'europe-west1'``; (default is ``'us-central1'``).; cloud : :obj:`str`; Cloud platform, either ``'gcp'`` or ``'aws'`` (default is ``'gcp'``).; url : :obj:`str`, optional; Optional URL to annotation DB configuration, if using custom configuration; (default is ``None``).; config : :obj:`str`, optional; Optional :obj:`dict` describing an annotation DB configuration, if using; custom configuration (default is ``None``). Note; ----; The ``'aws'`` `cloud` platform is currently only available for the ``'us'``; `region`. Examples; --------; Create an annotation database connecting to the default Hail Annotation DB:. >>> db = hl.experimental.DB(region='us-central1', cloud='gcp'); """""". _valid_key_properties: ClassVar = {'gene', 'unique'}; _valid_regions: ClassVar = {'us', 'us-central1', 'europe-west1'}; _valid_clouds: ClassVar = {'gcp', 'aws'}; _valid_combinations: ClassVar = {('us', 'aws'), ('us-central1', 'gcp'), ('europe-west1', 'gcp')}. def __init__(; self,; *,; region: str = 'us-central1',; cloud: str = 'gcp',; url: Optional[str] = None,; config: Optional[dict] = None,; ):; if region not in DB._valid_regions:; raise ValueError(; f'Specify valid region parameter,'; f' received: region={region",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:10020,Modifiability,config,configuration,10020," exists for annotation dataset: {self.name}. Rows have been'; f' annotated with version {indexed_values[1]}.'; ); return indexed_values[0]. [docs]class DB:; """"""An annotation database instance. This class facilitates the annotation of genetic datasets with variant annotations. It accepts; either an HTTP(S) URL to an Annotation DB configuration or a Python :obj:`dict` describing an; Annotation DB configuration. User must specify the `region` (aws: ``'us'``, gcp:; ``'us-central1'`` or ``'europe-west1'``) in which the cluster is running if connecting to the; default Hail Annotation DB. User must also specify the `cloud` platform that they are using; (``'gcp'`` or ``'aws'``). Parameters; ----------; region : :obj:`str`; Region cluster is running in, either ``'us'``, ``'us-central1'``, or ``'europe-west1'``; (default is ``'us-central1'``).; cloud : :obj:`str`; Cloud platform, either ``'gcp'`` or ``'aws'`` (default is ``'gcp'``).; url : :obj:`str`, optional; Optional URL to annotation DB configuration, if using custom configuration; (default is ``None``).; config : :obj:`str`, optional; Optional :obj:`dict` describing an annotation DB configuration, if using; custom configuration (default is ``None``). Note; ----; The ``'aws'`` `cloud` platform is currently only available for the ``'us'``; `region`. Examples; --------; Create an annotation database connecting to the default Hail Annotation DB:. >>> db = hl.experimental.DB(region='us-central1', cloud='gcp'); """""". _valid_key_properties: ClassVar = {'gene', 'unique'}; _valid_regions: ClassVar = {'us', 'us-central1', 'europe-west1'}; _valid_clouds: ClassVar = {'gcp', 'aws'}; _valid_combinations: ClassVar = {('us', 'aws'), ('us-central1', 'gcp'), ('europe-west1', 'gcp')}. def __init__(; self,; *,; region: str = 'us-central1',; cloud: str = 'gcp',; url: Optional[str] = None,; config: Optional[dict] = None,; ):; if region not in DB._valid_regions:; raise ValueError(; f'Specify valid region parameter,'; f' received: region={region",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:10059,Modifiability,config,config,10059," [docs]class DB:; """"""An annotation database instance. This class facilitates the annotation of genetic datasets with variant annotations. It accepts; either an HTTP(S) URL to an Annotation DB configuration or a Python :obj:`dict` describing an; Annotation DB configuration. User must specify the `region` (aws: ``'us'``, gcp:; ``'us-central1'`` or ``'europe-west1'``) in which the cluster is running if connecting to the; default Hail Annotation DB. User must also specify the `cloud` platform that they are using; (``'gcp'`` or ``'aws'``). Parameters; ----------; region : :obj:`str`; Region cluster is running in, either ``'us'``, ``'us-central1'``, or ``'europe-west1'``; (default is ``'us-central1'``).; cloud : :obj:`str`; Cloud platform, either ``'gcp'`` or ``'aws'`` (default is ``'gcp'``).; url : :obj:`str`, optional; Optional URL to annotation DB configuration, if using custom configuration; (default is ``None``).; config : :obj:`str`, optional; Optional :obj:`dict` describing an annotation DB configuration, if using; custom configuration (default is ``None``). Note; ----; The ``'aws'`` `cloud` platform is currently only available for the ``'us'``; `region`. Examples; --------; Create an annotation database connecting to the default Hail Annotation DB:. >>> db = hl.experimental.DB(region='us-central1', cloud='gcp'); """""". _valid_key_properties: ClassVar = {'gene', 'unique'}; _valid_regions: ClassVar = {'us', 'us-central1', 'europe-west1'}; _valid_clouds: ClassVar = {'gcp', 'aws'}; _valid_combinations: ClassVar = {('us', 'aws'), ('us-central1', 'gcp'), ('europe-west1', 'gcp')}. def __init__(; self,; *,; region: str = 'us-central1',; cloud: str = 'gcp',; url: Optional[str] = None,; config: Optional[dict] = None,; ):; if region not in DB._valid_regions:; raise ValueError(; f'Specify valid region parameter,'; f' received: region={region!r}.\n'; f'Valid regions are {DB._valid_regions}.'; ); if cloud not in DB._valid_clouds:; raise ValueError(; f'Specify valid cloud paramete",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:10139,Modifiability,config,configuration,10139," [docs]class DB:; """"""An annotation database instance. This class facilitates the annotation of genetic datasets with variant annotations. It accepts; either an HTTP(S) URL to an Annotation DB configuration or a Python :obj:`dict` describing an; Annotation DB configuration. User must specify the `region` (aws: ``'us'``, gcp:; ``'us-central1'`` or ``'europe-west1'``) in which the cluster is running if connecting to the; default Hail Annotation DB. User must also specify the `cloud` platform that they are using; (``'gcp'`` or ``'aws'``). Parameters; ----------; region : :obj:`str`; Region cluster is running in, either ``'us'``, ``'us-central1'``, or ``'europe-west1'``; (default is ``'us-central1'``).; cloud : :obj:`str`; Cloud platform, either ``'gcp'`` or ``'aws'`` (default is ``'gcp'``).; url : :obj:`str`, optional; Optional URL to annotation DB configuration, if using custom configuration; (default is ``None``).; config : :obj:`str`, optional; Optional :obj:`dict` describing an annotation DB configuration, if using; custom configuration (default is ``None``). Note; ----; The ``'aws'`` `cloud` platform is currently only available for the ``'us'``; `region`. Examples; --------; Create an annotation database connecting to the default Hail Annotation DB:. >>> db = hl.experimental.DB(region='us-central1', cloud='gcp'); """""". _valid_key_properties: ClassVar = {'gene', 'unique'}; _valid_regions: ClassVar = {'us', 'us-central1', 'europe-west1'}; _valid_clouds: ClassVar = {'gcp', 'aws'}; _valid_combinations: ClassVar = {('us', 'aws'), ('us-central1', 'gcp'), ('europe-west1', 'gcp')}. def __init__(; self,; *,; region: str = 'us-central1',; cloud: str = 'gcp',; url: Optional[str] = None,; config: Optional[dict] = None,; ):; if region not in DB._valid_regions:; raise ValueError(; f'Specify valid region parameter,'; f' received: region={region!r}.\n'; f'Valid regions are {DB._valid_regions}.'; ); if cloud not in DB._valid_clouds:; raise ValueError(; f'Specify valid cloud paramete",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:10171,Modifiability,config,configuration,10171," [docs]class DB:; """"""An annotation database instance. This class facilitates the annotation of genetic datasets with variant annotations. It accepts; either an HTTP(S) URL to an Annotation DB configuration or a Python :obj:`dict` describing an; Annotation DB configuration. User must specify the `region` (aws: ``'us'``, gcp:; ``'us-central1'`` or ``'europe-west1'``) in which the cluster is running if connecting to the; default Hail Annotation DB. User must also specify the `cloud` platform that they are using; (``'gcp'`` or ``'aws'``). Parameters; ----------; region : :obj:`str`; Region cluster is running in, either ``'us'``, ``'us-central1'``, or ``'europe-west1'``; (default is ``'us-central1'``).; cloud : :obj:`str`; Cloud platform, either ``'gcp'`` or ``'aws'`` (default is ``'gcp'``).; url : :obj:`str`, optional; Optional URL to annotation DB configuration, if using custom configuration; (default is ``None``).; config : :obj:`str`, optional; Optional :obj:`dict` describing an annotation DB configuration, if using; custom configuration (default is ``None``). Note; ----; The ``'aws'`` `cloud` platform is currently only available for the ``'us'``; `region`. Examples; --------; Create an annotation database connecting to the default Hail Annotation DB:. >>> db = hl.experimental.DB(region='us-central1', cloud='gcp'); """""". _valid_key_properties: ClassVar = {'gene', 'unique'}; _valid_regions: ClassVar = {'us', 'us-central1', 'europe-west1'}; _valid_clouds: ClassVar = {'gcp', 'aws'}; _valid_combinations: ClassVar = {('us', 'aws'), ('us-central1', 'gcp'), ('europe-west1', 'gcp')}. def __init__(; self,; *,; region: str = 'us-central1',; cloud: str = 'gcp',; url: Optional[str] = None,; config: Optional[dict] = None,; ):; if region not in DB._valid_regions:; raise ValueError(; f'Specify valid region parameter,'; f' received: region={region!r}.\n'; f'Valid regions are {DB._valid_regions}.'; ); if cloud not in DB._valid_clouds:; raise ValueError(; f'Specify valid cloud paramete",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:10838,Modifiability,config,config,10838,"lt is ``'us-central1'``).; cloud : :obj:`str`; Cloud platform, either ``'gcp'`` or ``'aws'`` (default is ``'gcp'``).; url : :obj:`str`, optional; Optional URL to annotation DB configuration, if using custom configuration; (default is ``None``).; config : :obj:`str`, optional; Optional :obj:`dict` describing an annotation DB configuration, if using; custom configuration (default is ``None``). Note; ----; The ``'aws'`` `cloud` platform is currently only available for the ``'us'``; `region`. Examples; --------; Create an annotation database connecting to the default Hail Annotation DB:. >>> db = hl.experimental.DB(region='us-central1', cloud='gcp'); """""". _valid_key_properties: ClassVar = {'gene', 'unique'}; _valid_regions: ClassVar = {'us', 'us-central1', 'europe-west1'}; _valid_clouds: ClassVar = {'gcp', 'aws'}; _valid_combinations: ClassVar = {('us', 'aws'), ('us-central1', 'gcp'), ('europe-west1', 'gcp')}. def __init__(; self,; *,; region: str = 'us-central1',; cloud: str = 'gcp',; url: Optional[str] = None,; config: Optional[dict] = None,; ):; if region not in DB._valid_regions:; raise ValueError(; f'Specify valid region parameter,'; f' received: region={region!r}.\n'; f'Valid regions are {DB._valid_regions}.'; ); if cloud not in DB._valid_clouds:; raise ValueError(; f'Specify valid cloud parameter,'; f' received: cloud={cloud!r}.\n'; f'Valid cloud platforms are {DB._valid_clouds}.'; ); if (region, cloud) not in DB._valid_combinations:; raise ValueError(; f'The {region!r} region is not available for'; f' the {cloud!r} cloud platform. '; f'Valid region, cloud combinations are'; f' {DB._valid_combinations}.'; ); if config is not None and url is not None:; raise ValueError(; f'Only specify one of the parameters url and' f' config, received: url={url} and config={config}'; ); if config is None:; if url is None:; config = get_datasets_metadata(); else:; session = external_requests_client_session(); response = retry_response_returning_functions(session.get, url); config ",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:11455,Modifiability,config,config,11455,"'gcp', 'aws'}; _valid_combinations: ClassVar = {('us', 'aws'), ('us-central1', 'gcp'), ('europe-west1', 'gcp')}. def __init__(; self,; *,; region: str = 'us-central1',; cloud: str = 'gcp',; url: Optional[str] = None,; config: Optional[dict] = None,; ):; if region not in DB._valid_regions:; raise ValueError(; f'Specify valid region parameter,'; f' received: region={region!r}.\n'; f'Valid regions are {DB._valid_regions}.'; ); if cloud not in DB._valid_clouds:; raise ValueError(; f'Specify valid cloud parameter,'; f' received: cloud={cloud!r}.\n'; f'Valid cloud platforms are {DB._valid_clouds}.'; ); if (region, cloud) not in DB._valid_combinations:; raise ValueError(; f'The {region!r} region is not available for'; f' the {cloud!r} cloud platform. '; f'Valid region, cloud combinations are'; f' {DB._valid_combinations}.'; ); if config is not None and url is not None:; raise ValueError(; f'Only specify one of the parameters url and' f' config, received: url={url} and config={config}'; ); if config is None:; if url is None:; config = get_datasets_metadata(); else:; session = external_requests_client_session(); response = retry_response_returning_functions(session.get, url); config = response.json(); assert isinstance(config, dict); elif not isinstance(config, dict):; raise ValueError(f'expected a dict mapping dataset names to ' f'configurations, but found {config}'); config = {k: v for k, v in config.items() if 'annotation_db' in v}; self.region = region; self.cloud = cloud; self.url = url; self.config = config; self.__by_name = {; k: Dataset.from_name_and_json(k, v, region, cloud); for k, v in config.items(); if Dataset.from_name_and_json(k, v, region, cloud) is not None; }. @property; def available_datasets(self) -> List[str]:; """"""List of names of available annotation datasets. Returns; -------; :obj:`list`; List of available annotation datasets.; """"""; return sorted(self.__by_name.keys()). @staticmethod; def _row_lens(rel: Union[Table, MatrixTable]) -> Union[TableRows, Ma",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:11564,Modifiability,config,config,11564,"'gcp', 'aws'}; _valid_combinations: ClassVar = {('us', 'aws'), ('us-central1', 'gcp'), ('europe-west1', 'gcp')}. def __init__(; self,; *,; region: str = 'us-central1',; cloud: str = 'gcp',; url: Optional[str] = None,; config: Optional[dict] = None,; ):; if region not in DB._valid_regions:; raise ValueError(; f'Specify valid region parameter,'; f' received: region={region!r}.\n'; f'Valid regions are {DB._valid_regions}.'; ); if cloud not in DB._valid_clouds:; raise ValueError(; f'Specify valid cloud parameter,'; f' received: cloud={cloud!r}.\n'; f'Valid cloud platforms are {DB._valid_clouds}.'; ); if (region, cloud) not in DB._valid_combinations:; raise ValueError(; f'The {region!r} region is not available for'; f' the {cloud!r} cloud platform. '; f'Valid region, cloud combinations are'; f' {DB._valid_combinations}.'; ); if config is not None and url is not None:; raise ValueError(; f'Only specify one of the parameters url and' f' config, received: url={url} and config={config}'; ); if config is None:; if url is None:; config = get_datasets_metadata(); else:; session = external_requests_client_session(); response = retry_response_returning_functions(session.get, url); config = response.json(); assert isinstance(config, dict); elif not isinstance(config, dict):; raise ValueError(f'expected a dict mapping dataset names to ' f'configurations, but found {config}'); config = {k: v for k, v in config.items() if 'annotation_db' in v}; self.region = region; self.cloud = cloud; self.url = url; self.config = config; self.__by_name = {; k: Dataset.from_name_and_json(k, v, region, cloud); for k, v in config.items(); if Dataset.from_name_and_json(k, v, region, cloud) is not None; }. @property; def available_datasets(self) -> List[str]:; """"""List of names of available annotation datasets. Returns; -------; :obj:`list`; List of available annotation datasets.; """"""; return sorted(self.__by_name.keys()). @staticmethod; def _row_lens(rel: Union[Table, MatrixTable]) -> Union[TableRows, Ma",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:11596,Modifiability,config,config,11596,"'gcp', 'aws'}; _valid_combinations: ClassVar = {('us', 'aws'), ('us-central1', 'gcp'), ('europe-west1', 'gcp')}. def __init__(; self,; *,; region: str = 'us-central1',; cloud: str = 'gcp',; url: Optional[str] = None,; config: Optional[dict] = None,; ):; if region not in DB._valid_regions:; raise ValueError(; f'Specify valid region parameter,'; f' received: region={region!r}.\n'; f'Valid regions are {DB._valid_regions}.'; ); if cloud not in DB._valid_clouds:; raise ValueError(; f'Specify valid cloud parameter,'; f' received: cloud={cloud!r}.\n'; f'Valid cloud platforms are {DB._valid_clouds}.'; ); if (region, cloud) not in DB._valid_combinations:; raise ValueError(; f'The {region!r} region is not available for'; f' the {cloud!r} cloud platform. '; f'Valid region, cloud combinations are'; f' {DB._valid_combinations}.'; ); if config is not None and url is not None:; raise ValueError(; f'Only specify one of the parameters url and' f' config, received: url={url} and config={config}'; ); if config is None:; if url is None:; config = get_datasets_metadata(); else:; session = external_requests_client_session(); response = retry_response_returning_functions(session.get, url); config = response.json(); assert isinstance(config, dict); elif not isinstance(config, dict):; raise ValueError(f'expected a dict mapping dataset names to ' f'configurations, but found {config}'); config = {k: v for k, v in config.items() if 'annotation_db' in v}; self.region = region; self.cloud = cloud; self.url = url; self.config = config; self.__by_name = {; k: Dataset.from_name_and_json(k, v, region, cloud); for k, v in config.items(); if Dataset.from_name_and_json(k, v, region, cloud) is not None; }. @property; def available_datasets(self) -> List[str]:; """"""List of names of available annotation datasets. Returns; -------; :obj:`list`; List of available annotation datasets.; """"""; return sorted(self.__by_name.keys()). @staticmethod; def _row_lens(rel: Union[Table, MatrixTable]) -> Union[TableRows, Ma",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:11604,Modifiability,config,config,11604,"'gcp', 'aws'}; _valid_combinations: ClassVar = {('us', 'aws'), ('us-central1', 'gcp'), ('europe-west1', 'gcp')}. def __init__(; self,; *,; region: str = 'us-central1',; cloud: str = 'gcp',; url: Optional[str] = None,; config: Optional[dict] = None,; ):; if region not in DB._valid_regions:; raise ValueError(; f'Specify valid region parameter,'; f' received: region={region!r}.\n'; f'Valid regions are {DB._valid_regions}.'; ); if cloud not in DB._valid_clouds:; raise ValueError(; f'Specify valid cloud parameter,'; f' received: cloud={cloud!r}.\n'; f'Valid cloud platforms are {DB._valid_clouds}.'; ); if (region, cloud) not in DB._valid_combinations:; raise ValueError(; f'The {region!r} region is not available for'; f' the {cloud!r} cloud platform. '; f'Valid region, cloud combinations are'; f' {DB._valid_combinations}.'; ); if config is not None and url is not None:; raise ValueError(; f'Only specify one of the parameters url and' f' config, received: url={url} and config={config}'; ); if config is None:; if url is None:; config = get_datasets_metadata(); else:; session = external_requests_client_session(); response = retry_response_returning_functions(session.get, url); config = response.json(); assert isinstance(config, dict); elif not isinstance(config, dict):; raise ValueError(f'expected a dict mapping dataset names to ' f'configurations, but found {config}'); config = {k: v for k, v in config.items() if 'annotation_db' in v}; self.region = region; self.cloud = cloud; self.url = url; self.config = config; self.__by_name = {; k: Dataset.from_name_and_json(k, v, region, cloud); for k, v in config.items(); if Dataset.from_name_and_json(k, v, region, cloud) is not None; }. @property; def available_datasets(self) -> List[str]:; """"""List of names of available annotation datasets. Returns; -------; :obj:`list`; List of available annotation datasets.; """"""; return sorted(self.__by_name.keys()). @staticmethod; def _row_lens(rel: Union[Table, MatrixTable]) -> Union[TableRows, Ma",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:11620,Modifiability,config,config,11620,"'gcp', 'aws'}; _valid_combinations: ClassVar = {('us', 'aws'), ('us-central1', 'gcp'), ('europe-west1', 'gcp')}. def __init__(; self,; *,; region: str = 'us-central1',; cloud: str = 'gcp',; url: Optional[str] = None,; config: Optional[dict] = None,; ):; if region not in DB._valid_regions:; raise ValueError(; f'Specify valid region parameter,'; f' received: region={region!r}.\n'; f'Valid regions are {DB._valid_regions}.'; ); if cloud not in DB._valid_clouds:; raise ValueError(; f'Specify valid cloud parameter,'; f' received: cloud={cloud!r}.\n'; f'Valid cloud platforms are {DB._valid_clouds}.'; ); if (region, cloud) not in DB._valid_combinations:; raise ValueError(; f'The {region!r} region is not available for'; f' the {cloud!r} cloud platform. '; f'Valid region, cloud combinations are'; f' {DB._valid_combinations}.'; ); if config is not None and url is not None:; raise ValueError(; f'Only specify one of the parameters url and' f' config, received: url={url} and config={config}'; ); if config is None:; if url is None:; config = get_datasets_metadata(); else:; session = external_requests_client_session(); response = retry_response_returning_functions(session.get, url); config = response.json(); assert isinstance(config, dict); elif not isinstance(config, dict):; raise ValueError(f'expected a dict mapping dataset names to ' f'configurations, but found {config}'); config = {k: v for k, v in config.items() if 'annotation_db' in v}; self.region = region; self.cloud = cloud; self.url = url; self.config = config; self.__by_name = {; k: Dataset.from_name_and_json(k, v, region, cloud); for k, v in config.items(); if Dataset.from_name_and_json(k, v, region, cloud) is not None; }. @property; def available_datasets(self) -> List[str]:; """"""List of names of available annotation datasets. Returns; -------; :obj:`list`; List of available annotation datasets.; """"""; return sorted(self.__by_name.keys()). @staticmethod; def _row_lens(rel: Union[Table, MatrixTable]) -> Union[TableRows, Ma",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:11654,Modifiability,config,config,11654,"'gcp', 'aws'}; _valid_combinations: ClassVar = {('us', 'aws'), ('us-central1', 'gcp'), ('europe-west1', 'gcp')}. def __init__(; self,; *,; region: str = 'us-central1',; cloud: str = 'gcp',; url: Optional[str] = None,; config: Optional[dict] = None,; ):; if region not in DB._valid_regions:; raise ValueError(; f'Specify valid region parameter,'; f' received: region={region!r}.\n'; f'Valid regions are {DB._valid_regions}.'; ); if cloud not in DB._valid_clouds:; raise ValueError(; f'Specify valid cloud parameter,'; f' received: cloud={cloud!r}.\n'; f'Valid cloud platforms are {DB._valid_clouds}.'; ); if (region, cloud) not in DB._valid_combinations:; raise ValueError(; f'The {region!r} region is not available for'; f' the {cloud!r} cloud platform. '; f'Valid region, cloud combinations are'; f' {DB._valid_combinations}.'; ); if config is not None and url is not None:; raise ValueError(; f'Only specify one of the parameters url and' f' config, received: url={url} and config={config}'; ); if config is None:; if url is None:; config = get_datasets_metadata(); else:; session = external_requests_client_session(); response = retry_response_returning_functions(session.get, url); config = response.json(); assert isinstance(config, dict); elif not isinstance(config, dict):; raise ValueError(f'expected a dict mapping dataset names to ' f'configurations, but found {config}'); config = {k: v for k, v in config.items() if 'annotation_db' in v}; self.region = region; self.cloud = cloud; self.url = url; self.config = config; self.__by_name = {; k: Dataset.from_name_and_json(k, v, region, cloud); for k, v in config.items(); if Dataset.from_name_and_json(k, v, region, cloud) is not None; }. @property; def available_datasets(self) -> List[str]:; """"""List of names of available annotation datasets. Returns; -------; :obj:`list`; List of available annotation datasets.; """"""; return sorted(self.__by_name.keys()). @staticmethod; def _row_lens(rel: Union[Table, MatrixTable]) -> Union[TableRows, Ma",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:11806,Modifiability,config,config,11806," url: Optional[str] = None,; config: Optional[dict] = None,; ):; if region not in DB._valid_regions:; raise ValueError(; f'Specify valid region parameter,'; f' received: region={region!r}.\n'; f'Valid regions are {DB._valid_regions}.'; ); if cloud not in DB._valid_clouds:; raise ValueError(; f'Specify valid cloud parameter,'; f' received: cloud={cloud!r}.\n'; f'Valid cloud platforms are {DB._valid_clouds}.'; ); if (region, cloud) not in DB._valid_combinations:; raise ValueError(; f'The {region!r} region is not available for'; f' the {cloud!r} cloud platform. '; f'Valid region, cloud combinations are'; f' {DB._valid_combinations}.'; ); if config is not None and url is not None:; raise ValueError(; f'Only specify one of the parameters url and' f' config, received: url={url} and config={config}'; ); if config is None:; if url is None:; config = get_datasets_metadata(); else:; session = external_requests_client_session(); response = retry_response_returning_functions(session.get, url); config = response.json(); assert isinstance(config, dict); elif not isinstance(config, dict):; raise ValueError(f'expected a dict mapping dataset names to ' f'configurations, but found {config}'); config = {k: v for k, v in config.items() if 'annotation_db' in v}; self.region = region; self.cloud = cloud; self.url = url; self.config = config; self.__by_name = {; k: Dataset.from_name_and_json(k, v, region, cloud); for k, v in config.items(); if Dataset.from_name_and_json(k, v, region, cloud) is not None; }. @property; def available_datasets(self) -> List[str]:; """"""List of names of available annotation datasets. Returns; -------; :obj:`list`; List of available annotation datasets.; """"""; return sorted(self.__by_name.keys()). @staticmethod; def _row_lens(rel: Union[Table, MatrixTable]) -> Union[TableRows, MatrixRows]:; """"""Get row lens from relational object. Parameters; ----------; rel : :class:`Table` or :class:`MatrixTable`. Returns; -------; :class:`TableRows` or :class:`MatrixRows`; """"""; i",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:11850,Modifiability,config,config,11850,"f'Specify valid region parameter,'; f' received: region={region!r}.\n'; f'Valid regions are {DB._valid_regions}.'; ); if cloud not in DB._valid_clouds:; raise ValueError(; f'Specify valid cloud parameter,'; f' received: cloud={cloud!r}.\n'; f'Valid cloud platforms are {DB._valid_clouds}.'; ); if (region, cloud) not in DB._valid_combinations:; raise ValueError(; f'The {region!r} region is not available for'; f' the {cloud!r} cloud platform. '; f'Valid region, cloud combinations are'; f' {DB._valid_combinations}.'; ); if config is not None and url is not None:; raise ValueError(; f'Only specify one of the parameters url and' f' config, received: url={url} and config={config}'; ); if config is None:; if url is None:; config = get_datasets_metadata(); else:; session = external_requests_client_session(); response = retry_response_returning_functions(session.get, url); config = response.json(); assert isinstance(config, dict); elif not isinstance(config, dict):; raise ValueError(f'expected a dict mapping dataset names to ' f'configurations, but found {config}'); config = {k: v for k, v in config.items() if 'annotation_db' in v}; self.region = region; self.cloud = cloud; self.url = url; self.config = config; self.__by_name = {; k: Dataset.from_name_and_json(k, v, region, cloud); for k, v in config.items(); if Dataset.from_name_and_json(k, v, region, cloud) is not None; }. @property; def available_datasets(self) -> List[str]:; """"""List of names of available annotation datasets. Returns; -------; :obj:`list`; List of available annotation datasets.; """"""; return sorted(self.__by_name.keys()). @staticmethod; def _row_lens(rel: Union[Table, MatrixTable]) -> Union[TableRows, MatrixRows]:; """"""Get row lens from relational object. Parameters; ----------; rel : :class:`Table` or :class:`MatrixTable`. Returns; -------; :class:`TableRows` or :class:`MatrixRows`; """"""; if isinstance(rel, MatrixTable):; return MatrixRows(rel); elif isinstance(rel, Table):; return TableRows(rel); else:; rais",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:11885,Modifiability,config,config,11885,"f'Specify valid region parameter,'; f' received: region={region!r}.\n'; f'Valid regions are {DB._valid_regions}.'; ); if cloud not in DB._valid_clouds:; raise ValueError(; f'Specify valid cloud parameter,'; f' received: cloud={cloud!r}.\n'; f'Valid cloud platforms are {DB._valid_clouds}.'; ); if (region, cloud) not in DB._valid_combinations:; raise ValueError(; f'The {region!r} region is not available for'; f' the {cloud!r} cloud platform. '; f'Valid region, cloud combinations are'; f' {DB._valid_combinations}.'; ); if config is not None and url is not None:; raise ValueError(; f'Only specify one of the parameters url and' f' config, received: url={url} and config={config}'; ); if config is None:; if url is None:; config = get_datasets_metadata(); else:; session = external_requests_client_session(); response = retry_response_returning_functions(session.get, url); config = response.json(); assert isinstance(config, dict); elif not isinstance(config, dict):; raise ValueError(f'expected a dict mapping dataset names to ' f'configurations, but found {config}'); config = {k: v for k, v in config.items() if 'annotation_db' in v}; self.region = region; self.cloud = cloud; self.url = url; self.config = config; self.__by_name = {; k: Dataset.from_name_and_json(k, v, region, cloud); for k, v in config.items(); if Dataset.from_name_and_json(k, v, region, cloud) is not None; }. @property; def available_datasets(self) -> List[str]:; """"""List of names of available annotation datasets. Returns; -------; :obj:`list`; List of available annotation datasets.; """"""; return sorted(self.__by_name.keys()). @staticmethod; def _row_lens(rel: Union[Table, MatrixTable]) -> Union[TableRows, MatrixRows]:; """"""Get row lens from relational object. Parameters; ----------; rel : :class:`Table` or :class:`MatrixTable`. Returns; -------; :class:`TableRows` or :class:`MatrixRows`; """"""; if isinstance(rel, MatrixTable):; return MatrixRows(rel); elif isinstance(rel, Table):; return TableRows(rel); else:; rais",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:11965,Modifiability,config,configurations,11965,"f'Specify valid region parameter,'; f' received: region={region!r}.\n'; f'Valid regions are {DB._valid_regions}.'; ); if cloud not in DB._valid_clouds:; raise ValueError(; f'Specify valid cloud parameter,'; f' received: cloud={cloud!r}.\n'; f'Valid cloud platforms are {DB._valid_clouds}.'; ); if (region, cloud) not in DB._valid_combinations:; raise ValueError(; f'The {region!r} region is not available for'; f' the {cloud!r} cloud platform. '; f'Valid region, cloud combinations are'; f' {DB._valid_combinations}.'; ); if config is not None and url is not None:; raise ValueError(; f'Only specify one of the parameters url and' f' config, received: url={url} and config={config}'; ); if config is None:; if url is None:; config = get_datasets_metadata(); else:; session = external_requests_client_session(); response = retry_response_returning_functions(session.get, url); config = response.json(); assert isinstance(config, dict); elif not isinstance(config, dict):; raise ValueError(f'expected a dict mapping dataset names to ' f'configurations, but found {config}'); config = {k: v for k, v in config.items() if 'annotation_db' in v}; self.region = region; self.cloud = cloud; self.url = url; self.config = config; self.__by_name = {; k: Dataset.from_name_and_json(k, v, region, cloud); for k, v in config.items(); if Dataset.from_name_and_json(k, v, region, cloud) is not None; }. @property; def available_datasets(self) -> List[str]:; """"""List of names of available annotation datasets. Returns; -------; :obj:`list`; List of available annotation datasets.; """"""; return sorted(self.__by_name.keys()). @staticmethod; def _row_lens(rel: Union[Table, MatrixTable]) -> Union[TableRows, MatrixRows]:; """"""Get row lens from relational object. Parameters; ----------; rel : :class:`Table` or :class:`MatrixTable`. Returns; -------; :class:`TableRows` or :class:`MatrixRows`; """"""; if isinstance(rel, MatrixTable):; return MatrixRows(rel); elif isinstance(rel, Table):; return TableRows(rel); else:; rais",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:11992,Modifiability,config,config,11992,"f'Specify valid region parameter,'; f' received: region={region!r}.\n'; f'Valid regions are {DB._valid_regions}.'; ); if cloud not in DB._valid_clouds:; raise ValueError(; f'Specify valid cloud parameter,'; f' received: cloud={cloud!r}.\n'; f'Valid cloud platforms are {DB._valid_clouds}.'; ); if (region, cloud) not in DB._valid_combinations:; raise ValueError(; f'The {region!r} region is not available for'; f' the {cloud!r} cloud platform. '; f'Valid region, cloud combinations are'; f' {DB._valid_combinations}.'; ); if config is not None and url is not None:; raise ValueError(; f'Only specify one of the parameters url and' f' config, received: url={url} and config={config}'; ); if config is None:; if url is None:; config = get_datasets_metadata(); else:; session = external_requests_client_session(); response = retry_response_returning_functions(session.get, url); config = response.json(); assert isinstance(config, dict); elif not isinstance(config, dict):; raise ValueError(f'expected a dict mapping dataset names to ' f'configurations, but found {config}'); config = {k: v for k, v in config.items() if 'annotation_db' in v}; self.region = region; self.cloud = cloud; self.url = url; self.config = config; self.__by_name = {; k: Dataset.from_name_and_json(k, v, region, cloud); for k, v in config.items(); if Dataset.from_name_and_json(k, v, region, cloud) is not None; }. @property; def available_datasets(self) -> List[str]:; """"""List of names of available annotation datasets. Returns; -------; :obj:`list`; List of available annotation datasets.; """"""; return sorted(self.__by_name.keys()). @staticmethod; def _row_lens(rel: Union[Table, MatrixTable]) -> Union[TableRows, MatrixRows]:; """"""Get row lens from relational object. Parameters; ----------; rel : :class:`Table` or :class:`MatrixTable`. Returns; -------; :class:`TableRows` or :class:`MatrixRows`; """"""; if isinstance(rel, MatrixTable):; return MatrixRows(rel); elif isinstance(rel, Table):; return TableRows(rel); else:; rais",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:12003,Modifiability,config,config,12003,"f'Specify valid region parameter,'; f' received: region={region!r}.\n'; f'Valid regions are {DB._valid_regions}.'; ); if cloud not in DB._valid_clouds:; raise ValueError(; f'Specify valid cloud parameter,'; f' received: cloud={cloud!r}.\n'; f'Valid cloud platforms are {DB._valid_clouds}.'; ); if (region, cloud) not in DB._valid_combinations:; raise ValueError(; f'The {region!r} region is not available for'; f' the {cloud!r} cloud platform. '; f'Valid region, cloud combinations are'; f' {DB._valid_combinations}.'; ); if config is not None and url is not None:; raise ValueError(; f'Only specify one of the parameters url and' f' config, received: url={url} and config={config}'; ); if config is None:; if url is None:; config = get_datasets_metadata(); else:; session = external_requests_client_session(); response = retry_response_returning_functions(session.get, url); config = response.json(); assert isinstance(config, dict); elif not isinstance(config, dict):; raise ValueError(f'expected a dict mapping dataset names to ' f'configurations, but found {config}'); config = {k: v for k, v in config.items() if 'annotation_db' in v}; self.region = region; self.cloud = cloud; self.url = url; self.config = config; self.__by_name = {; k: Dataset.from_name_and_json(k, v, region, cloud); for k, v in config.items(); if Dataset.from_name_and_json(k, v, region, cloud) is not None; }. @property; def available_datasets(self) -> List[str]:; """"""List of names of available annotation datasets. Returns; -------; :obj:`list`; List of available annotation datasets.; """"""; return sorted(self.__by_name.keys()). @staticmethod; def _row_lens(rel: Union[Table, MatrixTable]) -> Union[TableRows, MatrixRows]:; """"""Get row lens from relational object. Parameters; ----------; rel : :class:`Table` or :class:`MatrixTable`. Returns; -------; :class:`TableRows` or :class:`MatrixRows`; """"""; if isinstance(rel, MatrixTable):; return MatrixRows(rel); elif isinstance(rel, Table):; return TableRows(rel); else:; rais",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:12030,Modifiability,config,config,12030,"f'Specify valid region parameter,'; f' received: region={region!r}.\n'; f'Valid regions are {DB._valid_regions}.'; ); if cloud not in DB._valid_clouds:; raise ValueError(; f'Specify valid cloud parameter,'; f' received: cloud={cloud!r}.\n'; f'Valid cloud platforms are {DB._valid_clouds}.'; ); if (region, cloud) not in DB._valid_combinations:; raise ValueError(; f'The {region!r} region is not available for'; f' the {cloud!r} cloud platform. '; f'Valid region, cloud combinations are'; f' {DB._valid_combinations}.'; ); if config is not None and url is not None:; raise ValueError(; f'Only specify one of the parameters url and' f' config, received: url={url} and config={config}'; ); if config is None:; if url is None:; config = get_datasets_metadata(); else:; session = external_requests_client_session(); response = retry_response_returning_functions(session.get, url); config = response.json(); assert isinstance(config, dict); elif not isinstance(config, dict):; raise ValueError(f'expected a dict mapping dataset names to ' f'configurations, but found {config}'); config = {k: v for k, v in config.items() if 'annotation_db' in v}; self.region = region; self.cloud = cloud; self.url = url; self.config = config; self.__by_name = {; k: Dataset.from_name_and_json(k, v, region, cloud); for k, v in config.items(); if Dataset.from_name_and_json(k, v, region, cloud) is not None; }. @property; def available_datasets(self) -> List[str]:; """"""List of names of available annotation datasets. Returns; -------; :obj:`list`; List of available annotation datasets.; """"""; return sorted(self.__by_name.keys()). @staticmethod; def _row_lens(rel: Union[Table, MatrixTable]) -> Union[TableRows, MatrixRows]:; """"""Get row lens from relational object. Parameters; ----------; rel : :class:`Table` or :class:`MatrixTable`. Returns; -------; :class:`TableRows` or :class:`MatrixRows`; """"""; if isinstance(rel, MatrixTable):; return MatrixRows(rel); elif isinstance(rel, Table):; return TableRows(rel); else:; rais",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:12134,Modifiability,config,config,12134,"ved: cloud={cloud!r}.\n'; f'Valid cloud platforms are {DB._valid_clouds}.'; ); if (region, cloud) not in DB._valid_combinations:; raise ValueError(; f'The {region!r} region is not available for'; f' the {cloud!r} cloud platform. '; f'Valid region, cloud combinations are'; f' {DB._valid_combinations}.'; ); if config is not None and url is not None:; raise ValueError(; f'Only specify one of the parameters url and' f' config, received: url={url} and config={config}'; ); if config is None:; if url is None:; config = get_datasets_metadata(); else:; session = external_requests_client_session(); response = retry_response_returning_functions(session.get, url); config = response.json(); assert isinstance(config, dict); elif not isinstance(config, dict):; raise ValueError(f'expected a dict mapping dataset names to ' f'configurations, but found {config}'); config = {k: v for k, v in config.items() if 'annotation_db' in v}; self.region = region; self.cloud = cloud; self.url = url; self.config = config; self.__by_name = {; k: Dataset.from_name_and_json(k, v, region, cloud); for k, v in config.items(); if Dataset.from_name_and_json(k, v, region, cloud) is not None; }. @property; def available_datasets(self) -> List[str]:; """"""List of names of available annotation datasets. Returns; -------; :obj:`list`; List of available annotation datasets.; """"""; return sorted(self.__by_name.keys()). @staticmethod; def _row_lens(rel: Union[Table, MatrixTable]) -> Union[TableRows, MatrixRows]:; """"""Get row lens from relational object. Parameters; ----------; rel : :class:`Table` or :class:`MatrixTable`. Returns; -------; :class:`TableRows` or :class:`MatrixRows`; """"""; if isinstance(rel, MatrixTable):; return MatrixRows(rel); elif isinstance(rel, Table):; return TableRows(rel); else:; raise ValueError('annotation database can only annotate Hail' ' MatrixTable or Table'). def _dataset_by_name(self, name: str) -> Dataset:; """"""Retrieve :class:`Dataset` object by name. Parameters; ----------; name : :ob",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:12143,Modifiability,config,config,12143,"ved: cloud={cloud!r}.\n'; f'Valid cloud platforms are {DB._valid_clouds}.'; ); if (region, cloud) not in DB._valid_combinations:; raise ValueError(; f'The {region!r} region is not available for'; f' the {cloud!r} cloud platform. '; f'Valid region, cloud combinations are'; f' {DB._valid_combinations}.'; ); if config is not None and url is not None:; raise ValueError(; f'Only specify one of the parameters url and' f' config, received: url={url} and config={config}'; ); if config is None:; if url is None:; config = get_datasets_metadata(); else:; session = external_requests_client_session(); response = retry_response_returning_functions(session.get, url); config = response.json(); assert isinstance(config, dict); elif not isinstance(config, dict):; raise ValueError(f'expected a dict mapping dataset names to ' f'configurations, but found {config}'); config = {k: v for k, v in config.items() if 'annotation_db' in v}; self.region = region; self.cloud = cloud; self.url = url; self.config = config; self.__by_name = {; k: Dataset.from_name_and_json(k, v, region, cloud); for k, v in config.items(); if Dataset.from_name_and_json(k, v, region, cloud) is not None; }. @property; def available_datasets(self) -> List[str]:; """"""List of names of available annotation datasets. Returns; -------; :obj:`list`; List of available annotation datasets.; """"""; return sorted(self.__by_name.keys()). @staticmethod; def _row_lens(rel: Union[Table, MatrixTable]) -> Union[TableRows, MatrixRows]:; """"""Get row lens from relational object. Parameters; ----------; rel : :class:`Table` or :class:`MatrixTable`. Returns; -------; :class:`TableRows` or :class:`MatrixRows`; """"""; if isinstance(rel, MatrixTable):; return MatrixRows(rel); elif isinstance(rel, Table):; return TableRows(rel); else:; raise ValueError('annotation database can only annotate Hail' ' MatrixTable or Table'). def _dataset_by_name(self, name: str) -> Dataset:; """"""Retrieve :class:`Dataset` object by name. Parameters; ----------; name : :ob",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:12235,Modifiability,config,config,12235,"ouds}.'; ); if (region, cloud) not in DB._valid_combinations:; raise ValueError(; f'The {region!r} region is not available for'; f' the {cloud!r} cloud platform. '; f'Valid region, cloud combinations are'; f' {DB._valid_combinations}.'; ); if config is not None and url is not None:; raise ValueError(; f'Only specify one of the parameters url and' f' config, received: url={url} and config={config}'; ); if config is None:; if url is None:; config = get_datasets_metadata(); else:; session = external_requests_client_session(); response = retry_response_returning_functions(session.get, url); config = response.json(); assert isinstance(config, dict); elif not isinstance(config, dict):; raise ValueError(f'expected a dict mapping dataset names to ' f'configurations, but found {config}'); config = {k: v for k, v in config.items() if 'annotation_db' in v}; self.region = region; self.cloud = cloud; self.url = url; self.config = config; self.__by_name = {; k: Dataset.from_name_and_json(k, v, region, cloud); for k, v in config.items(); if Dataset.from_name_and_json(k, v, region, cloud) is not None; }. @property; def available_datasets(self) -> List[str]:; """"""List of names of available annotation datasets. Returns; -------; :obj:`list`; List of available annotation datasets.; """"""; return sorted(self.__by_name.keys()). @staticmethod; def _row_lens(rel: Union[Table, MatrixTable]) -> Union[TableRows, MatrixRows]:; """"""Get row lens from relational object. Parameters; ----------; rel : :class:`Table` or :class:`MatrixTable`. Returns; -------; :class:`TableRows` or :class:`MatrixRows`; """"""; if isinstance(rel, MatrixTable):; return MatrixRows(rel); elif isinstance(rel, Table):; return TableRows(rel); else:; raise ValueError('annotation database can only annotate Hail' ' MatrixTable or Table'). def _dataset_by_name(self, name: str) -> Dataset:; """"""Retrieve :class:`Dataset` object by name. Parameters; ----------; name : :obj:`str`; Name of dataset. Returns; -------; :class:`Dataset`; """"""; ",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:1947,Security,access,access,1947,"atasets_metadata; from .lens import MatrixRows, TableRows. class DatasetVersion:; """""":class:`DatasetVersion` has two constructors: :func:`.from_json` and; :func:`.get_region`. Parameters; ----------; url : :obj:`dict` or :obj:`str`; Nested dictionary of URLs containing key: value pairs, like; ``cloud: {region: url}`` if using :func:`.from_json` constructor,; or a string with the URL from appropriate region if using the; :func:`.get_region` constructor.; version : :obj:`str`, optional; String of dataset version, if not ``None``.; reference_genome : :obj:`str`, optional; String of dataset reference genome, if not ``None``.; """""". @staticmethod; def from_json(doc: dict, cloud: str) -> Optional['DatasetVersion']:; """"""Create :class:`.DatasetVersion` object from dictionary. Parameters; ----------; doc : :obj:`dict`; Dictionary containing url and version keys.; Value for url is a :obj:`dict` containing key: value pairs, like; ``cloud: {region: url}``.; cloud : :obj:`str`; Cloud platform to access dataset, either ``'gcp'`` or ``'aws'``. Returns; -------; :class:`.DatasetVersion` if available on cloud platform, else ``None``.; """"""; assert 'url' in doc, doc; assert 'version' in doc, doc; assert 'reference_genome' in doc, doc; if cloud in doc['url']:; return DatasetVersion(doc['url'][cloud], doc['version'], doc['reference_genome']); else:; return None. @staticmethod; def get_region(name: str, versions: List['DatasetVersion'], region: str) -> List['DatasetVersion']:; """"""Get versions of a :class:`.Dataset` in the specified region, if they; exist. Parameters; ----------; name : :obj:`str`; Name of dataset.; versions : :class:`list` of :class:`.DatasetVersion`; List of DatasetVersion objects where the value for :attr:`.url`; is a :obj:`dict` containing key: value pairs, like ``region: url``.; region : :obj:`str`; Region from which to access data, available regions given in; :attr:`hail.experimental.DB._valid_regions`. Returns; -------; available_versions : :class:`list` of :class:`",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:2800,Security,access,access,2800,"sion keys.; Value for url is a :obj:`dict` containing key: value pairs, like; ``cloud: {region: url}``.; cloud : :obj:`str`; Cloud platform to access dataset, either ``'gcp'`` or ``'aws'``. Returns; -------; :class:`.DatasetVersion` if available on cloud platform, else ``None``.; """"""; assert 'url' in doc, doc; assert 'version' in doc, doc; assert 'reference_genome' in doc, doc; if cloud in doc['url']:; return DatasetVersion(doc['url'][cloud], doc['version'], doc['reference_genome']); else:; return None. @staticmethod; def get_region(name: str, versions: List['DatasetVersion'], region: str) -> List['DatasetVersion']:; """"""Get versions of a :class:`.Dataset` in the specified region, if they; exist. Parameters; ----------; name : :obj:`str`; Name of dataset.; versions : :class:`list` of :class:`.DatasetVersion`; List of DatasetVersion objects where the value for :attr:`.url`; is a :obj:`dict` containing key: value pairs, like ``region: url``.; region : :obj:`str`; Region from which to access data, available regions given in; :attr:`hail.experimental.DB._valid_regions`. Returns; -------; available_versions : :class:`list` of :class:`.DatasetVersion`; List of available versions of a class:`.Dataset` for region.; """"""; available_versions = []; for version in versions:; if version.in_region(name, region):; version.url = version.url[region]; available_versions.append(version); return available_versions. def __init__(self, url: Union[dict, str], version: Optional[str], reference_genome: Optional[str]):; self.url = url; self.version = version; self.reference_genome = reference_genome. def in_region(self, name: str, region: str) -> bool:; """"""Check if a :class:`.DatasetVersion` object is accessible in the; desired region. Parameters; ----------; name : :obj:`str`; Name of dataset.; region : :obj:`str`; Region from which to access data, available regions given in; :func:`hail.experimental.DB._valid_regions`. Returns; -------; valid_region : :obj:`bool`; Whether or not the dataset e",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:3507,Security,access,accessible,3507,"rameters; ----------; name : :obj:`str`; Name of dataset.; versions : :class:`list` of :class:`.DatasetVersion`; List of DatasetVersion objects where the value for :attr:`.url`; is a :obj:`dict` containing key: value pairs, like ``region: url``.; region : :obj:`str`; Region from which to access data, available regions given in; :attr:`hail.experimental.DB._valid_regions`. Returns; -------; available_versions : :class:`list` of :class:`.DatasetVersion`; List of available versions of a class:`.Dataset` for region.; """"""; available_versions = []; for version in versions:; if version.in_region(name, region):; version.url = version.url[region]; available_versions.append(version); return available_versions. def __init__(self, url: Union[dict, str], version: Optional[str], reference_genome: Optional[str]):; self.url = url; self.version = version; self.reference_genome = reference_genome. def in_region(self, name: str, region: str) -> bool:; """"""Check if a :class:`.DatasetVersion` object is accessible in the; desired region. Parameters; ----------; name : :obj:`str`; Name of dataset.; region : :obj:`str`; Region from which to access data, available regions given in; :func:`hail.experimental.DB._valid_regions`. Returns; -------; valid_region : :obj:`bool`; Whether or not the dataset exists in the specified region.; """"""; current_version = self.version; available_regions = [k for k in self.url.keys()]; valid_region = region in available_regions; if not valid_region:; message = (; f'\nName: {name}\n'; f'Version: {current_version}\n'; f'This dataset exists but is not yet available in the'; f' {region} region bucket.\n'; f'Dataset is currently available in the'; f' {"", "".join(available_regions)} region bucket(s).\n'; f'Reach out to the Hail team at https://discuss.hail.is/'; f' to request this dataset in your region.'; ); warnings.warn(message, UserWarning, stacklevel=1); return valid_region. def maybe_index(self, indexer_key_expr: StructExpression, all_matches: bool) -> Optional[S",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:3645,Security,access,access,3645,"jects where the value for :attr:`.url`; is a :obj:`dict` containing key: value pairs, like ``region: url``.; region : :obj:`str`; Region from which to access data, available regions given in; :attr:`hail.experimental.DB._valid_regions`. Returns; -------; available_versions : :class:`list` of :class:`.DatasetVersion`; List of available versions of a class:`.Dataset` for region.; """"""; available_versions = []; for version in versions:; if version.in_region(name, region):; version.url = version.url[region]; available_versions.append(version); return available_versions. def __init__(self, url: Union[dict, str], version: Optional[str], reference_genome: Optional[str]):; self.url = url; self.version = version; self.reference_genome = reference_genome. def in_region(self, name: str, region: str) -> bool:; """"""Check if a :class:`.DatasetVersion` object is accessible in the; desired region. Parameters; ----------; name : :obj:`str`; Name of dataset.; region : :obj:`str`; Region from which to access data, available regions given in; :func:`hail.experimental.DB._valid_regions`. Returns; -------; valid_region : :obj:`bool`; Whether or not the dataset exists in the specified region.; """"""; current_version = self.version; available_regions = [k for k in self.url.keys()]; valid_region = region in available_regions; if not valid_region:; message = (; f'\nName: {name}\n'; f'Version: {current_version}\n'; f'This dataset exists but is not yet available in the'; f' {region} region bucket.\n'; f'Dataset is currently available in the'; f' {"", "".join(available_regions)} region bucket(s).\n'; f'Reach out to the Hail team at https://discuss.hail.is/'; f' to request this dataset in your region.'; ); warnings.warn(message, UserWarning, stacklevel=1); return valid_region. def maybe_index(self, indexer_key_expr: StructExpression, all_matches: bool) -> Optional[StructExpression]:; """"""Find the prefix of the given indexer expression that can index the; :class:`.DatasetVersion`, if it exists. Parameter",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:5615,Security,access,access,5615,"s:`.DatasetVersion`, if it exists. Parameters; ----------; indexer_key_expr : :class:`StructExpression`; Row key struct from relational object to be annotated.; all_matches : :obj:`bool`; ``True`` if `indexer_key_expr` key is not unique, indicated in; :attr:`.Dataset.key_properties` for each dataset. If ``True``, value; of `indexer_key_expr` is array of all matches. If ``False``, there; will only be single value of expression. Returns; -------; :class:`StructExpression`, optional; Struct of compatible indexed values, if they exist.; """"""; return hl.read_table(self.url)._maybe_flexindex_table_by_expr(indexer_key_expr, all_matches=all_matches). class Dataset:; """"""Dataset object constructed from name, description, url, key_properties,; and versions specified in JSON configuration file or a provided :obj:`dict`; mapping dataset names to configurations. Parameters; ----------; name : :obj:`str`; Name of dataset.; description : :obj:`str`; Brief description of dataset.; url : :obj:`str`; Cloud URL to access dataset.; key_properties : :class:`set` of :obj:`str`; Set containing key property strings, if present. Valid properties; include ``'gene'`` and ``'unique'``.; versions : :class:`list` of :class:`.DatasetVersion`; List of :class:`.DatasetVersion` objects.; """""". @staticmethod; def from_name_and_json(name: str, doc: dict, region: str, cloud: str) -> Optional['Dataset']:; """"""Create :class:`.Dataset` object from dictionary. Parameters; ----------; name : :obj:`str`; Name of dataset.; doc : :obj:`dict`; Dictionary containing dataset description, url, key_properties, and; versions.; region : :obj:`str`; Region from which to access data, available regions given in; :func:`hail.experimental.DB._valid_regions`.; cloud : :obj:`str`; Cloud platform to access dataset, either ``'gcp'`` or ``'aws'``. Returns; -------; :class:`Dataset`, optional; If versions exist for region returns a :class:`.Dataset` object,; else ``None``.; """"""; assert 'annotation_db' in doc, doc; assert 'key_prope",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:6248,Security,access,access,6248,"s). class Dataset:; """"""Dataset object constructed from name, description, url, key_properties,; and versions specified in JSON configuration file or a provided :obj:`dict`; mapping dataset names to configurations. Parameters; ----------; name : :obj:`str`; Name of dataset.; description : :obj:`str`; Brief description of dataset.; url : :obj:`str`; Cloud URL to access dataset.; key_properties : :class:`set` of :obj:`str`; Set containing key property strings, if present. Valid properties; include ``'gene'`` and ``'unique'``.; versions : :class:`list` of :class:`.DatasetVersion`; List of :class:`.DatasetVersion` objects.; """""". @staticmethod; def from_name_and_json(name: str, doc: dict, region: str, cloud: str) -> Optional['Dataset']:; """"""Create :class:`.Dataset` object from dictionary. Parameters; ----------; name : :obj:`str`; Name of dataset.; doc : :obj:`dict`; Dictionary containing dataset description, url, key_properties, and; versions.; region : :obj:`str`; Region from which to access data, available regions given in; :func:`hail.experimental.DB._valid_regions`.; cloud : :obj:`str`; Cloud platform to access dataset, either ``'gcp'`` or ``'aws'``. Returns; -------; :class:`Dataset`, optional; If versions exist for region returns a :class:`.Dataset` object,; else ``None``.; """"""; assert 'annotation_db' in doc, doc; assert 'key_properties' in doc['annotation_db'], doc['annotation_db']; assert 'description' in doc, doc; assert 'url' in doc, doc; assert 'versions' in doc, doc; key_properties = set(x for x in doc['annotation_db']['key_properties'] if x is not None); versions = [; DatasetVersion.from_json(x, cloud); for x in doc['versions']; if DatasetVersion.from_json(x, cloud) is not None; ]; versions_in_region = DatasetVersion.get_region(name, versions, region); if versions_in_region:; return Dataset(name, doc['description'], doc['url'], key_properties, versions_in_region). def __init__(self, name: str, description: str, url: str, key_properties: Set[str], versions: Li",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:6373,Security,access,access,6373,"ON configuration file or a provided :obj:`dict`; mapping dataset names to configurations. Parameters; ----------; name : :obj:`str`; Name of dataset.; description : :obj:`str`; Brief description of dataset.; url : :obj:`str`; Cloud URL to access dataset.; key_properties : :class:`set` of :obj:`str`; Set containing key property strings, if present. Valid properties; include ``'gene'`` and ``'unique'``.; versions : :class:`list` of :class:`.DatasetVersion`; List of :class:`.DatasetVersion` objects.; """""". @staticmethod; def from_name_and_json(name: str, doc: dict, region: str, cloud: str) -> Optional['Dataset']:; """"""Create :class:`.Dataset` object from dictionary. Parameters; ----------; name : :obj:`str`; Name of dataset.; doc : :obj:`dict`; Dictionary containing dataset description, url, key_properties, and; versions.; region : :obj:`str`; Region from which to access data, available regions given in; :func:`hail.experimental.DB._valid_regions`.; cloud : :obj:`str`; Cloud platform to access dataset, either ``'gcp'`` or ``'aws'``. Returns; -------; :class:`Dataset`, optional; If versions exist for region returns a :class:`.Dataset` object,; else ``None``.; """"""; assert 'annotation_db' in doc, doc; assert 'key_properties' in doc['annotation_db'], doc['annotation_db']; assert 'description' in doc, doc; assert 'url' in doc, doc; assert 'versions' in doc, doc; key_properties = set(x for x in doc['annotation_db']['key_properties'] if x is not None); versions = [; DatasetVersion.from_json(x, cloud); for x in doc['versions']; if DatasetVersion.from_json(x, cloud) is not None; ]; versions_in_region = DatasetVersion.get_region(name, versions, region); if versions_in_region:; return Dataset(name, doc['description'], doc['url'], key_properties, versions_in_region). def __init__(self, name: str, description: str, url: str, key_properties: Set[str], versions: List[DatasetVersion]):; assert set(key_properties).issubset(DB._valid_key_properties); self.name = name; self.description = d",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:2090,Testability,assert,assert,2090,"ary of URLs containing key: value pairs, like; ``cloud: {region: url}`` if using :func:`.from_json` constructor,; or a string with the URL from appropriate region if using the; :func:`.get_region` constructor.; version : :obj:`str`, optional; String of dataset version, if not ``None``.; reference_genome : :obj:`str`, optional; String of dataset reference genome, if not ``None``.; """""". @staticmethod; def from_json(doc: dict, cloud: str) -> Optional['DatasetVersion']:; """"""Create :class:`.DatasetVersion` object from dictionary. Parameters; ----------; doc : :obj:`dict`; Dictionary containing url and version keys.; Value for url is a :obj:`dict` containing key: value pairs, like; ``cloud: {region: url}``.; cloud : :obj:`str`; Cloud platform to access dataset, either ``'gcp'`` or ``'aws'``. Returns; -------; :class:`.DatasetVersion` if available on cloud platform, else ``None``.; """"""; assert 'url' in doc, doc; assert 'version' in doc, doc; assert 'reference_genome' in doc, doc; if cloud in doc['url']:; return DatasetVersion(doc['url'][cloud], doc['version'], doc['reference_genome']); else:; return None. @staticmethod; def get_region(name: str, versions: List['DatasetVersion'], region: str) -> List['DatasetVersion']:; """"""Get versions of a :class:`.Dataset` in the specified region, if they; exist. Parameters; ----------; name : :obj:`str`; Name of dataset.; versions : :class:`list` of :class:`.DatasetVersion`; List of DatasetVersion objects where the value for :attr:`.url`; is a :obj:`dict` containing key: value pairs, like ``region: url``.; region : :obj:`str`; Region from which to access data, available regions given in; :attr:`hail.experimental.DB._valid_regions`. Returns; -------; available_versions : :class:`list` of :class:`.DatasetVersion`; List of available versions of a class:`.Dataset` for region.; """"""; available_versions = []; for version in versions:; if version.in_region(name, region):; version.url = version.url[region]; available_versions.append(version); retu",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:2116,Testability,assert,assert,2116,"ary of URLs containing key: value pairs, like; ``cloud: {region: url}`` if using :func:`.from_json` constructor,; or a string with the URL from appropriate region if using the; :func:`.get_region` constructor.; version : :obj:`str`, optional; String of dataset version, if not ``None``.; reference_genome : :obj:`str`, optional; String of dataset reference genome, if not ``None``.; """""". @staticmethod; def from_json(doc: dict, cloud: str) -> Optional['DatasetVersion']:; """"""Create :class:`.DatasetVersion` object from dictionary. Parameters; ----------; doc : :obj:`dict`; Dictionary containing url and version keys.; Value for url is a :obj:`dict` containing key: value pairs, like; ``cloud: {region: url}``.; cloud : :obj:`str`; Cloud platform to access dataset, either ``'gcp'`` or ``'aws'``. Returns; -------; :class:`.DatasetVersion` if available on cloud platform, else ``None``.; """"""; assert 'url' in doc, doc; assert 'version' in doc, doc; assert 'reference_genome' in doc, doc; if cloud in doc['url']:; return DatasetVersion(doc['url'][cloud], doc['version'], doc['reference_genome']); else:; return None. @staticmethod; def get_region(name: str, versions: List['DatasetVersion'], region: str) -> List['DatasetVersion']:; """"""Get versions of a :class:`.Dataset` in the specified region, if they; exist. Parameters; ----------; name : :obj:`str`; Name of dataset.; versions : :class:`list` of :class:`.DatasetVersion`; List of DatasetVersion objects where the value for :attr:`.url`; is a :obj:`dict` containing key: value pairs, like ``region: url``.; region : :obj:`str`; Region from which to access data, available regions given in; :attr:`hail.experimental.DB._valid_regions`. Returns; -------; available_versions : :class:`list` of :class:`.DatasetVersion`; List of available versions of a class:`.Dataset` for region.; """"""; available_versions = []; for version in versions:; if version.in_region(name, region):; version.url = version.url[region]; available_versions.append(version); retu",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:2146,Testability,assert,assert,2146,"ary of URLs containing key: value pairs, like; ``cloud: {region: url}`` if using :func:`.from_json` constructor,; or a string with the URL from appropriate region if using the; :func:`.get_region` constructor.; version : :obj:`str`, optional; String of dataset version, if not ``None``.; reference_genome : :obj:`str`, optional; String of dataset reference genome, if not ``None``.; """""". @staticmethod; def from_json(doc: dict, cloud: str) -> Optional['DatasetVersion']:; """"""Create :class:`.DatasetVersion` object from dictionary. Parameters; ----------; doc : :obj:`dict`; Dictionary containing url and version keys.; Value for url is a :obj:`dict` containing key: value pairs, like; ``cloud: {region: url}``.; cloud : :obj:`str`; Cloud platform to access dataset, either ``'gcp'`` or ``'aws'``. Returns; -------; :class:`.DatasetVersion` if available on cloud platform, else ``None``.; """"""; assert 'url' in doc, doc; assert 'version' in doc, doc; assert 'reference_genome' in doc, doc; if cloud in doc['url']:; return DatasetVersion(doc['url'][cloud], doc['version'], doc['reference_genome']); else:; return None. @staticmethod; def get_region(name: str, versions: List['DatasetVersion'], region: str) -> List['DatasetVersion']:; """"""Get versions of a :class:`.Dataset` in the specified region, if they; exist. Parameters; ----------; name : :obj:`str`; Name of dataset.; versions : :class:`list` of :class:`.DatasetVersion`; List of DatasetVersion objects where the value for :attr:`.url`; is a :obj:`dict` containing key: value pairs, like ``region: url``.; region : :obj:`str`; Region from which to access data, available regions given in; :attr:`hail.experimental.DB._valid_regions`. Returns; -------; available_versions : :class:`list` of :class:`.DatasetVersion`; List of available versions of a class:`.Dataset` for region.; """"""; available_versions = []; for version in versions:; if version.in_region(name, region):; version.url = version.url[region]; available_versions.append(version); retu",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:6553,Testability,assert,assert,6553,"ings, if present. Valid properties; include ``'gene'`` and ``'unique'``.; versions : :class:`list` of :class:`.DatasetVersion`; List of :class:`.DatasetVersion` objects.; """""". @staticmethod; def from_name_and_json(name: str, doc: dict, region: str, cloud: str) -> Optional['Dataset']:; """"""Create :class:`.Dataset` object from dictionary. Parameters; ----------; name : :obj:`str`; Name of dataset.; doc : :obj:`dict`; Dictionary containing dataset description, url, key_properties, and; versions.; region : :obj:`str`; Region from which to access data, available regions given in; :func:`hail.experimental.DB._valid_regions`.; cloud : :obj:`str`; Cloud platform to access dataset, either ``'gcp'`` or ``'aws'``. Returns; -------; :class:`Dataset`, optional; If versions exist for region returns a :class:`.Dataset` object,; else ``None``.; """"""; assert 'annotation_db' in doc, doc; assert 'key_properties' in doc['annotation_db'], doc['annotation_db']; assert 'description' in doc, doc; assert 'url' in doc, doc; assert 'versions' in doc, doc; key_properties = set(x for x in doc['annotation_db']['key_properties'] if x is not None); versions = [; DatasetVersion.from_json(x, cloud); for x in doc['versions']; if DatasetVersion.from_json(x, cloud) is not None; ]; versions_in_region = DatasetVersion.get_region(name, versions, region); if versions_in_region:; return Dataset(name, doc['description'], doc['url'], key_properties, versions_in_region). def __init__(self, name: str, description: str, url: str, key_properties: Set[str], versions: List[DatasetVersion]):; assert set(key_properties).issubset(DB._valid_key_properties); self.name = name; self.description = description; self.url = url; self.key_properties = key_properties; self.versions = versions. @property; def is_gene_keyed(self) -> bool:; """"""If a :class:`Dataset` is gene keyed. Returns; -------; :obj:`bool`; Whether or not dataset is gene keyed.; """"""; return 'gene' in self.key_properties. def index_compatible_version(self, key_exp",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:6589,Testability,assert,assert,6589,"ings, if present. Valid properties; include ``'gene'`` and ``'unique'``.; versions : :class:`list` of :class:`.DatasetVersion`; List of :class:`.DatasetVersion` objects.; """""". @staticmethod; def from_name_and_json(name: str, doc: dict, region: str, cloud: str) -> Optional['Dataset']:; """"""Create :class:`.Dataset` object from dictionary. Parameters; ----------; name : :obj:`str`; Name of dataset.; doc : :obj:`dict`; Dictionary containing dataset description, url, key_properties, and; versions.; region : :obj:`str`; Region from which to access data, available regions given in; :func:`hail.experimental.DB._valid_regions`.; cloud : :obj:`str`; Cloud platform to access dataset, either ``'gcp'`` or ``'aws'``. Returns; -------; :class:`Dataset`, optional; If versions exist for region returns a :class:`.Dataset` object,; else ``None``.; """"""; assert 'annotation_db' in doc, doc; assert 'key_properties' in doc['annotation_db'], doc['annotation_db']; assert 'description' in doc, doc; assert 'url' in doc, doc; assert 'versions' in doc, doc; key_properties = set(x for x in doc['annotation_db']['key_properties'] if x is not None); versions = [; DatasetVersion.from_json(x, cloud); for x in doc['versions']; if DatasetVersion.from_json(x, cloud) is not None; ]; versions_in_region = DatasetVersion.get_region(name, versions, region); if versions_in_region:; return Dataset(name, doc['description'], doc['url'], key_properties, versions_in_region). def __init__(self, name: str, description: str, url: str, key_properties: Set[str], versions: List[DatasetVersion]):; assert set(key_properties).issubset(DB._valid_key_properties); self.name = name; self.description = description; self.url = url; self.key_properties = key_properties; self.versions = versions. @property; def is_gene_keyed(self) -> bool:; """"""If a :class:`Dataset` is gene keyed. Returns; -------; :obj:`bool`; Whether or not dataset is gene keyed.; """"""; return 'gene' in self.key_properties. def index_compatible_version(self, key_exp",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:6660,Testability,assert,assert,6660,"ings, if present. Valid properties; include ``'gene'`` and ``'unique'``.; versions : :class:`list` of :class:`.DatasetVersion`; List of :class:`.DatasetVersion` objects.; """""". @staticmethod; def from_name_and_json(name: str, doc: dict, region: str, cloud: str) -> Optional['Dataset']:; """"""Create :class:`.Dataset` object from dictionary. Parameters; ----------; name : :obj:`str`; Name of dataset.; doc : :obj:`dict`; Dictionary containing dataset description, url, key_properties, and; versions.; region : :obj:`str`; Region from which to access data, available regions given in; :func:`hail.experimental.DB._valid_regions`.; cloud : :obj:`str`; Cloud platform to access dataset, either ``'gcp'`` or ``'aws'``. Returns; -------; :class:`Dataset`, optional; If versions exist for region returns a :class:`.Dataset` object,; else ``None``.; """"""; assert 'annotation_db' in doc, doc; assert 'key_properties' in doc['annotation_db'], doc['annotation_db']; assert 'description' in doc, doc; assert 'url' in doc, doc; assert 'versions' in doc, doc; key_properties = set(x for x in doc['annotation_db']['key_properties'] if x is not None); versions = [; DatasetVersion.from_json(x, cloud); for x in doc['versions']; if DatasetVersion.from_json(x, cloud) is not None; ]; versions_in_region = DatasetVersion.get_region(name, versions, region); if versions_in_region:; return Dataset(name, doc['description'], doc['url'], key_properties, versions_in_region). def __init__(self, name: str, description: str, url: str, key_properties: Set[str], versions: List[DatasetVersion]):; assert set(key_properties).issubset(DB._valid_key_properties); self.name = name; self.description = description; self.url = url; self.key_properties = key_properties; self.versions = versions. @property; def is_gene_keyed(self) -> bool:; """"""If a :class:`Dataset` is gene keyed. Returns; -------; :obj:`bool`; Whether or not dataset is gene keyed.; """"""; return 'gene' in self.key_properties. def index_compatible_version(self, key_exp",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:6694,Testability,assert,assert,6694,"ings, if present. Valid properties; include ``'gene'`` and ``'unique'``.; versions : :class:`list` of :class:`.DatasetVersion`; List of :class:`.DatasetVersion` objects.; """""". @staticmethod; def from_name_and_json(name: str, doc: dict, region: str, cloud: str) -> Optional['Dataset']:; """"""Create :class:`.Dataset` object from dictionary. Parameters; ----------; name : :obj:`str`; Name of dataset.; doc : :obj:`dict`; Dictionary containing dataset description, url, key_properties, and; versions.; region : :obj:`str`; Region from which to access data, available regions given in; :func:`hail.experimental.DB._valid_regions`.; cloud : :obj:`str`; Cloud platform to access dataset, either ``'gcp'`` or ``'aws'``. Returns; -------; :class:`Dataset`, optional; If versions exist for region returns a :class:`.Dataset` object,; else ``None``.; """"""; assert 'annotation_db' in doc, doc; assert 'key_properties' in doc['annotation_db'], doc['annotation_db']; assert 'description' in doc, doc; assert 'url' in doc, doc; assert 'versions' in doc, doc; key_properties = set(x for x in doc['annotation_db']['key_properties'] if x is not None); versions = [; DatasetVersion.from_json(x, cloud); for x in doc['versions']; if DatasetVersion.from_json(x, cloud) is not None; ]; versions_in_region = DatasetVersion.get_region(name, versions, region); if versions_in_region:; return Dataset(name, doc['description'], doc['url'], key_properties, versions_in_region). def __init__(self, name: str, description: str, url: str, key_properties: Set[str], versions: List[DatasetVersion]):; assert set(key_properties).issubset(DB._valid_key_properties); self.name = name; self.description = description; self.url = url; self.key_properties = key_properties; self.versions = versions. @property; def is_gene_keyed(self) -> bool:; """"""If a :class:`Dataset` is gene keyed. Returns; -------; :obj:`bool`; Whether or not dataset is gene keyed.; """"""; return 'gene' in self.key_properties. def index_compatible_version(self, key_exp",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:6720,Testability,assert,assert,6720,"ings, if present. Valid properties; include ``'gene'`` and ``'unique'``.; versions : :class:`list` of :class:`.DatasetVersion`; List of :class:`.DatasetVersion` objects.; """""". @staticmethod; def from_name_and_json(name: str, doc: dict, region: str, cloud: str) -> Optional['Dataset']:; """"""Create :class:`.Dataset` object from dictionary. Parameters; ----------; name : :obj:`str`; Name of dataset.; doc : :obj:`dict`; Dictionary containing dataset description, url, key_properties, and; versions.; region : :obj:`str`; Region from which to access data, available regions given in; :func:`hail.experimental.DB._valid_regions`.; cloud : :obj:`str`; Cloud platform to access dataset, either ``'gcp'`` or ``'aws'``. Returns; -------; :class:`Dataset`, optional; If versions exist for region returns a :class:`.Dataset` object,; else ``None``.; """"""; assert 'annotation_db' in doc, doc; assert 'key_properties' in doc['annotation_db'], doc['annotation_db']; assert 'description' in doc, doc; assert 'url' in doc, doc; assert 'versions' in doc, doc; key_properties = set(x for x in doc['annotation_db']['key_properties'] if x is not None); versions = [; DatasetVersion.from_json(x, cloud); for x in doc['versions']; if DatasetVersion.from_json(x, cloud) is not None; ]; versions_in_region = DatasetVersion.get_region(name, versions, region); if versions_in_region:; return Dataset(name, doc['description'], doc['url'], key_properties, versions_in_region). def __init__(self, name: str, description: str, url: str, key_properties: Set[str], versions: List[DatasetVersion]):; assert set(key_properties).issubset(DB._valid_key_properties); self.name = name; self.description = description; self.url = url; self.key_properties = key_properties; self.versions = versions. @property; def is_gene_keyed(self) -> bool:; """"""If a :class:`Dataset` is gene keyed. Returns; -------; :obj:`bool`; Whether or not dataset is gene keyed.; """"""; return 'gene' in self.key_properties. def index_compatible_version(self, key_exp",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:7275,Testability,assert,assert,7275,"gion from which to access data, available regions given in; :func:`hail.experimental.DB._valid_regions`.; cloud : :obj:`str`; Cloud platform to access dataset, either ``'gcp'`` or ``'aws'``. Returns; -------; :class:`Dataset`, optional; If versions exist for region returns a :class:`.Dataset` object,; else ``None``.; """"""; assert 'annotation_db' in doc, doc; assert 'key_properties' in doc['annotation_db'], doc['annotation_db']; assert 'description' in doc, doc; assert 'url' in doc, doc; assert 'versions' in doc, doc; key_properties = set(x for x in doc['annotation_db']['key_properties'] if x is not None); versions = [; DatasetVersion.from_json(x, cloud); for x in doc['versions']; if DatasetVersion.from_json(x, cloud) is not None; ]; versions_in_region = DatasetVersion.get_region(name, versions, region); if versions_in_region:; return Dataset(name, doc['description'], doc['url'], key_properties, versions_in_region). def __init__(self, name: str, description: str, url: str, key_properties: Set[str], versions: List[DatasetVersion]):; assert set(key_properties).issubset(DB._valid_key_properties); self.name = name; self.description = description; self.url = url; self.key_properties = key_properties; self.versions = versions. @property; def is_gene_keyed(self) -> bool:; """"""If a :class:`Dataset` is gene keyed. Returns; -------; :obj:`bool`; Whether or not dataset is gene keyed.; """"""; return 'gene' in self.key_properties. def index_compatible_version(self, key_expr: StructExpression) -> StructExpression:; """"""Get index from compatible version of annotation dataset. Checks for compatible indexed values from each :class:`.DatasetVersion`; in :attr:`.Dataset.versions`, where `key_expr` is the row key struct; from the dataset to be annotated. Parameters; ----------; key_expr : :class:`.StructExpression`; Row key struct from relational object to be annotated. Returns; -------; :class:`.StructExpression`; Struct of compatible indexed values.; """"""; all_matches = 'unique' not in self",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/db.html:11832,Testability,assert,assert,11832,"f'Specify valid region parameter,'; f' received: region={region!r}.\n'; f'Valid regions are {DB._valid_regions}.'; ); if cloud not in DB._valid_clouds:; raise ValueError(; f'Specify valid cloud parameter,'; f' received: cloud={cloud!r}.\n'; f'Valid cloud platforms are {DB._valid_clouds}.'; ); if (region, cloud) not in DB._valid_combinations:; raise ValueError(; f'The {region!r} region is not available for'; f' the {cloud!r} cloud platform. '; f'Valid region, cloud combinations are'; f' {DB._valid_combinations}.'; ); if config is not None and url is not None:; raise ValueError(; f'Only specify one of the parameters url and' f' config, received: url={url} and config={config}'; ); if config is None:; if url is None:; config = get_datasets_metadata(); else:; session = external_requests_client_session(); response = retry_response_returning_functions(session.get, url); config = response.json(); assert isinstance(config, dict); elif not isinstance(config, dict):; raise ValueError(f'expected a dict mapping dataset names to ' f'configurations, but found {config}'); config = {k: v for k, v in config.items() if 'annotation_db' in v}; self.region = region; self.cloud = cloud; self.url = url; self.config = config; self.__by_name = {; k: Dataset.from_name_and_json(k, v, region, cloud); for k, v in config.items(); if Dataset.from_name_and_json(k, v, region, cloud) is not None; }. @property; def available_datasets(self) -> List[str]:; """"""List of names of available annotation datasets. Returns; -------; :obj:`list`; List of available annotation datasets.; """"""; return sorted(self.__by_name.keys()). @staticmethod; def _row_lens(rel: Union[Table, MatrixTable]) -> Union[TableRows, MatrixRows]:; """"""Get row lens from relational object. Parameters; ----------; rel : :class:`Table` or :class:`MatrixTable`. Returns; -------; :class:`TableRows` or :class:`MatrixRows`; """"""; if isinstance(rel, MatrixTable):; return MatrixRows(rel); elif isinstance(rel, Table):; return TableRows(rel); else:; rais",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/db.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/db.html
https://hail.is/docs/0.2/_modules/hail/experimental/export_entries_by_col.html:3668,Deployability,update,updated,3668," wheel 712 Jan 25 17:19 index.tsv; -rw-r--r-- 1 hail-dev wheel 712 Jan 25 17:19 part-00.tsv.bgz; -rw-r--r-- 1 hail-dev wheel 712 Jan 25 17:19 part-01.tsv.bgz; -rw-r--r-- 1 hail-dev wheel 712 Jan 25 17:19 part-02.tsv.bgz; -rw-r--r-- 1 hail-dev wheel 712 Jan 25 17:19 part-03.tsv.bgz; -rw-r--r-- 1 hail-dev wheel 712 Jan 25 17:19 part-04.tsv.bgz; -rw-r--r-- 1 hail-dev wheel 712 Jan 25 17:19 part-05.tsv.bgz; -rw-r--r-- 1 hail-dev wheel 712 Jan 25 17:19 part-06.tsv.bgz; -rw-r--r-- 1 hail-dev wheel 712 Jan 25 17:19 part-07.tsv.bgz; -rw-r--r-- 1 hail-dev wheel 712 Jan 25 17:19 part-08.tsv.bgz; -rw-r--r-- 1 hail-dev wheel 712 Jan 25 17:19 part-09.tsv.bgz. $ zcat output/cols_files/part-00.tsv.bgz; #{""col_idx"":0}; row_idx x; 0 6.2501e-02; 1 7.0083e-01; 2 3.6452e-01; 3 4.4170e-01; 4 7.9177e-02; 5 6.2392e-01; 6 5.9920e-01; 7 9.7540e-01; 8 8.4848e-01; 9 3.7423e-01. Due to overhead and file system limits related to having large numbers; of open files, this function will iteratively export groups of columns.; The `batch_size` parameter can control the size of these groups. Parameters; ----------; mt : :class:`.MatrixTable`; path : :obj:`int`; Path (directory to write to.; batch_size : :obj:`int`; Number of columns to write per iteration.; bgzip : :obj:`bool`; BGZip output files.; header_json_in_file : :obj:`bool`; Include JSON header in each component file (if False, only written to index.tsv); """"""; if use_string_key_as_file_name and not (len(mt.col_key) == 1 and mt.col_key[0].dtype == hl.tstr):; raise ValueError(; f'parameter ""use_string_key_as_file_name"" requires a single string column key, found {list(mt.col_key.dtype.values())}'; ); hl.utils.java.Env.backend().execute(; hl.ir.MatrixToValueApply(; mt._mir,; {; 'name': 'MatrixExportEntriesByCol',; 'parallelism': batch_size,; 'path': path,; 'bgzip': bgzip,; 'headerJsonInFile': header_json_in_file,; 'useStringKeyAsFileName': use_string_key_as_file_name,; },; ); ). © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/export_entries_by_col.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/export_entries_by_col.html
https://hail.is/docs/0.2/_modules/hail/experimental/expressions.html:2719,Deployability,update,updated,2719," path=str, overwrite=bool); def write_expression(expr, path, overwrite=False):; """"""Write an Expression. In the same vein as Python's pickle, write out an expression; that does not have a source (such as one that comes from; Table.aggregate with _localize=False). Example; -------; >>> ht = hl.utils.range_table(100).annotate(x=hl.rand_norm()); >>> mean_norm = ht.aggregate(hl.agg.mean(ht.x), _localize=False); >>> mean_norm; >>> hl.eval(mean_norm); >>> hl.experimental.write_expression(mean_norm, 'output/expression.he'). Parameters; ----------. expr : :class:`~.Expression`; Expression to write.; path : :class:`str`; Path to which to write expression.; Suggested extension: .he (hail expression).; overwrite : :obj:`bool`; If ``True``, overwrite an existing file at the destination. Returns; -------; None; """"""; source = expr._indices.source; if source is not None:; analyze('write_expression.expr', expr, source._global_indices); source = source.select_globals(__expr=expr); expr = source.index_globals().__expr; hl.utils.range_table(1).filter(False).key_by().drop('idx').annotate_globals(expr=expr).write(; path, overwrite=overwrite; ). [docs]@typecheck(path=str, _assert_type=nullable(hail_type)); def read_expression(path, _assert_type=None):; """"""Read an :class:`~.Expression` written with :func:`.experimental.write_expression`. Example; -------; >>> hl.experimental.write_expression(hl.array([1, 2]), 'output/test_expression.he'); >>> expression = hl.experimental.read_expression('output/test_expression.he'); >>> hl.eval(expression). Parameters; ----------. path : :class:`str`; File to read. Returns; -------; :class:`~.Expression`; """"""; _assert_table_type = None; _load_refs = True; if _assert_type:; _assert_table_type = ttable(hl.tstruct(expr=_assert_type), row_type=hl.tstruct(), row_key=[]); _load_refs = False; return hl.read_table(path, _assert_type=_assert_table_type, _load_refs=_load_refs).index_globals().expr. © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/expressions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/expressions.html
https://hail.is/docs/0.2/_modules/hail/experimental/filtering_allele_frequency.html:2325,Deployability,update,updated,2325,"; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.experimental.filtering_allele_frequency. Source code for hail.experimental.filtering_allele_frequency; from hail.expr.expressions import Float64Expression, expr_float64, expr_int32; from hail.expr.functions import _func; from hail.expr.types import tfloat64; from hail.typecheck import typecheck. [docs]@typecheck(ac=expr_int32, an=expr_int32, ci=expr_float64); def filtering_allele_frequency(ac, an, ci) -> Float64Expression:; """"""; Computes a filtering allele frequency (described below); for `ac` and `an` with confidence `ci`. The filtering allele frequency is the highest true population allele frequency; for which the upper bound of the `ci` (confidence interval) of allele count; under a Poisson distribution is still less than the variant's observed; `ac` (allele count) in the reference sample, given an `an` (allele number). This function defines a ""filtering AF"" that represents; the threshold disease-specific ""maximum credible AF"" at or below which; the disease could not plausibly be caused by that variant. A variant with; a filtering AF >= the maximum credible AF for the disease under consideration; should be filtered, while a variant with a filtering AF below the maximum; credible remains a candidate. This filtering AF is not disease-specific:; it can be applied to any disease of interest by comparing with a; user-defined disease-specific maximum credible AF. For more details, see: `Whiffin et al., 2017 <https://www.nature.com/articles/gim201726>`__. Parameters; ----------; ac : int or :class:`.Expression` of type :py:data:`.tint32`; an : int or :class:`.Expression` of type :py:data:`.tint32`; ci : float or :class:`.Expression` of type :py:data:`.tfloat64`. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`; """"""; return _func(""filtering_allele_frequency"", tfloat64, ac, an, ci). © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/filtering_allele_frequency.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/filtering_allele_frequency.html
https://hail.is/docs/0.2/_modules/hail/experimental/full_outer_join_mt.html:5391,Availability,error,error,5391," = right.localize_entries('right_entries', 'right_cols'). ht = left_t.join(right_t, how='outer'); ht = ht.annotate_globals(; left_keys=hl.group_by(; lambda t: t[0],; hl.enumerate(ht.left_cols.map(lambda x: hl.tuple([x[f] for f in left.col_key])), index_first=False),; ).map_values(lambda elts: elts.map(lambda t: t[1])),; right_keys=hl.group_by(; lambda t: t[0],; hl.enumerate(ht.right_cols.map(lambda x: hl.tuple([x[f] for f in right.col_key])), index_first=False),; ).map_values(lambda elts: elts.map(lambda t: t[1])),; ); ht = ht.annotate_globals(; key_indices=hl.array(ht.left_keys.key_set().union(ht.right_keys.key_set())); .map(lambda k: hl.struct(k=k, left_indices=ht.left_keys.get(k), right_indices=ht.right_keys.get(k))); .flatmap(; lambda s: hl.case(); .when(; hl.is_defined(s.left_indices) & hl.is_defined(s.right_indices),; hl.range(0, s.left_indices.length()).flatmap(; lambda i: hl.range(0, s.right_indices.length()).map(; lambda j: hl.struct(k=s.k, left_index=s.left_indices[i], right_index=s.right_indices[j]); ); ),; ); .when(; hl.is_defined(s.left_indices),; s.left_indices.map(lambda elt: hl.struct(k=s.k, left_index=elt, right_index=hl.missing('int32'))),; ); .when(; hl.is_defined(s.right_indices),; s.right_indices.map(lambda elt: hl.struct(k=s.k, left_index=hl.missing('int32'), right_index=elt)),; ); .or_error('assertion error'); ); ); ht = ht.annotate(; __entries=ht.key_indices.map(; lambda s: hl.struct(left_entry=ht.left_entries[s.left_index], right_entry=ht.right_entries[s.right_index]); ); ); ht = ht.annotate_globals(; __cols=ht.key_indices.map(; lambda s: hl.struct(; **{f: s.k[i] for i, f in enumerate(left.col_key)},; left_col=ht.left_cols[s.left_index],; right_col=ht.right_cols[s.right_index],; ); ); ); ht = ht.drop('left_entries', 'left_cols', 'left_keys', 'right_entries', 'right_cols', 'right_keys', 'key_indices'); return ht._unlocalize_entries('__entries', '__cols', list(left.col_key)). © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/full_outer_join_mt.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/full_outer_join_mt.html
https://hail.is/docs/0.2/_modules/hail/experimental/full_outer_join_mt.html:6017,Deployability,update,updated,6017," = right.localize_entries('right_entries', 'right_cols'). ht = left_t.join(right_t, how='outer'); ht = ht.annotate_globals(; left_keys=hl.group_by(; lambda t: t[0],; hl.enumerate(ht.left_cols.map(lambda x: hl.tuple([x[f] for f in left.col_key])), index_first=False),; ).map_values(lambda elts: elts.map(lambda t: t[1])),; right_keys=hl.group_by(; lambda t: t[0],; hl.enumerate(ht.right_cols.map(lambda x: hl.tuple([x[f] for f in right.col_key])), index_first=False),; ).map_values(lambda elts: elts.map(lambda t: t[1])),; ); ht = ht.annotate_globals(; key_indices=hl.array(ht.left_keys.key_set().union(ht.right_keys.key_set())); .map(lambda k: hl.struct(k=k, left_indices=ht.left_keys.get(k), right_indices=ht.right_keys.get(k))); .flatmap(; lambda s: hl.case(); .when(; hl.is_defined(s.left_indices) & hl.is_defined(s.right_indices),; hl.range(0, s.left_indices.length()).flatmap(; lambda i: hl.range(0, s.right_indices.length()).map(; lambda j: hl.struct(k=s.k, left_index=s.left_indices[i], right_index=s.right_indices[j]); ); ),; ); .when(; hl.is_defined(s.left_indices),; s.left_indices.map(lambda elt: hl.struct(k=s.k, left_index=elt, right_index=hl.missing('int32'))),; ); .when(; hl.is_defined(s.right_indices),; s.right_indices.map(lambda elt: hl.struct(k=s.k, left_index=hl.missing('int32'), right_index=elt)),; ); .or_error('assertion error'); ); ); ht = ht.annotate(; __entries=ht.key_indices.map(; lambda s: hl.struct(left_entry=ht.left_entries[s.left_index], right_entry=ht.right_entries[s.right_index]); ); ); ht = ht.annotate_globals(; __cols=ht.key_indices.map(; lambda s: hl.struct(; **{f: s.k[i] for i, f in enumerate(left.col_key)},; left_col=ht.left_cols[s.left_index],; right_col=ht.right_cols[s.right_index],; ); ); ); ht = ht.drop('left_entries', 'left_cols', 'left_keys', 'right_entries', 'right_cols', 'right_keys', 'key_indices'); return ht._unlocalize_entries('__entries', '__cols', list(left.col_key)). © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/full_outer_join_mt.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/full_outer_join_mt.html
https://hail.is/docs/0.2/_modules/hail/experimental/full_outer_join_mt.html:5381,Testability,assert,assertion,5381," = right.localize_entries('right_entries', 'right_cols'). ht = left_t.join(right_t, how='outer'); ht = ht.annotate_globals(; left_keys=hl.group_by(; lambda t: t[0],; hl.enumerate(ht.left_cols.map(lambda x: hl.tuple([x[f] for f in left.col_key])), index_first=False),; ).map_values(lambda elts: elts.map(lambda t: t[1])),; right_keys=hl.group_by(; lambda t: t[0],; hl.enumerate(ht.right_cols.map(lambda x: hl.tuple([x[f] for f in right.col_key])), index_first=False),; ).map_values(lambda elts: elts.map(lambda t: t[1])),; ); ht = ht.annotate_globals(; key_indices=hl.array(ht.left_keys.key_set().union(ht.right_keys.key_set())); .map(lambda k: hl.struct(k=k, left_indices=ht.left_keys.get(k), right_indices=ht.right_keys.get(k))); .flatmap(; lambda s: hl.case(); .when(; hl.is_defined(s.left_indices) & hl.is_defined(s.right_indices),; hl.range(0, s.left_indices.length()).flatmap(; lambda i: hl.range(0, s.right_indices.length()).map(; lambda j: hl.struct(k=s.k, left_index=s.left_indices[i], right_index=s.right_indices[j]); ); ),; ); .when(; hl.is_defined(s.left_indices),; s.left_indices.map(lambda elt: hl.struct(k=s.k, left_index=elt, right_index=hl.missing('int32'))),; ); .when(; hl.is_defined(s.right_indices),; s.right_indices.map(lambda elt: hl.struct(k=s.k, left_index=hl.missing('int32'), right_index=elt)),; ); .or_error('assertion error'); ); ); ht = ht.annotate(; __entries=ht.key_indices.map(; lambda s: hl.struct(left_entry=ht.left_entries[s.left_index], right_entry=ht.right_entries[s.right_index]); ); ); ht = ht.annotate_globals(; __cols=ht.key_indices.map(; lambda s: hl.struct(; **{f: s.k[i] for i, f in enumerate(left.col_key)},; left_col=ht.left_cols[s.left_index],; right_col=ht.right_cols[s.right_index],; ); ); ); ht = ht.drop('left_entries', 'left_cols', 'left_keys', 'right_entries', 'right_cols', 'right_keys', 'key_indices'); return ht._unlocalize_entries('__entries', '__cols', list(left.col_key)). © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/full_outer_join_mt.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/full_outer_join_mt.html
https://hail.is/docs/0.2/_modules/hail/experimental/import_gtf.html:5057,Availability,checkpoint,checkpoint,5057," : :obj:`bool`; If ``True``, load gzipped files serially on one core. This should; be used only when absolutely necessary, as processing time will be; increased due to lack of parallelism. Returns; -------; :class:`.Table`; """""". ht = hl.import_table(; path,; min_partitions=min_partitions,; comment='#',; no_header=True,; types={'f3': hl.tint, 'f4': hl.tint, 'f5': hl.tfloat, 'f7': hl.tint},; missing='.',; delimiter='\t',; force_bgz=force_bgz,; force=force,; ). ht = ht.rename({; 'f0': 'seqname',; 'f1': 'source',; 'f2': 'feature',; 'f3': 'start',; 'f4': 'end',; 'f5': 'score',; 'f6': 'strand',; 'f7': 'frame',; 'f8': 'attribute',; }). def parse_attributes(unparsed_attributes):; def parse_attribute(attribute):; key_and_value = attribute.split(' '); key = key_and_value[0]; value = key_and_value[1]; return (key, value.replace('""|;\\$', '')). return hl.dict(unparsed_attributes.split('; ').map(parse_attribute)). ht = ht.annotate(attribute=parse_attributes(ht['attribute'])). ht = ht.checkpoint(new_temp_file()). attributes = ht.aggregate(hl.agg.explode(lambda x: hl.agg.collect_as_set(x), ht['attribute'].keys())). ht = ht.transmute(**{x: hl.or_missing(ht['attribute'].contains(x), ht['attribute'][x]) for x in attributes if x}). if reference_genome:; if reference_genome.name == 'GRCh37':; ht = ht.annotate(; seqname=hl.case(); .when((ht['seqname'] == 'M') | (ht['seqname'] == 'chrM'), 'MT'); .when(ht['seqname'].startswith('chr'), ht['seqname'].replace('^chr', '')); .default(ht['seqname']); ); else:; ht = ht.annotate(; seqname=hl.case(); .when(ht['seqname'].startswith('HLA'), ht['seqname']); .when(ht['seqname'].startswith('chrHLA'), ht['seqname'].replace('^chr', '')); .when(ht['seqname'].startswith('chr'), ht['seqname']); .default('chr' + ht['seqname']); ); if skip_invalid_contigs:; valid_contigs = hl.literal(set(reference_genome.contigs)); ht = ht.filter(valid_contigs.contains(ht['seqname'])); ht = ht.transmute(; interval=hl.locus_interval(; ht['seqname'],; ht['start'],; ht['end'],; ",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/import_gtf.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/import_gtf.html
https://hail.is/docs/0.2/_modules/hail/experimental/import_gtf.html:6975,Availability,avail,available,6975,"); ht = ht.transmute(; interval=hl.locus_interval(; ht['seqname'],; ht['start'],; ht['end'],; includes_start=True,; includes_end=True,; reference_genome=reference_genome,; ); ); else:; ht = ht.transmute(; interval=hl.interval(; hl.struct(seqname=ht['seqname'], position=ht['start']),; hl.struct(seqname=ht['seqname'], position=ht['end']),; includes_start=True,; includes_end=True,; ); ). ht = ht.key_by('interval'). return ht. [docs]@typecheck(; gene_symbols=nullable(sequenceof(str)),; gene_ids=nullable(sequenceof(str)),; transcript_ids=nullable(sequenceof(str)),; verbose=bool,; reference_genome=nullable(reference_genome_type),; gtf_file=nullable(str),; ); def get_gene_intervals(; gene_symbols=None, gene_ids=None, transcript_ids=None, verbose=True, reference_genome=None, gtf_file=None; ):; """"""Get intervals of genes or transcripts. Get the boundaries of genes or transcripts from a GTF file, for quick filtering of a Table or MatrixTable. On Google Cloud platform:; Gencode v19 (GRCh37) GTF available at: gs://hail-common/references/gencode/gencode.v19.annotation.gtf.bgz; Gencode v29 (GRCh38) GTF available at: gs://hail-common/references/gencode/gencode.v29.annotation.gtf.bgz. Example; -------; >>> hl.filter_intervals(ht, get_gene_intervals(gene_symbols=['PCSK9'], reference_genome='GRCh37')) # doctest: +SKIP. Parameters; ----------. gene_symbols : :obj:`list` of :class:`str`, optional; Gene symbols (e.g. PCSK9).; gene_ids : :obj:`list` of :class:`str`, optional; Gene IDs (e.g. ENSG00000223972).; transcript_ids : :obj:`list` of :class:`str`, optional; Transcript IDs (e.g. ENSG00000223972).; verbose : :obj:`bool`; If ``True``, print which genes and transcripts were matched in the GTF file.; reference_genome : :class:`str` or :class:`.ReferenceGenome`, optional; Reference genome to use (passed along to import_gtf).; gtf_file : :class:`str`; GTF file to load. If none is provided, but `reference_genome` is one of; `GRCh37` or `GRCh38`, a default will be used (on Google Cloud Platf",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/import_gtf.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/import_gtf.html
https://hail.is/docs/0.2/_modules/hail/experimental/import_gtf.html:7082,Availability,avail,available,7082,"ludes_end=True,; reference_genome=reference_genome,; ); ); else:; ht = ht.transmute(; interval=hl.interval(; hl.struct(seqname=ht['seqname'], position=ht['start']),; hl.struct(seqname=ht['seqname'], position=ht['end']),; includes_start=True,; includes_end=True,; ); ). ht = ht.key_by('interval'). return ht. [docs]@typecheck(; gene_symbols=nullable(sequenceof(str)),; gene_ids=nullable(sequenceof(str)),; transcript_ids=nullable(sequenceof(str)),; verbose=bool,; reference_genome=nullable(reference_genome_type),; gtf_file=nullable(str),; ); def get_gene_intervals(; gene_symbols=None, gene_ids=None, transcript_ids=None, verbose=True, reference_genome=None, gtf_file=None; ):; """"""Get intervals of genes or transcripts. Get the boundaries of genes or transcripts from a GTF file, for quick filtering of a Table or MatrixTable. On Google Cloud platform:; Gencode v19 (GRCh37) GTF available at: gs://hail-common/references/gencode/gencode.v19.annotation.gtf.bgz; Gencode v29 (GRCh38) GTF available at: gs://hail-common/references/gencode/gencode.v29.annotation.gtf.bgz. Example; -------; >>> hl.filter_intervals(ht, get_gene_intervals(gene_symbols=['PCSK9'], reference_genome='GRCh37')) # doctest: +SKIP. Parameters; ----------. gene_symbols : :obj:`list` of :class:`str`, optional; Gene symbols (e.g. PCSK9).; gene_ids : :obj:`list` of :class:`str`, optional; Gene IDs (e.g. ENSG00000223972).; transcript_ids : :obj:`list` of :class:`str`, optional; Transcript IDs (e.g. ENSG00000223972).; verbose : :obj:`bool`; If ``True``, print which genes and transcripts were matched in the GTF file.; reference_genome : :class:`str` or :class:`.ReferenceGenome`, optional; Reference genome to use (passed along to import_gtf).; gtf_file : :class:`str`; GTF file to load. If none is provided, but `reference_genome` is one of; `GRCh37` or `GRCh38`, a default will be used (on Google Cloud Platform). Returns; -------; :obj:`list` of :class:`.Interval`; """"""; if gene_symbols is None and gene_ids is None and trans",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/import_gtf.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/import_gtf.html
https://hail.is/docs/0.2/_modules/hail/experimental/import_gtf.html:10360,Deployability,update,updated,10360,"ene_symbols)); if gene_ids:; criteria.append(hl.any(lambda y: (ht.feature == 'gene') & (ht.gene_id == y.split('\\.')[0]), gene_ids)); if transcript_ids:; criteria.append(; hl.any(lambda y: (ht.feature == 'transcript') & (ht.transcript_id == y.split('\\.')[0]), transcript_ids); ). ht = ht.filter(functools.reduce(operator.ior, criteria)); gene_info = ht.aggregate(hl.agg.collect((ht.feature, ht.gene_name, ht.gene_id, ht.transcript_id, ht.interval))); if verbose:; info(; f'get_gene_intervals found {len(gene_info)} entries:\n'; + ""\n"".join(map(lambda x: f'{x[0]}: {x[1]} ({x[2] if x[0] == ""gene"" else x[3]})', gene_info)); ); intervals = list(map(lambda x: x[-1], gene_info)); return intervals. def _load_gencode_gtf(gtf_file=None, reference_genome=None):; """"""; Get Gencode GTF (from file or reference genome). Parameters; ----------; reference_genome : :class:`.ReferenceGenome`, optional; Reference genome to use (passed along to import_gtf).; gtf_file : :class:`str`; GTF file to load. If none is provided, but `reference_genome` is one of; `GRCh37` or `GRCh38`, a default will be used (on Google Cloud Platform). Returns; -------; :class:`.Table`; """"""; GTFS = {; 'GRCh37': 'gs://hail-common/references/gencode/gencode.v19.annotation.gtf.bgz',; 'GRCh38': 'gs://hail-common/references/gencode/gencode.v29.annotation.gtf.bgz',; }; if reference_genome is None:; reference_genome = hl.default_reference().name; else:; reference_genome = reference_genome.name; if gtf_file is None:; gtf_file = GTFS.get(reference_genome); if gtf_file is None:; raise ValueError(; 'get_gene_intervals requires a GTF file, or the reference genome be one of GRCh37 or GRCh38 (when on Google Cloud Platform)'; ); ht = hl.experimental.import_gtf(; gtf_file, reference_genome=reference_genome, skip_invalid_contigs=True, min_partitions=12; ); ht = ht.annotate(gene_id=ht.gene_id.split('\\.')[0], transcript_id=ht.transcript_id.split('\\.')[0]); return ht. © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/import_gtf.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/import_gtf.html
https://hail.is/docs/0.2/_modules/hail/experimental/import_gtf.html:8694,Energy Efficiency,reduce,reduce,8694," : :class:`str` or :class:`.ReferenceGenome`, optional; Reference genome to use (passed along to import_gtf).; gtf_file : :class:`str`; GTF file to load. If none is provided, but `reference_genome` is one of; `GRCh37` or `GRCh38`, a default will be used (on Google Cloud Platform). Returns; -------; :obj:`list` of :class:`.Interval`; """"""; if gene_symbols is None and gene_ids is None and transcript_ids is None:; raise ValueError('get_gene_intervals requires at least one of gene_symbols, gene_ids, or transcript_ids'); ht = _load_gencode_gtf(gtf_file, reference_genome); criteria = []; if gene_symbols:; criteria.append(hl.any(lambda y: (ht.feature == 'gene') & (ht.gene_name == y), gene_symbols)); if gene_ids:; criteria.append(hl.any(lambda y: (ht.feature == 'gene') & (ht.gene_id == y.split('\\.')[0]), gene_ids)); if transcript_ids:; criteria.append(; hl.any(lambda y: (ht.feature == 'transcript') & (ht.transcript_id == y.split('\\.')[0]), transcript_ids); ). ht = ht.filter(functools.reduce(operator.ior, criteria)); gene_info = ht.aggregate(hl.agg.collect((ht.feature, ht.gene_name, ht.gene_id, ht.transcript_id, ht.interval))); if verbose:; info(; f'get_gene_intervals found {len(gene_info)} entries:\n'; + ""\n"".join(map(lambda x: f'{x[0]}: {x[1]} ({x[2] if x[0] == ""gene"" else x[3]})', gene_info)); ); intervals = list(map(lambda x: x[-1], gene_info)); return intervals. def _load_gencode_gtf(gtf_file=None, reference_genome=None):; """"""; Get Gencode GTF (from file or reference genome). Parameters; ----------; reference_genome : :class:`.ReferenceGenome`, optional; Reference genome to use (passed along to import_gtf).; gtf_file : :class:`str`; GTF file to load. If none is provided, but `reference_genome` is one of; `GRCh37` or `GRCh38`, a default will be used (on Google Cloud Platform). Returns; -------; :class:`.Table`; """"""; GTFS = {; 'GRCh37': 'gs://hail-common/references/gencode/gencode.v19.annotation.gtf.bgz',; 'GRCh38': 'gs://hail-common/references/gencode/gencode.v29.annota",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/import_gtf.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/import_gtf.html
https://hail.is/docs/0.2/_modules/hail/experimental/import_gtf.html:3800,Performance,load,load,3800,"Row fields:; 'source': str; 'feature': str; 'score': float64; 'strand': str; 'frame': int32; 'gene_type': str; 'exon_id': str; 'havana_transcript': str; 'level': str; 'transcript_name': str; 'gene_status': str; 'gene_id': str; 'transcript_type': str; 'tag': str; 'transcript_status': str; 'gene_name': str; 'transcript_id': str; 'exon_number': str; 'havana_gene': str; 'interval': interval<locus<GRCh37>>; ----------------------------------------; Key: ['interval']; ----------------------------------------. Parameters; ----------. path : :class:`str`; File to import.; reference_genome : :class:`str` or :class:`.ReferenceGenome`, optional; Reference genome to use.; skip_invalid_contigs : :obj:`bool`; If ``True`` and `reference_genome` is not ``None``, skip lines where; ``seqname`` is not consistent with the reference genome.; min_partitions : :obj:`int` or :obj:`None`; Minimum number of partitions (passed to import_table).; force_bgz : :obj:`bool`; If ``True``, load files as blocked gzip files, assuming; that they were actually compressed using the BGZ codec. This option is; useful when the file extension is not ``'.bgz'``, but the file is; blocked gzip, so that the file can be read in parallel and not on a; single node.; force : :obj:`bool`; If ``True``, load gzipped files serially on one core. This should; be used only when absolutely necessary, as processing time will be; increased due to lack of parallelism. Returns; -------; :class:`.Table`; """""". ht = hl.import_table(; path,; min_partitions=min_partitions,; comment='#',; no_header=True,; types={'f3': hl.tint, 'f4': hl.tint, 'f5': hl.tfloat, 'f7': hl.tint},; missing='.',; delimiter='\t',; force_bgz=force_bgz,; force=force,; ). ht = ht.rename({; 'f0': 'seqname',; 'f1': 'source',; 'f2': 'feature',; 'f3': 'start',; 'f4': 'end',; 'f5': 'score',; 'f6': 'strand',; 'f7': 'frame',; 'f8': 'attribute',; }). def parse_attributes(unparsed_attributes):; def parse_attribute(attribute):; key_and_value = attribute.split(' '); key = k",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/import_gtf.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/import_gtf.html
https://hail.is/docs/0.2/_modules/hail/experimental/import_gtf.html:4100,Performance,load,load,4100,"t_status': str; 'gene_name': str; 'transcript_id': str; 'exon_number': str; 'havana_gene': str; 'interval': interval<locus<GRCh37>>; ----------------------------------------; Key: ['interval']; ----------------------------------------. Parameters; ----------. path : :class:`str`; File to import.; reference_genome : :class:`str` or :class:`.ReferenceGenome`, optional; Reference genome to use.; skip_invalid_contigs : :obj:`bool`; If ``True`` and `reference_genome` is not ``None``, skip lines where; ``seqname`` is not consistent with the reference genome.; min_partitions : :obj:`int` or :obj:`None`; Minimum number of partitions (passed to import_table).; force_bgz : :obj:`bool`; If ``True``, load files as blocked gzip files, assuming; that they were actually compressed using the BGZ codec. This option is; useful when the file extension is not ``'.bgz'``, but the file is; blocked gzip, so that the file can be read in parallel and not on a; single node.; force : :obj:`bool`; If ``True``, load gzipped files serially on one core. This should; be used only when absolutely necessary, as processing time will be; increased due to lack of parallelism. Returns; -------; :class:`.Table`; """""". ht = hl.import_table(; path,; min_partitions=min_partitions,; comment='#',; no_header=True,; types={'f3': hl.tint, 'f4': hl.tint, 'f5': hl.tfloat, 'f7': hl.tint},; missing='.',; delimiter='\t',; force_bgz=force_bgz,; force=force,; ). ht = ht.rename({; 'f0': 'seqname',; 'f1': 'source',; 'f2': 'feature',; 'f3': 'start',; 'f4': 'end',; 'f5': 'score',; 'f6': 'strand',; 'f7': 'frame',; 'f8': 'attribute',; }). def parse_attributes(unparsed_attributes):; def parse_attribute(attribute):; key_and_value = attribute.split(' '); key = key_and_value[0]; value = key_and_value[1]; return (key, value.replace('""|;\\$', '')). return hl.dict(unparsed_attributes.split('; ').map(parse_attribute)). ht = ht.annotate(attribute=parse_attributes(ht['attribute'])). ht = ht.checkpoint(new_temp_file()). attributes = ht.",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/import_gtf.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/import_gtf.html
https://hail.is/docs/0.2/_modules/hail/experimental/import_gtf.html:7850,Performance,load,load,7850,"s of genes or transcripts from a GTF file, for quick filtering of a Table or MatrixTable. On Google Cloud platform:; Gencode v19 (GRCh37) GTF available at: gs://hail-common/references/gencode/gencode.v19.annotation.gtf.bgz; Gencode v29 (GRCh38) GTF available at: gs://hail-common/references/gencode/gencode.v29.annotation.gtf.bgz. Example; -------; >>> hl.filter_intervals(ht, get_gene_intervals(gene_symbols=['PCSK9'], reference_genome='GRCh37')) # doctest: +SKIP. Parameters; ----------. gene_symbols : :obj:`list` of :class:`str`, optional; Gene symbols (e.g. PCSK9).; gene_ids : :obj:`list` of :class:`str`, optional; Gene IDs (e.g. ENSG00000223972).; transcript_ids : :obj:`list` of :class:`str`, optional; Transcript IDs (e.g. ENSG00000223972).; verbose : :obj:`bool`; If ``True``, print which genes and transcripts were matched in the GTF file.; reference_genome : :class:`str` or :class:`.ReferenceGenome`, optional; Reference genome to use (passed along to import_gtf).; gtf_file : :class:`str`; GTF file to load. If none is provided, but `reference_genome` is one of; `GRCh37` or `GRCh38`, a default will be used (on Google Cloud Platform). Returns; -------; :obj:`list` of :class:`.Interval`; """"""; if gene_symbols is None and gene_ids is None and transcript_ids is None:; raise ValueError('get_gene_intervals requires at least one of gene_symbols, gene_ids, or transcript_ids'); ht = _load_gencode_gtf(gtf_file, reference_genome); criteria = []; if gene_symbols:; criteria.append(hl.any(lambda y: (ht.feature == 'gene') & (ht.gene_name == y), gene_symbols)); if gene_ids:; criteria.append(hl.any(lambda y: (ht.feature == 'gene') & (ht.gene_id == y.split('\\.')[0]), gene_ids)); if transcript_ids:; criteria.append(; hl.any(lambda y: (ht.feature == 'transcript') & (ht.transcript_id == y.split('\\.')[0]), transcript_ids); ). ht = ht.filter(functools.reduce(operator.ior, criteria)); gene_info = ht.aggregate(hl.agg.collect((ht.feature, ht.gene_name, ht.gene_id, ht.transcript_id, ht.interv",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/import_gtf.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/import_gtf.html
https://hail.is/docs/0.2/_modules/hail/experimental/import_gtf.html:9372,Performance,load,load,9372," 'gene') & (ht.gene_name == y), gene_symbols)); if gene_ids:; criteria.append(hl.any(lambda y: (ht.feature == 'gene') & (ht.gene_id == y.split('\\.')[0]), gene_ids)); if transcript_ids:; criteria.append(; hl.any(lambda y: (ht.feature == 'transcript') & (ht.transcript_id == y.split('\\.')[0]), transcript_ids); ). ht = ht.filter(functools.reduce(operator.ior, criteria)); gene_info = ht.aggregate(hl.agg.collect((ht.feature, ht.gene_name, ht.gene_id, ht.transcript_id, ht.interval))); if verbose:; info(; f'get_gene_intervals found {len(gene_info)} entries:\n'; + ""\n"".join(map(lambda x: f'{x[0]}: {x[1]} ({x[2] if x[0] == ""gene"" else x[3]})', gene_info)); ); intervals = list(map(lambda x: x[-1], gene_info)); return intervals. def _load_gencode_gtf(gtf_file=None, reference_genome=None):; """"""; Get Gencode GTF (from file or reference genome). Parameters; ----------; reference_genome : :class:`.ReferenceGenome`, optional; Reference genome to use (passed along to import_gtf).; gtf_file : :class:`str`; GTF file to load. If none is provided, but `reference_genome` is one of; `GRCh37` or `GRCh38`, a default will be used (on Google Cloud Platform). Returns; -------; :class:`.Table`; """"""; GTFS = {; 'GRCh37': 'gs://hail-common/references/gencode/gencode.v19.annotation.gtf.bgz',; 'GRCh38': 'gs://hail-common/references/gencode/gencode.v29.annotation.gtf.bgz',; }; if reference_genome is None:; reference_genome = hl.default_reference().name; else:; reference_genome = reference_genome.name; if gtf_file is None:; gtf_file = GTFS.get(reference_genome); if gtf_file is None:; raise ValueError(; 'get_gene_intervals requires a GTF file, or the reference genome be one of GRCh37 or GRCh38 (when on Google Cloud Platform)'; ); ht = hl.experimental.import_gtf(; gtf_file, reference_genome=reference_genome, skip_invalid_contigs=True, min_partitions=12; ); ht = ht.annotate(gene_id=ht.gene_id.split('\\.')[0], transcript_id=ht.transcript_id.split('\\.')[0]); return ht. © Copyright 2015-2024, Hail Team.; ",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/import_gtf.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/import_gtf.html
https://hail.is/docs/0.2/_modules/hail/experimental/import_gtf.html:2598,Testability,test,test,2598,"; 'frame': int32; 'interval': interval<>. There will also be corresponding fields for every tag found in the; attribute field of the GTF file. Note; ----. This function will return an ``interval`` field of type :class:`.tinterval`; constructed from the ``seqname``, ``start``, and ``end`` fields in the; GTF file. This interval is inclusive of both the start and end positions; in the GTF file. If the ``reference_genome`` parameter is specified, the start and end; points of the ``interval`` field will be of type :class:`.tlocus`.; Otherwise, the start and end points of the ``interval`` field will be of; type :class:`.tstruct` with fields ``seqname`` (type :class:`str`) and; ``position`` (type :obj:`.tint32`). Furthermore, if the ``reference_genome`` parameter is specified and; ``skip_invalid_contigs`` is ``True``, this import function will skip; lines in the GTF where ``seqname`` is not consistent with the reference; genome specified. Example; -------. >>> ht = hl.experimental.import_gtf('data/test.gtf',; ... reference_genome='GRCh37',; ... skip_invalid_contigs=True). >>> ht.describe() # doctest: +SKIP_OUTPUT_CHECK; ----------------------------------------; Global fields:; None; ----------------------------------------; Row fields:; 'source': str; 'feature': str; 'score': float64; 'strand': str; 'frame': int32; 'gene_type': str; 'exon_id': str; 'havana_transcript': str; 'level': str; 'transcript_name': str; 'gene_status': str; 'gene_id': str; 'transcript_type': str; 'tag': str; 'transcript_status': str; 'gene_name': str; 'transcript_id': str; 'exon_number': str; 'havana_gene': str; 'interval': interval<locus<GRCh37>>; ----------------------------------------; Key: ['interval']; ----------------------------------------. Parameters; ----------. path : :class:`str`; File to import.; reference_genome : :class:`str` or :class:`.ReferenceGenome`, optional; Reference genome to use.; skip_invalid_contigs : :obj:`bool`; If ``True`` and `reference_genome` is not ``None``, skip l",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/import_gtf.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/import_gtf.html
https://hail.is/docs/0.2/_modules/hail/experimental/ldscore.html:1486,Deployability,continuous,continuous,1486,"l.ldscore; import hail as hl; from hail.expr.expressions import expr_float64, expr_locus, expr_numeric; from hail.linalg import BlockMatrix; from hail.table import Table; from hail.typecheck import nullable, oneof, sequenceof, typecheck; from hail.utils import new_temp_file, wrap_to_list. [docs]@typecheck(; entry_expr=expr_float64,; locus_expr=expr_locus(),; radius=oneof(int, float),; coord_expr=nullable(expr_float64),; annotation_exprs=nullable(oneof(expr_numeric, sequenceof(expr_numeric))),; block_size=nullable(int),; ); def ld_score(entry_expr, locus_expr, radius, coord_expr=None, annotation_exprs=None, block_size=None) -> Table:; """"""Calculate LD scores. Example; -------. >>> # Load genetic data into MatrixTable; >>> mt = hl.import_plink(bed='data/ldsc.bed',; ... bim='data/ldsc.bim',; ... fam='data/ldsc.fam'). >>> # Create locus-keyed Table with numeric variant annotations; >>> ht = hl.import_table('data/ldsc.annot',; ... types={'BP': hl.tint,; ... 'binary': hl.tfloat,; ... 'continuous': hl.tfloat}); >>> ht = ht.annotate(locus=hl.locus(ht.CHR, ht.BP)); >>> ht = ht.key_by('locus'). >>> # Annotate MatrixTable with external annotations; >>> mt = mt.annotate_rows(binary_annotation=ht[mt.locus].binary,; ... continuous_annotation=ht[mt.locus].continuous). >>> # Calculate LD scores using centimorgan coordinates; >>> ht_scores = hl.experimental.ld_score(entry_expr=mt.GT.n_alt_alleles(),; ... locus_expr=mt.locus,; ... radius=1.0,; ... coord_expr=mt.cm_position,; ... annotation_exprs=[mt.binary_annotation,; ... mt.continuous_annotation]). >>> # Show results; >>> ht_scores.show(3). .. code-block:: text. +---------------+-------------------+-----------------------+-------------+; | locus | binary_annotation | continuous_annotation | univariate |; +---------------+-------------------+-----------------------+-------------+; | locus<GRCh37> | float64 | float64 | float64 |; +---------------+-------------------+-----------------------+-------------+; | 20:82079 | 1.15183e+00 | 7.",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/ldscore.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/ldscore.html
https://hail.is/docs/0.2/_modules/hail/experimental/ldscore.html:1753,Deployability,continuous,continuous,1753,"emp_file, wrap_to_list. [docs]@typecheck(; entry_expr=expr_float64,; locus_expr=expr_locus(),; radius=oneof(int, float),; coord_expr=nullable(expr_float64),; annotation_exprs=nullable(oneof(expr_numeric, sequenceof(expr_numeric))),; block_size=nullable(int),; ); def ld_score(entry_expr, locus_expr, radius, coord_expr=None, annotation_exprs=None, block_size=None) -> Table:; """"""Calculate LD scores. Example; -------. >>> # Load genetic data into MatrixTable; >>> mt = hl.import_plink(bed='data/ldsc.bed',; ... bim='data/ldsc.bim',; ... fam='data/ldsc.fam'). >>> # Create locus-keyed Table with numeric variant annotations; >>> ht = hl.import_table('data/ldsc.annot',; ... types={'BP': hl.tint,; ... 'binary': hl.tfloat,; ... 'continuous': hl.tfloat}); >>> ht = ht.annotate(locus=hl.locus(ht.CHR, ht.BP)); >>> ht = ht.key_by('locus'). >>> # Annotate MatrixTable with external annotations; >>> mt = mt.annotate_rows(binary_annotation=ht[mt.locus].binary,; ... continuous_annotation=ht[mt.locus].continuous). >>> # Calculate LD scores using centimorgan coordinates; >>> ht_scores = hl.experimental.ld_score(entry_expr=mt.GT.n_alt_alleles(),; ... locus_expr=mt.locus,; ... radius=1.0,; ... coord_expr=mt.cm_position,; ... annotation_exprs=[mt.binary_annotation,; ... mt.continuous_annotation]). >>> # Show results; >>> ht_scores.show(3). .. code-block:: text. +---------------+-------------------+-----------------------+-------------+; | locus | binary_annotation | continuous_annotation | univariate |; +---------------+-------------------+-----------------------+-------------+; | locus<GRCh37> | float64 | float64 | float64 |; +---------------+-------------------+-----------------------+-------------+; | 20:82079 | 1.15183e+00 | 7.30145e+01 | 1.60117e+00 |; | 20:103517 | 2.04604e+00 | 2.75392e+02 | 4.69239e+00 |; | 20:108286 | 2.06585e+00 | 2.86453e+02 | 5.00124e+00 |; +---------------+-------------------+-----------------------+-------------+. Warning; -------; :func:`.ld_score` will fail if",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/ldscore.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/ldscore.html
https://hail.is/docs/0.2/_modules/hail/experimental/ldscore.html:6967,Deployability,update,updated,6967,"e ValueError(""""""ld_score: entry_expr, locus_expr, coord_expr; (if specified), and annotation_exprs (if; specified) must come from same MatrixTable.""""""). n = mt.count_cols(); r2 = hl.row_correlation(entry_expr, block_size) ** 2; r2_adj = ((n - 1.0) / (n - 2.0)) * r2 - (1.0 / (n - 2.0)). starts, stops = hl.linalg.utils.locus_windows(locus_expr, radius, coord_expr); r2_adj_sparse = r2_adj.sparsify_row_intervals(starts, stops). r2_adj_sparse_tmp = new_temp_file(); r2_adj_sparse.write(r2_adj_sparse_tmp); r2_adj_sparse = BlockMatrix.read(r2_adj_sparse_tmp). if not annotation_exprs:; cols = ['univariate']; col_idxs = {0: 'univariate'}; l2 = r2_adj_sparse.sum(axis=1); else:; ht = mt.select_rows(*wrap_to_list(annotation_exprs)).rows(); ht = ht.annotate(univariate=hl.literal(1.0)); names = [name for name in ht.row if name not in ht.key]. ht_union = Table.union(*[; (ht.annotate(name=hl.str(x), value=hl.float(ht[x])).select('name', 'value')) for x in names; ]); mt_annotations = ht_union.to_matrix_table(row_key=list(ht_union.key), col_key=['name']). cols = mt_annotations.key_cols_by()['name'].collect(); col_idxs = {i: cols[i] for i in range(len(cols))}. a_tmp = new_temp_file(); BlockMatrix.write_from_entry_expr(mt_annotations.value, a_tmp). a = BlockMatrix.read(a_tmp); l2 = r2_adj_sparse @ a. l2_bm_tmp = new_temp_file(); l2_tsv_tmp = new_temp_file(); l2.write(l2_bm_tmp, force_row_major=True); BlockMatrix.export(l2_bm_tmp, l2_tsv_tmp). ht_scores = hl.import_table(l2_tsv_tmp, no_header=True, impute=True); ht_scores = ht_scores.add_index(); ht_scores = ht_scores.key_by('idx'); ht_scores = ht_scores.rename({'f{:}'.format(i): col_idxs[i] for i in range(len(cols))}). ht = mt.select_rows(__locus=locus_expr).rows(); ht = ht.add_index(); ht = ht.annotate(**ht_scores[ht.idx]); ht = ht.key_by('__locus'); ht = ht.select(*[x for x in ht_scores.row if x not in ht_scores.key]); ht = ht.rename({'__locus': 'locus'}). return ht. © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/ldscore.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/ldscore.html
https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html:30907,Availability,error,error,30907,"`dict`; Coefficients to multiply each field. The coefficients are specified by; `coef_dict` value, the row (or col) field name is specified by `coef_dict` key.; """"""; assert str_expr is not None or ref_coef_dict is not None, ""str_expr and ref_coef_dict cannot both be None""; assert axis in {'rows', 'cols'}, ""axis must be 'rows' or 'cols'""; fields_to_search = tb.row if axis == 'rows' or isinstance(tb, Table) else tb.col; # when axis='rows' we're searching for annotations, axis='cols' searching for covariates; axis_field = 'annotation' if axis == 'rows' else 'covariate'; if str_expr is None:; # take all row (or col) fields in mt matching keys in coef_dict; coef_dict = {k: ref_coef_dict[k] for k in ref_coef_dict.keys() if k in fields_to_search}; # if intersect is empty: return error; assert len(coef_dict) > 0, f'None of the keys in ref_coef_dict match any {axis[:-1]} fields'; return coef_dict # return subset of ref_coef_dict; else:; # str_expr search in list of row (or col) fields; fields = [rf for rf in list(fields_to_search) if str_expr in rf]; assert len(fields) > 0, f'No {axis[:-1]} fields matched str_expr search: {str_expr}'; if ref_coef_dict is None:; print(f'Assuming coef = 1 for all {axis_field}s'); return {k: 1 for k in fields}; in_ref_coef_dict = set(fields).intersection(set(ref_coef_dict.keys())) # fields in ref_coef_dict; # if >0 fields returned by search are not in ref_coef_dict; if in_ref_coef_dict != set(fields):; # if none of the fields returned by search are in ref_coef_dict; assert len(in_ref_coef_dict) > 0, f'None of the {axis_field} fields in ref_coef_dict match search results'; fields_to_ignore = set(fields).difference(in_ref_coef_dict); print(f'Ignored fields from {axis_field} search: {fields_to_ignore}'); print('To include ignored fields, change str_expr to match desired fields'); fields = list(in_ref_coef_dict); return {k: ref_coef_dict[k] for k in fields}. [docs]@typecheck(mt=MatrixTable, y=expr_int32, P=oneof(int, float)); def ascertainment_bias(",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/ldscsim.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html
https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html:35369,Deployability,update,updated,35369,"((1 - K) * P); cas = mt.filter_cols(mt.y_w_asc_bias == 1); con = mt.filter_cols(mt.y_w_asc_bias == 0).add_col_index(name='col_idx_' + uid); keep = round(p * n * (1 - K)) * [1] + round((1 - p) * n * (1 - K)) * [0]; con = con.annotate_cols(**{'keep_' + uid: hl.literal(keep)[hl.int32(con['col_idx_' + uid])]}); con = con.filter_cols(con['keep_' + uid] == 1); con = _clean_fields(con, uid); mt = con.union_cols(cas); return mt. [docs]@typecheck(mt=MatrixTable, y=oneof(expr_int32, expr_float64), K=oneof(int, float), exact=bool); def binarize(mt, y, K, exact=False):; r""""""Binarize phenotype `y` such that it has prevalence `K` = cases/(cases+controls); Uses inverse CDF of Gaussian to set binarization threshold when `exact` = False,; otherwise uses ranking to determine threshold. Parameters; ----------; mt : :class:`.MatrixTable`; :class:`.MatrixTable` containing phenotype to be binarized.; y : :class:`.Expression`; Column field of phenotype.; K : :obj:`int` or :obj:`float`; Desired ""population prevalence"" of phenotype.; exact : :obj:`bool`; Whether to get prevalence as close as possible to `K` (does not use inverse CDF). Returns; -------; :class:`.MatrixTable`; :class:`.MatrixTable` containing binary phenotype with prevalence of approx. `K`; """"""; if exact:; key = list(mt.col_key); uid = Env.get_uid(base=100); mt = mt.annotate_cols(**{'y_' + uid: y}); tb = mt.cols().order_by('y_' + uid); tb = tb.add_index('idx_' + uid); n = tb.count(); # ""+ 1"" because of zero indexing; tb = tb.annotate(y_binarized=tb['idx_' + uid] + 1 <= round(n * K)); tb, mt = tb.key_by('y_' + uid), mt.key_cols_by('y_' + uid); mt = mt.annotate_cols(y_binarized=tb[mt['y_' + uid]].y_binarized); mt = mt.key_cols_by(*map(lambda x: mt[x], key)); else: # use inverse CDF; y_stats = mt.aggregate_cols(hl.agg.stats(y)); threshold = stats.norm.ppf(1 - K, loc=y_stats.mean, scale=y_stats.stdev); mt = mt.annotate_cols(y_binarized=y > threshold); return mt. © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/ldscsim.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html
https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html:2174,Integrability,depend,depending,2174," @author: nbaya; """""". import numpy as np; import pandas as pd; from scipy import stats. import hail as hl; from hail.expr.expressions import expr_array, expr_call, expr_float64, expr_int32; from hail.matrixtable import MatrixTable; from hail.table import Table; from hail.typecheck import nullable, oneof, typecheck; from hail.utils.java import Env. [docs]@typecheck(; mt=MatrixTable,; genotype=oneof(expr_int32, expr_float64, expr_call),; h2=(oneof(float, int, list, np.ndarray)),; pi=nullable(oneof(float, int, list, np.ndarray)),; rg=nullable(oneof(float, int, list, np.ndarray)),; annot=nullable(oneof(expr_float64, expr_int32)),; popstrat=nullable(oneof(expr_int32, expr_float64)),; popstrat_var=nullable(oneof(float, int)),; exact_h2=bool,; ); def simulate_phenotypes(; mt, genotype, h2, pi=None, rg=None, annot=None, popstrat=None, popstrat_var=None, exact_h2=False; ):; r""""""Simulate phenotypes for testing LD score regression. Simulates betas (SNP effects) under the infinitesimal, spike & slab, or; annotation-informed models, depending on parameters passed. Optionally adds; population stratification. Parameters; ----------; mt : :class:`.MatrixTable`; :class:`.MatrixTable` containing genotypes to be used. Also should contain; variant annotations as row fields if running the annotation-informed; model or covariates as column fields if adding population stratification.; genotype : :class:`.Expression` or :class:`.CallExpression`; Entry field containing genotypes of individuals to be used for the; simulation.; h2 : :obj:`float` or :obj:`int` or :obj:`list` or :class:`numpy.ndarray`; SNP-based heritability of simulated trait.; pi : :obj:`float` or :obj:`int` or :obj:`list` or :class:`numpy.ndarray`, optional; Probability of SNP being causal when simulating under the spike & slab; model.; rg : :obj:`float` or :obj:`int` or :obj:`list` or :class:`numpy.ndarray`, optional; Genetic correlation between traits.; annot : :class:`.Expression`, optional; Row field to use as our aggrega",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/ldscsim.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html
https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html:5385,Integrability,depend,depending,5385,"a'],; h2=h2,; popstrat=None if popstrat is None else mt['popstrat_' + uid],; popstrat_var=popstrat_var,; exact_h2=exact_h2,; ); mt = annotate_all(; mt=mt,; global_exprs={; 'ldscsim': hl.struct(**{; 'h2': h2[0] if len(h2) == 1 else h2,; **({} if pi == [None] else {'pi': pi}),; **({} if rg == [None] else {'rg': rg[0] if len(rg) == 1 else rg}),; **({} if annot is None else {'is_annot_inf': True}),; **({} if popstrat is None else {'is_popstrat_inf': True}),; **({} if popstrat_var is None else {'popstrat_var': popstrat_var}),; 'exact_h2': exact_h2,; }); },; ); mt = _clean_fields(mt, uid); return mt. [docs]@typecheck(; mt=MatrixTable,; h2=(oneof(float, int, list, np.ndarray)),; pi=nullable(oneof(float, int, list, np.ndarray)),; annot=nullable(oneof(expr_float64, expr_int32)),; rg=nullable(oneof(float, int, list, np.ndarray)),; ); def make_betas(mt, h2, pi=None, annot=None, rg=None):; r""""""Generates betas under different models. Simulates betas (SNP effects) under the infinitesimal, spike & slab, or; annotation-informed models, depending on parameters passed. Parameters; ----------; mt : :class:`.MatrixTable`; MatrixTable containing genotypes to be used. Also should contain; variant annotations as row fields if running the annotation-informed; model or covariates as column fields if adding population stratification.; h2 : :obj:`float` or :obj:`int` or :obj:`list` or :class:`numpy.ndarray`; SNP-based heritability of simulated trait(s).; pi : :obj:`float` or :obj:`int` or :obj:`list` or :class:`numpy.ndarray`, optional; Probability of SNP being causal when simulating under the spike & slab; model. If doing two-trait spike & slab `pi` is a list of probabilities for; overlapping causal SNPs (see docstring of :func:`.multitrait_ss`); annot : :class:`.Expression`, optional; Row field of aggregated annotations for annotation-informed model.; rg : :obj:`float` or :obj:`int` or :obj:`list` or :class:`numpy.ndarray`, optional; Genetic correlation between traits. Returns; -------; mt :",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/ldscsim.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html
https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html:583,Testability,test,testing,583,"﻿. Hail | ; hail.experimental.ldscsim. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.experimental.ldscsim. Source code for hail.experimental.ldscsim; #!/usr/bin/env python3; # -*- coding: utf-8 -*-; """"""; Simulation framework for testing LDSC. Models for SNP effects:; - Infinitesimal (can simulate n correlated traits); - Spike & slab (can simulate up to 2 correlated traits); - Annotation-informed. Features:; - Field aggregation tools for annotation-informed model and; population stratification with many covariates.; - Automatic adjustment of genetic correlation parameters; to allow for the joint simulation of up to 100 randomly; correlated phenotypes.; - Methods for binarizing phenotypes to have a certain prevalence; and for adding ascertainment bias to binarized phenotypes. @author: nbaya; """""". import numpy as np; import pandas as pd; from scipy import stats. import hail as hl; from hail.expr.expressions import expr_array, expr_call, expr_float64, expr_int32; from hail.matrixtable import MatrixTable; from hail.table import Table; from hail.typecheck import nullable, oneof, typecheck; from hail.utils.java import Env. [docs]@typecheck(; mt=MatrixTable,; genotype=oneof(expr_int32, expr_float64, expr_call),; h2=(oneof(float, int, list, np.ndarray)),; pi=nullable(oneof(float, int, list, np.ndarray)),; rg=nullable(oneof(float, int, list, np.ndarray)),; annot=nullable(oneof(expr_float64, expr_int32)),; popstrat=nullable(oneof(expr_int32, expr_float64)),; popstrat_var=nullable(oneof(float, int)),; exact_h2=bool,; ); def simulate_phenotypes(; mt, genotype, h2, pi=None, rg=None, annot=None, popstrat=None, popstrat_var=None, exact",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/ldscsim.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html
https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html:2044,Testability,test,testing,2044,"stment of genetic correlation parameters; to allow for the joint simulation of up to 100 randomly; correlated phenotypes.; - Methods for binarizing phenotypes to have a certain prevalence; and for adding ascertainment bias to binarized phenotypes. @author: nbaya; """""". import numpy as np; import pandas as pd; from scipy import stats. import hail as hl; from hail.expr.expressions import expr_array, expr_call, expr_float64, expr_int32; from hail.matrixtable import MatrixTable; from hail.table import Table; from hail.typecheck import nullable, oneof, typecheck; from hail.utils.java import Env. [docs]@typecheck(; mt=MatrixTable,; genotype=oneof(expr_int32, expr_float64, expr_call),; h2=(oneof(float, int, list, np.ndarray)),; pi=nullable(oneof(float, int, list, np.ndarray)),; rg=nullable(oneof(float, int, list, np.ndarray)),; annot=nullable(oneof(expr_float64, expr_int32)),; popstrat=nullable(oneof(expr_int32, expr_float64)),; popstrat_var=nullable(oneof(float, int)),; exact_h2=bool,; ); def simulate_phenotypes(; mt, genotype, h2, pi=None, rg=None, annot=None, popstrat=None, popstrat_var=None, exact_h2=False; ):; r""""""Simulate phenotypes for testing LD score regression. Simulates betas (SNP effects) under the infinitesimal, spike & slab, or; annotation-informed models, depending on parameters passed. Optionally adds; population stratification. Parameters; ----------; mt : :class:`.MatrixTable`; :class:`.MatrixTable` containing genotypes to be used. Also should contain; variant annotations as row fields if running the annotation-informed; model or covariates as column fields if adding population stratification.; genotype : :class:`.Expression` or :class:`.CallExpression`; Entry field containing genotypes of individuals to be used for the; simulation.; h2 : :obj:`float` or :obj:`int` or :obj:`list` or :class:`numpy.ndarray`; SNP-based heritability of simulated trait.; pi : :obj:`float` or :obj:`int` or :obj:`list` or :class:`numpy.ndarray`, optional; Probability of SNP being ",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/ldscsim.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html
https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html:7113,Testability,assert,assert,7113,"-----; mt : :class:`.MatrixTable`; :class:`.MatrixTable` with betas as a row field, simulated according to specified model.; pi : :obj:`list`; Probability of a SNP being causal for different traits, possibly altered; from input `pi` if covariance matrix for multitrait simulation was not; positive semi-definite.; rg : :obj:`list`; Genetic correlation between traits, possibly altered from input `rg` if; covariance matrix for multitrait simulation was not positive semi-definite. """"""; h2 = h2.tolist() if isinstance(h2, np.ndarray) else ([h2] if not isinstance(h2, list) else h2); pi = pi.tolist() if isinstance(pi, np.ndarray) else ([pi] if not isinstance(pi, list) else pi); rg = rg.tolist() if isinstance(rg, np.ndarray) else ([rg] if not isinstance(rg, list) else rg); assert all(x >= 0 and x <= 1 for x in h2), 'h2 values must be between 0 and 1'; assert (pi is not [None]) or all(; x >= 0 and x <= 1 for x in pi; ), 'pi values for spike & slab must be between 0 and 1'; assert rg == [None] or all(x >= -1 and x <= 1 for x in rg), 'rg values must be between -1 and 1 or None'; if annot is not None: # multi-trait annotation-informed; assert rg == [None], 'Correlated traits not supported for annotation-informed model'; h2 = h2 if isinstance(h2, list) else [h2]; annot_sum = mt.aggregate_rows(hl.agg.sum(annot)); mt = mt.annotate_rows(beta=hl.literal(h2).map(lambda x: hl.rand_norm(0, hl.sqrt(annot * x / (annot_sum * M))))); elif len(h2) > 1 and (pi in ([None], [1])): # multi-trait correlated infinitesimal; mt, rg = multitrait_inf(mt=mt, h2=h2, rg=rg); elif len(h2) == 2 and len(pi) > 1 and len(rg) == 1: # two trait correlated spike & slab; print('multitrait ss'); mt, pi, rg = multitrait_ss(mt=mt, h2=h2, rg=0 if rg is [None] else rg[0], pi=pi); elif len(h2) == 1 and len(pi) == 1: # single trait infinitesimal/spike & slab; M = mt.count_rows(); pi_temp = 1 if pi == [None] else pi[0]; mt = mt.annotate_rows(beta=hl.rand_bool(pi_temp) * hl.rand_norm(0, hl.sqrt(h2[0] / (M * pi_temp)))); el",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/ldscsim.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html
https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html:7193,Testability,assert,assert,7193,"-----; mt : :class:`.MatrixTable`; :class:`.MatrixTable` with betas as a row field, simulated according to specified model.; pi : :obj:`list`; Probability of a SNP being causal for different traits, possibly altered; from input `pi` if covariance matrix for multitrait simulation was not; positive semi-definite.; rg : :obj:`list`; Genetic correlation between traits, possibly altered from input `rg` if; covariance matrix for multitrait simulation was not positive semi-definite. """"""; h2 = h2.tolist() if isinstance(h2, np.ndarray) else ([h2] if not isinstance(h2, list) else h2); pi = pi.tolist() if isinstance(pi, np.ndarray) else ([pi] if not isinstance(pi, list) else pi); rg = rg.tolist() if isinstance(rg, np.ndarray) else ([rg] if not isinstance(rg, list) else rg); assert all(x >= 0 and x <= 1 for x in h2), 'h2 values must be between 0 and 1'; assert (pi is not [None]) or all(; x >= 0 and x <= 1 for x in pi; ), 'pi values for spike & slab must be between 0 and 1'; assert rg == [None] or all(x >= -1 and x <= 1 for x in rg), 'rg values must be between -1 and 1 or None'; if annot is not None: # multi-trait annotation-informed; assert rg == [None], 'Correlated traits not supported for annotation-informed model'; h2 = h2 if isinstance(h2, list) else [h2]; annot_sum = mt.aggregate_rows(hl.agg.sum(annot)); mt = mt.annotate_rows(beta=hl.literal(h2).map(lambda x: hl.rand_norm(0, hl.sqrt(annot * x / (annot_sum * M))))); elif len(h2) > 1 and (pi in ([None], [1])): # multi-trait correlated infinitesimal; mt, rg = multitrait_inf(mt=mt, h2=h2, rg=rg); elif len(h2) == 2 and len(pi) > 1 and len(rg) == 1: # two trait correlated spike & slab; print('multitrait ss'); mt, pi, rg = multitrait_ss(mt=mt, h2=h2, rg=0 if rg is [None] else rg[0], pi=pi); elif len(h2) == 1 and len(pi) == 1: # single trait infinitesimal/spike & slab; M = mt.count_rows(); pi_temp = 1 if pi == [None] else pi[0]; mt = mt.annotate_rows(beta=hl.rand_bool(pi_temp) * hl.rand_norm(0, hl.sqrt(h2[0] / (M * pi_temp)))); el",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/ldscsim.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html
https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html:7316,Testability,assert,assert,7316,"-----; mt : :class:`.MatrixTable`; :class:`.MatrixTable` with betas as a row field, simulated according to specified model.; pi : :obj:`list`; Probability of a SNP being causal for different traits, possibly altered; from input `pi` if covariance matrix for multitrait simulation was not; positive semi-definite.; rg : :obj:`list`; Genetic correlation between traits, possibly altered from input `rg` if; covariance matrix for multitrait simulation was not positive semi-definite. """"""; h2 = h2.tolist() if isinstance(h2, np.ndarray) else ([h2] if not isinstance(h2, list) else h2); pi = pi.tolist() if isinstance(pi, np.ndarray) else ([pi] if not isinstance(pi, list) else pi); rg = rg.tolist() if isinstance(rg, np.ndarray) else ([rg] if not isinstance(rg, list) else rg); assert all(x >= 0 and x <= 1 for x in h2), 'h2 values must be between 0 and 1'; assert (pi is not [None]) or all(; x >= 0 and x <= 1 for x in pi; ), 'pi values for spike & slab must be between 0 and 1'; assert rg == [None] or all(x >= -1 and x <= 1 for x in rg), 'rg values must be between -1 and 1 or None'; if annot is not None: # multi-trait annotation-informed; assert rg == [None], 'Correlated traits not supported for annotation-informed model'; h2 = h2 if isinstance(h2, list) else [h2]; annot_sum = mt.aggregate_rows(hl.agg.sum(annot)); mt = mt.annotate_rows(beta=hl.literal(h2).map(lambda x: hl.rand_norm(0, hl.sqrt(annot * x / (annot_sum * M))))); elif len(h2) > 1 and (pi in ([None], [1])): # multi-trait correlated infinitesimal; mt, rg = multitrait_inf(mt=mt, h2=h2, rg=rg); elif len(h2) == 2 and len(pi) > 1 and len(rg) == 1: # two trait correlated spike & slab; print('multitrait ss'); mt, pi, rg = multitrait_ss(mt=mt, h2=h2, rg=0 if rg is [None] else rg[0], pi=pi); elif len(h2) == 1 and len(pi) == 1: # single trait infinitesimal/spike & slab; M = mt.count_rows(); pi_temp = 1 if pi == [None] else pi[0]; mt = mt.annotate_rows(beta=hl.rand_bool(pi_temp) * hl.rand_norm(0, hl.sqrt(h2[0] / (M * pi_temp)))); el",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/ldscsim.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html
https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html:7479,Testability,assert,assert,7479,"-----; mt : :class:`.MatrixTable`; :class:`.MatrixTable` with betas as a row field, simulated according to specified model.; pi : :obj:`list`; Probability of a SNP being causal for different traits, possibly altered; from input `pi` if covariance matrix for multitrait simulation was not; positive semi-definite.; rg : :obj:`list`; Genetic correlation between traits, possibly altered from input `rg` if; covariance matrix for multitrait simulation was not positive semi-definite. """"""; h2 = h2.tolist() if isinstance(h2, np.ndarray) else ([h2] if not isinstance(h2, list) else h2); pi = pi.tolist() if isinstance(pi, np.ndarray) else ([pi] if not isinstance(pi, list) else pi); rg = rg.tolist() if isinstance(rg, np.ndarray) else ([rg] if not isinstance(rg, list) else rg); assert all(x >= 0 and x <= 1 for x in h2), 'h2 values must be between 0 and 1'; assert (pi is not [None]) or all(; x >= 0 and x <= 1 for x in pi; ), 'pi values for spike & slab must be between 0 and 1'; assert rg == [None] or all(x >= -1 and x <= 1 for x in rg), 'rg values must be between -1 and 1 or None'; if annot is not None: # multi-trait annotation-informed; assert rg == [None], 'Correlated traits not supported for annotation-informed model'; h2 = h2 if isinstance(h2, list) else [h2]; annot_sum = mt.aggregate_rows(hl.agg.sum(annot)); mt = mt.annotate_rows(beta=hl.literal(h2).map(lambda x: hl.rand_norm(0, hl.sqrt(annot * x / (annot_sum * M))))); elif len(h2) > 1 and (pi in ([None], [1])): # multi-trait correlated infinitesimal; mt, rg = multitrait_inf(mt=mt, h2=h2, rg=rg); elif len(h2) == 2 and len(pi) > 1 and len(rg) == 1: # two trait correlated spike & slab; print('multitrait ss'); mt, pi, rg = multitrait_ss(mt=mt, h2=h2, rg=0 if rg is [None] else rg[0], pi=pi); elif len(h2) == 1 and len(pi) == 1: # single trait infinitesimal/spike & slab; M = mt.count_rows(); pi_temp = 1 if pi == [None] else pi[0]; mt = mt.annotate_rows(beta=hl.rand_bool(pi_temp) * hl.rand_norm(0, hl.sqrt(h2[0] / (M * pi_temp)))); el",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/ldscsim.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html
https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html:10401,Testability,assert,assert,10401," :math:`r_g`; is assumed to be 0 between traits. If `rg` and `cov_matrix` are both; not None, :math:`r_g` values from `cov_matrix` take precedence.; cov_matrix : :class:`numpy.ndarray`, optional; Covariance matrix for traits, **unscaled by :math:`M`**, the number of SNPs.; Overrides `h2` and `rg` even when `h2` or `rg` are not ``None``.; seed : :obj:`int`, optional; Seed for random number generator. If `seed` is ``None``, `seed` is set randomly. Returns; -------; mt : :class:`.MatrixTable`; :class:`.MatrixTable` with simulated SNP effects as a row field of arrays.; rg : :obj:`list`; Genetic correlation between traits, possibly altered from input `rg` if; covariance matrix was not positive semi-definite.; """"""; uid = Env.get_uid(base=100); h2 = h2.tolist() if isinstance(h2, np.ndarray) else ([h2] if not isinstance(h2, list) else h2); rg = rg.tolist() if isinstance(rg, np.ndarray) else ([rg] if not isinstance(rg, list) else rg); assert all(x >= 0 and x <= 1 for x in h2), 'h2 values must be between 0 and 1'; assert h2 is not [None] or cov_matrix is not None, 'h2 and cov_matrix cannot both be None'; M = mt.count_rows(); if cov_matrix is not None:; n_phens = cov_matrix.shape[0]; else:; n_phens = len(h2); if rg == [None]:; print(f'Assuming rg=0 for all {n_phens} traits'); rg = [0] * int((n_phens**2 - n_phens) / 2); assert all(x >= -1 and x <= 1 for x in rg), 'rg values must be between 0 and 1'; cov, rg = get_cov_matrix(h2, rg); cov = (1 / M) * cov; # seed random state for replicability; randstate = np.random.RandomState(int(seed)); betas = randstate.multivariate_normal(; mean=np.zeros(n_phens),; cov=cov,; size=[; M,; ],; ); df = pd.DataFrame([0] * M, columns=['beta']); tb = hl.Table.from_pandas(df); tb = tb.add_index().key_by('idx'); tb = tb.annotate(beta=hl.literal(betas.tolist())[hl.int32(tb.idx)]); mt = mt.add_row_index(name='row_idx' + uid); mt = mt.annotate_rows(beta=tb[mt['row_idx' + uid]]['beta']); mt = _clean_fields(mt, uid); return mt, rg. [docs]@typecheck(; mt=Mat",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/ldscsim.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html
https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html:10481,Testability,assert,assert,10481," :math:`r_g`; is assumed to be 0 between traits. If `rg` and `cov_matrix` are both; not None, :math:`r_g` values from `cov_matrix` take precedence.; cov_matrix : :class:`numpy.ndarray`, optional; Covariance matrix for traits, **unscaled by :math:`M`**, the number of SNPs.; Overrides `h2` and `rg` even when `h2` or `rg` are not ``None``.; seed : :obj:`int`, optional; Seed for random number generator. If `seed` is ``None``, `seed` is set randomly. Returns; -------; mt : :class:`.MatrixTable`; :class:`.MatrixTable` with simulated SNP effects as a row field of arrays.; rg : :obj:`list`; Genetic correlation between traits, possibly altered from input `rg` if; covariance matrix was not positive semi-definite.; """"""; uid = Env.get_uid(base=100); h2 = h2.tolist() if isinstance(h2, np.ndarray) else ([h2] if not isinstance(h2, list) else h2); rg = rg.tolist() if isinstance(rg, np.ndarray) else ([rg] if not isinstance(rg, list) else rg); assert all(x >= 0 and x <= 1 for x in h2), 'h2 values must be between 0 and 1'; assert h2 is not [None] or cov_matrix is not None, 'h2 and cov_matrix cannot both be None'; M = mt.count_rows(); if cov_matrix is not None:; n_phens = cov_matrix.shape[0]; else:; n_phens = len(h2); if rg == [None]:; print(f'Assuming rg=0 for all {n_phens} traits'); rg = [0] * int((n_phens**2 - n_phens) / 2); assert all(x >= -1 and x <= 1 for x in rg), 'rg values must be between 0 and 1'; cov, rg = get_cov_matrix(h2, rg); cov = (1 / M) * cov; # seed random state for replicability; randstate = np.random.RandomState(int(seed)); betas = randstate.multivariate_normal(; mean=np.zeros(n_phens),; cov=cov,; size=[; M,; ],; ); df = pd.DataFrame([0] * M, columns=['beta']); tb = hl.Table.from_pandas(df); tb = tb.add_index().key_by('idx'); tb = tb.annotate(beta=hl.literal(betas.tolist())[hl.int32(tb.idx)]); mt = mt.add_row_index(name='row_idx' + uid); mt = mt.annotate_rows(beta=tb[mt['row_idx' + uid]]['beta']); mt = _clean_fields(mt, uid); return mt, rg. [docs]@typecheck(; mt=Mat",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/ldscsim.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html
https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html:10791,Testability,assert,assert,10791,":`int`, optional; Seed for random number generator. If `seed` is ``None``, `seed` is set randomly. Returns; -------; mt : :class:`.MatrixTable`; :class:`.MatrixTable` with simulated SNP effects as a row field of arrays.; rg : :obj:`list`; Genetic correlation between traits, possibly altered from input `rg` if; covariance matrix was not positive semi-definite.; """"""; uid = Env.get_uid(base=100); h2 = h2.tolist() if isinstance(h2, np.ndarray) else ([h2] if not isinstance(h2, list) else h2); rg = rg.tolist() if isinstance(rg, np.ndarray) else ([rg] if not isinstance(rg, list) else rg); assert all(x >= 0 and x <= 1 for x in h2), 'h2 values must be between 0 and 1'; assert h2 is not [None] or cov_matrix is not None, 'h2 and cov_matrix cannot both be None'; M = mt.count_rows(); if cov_matrix is not None:; n_phens = cov_matrix.shape[0]; else:; n_phens = len(h2); if rg == [None]:; print(f'Assuming rg=0 for all {n_phens} traits'); rg = [0] * int((n_phens**2 - n_phens) / 2); assert all(x >= -1 and x <= 1 for x in rg), 'rg values must be between 0 and 1'; cov, rg = get_cov_matrix(h2, rg); cov = (1 / M) * cov; # seed random state for replicability; randstate = np.random.RandomState(int(seed)); betas = randstate.multivariate_normal(; mean=np.zeros(n_phens),; cov=cov,; size=[; M,; ],; ); df = pd.DataFrame([0] * M, columns=['beta']); tb = hl.Table.from_pandas(df); tb = tb.add_index().key_by('idx'); tb = tb.annotate(beta=hl.literal(betas.tolist())[hl.int32(tb.idx)]); mt = mt.add_row_index(name='row_idx' + uid); mt = mt.annotate_rows(beta=tb[mt['row_idx' + uid]]['beta']); mt = _clean_fields(mt, uid); return mt, rg. [docs]@typecheck(; mt=MatrixTable, h2=oneof(list, np.ndarray), pi=oneof(list, np.ndarray), rg=oneof(float, int), seed=nullable(int); ); def multitrait_ss(mt, h2, pi, rg=0, seed=None):; r""""""Generates spike & slab betas for simulation of two correlated phenotypes. Parameters; ----------; mt : :class:`.MatrixTable`; :class:`.MatrixTable` for simulated phenotype.; h2 : :obj:`l",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/ldscsim.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html
https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html:13148,Testability,assert,assert,13148,"that are causal for trait 2 but not trait 1.; rg : :obj:`float` or :obj:`int`; Genetic correlation between traits.; seed : :obj:`int`, optional; Seed for random number generator. If `seed` is ``None``, `seed` is set randomly. Warning; -------; May give inaccurate results if chosen parameters make the covariance matrix; not positive semi-definite. Covariance matrix is likely to not be positive; semi-definite when :math:`p_{TT}` is small and rg is large. Returns; -------; mt : :class:`.MatrixTable`; :class:`.MatrixTable` with simulated SNP effects as a row field of arrays.; pi : :obj:`list` or :class:`numpy.ndarray`; List of proportion of SNPs: :math:`p_{TT}`, :math:`p_{TF}`, :math:`p_{FT}`.; Possibly altered if covariance matrix of traits was not positive semi-definite.; rg : :obj:`list`; Genetic correlation between traits, possibly altered from input `rg` if; covariance matrix was not positive semi-definite.; """"""; assert sum(pi) <= 1, ""probabilities of being causal must sum to be less than 1""; ptt, ptf, pft, pff = pi[0], pi[1], pi[2], 1 - sum(pi); cov_matrix = np.asarray([[1 / (ptt + ptf), rg / ptt], [rg / ptt, 1 / (ptt + pft)]]); M = mt.count_rows(); # seed random state for replicability; randstate = np.random.RandomState(int(seed)); if np.any(np.linalg.eigvals(cov_matrix) < 0):; print('adjusting parameters to make covariance matrix positive semidefinite'); rg0, ptt0 = rg, ptt; while np.any(np.linalg.eigvals(cov_matrix) < 0): # check positive semidefinite; rg = round(0.99 * rg, 6); ptt = round(ptt + (pff) * 0.001, 6); cov_matrix = np.asarray([[1 / (ptt + ptf), rg / ptt], [rg / ptt, 1 / (ptt + pft)]]); pff0, pff = pff, 1 - sum([ptt, ptf, pft]); print(f'rg: {rg0} -> {rg}\nptt: {ptt0} -> {ptt}\npff: {pff0} -> {pff}'); pi = [ptt, ptf, pft, pff]; beta = randstate.multivariate_normal(; mean=np.zeros(2),; cov=cov_matrix,; size=[; int(M),; ],; ); zeros = np.zeros(shape=int(M)).T; beta_matrix = np.stack(; (beta, np.asarray([beta[:, 0], zeros]).T, np.asarray([zeros, zeros]).T",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/ldscsim.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html
https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html:19359,Testability,assert,assert,19359,":`h^2` values in list should be; ordered by their order in the diagonal of the covariance array, reading; from top left to bottom right.; rg : :obj:`list` or :class:`numpy.ndarray`; :math:`r_g` values for traits. :math:`r_g` values should be ordered in; the order they appear in the upper triangle of the covariance matrix,; from left to right, top to bottom.; psd_rg : :obj:`bool`; Whether to automatically adjust rg values to get a positive semi-definite; covariance matrix, which ensures that SNP effects simulated with that; covariance matrix have the desired variance and correlation properties; specified by the h2 and rg parameters. Returns; -------; cov_matrix : :class:`numpy.ndarray`; Covariance matrix calculated using `h2` and (possibly altered) `rg` values.; rg : :obj:`list`; Genetic correlation between traits, possibly altered from input `rg` if; covariance matrix was not positive semi-definite.; """"""; assert all(x >= 0 and x <= 1 for x in h2), 'h2 values must be between 0 and 1'; assert all(x >= -1 and x <= 1 for x in rg), 'rg values must be between -1 and 1'; rg = np.asarray(rg) if isinstance(rg, list) else rg; n_rg = len(rg); n_h2 = len(h2); # expected number of rg values, given number of traits; exp_n_rg = int((n_h2**2 - n_h2) / 2); assert n_rg == exp_n_rg, f'The number of rg values given is {n_rg}, expected {exp_n_rg}'; cor = np.zeros(shape=(n_h2, n_h2)); # set upper triangle of correlation matrix to be rg; cor[np.triu_indices(n=n_h2, k=1)] = rg; cor += cor.T; cor[np.diag_indices(n=n_h2)] = 1; if psd_rg:; cor0 = cor; cor = _nearpsd(cor); idx = np.triu_indices(n=n_h2, k=1); maxlines = 50; msg = ['Adjusting rg values to make covariance matrix positive semidefinite']; msg += (; [(f'{cor0[idx[0][i],idx[1][i]]} -> {cor[idx[0][i],idx[1][i]]}') for i in range(n_rg)]; if n_rg <= maxlines; else [(f'{cor0[idx[0][i],idx[1][i]]} -> {cor[idx[0][i],idx[1][i]]}') for i in range(maxlines)]; + [f'[ printed first {maxlines} rg changes -- omitted {n_rg - maxlines} ]']; ); print",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/ldscsim.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html
https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html:19439,Testability,assert,assert,19439,":`h^2` values in list should be; ordered by their order in the diagonal of the covariance array, reading; from top left to bottom right.; rg : :obj:`list` or :class:`numpy.ndarray`; :math:`r_g` values for traits. :math:`r_g` values should be ordered in; the order they appear in the upper triangle of the covariance matrix,; from left to right, top to bottom.; psd_rg : :obj:`bool`; Whether to automatically adjust rg values to get a positive semi-definite; covariance matrix, which ensures that SNP effects simulated with that; covariance matrix have the desired variance and correlation properties; specified by the h2 and rg parameters. Returns; -------; cov_matrix : :class:`numpy.ndarray`; Covariance matrix calculated using `h2` and (possibly altered) `rg` values.; rg : :obj:`list`; Genetic correlation between traits, possibly altered from input `rg` if; covariance matrix was not positive semi-definite.; """"""; assert all(x >= 0 and x <= 1 for x in h2), 'h2 values must be between 0 and 1'; assert all(x >= -1 and x <= 1 for x in rg), 'rg values must be between -1 and 1'; rg = np.asarray(rg) if isinstance(rg, list) else rg; n_rg = len(rg); n_h2 = len(h2); # expected number of rg values, given number of traits; exp_n_rg = int((n_h2**2 - n_h2) / 2); assert n_rg == exp_n_rg, f'The number of rg values given is {n_rg}, expected {exp_n_rg}'; cor = np.zeros(shape=(n_h2, n_h2)); # set upper triangle of correlation matrix to be rg; cor[np.triu_indices(n=n_h2, k=1)] = rg; cor += cor.T; cor[np.diag_indices(n=n_h2)] = 1; if psd_rg:; cor0 = cor; cor = _nearpsd(cor); idx = np.triu_indices(n=n_h2, k=1); maxlines = 50; msg = ['Adjusting rg values to make covariance matrix positive semidefinite']; msg += (; [(f'{cor0[idx[0][i],idx[1][i]]} -> {cor[idx[0][i],idx[1][i]]}') for i in range(n_rg)]; if n_rg <= maxlines; else [(f'{cor0[idx[0][i],idx[1][i]]} -> {cor[idx[0][i],idx[1][i]]}') for i in range(maxlines)]; + [f'[ printed first {maxlines} rg changes -- omitted {n_rg - maxlines} ]']; ); print",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/ldscsim.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html
https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html:19700,Testability,assert,assert,19700," values should be ordered in; the order they appear in the upper triangle of the covariance matrix,; from left to right, top to bottom.; psd_rg : :obj:`bool`; Whether to automatically adjust rg values to get a positive semi-definite; covariance matrix, which ensures that SNP effects simulated with that; covariance matrix have the desired variance and correlation properties; specified by the h2 and rg parameters. Returns; -------; cov_matrix : :class:`numpy.ndarray`; Covariance matrix calculated using `h2` and (possibly altered) `rg` values.; rg : :obj:`list`; Genetic correlation between traits, possibly altered from input `rg` if; covariance matrix was not positive semi-definite.; """"""; assert all(x >= 0 and x <= 1 for x in h2), 'h2 values must be between 0 and 1'; assert all(x >= -1 and x <= 1 for x in rg), 'rg values must be between -1 and 1'; rg = np.asarray(rg) if isinstance(rg, list) else rg; n_rg = len(rg); n_h2 = len(h2); # expected number of rg values, given number of traits; exp_n_rg = int((n_h2**2 - n_h2) / 2); assert n_rg == exp_n_rg, f'The number of rg values given is {n_rg}, expected {exp_n_rg}'; cor = np.zeros(shape=(n_h2, n_h2)); # set upper triangle of correlation matrix to be rg; cor[np.triu_indices(n=n_h2, k=1)] = rg; cor += cor.T; cor[np.diag_indices(n=n_h2)] = 1; if psd_rg:; cor0 = cor; cor = _nearpsd(cor); idx = np.triu_indices(n=n_h2, k=1); maxlines = 50; msg = ['Adjusting rg values to make covariance matrix positive semidefinite']; msg += (; [(f'{cor0[idx[0][i],idx[1][i]]} -> {cor[idx[0][i],idx[1][i]]}') for i in range(n_rg)]; if n_rg <= maxlines; else [(f'{cor0[idx[0][i],idx[1][i]]} -> {cor[idx[0][i],idx[1][i]]}') for i in range(maxlines)]; + [f'[ printed first {maxlines} rg changes -- omitted {n_rg - maxlines} ]']; ); print('\n'.join(msg)); rg = np.ravel(cor[idx]); S = np.diag(h2) ** (1 / 2); cov_matrix = S @ cor @ S # covariance matrix decomposition. # check positive semidefinite; if not np.all(np.linalg.eigvals(cov_matrix) >= 0) and not psd",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/ldscsim.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html
https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html:23086,Testability,assert,assert,23086,"n`; Entry field of genotypes.; beta : :class:`.Expression`; Row field of SNP effects.; h2 : :obj:`float` or :obj:`int` or :obj:`list` or :class:`numpy.ndarray`; SNP-based heritability (:math:`h^2`) of simulated trait. Can only be; ``None`` if running annotation-informed model.; popstrat : :class:`.Expression`, optional; Column field containing population stratification term.; popstrat_var : :obj:`float` or :obj:`int`; Variance of population stratification term.; exact_h2: :obj:`bool`; Whether to exactly simulate ratio of variance of genetic component of; phenotype to variance of phenotype to be h2. If `False`, ratio will be; h2 in expectation. Observed h2 in the simulation will be close to; expected h2 for large-scale simulations. Returns; -------; :class:`.MatrixTable`; :class:`.MatrixTable` with simulated phenotype as column field.; """"""; print('calculating phenotype'); h2 = h2.tolist() if isinstance(h2, np.ndarray) else ([h2] if not isinstance(h2, list) else h2); assert popstrat_var is None or (popstrat_var >= 0), 'popstrat_var must be non-negative'; uid = Env.get_uid(base=100); mt = annotate_all(; mt=mt,; row_exprs={'beta_' + uid: beta},; col_exprs={} if popstrat is None else {'popstrat_' + uid: popstrat},; entry_exprs={'gt_' + uid: genotype.n_alt_alleles() if genotype.dtype is hl.dtype('call') else genotype},; ); mt = mt.filter_rows(hl.agg.stats(mt['gt_' + uid]).stdev > 0); mt = normalize_genotypes(mt['gt_' + uid]); if mt['beta_' + uid].dtype == hl.dtype('array<float64>'): # if >1 traits; if exact_h2:; raise ValueError('exact_h2=True not supported for multitrait simulations'); else:; mt = mt.annotate_cols(; y_no_noise=hl.agg.array_agg(lambda beta: hl.agg.sum(beta * mt['norm_gt']), mt['beta_' + uid]); ); mt = mt.annotate_cols(y=mt.y_no_noise + hl.literal(h2).map(lambda x: hl.rand_norm(0, hl.sqrt(1 - x)))); elif exact_h2 and min([h2[0], 1 - h2[0]]) != 0:; print('exact h2'); mt = mt.annotate_cols(**{'y_no_noise_' + uid: hl.agg.sum(mt['beta_' + uid] * mt['norm_gt'])}",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/ldscsim.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html
https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html:26992,Testability,assert,assert,26992,"dev); mt = _clean_fields(mt, uid); return mt. @typecheck(mt=MatrixTable, str_expr=str); def _clean_fields(mt, str_expr):; r""""""Removes fields with names that have `str_expr` in them. Parameters; ----------; mt : :class:`.MatrixTable`; :class:`.MatrixTable` with fields to be removed.; str_expr : :class:`str`; string to filter names of fields to remove. Returns; -------; :class:`.MatrixTable`; :class:`.MatrixTable` with specified fields removed.; """"""; all_fields = list(mt.col) + list(mt.row) + list(mt.entry) + list(mt.globals); return mt.drop(*(x for x in all_fields if str_expr in x)). [docs]@typecheck(mt=MatrixTable, row_exprs=dict, col_exprs=dict, entry_exprs=dict, global_exprs=dict); def annotate_all(mt, row_exprs={}, col_exprs={}, entry_exprs={}, global_exprs={}):; r""""""Equivalent of _annotate_all, but checks source MatrixTable of exprs""""""; exprs = {**row_exprs, **col_exprs, **entry_exprs, **global_exprs}; for key, value in exprs.items():; if value.dtype in (hl.tfloat64, hl.tint32):; assert value._indices.source == mt, 'Cannot combine expressions from different source objects.'; return mt._annotate_all(row_exprs, col_exprs, entry_exprs, global_exprs). [docs]@typecheck(tb=oneof(MatrixTable, Table), coef_dict=nullable(dict), str_expr=nullable(str), axis=str); def agg_fields(tb, coef_dict=None, str_expr=None, axis='rows'):; r""""""Aggregates by linear combination fields matching either keys in `coef_dict`; or `str_expr`. Outputs the aggregation in a :class:`.MatrixTable` or :class:`.Table`; as a new row field ""agg_annot"" or a new column field ""agg_cov"". Parameters; ----------; tb : :class:`.MatrixTable` or :class:`.Table`; :class:`.MatrixTable` or :class:`.Table` containing fields to be aggregated.; coef_dict : :obj:`dict`, optional; Coefficients to multiply each field. The coefficients are specified by; `coef_dict` value, the row (or col) field name is specified by `coef_dict` key.; If not included, coefficients are assumed to be 1.; str_expr : :class:`str`, optional; Str",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/ldscsim.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html
https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html:28362,Testability,assert,assert,28362,"_annot"" or a new column field ""agg_cov"". Parameters; ----------; tb : :class:`.MatrixTable` or :class:`.Table`; :class:`.MatrixTable` or :class:`.Table` containing fields to be aggregated.; coef_dict : :obj:`dict`, optional; Coefficients to multiply each field. The coefficients are specified by; `coef_dict` value, the row (or col) field name is specified by `coef_dict` key.; If not included, coefficients are assumed to be 1.; str_expr : :class:`str`, optional; String expression to match against row (or col) field names.; axis : :class:`str`; Either 'rows' or 'cols'. If 'rows', this aggregates across row fields.; If 'cols', this aggregates across col fields. If tb is a Table, axis = 'rows'. Returns; -------; :class:`.MatrixTable` or :class:`.Table`; :class:`.MatrixTable` or :class:`.Table` containing aggregation field.; """"""; assert str_expr is not None or coef_dict is not None, ""str_expr and coef_dict cannot both be None""; assert axis in {'rows', 'cols'}, ""axis must be 'rows' or 'cols'""; coef_dict = get_coef_dict(tb=tb, str_expr=str_expr, ref_coef_dict=coef_dict, axis=axis); axis_field = 'annot' if axis == 'rows' else 'cov'; annotate_fn = (; (MatrixTable.annotate_rows if axis == 'rows' else MatrixTable.annotate_cols); if isinstance(tb, MatrixTable); else Table.annotate; ); tb = annotate_fn(self=tb, **{'agg_' + axis_field: 0}); print(f'Fields and associated coefficients used in {axis_field} aggregation: {coef_dict}'); for field, coef in coef_dict.items():; tb = annotate_fn(self=tb, **{'agg_' + axis_field: tb['agg_' + axis_field] + coef * tb[field]}); return tb. [docs]@typecheck(tb=oneof(MatrixTable, Table), str_expr=nullable(str), ref_coef_dict=nullable(dict), axis=str); def get_coef_dict(tb, str_expr=None, ref_coef_dict=None, axis='rows'):; r""""""Gets either col or row fields matching `str_expr` and take intersection; with keys in coefficient reference dict. Parameters; ----------; tb : :class:`.MatrixTable` or :class:`.Table`; :class:`.MatrixTable` or :class:`.Table` c",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/ldscsim.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html
https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html:28462,Testability,assert,assert,28462,"_annot"" or a new column field ""agg_cov"". Parameters; ----------; tb : :class:`.MatrixTable` or :class:`.Table`; :class:`.MatrixTable` or :class:`.Table` containing fields to be aggregated.; coef_dict : :obj:`dict`, optional; Coefficients to multiply each field. The coefficients are specified by; `coef_dict` value, the row (or col) field name is specified by `coef_dict` key.; If not included, coefficients are assumed to be 1.; str_expr : :class:`str`, optional; String expression to match against row (or col) field names.; axis : :class:`str`; Either 'rows' or 'cols'. If 'rows', this aggregates across row fields.; If 'cols', this aggregates across col fields. If tb is a Table, axis = 'rows'. Returns; -------; :class:`.MatrixTable` or :class:`.Table`; :class:`.MatrixTable` or :class:`.Table` containing aggregation field.; """"""; assert str_expr is not None or coef_dict is not None, ""str_expr and coef_dict cannot both be None""; assert axis in {'rows', 'cols'}, ""axis must be 'rows' or 'cols'""; coef_dict = get_coef_dict(tb=tb, str_expr=str_expr, ref_coef_dict=coef_dict, axis=axis); axis_field = 'annot' if axis == 'rows' else 'cov'; annotate_fn = (; (MatrixTable.annotate_rows if axis == 'rows' else MatrixTable.annotate_cols); if isinstance(tb, MatrixTable); else Table.annotate; ); tb = annotate_fn(self=tb, **{'agg_' + axis_field: 0}); print(f'Fields and associated coefficients used in {axis_field} aggregation: {coef_dict}'); for field, coef in coef_dict.items():; tb = annotate_fn(self=tb, **{'agg_' + axis_field: tb['agg_' + axis_field] + coef * tb[field]}); return tb. [docs]@typecheck(tb=oneof(MatrixTable, Table), str_expr=nullable(str), ref_coef_dict=nullable(dict), axis=str); def get_coef_dict(tb, str_expr=None, ref_coef_dict=None, axis='rows'):; r""""""Gets either col or row fields matching `str_expr` and take intersection; with keys in coefficient reference dict. Parameters; ----------; tb : :class:`.MatrixTable` or :class:`.Table`; :class:`.MatrixTable` or :class:`.Table` c",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/ldscsim.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html
https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html:30290,Testability,assert,assert,30290,"n coefficient reference dict. Parameters; ----------; tb : :class:`.MatrixTable` or :class:`.Table`; :class:`.MatrixTable` or :class:`.Table` containing row (or col) for `coef_dict`.; str_expr : :class:`str`, optional; String expression pattern to match against row (or col) fields. If left; unspecified, the intersection of field names is only between existing; row (or col) fields in `mt` and keys of `ref_coef_dict`.; ref_coef_dict : :obj:`dict`, optional; Reference coefficient dictionary with keys that are row (or col) field; names from which to subset. If not included, coefficients are assumed to be 1.; axis : :class:`str`; Field type in which to search for field names. Options: 'rows', 'cols'. Returns; -------; coef_dict : :obj:`dict`; Coefficients to multiply each field. The coefficients are specified by; `coef_dict` value, the row (or col) field name is specified by `coef_dict` key.; """"""; assert str_expr is not None or ref_coef_dict is not None, ""str_expr and ref_coef_dict cannot both be None""; assert axis in {'rows', 'cols'}, ""axis must be 'rows' or 'cols'""; fields_to_search = tb.row if axis == 'rows' or isinstance(tb, Table) else tb.col; # when axis='rows' we're searching for annotations, axis='cols' searching for covariates; axis_field = 'annotation' if axis == 'rows' else 'covariate'; if str_expr is None:; # take all row (or col) fields in mt matching keys in coef_dict; coef_dict = {k: ref_coef_dict[k] for k in ref_coef_dict.keys() if k in fields_to_search}; # if intersect is empty: return error; assert len(coef_dict) > 0, f'None of the keys in ref_coef_dict match any {axis[:-1]} fields'; return coef_dict # return subset of ref_coef_dict; else:; # str_expr search in list of row (or col) fields; fields = [rf for rf in list(fields_to_search) if str_expr in rf]; assert len(fields) > 0, f'No {axis[:-1]} fields matched str_expr search: {str_expr}'; if ref_coef_dict is None:; print(f'Assuming coef = 1 for all {axis_field}s'); return {k: 1 for k in fields}; in_ref_c",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/ldscsim.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html
https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html:30398,Testability,assert,assert,30398,"n coefficient reference dict. Parameters; ----------; tb : :class:`.MatrixTable` or :class:`.Table`; :class:`.MatrixTable` or :class:`.Table` containing row (or col) for `coef_dict`.; str_expr : :class:`str`, optional; String expression pattern to match against row (or col) fields. If left; unspecified, the intersection of field names is only between existing; row (or col) fields in `mt` and keys of `ref_coef_dict`.; ref_coef_dict : :obj:`dict`, optional; Reference coefficient dictionary with keys that are row (or col) field; names from which to subset. If not included, coefficients are assumed to be 1.; axis : :class:`str`; Field type in which to search for field names. Options: 'rows', 'cols'. Returns; -------; coef_dict : :obj:`dict`; Coefficients to multiply each field. The coefficients are specified by; `coef_dict` value, the row (or col) field name is specified by `coef_dict` key.; """"""; assert str_expr is not None or ref_coef_dict is not None, ""str_expr and ref_coef_dict cannot both be None""; assert axis in {'rows', 'cols'}, ""axis must be 'rows' or 'cols'""; fields_to_search = tb.row if axis == 'rows' or isinstance(tb, Table) else tb.col; # when axis='rows' we're searching for annotations, axis='cols' searching for covariates; axis_field = 'annotation' if axis == 'rows' else 'covariate'; if str_expr is None:; # take all row (or col) fields in mt matching keys in coef_dict; coef_dict = {k: ref_coef_dict[k] for k in ref_coef_dict.keys() if k in fields_to_search}; # if intersect is empty: return error; assert len(coef_dict) > 0, f'None of the keys in ref_coef_dict match any {axis[:-1]} fields'; return coef_dict # return subset of ref_coef_dict; else:; # str_expr search in list of row (or col) fields; fields = [rf for rf in list(fields_to_search) if str_expr in rf]; assert len(fields) > 0, f'No {axis[:-1]} fields matched str_expr search: {str_expr}'; if ref_coef_dict is None:; print(f'Assuming coef = 1 for all {axis_field}s'); return {k: 1 for k in fields}; in_ref_c",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/ldscsim.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html
https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html:30914,Testability,assert,assert,30914,"`dict`; Coefficients to multiply each field. The coefficients are specified by; `coef_dict` value, the row (or col) field name is specified by `coef_dict` key.; """"""; assert str_expr is not None or ref_coef_dict is not None, ""str_expr and ref_coef_dict cannot both be None""; assert axis in {'rows', 'cols'}, ""axis must be 'rows' or 'cols'""; fields_to_search = tb.row if axis == 'rows' or isinstance(tb, Table) else tb.col; # when axis='rows' we're searching for annotations, axis='cols' searching for covariates; axis_field = 'annotation' if axis == 'rows' else 'covariate'; if str_expr is None:; # take all row (or col) fields in mt matching keys in coef_dict; coef_dict = {k: ref_coef_dict[k] for k in ref_coef_dict.keys() if k in fields_to_search}; # if intersect is empty: return error; assert len(coef_dict) > 0, f'None of the keys in ref_coef_dict match any {axis[:-1]} fields'; return coef_dict # return subset of ref_coef_dict; else:; # str_expr search in list of row (or col) fields; fields = [rf for rf in list(fields_to_search) if str_expr in rf]; assert len(fields) > 0, f'No {axis[:-1]} fields matched str_expr search: {str_expr}'; if ref_coef_dict is None:; print(f'Assuming coef = 1 for all {axis_field}s'); return {k: 1 for k in fields}; in_ref_coef_dict = set(fields).intersection(set(ref_coef_dict.keys())) # fields in ref_coef_dict; # if >0 fields returned by search are not in ref_coef_dict; if in_ref_coef_dict != set(fields):; # if none of the fields returned by search are in ref_coef_dict; assert len(in_ref_coef_dict) > 0, f'None of the {axis_field} fields in ref_coef_dict match search results'; fields_to_ignore = set(fields).difference(in_ref_coef_dict); print(f'Ignored fields from {axis_field} search: {fields_to_ignore}'); print('To include ignored fields, change str_expr to match desired fields'); fields = list(in_ref_coef_dict); return {k: ref_coef_dict[k] for k in fields}. [docs]@typecheck(mt=MatrixTable, y=expr_int32, P=oneof(int, float)); def ascertainment_bias(",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/ldscsim.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html
https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html:31182,Testability,assert,assert,31182,"`dict`; Coefficients to multiply each field. The coefficients are specified by; `coef_dict` value, the row (or col) field name is specified by `coef_dict` key.; """"""; assert str_expr is not None or ref_coef_dict is not None, ""str_expr and ref_coef_dict cannot both be None""; assert axis in {'rows', 'cols'}, ""axis must be 'rows' or 'cols'""; fields_to_search = tb.row if axis == 'rows' or isinstance(tb, Table) else tb.col; # when axis='rows' we're searching for annotations, axis='cols' searching for covariates; axis_field = 'annotation' if axis == 'rows' else 'covariate'; if str_expr is None:; # take all row (or col) fields in mt matching keys in coef_dict; coef_dict = {k: ref_coef_dict[k] for k in ref_coef_dict.keys() if k in fields_to_search}; # if intersect is empty: return error; assert len(coef_dict) > 0, f'None of the keys in ref_coef_dict match any {axis[:-1]} fields'; return coef_dict # return subset of ref_coef_dict; else:; # str_expr search in list of row (or col) fields; fields = [rf for rf in list(fields_to_search) if str_expr in rf]; assert len(fields) > 0, f'No {axis[:-1]} fields matched str_expr search: {str_expr}'; if ref_coef_dict is None:; print(f'Assuming coef = 1 for all {axis_field}s'); return {k: 1 for k in fields}; in_ref_coef_dict = set(fields).intersection(set(ref_coef_dict.keys())) # fields in ref_coef_dict; # if >0 fields returned by search are not in ref_coef_dict; if in_ref_coef_dict != set(fields):; # if none of the fields returned by search are in ref_coef_dict; assert len(in_ref_coef_dict) > 0, f'None of the {axis_field} fields in ref_coef_dict match search results'; fields_to_ignore = set(fields).difference(in_ref_coef_dict); print(f'Ignored fields from {axis_field} search: {fields_to_ignore}'); print('To include ignored fields, change str_expr to match desired fields'); fields = list(in_ref_coef_dict); return {k: ref_coef_dict[k] for k in fields}. [docs]@typecheck(mt=MatrixTable, y=expr_int32, P=oneof(int, float)); def ascertainment_bias(",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/ldscsim.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html
https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html:31637,Testability,assert,assert,31637,"s' searching for covariates; axis_field = 'annotation' if axis == 'rows' else 'covariate'; if str_expr is None:; # take all row (or col) fields in mt matching keys in coef_dict; coef_dict = {k: ref_coef_dict[k] for k in ref_coef_dict.keys() if k in fields_to_search}; # if intersect is empty: return error; assert len(coef_dict) > 0, f'None of the keys in ref_coef_dict match any {axis[:-1]} fields'; return coef_dict # return subset of ref_coef_dict; else:; # str_expr search in list of row (or col) fields; fields = [rf for rf in list(fields_to_search) if str_expr in rf]; assert len(fields) > 0, f'No {axis[:-1]} fields matched str_expr search: {str_expr}'; if ref_coef_dict is None:; print(f'Assuming coef = 1 for all {axis_field}s'); return {k: 1 for k in fields}; in_ref_coef_dict = set(fields).intersection(set(ref_coef_dict.keys())) # fields in ref_coef_dict; # if >0 fields returned by search are not in ref_coef_dict; if in_ref_coef_dict != set(fields):; # if none of the fields returned by search are in ref_coef_dict; assert len(in_ref_coef_dict) > 0, f'None of the {axis_field} fields in ref_coef_dict match search results'; fields_to_ignore = set(fields).difference(in_ref_coef_dict); print(f'Ignored fields from {axis_field} search: {fields_to_ignore}'); print('To include ignored fields, change str_expr to match desired fields'); fields = list(in_ref_coef_dict); return {k: ref_coef_dict[k] for k in fields}. [docs]@typecheck(mt=MatrixTable, y=expr_int32, P=oneof(int, float)); def ascertainment_bias(mt, y, P):; r""""""Adds ascertainment bias to a binary phenotype to give it a sample; prevalence of `P` = cases/(cases+controls). Parameters; ----------; mt : :class:`.MatrixTable`; :class:`.MatrixTable` containing binary phenotype to be used.; y : :class:`.Expression`; Column field of binary phenotype.; P : :obj:`int` or :obj:`float`; Desired ""sample prevalence"" of phenotype. Returns; -------; :class:`.MatrixTable`; :class:`.MatrixTable` containing binary phenotype with prevalence",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/ldscsim.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html
https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html:32628,Testability,assert,assert,32628,"ef_coef_dict) > 0, f'None of the {axis_field} fields in ref_coef_dict match search results'; fields_to_ignore = set(fields).difference(in_ref_coef_dict); print(f'Ignored fields from {axis_field} search: {fields_to_ignore}'); print('To include ignored fields, change str_expr to match desired fields'); fields = list(in_ref_coef_dict); return {k: ref_coef_dict[k] for k in fields}. [docs]@typecheck(mt=MatrixTable, y=expr_int32, P=oneof(int, float)); def ascertainment_bias(mt, y, P):; r""""""Adds ascertainment bias to a binary phenotype to give it a sample; prevalence of `P` = cases/(cases+controls). Parameters; ----------; mt : :class:`.MatrixTable`; :class:`.MatrixTable` containing binary phenotype to be used.; y : :class:`.Expression`; Column field of binary phenotype.; P : :obj:`int` or :obj:`float`; Desired ""sample prevalence"" of phenotype. Returns; -------; :class:`.MatrixTable`; :class:`.MatrixTable` containing binary phenotype with prevalence of approx. P; """"""; assert P >= 0 and P <= 1, 'P must be in [0,1]'; uid = Env.get_uid(base=100); mt = mt.annotate_cols(y_w_asc_bias=y); y_stats = mt.aggregate_cols(hl.agg.stats(mt.y_w_asc_bias)); K = y_stats.mean; n = y_stats.n; assert abs(P - K) < 1, 'Specified sample prevalence is incompatible with population prevalence.'; if P < K:; p = (1 - K) * P / (K * (1 - P)); con = mt.filter_cols(mt.y_w_asc_bias == 0); cas = mt.filter_cols(mt.y_w_asc_bias == 1).add_col_index(name='col_idx_' + uid); keep = round(p * n * K) * [1] + round((1 - p) * n * K) * [0]; cas = cas.annotate_cols(**{'keep_' + uid: hl.literal(keep)[hl.int32(cas['col_idx_' + uid])]}); cas = cas.filter_cols(cas['keep_' + uid] == 1); cas = _clean_fields(cas, uid); mt = cas.union_cols(con); elif P > K:; p = K * (1 - P) / ((1 - K) * P); cas = mt.filter_cols(mt.y_w_asc_bias == 1); con = mt.filter_cols(mt.y_w_asc_bias == 0).add_col_index(name='col_idx_' + uid); keep = round(p * n * (1 - K)) * [1] + round((1 - p) * n * (1 - K)) * [0]; con = con.annotate_cols(**{'keep_' + uid: ",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/ldscsim.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html
https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html:32837,Testability,assert,assert,32837,"'To include ignored fields, change str_expr to match desired fields'); fields = list(in_ref_coef_dict); return {k: ref_coef_dict[k] for k in fields}. [docs]@typecheck(mt=MatrixTable, y=expr_int32, P=oneof(int, float)); def ascertainment_bias(mt, y, P):; r""""""Adds ascertainment bias to a binary phenotype to give it a sample; prevalence of `P` = cases/(cases+controls). Parameters; ----------; mt : :class:`.MatrixTable`; :class:`.MatrixTable` containing binary phenotype to be used.; y : :class:`.Expression`; Column field of binary phenotype.; P : :obj:`int` or :obj:`float`; Desired ""sample prevalence"" of phenotype. Returns; -------; :class:`.MatrixTable`; :class:`.MatrixTable` containing binary phenotype with prevalence of approx. P; """"""; assert P >= 0 and P <= 1, 'P must be in [0,1]'; uid = Env.get_uid(base=100); mt = mt.annotate_cols(y_w_asc_bias=y); y_stats = mt.aggregate_cols(hl.agg.stats(mt.y_w_asc_bias)); K = y_stats.mean; n = y_stats.n; assert abs(P - K) < 1, 'Specified sample prevalence is incompatible with population prevalence.'; if P < K:; p = (1 - K) * P / (K * (1 - P)); con = mt.filter_cols(mt.y_w_asc_bias == 0); cas = mt.filter_cols(mt.y_w_asc_bias == 1).add_col_index(name='col_idx_' + uid); keep = round(p * n * K) * [1] + round((1 - p) * n * K) * [0]; cas = cas.annotate_cols(**{'keep_' + uid: hl.literal(keep)[hl.int32(cas['col_idx_' + uid])]}); cas = cas.filter_cols(cas['keep_' + uid] == 1); cas = _clean_fields(cas, uid); mt = cas.union_cols(con); elif P > K:; p = K * (1 - P) / ((1 - K) * P); cas = mt.filter_cols(mt.y_w_asc_bias == 1); con = mt.filter_cols(mt.y_w_asc_bias == 0).add_col_index(name='col_idx_' + uid); keep = round(p * n * (1 - K)) * [1] + round((1 - p) * n * (1 - K)) * [0]; con = con.annotate_cols(**{'keep_' + uid: hl.literal(keep)[hl.int32(con['col_idx_' + uid])]}); con = con.filter_cols(con['keep_' + uid] == 1); con = _clean_fields(con, uid); mt = con.union_cols(cas); return mt. [docs]@typecheck(mt=MatrixTable, y=oneof(expr_int32, expr_flo",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/ldscsim.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/ldscsim.html
https://hail.is/docs/0.2/_modules/hail/experimental/ld_score_regression.html:6747,Availability,error,error,6747,must be a single entry-indexed field; (not a list of fields).; * ``n_samples_exprs`` must be a single entry-indexed field; (not a list of fields).; * The ``phenotype`` field that keys the table returned by; :func:`.ld_score_regression` will have values corresponding to the; column keys of the input matrix table. This function returns a :class:`~.Table` with one row per set of summary; statistics passed to the ``chi_sq_exprs`` argument. The following; row-indexed fields are included in the table:. * **phenotype** (:py:data:`.tstr`) -- The name of the phenotype. The; returned table is keyed by this field. See the notes below for; details on the possible values of this field.; * **mean_chi_sq** (:py:data:`.tfloat64`) -- The mean chi-squared; test statistic for the given phenotype.; * **intercept** (`Struct`) -- Contains fields:. - **estimate** (:py:data:`.tfloat64`) -- A point estimate of the; intercept :math:`1 + Na`.; - **standard_error** (:py:data:`.tfloat64`) -- An estimate of; the standard error of this point estimate. * **snp_heritability** (`Struct`) -- Contains fields:. - **estimate** (:py:data:`.tfloat64`) -- A point estimate of the; SNP-heritability :math:`h_g^2`.; - **standard_error** (:py:data:`.tfloat64`) -- An estimate of; the standard error of this point estimate. Warning; -------; :func:`.ld_score_regression` considers only the rows for which both row; fields ``weight_expr`` and ``ld_score_expr`` are defined. Rows with missing; values in either field are removed prior to fitting the LD score; regression model. Parameters; ----------; weight_expr : :class:`.Float64Expression`; Row-indexed expression for the LD scores used to derive; variant weights in the model.; ld_score_expr : :class:`.Float64Expression`; Row-indexed expression for the LD scores used as covariates; in the model.; chi_sq_exprs : :class:`.Float64Expression` or :obj:`list` of; :class:`.Float64Expression`; One or more row-indexed (if table) or entry-indexed; (if matrix table) expressions f,MatchSource.WIKI,docs/0.2/_modules/hail/experimental/ld_score_regression.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/ld_score_regression.html
https://hail.is/docs/0.2/_modules/hail/experimental/ld_score_regression.html:7007,Availability,error,error,7007,onding to the; column keys of the input matrix table. This function returns a :class:`~.Table` with one row per set of summary; statistics passed to the ``chi_sq_exprs`` argument. The following; row-indexed fields are included in the table:. * **phenotype** (:py:data:`.tstr`) -- The name of the phenotype. The; returned table is keyed by this field. See the notes below for; details on the possible values of this field.; * **mean_chi_sq** (:py:data:`.tfloat64`) -- The mean chi-squared; test statistic for the given phenotype.; * **intercept** (`Struct`) -- Contains fields:. - **estimate** (:py:data:`.tfloat64`) -- A point estimate of the; intercept :math:`1 + Na`.; - **standard_error** (:py:data:`.tfloat64`) -- An estimate of; the standard error of this point estimate. * **snp_heritability** (`Struct`) -- Contains fields:. - **estimate** (:py:data:`.tfloat64`) -- A point estimate of the; SNP-heritability :math:`h_g^2`.; - **standard_error** (:py:data:`.tfloat64`) -- An estimate of; the standard error of this point estimate. Warning; -------; :func:`.ld_score_regression` considers only the rows for which both row; fields ``weight_expr`` and ``ld_score_expr`` are defined. Rows with missing; values in either field are removed prior to fitting the LD score; regression model. Parameters; ----------; weight_expr : :class:`.Float64Expression`; Row-indexed expression for the LD scores used to derive; variant weights in the model.; ld_score_expr : :class:`.Float64Expression`; Row-indexed expression for the LD scores used as covariates; in the model.; chi_sq_exprs : :class:`.Float64Expression` or :obj:`list` of; :class:`.Float64Expression`; One or more row-indexed (if table) or entry-indexed; (if matrix table) expressions for chi-squared; statistics resulting from genome-wide association; studies (GWAS).; n_samples_exprs: :class:`.NumericExpression` or :obj:`list` of; :class:`.NumericExpression`; One or more row-indexed (if table) or entry-indexed; (if matrix table) expressions ,MatchSource.WIKI,docs/0.2/_modules/hail/experimental/ld_score_regression.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/ld_score_regression.html
https://hail.is/docs/0.2/_modules/hail/experimental/ld_score_regression.html:8220,Availability,error,errors,8220,"are defined. Rows with missing; values in either field are removed prior to fitting the LD score; regression model. Parameters; ----------; weight_expr : :class:`.Float64Expression`; Row-indexed expression for the LD scores used to derive; variant weights in the model.; ld_score_expr : :class:`.Float64Expression`; Row-indexed expression for the LD scores used as covariates; in the model.; chi_sq_exprs : :class:`.Float64Expression` or :obj:`list` of; :class:`.Float64Expression`; One or more row-indexed (if table) or entry-indexed; (if matrix table) expressions for chi-squared; statistics resulting from genome-wide association; studies (GWAS).; n_samples_exprs: :class:`.NumericExpression` or :obj:`list` of; :class:`.NumericExpression`; One or more row-indexed (if table) or entry-indexed; (if matrix table) expressions indicating the number of; samples used in the studies that generated the test; statistics supplied to ``chi_sq_exprs``.; n_blocks : :obj:`int`; The number of blocks used in the jackknife approach to; estimating standard errors.; two_step_threshold : :obj:`int`; Variants with chi-squared statistics greater than this; value are excluded in the first step of the two-step; procedure used to fit the model.; n_reference_panel_variants : :obj:`int`, optional; Number of variants used to estimate the; SNP-heritability :math:`h_g^2`. Returns; -------; :class:`~.Table`; Table keyed by ``phenotype`` with intercept and heritability estimates; for each phenotype passed to the function."""""". chi_sq_exprs = wrap_to_list(chi_sq_exprs); n_samples_exprs = wrap_to_list(n_samples_exprs). assert (len(chi_sq_exprs) == len(n_samples_exprs)) or (len(n_samples_exprs) == 1); __k = 2 # number of covariates, including intercept. ds = chi_sq_exprs[0]._indices.source. analyze('ld_score_regression/weight_expr', weight_expr, ds._row_indices); analyze('ld_score_regression/ld_score_expr', ld_score_expr, ds._row_indices). # format input dataset; if isinstance(ds, hl.MatrixTable):; if len(chi",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/ld_score_regression.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/ld_score_regression.html
https://hail.is/docs/0.2/_modules/hail/experimental/ld_score_regression.html:18103,Deployability,update,updated,18103,"as_bias_corrected),; __step2_jackknife_variance=(; hl.sum(mt.__step2_block_betas_bias_corrected**2); - hl.sum(mt.__step2_block_betas_bias_corrected) ** 2 / n_blocks; ); / (n_blocks - 1); / n_blocks,; ). # combine step 1 and step 2 block jackknifes; mt = mt.annotate_entries(; __step2_initial_w=1.0; / (mt.__w_initial_floor * 2.0 * (mt.__initial_betas[0] + +mt.__initial_betas[1] * mt.__x_floor) ** 2); ). mt = mt.annotate_cols(; __final_betas=[mt.__step1_betas[0], mt.__step2_betas[1]],; __c=(hl.agg.sum(mt.__step2_initial_w * mt.__x) / hl.agg.sum(mt.__step2_initial_w * mt.__x**2)),; ). mt = mt.annotate_cols(; __final_block_betas=hl.map(; lambda i: (mt.__step2_block_betas[i] - mt.__c * (mt.__step1_block_betas[i][0] - mt.__final_betas[0])),; hl.range(0, n_blocks),; ); ). mt = mt.annotate_cols(; __final_block_betas_bias_corrected=(n_blocks * mt.__final_betas[1] - (n_blocks - 1) * mt.__final_block_betas); ). mt = mt.annotate_cols(; __final_jackknife_mean=[mt.__step1_jackknife_mean[0], hl.mean(mt.__final_block_betas_bias_corrected)],; __final_jackknife_variance=[; mt.__step1_jackknife_variance[0],; (; hl.sum(mt.__final_block_betas_bias_corrected**2); - hl.sum(mt.__final_block_betas_bias_corrected) ** 2 / n_blocks; ); / (n_blocks - 1); / n_blocks,; ],; ). # convert coefficient to heritability estimate; mt = mt.annotate_cols(; phenotype=mt.__y_name,; mean_chi_sq=hl.agg.mean(mt.__y),; intercept=hl.struct(estimate=mt.__final_betas[0], standard_error=hl.sqrt(mt.__final_jackknife_variance[0])),; snp_heritability=hl.struct(; estimate=(M / hl.agg.mean(mt.__n)) * mt.__final_betas[1],; standard_error=hl.sqrt((M / hl.agg.mean(mt.__n)) ** 2 * mt.__final_jackknife_variance[1]),; ),; ). # format and return results; ht = mt.cols(); ht = ht.key_by(ht.phenotype); ht = ht.select(ht.mean_chi_sq, ht.intercept, ht.snp_heritability). ht_tmp_file = new_temp_file(); ht.write(ht_tmp_file); ht = hl.read_table(ht_tmp_file). return ht. © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/ld_score_regression.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/ld_score_regression.html
https://hail.is/docs/0.2/_modules/hail/experimental/ld_score_regression.html:1826,Testability,test,test,1826,"ight_expr=expr_float64,; ld_score_expr=expr_numeric,; chi_sq_exprs=oneof(expr_float64, sequenceof(expr_float64)),; n_samples_exprs=oneof(expr_numeric, sequenceof(expr_numeric)),; n_blocks=int,; two_step_threshold=int,; n_reference_panel_variants=nullable(int),; ); def ld_score_regression(; weight_expr,; ld_score_expr,; chi_sq_exprs,; n_samples_exprs,; n_blocks=200,; two_step_threshold=30,; n_reference_panel_variants=None,; ) -> Table:; r""""""Estimate SNP-heritability and level of confounding biases from genome-wide association study; (GWAS) summary statistics. Given a set or multiple sets of GWAS summary statistics, :func:`.ld_score_regression` estimates the heritability; of a trait or set of traits and the level of confounding biases present in; the underlying studies by regressing chi-squared statistics on LD scores,; leveraging the model:. .. math::. \mathrm{E}[\chi_j^2] = 1 + Na + \frac{Nh_g^2}{M}l_j. * :math:`\mathrm{E}[\chi_j^2]` is the expected chi-squared statistic; for variant :math:`j` resulting from a test of association between; variant :math:`j` and a trait.; * :math:`l_j = \sum_{k} r_{jk}^2` is the LD score of variant; :math:`j`, calculated as the sum of squared correlation coefficients; between variant :math:`j` and nearby variants. See :func:`ld_score`; for further details.; * :math:`a` captures the contribution of confounding biases, such as; cryptic relatedness and uncontrolled population structure, to the; association test statistic.; * :math:`h_g^2` is the SNP-heritability, or the proportion of variation; in the trait explained by the effects of variants included in the; regression model above.; * :math:`M` is the number of variants used to estimate :math:`h_g^2`.; * :math:`N` is the number of samples in the underlying association study. For more details on the method implemented in this function, see:. * `LD Score regression distinguishes confounding from polygenicity in genome-wide association studies (Bulik-Sullivan et al, 2015) <https://www.ncbi",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/ld_score_regression.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/ld_score_regression.html
https://hail.is/docs/0.2/_modules/hail/experimental/ld_score_regression.html:2259,Testability,test,test,2259,"; n_reference_panel_variants=None,; ) -> Table:; r""""""Estimate SNP-heritability and level of confounding biases from genome-wide association study; (GWAS) summary statistics. Given a set or multiple sets of GWAS summary statistics, :func:`.ld_score_regression` estimates the heritability; of a trait or set of traits and the level of confounding biases present in; the underlying studies by regressing chi-squared statistics on LD scores,; leveraging the model:. .. math::. \mathrm{E}[\chi_j^2] = 1 + Na + \frac{Nh_g^2}{M}l_j. * :math:`\mathrm{E}[\chi_j^2]` is the expected chi-squared statistic; for variant :math:`j` resulting from a test of association between; variant :math:`j` and a trait.; * :math:`l_j = \sum_{k} r_{jk}^2` is the LD score of variant; :math:`j`, calculated as the sum of squared correlation coefficients; between variant :math:`j` and nearby variants. See :func:`ld_score`; for further details.; * :math:`a` captures the contribution of confounding biases, such as; cryptic relatedness and uncontrolled population structure, to the; association test statistic.; * :math:`h_g^2` is the SNP-heritability, or the proportion of variation; in the trait explained by the effects of variants included in the; regression model above.; * :math:`M` is the number of variants used to estimate :math:`h_g^2`.; * :math:`N` is the number of samples in the underlying association study. For more details on the method implemented in this function, see:. * `LD Score regression distinguishes confounding from polygenicity in genome-wide association studies (Bulik-Sullivan et al, 2015) <https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4495769/>`__. Examples; --------. Run the method on a matrix table of summary statistics, where the rows; are variants and the columns are different phenotypes:. >>> mt_gwas = ld_score_all_phenos_sumstats; >>> ht_results = hl.experimental.ld_score_regression(; ... weight_expr=mt_gwas['ld_score'],; ... ld_score_expr=mt_gwas['ld_score'],; ... chi_sq_exprs=mt_gw",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/ld_score_regression.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/ld_score_regression.html
https://hail.is/docs/0.2/_modules/hail/experimental/ld_score_regression.html:6489,Testability,test,test,6489,data:`.tstr` that uniquely identifies phenotypes; represented in the matrix table. The column key must be a single; expression; compound keys are not accepted.; * ``weight_expr`` and ``ld_score_expr`` must be row-indexed; fields.; * ``chi_sq_exprs`` must be a single entry-indexed field; (not a list of fields).; * ``n_samples_exprs`` must be a single entry-indexed field; (not a list of fields).; * The ``phenotype`` field that keys the table returned by; :func:`.ld_score_regression` will have values corresponding to the; column keys of the input matrix table. This function returns a :class:`~.Table` with one row per set of summary; statistics passed to the ``chi_sq_exprs`` argument. The following; row-indexed fields are included in the table:. * **phenotype** (:py:data:`.tstr`) -- The name of the phenotype. The; returned table is keyed by this field. See the notes below for; details on the possible values of this field.; * **mean_chi_sq** (:py:data:`.tfloat64`) -- The mean chi-squared; test statistic for the given phenotype.; * **intercept** (`Struct`) -- Contains fields:. - **estimate** (:py:data:`.tfloat64`) -- A point estimate of the; intercept :math:`1 + Na`.; - **standard_error** (:py:data:`.tfloat64`) -- An estimate of; the standard error of this point estimate. * **snp_heritability** (`Struct`) -- Contains fields:. - **estimate** (:py:data:`.tfloat64`) -- A point estimate of the; SNP-heritability :math:`h_g^2`.; - **standard_error** (:py:data:`.tfloat64`) -- An estimate of; the standard error of this point estimate. Warning; -------; :func:`.ld_score_regression` considers only the rows for which both row; fields ``weight_expr`` and ``ld_score_expr`` are defined. Rows with missing; values in either field are removed prior to fitting the LD score; regression model. Parameters; ----------; weight_expr : :class:`.Float64Expression`; Row-indexed expression for the LD scores used to derive; variant weights in the model.; ld_score_expr : :class:`.Float64Expression`; Ro,MatchSource.WIKI,docs/0.2/_modules/hail/experimental/ld_score_regression.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/ld_score_regression.html
https://hail.is/docs/0.2/_modules/hail/experimental/ld_score_regression.html:8073,Testability,test,test,8073,"rror of this point estimate. Warning; -------; :func:`.ld_score_regression` considers only the rows for which both row; fields ``weight_expr`` and ``ld_score_expr`` are defined. Rows with missing; values in either field are removed prior to fitting the LD score; regression model. Parameters; ----------; weight_expr : :class:`.Float64Expression`; Row-indexed expression for the LD scores used to derive; variant weights in the model.; ld_score_expr : :class:`.Float64Expression`; Row-indexed expression for the LD scores used as covariates; in the model.; chi_sq_exprs : :class:`.Float64Expression` or :obj:`list` of; :class:`.Float64Expression`; One or more row-indexed (if table) or entry-indexed; (if matrix table) expressions for chi-squared; statistics resulting from genome-wide association; studies (GWAS).; n_samples_exprs: :class:`.NumericExpression` or :obj:`list` of; :class:`.NumericExpression`; One or more row-indexed (if table) or entry-indexed; (if matrix table) expressions indicating the number of; samples used in the studies that generated the test; statistics supplied to ``chi_sq_exprs``.; n_blocks : :obj:`int`; The number of blocks used in the jackknife approach to; estimating standard errors.; two_step_threshold : :obj:`int`; Variants with chi-squared statistics greater than this; value are excluded in the first step of the two-step; procedure used to fit the model.; n_reference_panel_variants : :obj:`int`, optional; Number of variants used to estimate the; SNP-heritability :math:`h_g^2`. Returns; -------; :class:`~.Table`; Table keyed by ``phenotype`` with intercept and heritability estimates; for each phenotype passed to the function."""""". chi_sq_exprs = wrap_to_list(chi_sq_exprs); n_samples_exprs = wrap_to_list(n_samples_exprs). assert (len(chi_sq_exprs) == len(n_samples_exprs)) or (len(n_samples_exprs) == 1); __k = 2 # number of covariates, including intercept. ds = chi_sq_exprs[0]._indices.source. analyze('ld_score_regression/weight_expr', weight_expr, d",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/ld_score_regression.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/ld_score_regression.html
https://hail.is/docs/0.2/_modules/hail/experimental/ld_score_regression.html:8777,Testability,assert,assert,8777,"ass:`.NumericExpression` or :obj:`list` of; :class:`.NumericExpression`; One or more row-indexed (if table) or entry-indexed; (if matrix table) expressions indicating the number of; samples used in the studies that generated the test; statistics supplied to ``chi_sq_exprs``.; n_blocks : :obj:`int`; The number of blocks used in the jackknife approach to; estimating standard errors.; two_step_threshold : :obj:`int`; Variants with chi-squared statistics greater than this; value are excluded in the first step of the two-step; procedure used to fit the model.; n_reference_panel_variants : :obj:`int`, optional; Number of variants used to estimate the; SNP-heritability :math:`h_g^2`. Returns; -------; :class:`~.Table`; Table keyed by ``phenotype`` with intercept and heritability estimates; for each phenotype passed to the function."""""". chi_sq_exprs = wrap_to_list(chi_sq_exprs); n_samples_exprs = wrap_to_list(n_samples_exprs). assert (len(chi_sq_exprs) == len(n_samples_exprs)) or (len(n_samples_exprs) == 1); __k = 2 # number of covariates, including intercept. ds = chi_sq_exprs[0]._indices.source. analyze('ld_score_regression/weight_expr', weight_expr, ds._row_indices); analyze('ld_score_regression/ld_score_expr', ld_score_expr, ds._row_indices). # format input dataset; if isinstance(ds, hl.MatrixTable):; if len(chi_sq_exprs) != 1:; raise ValueError(""""""Only one chi_sq_expr allowed if originating; from a matrix table.""""""); if len(n_samples_exprs) != 1:; raise ValueError(""""""Only one n_samples_expr allowed if; originating from a matrix table.""""""). col_key = list(ds.col_key); if len(col_key) != 1:; raise ValueError(""""""Matrix table must be keyed by a single; phenotype field.""""""). analyze('ld_score_regression/chi_squared_expr', chi_sq_exprs[0], ds._entry_indices); analyze('ld_score_regression/n_samples_expr', n_samples_exprs[0], ds._entry_indices). ds = ds._select_all(; row_exprs={; '__locus': ds.locus,; '__alleles': ds.alleles,; '__w_initial': weight_expr,; '__w_initial_floor': ",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/ld_score_regression.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/ld_score_regression.html
https://hail.is/docs/0.2/_modules/hail/experimental/ld_score_regression.html:10309,Testability,assert,assert,10309,"lowed if; originating from a matrix table.""""""). col_key = list(ds.col_key); if len(col_key) != 1:; raise ValueError(""""""Matrix table must be keyed by a single; phenotype field.""""""). analyze('ld_score_regression/chi_squared_expr', chi_sq_exprs[0], ds._entry_indices); analyze('ld_score_regression/n_samples_expr', n_samples_exprs[0], ds._entry_indices). ds = ds._select_all(; row_exprs={; '__locus': ds.locus,; '__alleles': ds.alleles,; '__w_initial': weight_expr,; '__w_initial_floor': hl.max(weight_expr, 1.0),; '__x': ld_score_expr,; '__x_floor': hl.max(ld_score_expr, 1.0),; },; row_key=['__locus', '__alleles'],; col_exprs={'__y_name': ds[col_key[0]]},; col_key=['__y_name'],; entry_exprs={'__y': chi_sq_exprs[0], '__n': n_samples_exprs[0]},; ); ds = ds.annotate_entries(**{'__w': ds.__w_initial}). ds = ds.filter_rows(; hl.is_defined(ds.__locus); & hl.is_defined(ds.__alleles); & hl.is_defined(ds.__w_initial); & hl.is_defined(ds.__x); ). else:; assert isinstance(ds, Table); for y in chi_sq_exprs:; analyze('ld_score_regression/chi_squared_expr', y, ds._row_indices); for n in n_samples_exprs:; analyze('ld_score_regression/n_samples_expr', n, ds._row_indices). ys = ['__y{:}'.format(i) for i, _ in enumerate(chi_sq_exprs)]; ws = ['__w{:}'.format(i) for i, _ in enumerate(chi_sq_exprs)]; ns = ['__n{:}'.format(i) for i, _ in enumerate(n_samples_exprs)]. ds = ds.select(; **dict(; **{'__locus': ds.locus, '__alleles': ds.alleles, '__w_initial': weight_expr, '__x': ld_score_expr},; **{y: chi_sq_exprs[i] for i, y in enumerate(ys)},; **{w: weight_expr for w in ws},; **{n: n_samples_exprs[i] for i, n in enumerate(ns)},; ); ); ds = ds.key_by(ds.__locus, ds.__alleles). table_tmp_file = new_temp_file(); ds.write(table_tmp_file); ds = hl.read_table(table_tmp_file). hts = [; ds.select(**{; '__w_initial': ds.__w_initial,; '__w_initial_floor': hl.max(ds.__w_initial, 1.0),; '__x': ds.__x,; '__x_floor': hl.max(ds.__x, 1.0),; '__y_name': i,; '__y': ds[ys[i]],; '__w': ds[ws[i]],; '__n': hl.int(ds[ns[",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/ld_score_regression.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/ld_score_regression.html
https://hail.is/docs/0.2/_modules/hail/experimental/loop.html:1435,Availability,error,error,1435,"cy. menu; Hail. Module code; hail.experimental.loop. Source code for hail.experimental.loop; from typing import Callable. from hail import ir; from hail.expr.expressions import construct_expr, construct_variable, expr_any, to_expr, unify_all; from hail.expr.types import hail_type; from hail.typecheck import anytype, typecheck; from hail.utils.java import Env. [docs]@typecheck(f=anytype, typ=hail_type, args=expr_any); def loop(f: Callable, typ, *args):; r""""""Define and call a tail-recursive function with given arguments. Notes; -----; The argument `f` must be a function where the first argument defines the; recursive call, and the remaining arguments are the arguments to the; recursive function, e.g. to define the recursive function. .. math::. f(x, y) = \begin{cases}; y & \textrm{if } x \equiv 0 \\; f(x - 1, y + x) & \textrm{otherwise}; \end{cases}. we would write:; >>> f = lambda recur, x, y: hl.if_else(x == 0, y, recur(x - 1, y + x)). Full recursion is not supported, and any non-tail-recursive methods will; throw an error when called. This means that the result of any recursive call within the function must; also be the result of the entire function, without modification. Let's; consider two different recursive definitions for the triangle function; :math:`f(x) = 0 + 1 + \dots + x`:. >>> def triangle1(x):; ... if x == 1:; ... return x; ... return x + triangle1(x - 1). >>> def triangle2(x, total):; ... if x == 0:; ... return total; ... return triangle2(x - 1, total + x). The first function definition, `triangle1`, will call itself and then add x.; This is an example of a non-tail recursive function, since `triangle1(9)`; needs to modify the result of the inner recursive call to `triangle1(8)` by; adding 9 to the result. The second function is tail recursive: the result of `triangle2(9, 0)` is; the same as the result of the inner recursive call, `triangle2(8, 9)`. Example; -------; To find the sum of all the numbers from n=1...10:; >>> triangle_f = lambda f, x, total",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/loop.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/loop.html
https://hail.is/docs/0.2/_modules/hail/experimental/loop.html:3093,Availability,error,error,3093,"the inner recursive call to `triangle1(8)` by; adding 9 to the result. The second function is tail recursive: the result of `triangle2(9, 0)` is; the same as the result of the inner recursive call, `triangle2(8, 9)`. Example; -------; To find the sum of all the numbers from n=1...10:; >>> triangle_f = lambda f, x, total: hl.if_else(x == 0, total, f(x - 1, total + x)); >>> x = hl.experimental.loop(triangle_f, hl.tint32, 10, 0); >>> hl.eval(x); 55. Let's say we want to find the root of a polynomial equation:; >>> def polynomial(x):; ... return 5 * x**3 - 2 * x - 1. We'll use `Newton's method<https://en.wikipedia.org/wiki/Newton%27s_method>`; to find it, so we'll also define the derivative:. >>> def derivative(x):; ... return 15 * x**2 - 2. and starting at :math:`x_0 = 0`, we'll compute the next step :math:`x_{i+1} = x_i - \frac{f(x_i)}{f'(x_i)}`; until the difference between :math:`x_{i}` and :math:`x_{i+1}` falls below; our convergence threshold:. >>> threshold = 0.005; >>> def find_root(f, guess, error):; ... converged = hl.is_defined(error) & (error < threshold); ... new_guess = guess - (polynomial(guess) / derivative(guess)); ... new_error = hl.abs(new_guess - guess); ... return hl.if_else(converged, guess, f(new_guess, new_error)); >>> x = hl.experimental.loop(find_root, hl.tfloat, 0.0, hl.missing(hl.tfloat)); >>> hl.eval(x); 0.8052291984599675. Warning; -------; Using arguments of a type other than numeric types and booleans can cause; memory issues if if you expect the recursive call to happen many times. Parameters; ----------; f : function ( (marker, \*args) -> :class:`.Expression`; Function of one callable marker, denoting where the recursive call (or calls) is located,; and many `args`, the loop variables.; typ : :class:`str` or :class:`.HailType`; Type the loop returns.; args : variable-length args of :class:`.Expression`; Expressions to initialize the loop values.; Returns; -------; :class:`.Expression`; Result of the loop with `args` as initial loop value",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/loop.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/loop.html
https://hail.is/docs/0.2/_modules/hail/experimental/loop.html:3132,Availability,error,error,3132,"e result. The second function is tail recursive: the result of `triangle2(9, 0)` is; the same as the result of the inner recursive call, `triangle2(8, 9)`. Example; -------; To find the sum of all the numbers from n=1...10:; >>> triangle_f = lambda f, x, total: hl.if_else(x == 0, total, f(x - 1, total + x)); >>> x = hl.experimental.loop(triangle_f, hl.tint32, 10, 0); >>> hl.eval(x); 55. Let's say we want to find the root of a polynomial equation:; >>> def polynomial(x):; ... return 5 * x**3 - 2 * x - 1. We'll use `Newton's method<https://en.wikipedia.org/wiki/Newton%27s_method>`; to find it, so we'll also define the derivative:. >>> def derivative(x):; ... return 15 * x**2 - 2. and starting at :math:`x_0 = 0`, we'll compute the next step :math:`x_{i+1} = x_i - \frac{f(x_i)}{f'(x_i)}`; until the difference between :math:`x_{i}` and :math:`x_{i+1}` falls below; our convergence threshold:. >>> threshold = 0.005; >>> def find_root(f, guess, error):; ... converged = hl.is_defined(error) & (error < threshold); ... new_guess = guess - (polynomial(guess) / derivative(guess)); ... new_error = hl.abs(new_guess - guess); ... return hl.if_else(converged, guess, f(new_guess, new_error)); >>> x = hl.experimental.loop(find_root, hl.tfloat, 0.0, hl.missing(hl.tfloat)); >>> hl.eval(x); 0.8052291984599675. Warning; -------; Using arguments of a type other than numeric types and booleans can cause; memory issues if if you expect the recursive call to happen many times. Parameters; ----------; f : function ( (marker, \*args) -> :class:`.Expression`; Function of one callable marker, denoting where the recursive call (or calls) is located,; and many `args`, the loop variables.; typ : :class:`str` or :class:`.HailType`; Type the loop returns.; args : variable-length args of :class:`.Expression`; Expressions to initialize the loop values.; Returns; -------; :class:`.Expression`; Result of the loop with `args` as initial loop values.; """""". loop_name = Env.get_uid(). def contains_recursive_c",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/loop.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/loop.html
https://hail.is/docs/0.2/_modules/hail/experimental/loop.html:3142,Availability,error,error,3142,"e result. The second function is tail recursive: the result of `triangle2(9, 0)` is; the same as the result of the inner recursive call, `triangle2(8, 9)`. Example; -------; To find the sum of all the numbers from n=1...10:; >>> triangle_f = lambda f, x, total: hl.if_else(x == 0, total, f(x - 1, total + x)); >>> x = hl.experimental.loop(triangle_f, hl.tint32, 10, 0); >>> hl.eval(x); 55. Let's say we want to find the root of a polynomial equation:; >>> def polynomial(x):; ... return 5 * x**3 - 2 * x - 1. We'll use `Newton's method<https://en.wikipedia.org/wiki/Newton%27s_method>`; to find it, so we'll also define the derivative:. >>> def derivative(x):; ... return 15 * x**2 - 2. and starting at :math:`x_0 = 0`, we'll compute the next step :math:`x_{i+1} = x_i - \frac{f(x_i)}{f'(x_i)}`; until the difference between :math:`x_{i}` and :math:`x_{i+1}` falls below; our convergence threshold:. >>> threshold = 0.005; >>> def find_root(f, guess, error):; ... converged = hl.is_defined(error) & (error < threshold); ... new_guess = guess - (polynomial(guess) / derivative(guess)); ... new_error = hl.abs(new_guess - guess); ... return hl.if_else(converged, guess, f(new_guess, new_error)); >>> x = hl.experimental.loop(find_root, hl.tfloat, 0.0, hl.missing(hl.tfloat)); >>> hl.eval(x); 0.8052291984599675. Warning; -------; Using arguments of a type other than numeric types and booleans can cause; memory issues if if you expect the recursive call to happen many times. Parameters; ----------; f : function ( (marker, \*args) -> :class:`.Expression`; Function of one callable marker, denoting where the recursive call (or calls) is located,; and many `args`, the loop variables.; typ : :class:`str` or :class:`.HailType`; Type the loop returns.; args : variable-length args of :class:`.Expression`; Expressions to initialize the loop values.; Returns; -------; :class:`.Expression`; Result of the loop with `args` as initial loop values.; """""". loop_name = Env.get_uid(). def contains_recursive_c",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/loop.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/loop.html
https://hail.is/docs/0.2/_modules/hail/experimental/loop.html:5420,Availability,error,error,5420,"(loop_ir, ir.If):; if contains_recursive_call(loop_ir.cond):; raise TypeError(""branch condition can't contain recursive call!""); check_tail_recursive(loop_ir.cnsq); check_tail_recursive(loop_ir.altr); elif isinstance(loop_ir, ir.Let):; if contains_recursive_call(loop_ir.value):; raise TypeError(""bound value used in other expression can't contain recursive call!""); check_tail_recursive(loop_ir.body); elif isinstance(loop_ir, ir.TailLoop):; if any(contains_recursive_call(x) for n, x in loop_ir.params):; raise TypeError(""parameters passed to inner loop can't contain recursive call!""); elif not isinstance(loop_ir, ir.Recur) and contains_recursive_call(loop_ir):; raise TypeError(""found recursive expression outside of tail position!""). @typecheck(recur_exprs=expr_any); def make_loop(*recur_exprs):; if len(recur_exprs) != len(args):; raise TypeError('Recursive call in loop has wrong number of arguments'); err = None; for i, (rexpr, expr) in enumerate(zip(recur_exprs, args)):; if rexpr.dtype != expr.dtype:; if err is None:; err = 'Type error in recursive call,'; err += f'\n at argument index {i}, loop arg type: {expr.dtype}, '; err += f'recur arg type: {rexpr.dtype}'; if err is not None:; raise TypeError(err); irs = [expr._ir for expr in recur_exprs]; indices, aggregations = unify_all(*recur_exprs); return construct_expr(ir.Recur(loop_name, irs, typ), typ, indices, aggregations). uid_irs = []; loop_vars = []. for expr in args:; uid = Env.get_uid(); loop_vars.append(construct_variable(uid, expr._type, expr._indices, expr._aggregations)); uid_irs.append((uid, expr._ir)). loop_f = to_expr(f(make_loop, *loop_vars)); if loop_f.dtype != typ:; raise TypeError(f""requested type {typ} does not match inferred type {loop_f.dtype}""); check_tail_recursive(loop_f._ir); indices, aggregations = unify_all(*args, loop_f). return construct_expr(ir.TailLoop(loop_name, loop_f._ir, uid_irs), loop_f.dtype, indices, aggregations). © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/loop.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/loop.html
https://hail.is/docs/0.2/_modules/hail/experimental/loop.html:6348,Deployability,update,updated,6348,"(loop_ir, ir.If):; if contains_recursive_call(loop_ir.cond):; raise TypeError(""branch condition can't contain recursive call!""); check_tail_recursive(loop_ir.cnsq); check_tail_recursive(loop_ir.altr); elif isinstance(loop_ir, ir.Let):; if contains_recursive_call(loop_ir.value):; raise TypeError(""bound value used in other expression can't contain recursive call!""); check_tail_recursive(loop_ir.body); elif isinstance(loop_ir, ir.TailLoop):; if any(contains_recursive_call(x) for n, x in loop_ir.params):; raise TypeError(""parameters passed to inner loop can't contain recursive call!""); elif not isinstance(loop_ir, ir.Recur) and contains_recursive_call(loop_ir):; raise TypeError(""found recursive expression outside of tail position!""). @typecheck(recur_exprs=expr_any); def make_loop(*recur_exprs):; if len(recur_exprs) != len(args):; raise TypeError('Recursive call in loop has wrong number of arguments'); err = None; for i, (rexpr, expr) in enumerate(zip(recur_exprs, args)):; if rexpr.dtype != expr.dtype:; if err is None:; err = 'Type error in recursive call,'; err += f'\n at argument index {i}, loop arg type: {expr.dtype}, '; err += f'recur arg type: {rexpr.dtype}'; if err is not None:; raise TypeError(err); irs = [expr._ir for expr in recur_exprs]; indices, aggregations = unify_all(*recur_exprs); return construct_expr(ir.Recur(loop_name, irs, typ), typ, indices, aggregations). uid_irs = []; loop_vars = []. for expr in args:; uid = Env.get_uid(); loop_vars.append(construct_variable(uid, expr._type, expr._indices, expr._aggregations)); uid_irs.append((uid, expr._ir)). loop_f = to_expr(f(make_loop, *loop_vars)); if loop_f.dtype != typ:; raise TypeError(f""requested type {typ} does not match inferred type {loop_f.dtype}""); check_tail_recursive(loop_f._ir); indices, aggregations = unify_all(*args, loop_f). return construct_expr(ir.TailLoop(loop_name, loop_f._ir, uid_irs), loop_f.dtype, indices, aggregations). © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/loop.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/loop.html
https://hail.is/docs/0.2/_modules/hail/experimental/loop.html:3815,Modifiability,variab,variables,3815,"define the derivative:. >>> def derivative(x):; ... return 15 * x**2 - 2. and starting at :math:`x_0 = 0`, we'll compute the next step :math:`x_{i+1} = x_i - \frac{f(x_i)}{f'(x_i)}`; until the difference between :math:`x_{i}` and :math:`x_{i+1}` falls below; our convergence threshold:. >>> threshold = 0.005; >>> def find_root(f, guess, error):; ... converged = hl.is_defined(error) & (error < threshold); ... new_guess = guess - (polynomial(guess) / derivative(guess)); ... new_error = hl.abs(new_guess - guess); ... return hl.if_else(converged, guess, f(new_guess, new_error)); >>> x = hl.experimental.loop(find_root, hl.tfloat, 0.0, hl.missing(hl.tfloat)); >>> hl.eval(x); 0.8052291984599675. Warning; -------; Using arguments of a type other than numeric types and booleans can cause; memory issues if if you expect the recursive call to happen many times. Parameters; ----------; f : function ( (marker, \*args) -> :class:`.Expression`; Function of one callable marker, denoting where the recursive call (or calls) is located,; and many `args`, the loop variables.; typ : :class:`str` or :class:`.HailType`; Type the loop returns.; args : variable-length args of :class:`.Expression`; Expressions to initialize the loop values.; Returns; -------; :class:`.Expression`; Result of the loop with `args` as initial loop values.; """""". loop_name = Env.get_uid(). def contains_recursive_call(non_recursive):; if isinstance(non_recursive, ir.Recur) and non_recursive.name == loop_name:; return True; return any([contains_recursive_call(c) for c in non_recursive.children]). def check_tail_recursive(loop_ir):; if isinstance(loop_ir, ir.If):; if contains_recursive_call(loop_ir.cond):; raise TypeError(""branch condition can't contain recursive call!""); check_tail_recursive(loop_ir.cnsq); check_tail_recursive(loop_ir.altr); elif isinstance(loop_ir, ir.Let):; if contains_recursive_call(loop_ir.value):; raise TypeError(""bound value used in other expression can't contain recursive call!""); check_tail_r",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/loop.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/loop.html
https://hail.is/docs/0.2/_modules/hail/experimental/loop.html:3900,Modifiability,variab,variable-length,3900," \frac{f(x_i)}{f'(x_i)}`; until the difference between :math:`x_{i}` and :math:`x_{i+1}` falls below; our convergence threshold:. >>> threshold = 0.005; >>> def find_root(f, guess, error):; ... converged = hl.is_defined(error) & (error < threshold); ... new_guess = guess - (polynomial(guess) / derivative(guess)); ... new_error = hl.abs(new_guess - guess); ... return hl.if_else(converged, guess, f(new_guess, new_error)); >>> x = hl.experimental.loop(find_root, hl.tfloat, 0.0, hl.missing(hl.tfloat)); >>> hl.eval(x); 0.8052291984599675. Warning; -------; Using arguments of a type other than numeric types and booleans can cause; memory issues if if you expect the recursive call to happen many times. Parameters; ----------; f : function ( (marker, \*args) -> :class:`.Expression`; Function of one callable marker, denoting where the recursive call (or calls) is located,; and many `args`, the loop variables.; typ : :class:`str` or :class:`.HailType`; Type the loop returns.; args : variable-length args of :class:`.Expression`; Expressions to initialize the loop values.; Returns; -------; :class:`.Expression`; Result of the loop with `args` as initial loop values.; """""". loop_name = Env.get_uid(). def contains_recursive_call(non_recursive):; if isinstance(non_recursive, ir.Recur) and non_recursive.name == loop_name:; return True; return any([contains_recursive_call(c) for c in non_recursive.children]). def check_tail_recursive(loop_ir):; if isinstance(loop_ir, ir.If):; if contains_recursive_call(loop_ir.cond):; raise TypeError(""branch condition can't contain recursive call!""); check_tail_recursive(loop_ir.cnsq); check_tail_recursive(loop_ir.altr); elif isinstance(loop_ir, ir.Let):; if contains_recursive_call(loop_ir.value):; raise TypeError(""bound value used in other expression can't contain recursive call!""); check_tail_recursive(loop_ir.body); elif isinstance(loop_ir, ir.TailLoop):; if any(contains_recursive_call(x) for n, x in loop_ir.params):; raise TypeError(""parameters p",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/loop.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/loop.html
https://hail.is/docs/0.2/_modules/hail/experimental/pca.html:3303,Deployability,update,updated,3303,"lt_alleles()) / 2) # doctest: +SKIP; >>> loadings_ht = loadings_ht.annotate(af=mt.rows()[loadings_ht.key].af) # doctest: +SKIP; >>> # Project new genotypes onto loadings; >>> ht = pc_project(mt_to_project.GT, loadings_ht.loadings, loadings_ht.af) # doctest: +SKIP. Parameters; ----------; call_expr : :class:`.CallExpression`; Entry-indexed call expression for genotypes; to project onto loadings.; loadings_expr : :class:`.ArrayNumericExpression`; Location of expression for loadings; af_expr : :class:`.Float64Expression`; Location of expression for allele frequency. Returns; -------; :class:`.Table`; Table with scores calculated from loadings in column `scores`; """"""; raise_unless_entry_indexed('pc_project', call_expr); raise_unless_row_indexed('pc_project', loadings_expr); raise_unless_row_indexed('pc_project', af_expr). gt_source = call_expr._indices.source; loadings_source = loadings_expr._indices.source; af_source = af_expr._indices.source. loadings_expr = _get_expr_or_join(loadings_expr, loadings_source, gt_source, '_loadings'); af_expr = _get_expr_or_join(af_expr, af_source, gt_source, '_af'). mt = gt_source._annotate_all(; row_exprs={'_loadings': loadings_expr, '_af': af_expr}, entry_exprs={'_call': call_expr}; ). if isinstance(loadings_source, hl.MatrixTable):; n_variants = loadings_source.count_rows(); else:; n_variants = loadings_source.count(). mt = mt.filter_rows(hl.is_defined(mt._loadings) & hl.is_defined(mt._af) & (mt._af > 0) & (mt._af < 1)). gt_norm = (mt._call.n_alt_alleles() - 2 * mt._af) / hl.sqrt(n_variants * 2 * mt._af * (1 - mt._af)). return mt.select_cols(scores=hl.agg.array_sum(mt._loadings * gt_norm)).cols(). def _get_expr_or_join(expr, source, other_source, loc):; if source != other_source:; if isinstance(source, hl.MatrixTable):; source = source.annotate_rows(**{loc: expr}); else:; source = source.annotate(**{loc: expr}); expr = source[other_source.row_key][loc]; return expr. © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/pca.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/pca.html
https://hail.is/docs/0.2/_modules/hail/experimental/pca.html:892,Performance,load,loadings,892,"﻿. Hail | ; hail.experimental.pca. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.experimental.pca. Source code for hail.experimental.pca; import hail as hl; from hail.expr.expressions import (; expr_array,; expr_call,; expr_numeric,; raise_unless_entry_indexed,; raise_unless_row_indexed,; ); from hail.typecheck import typecheck. [docs]@typecheck(call_expr=expr_call, loadings_expr=expr_array(expr_numeric), af_expr=expr_numeric); def pc_project(call_expr, loadings_expr, af_expr):; """"""Projects genotypes onto pre-computed PCs. Requires loadings and; allele-frequency from a reference dataset (see example). Note that; `loadings_expr` must have no missing data and reflect the rows; from the original PCA run for this method to be accurate. Example; -------; >>> # Compute loadings and allele frequency for reference dataset; >>> _, _, loadings_ht = hl.hwe_normalized_pca(mt.GT, k=10, compute_loadings=True) # doctest: +SKIP; >>> mt = mt.annotate_rows(af=hl.agg.mean(mt.GT.n_alt_alleles()) / 2) # doctest: +SKIP; >>> loadings_ht = loadings_ht.annotate(af=mt.rows()[loadings_ht.key].af) # doctest: +SKIP; >>> # Project new genotypes onto loadings; >>> ht = pc_project(mt_to_project.GT, loadings_ht.loadings, loadings_ht.af) # doctest: +SKIP. Parameters; ----------; call_expr : :class:`.CallExpression`; Entry-indexed call expression for genotypes; to project onto loadings.; loadings_expr : :class:`.ArrayNumericExpression`; Location of expression for loadings; af_expr : :class:`.Float64Expression`; Location of expression for allele frequency. Returns; -------; :class:`.Table`; Table with scores calculated from loadings in column `scores`; """"",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/pca.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/pca.html
https://hail.is/docs/0.2/_modules/hail/experimental/pca.html:1128,Performance,load,loadings,1128,"; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.experimental.pca. Source code for hail.experimental.pca; import hail as hl; from hail.expr.expressions import (; expr_array,; expr_call,; expr_numeric,; raise_unless_entry_indexed,; raise_unless_row_indexed,; ); from hail.typecheck import typecheck. [docs]@typecheck(call_expr=expr_call, loadings_expr=expr_array(expr_numeric), af_expr=expr_numeric); def pc_project(call_expr, loadings_expr, af_expr):; """"""Projects genotypes onto pre-computed PCs. Requires loadings and; allele-frequency from a reference dataset (see example). Note that; `loadings_expr` must have no missing data and reflect the rows; from the original PCA run for this method to be accurate. Example; -------; >>> # Compute loadings and allele frequency for reference dataset; >>> _, _, loadings_ht = hl.hwe_normalized_pca(mt.GT, k=10, compute_loadings=True) # doctest: +SKIP; >>> mt = mt.annotate_rows(af=hl.agg.mean(mt.GT.n_alt_alleles()) / 2) # doctest: +SKIP; >>> loadings_ht = loadings_ht.annotate(af=mt.rows()[loadings_ht.key].af) # doctest: +SKIP; >>> # Project new genotypes onto loadings; >>> ht = pc_project(mt_to_project.GT, loadings_ht.loadings, loadings_ht.af) # doctest: +SKIP. Parameters; ----------; call_expr : :class:`.CallExpression`; Entry-indexed call expression for genotypes; to project onto loadings.; loadings_expr : :class:`.ArrayNumericExpression`; Location of expression for loadings; af_expr : :class:`.Float64Expression`; Location of expression for allele frequency. Returns; -------; :class:`.Table`; Table with scores calculated from loadings in column `scores`; """"""; raise_unless_entry_indexed('pc_project', call_expr); raise_unless_row_indexed('pc_project', loadings_expr); raise_unless_row_indexed('pc_project', a",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/pca.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/pca.html
https://hail.is/docs/0.2/_modules/hail/experimental/pca.html:1492,Performance,load,loadings,1492,".pca; import hail as hl; from hail.expr.expressions import (; expr_array,; expr_call,; expr_numeric,; raise_unless_entry_indexed,; raise_unless_row_indexed,; ); from hail.typecheck import typecheck. [docs]@typecheck(call_expr=expr_call, loadings_expr=expr_array(expr_numeric), af_expr=expr_numeric); def pc_project(call_expr, loadings_expr, af_expr):; """"""Projects genotypes onto pre-computed PCs. Requires loadings and; allele-frequency from a reference dataset (see example). Note that; `loadings_expr` must have no missing data and reflect the rows; from the original PCA run for this method to be accurate. Example; -------; >>> # Compute loadings and allele frequency for reference dataset; >>> _, _, loadings_ht = hl.hwe_normalized_pca(mt.GT, k=10, compute_loadings=True) # doctest: +SKIP; >>> mt = mt.annotate_rows(af=hl.agg.mean(mt.GT.n_alt_alleles()) / 2) # doctest: +SKIP; >>> loadings_ht = loadings_ht.annotate(af=mt.rows()[loadings_ht.key].af) # doctest: +SKIP; >>> # Project new genotypes onto loadings; >>> ht = pc_project(mt_to_project.GT, loadings_ht.loadings, loadings_ht.af) # doctest: +SKIP. Parameters; ----------; call_expr : :class:`.CallExpression`; Entry-indexed call expression for genotypes; to project onto loadings.; loadings_expr : :class:`.ArrayNumericExpression`; Location of expression for loadings; af_expr : :class:`.Float64Expression`; Location of expression for allele frequency. Returns; -------; :class:`.Table`; Table with scores calculated from loadings in column `scores`; """"""; raise_unless_entry_indexed('pc_project', call_expr); raise_unless_row_indexed('pc_project', loadings_expr); raise_unless_row_indexed('pc_project', af_expr). gt_source = call_expr._indices.source; loadings_source = loadings_expr._indices.source; af_source = af_expr._indices.source. loadings_expr = _get_expr_or_join(loadings_expr, loadings_source, gt_source, '_loadings'); af_expr = _get_expr_or_join(af_expr, af_source, gt_source, '_af'). mt = gt_source._annotate_all(; row_exprs={'",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/pca.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/pca.html
https://hail.is/docs/0.2/_modules/hail/experimental/pca.html:1552,Performance,load,loadings,1552,"pr_call,; expr_numeric,; raise_unless_entry_indexed,; raise_unless_row_indexed,; ); from hail.typecheck import typecheck. [docs]@typecheck(call_expr=expr_call, loadings_expr=expr_array(expr_numeric), af_expr=expr_numeric); def pc_project(call_expr, loadings_expr, af_expr):; """"""Projects genotypes onto pre-computed PCs. Requires loadings and; allele-frequency from a reference dataset (see example). Note that; `loadings_expr` must have no missing data and reflect the rows; from the original PCA run for this method to be accurate. Example; -------; >>> # Compute loadings and allele frequency for reference dataset; >>> _, _, loadings_ht = hl.hwe_normalized_pca(mt.GT, k=10, compute_loadings=True) # doctest: +SKIP; >>> mt = mt.annotate_rows(af=hl.agg.mean(mt.GT.n_alt_alleles()) / 2) # doctest: +SKIP; >>> loadings_ht = loadings_ht.annotate(af=mt.rows()[loadings_ht.key].af) # doctest: +SKIP; >>> # Project new genotypes onto loadings; >>> ht = pc_project(mt_to_project.GT, loadings_ht.loadings, loadings_ht.af) # doctest: +SKIP. Parameters; ----------; call_expr : :class:`.CallExpression`; Entry-indexed call expression for genotypes; to project onto loadings.; loadings_expr : :class:`.ArrayNumericExpression`; Location of expression for loadings; af_expr : :class:`.Float64Expression`; Location of expression for allele frequency. Returns; -------; :class:`.Table`; Table with scores calculated from loadings in column `scores`; """"""; raise_unless_entry_indexed('pc_project', call_expr); raise_unless_row_indexed('pc_project', loadings_expr); raise_unless_row_indexed('pc_project', af_expr). gt_source = call_expr._indices.source; loadings_source = loadings_expr._indices.source; af_source = af_expr._indices.source. loadings_expr = _get_expr_or_join(loadings_expr, loadings_source, gt_source, '_loadings'); af_expr = _get_expr_or_join(af_expr, af_source, gt_source, '_af'). mt = gt_source._annotate_all(; row_exprs={'_loadings': loadings_expr, '_af': af_expr}, entry_exprs={'_call': call_expr}",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/pca.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/pca.html
https://hail.is/docs/0.2/_modules/hail/experimental/pca.html:1719,Performance,load,loadings,1719," [docs]@typecheck(call_expr=expr_call, loadings_expr=expr_array(expr_numeric), af_expr=expr_numeric); def pc_project(call_expr, loadings_expr, af_expr):; """"""Projects genotypes onto pre-computed PCs. Requires loadings and; allele-frequency from a reference dataset (see example). Note that; `loadings_expr` must have no missing data and reflect the rows; from the original PCA run for this method to be accurate. Example; -------; >>> # Compute loadings and allele frequency for reference dataset; >>> _, _, loadings_ht = hl.hwe_normalized_pca(mt.GT, k=10, compute_loadings=True) # doctest: +SKIP; >>> mt = mt.annotate_rows(af=hl.agg.mean(mt.GT.n_alt_alleles()) / 2) # doctest: +SKIP; >>> loadings_ht = loadings_ht.annotate(af=mt.rows()[loadings_ht.key].af) # doctest: +SKIP; >>> # Project new genotypes onto loadings; >>> ht = pc_project(mt_to_project.GT, loadings_ht.loadings, loadings_ht.af) # doctest: +SKIP. Parameters; ----------; call_expr : :class:`.CallExpression`; Entry-indexed call expression for genotypes; to project onto loadings.; loadings_expr : :class:`.ArrayNumericExpression`; Location of expression for loadings; af_expr : :class:`.Float64Expression`; Location of expression for allele frequency. Returns; -------; :class:`.Table`; Table with scores calculated from loadings in column `scores`; """"""; raise_unless_entry_indexed('pc_project', call_expr); raise_unless_row_indexed('pc_project', loadings_expr); raise_unless_row_indexed('pc_project', af_expr). gt_source = call_expr._indices.source; loadings_source = loadings_expr._indices.source; af_source = af_expr._indices.source. loadings_expr = _get_expr_or_join(loadings_expr, loadings_source, gt_source, '_loadings'); af_expr = _get_expr_or_join(af_expr, af_source, gt_source, '_af'). mt = gt_source._annotate_all(; row_exprs={'_loadings': loadings_expr, '_af': af_expr}, entry_exprs={'_call': call_expr}; ). if isinstance(loadings_source, hl.MatrixTable):; n_variants = loadings_source.count_rows(); else:; n_variants = loadi",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/pca.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/pca.html
https://hail.is/docs/0.2/_modules/hail/experimental/pca.html:1807,Performance,load,loadings,1807,"oject(call_expr, loadings_expr, af_expr):; """"""Projects genotypes onto pre-computed PCs. Requires loadings and; allele-frequency from a reference dataset (see example). Note that; `loadings_expr` must have no missing data and reflect the rows; from the original PCA run for this method to be accurate. Example; -------; >>> # Compute loadings and allele frequency for reference dataset; >>> _, _, loadings_ht = hl.hwe_normalized_pca(mt.GT, k=10, compute_loadings=True) # doctest: +SKIP; >>> mt = mt.annotate_rows(af=hl.agg.mean(mt.GT.n_alt_alleles()) / 2) # doctest: +SKIP; >>> loadings_ht = loadings_ht.annotate(af=mt.rows()[loadings_ht.key].af) # doctest: +SKIP; >>> # Project new genotypes onto loadings; >>> ht = pc_project(mt_to_project.GT, loadings_ht.loadings, loadings_ht.af) # doctest: +SKIP. Parameters; ----------; call_expr : :class:`.CallExpression`; Entry-indexed call expression for genotypes; to project onto loadings.; loadings_expr : :class:`.ArrayNumericExpression`; Location of expression for loadings; af_expr : :class:`.Float64Expression`; Location of expression for allele frequency. Returns; -------; :class:`.Table`; Table with scores calculated from loadings in column `scores`; """"""; raise_unless_entry_indexed('pc_project', call_expr); raise_unless_row_indexed('pc_project', loadings_expr); raise_unless_row_indexed('pc_project', af_expr). gt_source = call_expr._indices.source; loadings_source = loadings_expr._indices.source; af_source = af_expr._indices.source. loadings_expr = _get_expr_or_join(loadings_expr, loadings_source, gt_source, '_loadings'); af_expr = _get_expr_or_join(af_expr, af_source, gt_source, '_af'). mt = gt_source._annotate_all(; row_exprs={'_loadings': loadings_expr, '_af': af_expr}, entry_exprs={'_call': call_expr}; ). if isinstance(loadings_source, hl.MatrixTable):; n_variants = loadings_source.count_rows(); else:; n_variants = loadings_source.count(). mt = mt.filter_rows(hl.is_defined(mt._loadings) & hl.is_defined(mt._af) & (mt._af > 0) & (m",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/pca.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/pca.html
https://hail.is/docs/0.2/_modules/hail/experimental/pca.html:1970,Performance,load,loadings,1970,"he original PCA run for this method to be accurate. Example; -------; >>> # Compute loadings and allele frequency for reference dataset; >>> _, _, loadings_ht = hl.hwe_normalized_pca(mt.GT, k=10, compute_loadings=True) # doctest: +SKIP; >>> mt = mt.annotate_rows(af=hl.agg.mean(mt.GT.n_alt_alleles()) / 2) # doctest: +SKIP; >>> loadings_ht = loadings_ht.annotate(af=mt.rows()[loadings_ht.key].af) # doctest: +SKIP; >>> # Project new genotypes onto loadings; >>> ht = pc_project(mt_to_project.GT, loadings_ht.loadings, loadings_ht.af) # doctest: +SKIP. Parameters; ----------; call_expr : :class:`.CallExpression`; Entry-indexed call expression for genotypes; to project onto loadings.; loadings_expr : :class:`.ArrayNumericExpression`; Location of expression for loadings; af_expr : :class:`.Float64Expression`; Location of expression for allele frequency. Returns; -------; :class:`.Table`; Table with scores calculated from loadings in column `scores`; """"""; raise_unless_entry_indexed('pc_project', call_expr); raise_unless_row_indexed('pc_project', loadings_expr); raise_unless_row_indexed('pc_project', af_expr). gt_source = call_expr._indices.source; loadings_source = loadings_expr._indices.source; af_source = af_expr._indices.source. loadings_expr = _get_expr_or_join(loadings_expr, loadings_source, gt_source, '_loadings'); af_expr = _get_expr_or_join(af_expr, af_source, gt_source, '_af'). mt = gt_source._annotate_all(; row_exprs={'_loadings': loadings_expr, '_af': af_expr}, entry_exprs={'_call': call_expr}; ). if isinstance(loadings_source, hl.MatrixTable):; n_variants = loadings_source.count_rows(); else:; n_variants = loadings_source.count(). mt = mt.filter_rows(hl.is_defined(mt._loadings) & hl.is_defined(mt._af) & (mt._af > 0) & (mt._af < 1)). gt_norm = (mt._call.n_alt_alleles() - 2 * mt._af) / hl.sqrt(n_variants * 2 * mt._af * (1 - mt._af)). return mt.select_cols(scores=hl.agg.array_sum(mt._loadings * gt_norm)).cols(). def _get_expr_or_join(expr, source, other_source, loc):",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/pca.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/pca.html
https://hail.is/docs/0.2/_modules/hail/experimental/phase_by_transmission.html:13533,Deployability,update,updated,13533,"er/mother schema,; and the resulting entry schema is the same as the proband_entry/father_entry/mother_entry schema.; If the `keep_trio_cols` option is set, then an additional `source_trio` column is added with the trio column data.; If the `keep_trio_entries` option is set, then an additional `source_trio_entry` column is added with the trio entry data. Note; ----; This assumes that the input MatrixTable is a trio MatrixTable (similar to; the result of :func:`~.trio_matrix`) Its entry schema has to contain; 'proband_entry`, `father_entry` and `mother_entry` all with the same type.; Its column schema has to contain 'proband`, `father` and `mother` all with; the same type. Parameters; ----------; tm : :class:`.MatrixTable`; Trio MatrixTable (entries have to be a Struct with `proband_entry`, `mother_entry` and `father_entry` present); col_keys : :obj:`list` of str; Column key(s) for the resulting sample MatrixTable; keep_trio_cols: bool; Whether to add a `source_trio` column with the trio column data (default `True`); keep_trio_entries: bool; Whether to add a `source_trio_entries` column with the trio entry data (default `False`). Returns; -------; :class:`.MatrixTable`; Sample MatrixTable; """""". select_entries_expr = {'__trio_entries': hl.array([tm.proband_entry, tm.father_entry, tm.mother_entry])}; if keep_trio_entries:; select_entries_expr['source_trio_entry'] = hl.struct(**tm.entry); tm = tm.select_entries(**select_entries_expr). tm = tm.key_cols_by(); select_cols_expr = {'__trio_members': hl.enumerate(hl.array([tm.proband, tm.father, tm.mother]))}; if keep_trio_cols:; select_cols_expr['source_trio'] = hl.struct(**tm.col); tm = tm.select_cols(**select_cols_expr). mt = tm.explode_cols(tm.__trio_members). mt = mt.transmute_entries(**mt.__trio_entries[mt.__trio_members[0]]). mt = mt.key_cols_by(); mt = mt.transmute_cols(**mt.__trio_members[1]). if col_keys:; mt = mt.key_cols_by(*col_keys). return mt. © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/phase_by_transmission.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/phase_by_transmission.html
https://hail.is/docs/0.2/_modules/hail/experimental/phase_by_transmission.html:2420,Integrability,wrap,wrapper,2420," Sex chromosomes of male individuals should be haploid to be phased correctly.; - If `proband_call` is diploid on non-par regions of the sex chromosomes, it is assumed to be female. Returns `NA` when genotype calls cannot be phased.; The following genotype calls combinations cannot be phased by transmission:; 1. One of the calls in the trio is missing; 2. The proband genotype cannot be obtained from the parents alleles (Mendelian violation); 3. All individuals of the trio are heterozygous for the same two alleles; 4. Father is diploid on non-PAR region of X or Y; 5. Proband is diploid on non-PAR region of Y. In addition, individual phased genotype calls are returned as missing in the following situations:; 1. All mother genotype calls non-PAR region of Y; 2. Diploid father genotype calls on non-PAR region of X for a male proband (proband and mother are still phased as father doesn't participate in allele transmission). Note; ----; :func:`~.phase_trio_matrix_by_transmission` provides a convenience wrapper for phasing a trio matrix. Parameters; ----------; locus : :class:`.LocusExpression`; Expression for the locus in the trio matrix; alleles : :class:`.ArrayExpression`; Expression for the alleles in the trio matrix; proband_call : :class:`.CallExpression`; Expression for the proband call in the trio matrix; father_call : :class:`.CallExpression`; Expression for the father call in the trio matrix; mother_call : :class:`.CallExpression`; Expression for the mother call in the trio matrix. Returns; -------; :class:`.ArrayExpression`; Array containing: [phased proband call, phased father call, phased mother call]"""""". def call_to_one_hot_alleles_array(; call: hl.expr.CallExpression, alleles: hl.expr.ArrayExpression; ) -> hl.expr.ArrayExpression:; """"""; Get the set of all different one-hot-encoded allele-vectors in a genotype call.; It is returned as an ordered array where the first vector corresponds to the first allele,; and the second vector (only present if het) the seco",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/phase_by_transmission.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/phase_by_transmission.html
https://hail.is/docs/0.2/_modules/hail/experimental/plots.html:11564,Deployability,update,updated,11564,"top=row_file_sizes_edges[1:],; fill_color=""#036564"",; line_color=""#033649"",; ). rows_grid = gridplot([[p_rows_per_partition, p_stats], [p, p_file_size]]). if 'entry_file_sizes' in all_data:; title = f'Statistics for {data_type}: {t_path}'. msg = f""Rows: {sum(all_data['rows_per_partition']):,}<br/>Partitions: {len(all_data['rows_per_partition']):,}<br/>Size: {total_entry_file_size}<br/>""; if success_file[0]:; msg += success_file[0]. source = ColumnDataSource(pd.DataFrame(all_data)); p = figure(tools=tools, width=panel_size, height=panel_size); p.title.text = title; p.xaxis.axis_label = 'Number of rows'; p.yaxis.axis_label = f'File size ({entry_scale}B)'; color_map = factor_cmap('spans_chromosome', palette=Spectral8, factors=list(set(all_data['spans_chromosome']))); p.scatter('rows_per_partition', 'entry_file_sizes', color=color_map, legend='spans_chromosome', source=source); p.legend.location = 'bottom_right'; p.select_one(HoverTool).tooltips = [; (x, f'@{x}') for x in ('rows_per_partition', 'entry_file_sizes_human', 'partition_bounds', 'index'); ]. p_stats = Div(text=msg); p_rows_per_partition = figure(x_range=p.x_range, width=panel_size, height=subpanel_size); p_rows_per_partition.quad(; top=rows_per_partition_hist,; bottom=0,; left=rows_per_partition_edges[:-1],; right=rows_per_partition_edges[1:],; fill_color=""#036564"",; line_color=""#033649"",; ); p_file_size = figure(y_range=p.y_range, width=subpanel_size, height=panel_size). row_file_sizes_hist, row_file_sizes_edges = np.histogram(all_data['entry_file_sizes'], bins=50); p_file_size.quad(; right=row_file_sizes_hist,; left=0,; bottom=row_file_sizes_edges[:-1],; top=row_file_sizes_edges[1:],; fill_color=""#036564"",; line_color=""#033649"",; ); entries_grid = gridplot([[p_rows_per_partition, p_stats], [p, p_file_size]]). return Tabs(tabs=[TabPanel(child=entries_grid, title='Entries'), TabPanel(child=rows_grid, title='Rows')]); else:; return rows_grid. © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/plots.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/plots.html
https://hail.is/docs/0.2/_modules/hail/experimental/plots.html:4615,Performance,load,load,4615,"t for a Hail Table or MatrixTable. Parameters; ----------; t_path : str; Path to the Hail Table or MatrixTable files. Returns; -------; :class:`bokeh.plotting.figure` or :class:`bokeh.models.layouts.Column`; """""". def get_rows_data(rows_files):; file_sizes = []; partition_bounds = []; parts_file = [x['path'] for x in rows_files if x['path'].endswith('parts')]; if parts_file:; parts = hadoop_ls(parts_file[0]); for i, x in enumerate(parts):; index = x['path'].split(f'{parts_file[0]}/part-')[1].split('-')[0]; if i < len(parts) - 1:; test_index = parts[i + 1]['path'].split(f'{parts_file[0]}/part-')[1].split('-')[0]; if test_index == index:; continue; file_sizes.append(x['size_bytes']); metadata_file = [x['path'] for x in rows_files if x['path'].endswith('metadata.json.gz')]; if metadata_file:; with hadoop_open(metadata_file[0], 'rb') as f:; rows_meta = json.load(f); try:; partition_bounds = [; (; x['start']['locus']['contig'],; x['start']['locus']['position'],; x['end']['locus']['contig'],; x['end']['locus']['position'],; ); for x in rows_meta['jRangeBounds']; ]; except KeyError:; pass; return partition_bounds, file_sizes. def scale_file_sizes(file_sizes):; min_file_size = min(file_sizes) * 1.1; total_file_size = sum(file_sizes); all_scales = [('T', 1e12), ('G', 1e9), ('M', 1e6), ('K', 1e3), ('', 1e0)]; for overall_scale, overall_factor in all_scales:; if total_file_size > overall_factor:; total_file_size /= overall_factor; break; for scale, factor in all_scales:; if min_file_size > factor:; file_sizes = [x / factor for x in file_sizes]; break; total_file_size = f'{total_file_size:.1f} {overall_scale}B'; return total_file_size, file_sizes, scale. files = hadoop_ls(t_path). rows_file = [x['path'] for x in files if x['path'].endswith('rows')]; entries_file = [x['path'] for x in files if x['path'].endswith('entries')]; success_file = [x['modification_time'] for x in files if x['path'].endswith('SUCCESS')]. metadata_file = [x['path'] for x in files if x['path'].endswith('met",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/plots.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/plots.html
https://hail.is/docs/0.2/_modules/hail/experimental/plots.html:5919,Performance,load,load,5919,"tal_file_size = sum(file_sizes); all_scales = [('T', 1e12), ('G', 1e9), ('M', 1e6), ('K', 1e3), ('', 1e0)]; for overall_scale, overall_factor in all_scales:; if total_file_size > overall_factor:; total_file_size /= overall_factor; break; for scale, factor in all_scales:; if min_file_size > factor:; file_sizes = [x / factor for x in file_sizes]; break; total_file_size = f'{total_file_size:.1f} {overall_scale}B'; return total_file_size, file_sizes, scale. files = hadoop_ls(t_path). rows_file = [x['path'] for x in files if x['path'].endswith('rows')]; entries_file = [x['path'] for x in files if x['path'].endswith('entries')]; success_file = [x['modification_time'] for x in files if x['path'].endswith('SUCCESS')]. metadata_file = [x['path'] for x in files if x['path'].endswith('metadata.json.gz')]; if not metadata_file:; raise FileNotFoundError('No metadata.json.gz file found.'). with hadoop_open(metadata_file[0], 'rb') as f:; overall_meta = json.load(f); rows_per_partition = overall_meta['components']['partition_counts']['counts']. if not rows_file:; raise FileNotFoundError('No rows directory found.'); rows_files = hadoop_ls(rows_file[0]). data_type = 'Table'; if entries_file:; data_type = 'MatrixTable'; rows_file = [x['path'] for x in rows_files if x['path'].endswith('rows')]; rows_files = hadoop_ls(rows_file[0]); row_partition_bounds, row_file_sizes = get_rows_data(rows_files). total_file_size, row_file_sizes, row_scale = scale_file_sizes(row_file_sizes). panel_size = 480; subpanel_size = 120. if not row_partition_bounds:; warning('Table is not partitioned. Only plotting file sizes'); row_file_sizes_hist, row_file_sizes_edges = np.histogram(row_file_sizes, bins=50); p_file_size = figure(width=panel_size, height=panel_size); p_file_size.quad(; right=row_file_sizes_hist,; left=0,; bottom=row_file_sizes_edges[:-1],; top=row_file_sizes_edges[1:],; fill_color=""#036564"",; line_color=""#033649"",; ); p_file_size.yaxis.axis_label = f'File size ({row_scale}B)'; return p_file_siz",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/plots.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/plots.html
https://hail.is/docs/0.2/_modules/hail/experimental/tidyr.html:5047,Deployability,update,updated,5047,"ggregate(; **{rv: hl.agg.take(ht[rv], 1)[0] for rv in ht.row_value if rv not in set([*key, field, value])},; **{; fv: hl.agg.filter(; ht[field] == fv,; hl.rbind(hl.agg.take(ht[value], 1), lambda take: hl.if_else(hl.len(take) > 0, take[0], 'NA')),; ); for fv in field_vals; },; ). ht_tmp = new_temp_file(); ht.write(ht_tmp). return ht. [docs]@typecheck(ht=Table, field=str, into=sequenceof(str), delim=oneof(str, int)); def separate(ht, field, into, delim) -> Table:; """"""Separate a field into multiple fields by splitting on a delimiter; character or position. :func:`.separate` mimics the functionality of the `separate()` function in R's; ``tidyr`` package. This function will create a new table where ``field`` has been split into; multiple new fields, whose names are given by ``into``. If ``delim`` is a ``str`` (including regular expression strings), ``field``; will be separated into columns by that string. In this case, the length; of ``into`` must match the number of resulting fields. If ``delim`` is an ``int``, ``field`` will be separated into two row fields,; where the first field contains the first ``delim`` characters of ``field``; and the second field contains the remaining characters. Parameters; ----------; ht : :class:`.Table`; A Hail table.; field : :class:`str`; The name of the field to separate in ``ht``.; into : list of :class:`str`; The names of the fields to create by separating ``field``.; delimiter : :class:`str` or :obj:`int`; The character or position by which to separate ``field``. Returns; -------; :class:`.Table`; Table with original ``field`` split into fields whose names are defined; by `into`."""""". if isinstance(delim, int):; ht = ht.annotate(**{into[0]: ht[field][:delim], into[1]: ht[field][delim:]}); else:; split = ht[field].split(delim); ht = ht.annotate(**{into[i]: split[i] for i in range(len(into))}); ht = ht.drop(field). ht_tmp = new_temp_file(); ht.write(ht_tmp). return ht. © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/tidyr.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/tidyr.html
https://hail.is/docs/0.2/_modules/hail/experimental/tidyr.html:1196,Modifiability,variab,variable-length,1196,"); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.experimental.tidyr. Source code for hail.experimental.tidyr; import hail as hl; from hail.table import Table; from hail.typecheck import nullable, oneof, sequenceof, typecheck; from hail.utils import new_temp_file, wrap_to_list. [docs]@typecheck(ht=Table, key=str, value=str, fields=str); def gather(ht, key, value, *fields) -> Table:; """"""Collapse fields into key-value pairs. :func:`.gather` mimics the functionality of the `gather()` function found in R's; ``tidyr`` package. This is a way to turn ""wide"" format data into ""long""; format data. Parameters; ----------; ht : :class:`.Table`; A Hail table.; key : :class:`str`; The name of the key field in the gathered table.; value : :class:`str`; The name of the value field in the gathered table.; fields : variable-length args of obj:`str`; Names of fields to gather in ``ht``. Returns; -------; :class:`.Table`; Table with original ``fields`` gathered into ``key`` and ``value`` fields."""""". ht = ht.annotate(_col_val=hl.array([hl.struct(field_name=field, value=ht[field]) for field in fields])); ht = ht.drop(*fields); ht = ht.explode(ht['_col_val']); ht = ht.annotate(**{key: ht['_col_val'][0], value: ht['_col_val'][1]}); ht = ht.drop('_col_val'). ht_tmp = new_temp_file(); ht.write(ht_tmp). return hl.read_table(ht_tmp). [docs]@typecheck(ht=Table, field=str, value=str, key=nullable(oneof(str, sequenceof(str)))); def spread(ht, field, value, key=None) -> Table:; """"""Spread a key-value pair of fields across multiple fields. :func:`.spread` mimics the functionality of the `spread()` function in R's; `tidyr` package. This is a way to turn ""long"" format data into ""wide""; format data. Given a ``field``, :func:`.spread` will create a new table by grouping; ``ht`` by its row key and, optionally, any additional fields passed to the;",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/tidyr.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/tidyr.html
https://hail.is/docs/0.2/_modules/hail/experimental/time.html:4310,Deployability,update,updated,4310,"(time=expr_str, format=expr_str, zone_id=expr_str); def strptime(time, format, zone_id):; """"""; Interpret a formatted datetime string as a Unix timestamp (number of seconds since 1970-01-01T00:00Z (ISO)). Examples; --------. >>> hl.eval(hl.experimental.strptime(""07/08/19 3:00:01 AM"", ""%D %l:%M:%S %p"", ""America/New_York"")); 1562569201. >>> hl.eval(hl.experimental.strptime(""Saturday, October 11, 1997. 05:45:23 AM"", ""%A, %B %e, %Y. %r"", ""GMT+2"")); 876541523. Notes; -----; The following formatting characters are supported in format strings: A a B b D d e F H I j k l M m n p R r S s T t U u V v W Y y z; See documentation here: https://linux.die.net/man/3/strftime. A zone id can take one of three forms. It can be an explicit offset, like ""+01:00"", a relative offset, like ""GMT+2"",; or a IANA timezone database (TZDB) identifier, like ""America/New_York"". Wikipedia maintains a list of TZDB identifiers here: https://en.wikipedia.org/wiki/List_of_tz_database_time_zones. Currently, the parser implicitly uses the ""en_US"" locale. This function will fail if there is not enough information in the string to determine a particular timestamp.; For example, if you have the string `""07/08/09""` and the format string `""%Y.%m.%d""`, this method will fail, since that's not specific; enough to determine seconds from. You can fix this by adding ""00:00:00"" to your date string and ""%H:%M:%S"" to your format string. Parameters; ----------; time : str or :class:`.Expression` of type :py:data:`.tstr`; The string from which to parse the time.; format : str or :class:`.Expression` of type :py:data:`.tstr`; The format string describing how to parse the time.; zone_id: str or :class:`.Expression` of type :py:data:`.tstr`; An id representing the timezone. See notes above. Returns; -------; :class:`~.Int64Expression`; The Unix timestamp associated with the given time string.; """"""; return _func(""strptime"", hl.tint64, time, format, zone_id). © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,docs/0.2/_modules/hail/experimental/time.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/experimental/time.html
https://hail.is/docs/0.2/_modules/hail/expr/builders.html:4849,Availability,error,error,4849,"expr_any); def default(self, then):; """"""Finish the switch statement by adding a default case. Notes; -----; If no value from a :meth:`~.SwitchBuilder.when` call is matched, then; `then` is returned. Parameters; ----------; then : :class:`.Expression`. Returns; -------; :class:`.Expression`; """"""; if len(self._cases) == 0 and self._when_missing_case is None:; return then; self._unify_type(then.dtype); return self._finish(then). [docs] def or_missing(self):; """"""Finish the switch statement by returning missing. Notes; -----; If no value from a :meth:`~.SwitchBuilder.when` call is matched, then; the result is missing. Parameters; ----------; then : :class:`.Expression`. Returns; -------; :class:`.Expression`; """"""; if len(self._cases) == 0:; raise ExpressionException(""'or_missing' cannot be called without at least one 'when' call""); from hail.expr.functions import missing. return self._finish(missing(self._ret_type)). [docs] @typecheck_method(message=expr_str); def or_error(self, message):; """"""Finish the switch statement by throwing an error with the given message. Notes; -----; If no value from a :meth:`.SwitchBuilder.when` call is matched, then an; error is thrown. Parameters; ----------; message : :class:`.Expression` of type :obj:`.tstr`. Returns; -------; :class:`.Expression`; """"""; if len(self._cases) == 0:; raise ExpressionException(""'or_error' cannot be called without at least one 'when' call""); error_expr = construct_expr(ir.Die(message._ir, self._ret_type), self._ret_type); return self._finish(error_expr). [docs]class CaseBuilder(ConditionalBuilder):; """"""Class for chaining multiple if-else statements. Examples; --------. >>> x = hl.literal('foo bar baz'); >>> expr = (hl.case(); ... .when(x[:3] == 'FOO', 1); ... .when(x.length() == 11, 2); ... .when(x == 'secret phrase', 3); ... .default(0)); >>> hl.eval(expr); 2. Notes; -----; All expressions appearing as the `then` parameters to; :meth:`~hail.expr.builders.CaseBuilder.when` or; :meth:`~hail.expr.builders.CaseBui",MatchSource.WIKI,docs/0.2/_modules/hail/expr/builders.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/builders.html
https://hail.is/docs/0.2/_modules/hail/expr/builders.html:4966,Availability,error,error,4966," call is matched, then; `then` is returned. Parameters; ----------; then : :class:`.Expression`. Returns; -------; :class:`.Expression`; """"""; if len(self._cases) == 0 and self._when_missing_case is None:; return then; self._unify_type(then.dtype); return self._finish(then). [docs] def or_missing(self):; """"""Finish the switch statement by returning missing. Notes; -----; If no value from a :meth:`~.SwitchBuilder.when` call is matched, then; the result is missing. Parameters; ----------; then : :class:`.Expression`. Returns; -------; :class:`.Expression`; """"""; if len(self._cases) == 0:; raise ExpressionException(""'or_missing' cannot be called without at least one 'when' call""); from hail.expr.functions import missing. return self._finish(missing(self._ret_type)). [docs] @typecheck_method(message=expr_str); def or_error(self, message):; """"""Finish the switch statement by throwing an error with the given message. Notes; -----; If no value from a :meth:`.SwitchBuilder.when` call is matched, then an; error is thrown. Parameters; ----------; message : :class:`.Expression` of type :obj:`.tstr`. Returns; -------; :class:`.Expression`; """"""; if len(self._cases) == 0:; raise ExpressionException(""'or_error' cannot be called without at least one 'when' call""); error_expr = construct_expr(ir.Die(message._ir, self._ret_type), self._ret_type); return self._finish(error_expr). [docs]class CaseBuilder(ConditionalBuilder):; """"""Class for chaining multiple if-else statements. Examples; --------. >>> x = hl.literal('foo bar baz'); >>> expr = (hl.case(); ... .when(x[:3] == 'FOO', 1); ... .when(x.length() == 11, 2); ... .when(x == 'secret phrase', 3); ... .default(0)); >>> hl.eval(expr); 2. Notes; -----; All expressions appearing as the `then` parameters to; :meth:`~hail.expr.builders.CaseBuilder.when` or; :meth:`~hail.expr.builders.CaseBuilder.default` method calls must be the; same type. Parameters; ----------; missing_false: :obj:`.bool`; Treat missing predicates as ``False``. See Also; --",MatchSource.WIKI,docs/0.2/_modules/hail/expr/builders.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/builders.html
https://hail.is/docs/0.2/_modules/hail/expr/builders.html:8126,Availability,error,error,8126,"ion` that evaluates to missing; will return a missing result, not proceed to the next case. Always; test missingness first in a :class:`.CaseBuilder`. Parameters; ----------; condition: :class:`.BooleanExpression`; then : :class:`.Expression`. Returns; -------; :class:`.CaseBuilder`; Mutates and returns `self`.; """"""; self._unify_type(then.dtype); self._cases.append((condition, then)); return self. [docs] @typecheck_method(then=expr_any); def default(self, then):; """"""Finish the case statement by adding a default case. Notes; -----; If no condition from a :meth:`~.CaseBuilder.when` call is ``True``,; then `then` is returned. Parameters; ----------; then : :class:`.Expression`. Returns; -------; :class:`.Expression`; """"""; if len(self._cases) == 0:; return then; self._unify_type(then.dtype); return self._finish(then). [docs] def or_missing(self):; """"""Finish the case statement by returning missing. Notes; -----; If no condition from a :meth:`.CaseBuilder.when` call is ``True``, then; the result is missing. Parameters; ----------; then : :class:`.Expression`. Returns; -------; :class:`.Expression`; """"""; if len(self._cases) == 0:; raise ExpressionException(""'or_missing' cannot be called without at least one 'when' call""); from hail.expr.functions import missing. return self._finish(missing(self._ret_type)). [docs] @typecheck_method(message=expr_str); def or_error(self, message):; """"""Finish the case statement by throwing an error with the given message. Notes; -----; If no condition from a :meth:`.CaseBuilder.when` call is ``True``, then; an error is thrown. Parameters; ----------; message : :class:`.Expression` of type :obj:`.tstr`. Returns; -------; :class:`.Expression`; """"""; if len(self._cases) == 0:; raise ExpressionException(""'or_error' cannot be called without at least one 'when' call""); error_expr = construct_expr(ir.Die(message._ir, self._ret_type), self._ret_type); return self._finish(error_expr). © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,docs/0.2/_modules/hail/expr/builders.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/builders.html
https://hail.is/docs/0.2/_modules/hail/expr/builders.html:8246,Availability,error,error,8246,"ion` that evaluates to missing; will return a missing result, not proceed to the next case. Always; test missingness first in a :class:`.CaseBuilder`. Parameters; ----------; condition: :class:`.BooleanExpression`; then : :class:`.Expression`. Returns; -------; :class:`.CaseBuilder`; Mutates and returns `self`.; """"""; self._unify_type(then.dtype); self._cases.append((condition, then)); return self. [docs] @typecheck_method(then=expr_any); def default(self, then):; """"""Finish the case statement by adding a default case. Notes; -----; If no condition from a :meth:`~.CaseBuilder.when` call is ``True``,; then `then` is returned. Parameters; ----------; then : :class:`.Expression`. Returns; -------; :class:`.Expression`; """"""; if len(self._cases) == 0:; return then; self._unify_type(then.dtype); return self._finish(then). [docs] def or_missing(self):; """"""Finish the case statement by returning missing. Notes; -----; If no condition from a :meth:`.CaseBuilder.when` call is ``True``, then; the result is missing. Parameters; ----------; then : :class:`.Expression`. Returns; -------; :class:`.Expression`; """"""; if len(self._cases) == 0:; raise ExpressionException(""'or_missing' cannot be called without at least one 'when' call""); from hail.expr.functions import missing. return self._finish(missing(self._ret_type)). [docs] @typecheck_method(message=expr_str); def or_error(self, message):; """"""Finish the case statement by throwing an error with the given message. Notes; -----; If no condition from a :meth:`.CaseBuilder.when` call is ``True``, then; an error is thrown. Parameters; ----------; message : :class:`.Expression` of type :obj:`.tstr`. Returns; -------; :class:`.Expression`; """"""; if len(self._cases) == 0:; raise ExpressionException(""'or_error' cannot be called without at least one 'when' call""); error_expr = construct_expr(ir.Die(message._ir, self._ret_type), self._ret_type); return self._finish(error_expr). © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,docs/0.2/_modules/hail/expr/builders.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/builders.html
https://hail.is/docs/0.2/_modules/hail/expr/builders.html:8658,Deployability,update,updated,8658,"ion` that evaluates to missing; will return a missing result, not proceed to the next case. Always; test missingness first in a :class:`.CaseBuilder`. Parameters; ----------; condition: :class:`.BooleanExpression`; then : :class:`.Expression`. Returns; -------; :class:`.CaseBuilder`; Mutates and returns `self`.; """"""; self._unify_type(then.dtype); self._cases.append((condition, then)); return self. [docs] @typecheck_method(then=expr_any); def default(self, then):; """"""Finish the case statement by adding a default case. Notes; -----; If no condition from a :meth:`~.CaseBuilder.when` call is ``True``,; then `then` is returned. Parameters; ----------; then : :class:`.Expression`. Returns; -------; :class:`.Expression`; """"""; if len(self._cases) == 0:; return then; self._unify_type(then.dtype); return self._finish(then). [docs] def or_missing(self):; """"""Finish the case statement by returning missing. Notes; -----; If no condition from a :meth:`.CaseBuilder.when` call is ``True``, then; the result is missing. Parameters; ----------; then : :class:`.Expression`. Returns; -------; :class:`.Expression`; """"""; if len(self._cases) == 0:; raise ExpressionException(""'or_missing' cannot be called without at least one 'when' call""); from hail.expr.functions import missing. return self._finish(missing(self._ret_type)). [docs] @typecheck_method(message=expr_str); def or_error(self, message):; """"""Finish the case statement by throwing an error with the given message. Notes; -----; If no condition from a :meth:`.CaseBuilder.when` call is ``True``, then; an error is thrown. Parameters; ----------; message : :class:`.Expression` of type :obj:`.tstr`. Returns; -------; :class:`.Expression`; """"""; if len(self._cases) == 0:; raise ExpressionException(""'or_error' cannot be called without at least one 'when' call""); error_expr = construct_expr(ir.Die(message._ir, self._ret_type), self._ret_type); return self._finish(error_expr). © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,docs/0.2/_modules/hail/expr/builders.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/builders.html
https://hail.is/docs/0.2/_modules/hail/expr/builders.html:4754,Integrability,message,message,4754,"expr_any); def default(self, then):; """"""Finish the switch statement by adding a default case. Notes; -----; If no value from a :meth:`~.SwitchBuilder.when` call is matched, then; `then` is returned. Parameters; ----------; then : :class:`.Expression`. Returns; -------; :class:`.Expression`; """"""; if len(self._cases) == 0 and self._when_missing_case is None:; return then; self._unify_type(then.dtype); return self._finish(then). [docs] def or_missing(self):; """"""Finish the switch statement by returning missing. Notes; -----; If no value from a :meth:`~.SwitchBuilder.when` call is matched, then; the result is missing. Parameters; ----------; then : :class:`.Expression`. Returns; -------; :class:`.Expression`; """"""; if len(self._cases) == 0:; raise ExpressionException(""'or_missing' cannot be called without at least one 'when' call""); from hail.expr.functions import missing. return self._finish(missing(self._ret_type)). [docs] @typecheck_method(message=expr_str); def or_error(self, message):; """"""Finish the switch statement by throwing an error with the given message. Notes; -----; If no value from a :meth:`.SwitchBuilder.when` call is matched, then an; error is thrown. Parameters; ----------; message : :class:`.Expression` of type :obj:`.tstr`. Returns; -------; :class:`.Expression`; """"""; if len(self._cases) == 0:; raise ExpressionException(""'or_error' cannot be called without at least one 'when' call""); error_expr = construct_expr(ir.Die(message._ir, self._ret_type), self._ret_type); return self._finish(error_expr). [docs]class CaseBuilder(ConditionalBuilder):; """"""Class for chaining multiple if-else statements. Examples; --------. >>> x = hl.literal('foo bar baz'); >>> expr = (hl.case(); ... .when(x[:3] == 'FOO', 1); ... .when(x.length() == 11, 2); ... .when(x == 'secret phrase', 3); ... .default(0)); >>> hl.eval(expr); 2. Notes; -----; All expressions appearing as the `then` parameters to; :meth:`~hail.expr.builders.CaseBuilder.when` or; :meth:`~hail.expr.builders.CaseBui",MatchSource.WIKI,docs/0.2/_modules/hail/expr/builders.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/builders.html
https://hail.is/docs/0.2/_modules/hail/expr/builders.html:4792,Integrability,message,message,4792,"expr_any); def default(self, then):; """"""Finish the switch statement by adding a default case. Notes; -----; If no value from a :meth:`~.SwitchBuilder.when` call is matched, then; `then` is returned. Parameters; ----------; then : :class:`.Expression`. Returns; -------; :class:`.Expression`; """"""; if len(self._cases) == 0 and self._when_missing_case is None:; return then; self._unify_type(then.dtype); return self._finish(then). [docs] def or_missing(self):; """"""Finish the switch statement by returning missing. Notes; -----; If no value from a :meth:`~.SwitchBuilder.when` call is matched, then; the result is missing. Parameters; ----------; then : :class:`.Expression`. Returns; -------; :class:`.Expression`; """"""; if len(self._cases) == 0:; raise ExpressionException(""'or_missing' cannot be called without at least one 'when' call""); from hail.expr.functions import missing. return self._finish(missing(self._ret_type)). [docs] @typecheck_method(message=expr_str); def or_error(self, message):; """"""Finish the switch statement by throwing an error with the given message. Notes; -----; If no value from a :meth:`.SwitchBuilder.when` call is matched, then an; error is thrown. Parameters; ----------; message : :class:`.Expression` of type :obj:`.tstr`. Returns; -------; :class:`.Expression`; """"""; if len(self._cases) == 0:; raise ExpressionException(""'or_error' cannot be called without at least one 'when' call""); error_expr = construct_expr(ir.Die(message._ir, self._ret_type), self._ret_type); return self._finish(error_expr). [docs]class CaseBuilder(ConditionalBuilder):; """"""Class for chaining multiple if-else statements. Examples; --------. >>> x = hl.literal('foo bar baz'); >>> expr = (hl.case(); ... .when(x[:3] == 'FOO', 1); ... .when(x.length() == 11, 2); ... .when(x == 'secret phrase', 3); ... .default(0)); >>> hl.eval(expr); 2. Notes; -----; All expressions appearing as the `then` parameters to; :meth:`~hail.expr.builders.CaseBuilder.when` or; :meth:`~hail.expr.builders.CaseBui",MatchSource.WIKI,docs/0.2/_modules/hail/expr/builders.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/builders.html
https://hail.is/docs/0.2/_modules/hail/expr/builders.html:4870,Integrability,message,message,4870,"expr_any); def default(self, then):; """"""Finish the switch statement by adding a default case. Notes; -----; If no value from a :meth:`~.SwitchBuilder.when` call is matched, then; `then` is returned. Parameters; ----------; then : :class:`.Expression`. Returns; -------; :class:`.Expression`; """"""; if len(self._cases) == 0 and self._when_missing_case is None:; return then; self._unify_type(then.dtype); return self._finish(then). [docs] def or_missing(self):; """"""Finish the switch statement by returning missing. Notes; -----; If no value from a :meth:`~.SwitchBuilder.when` call is matched, then; the result is missing. Parameters; ----------; then : :class:`.Expression`. Returns; -------; :class:`.Expression`; """"""; if len(self._cases) == 0:; raise ExpressionException(""'or_missing' cannot be called without at least one 'when' call""); from hail.expr.functions import missing. return self._finish(missing(self._ret_type)). [docs] @typecheck_method(message=expr_str); def or_error(self, message):; """"""Finish the switch statement by throwing an error with the given message. Notes; -----; If no value from a :meth:`.SwitchBuilder.when` call is matched, then an; error is thrown. Parameters; ----------; message : :class:`.Expression` of type :obj:`.tstr`. Returns; -------; :class:`.Expression`; """"""; if len(self._cases) == 0:; raise ExpressionException(""'or_error' cannot be called without at least one 'when' call""); error_expr = construct_expr(ir.Die(message._ir, self._ret_type), self._ret_type); return self._finish(error_expr). [docs]class CaseBuilder(ConditionalBuilder):; """"""Class for chaining multiple if-else statements. Examples; --------. >>> x = hl.literal('foo bar baz'); >>> expr = (hl.case(); ... .when(x[:3] == 'FOO', 1); ... .when(x.length() == 11, 2); ... .when(x == 'secret phrase', 3); ... .default(0)); >>> hl.eval(expr); 2. Notes; -----; All expressions appearing as the `then` parameters to; :meth:`~hail.expr.builders.CaseBuilder.when` or; :meth:`~hail.expr.builders.CaseBui",MatchSource.WIKI,docs/0.2/_modules/hail/expr/builders.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/builders.html
https://hail.is/docs/0.2/_modules/hail/expr/builders.html:5007,Integrability,message,message,5007,"rameters; ----------; then : :class:`.Expression`. Returns; -------; :class:`.Expression`; """"""; if len(self._cases) == 0 and self._when_missing_case is None:; return then; self._unify_type(then.dtype); return self._finish(then). [docs] def or_missing(self):; """"""Finish the switch statement by returning missing. Notes; -----; If no value from a :meth:`~.SwitchBuilder.when` call is matched, then; the result is missing. Parameters; ----------; then : :class:`.Expression`. Returns; -------; :class:`.Expression`; """"""; if len(self._cases) == 0:; raise ExpressionException(""'or_missing' cannot be called without at least one 'when' call""); from hail.expr.functions import missing. return self._finish(missing(self._ret_type)). [docs] @typecheck_method(message=expr_str); def or_error(self, message):; """"""Finish the switch statement by throwing an error with the given message. Notes; -----; If no value from a :meth:`.SwitchBuilder.when` call is matched, then an; error is thrown. Parameters; ----------; message : :class:`.Expression` of type :obj:`.tstr`. Returns; -------; :class:`.Expression`; """"""; if len(self._cases) == 0:; raise ExpressionException(""'or_error' cannot be called without at least one 'when' call""); error_expr = construct_expr(ir.Die(message._ir, self._ret_type), self._ret_type); return self._finish(error_expr). [docs]class CaseBuilder(ConditionalBuilder):; """"""Class for chaining multiple if-else statements. Examples; --------. >>> x = hl.literal('foo bar baz'); >>> expr = (hl.case(); ... .when(x[:3] == 'FOO', 1); ... .when(x.length() == 11, 2); ... .when(x == 'secret phrase', 3); ... .default(0)); >>> hl.eval(expr); 2. Notes; -----; All expressions appearing as the `then` parameters to; :meth:`~hail.expr.builders.CaseBuilder.when` or; :meth:`~hail.expr.builders.CaseBuilder.default` method calls must be the; same type. Parameters; ----------; missing_false: :obj:`.bool`; Treat missing predicates as ``False``. See Also; --------; :func:`.case`, :func:`.cond`, :func:`.",MatchSource.WIKI,docs/0.2/_modules/hail/expr/builders.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/builders.html
https://hail.is/docs/0.2/_modules/hail/expr/builders.html:5258,Integrability,message,message,5258,":; """"""Finish the switch statement by returning missing. Notes; -----; If no value from a :meth:`~.SwitchBuilder.when` call is matched, then; the result is missing. Parameters; ----------; then : :class:`.Expression`. Returns; -------; :class:`.Expression`; """"""; if len(self._cases) == 0:; raise ExpressionException(""'or_missing' cannot be called without at least one 'when' call""); from hail.expr.functions import missing. return self._finish(missing(self._ret_type)). [docs] @typecheck_method(message=expr_str); def or_error(self, message):; """"""Finish the switch statement by throwing an error with the given message. Notes; -----; If no value from a :meth:`.SwitchBuilder.when` call is matched, then an; error is thrown. Parameters; ----------; message : :class:`.Expression` of type :obj:`.tstr`. Returns; -------; :class:`.Expression`; """"""; if len(self._cases) == 0:; raise ExpressionException(""'or_error' cannot be called without at least one 'when' call""); error_expr = construct_expr(ir.Die(message._ir, self._ret_type), self._ret_type); return self._finish(error_expr). [docs]class CaseBuilder(ConditionalBuilder):; """"""Class for chaining multiple if-else statements. Examples; --------. >>> x = hl.literal('foo bar baz'); >>> expr = (hl.case(); ... .when(x[:3] == 'FOO', 1); ... .when(x.length() == 11, 2); ... .when(x == 'secret phrase', 3); ... .default(0)); >>> hl.eval(expr); 2. Notes; -----; All expressions appearing as the `then` parameters to; :meth:`~hail.expr.builders.CaseBuilder.when` or; :meth:`~hail.expr.builders.CaseBuilder.default` method calls must be the; same type. Parameters; ----------; missing_false: :obj:`.bool`; Treat missing predicates as ``False``. See Also; --------; :func:`.case`, :func:`.cond`, :func:`.switch`; """""". def __init__(self, missing_false=False):; super(CaseBuilder, self).__init__(); self._missing_false = missing_false. def _finish(self, default):; assert len(self._cases) > 0. from hail.expr.functions import if_else. expr = default; for conditi",MatchSource.WIKI,docs/0.2/_modules/hail/expr/builders.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/builders.html
https://hail.is/docs/0.2/_modules/hail/expr/builders.html:8033,Integrability,message,message,8033,"ion` that evaluates to missing; will return a missing result, not proceed to the next case. Always; test missingness first in a :class:`.CaseBuilder`. Parameters; ----------; condition: :class:`.BooleanExpression`; then : :class:`.Expression`. Returns; -------; :class:`.CaseBuilder`; Mutates and returns `self`.; """"""; self._unify_type(then.dtype); self._cases.append((condition, then)); return self. [docs] @typecheck_method(then=expr_any); def default(self, then):; """"""Finish the case statement by adding a default case. Notes; -----; If no condition from a :meth:`~.CaseBuilder.when` call is ``True``,; then `then` is returned. Parameters; ----------; then : :class:`.Expression`. Returns; -------; :class:`.Expression`; """"""; if len(self._cases) == 0:; return then; self._unify_type(then.dtype); return self._finish(then). [docs] def or_missing(self):; """"""Finish the case statement by returning missing. Notes; -----; If no condition from a :meth:`.CaseBuilder.when` call is ``True``, then; the result is missing. Parameters; ----------; then : :class:`.Expression`. Returns; -------; :class:`.Expression`; """"""; if len(self._cases) == 0:; raise ExpressionException(""'or_missing' cannot be called without at least one 'when' call""); from hail.expr.functions import missing. return self._finish(missing(self._ret_type)). [docs] @typecheck_method(message=expr_str); def or_error(self, message):; """"""Finish the case statement by throwing an error with the given message. Notes; -----; If no condition from a :meth:`.CaseBuilder.when` call is ``True``, then; an error is thrown. Parameters; ----------; message : :class:`.Expression` of type :obj:`.tstr`. Returns; -------; :class:`.Expression`; """"""; if len(self._cases) == 0:; raise ExpressionException(""'or_error' cannot be called without at least one 'when' call""); error_expr = construct_expr(ir.Die(message._ir, self._ret_type), self._ret_type); return self._finish(error_expr). © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,docs/0.2/_modules/hail/expr/builders.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/builders.html
https://hail.is/docs/0.2/_modules/hail/expr/builders.html:8071,Integrability,message,message,8071,"ion` that evaluates to missing; will return a missing result, not proceed to the next case. Always; test missingness first in a :class:`.CaseBuilder`. Parameters; ----------; condition: :class:`.BooleanExpression`; then : :class:`.Expression`. Returns; -------; :class:`.CaseBuilder`; Mutates and returns `self`.; """"""; self._unify_type(then.dtype); self._cases.append((condition, then)); return self. [docs] @typecheck_method(then=expr_any); def default(self, then):; """"""Finish the case statement by adding a default case. Notes; -----; If no condition from a :meth:`~.CaseBuilder.when` call is ``True``,; then `then` is returned. Parameters; ----------; then : :class:`.Expression`. Returns; -------; :class:`.Expression`; """"""; if len(self._cases) == 0:; return then; self._unify_type(then.dtype); return self._finish(then). [docs] def or_missing(self):; """"""Finish the case statement by returning missing. Notes; -----; If no condition from a :meth:`.CaseBuilder.when` call is ``True``, then; the result is missing. Parameters; ----------; then : :class:`.Expression`. Returns; -------; :class:`.Expression`; """"""; if len(self._cases) == 0:; raise ExpressionException(""'or_missing' cannot be called without at least one 'when' call""); from hail.expr.functions import missing. return self._finish(missing(self._ret_type)). [docs] @typecheck_method(message=expr_str); def or_error(self, message):; """"""Finish the case statement by throwing an error with the given message. Notes; -----; If no condition from a :meth:`.CaseBuilder.when` call is ``True``, then; an error is thrown. Parameters; ----------; message : :class:`.Expression` of type :obj:`.tstr`. Returns; -------; :class:`.Expression`; """"""; if len(self._cases) == 0:; raise ExpressionException(""'or_error' cannot be called without at least one 'when' call""); error_expr = construct_expr(ir.Die(message._ir, self._ret_type), self._ret_type); return self._finish(error_expr). © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,docs/0.2/_modules/hail/expr/builders.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/builders.html
https://hail.is/docs/0.2/_modules/hail/expr/builders.html:8147,Integrability,message,message,8147,"ion` that evaluates to missing; will return a missing result, not proceed to the next case. Always; test missingness first in a :class:`.CaseBuilder`. Parameters; ----------; condition: :class:`.BooleanExpression`; then : :class:`.Expression`. Returns; -------; :class:`.CaseBuilder`; Mutates and returns `self`.; """"""; self._unify_type(then.dtype); self._cases.append((condition, then)); return self. [docs] @typecheck_method(then=expr_any); def default(self, then):; """"""Finish the case statement by adding a default case. Notes; -----; If no condition from a :meth:`~.CaseBuilder.when` call is ``True``,; then `then` is returned. Parameters; ----------; then : :class:`.Expression`. Returns; -------; :class:`.Expression`; """"""; if len(self._cases) == 0:; return then; self._unify_type(then.dtype); return self._finish(then). [docs] def or_missing(self):; """"""Finish the case statement by returning missing. Notes; -----; If no condition from a :meth:`.CaseBuilder.when` call is ``True``, then; the result is missing. Parameters; ----------; then : :class:`.Expression`. Returns; -------; :class:`.Expression`; """"""; if len(self._cases) == 0:; raise ExpressionException(""'or_missing' cannot be called without at least one 'when' call""); from hail.expr.functions import missing. return self._finish(missing(self._ret_type)). [docs] @typecheck_method(message=expr_str); def or_error(self, message):; """"""Finish the case statement by throwing an error with the given message. Notes; -----; If no condition from a :meth:`.CaseBuilder.when` call is ``True``, then; an error is thrown. Parameters; ----------; message : :class:`.Expression` of type :obj:`.tstr`. Returns; -------; :class:`.Expression`; """"""; if len(self._cases) == 0:; raise ExpressionException(""'or_error' cannot be called without at least one 'when' call""); error_expr = construct_expr(ir.Die(message._ir, self._ret_type), self._ret_type); return self._finish(error_expr). © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,docs/0.2/_modules/hail/expr/builders.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/builders.html
https://hail.is/docs/0.2/_modules/hail/expr/builders.html:8287,Integrability,message,message,8287,"ion` that evaluates to missing; will return a missing result, not proceed to the next case. Always; test missingness first in a :class:`.CaseBuilder`. Parameters; ----------; condition: :class:`.BooleanExpression`; then : :class:`.Expression`. Returns; -------; :class:`.CaseBuilder`; Mutates and returns `self`.; """"""; self._unify_type(then.dtype); self._cases.append((condition, then)); return self. [docs] @typecheck_method(then=expr_any); def default(self, then):; """"""Finish the case statement by adding a default case. Notes; -----; If no condition from a :meth:`~.CaseBuilder.when` call is ``True``,; then `then` is returned. Parameters; ----------; then : :class:`.Expression`. Returns; -------; :class:`.Expression`; """"""; if len(self._cases) == 0:; return then; self._unify_type(then.dtype); return self._finish(then). [docs] def or_missing(self):; """"""Finish the case statement by returning missing. Notes; -----; If no condition from a :meth:`.CaseBuilder.when` call is ``True``, then; the result is missing. Parameters; ----------; then : :class:`.Expression`. Returns; -------; :class:`.Expression`; """"""; if len(self._cases) == 0:; raise ExpressionException(""'or_missing' cannot be called without at least one 'when' call""); from hail.expr.functions import missing. return self._finish(missing(self._ret_type)). [docs] @typecheck_method(message=expr_str); def or_error(self, message):; """"""Finish the case statement by throwing an error with the given message. Notes; -----; If no condition from a :meth:`.CaseBuilder.when` call is ``True``, then; an error is thrown. Parameters; ----------; message : :class:`.Expression` of type :obj:`.tstr`. Returns; -------; :class:`.Expression`; """"""; if len(self._cases) == 0:; raise ExpressionException(""'or_error' cannot be called without at least one 'when' call""); error_expr = construct_expr(ir.Die(message._ir, self._ret_type), self._ret_type); return self._finish(error_expr). © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,docs/0.2/_modules/hail/expr/builders.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/builders.html
https://hail.is/docs/0.2/_modules/hail/expr/builders.html:8538,Integrability,message,message,8538,"ion` that evaluates to missing; will return a missing result, not proceed to the next case. Always; test missingness first in a :class:`.CaseBuilder`. Parameters; ----------; condition: :class:`.BooleanExpression`; then : :class:`.Expression`. Returns; -------; :class:`.CaseBuilder`; Mutates and returns `self`.; """"""; self._unify_type(then.dtype); self._cases.append((condition, then)); return self. [docs] @typecheck_method(then=expr_any); def default(self, then):; """"""Finish the case statement by adding a default case. Notes; -----; If no condition from a :meth:`~.CaseBuilder.when` call is ``True``,; then `then` is returned. Parameters; ----------; then : :class:`.Expression`. Returns; -------; :class:`.Expression`; """"""; if len(self._cases) == 0:; return then; self._unify_type(then.dtype); return self._finish(then). [docs] def or_missing(self):; """"""Finish the case statement by returning missing. Notes; -----; If no condition from a :meth:`.CaseBuilder.when` call is ``True``, then; the result is missing. Parameters; ----------; then : :class:`.Expression`. Returns; -------; :class:`.Expression`; """"""; if len(self._cases) == 0:; raise ExpressionException(""'or_missing' cannot be called without at least one 'when' call""); from hail.expr.functions import missing. return self._finish(missing(self._ret_type)). [docs] @typecheck_method(message=expr_str); def or_error(self, message):; """"""Finish the case statement by throwing an error with the given message. Notes; -----; If no condition from a :meth:`.CaseBuilder.when` call is ``True``, then; an error is thrown. Parameters; ----------; message : :class:`.Expression` of type :obj:`.tstr`. Returns; -------; :class:`.Expression`; """"""; if len(self._cases) == 0:; raise ExpressionException(""'or_error' cannot be called without at least one 'when' call""); error_expr = construct_expr(ir.Die(message._ir, self._ret_type), self._ret_type); return self._finish(error_expr). © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,docs/0.2/_modules/hail/expr/builders.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/builders.html
https://hail.is/docs/0.2/_modules/hail/expr/builders.html:2000,Testability,assert,assert,2000,"ave same type, found '{}' and '{}'"".format(self._ret_type, t)). [docs]class SwitchBuilder(ConditionalBuilder):; """"""Class for generating conditional trees based on value of an expression. Examples; --------. >>> csq = hl.literal('loss of function'); >>> expr = (hl.switch(csq); ... .when('synonymous', 1); ... .when('SYN', 1); ... .when('missense', 2); ... .when('MIS', 2); ... .when('loss of function', 3); ... .when('LOF', 3); ... .or_missing()); >>> hl.eval(expr); 3. Notes; -----; All expressions appearing as the `then` parameters to; :meth:`~hail.expr.builders.SwitchBuilder.when` or; :meth:`~hail.expr.builders.SwitchBuilder.default` method calls must be the; same type. See Also; --------; :func:`.case`, :func:`.cond`, :func:`.switch`. Parameters; ----------; expr : :class:`.Expression`; Value to match against.; """""". @typecheck_method(base=expr_any); def __init__(self, base):; self._base = base; self._when_missing_case = None; super(SwitchBuilder, self).__init__(). def _finish(self, default):; assert len(self._cases) > 0 or self._when_missing_case is not None. def f(base):; # build cond chain bottom-up; if default is self._base:; expr = base; else:; expr = default; for value, then in self._cases[::-1]:; expr = hl.if_else(base == value, then, expr); # needs to be on the outside, because upstream missingness would propagate; if self._when_missing_case is not None:; expr = hl.if_else(hl.is_missing(base), self._when_missing_case, expr); return expr. return hl.bind(f, self._base). [docs] @typecheck_method(value=expr_any, then=expr_any); def when(self, value, then) -> 'SwitchBuilder':; """"""Add a value test. If the `base` expression is equal to `value`, then; returns `then`. Warning; -------; Missingness always compares to missing. Both ``NA == NA`` and; ``NA != NA`` return ``NA``. Use :meth:`~SwitchBuilder.when_missing`; to test missingness. Parameters; ----------; value : :class:`.Expression`; then : :class:`.Expression`. Returns; -------; :class:`.SwitchBuilder`; Mutates a",MatchSource.WIKI,docs/0.2/_modules/hail/expr/builders.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/builders.html
https://hail.is/docs/0.2/_modules/hail/expr/builders.html:2613,Testability,test,test,2613,"ders.SwitchBuilder.when` or; :meth:`~hail.expr.builders.SwitchBuilder.default` method calls must be the; same type. See Also; --------; :func:`.case`, :func:`.cond`, :func:`.switch`. Parameters; ----------; expr : :class:`.Expression`; Value to match against.; """""". @typecheck_method(base=expr_any); def __init__(self, base):; self._base = base; self._when_missing_case = None; super(SwitchBuilder, self).__init__(). def _finish(self, default):; assert len(self._cases) > 0 or self._when_missing_case is not None. def f(base):; # build cond chain bottom-up; if default is self._base:; expr = base; else:; expr = default; for value, then in self._cases[::-1]:; expr = hl.if_else(base == value, then, expr); # needs to be on the outside, because upstream missingness would propagate; if self._when_missing_case is not None:; expr = hl.if_else(hl.is_missing(base), self._when_missing_case, expr); return expr. return hl.bind(f, self._base). [docs] @typecheck_method(value=expr_any, then=expr_any); def when(self, value, then) -> 'SwitchBuilder':; """"""Add a value test. If the `base` expression is equal to `value`, then; returns `then`. Warning; -------; Missingness always compares to missing. Both ``NA == NA`` and; ``NA != NA`` return ``NA``. Use :meth:`~SwitchBuilder.when_missing`; to test missingness. Parameters; ----------; value : :class:`.Expression`; then : :class:`.Expression`. Returns; -------; :class:`.SwitchBuilder`; Mutates and returns `self`.; """"""; can_compare = unify_types(self._base.dtype, value.dtype); if not can_compare:; raise TypeError(""cannot compare expressions of type '{}' and '{}'"".format(self._base.dtype, value.dtype)). self._unify_type(then.dtype); self._cases.append((value, then)); return self. [docs] @typecheck_method(then=expr_any); def when_missing(self, then) -> 'SwitchBuilder':; """"""Add a test for missingness. If the `base` expression is missing,; returns `then`. Parameters; ----------; then : :class:`.Expression`. Returns; -------; :class:`.SwitchBuilder`; M",MatchSource.WIKI,docs/0.2/_modules/hail/expr/builders.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/builders.html
https://hail.is/docs/0.2/_modules/hail/expr/builders.html:2840,Testability,test,test,2840,"ase=expr_any); def __init__(self, base):; self._base = base; self._when_missing_case = None; super(SwitchBuilder, self).__init__(). def _finish(self, default):; assert len(self._cases) > 0 or self._when_missing_case is not None. def f(base):; # build cond chain bottom-up; if default is self._base:; expr = base; else:; expr = default; for value, then in self._cases[::-1]:; expr = hl.if_else(base == value, then, expr); # needs to be on the outside, because upstream missingness would propagate; if self._when_missing_case is not None:; expr = hl.if_else(hl.is_missing(base), self._when_missing_case, expr); return expr. return hl.bind(f, self._base). [docs] @typecheck_method(value=expr_any, then=expr_any); def when(self, value, then) -> 'SwitchBuilder':; """"""Add a value test. If the `base` expression is equal to `value`, then; returns `then`. Warning; -------; Missingness always compares to missing. Both ``NA == NA`` and; ``NA != NA`` return ``NA``. Use :meth:`~SwitchBuilder.when_missing`; to test missingness. Parameters; ----------; value : :class:`.Expression`; then : :class:`.Expression`. Returns; -------; :class:`.SwitchBuilder`; Mutates and returns `self`.; """"""; can_compare = unify_types(self._base.dtype, value.dtype); if not can_compare:; raise TypeError(""cannot compare expressions of type '{}' and '{}'"".format(self._base.dtype, value.dtype)). self._unify_type(then.dtype); self._cases.append((value, then)); return self. [docs] @typecheck_method(then=expr_any); def when_missing(self, then) -> 'SwitchBuilder':; """"""Add a test for missingness. If the `base` expression is missing,; returns `then`. Parameters; ----------; then : :class:`.Expression`. Returns; -------; :class:`.SwitchBuilder`; Mutates and returns `self`.; """"""; if self._when_missing_case is not None:; raise ExpressionException(""'when_missing' can only be called once""); self._unify_type(then.dtype). self._when_missing_case = then; return self. [docs] @typecheck_method(then=expr_any); def default(self, then):; ",MatchSource.WIKI,docs/0.2/_modules/hail/expr/builders.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/builders.html
https://hail.is/docs/0.2/_modules/hail/expr/builders.html:3382,Testability,test,test,3382,"f._when_missing_case is not None:; expr = hl.if_else(hl.is_missing(base), self._when_missing_case, expr); return expr. return hl.bind(f, self._base). [docs] @typecheck_method(value=expr_any, then=expr_any); def when(self, value, then) -> 'SwitchBuilder':; """"""Add a value test. If the `base` expression is equal to `value`, then; returns `then`. Warning; -------; Missingness always compares to missing. Both ``NA == NA`` and; ``NA != NA`` return ``NA``. Use :meth:`~SwitchBuilder.when_missing`; to test missingness. Parameters; ----------; value : :class:`.Expression`; then : :class:`.Expression`. Returns; -------; :class:`.SwitchBuilder`; Mutates and returns `self`.; """"""; can_compare = unify_types(self._base.dtype, value.dtype); if not can_compare:; raise TypeError(""cannot compare expressions of type '{}' and '{}'"".format(self._base.dtype, value.dtype)). self._unify_type(then.dtype); self._cases.append((value, then)); return self. [docs] @typecheck_method(then=expr_any); def when_missing(self, then) -> 'SwitchBuilder':; """"""Add a test for missingness. If the `base` expression is missing,; returns `then`. Parameters; ----------; then : :class:`.Expression`. Returns; -------; :class:`.SwitchBuilder`; Mutates and returns `self`.; """"""; if self._when_missing_case is not None:; raise ExpressionException(""'when_missing' can only be called once""); self._unify_type(then.dtype). self._when_missing_case = then; return self. [docs] @typecheck_method(then=expr_any); def default(self, then):; """"""Finish the switch statement by adding a default case. Notes; -----; If no value from a :meth:`~.SwitchBuilder.when` call is matched, then; `then` is returned. Parameters; ----------; then : :class:`.Expression`. Returns; -------; :class:`.Expression`; """"""; if len(self._cases) == 0 and self._when_missing_case is None:; return then; self._unify_type(then.dtype); return self._finish(then). [docs] def or_missing(self):; """"""Finish the switch statement by returning missing. Notes; -----; If no value ",MatchSource.WIKI,docs/0.2/_modules/hail/expr/builders.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/builders.html
https://hail.is/docs/0.2/_modules/hail/expr/builders.html:6163,Testability,assert,assert,6163,"n(""'or_error' cannot be called without at least one 'when' call""); error_expr = construct_expr(ir.Die(message._ir, self._ret_type), self._ret_type); return self._finish(error_expr). [docs]class CaseBuilder(ConditionalBuilder):; """"""Class for chaining multiple if-else statements. Examples; --------. >>> x = hl.literal('foo bar baz'); >>> expr = (hl.case(); ... .when(x[:3] == 'FOO', 1); ... .when(x.length() == 11, 2); ... .when(x == 'secret phrase', 3); ... .default(0)); >>> hl.eval(expr); 2. Notes; -----; All expressions appearing as the `then` parameters to; :meth:`~hail.expr.builders.CaseBuilder.when` or; :meth:`~hail.expr.builders.CaseBuilder.default` method calls must be the; same type. Parameters; ----------; missing_false: :obj:`.bool`; Treat missing predicates as ``False``. See Also; --------; :func:`.case`, :func:`.cond`, :func:`.switch`; """""". def __init__(self, missing_false=False):; super(CaseBuilder, self).__init__(); self._missing_false = missing_false. def _finish(self, default):; assert len(self._cases) > 0. from hail.expr.functions import if_else. expr = default; for conditional, then in self._cases[::-1]:; expr = if_else(conditional, then, expr, missing_false=self._missing_false); return expr. [docs] @typecheck_method(condition=expr_bool, then=expr_any); def when(self, condition, then) -> 'CaseBuilder':; """"""Add a branch. If `condition` is ``True``, then returns `then`. Warning; -------; Missingness is treated similarly to :func:`.cond`. Missingness is; **not** treated as ``False``. A `condition` that evaluates to missing; will return a missing result, not proceed to the next case. Always; test missingness first in a :class:`.CaseBuilder`. Parameters; ----------; condition: :class:`.BooleanExpression`; then : :class:`.Expression`. Returns; -------; :class:`.CaseBuilder`; Mutates and returns `self`.; """"""; self._unify_type(then.dtype); self._cases.append((condition, then)); return self. [docs] @typecheck_method(then=expr_any); def default(self, then):; """"",MatchSource.WIKI,docs/0.2/_modules/hail/expr/builders.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/builders.html
https://hail.is/docs/0.2/_modules/hail/expr/builders.html:6786,Testability,test,test,6786,"Builder.default` method calls must be the; same type. Parameters; ----------; missing_false: :obj:`.bool`; Treat missing predicates as ``False``. See Also; --------; :func:`.case`, :func:`.cond`, :func:`.switch`; """""". def __init__(self, missing_false=False):; super(CaseBuilder, self).__init__(); self._missing_false = missing_false. def _finish(self, default):; assert len(self._cases) > 0. from hail.expr.functions import if_else. expr = default; for conditional, then in self._cases[::-1]:; expr = if_else(conditional, then, expr, missing_false=self._missing_false); return expr. [docs] @typecheck_method(condition=expr_bool, then=expr_any); def when(self, condition, then) -> 'CaseBuilder':; """"""Add a branch. If `condition` is ``True``, then returns `then`. Warning; -------; Missingness is treated similarly to :func:`.cond`. Missingness is; **not** treated as ``False``. A `condition` that evaluates to missing; will return a missing result, not proceed to the next case. Always; test missingness first in a :class:`.CaseBuilder`. Parameters; ----------; condition: :class:`.BooleanExpression`; then : :class:`.Expression`. Returns; -------; :class:`.CaseBuilder`; Mutates and returns `self`.; """"""; self._unify_type(then.dtype); self._cases.append((condition, then)); return self. [docs] @typecheck_method(then=expr_any); def default(self, then):; """"""Finish the case statement by adding a default case. Notes; -----; If no condition from a :meth:`~.CaseBuilder.when` call is ``True``,; then `then` is returned. Parameters; ----------; then : :class:`.Expression`. Returns; -------; :class:`.Expression`; """"""; if len(self._cases) == 0:; return then; self._unify_type(then.dtype); return self._finish(then). [docs] def or_missing(self):; """"""Finish the case statement by returning missing. Notes; -----; If no condition from a :meth:`.CaseBuilder.when` call is ``True``, then; the result is missing. Parameters; ----------; then : :class:`.Expression`. Returns; -------; :class:`.Expression`; """""";",MatchSource.WIKI,docs/0.2/_modules/hail/expr/builders.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/builders.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:5163,Availability,error,error,5163,"turn res. return hl.rbind(cdf, compute). @typecheck(raw_cdf=expr_struct()); def _result_from_raw_cdf(raw_cdf):; levels = raw_cdf.levels; item_weights = (; hl._stream_range(hl.len(levels) - 1); .flatmap(; lambda l: hl._stream_range(levels[l], levels[l + 1]).map(; lambda i: hl.struct(level=l, value=raw_cdf['items'][i]); ); ); .aggregate(lambda x: hl.agg.group_by(x.value, hl.agg.sum(hl.bit_lshift(1, x.level)))); ); weights = item_weights.values(); ranks = weights.scan(lambda acc, weight: acc + weight, 0); values = item_weights.keys(); return hl.struct(values=values, ranks=ranks, _compaction_counts=raw_cdf._compaction_counts). @typecheck(k=expr_int32, left=expr_struct(), right=expr_struct()); def _cdf_combine(k, left, right):; t = tstruct(levels=tarray(tint32), items=tarray(tfloat64), _compaction_counts=tarray(tint32)); return _func('approxCDFCombine', t, k, left, right). @typecheck(cdf=expr_struct(), failure_prob=expr_oneof(expr_float32, expr_float64), all_quantiles=bool); def _error_from_cdf(cdf, failure_prob, all_quantiles=False):; """"""Estimates error of approx_cdf aggregator, using Hoeffding's inequality. Parameters; ----------; cdf : :class:`.StructExpression`; Result of :func:`.approx_cdf` aggregator; failure_prob: :class:`.NumericExpression`; Upper bound on probability of true error being greater than estimated error.; all_quantiles: :obj:`bool`; If ``True``, with probability 1 - `failure_prob`, error estimate applies; to all quantiles simultaneously. Returns; -------; :class:`.NumericExpression`; Upper bound on error of quantile estimates.; """""". def compute_sum(cdf):; s = hl.sum(; hl.range(0, hl.len(cdf._compaction_counts)).map(lambda i: cdf._compaction_counts[i] * (2 ** (2 * i))); ); return s / (cdf.ranks[-1] ** 2). def update_grid_size(p, s):; return 4 * hl.sqrt(hl.log(2 * p / failure_prob) / (2 * s)). def compute_grid_size(s):; return hl.fold(lambda p, i: update_grid_size(p, s), 1 / failure_prob, hl.range(0, 5)). def compute_single_error(s, failure_prob=failure",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:5403,Availability,error,error,5403,"alue=raw_cdf['items'][i]); ); ); .aggregate(lambda x: hl.agg.group_by(x.value, hl.agg.sum(hl.bit_lshift(1, x.level)))); ); weights = item_weights.values(); ranks = weights.scan(lambda acc, weight: acc + weight, 0); values = item_weights.keys(); return hl.struct(values=values, ranks=ranks, _compaction_counts=raw_cdf._compaction_counts). @typecheck(k=expr_int32, left=expr_struct(), right=expr_struct()); def _cdf_combine(k, left, right):; t = tstruct(levels=tarray(tint32), items=tarray(tfloat64), _compaction_counts=tarray(tint32)); return _func('approxCDFCombine', t, k, left, right). @typecheck(cdf=expr_struct(), failure_prob=expr_oneof(expr_float32, expr_float64), all_quantiles=bool); def _error_from_cdf(cdf, failure_prob, all_quantiles=False):; """"""Estimates error of approx_cdf aggregator, using Hoeffding's inequality. Parameters; ----------; cdf : :class:`.StructExpression`; Result of :func:`.approx_cdf` aggregator; failure_prob: :class:`.NumericExpression`; Upper bound on probability of true error being greater than estimated error.; all_quantiles: :obj:`bool`; If ``True``, with probability 1 - `failure_prob`, error estimate applies; to all quantiles simultaneously. Returns; -------; :class:`.NumericExpression`; Upper bound on error of quantile estimates.; """""". def compute_sum(cdf):; s = hl.sum(; hl.range(0, hl.len(cdf._compaction_counts)).map(lambda i: cdf._compaction_counts[i] * (2 ** (2 * i))); ); return s / (cdf.ranks[-1] ** 2). def update_grid_size(p, s):; return 4 * hl.sqrt(hl.log(2 * p / failure_prob) / (2 * s)). def compute_grid_size(s):; return hl.fold(lambda p, i: update_grid_size(p, s), 1 / failure_prob, hl.range(0, 5)). def compute_single_error(s, failure_prob=failure_prob):; return hl.sqrt(hl.log(2 / failure_prob) * s / 2). def compute_global_error(s):; return hl.rbind(compute_grid_size(s), lambda p: 1 / p + compute_single_error(s, failure_prob / p)). if all_quantiles:; return hl.rbind(cdf, lambda cdf: hl.rbind(compute_sum(cdf), compute_global_error)); ",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:5438,Availability,error,error,5438,"alue=raw_cdf['items'][i]); ); ); .aggregate(lambda x: hl.agg.group_by(x.value, hl.agg.sum(hl.bit_lshift(1, x.level)))); ); weights = item_weights.values(); ranks = weights.scan(lambda acc, weight: acc + weight, 0); values = item_weights.keys(); return hl.struct(values=values, ranks=ranks, _compaction_counts=raw_cdf._compaction_counts). @typecheck(k=expr_int32, left=expr_struct(), right=expr_struct()); def _cdf_combine(k, left, right):; t = tstruct(levels=tarray(tint32), items=tarray(tfloat64), _compaction_counts=tarray(tint32)); return _func('approxCDFCombine', t, k, left, right). @typecheck(cdf=expr_struct(), failure_prob=expr_oneof(expr_float32, expr_float64), all_quantiles=bool); def _error_from_cdf(cdf, failure_prob, all_quantiles=False):; """"""Estimates error of approx_cdf aggregator, using Hoeffding's inequality. Parameters; ----------; cdf : :class:`.StructExpression`; Result of :func:`.approx_cdf` aggregator; failure_prob: :class:`.NumericExpression`; Upper bound on probability of true error being greater than estimated error.; all_quantiles: :obj:`bool`; If ``True``, with probability 1 - `failure_prob`, error estimate applies; to all quantiles simultaneously. Returns; -------; :class:`.NumericExpression`; Upper bound on error of quantile estimates.; """""". def compute_sum(cdf):; s = hl.sum(; hl.range(0, hl.len(cdf._compaction_counts)).map(lambda i: cdf._compaction_counts[i] * (2 ** (2 * i))); ); return s / (cdf.ranks[-1] ** 2). def update_grid_size(p, s):; return 4 * hl.sqrt(hl.log(2 * p / failure_prob) / (2 * s)). def compute_grid_size(s):; return hl.fold(lambda p, i: update_grid_size(p, s), 1 / failure_prob, hl.range(0, 5)). def compute_single_error(s, failure_prob=failure_prob):; return hl.sqrt(hl.log(2 / failure_prob) * s / 2). def compute_global_error(s):; return hl.rbind(compute_grid_size(s), lambda p: 1 / p + compute_single_error(s, failure_prob / p)). if all_quantiles:; return hl.rbind(cdf, lambda cdf: hl.rbind(compute_sum(cdf), compute_global_error)); ",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:5524,Availability,error,error,5524,")); ); weights = item_weights.values(); ranks = weights.scan(lambda acc, weight: acc + weight, 0); values = item_weights.keys(); return hl.struct(values=values, ranks=ranks, _compaction_counts=raw_cdf._compaction_counts). @typecheck(k=expr_int32, left=expr_struct(), right=expr_struct()); def _cdf_combine(k, left, right):; t = tstruct(levels=tarray(tint32), items=tarray(tfloat64), _compaction_counts=tarray(tint32)); return _func('approxCDFCombine', t, k, left, right). @typecheck(cdf=expr_struct(), failure_prob=expr_oneof(expr_float32, expr_float64), all_quantiles=bool); def _error_from_cdf(cdf, failure_prob, all_quantiles=False):; """"""Estimates error of approx_cdf aggregator, using Hoeffding's inequality. Parameters; ----------; cdf : :class:`.StructExpression`; Result of :func:`.approx_cdf` aggregator; failure_prob: :class:`.NumericExpression`; Upper bound on probability of true error being greater than estimated error.; all_quantiles: :obj:`bool`; If ``True``, with probability 1 - `failure_prob`, error estimate applies; to all quantiles simultaneously. Returns; -------; :class:`.NumericExpression`; Upper bound on error of quantile estimates.; """""". def compute_sum(cdf):; s = hl.sum(; hl.range(0, hl.len(cdf._compaction_counts)).map(lambda i: cdf._compaction_counts[i] * (2 ** (2 * i))); ); return s / (cdf.ranks[-1] ** 2). def update_grid_size(p, s):; return 4 * hl.sqrt(hl.log(2 * p / failure_prob) / (2 * s)). def compute_grid_size(s):; return hl.fold(lambda p, i: update_grid_size(p, s), 1 / failure_prob, hl.range(0, 5)). def compute_single_error(s, failure_prob=failure_prob):; return hl.sqrt(hl.log(2 / failure_prob) * s / 2). def compute_global_error(s):; return hl.rbind(compute_grid_size(s), lambda p: 1 / p + compute_single_error(s, failure_prob / p)). if all_quantiles:; return hl.rbind(cdf, lambda cdf: hl.rbind(compute_sum(cdf), compute_global_error)); else:; return hl.rbind(cdf, lambda cdf: hl.rbind(compute_sum(cdf), compute_single_error)). def _error_from_cdf_pytho",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:5643,Availability,error,error,5643,"; return hl.struct(values=values, ranks=ranks, _compaction_counts=raw_cdf._compaction_counts). @typecheck(k=expr_int32, left=expr_struct(), right=expr_struct()); def _cdf_combine(k, left, right):; t = tstruct(levels=tarray(tint32), items=tarray(tfloat64), _compaction_counts=tarray(tint32)); return _func('approxCDFCombine', t, k, left, right). @typecheck(cdf=expr_struct(), failure_prob=expr_oneof(expr_float32, expr_float64), all_quantiles=bool); def _error_from_cdf(cdf, failure_prob, all_quantiles=False):; """"""Estimates error of approx_cdf aggregator, using Hoeffding's inequality. Parameters; ----------; cdf : :class:`.StructExpression`; Result of :func:`.approx_cdf` aggregator; failure_prob: :class:`.NumericExpression`; Upper bound on probability of true error being greater than estimated error.; all_quantiles: :obj:`bool`; If ``True``, with probability 1 - `failure_prob`, error estimate applies; to all quantiles simultaneously. Returns; -------; :class:`.NumericExpression`; Upper bound on error of quantile estimates.; """""". def compute_sum(cdf):; s = hl.sum(; hl.range(0, hl.len(cdf._compaction_counts)).map(lambda i: cdf._compaction_counts[i] * (2 ** (2 * i))); ); return s / (cdf.ranks[-1] ** 2). def update_grid_size(p, s):; return 4 * hl.sqrt(hl.log(2 * p / failure_prob) / (2 * s)). def compute_grid_size(s):; return hl.fold(lambda p, i: update_grid_size(p, s), 1 / failure_prob, hl.range(0, 5)). def compute_single_error(s, failure_prob=failure_prob):; return hl.sqrt(hl.log(2 / failure_prob) * s / 2). def compute_global_error(s):; return hl.rbind(compute_grid_size(s), lambda p: 1 / p + compute_single_error(s, failure_prob / p)). if all_quantiles:; return hl.rbind(cdf, lambda cdf: hl.rbind(compute_sum(cdf), compute_global_error)); else:; return hl.rbind(cdf, lambda cdf: hl.rbind(compute_sum(cdf), compute_single_error)). def _error_from_cdf_python(cdf, failure_prob, all_quantiles=False):; """"""Estimates error of approx_cdf aggregator, using Hoeffding's inequality. Parameter",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:6569,Availability,error,error,6569,"ntiles simultaneously. Returns; -------; :class:`.NumericExpression`; Upper bound on error of quantile estimates.; """""". def compute_sum(cdf):; s = hl.sum(; hl.range(0, hl.len(cdf._compaction_counts)).map(lambda i: cdf._compaction_counts[i] * (2 ** (2 * i))); ); return s / (cdf.ranks[-1] ** 2). def update_grid_size(p, s):; return 4 * hl.sqrt(hl.log(2 * p / failure_prob) / (2 * s)). def compute_grid_size(s):; return hl.fold(lambda p, i: update_grid_size(p, s), 1 / failure_prob, hl.range(0, 5)). def compute_single_error(s, failure_prob=failure_prob):; return hl.sqrt(hl.log(2 / failure_prob) * s / 2). def compute_global_error(s):; return hl.rbind(compute_grid_size(s), lambda p: 1 / p + compute_single_error(s, failure_prob / p)). if all_quantiles:; return hl.rbind(cdf, lambda cdf: hl.rbind(compute_sum(cdf), compute_global_error)); else:; return hl.rbind(cdf, lambda cdf: hl.rbind(compute_sum(cdf), compute_single_error)). def _error_from_cdf_python(cdf, failure_prob, all_quantiles=False):; """"""Estimates error of approx_cdf aggregator, using Hoeffding's inequality. Parameters; ----------; cdf : :obj:`dict`; Result of :func:`.approx_cdf` aggregator, evaluated to a python dict; failure_prob: :obj:`float`; Upper bound on probability of true error being greater than estimated error.; all_quantiles: :obj:`bool`; If ``True``, with probability 1 - `failure_prob`, error estimate applies; to all quantiles simultaneously. Returns; -------; :obj:`float`; Upper bound on error of quantile estimates.; """"""; import math. s = 0; for i in builtins.range(builtins.len(cdf._compaction_counts)):; s += cdf._compaction_counts[i] << (2 * i); s = s / (cdf.ranks[-1] ** 2). def update_grid_size(p):; return 4 * math.sqrt(math.log(2 * p / failure_prob) / (2 * s)). def compute_grid_size(s):; p = 1 / failure_prob; for _ in builtins.range(5):; p = update_grid_size(p); return p. def compute_single_error(s, failure_prob=failure_prob):; return math.sqrt(math.log(2 / failure_prob) * s / 2). if s == 0:; # no com",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:6807,Availability,error,error,6807,": cdf._compaction_counts[i] * (2 ** (2 * i))); ); return s / (cdf.ranks[-1] ** 2). def update_grid_size(p, s):; return 4 * hl.sqrt(hl.log(2 * p / failure_prob) / (2 * s)). def compute_grid_size(s):; return hl.fold(lambda p, i: update_grid_size(p, s), 1 / failure_prob, hl.range(0, 5)). def compute_single_error(s, failure_prob=failure_prob):; return hl.sqrt(hl.log(2 / failure_prob) * s / 2). def compute_global_error(s):; return hl.rbind(compute_grid_size(s), lambda p: 1 / p + compute_single_error(s, failure_prob / p)). if all_quantiles:; return hl.rbind(cdf, lambda cdf: hl.rbind(compute_sum(cdf), compute_global_error)); else:; return hl.rbind(cdf, lambda cdf: hl.rbind(compute_sum(cdf), compute_single_error)). def _error_from_cdf_python(cdf, failure_prob, all_quantiles=False):; """"""Estimates error of approx_cdf aggregator, using Hoeffding's inequality. Parameters; ----------; cdf : :obj:`dict`; Result of :func:`.approx_cdf` aggregator, evaluated to a python dict; failure_prob: :obj:`float`; Upper bound on probability of true error being greater than estimated error.; all_quantiles: :obj:`bool`; If ``True``, with probability 1 - `failure_prob`, error estimate applies; to all quantiles simultaneously. Returns; -------; :obj:`float`; Upper bound on error of quantile estimates.; """"""; import math. s = 0; for i in builtins.range(builtins.len(cdf._compaction_counts)):; s += cdf._compaction_counts[i] << (2 * i); s = s / (cdf.ranks[-1] ** 2). def update_grid_size(p):; return 4 * math.sqrt(math.log(2 * p / failure_prob) / (2 * s)). def compute_grid_size(s):; p = 1 / failure_prob; for _ in builtins.range(5):; p = update_grid_size(p); return p. def compute_single_error(s, failure_prob=failure_prob):; return math.sqrt(math.log(2 / failure_prob) * s / 2). if s == 0:; # no compactions ergo no error; return 0; elif all_quantiles:; p = compute_grid_size(s); return 1 / p + compute_single_error(s, failure_prob / p); else:; return compute_single_error(s, failure_prob). [docs]@typecheck(t=h",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:6842,Availability,error,error,6842,": cdf._compaction_counts[i] * (2 ** (2 * i))); ); return s / (cdf.ranks[-1] ** 2). def update_grid_size(p, s):; return 4 * hl.sqrt(hl.log(2 * p / failure_prob) / (2 * s)). def compute_grid_size(s):; return hl.fold(lambda p, i: update_grid_size(p, s), 1 / failure_prob, hl.range(0, 5)). def compute_single_error(s, failure_prob=failure_prob):; return hl.sqrt(hl.log(2 / failure_prob) * s / 2). def compute_global_error(s):; return hl.rbind(compute_grid_size(s), lambda p: 1 / p + compute_single_error(s, failure_prob / p)). if all_quantiles:; return hl.rbind(cdf, lambda cdf: hl.rbind(compute_sum(cdf), compute_global_error)); else:; return hl.rbind(cdf, lambda cdf: hl.rbind(compute_sum(cdf), compute_single_error)). def _error_from_cdf_python(cdf, failure_prob, all_quantiles=False):; """"""Estimates error of approx_cdf aggregator, using Hoeffding's inequality. Parameters; ----------; cdf : :obj:`dict`; Result of :func:`.approx_cdf` aggregator, evaluated to a python dict; failure_prob: :obj:`float`; Upper bound on probability of true error being greater than estimated error.; all_quantiles: :obj:`bool`; If ``True``, with probability 1 - `failure_prob`, error estimate applies; to all quantiles simultaneously. Returns; -------; :obj:`float`; Upper bound on error of quantile estimates.; """"""; import math. s = 0; for i in builtins.range(builtins.len(cdf._compaction_counts)):; s += cdf._compaction_counts[i] << (2 * i); s = s / (cdf.ranks[-1] ** 2). def update_grid_size(p):; return 4 * math.sqrt(math.log(2 * p / failure_prob) / (2 * s)). def compute_grid_size(s):; p = 1 / failure_prob; for _ in builtins.range(5):; p = update_grid_size(p); return p. def compute_single_error(s, failure_prob=failure_prob):; return math.sqrt(math.log(2 / failure_prob) * s / 2). if s == 0:; # no compactions ergo no error; return 0; elif all_quantiles:; p = compute_grid_size(s); return 1 / p + compute_single_error(s, failure_prob / p); else:; return compute_single_error(s, failure_prob). [docs]@typecheck(t=h",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:6928,Availability,error,error,6928,"failure_prob) / (2 * s)). def compute_grid_size(s):; return hl.fold(lambda p, i: update_grid_size(p, s), 1 / failure_prob, hl.range(0, 5)). def compute_single_error(s, failure_prob=failure_prob):; return hl.sqrt(hl.log(2 / failure_prob) * s / 2). def compute_global_error(s):; return hl.rbind(compute_grid_size(s), lambda p: 1 / p + compute_single_error(s, failure_prob / p)). if all_quantiles:; return hl.rbind(cdf, lambda cdf: hl.rbind(compute_sum(cdf), compute_global_error)); else:; return hl.rbind(cdf, lambda cdf: hl.rbind(compute_sum(cdf), compute_single_error)). def _error_from_cdf_python(cdf, failure_prob, all_quantiles=False):; """"""Estimates error of approx_cdf aggregator, using Hoeffding's inequality. Parameters; ----------; cdf : :obj:`dict`; Result of :func:`.approx_cdf` aggregator, evaluated to a python dict; failure_prob: :obj:`float`; Upper bound on probability of true error being greater than estimated error.; all_quantiles: :obj:`bool`; If ``True``, with probability 1 - `failure_prob`, error estimate applies; to all quantiles simultaneously. Returns; -------; :obj:`float`; Upper bound on error of quantile estimates.; """"""; import math. s = 0; for i in builtins.range(builtins.len(cdf._compaction_counts)):; s += cdf._compaction_counts[i] << (2 * i); s = s / (cdf.ranks[-1] ** 2). def update_grid_size(p):; return 4 * math.sqrt(math.log(2 * p / failure_prob) / (2 * s)). def compute_grid_size(s):; p = 1 / failure_prob; for _ in builtins.range(5):; p = update_grid_size(p); return p. def compute_single_error(s, failure_prob=failure_prob):; return math.sqrt(math.log(2 / failure_prob) * s / 2). if s == 0:; # no compactions ergo no error; return 0; elif all_quantiles:; p = compute_grid_size(s); return 1 / p + compute_single_error(s, failure_prob / p); else:; return compute_single_error(s, failure_prob). [docs]@typecheck(t=hail_type); def missing(t: Union[HailType, str]):; """"""Creates an expression representing a missing value of a specified type. Examples; --------. >",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:7032,Availability,error,error,7032," / failure_prob, hl.range(0, 5)). def compute_single_error(s, failure_prob=failure_prob):; return hl.sqrt(hl.log(2 / failure_prob) * s / 2). def compute_global_error(s):; return hl.rbind(compute_grid_size(s), lambda p: 1 / p + compute_single_error(s, failure_prob / p)). if all_quantiles:; return hl.rbind(cdf, lambda cdf: hl.rbind(compute_sum(cdf), compute_global_error)); else:; return hl.rbind(cdf, lambda cdf: hl.rbind(compute_sum(cdf), compute_single_error)). def _error_from_cdf_python(cdf, failure_prob, all_quantiles=False):; """"""Estimates error of approx_cdf aggregator, using Hoeffding's inequality. Parameters; ----------; cdf : :obj:`dict`; Result of :func:`.approx_cdf` aggregator, evaluated to a python dict; failure_prob: :obj:`float`; Upper bound on probability of true error being greater than estimated error.; all_quantiles: :obj:`bool`; If ``True``, with probability 1 - `failure_prob`, error estimate applies; to all quantiles simultaneously. Returns; -------; :obj:`float`; Upper bound on error of quantile estimates.; """"""; import math. s = 0; for i in builtins.range(builtins.len(cdf._compaction_counts)):; s += cdf._compaction_counts[i] << (2 * i); s = s / (cdf.ranks[-1] ** 2). def update_grid_size(p):; return 4 * math.sqrt(math.log(2 * p / failure_prob) / (2 * s)). def compute_grid_size(s):; p = 1 / failure_prob; for _ in builtins.range(5):; p = update_grid_size(p); return p. def compute_single_error(s, failure_prob=failure_prob):; return math.sqrt(math.log(2 / failure_prob) * s / 2). if s == 0:; # no compactions ergo no error; return 0; elif all_quantiles:; p = compute_grid_size(s); return 1 / p + compute_single_error(s, failure_prob / p); else:; return compute_single_error(s, failure_prob). [docs]@typecheck(t=hail_type); def missing(t: Union[HailType, str]):; """"""Creates an expression representing a missing value of a specified type. Examples; --------. >>> hl.eval(hl.missing(hl.tarray(hl.tstr))); None. >>> hl.eval(hl.missing('array<str>')); None. Notes; ----",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:7575,Availability,error,error,7575,"----------; cdf : :obj:`dict`; Result of :func:`.approx_cdf` aggregator, evaluated to a python dict; failure_prob: :obj:`float`; Upper bound on probability of true error being greater than estimated error.; all_quantiles: :obj:`bool`; If ``True``, with probability 1 - `failure_prob`, error estimate applies; to all quantiles simultaneously. Returns; -------; :obj:`float`; Upper bound on error of quantile estimates.; """"""; import math. s = 0; for i in builtins.range(builtins.len(cdf._compaction_counts)):; s += cdf._compaction_counts[i] << (2 * i); s = s / (cdf.ranks[-1] ** 2). def update_grid_size(p):; return 4 * math.sqrt(math.log(2 * p / failure_prob) / (2 * s)). def compute_grid_size(s):; p = 1 / failure_prob; for _ in builtins.range(5):; p = update_grid_size(p); return p. def compute_single_error(s, failure_prob=failure_prob):; return math.sqrt(math.log(2 / failure_prob) * s / 2). if s == 0:; # no compactions ergo no error; return 0; elif all_quantiles:; p = compute_grid_size(s); return 1 / p + compute_single_error(s, failure_prob / p); else:; return compute_single_error(s, failure_prob). [docs]@typecheck(t=hail_type); def missing(t: Union[HailType, str]):; """"""Creates an expression representing a missing value of a specified type. Examples; --------. >>> hl.eval(hl.missing(hl.tarray(hl.tstr))); None. >>> hl.eval(hl.missing('array<str>')); None. Notes; -----; This method is useful for constructing an expression that includes missing; values, since :obj:`None` cannot be interpreted as an expression. Parameters; ----------; t : :class:`str` or :class:`.HailType`; Type of the missing expression. Returns; -------; :class:`.Expression`; A missing expression of type `t`.; """"""; return construct_expr(ir.NA(t), t). [docs]@deprecated(version=""0.2.62"", reason=""Replaced by hl.missing""); @typecheck(t=hail_type); def null(t: Union[HailType, str]):; """"""Deprecated in favor of :func:`.missing`. Creates an expression representing a missing value of a specified type. Examples; -------",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:17873,Availability,error,errors,17873,"hBuilder. return SwitchBuilder(expr). [docs]@typecheck(f=anytype, exprs=expr_any, _ctx=nullable(str)); def bind(f: Callable, *exprs, _ctx=None):; """"""Bind a temporary variable and use it in a function. Examples; --------. >>> hl.eval(hl.bind(lambda x: x + 1, 1)); 2. :func:`.bind` also can take multiple arguments:. >>> hl.eval(hl.bind(lambda x, y: x / y, x, x)); 1.0. Parameters; ----------; f : function ( (args) -> :class:`.Expression`); Function of `exprs`.; exprs : variable-length args of :class:`.Expression`; Expressions to bind. Returns; -------; :class:`.Expression`; Result of evaluating `f` with `exprs` as arguments.; """"""; args = []; uids = []; irs = []. for expr in exprs:; uid = Env.get_uid(base=_ctx); args.append(construct_variable(uid, expr._type, expr._indices, expr._aggregations)); uids.append(uid); irs.append(expr._ir). lambda_result = to_expr(f(*args)); if _ctx:; indices, aggregations = unify_all(lambda_result) # FIXME: hacky. May drop field refs from errors?; else:; indices, aggregations = unify_all(*exprs, lambda_result). res_ir = lambda_result._ir; for uid, value_ir in builtins.zip(uids, irs):; if _ctx == 'agg':; res_ir = ir.AggLet(uid, value_ir, res_ir, is_scan=False); elif _ctx == 'scan':; res_ir = ir.AggLet(uid, value_ir, res_ir, is_scan=True); else:; res_ir = ir.Let(uid, value_ir, res_ir). return construct_expr(res_ir, lambda_result.dtype, indices, aggregations). [docs]def rbind(*exprs, _ctx=None):; """"""Bind a temporary variable and use it in a function. This is :func:`.bind` with flipped argument order. Examples; --------. >>> hl.eval(hl.rbind(1, lambda x: x + 1)); 2. :func:`.rbind` also can take multiple arguments:. >>> hl.eval(hl.rbind(4.0, 2.0, lambda x, y: x / y)); 2.0. Parameters; ----------; exprs : variable-length args of :class:`.Expression`; Expressions to bind.; f : function ( (args) -> :class:`.Expression`); Function of `exprs`. Returns; -------; :class:`.Expression`; Result of evaluating `f` with `exprs` as arguments.; """""". *args, f = ex",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:64237,Availability,fault,fault,64237,"7. >>> hl.eval(hl.pchisqtail(5, 1, lower_tail=True)); 0.9746526813225317. >>> hl.eval(hl.pchisqtail(5, 1, log_p=True)); -3.6750823266311876. Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64`; The value at which to evaluate the CDF.; df : float or :class:`.Expression` of type :py:data:`.tfloat64`; Degrees of freedom.; ncp: float or :class:`.Expression` of type :py:data:`.tfloat64`; Noncentrality parameter, defaults to 0 if unspecified.; lower_tail : bool or :class:`.BooleanExpression`; If ``True``, compute the probability of an outcome at or below `x`,; otherwise greater than `x`.; log_p : bool or :class:`.BooleanExpression`; Return the natural logarithm of the probability. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`; """"""; if ncp is None:; return _func(""pchisqtail"", tfloat64, x, df, lower_tail, log_p); else:; return _func(""pnchisqtail"", tfloat64, x, df, ncp, lower_tail, log_p). PGENCHISQ_RETURN_TYPE = tstruct(value=tfloat64, n_iterations=tint32, converged=tbool, fault=tint32). [docs]@typecheck(; x=expr_float64,; w=expr_array(expr_float64),; k=expr_array(expr_int32),; lam=expr_array(expr_float64),; mu=expr_float64,; sigma=expr_float64,; max_iterations=nullable(expr_int32),; min_accuracy=nullable(expr_float64),; ); def pgenchisq(x, w, k, lam, mu, sigma, *, max_iterations=None, min_accuracy=None) -> Float64Expression:; r""""""The cumulative probability function of a `generalized chi-squared distribution; <https://en.wikipedia.org/wiki/Generalized_chi-squared_distribution>`__. The generalized chi-squared distribution has many interpretations. We share here four; interpretations of the values of this distribution:. 1. A linear combination of normal variables and squares of normal variables. 2. A weighted sum of sums of squares of normally distributed values plus a normally distributed; value. 3. A weighted sum of chi-squared distributed values plus a normally distributed value. 4. A `""quadratic form"" <https://en.wik",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:70446,Availability,error,error,70446," evaluate the cumulative distribution function (CDF).; w : :obj:`list` of :obj:`float` or :class:`.Expression` of type :py:class:`.tarray` of :py:data:`.tfloat64`; A weight for each non-central chi-square term.; k : :obj:`list` of :obj:`int` or :class:`.Expression` of type :py:class:`.tarray` of :py:data:`.tint32`; A degrees of freedom parameter for each non-central chi-square term.; lam : :obj:`list` of :obj:`float` or :class:`.Expression` of type :py:class:`.tarray` of :py:data:`.tfloat64`; A non-centrality parameter for each non-central chi-square term. We use `lam` instead; of `lambda` because the latter is a reserved word in Python.; mu : :obj:`float` or :class:`.Expression` of type :py:data:`.tfloat64`; The standard deviation of the normal term.; sigma : :obj:`float` or :class:`.Expression` of type :py:data:`.tfloat64`; The standard deviation of the normal term.; max_iterations : :obj:`int` or :class:`.Expression` of type :py:data:`.tint32`; The maximum number of iterations of the numerical integration before raising an error. The; default maximum number of iterations is ``1e5``.; min_accuracy : :obj:`int` or :class:`.Expression` of type :py:data:`.tint32`; The minimum accuracy of the returned value. If the minimum accuracy is not achieved, this; function will raise an error. The default minimum accuracy is ``1e-5``. Returns; -------; :class:`.StructExpression`; This method returns a structure with the value as well as information about the numerical; integration. - value : :class:`.Float64Expression`. If converged is true, the value of the CDF evaluated; at `x`. Otherwise, this is the last value the integration evaluated before aborting. - n_iterations : :class:`.Int32Expression`. The number of iterations before stopping. - converged : :class:`.BooleanExpression`. True if the `min_accuracy` was achieved and round; off error is not likely significant. - fault : :class:`.Int32Expression`. If converged is true, fault is zero. If converged is; false, fault is eith",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:70700,Availability,error,error,70700,"n` of type :py:class:`.tarray` of :py:data:`.tint32`; A degrees of freedom parameter for each non-central chi-square term.; lam : :obj:`list` of :obj:`float` or :class:`.Expression` of type :py:class:`.tarray` of :py:data:`.tfloat64`; A non-centrality parameter for each non-central chi-square term. We use `lam` instead; of `lambda` because the latter is a reserved word in Python.; mu : :obj:`float` or :class:`.Expression` of type :py:data:`.tfloat64`; The standard deviation of the normal term.; sigma : :obj:`float` or :class:`.Expression` of type :py:data:`.tfloat64`; The standard deviation of the normal term.; max_iterations : :obj:`int` or :class:`.Expression` of type :py:data:`.tint32`; The maximum number of iterations of the numerical integration before raising an error. The; default maximum number of iterations is ``1e5``.; min_accuracy : :obj:`int` or :class:`.Expression` of type :py:data:`.tint32`; The minimum accuracy of the returned value. If the minimum accuracy is not achieved, this; function will raise an error. The default minimum accuracy is ``1e-5``. Returns; -------; :class:`.StructExpression`; This method returns a structure with the value as well as information about the numerical; integration. - value : :class:`.Float64Expression`. If converged is true, the value of the CDF evaluated; at `x`. Otherwise, this is the last value the integration evaluated before aborting. - n_iterations : :class:`.Int32Expression`. The number of iterations before stopping. - converged : :class:`.BooleanExpression`. True if the `min_accuracy` was achieved and round; off error is not likely significant. - fault : :class:`.Int32Expression`. If converged is true, fault is zero. If converged is; false, fault is either one or two. One indicates that the requried accuracy was not; achieved. Two indicates the round-off error is possibly significant. """"""; if max_iterations is None:; max_iterations = hl.literal(10_000); if min_accuracy is None:; min_accuracy = hl.literal(1e-5); ",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:71261,Availability,error,error,71261,"ndard deviation of the normal term.; max_iterations : :obj:`int` or :class:`.Expression` of type :py:data:`.tint32`; The maximum number of iterations of the numerical integration before raising an error. The; default maximum number of iterations is ``1e5``.; min_accuracy : :obj:`int` or :class:`.Expression` of type :py:data:`.tint32`; The minimum accuracy of the returned value. If the minimum accuracy is not achieved, this; function will raise an error. The default minimum accuracy is ``1e-5``. Returns; -------; :class:`.StructExpression`; This method returns a structure with the value as well as information about the numerical; integration. - value : :class:`.Float64Expression`. If converged is true, the value of the CDF evaluated; at `x`. Otherwise, this is the last value the integration evaluated before aborting. - n_iterations : :class:`.Int32Expression`. The number of iterations before stopping. - converged : :class:`.BooleanExpression`. True if the `min_accuracy` was achieved and round; off error is not likely significant. - fault : :class:`.Int32Expression`. If converged is true, fault is zero. If converged is; false, fault is either one or two. One indicates that the requried accuracy was not; achieved. Two indicates the round-off error is possibly significant. """"""; if max_iterations is None:; max_iterations = hl.literal(10_000); if min_accuracy is None:; min_accuracy = hl.literal(1e-5); return _func(""pgenchisq"", PGENCHISQ_RETURN_TYPE, x - mu, w, k, lam, sigma, max_iterations, min_accuracy). [docs]@typecheck(x=expr_float64, mu=expr_float64, sigma=expr_float64, lower_tail=expr_bool, log_p=expr_bool); def pnorm(x, mu=0, sigma=1, lower_tail=True, log_p=False) -> Float64Expression:; """"""The cumulative probability function of a normal distribution with mean; `mu` and standard deviation `sigma`. Returns cumulative probability of; standard normal distribution by default. Examples; --------. >>> hl.eval(hl.pnorm(0)); 0.5. >>> hl.eval(hl.pnorm(1, mu=2, sigma=2)); 0.30",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:71296,Availability,fault,fault,71296,":obj:`int` or :class:`.Expression` of type :py:data:`.tint32`; The maximum number of iterations of the numerical integration before raising an error. The; default maximum number of iterations is ``1e5``.; min_accuracy : :obj:`int` or :class:`.Expression` of type :py:data:`.tint32`; The minimum accuracy of the returned value. If the minimum accuracy is not achieved, this; function will raise an error. The default minimum accuracy is ``1e-5``. Returns; -------; :class:`.StructExpression`; This method returns a structure with the value as well as information about the numerical; integration. - value : :class:`.Float64Expression`. If converged is true, the value of the CDF evaluated; at `x`. Otherwise, this is the last value the integration evaluated before aborting. - n_iterations : :class:`.Int32Expression`. The number of iterations before stopping. - converged : :class:`.BooleanExpression`. True if the `min_accuracy` was achieved and round; off error is not likely significant. - fault : :class:`.Int32Expression`. If converged is true, fault is zero. If converged is; false, fault is either one or two. One indicates that the requried accuracy was not; achieved. Two indicates the round-off error is possibly significant. """"""; if max_iterations is None:; max_iterations = hl.literal(10_000); if min_accuracy is None:; min_accuracy = hl.literal(1e-5); return _func(""pgenchisq"", PGENCHISQ_RETURN_TYPE, x - mu, w, k, lam, sigma, max_iterations, min_accuracy). [docs]@typecheck(x=expr_float64, mu=expr_float64, sigma=expr_float64, lower_tail=expr_bool, log_p=expr_bool); def pnorm(x, mu=0, sigma=1, lower_tail=True, log_p=False) -> Float64Expression:; """"""The cumulative probability function of a normal distribution with mean; `mu` and standard deviation `sigma`. Returns cumulative probability of; standard normal distribution by default. Examples; --------. >>> hl.eval(hl.pnorm(0)); 0.5. >>> hl.eval(hl.pnorm(1, mu=2, sigma=2)); 0.30853753872598694. >>> hl.eval(hl.pnorm(2, lower_tail=Fa",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:71353,Availability,fault,fault,71353,"y:data:`.tint32`; The maximum number of iterations of the numerical integration before raising an error. The; default maximum number of iterations is ``1e5``.; min_accuracy : :obj:`int` or :class:`.Expression` of type :py:data:`.tint32`; The minimum accuracy of the returned value. If the minimum accuracy is not achieved, this; function will raise an error. The default minimum accuracy is ``1e-5``. Returns; -------; :class:`.StructExpression`; This method returns a structure with the value as well as information about the numerical; integration. - value : :class:`.Float64Expression`. If converged is true, the value of the CDF evaluated; at `x`. Otherwise, this is the last value the integration evaluated before aborting. - n_iterations : :class:`.Int32Expression`. The number of iterations before stopping. - converged : :class:`.BooleanExpression`. True if the `min_accuracy` was achieved and round; off error is not likely significant. - fault : :class:`.Int32Expression`. If converged is true, fault is zero. If converged is; false, fault is either one or two. One indicates that the requried accuracy was not; achieved. Two indicates the round-off error is possibly significant. """"""; if max_iterations is None:; max_iterations = hl.literal(10_000); if min_accuracy is None:; min_accuracy = hl.literal(1e-5); return _func(""pgenchisq"", PGENCHISQ_RETURN_TYPE, x - mu, w, k, lam, sigma, max_iterations, min_accuracy). [docs]@typecheck(x=expr_float64, mu=expr_float64, sigma=expr_float64, lower_tail=expr_bool, log_p=expr_bool); def pnorm(x, mu=0, sigma=1, lower_tail=True, log_p=False) -> Float64Expression:; """"""The cumulative probability function of a normal distribution with mean; `mu` and standard deviation `sigma`. Returns cumulative probability of; standard normal distribution by default. Examples; --------. >>> hl.eval(hl.pnorm(0)); 0.5. >>> hl.eval(hl.pnorm(1, mu=2, sigma=2)); 0.30853753872598694. >>> hl.eval(hl.pnorm(2, lower_tail=False)); 0.022750131948179212. >>> hl.eval(hl.pn",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:71392,Availability,fault,fault,71392,"tions of the numerical integration before raising an error. The; default maximum number of iterations is ``1e5``.; min_accuracy : :obj:`int` or :class:`.Expression` of type :py:data:`.tint32`; The minimum accuracy of the returned value. If the minimum accuracy is not achieved, this; function will raise an error. The default minimum accuracy is ``1e-5``. Returns; -------; :class:`.StructExpression`; This method returns a structure with the value as well as information about the numerical; integration. - value : :class:`.Float64Expression`. If converged is true, the value of the CDF evaluated; at `x`. Otherwise, this is the last value the integration evaluated before aborting. - n_iterations : :class:`.Int32Expression`. The number of iterations before stopping. - converged : :class:`.BooleanExpression`. True if the `min_accuracy` was achieved and round; off error is not likely significant. - fault : :class:`.Int32Expression`. If converged is true, fault is zero. If converged is; false, fault is either one or two. One indicates that the requried accuracy was not; achieved. Two indicates the round-off error is possibly significant. """"""; if max_iterations is None:; max_iterations = hl.literal(10_000); if min_accuracy is None:; min_accuracy = hl.literal(1e-5); return _func(""pgenchisq"", PGENCHISQ_RETURN_TYPE, x - mu, w, k, lam, sigma, max_iterations, min_accuracy). [docs]@typecheck(x=expr_float64, mu=expr_float64, sigma=expr_float64, lower_tail=expr_bool, log_p=expr_bool); def pnorm(x, mu=0, sigma=1, lower_tail=True, log_p=False) -> Float64Expression:; """"""The cumulative probability function of a normal distribution with mean; `mu` and standard deviation `sigma`. Returns cumulative probability of; standard normal distribution by default. Examples; --------. >>> hl.eval(hl.pnorm(0)); 0.5. >>> hl.eval(hl.pnorm(1, mu=2, sigma=2)); 0.30853753872598694. >>> hl.eval(hl.pnorm(2, lower_tail=False)); 0.022750131948179212. >>> hl.eval(hl.pnorm(2, log_p=True)); -0.023012909328963493. ",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:71508,Availability,error,error,71508,"min_accuracy : :obj:`int` or :class:`.Expression` of type :py:data:`.tint32`; The minimum accuracy of the returned value. If the minimum accuracy is not achieved, this; function will raise an error. The default minimum accuracy is ``1e-5``. Returns; -------; :class:`.StructExpression`; This method returns a structure with the value as well as information about the numerical; integration. - value : :class:`.Float64Expression`. If converged is true, the value of the CDF evaluated; at `x`. Otherwise, this is the last value the integration evaluated before aborting. - n_iterations : :class:`.Int32Expression`. The number of iterations before stopping. - converged : :class:`.BooleanExpression`. True if the `min_accuracy` was achieved and round; off error is not likely significant. - fault : :class:`.Int32Expression`. If converged is true, fault is zero. If converged is; false, fault is either one or two. One indicates that the requried accuracy was not; achieved. Two indicates the round-off error is possibly significant. """"""; if max_iterations is None:; max_iterations = hl.literal(10_000); if min_accuracy is None:; min_accuracy = hl.literal(1e-5); return _func(""pgenchisq"", PGENCHISQ_RETURN_TYPE, x - mu, w, k, lam, sigma, max_iterations, min_accuracy). [docs]@typecheck(x=expr_float64, mu=expr_float64, sigma=expr_float64, lower_tail=expr_bool, log_p=expr_bool); def pnorm(x, mu=0, sigma=1, lower_tail=True, log_p=False) -> Float64Expression:; """"""The cumulative probability function of a normal distribution with mean; `mu` and standard deviation `sigma`. Returns cumulative probability of; standard normal distribution by default. Examples; --------. >>> hl.eval(hl.pnorm(0)); 0.5. >>> hl.eval(hl.pnorm(1, mu=2, sigma=2)); 0.30853753872598694. >>> hl.eval(hl.pnorm(2, lower_tail=False)); 0.022750131948179212. >>> hl.eval(hl.pnorm(2, log_p=True)); -0.023012909328963493. Notes; -----; Returns the left-tail probability `p` = Prob(:math:`Z < x`) with :math:`Z`; a normal random variable. ",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:105023,Availability,down,downcode,105023,"k \}`, let :math:`p_i` be the probability that; a randomly chosen character is :math:`c_i`, e.g. the number of instances; of :math:`c_i` divided by :math:`n`. Then the base-2 Shannon entropy is; given by. .. math::. H = \sum_{i=1}^k p_i \log_2(p_i). Parameters; ----------; s : :class:`.StringExpression`. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`; """"""; return _func(""entropy"", tfloat64, s). @typecheck(x=expr_any, trunc=nullable(expr_int32)); def _showstr(x, trunc=None):; if trunc is None:; return _func(""showStr"", tstr, x); return _func(""showStr"", tstr, x, trunc). [docs]@typecheck(x=expr_any); def str(x) -> StringExpression:; """"""Returns the string representation of `x`. Examples; --------. >>> hl.eval(hl.str(hl.struct(a=5, b=7))); '{""a"":5,""b"":7}'. Parameters; ----------; x. Returns; -------; :class:`.StringExpression`; """"""; if x.dtype == tstr:; return x; else:; return _func(""str"", tstr, x). [docs]@typecheck(c=expr_call, i=expr_int32); def downcode(c, i) -> CallExpression:; """"""Create a new call by setting all alleles other than i to ref. Examples; --------; Preserve the third allele and downcode all other alleles to reference. >>> hl.eval(hl.downcode(hl.call(1, 2), 2)); Call(alleles=[0, 1], phased=False). >>> hl.eval(hl.downcode(hl.call(2, 2), 2)); Call(alleles=[1, 1], phased=False). >>> hl.eval(hl.downcode(hl.call(0, 1), 2)); Call(alleles=[0, 0], phased=False). Parameters; ----------; c : :class:`.CallExpression`; A call.; i : :class:`.Expression` of type :py:data:`.tint32`; The index of the allele that will be sent to the alternate allele. All; other alleles will be downcoded to reference. Returns; -------; :class:`.CallExpression`; """"""; return _func(""downcode"", tcall, c, i). @typecheck(pl=expr_array(expr_int32)); def gq_from_pl(pl) -> Int32Expression:; """"""Compute genotype quality from Phred-scaled probability likelihoods. Examples; --------. >>> hl.eval(hl.gq_from_pl([0, 69, 1035])); 69. Parameters; ----------; pl : :class:`.Expression` of ty",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:105173,Availability,down,downcode,105173,"; of :math:`c_i` divided by :math:`n`. Then the base-2 Shannon entropy is; given by. .. math::. H = \sum_{i=1}^k p_i \log_2(p_i). Parameters; ----------; s : :class:`.StringExpression`. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`; """"""; return _func(""entropy"", tfloat64, s). @typecheck(x=expr_any, trunc=nullable(expr_int32)); def _showstr(x, trunc=None):; if trunc is None:; return _func(""showStr"", tstr, x); return _func(""showStr"", tstr, x, trunc). [docs]@typecheck(x=expr_any); def str(x) -> StringExpression:; """"""Returns the string representation of `x`. Examples; --------. >>> hl.eval(hl.str(hl.struct(a=5, b=7))); '{""a"":5,""b"":7}'. Parameters; ----------; x. Returns; -------; :class:`.StringExpression`; """"""; if x.dtype == tstr:; return x; else:; return _func(""str"", tstr, x). [docs]@typecheck(c=expr_call, i=expr_int32); def downcode(c, i) -> CallExpression:; """"""Create a new call by setting all alleles other than i to ref. Examples; --------; Preserve the third allele and downcode all other alleles to reference. >>> hl.eval(hl.downcode(hl.call(1, 2), 2)); Call(alleles=[0, 1], phased=False). >>> hl.eval(hl.downcode(hl.call(2, 2), 2)); Call(alleles=[1, 1], phased=False). >>> hl.eval(hl.downcode(hl.call(0, 1), 2)); Call(alleles=[0, 0], phased=False). Parameters; ----------; c : :class:`.CallExpression`; A call.; i : :class:`.Expression` of type :py:data:`.tint32`; The index of the allele that will be sent to the alternate allele. All; other alleles will be downcoded to reference. Returns; -------; :class:`.CallExpression`; """"""; return _func(""downcode"", tcall, c, i). @typecheck(pl=expr_array(expr_int32)); def gq_from_pl(pl) -> Int32Expression:; """"""Compute genotype quality from Phred-scaled probability likelihoods. Examples; --------. >>> hl.eval(hl.gq_from_pl([0, 69, 1035])); 69. Parameters; ----------; pl : :class:`.Expression` of type :class:`.tarray` of :obj:`.tint32`. Returns; -------; :class:`.Expression` of type :py:data:`.tint32`; """"""; return _f",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:105229,Availability,down,downcode,105229,"py is; given by. .. math::. H = \sum_{i=1}^k p_i \log_2(p_i). Parameters; ----------; s : :class:`.StringExpression`. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`; """"""; return _func(""entropy"", tfloat64, s). @typecheck(x=expr_any, trunc=nullable(expr_int32)); def _showstr(x, trunc=None):; if trunc is None:; return _func(""showStr"", tstr, x); return _func(""showStr"", tstr, x, trunc). [docs]@typecheck(x=expr_any); def str(x) -> StringExpression:; """"""Returns the string representation of `x`. Examples; --------. >>> hl.eval(hl.str(hl.struct(a=5, b=7))); '{""a"":5,""b"":7}'. Parameters; ----------; x. Returns; -------; :class:`.StringExpression`; """"""; if x.dtype == tstr:; return x; else:; return _func(""str"", tstr, x). [docs]@typecheck(c=expr_call, i=expr_int32); def downcode(c, i) -> CallExpression:; """"""Create a new call by setting all alleles other than i to ref. Examples; --------; Preserve the third allele and downcode all other alleles to reference. >>> hl.eval(hl.downcode(hl.call(1, 2), 2)); Call(alleles=[0, 1], phased=False). >>> hl.eval(hl.downcode(hl.call(2, 2), 2)); Call(alleles=[1, 1], phased=False). >>> hl.eval(hl.downcode(hl.call(0, 1), 2)); Call(alleles=[0, 0], phased=False). Parameters; ----------; c : :class:`.CallExpression`; A call.; i : :class:`.Expression` of type :py:data:`.tint32`; The index of the allele that will be sent to the alternate allele. All; other alleles will be downcoded to reference. Returns; -------; :class:`.CallExpression`; """"""; return _func(""downcode"", tcall, c, i). @typecheck(pl=expr_array(expr_int32)); def gq_from_pl(pl) -> Int32Expression:; """"""Compute genotype quality from Phred-scaled probability likelihoods. Examples; --------. >>> hl.eval(hl.gq_from_pl([0, 69, 1035])); 69. Parameters; ----------; pl : :class:`.Expression` of type :class:`.tarray` of :obj:`.tint32`. Returns; -------; :class:`.Expression` of type :py:data:`.tint32`; """"""; return _func(""gqFromPL"", tint32, pl). [docs]@typecheck(n=expr_int32); def tr",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:105309,Availability,down,downcode,105309,"----; s : :class:`.StringExpression`. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`; """"""; return _func(""entropy"", tfloat64, s). @typecheck(x=expr_any, trunc=nullable(expr_int32)); def _showstr(x, trunc=None):; if trunc is None:; return _func(""showStr"", tstr, x); return _func(""showStr"", tstr, x, trunc). [docs]@typecheck(x=expr_any); def str(x) -> StringExpression:; """"""Returns the string representation of `x`. Examples; --------. >>> hl.eval(hl.str(hl.struct(a=5, b=7))); '{""a"":5,""b"":7}'. Parameters; ----------; x. Returns; -------; :class:`.StringExpression`; """"""; if x.dtype == tstr:; return x; else:; return _func(""str"", tstr, x). [docs]@typecheck(c=expr_call, i=expr_int32); def downcode(c, i) -> CallExpression:; """"""Create a new call by setting all alleles other than i to ref. Examples; --------; Preserve the third allele and downcode all other alleles to reference. >>> hl.eval(hl.downcode(hl.call(1, 2), 2)); Call(alleles=[0, 1], phased=False). >>> hl.eval(hl.downcode(hl.call(2, 2), 2)); Call(alleles=[1, 1], phased=False). >>> hl.eval(hl.downcode(hl.call(0, 1), 2)); Call(alleles=[0, 0], phased=False). Parameters; ----------; c : :class:`.CallExpression`; A call.; i : :class:`.Expression` of type :py:data:`.tint32`; The index of the allele that will be sent to the alternate allele. All; other alleles will be downcoded to reference. Returns; -------; :class:`.CallExpression`; """"""; return _func(""downcode"", tcall, c, i). @typecheck(pl=expr_array(expr_int32)); def gq_from_pl(pl) -> Int32Expression:; """"""Compute genotype quality from Phred-scaled probability likelihoods. Examples; --------. >>> hl.eval(hl.gq_from_pl([0, 69, 1035])); 69. Parameters; ----------; pl : :class:`.Expression` of type :class:`.tarray` of :obj:`.tint32`. Returns; -------; :class:`.Expression` of type :py:data:`.tint32`; """"""; return _func(""gqFromPL"", tint32, pl). [docs]@typecheck(n=expr_int32); def triangle(n) -> Int32Expression:; """"""Returns the triangle number of `n`. Examples; ",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:105389,Availability,down,downcode,105389,"type :py:data:`.tfloat64`; """"""; return _func(""entropy"", tfloat64, s). @typecheck(x=expr_any, trunc=nullable(expr_int32)); def _showstr(x, trunc=None):; if trunc is None:; return _func(""showStr"", tstr, x); return _func(""showStr"", tstr, x, trunc). [docs]@typecheck(x=expr_any); def str(x) -> StringExpression:; """"""Returns the string representation of `x`. Examples; --------. >>> hl.eval(hl.str(hl.struct(a=5, b=7))); '{""a"":5,""b"":7}'. Parameters; ----------; x. Returns; -------; :class:`.StringExpression`; """"""; if x.dtype == tstr:; return x; else:; return _func(""str"", tstr, x). [docs]@typecheck(c=expr_call, i=expr_int32); def downcode(c, i) -> CallExpression:; """"""Create a new call by setting all alleles other than i to ref. Examples; --------; Preserve the third allele and downcode all other alleles to reference. >>> hl.eval(hl.downcode(hl.call(1, 2), 2)); Call(alleles=[0, 1], phased=False). >>> hl.eval(hl.downcode(hl.call(2, 2), 2)); Call(alleles=[1, 1], phased=False). >>> hl.eval(hl.downcode(hl.call(0, 1), 2)); Call(alleles=[0, 0], phased=False). Parameters; ----------; c : :class:`.CallExpression`; A call.; i : :class:`.Expression` of type :py:data:`.tint32`; The index of the allele that will be sent to the alternate allele. All; other alleles will be downcoded to reference. Returns; -------; :class:`.CallExpression`; """"""; return _func(""downcode"", tcall, c, i). @typecheck(pl=expr_array(expr_int32)); def gq_from_pl(pl) -> Int32Expression:; """"""Compute genotype quality from Phred-scaled probability likelihoods. Examples; --------. >>> hl.eval(hl.gq_from_pl([0, 69, 1035])); 69. Parameters; ----------; pl : :class:`.Expression` of type :class:`.tarray` of :obj:`.tint32`. Returns; -------; :class:`.Expression` of type :py:data:`.tint32`; """"""; return _func(""gqFromPL"", tint32, pl). [docs]@typecheck(n=expr_int32); def triangle(n) -> Int32Expression:; """"""Returns the triangle number of `n`. Examples; --------. >>> hl.eval(hl.triangle(3)); 6. Notes; -----; The calculation is ``n *",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:105664,Availability,down,downcoded,105664,"xpr_any); def str(x) -> StringExpression:; """"""Returns the string representation of `x`. Examples; --------. >>> hl.eval(hl.str(hl.struct(a=5, b=7))); '{""a"":5,""b"":7}'. Parameters; ----------; x. Returns; -------; :class:`.StringExpression`; """"""; if x.dtype == tstr:; return x; else:; return _func(""str"", tstr, x). [docs]@typecheck(c=expr_call, i=expr_int32); def downcode(c, i) -> CallExpression:; """"""Create a new call by setting all alleles other than i to ref. Examples; --------; Preserve the third allele and downcode all other alleles to reference. >>> hl.eval(hl.downcode(hl.call(1, 2), 2)); Call(alleles=[0, 1], phased=False). >>> hl.eval(hl.downcode(hl.call(2, 2), 2)); Call(alleles=[1, 1], phased=False). >>> hl.eval(hl.downcode(hl.call(0, 1), 2)); Call(alleles=[0, 0], phased=False). Parameters; ----------; c : :class:`.CallExpression`; A call.; i : :class:`.Expression` of type :py:data:`.tint32`; The index of the allele that will be sent to the alternate allele. All; other alleles will be downcoded to reference. Returns; -------; :class:`.CallExpression`; """"""; return _func(""downcode"", tcall, c, i). @typecheck(pl=expr_array(expr_int32)); def gq_from_pl(pl) -> Int32Expression:; """"""Compute genotype quality from Phred-scaled probability likelihoods. Examples; --------. >>> hl.eval(hl.gq_from_pl([0, 69, 1035])); 69. Parameters; ----------; pl : :class:`.Expression` of type :class:`.tarray` of :obj:`.tint32`. Returns; -------; :class:`.Expression` of type :py:data:`.tint32`; """"""; return _func(""gqFromPL"", tint32, pl). [docs]@typecheck(n=expr_int32); def triangle(n) -> Int32Expression:; """"""Returns the triangle number of `n`. Examples; --------. >>> hl.eval(hl.triangle(3)); 6. Notes; -----; The calculation is ``n * (n + 1) / 2``. Parameters; ----------; n : :class:`.Expression` of type :py:data:`.tint32`. Returns; -------; :class:`.Expression` of type :py:data:`.tint32`; """"""; return _func(""triangle"", tint32, n). [docs]@typecheck(f=func_spec(1, expr_bool), collection=expr_oneof",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:105751,Availability,down,downcode,105751,"x`. Examples; --------. >>> hl.eval(hl.str(hl.struct(a=5, b=7))); '{""a"":5,""b"":7}'. Parameters; ----------; x. Returns; -------; :class:`.StringExpression`; """"""; if x.dtype == tstr:; return x; else:; return _func(""str"", tstr, x). [docs]@typecheck(c=expr_call, i=expr_int32); def downcode(c, i) -> CallExpression:; """"""Create a new call by setting all alleles other than i to ref. Examples; --------; Preserve the third allele and downcode all other alleles to reference. >>> hl.eval(hl.downcode(hl.call(1, 2), 2)); Call(alleles=[0, 1], phased=False). >>> hl.eval(hl.downcode(hl.call(2, 2), 2)); Call(alleles=[1, 1], phased=False). >>> hl.eval(hl.downcode(hl.call(0, 1), 2)); Call(alleles=[0, 0], phased=False). Parameters; ----------; c : :class:`.CallExpression`; A call.; i : :class:`.Expression` of type :py:data:`.tint32`; The index of the allele that will be sent to the alternate allele. All; other alleles will be downcoded to reference. Returns; -------; :class:`.CallExpression`; """"""; return _func(""downcode"", tcall, c, i). @typecheck(pl=expr_array(expr_int32)); def gq_from_pl(pl) -> Int32Expression:; """"""Compute genotype quality from Phred-scaled probability likelihoods. Examples; --------. >>> hl.eval(hl.gq_from_pl([0, 69, 1035])); 69. Parameters; ----------; pl : :class:`.Expression` of type :class:`.tarray` of :obj:`.tint32`. Returns; -------; :class:`.Expression` of type :py:data:`.tint32`; """"""; return _func(""gqFromPL"", tint32, pl). [docs]@typecheck(n=expr_int32); def triangle(n) -> Int32Expression:; """"""Returns the triangle number of `n`. Examples; --------. >>> hl.eval(hl.triangle(3)); 6. Notes; -----; The calculation is ``n * (n + 1) / 2``. Parameters; ----------; n : :class:`.Expression` of type :py:data:`.tint32`. Returns; -------; :class:`.Expression` of type :py:data:`.tint32`; """"""; return _func(""triangle"", tint32, n). [docs]@typecheck(f=func_spec(1, expr_bool), collection=expr_oneof(expr_set(), expr_array())); def filter(f: Callable, collection):; """"""Returns a new",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:145843,Availability,down,downstream,145843,"s.dtype.element_type); stream_req = stream_f(ctx_var); make_prod_ir = stream_req._ir; if isinstance(make_prod_ir.typ, hl.tarray):; make_prod_ir = ir.ToStream(make_prod_ir); t = stream_req.dtype.element_type. key_typ = hl.tstruct(**{k: t[k] for k in key}); vals_typ = hl.tarray(t). key_uid = Env.get_uid(); vals_uid = Env.get_uid(). key_var = construct_variable(key_uid, key_typ); vals_var = construct_variable(vals_uid, vals_typ). join_ir = join_f(key_var, vals_var); zj = ir.ToArray(ir.StreamZipJoinProducers(contexts._ir, ctx_uid, make_prod_ir, key, key_uid, vals_uid, join_ir._ir)); indices, aggs = unify_all(contexts, stream_req, join_ir); return construct_expr(zj, zj.typ, indices, aggs). [docs]@typecheck(arrays=expr_oneof(expr_stream(expr_any), expr_array(expr_any)), key=sequenceof(builtins.str)); def keyed_intersection(*arrays, key):; """"""Compute the intersection of sorted arrays on a given key. Requires sorted arrays with distinct keys. Warning; -------; Experimental. Does not support downstream randomness. Parameters; ----------; arrays; key. Returns; -------; :class:`.ArrayExpression`; """"""; return _union_intersection_base(; 'keyed_intersection',; arrays,; key,; lambda key_var, vals_var: hl.tuple((key_var, vals_var)),; lambda res: res.filter(lambda x: hl.fold(lambda acc, elt: acc & hl.is_defined(elt), True, x[1])).map(; lambda x: x[1].first(); ),; ). [docs]@typecheck(arrays=expr_oneof(expr_stream(expr_any), expr_array(expr_any)), key=sequenceof(builtins.str)); def keyed_union(*arrays, key):; """"""Compute the distinct union of sorted arrays on a given key. Requires sorted arrays with distinct keys. Warning; -------; Experimental. Does not support downstream randomness. Parameters; ----------; exprs; key. Returns; -------; :class:`.ArrayExpression`; """"""; return _union_intersection_base(; 'keyed_union',; arrays,; key,; lambda keys_var, vals_var: hl.fold(; lambda acc, elt: hl.coalesce(acc, elt), hl.missing(vals_var.dtype.element_type), vals_var; ),; lambda res: res,; ). [d",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:146516,Availability,down,downstream,146516,"typ, indices, aggs). [docs]@typecheck(arrays=expr_oneof(expr_stream(expr_any), expr_array(expr_any)), key=sequenceof(builtins.str)); def keyed_intersection(*arrays, key):; """"""Compute the intersection of sorted arrays on a given key. Requires sorted arrays with distinct keys. Warning; -------; Experimental. Does not support downstream randomness. Parameters; ----------; arrays; key. Returns; -------; :class:`.ArrayExpression`; """"""; return _union_intersection_base(; 'keyed_intersection',; arrays,; key,; lambda key_var, vals_var: hl.tuple((key_var, vals_var)),; lambda res: res.filter(lambda x: hl.fold(lambda acc, elt: acc & hl.is_defined(elt), True, x[1])).map(; lambda x: x[1].first(); ),; ). [docs]@typecheck(arrays=expr_oneof(expr_stream(expr_any), expr_array(expr_any)), key=sequenceof(builtins.str)); def keyed_union(*arrays, key):; """"""Compute the distinct union of sorted arrays on a given key. Requires sorted arrays with distinct keys. Warning; -------; Experimental. Does not support downstream randomness. Parameters; ----------; exprs; key. Returns; -------; :class:`.ArrayExpression`; """"""; return _union_intersection_base(; 'keyed_union',; arrays,; key,; lambda keys_var, vals_var: hl.fold(; lambda acc, elt: hl.coalesce(acc, elt), hl.missing(vals_var.dtype.element_type), vals_var; ),; lambda res: res,; ). [docs]@typecheck(collection=expr_oneof(expr_array(), expr_set()), delimiter=expr_str); def delimit(collection, delimiter=',') -> StringExpression:; """"""Joins elements of `collection` into single string delimited by `delimiter`. Examples; --------. >>> a = ['Bob', 'Charlie', 'Alice', 'Bob', 'Bob']. >>> hl.eval(hl.delimit(a)); 'Bob,Charlie,Alice,Bob,Bob'. Notes; -----; If the element type of `collection` is not :py:data:`.tstr`, then the; :func:`str` function will be called on each element before joining with; the delimiter. Parameters; ----------; collection : :class:`.ArrayExpression` or :class:`.SetExpression`; Collection.; delimiter : str or :class:`.StringExpressio",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:161407,Availability,avail,available,161407,"he locus ``'1:45323'``:. >>> hl.eval(hl.get_sequence('1', 45323, reference_genome='GRCh37')) # doctest: +SKIP; ""T"". Notes; -----; This function requires `reference genome` has an attached; reference sequence. Use :meth:`.ReferenceGenome.add_sequence` to; load and attach a reference sequence to a reference genome. Returns ``None`` if `contig` and `position` are not valid coordinates in; `reference_genome`. Parameters; ----------; contig : :class:`.Expression` of type :py:data:`.tstr`; Locus contig.; position : :class:`.Expression` of type :py:data:`.tint32`; Locus position.; before : :class:`.Expression` of type :py:data:`.tint32`, optional; Number of bases to include before the locus of interest. Truncates at; contig boundary.; after : :class:`.Expression` of type :py:data:`.tint32`, optional; Number of bases to include after the locus of interest. Truncates at; contig boundary.; reference_genome : :class:`str` or :class:`.ReferenceGenome`; Reference genome to use. Must have a reference sequence available. Returns; -------; :class:`.StringExpression`; """""". if not reference_genome.has_sequence():; raise TypeError(; ""Reference genome '{}' does not have a sequence loaded. Use 'add_sequence' to load the sequence from a FASTA file."".format(; reference_genome.name; ); ). return _func(""getReferenceSequence"", tstr, contig, position, before, after, type_args=(tlocus(reference_genome),)). [docs]@typecheck(contig=expr_str, reference_genome=reference_genome_type); def is_valid_contig(contig, reference_genome='default') -> BooleanExpression:; """"""Returns ``True`` if `contig` is a valid contig name in `reference_genome`. Examples; --------. >>> hl.eval(hl.is_valid_contig('1', reference_genome='GRCh37')); True. >>> hl.eval(hl.is_valid_contig('chr1', reference_genome='GRCh37')); False. Parameters; ----------; contig : :class:`.Expression` of type :py:data:`.tstr`; reference_genome : :class:`str` or :class:`.ReferenceGenome`. Returns; -------; :class:`.BooleanExpression`; """"""; return",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:164179,Availability,error,error,164179,"tion, reference_genome='default') -> BooleanExpression:; """"""Returns ``True`` if `contig` and `position` is a valid site in `reference_genome`. Examples; --------. >>> hl.eval(hl.is_valid_locus('1', 324254, 'GRCh37')); True. >>> hl.eval(hl.is_valid_locus('chr1', 324254, 'GRCh37')); False. Parameters; ----------; contig : :class:`.Expression` of type :py:data:`.tstr`; position : :class:`.Expression` of type :py:data:`.tint`; reference_genome : :class:`str` or :class:`.ReferenceGenome`. Returns; -------; :class:`.BooleanExpression`; """"""; return _func(""isValidLocus"", tbool, contig, position, type_args=(tlocus(reference_genome),)). [docs]@typecheck(locus=expr_locus(), is_female=expr_bool, father=expr_call, mother=expr_call, child=expr_call); def mendel_error_code(locus, is_female, father, mother, child):; r""""""Compute a Mendelian violation code for genotypes. >>> father = hl.call(0, 0); >>> mother = hl.call(1, 1); >>> child1 = hl.call(0, 1) # consistent; >>> child2 = hl.call(0, 0) # Mendel error; >>> locus = hl.locus('2', 2000000). >>> hl.eval(hl.mendel_error_code(locus, True, father, mother, child1)); None. >>> hl.eval(hl.mendel_error_code(locus, True, father, mother, child2)); 7. Note; ----; Ignores call phasing, and assumes diploid and biallelic. Haploid calls for; hemiploid samples on sex chromosomes also are acceptable input. Notes; -----; In the table below, the copy state of a locus with respect to a trio is; defined as follows, where PAR is the `pseudoautosomal region; <https://en.wikipedia.org/wiki/Pseudoautosomal_region>`__ (PAR) of X and Y; defined by the reference genome and the autosome is defined by; :meth:`.LocusExpression.in_autosome`:. - Auto -- in autosome or in PAR, or in non-PAR of X and female child; - HemiX -- in non-PAR of X and male child; - HemiY -- in non-PAR of Y and male child. `Any` refers to the set \{ HomRef, Het, HomVar, NoCall \} and `~`; denotes complement in this set. +------+---------+---------+--------+------------+---------------+; | ",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:172390,Availability,toler,tolerance,172390,"enome`.; """""". if not 0.0 <= min_match <= 1.0:; raise TypeError(""'liftover' requires 'min_match' is in the range [0, 1]. Got {}"".format(min_match)). if isinstance(x.dtype, tlocus):; rg = x.dtype.reference_genome; method_name = ""liftoverLocus""; rtype = tstruct(result=tlocus(dest_reference_genome), is_negative_strand=tbool); else:; rg = x.dtype.point_type.reference_genome; method_name = ""liftoverLocusInterval""; rtype = tstruct(result=tinterval(tlocus(dest_reference_genome)), is_negative_strand=tbool). if not rg.has_liftover(dest_reference_genome.name):; raise TypeError(; """"""Reference genome '{}' does not have liftover to '{}'.; Use 'add_liftover' to load a liftover chain file."""""".format(rg.name, dest_reference_genome.name); ). expr = _func(method_name, rtype, x, to_expr(min_match, tfloat64)); if not include_strand:; expr = expr.result; return expr. [docs]@typecheck(; f=func_spec(1, expr_float64),; min=expr_float64,; max=expr_float64,; max_iter=builtins.int,; epsilon=builtins.float,; tolerance=builtins.float,; ); def uniroot(f: Callable, min, max, *, max_iter=1000, epsilon=2.2204460492503131e-16, tolerance=1.220703e-4):; """"""Finds a root of the function `f` within the interval `[min, max]`. Examples; --------. >>> hl.eval(hl.uniroot(lambda x: x - 1, -5, 5)); 1.0. Notes; -----; `f(min)` and `f(max)` must not have the same sign. If no root can be found, the result of this call will be `NA` (missing). :func:`.uniroot` returns an estimate for a root with accuracy; `4 * epsilon * abs(x) + tolerance`. 4*EPSILON*abs(x) + tol. Parameters; ----------; f : function ( (arg) -> :class:`.Float64Expression`); Must return a :class:`.Float64Expression`.; min : :class:`.Float64Expression`; max : :class:`.Float64Expression`; max_iter : `int`; The maximum number of iterations before giving up.; epsilon : `float`; The scaling factor in the accuracy of the root found.; tolerance : `float`; The constant factor in approximate accuracy of the root found. Returns; -------; :class:`.Float64Express",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:172505,Availability,toler,tolerance,172505," range [0, 1]. Got {}"".format(min_match)). if isinstance(x.dtype, tlocus):; rg = x.dtype.reference_genome; method_name = ""liftoverLocus""; rtype = tstruct(result=tlocus(dest_reference_genome), is_negative_strand=tbool); else:; rg = x.dtype.point_type.reference_genome; method_name = ""liftoverLocusInterval""; rtype = tstruct(result=tinterval(tlocus(dest_reference_genome)), is_negative_strand=tbool). if not rg.has_liftover(dest_reference_genome.name):; raise TypeError(; """"""Reference genome '{}' does not have liftover to '{}'.; Use 'add_liftover' to load a liftover chain file."""""".format(rg.name, dest_reference_genome.name); ). expr = _func(method_name, rtype, x, to_expr(min_match, tfloat64)); if not include_strand:; expr = expr.result; return expr. [docs]@typecheck(; f=func_spec(1, expr_float64),; min=expr_float64,; max=expr_float64,; max_iter=builtins.int,; epsilon=builtins.float,; tolerance=builtins.float,; ); def uniroot(f: Callable, min, max, *, max_iter=1000, epsilon=2.2204460492503131e-16, tolerance=1.220703e-4):; """"""Finds a root of the function `f` within the interval `[min, max]`. Examples; --------. >>> hl.eval(hl.uniroot(lambda x: x - 1, -5, 5)); 1.0. Notes; -----; `f(min)` and `f(max)` must not have the same sign. If no root can be found, the result of this call will be `NA` (missing). :func:`.uniroot` returns an estimate for a root with accuracy; `4 * epsilon * abs(x) + tolerance`. 4*EPSILON*abs(x) + tol. Parameters; ----------; f : function ( (arg) -> :class:`.Float64Expression`); Must return a :class:`.Float64Expression`.; min : :class:`.Float64Expression`; max : :class:`.Float64Expression`; max_iter : `int`; The maximum number of iterations before giving up.; epsilon : `float`; The scaling factor in the accuracy of the root found.; tolerance : `float`; The constant factor in approximate accuracy of the root found. Returns; -------; :class:`.Float64Expression`; The root of the function `f`.; """""". # Based on:; # https://github.com/wch/r-source/blob/e5b21d0397",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:172899,Availability,toler,tolerance,172899,"ome)), is_negative_strand=tbool). if not rg.has_liftover(dest_reference_genome.name):; raise TypeError(; """"""Reference genome '{}' does not have liftover to '{}'.; Use 'add_liftover' to load a liftover chain file."""""".format(rg.name, dest_reference_genome.name); ). expr = _func(method_name, rtype, x, to_expr(min_match, tfloat64)); if not include_strand:; expr = expr.result; return expr. [docs]@typecheck(; f=func_spec(1, expr_float64),; min=expr_float64,; max=expr_float64,; max_iter=builtins.int,; epsilon=builtins.float,; tolerance=builtins.float,; ); def uniroot(f: Callable, min, max, *, max_iter=1000, epsilon=2.2204460492503131e-16, tolerance=1.220703e-4):; """"""Finds a root of the function `f` within the interval `[min, max]`. Examples; --------. >>> hl.eval(hl.uniroot(lambda x: x - 1, -5, 5)); 1.0. Notes; -----; `f(min)` and `f(max)` must not have the same sign. If no root can be found, the result of this call will be `NA` (missing). :func:`.uniroot` returns an estimate for a root with accuracy; `4 * epsilon * abs(x) + tolerance`. 4*EPSILON*abs(x) + tol. Parameters; ----------; f : function ( (arg) -> :class:`.Float64Expression`); Must return a :class:`.Float64Expression`.; min : :class:`.Float64Expression`; max : :class:`.Float64Expression`; max_iter : `int`; The maximum number of iterations before giving up.; epsilon : `float`; The scaling factor in the accuracy of the root found.; tolerance : `float`; The constant factor in approximate accuracy of the root found. Returns; -------; :class:`.Float64Expression`; The root of the function `f`.; """""". # Based on:; # https://github.com/wch/r-source/blob/e5b21d0397c607883ff25cca379687b86933d730/src/library/stats/src/zeroin.c. def error_if_missing(x):; res = f(x); return case().when(is_defined(res), res).or_error(format(""'uniroot': value of f(x) is missing for x = %.1e"", x)). wrapped_f = hl.experimental.define_function(error_if_missing, 'float'). def uniroot(recur, a, b, c, fa, fb, fc, prev, iterations_remaining):; tol = 2 ",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:173271,Availability,toler,tolerance,173271,"_float64,; max=expr_float64,; max_iter=builtins.int,; epsilon=builtins.float,; tolerance=builtins.float,; ); def uniroot(f: Callable, min, max, *, max_iter=1000, epsilon=2.2204460492503131e-16, tolerance=1.220703e-4):; """"""Finds a root of the function `f` within the interval `[min, max]`. Examples; --------. >>> hl.eval(hl.uniroot(lambda x: x - 1, -5, 5)); 1.0. Notes; -----; `f(min)` and `f(max)` must not have the same sign. If no root can be found, the result of this call will be `NA` (missing). :func:`.uniroot` returns an estimate for a root with accuracy; `4 * epsilon * abs(x) + tolerance`. 4*EPSILON*abs(x) + tol. Parameters; ----------; f : function ( (arg) -> :class:`.Float64Expression`); Must return a :class:`.Float64Expression`.; min : :class:`.Float64Expression`; max : :class:`.Float64Expression`; max_iter : `int`; The maximum number of iterations before giving up.; epsilon : `float`; The scaling factor in the accuracy of the root found.; tolerance : `float`; The constant factor in approximate accuracy of the root found. Returns; -------; :class:`.Float64Expression`; The root of the function `f`.; """""". # Based on:; # https://github.com/wch/r-source/blob/e5b21d0397c607883ff25cca379687b86933d730/src/library/stats/src/zeroin.c. def error_if_missing(x):; res = f(x); return case().when(is_defined(res), res).or_error(format(""'uniroot': value of f(x) is missing for x = %.1e"", x)). wrapped_f = hl.experimental.define_function(error_if_missing, 'float'). def uniroot(recur, a, b, c, fa, fb, fc, prev, iterations_remaining):; tol = 2 * epsilon * abs(b) + tolerance / 2; cb = c - b; t1 = fb / fc; t2 = fb / fa; q1 = fa / fc # = t1 / t2; pq = if_else(; a == c,; (cb * t1) / (t1 - 1.0), # linear; -t2 * (cb * q1 * (q1 - t1) - (b - a) * (t1 - 1.0)) / ((q1 - 1.0) * (t1 - 1.0) * (t2 - 1.0)),; ) # quadratic. interpolated = if_else(; (sign(pq) == sign(cb)); & (0.75 * abs(cb) > abs(pq) + tol / 2) # b + pq within [b, c]; & (abs(pq) < abs(prev / 2)), # pq not too large; pq,; cb / 2,; ). ",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:173886,Availability,toler,tolerance,173886," tolerance`. 4*EPSILON*abs(x) + tol. Parameters; ----------; f : function ( (arg) -> :class:`.Float64Expression`); Must return a :class:`.Float64Expression`.; min : :class:`.Float64Expression`; max : :class:`.Float64Expression`; max_iter : `int`; The maximum number of iterations before giving up.; epsilon : `float`; The scaling factor in the accuracy of the root found.; tolerance : `float`; The constant factor in approximate accuracy of the root found. Returns; -------; :class:`.Float64Expression`; The root of the function `f`.; """""". # Based on:; # https://github.com/wch/r-source/blob/e5b21d0397c607883ff25cca379687b86933d730/src/library/stats/src/zeroin.c. def error_if_missing(x):; res = f(x); return case().when(is_defined(res), res).or_error(format(""'uniroot': value of f(x) is missing for x = %.1e"", x)). wrapped_f = hl.experimental.define_function(error_if_missing, 'float'). def uniroot(recur, a, b, c, fa, fb, fc, prev, iterations_remaining):; tol = 2 * epsilon * abs(b) + tolerance / 2; cb = c - b; t1 = fb / fc; t2 = fb / fa; q1 = fa / fc # = t1 / t2; pq = if_else(; a == c,; (cb * t1) / (t1 - 1.0), # linear; -t2 * (cb * q1 * (q1 - t1) - (b - a) * (t1 - 1.0)) / ((q1 - 1.0) * (t1 - 1.0) * (t2 - 1.0)),; ) # quadratic. interpolated = if_else(; (sign(pq) == sign(cb)); & (0.75 * abs(cb) > abs(pq) + tol / 2) # b + pq within [b, c]; & (abs(pq) < abs(prev / 2)), # pq not too large; pq,; cb / 2,; ). new_step = if_else((abs(prev) >= tol) & (abs(fa) > abs(fb)), interpolated, cb / 2) # try interpolation. new_b = b + if_else(new_step < 0, hl.min(new_step, -tol), hl.max(new_step, tol)); new_fb = wrapped_f(new_b). return if_else(; iterations_remaining == 0,; missing('float'),; if_else(; abs(fc) < abs(fb),; recur(b, c, b, fb, fc, fb, prev, iterations_remaining),; if_else(; (abs(cb / 2) <= tol) | (fb == 0),; b, # acceptable approximation found; if_else(; sign(new_fb) == sign(fc), # use c = b for next iteration if signs match; recur(b, new_b, b, fb, new_fb, fb, new_step, iterations_re",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:176739,Availability,toler,tolerance,176739,"%.3e', 0.09345332)); '9.345e-02'. >>> hl.eval(hl.format('%.4f', hl.missing(hl.tfloat64))); 'null'. >>> hl.eval(hl.format('%s %s %s', 'hello', hl.tuple([3, hl.locus('1', 2453)]), True)); 'hello (3, 1:2453) true'. Notes; -----; See the `Java documentation <https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/util/Formatter.html#syntax>`__; for valid format specifiers and arguments. Missing values are printed as ``'null'`` except when using the; format flags `'b'` and `'B'` (printed as ``'false'`` instead). Parameters; ----------; f : :class:`.StringExpression`; Java `format string <https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/util/Formatter.html#syntax>`__.; args : variable-length arguments of :class:`.Expression`; Arguments to format. Returns; -------; :class:`.StringExpression`; """""". return _func(""format"", hl.tstr, f, hl.tuple(args)). [docs]@typecheck(x=expr_float64, y=expr_float64, tolerance=expr_float64, absolute=expr_bool, nan_same=expr_bool); def approx_equal(x, y, tolerance=1e-6, absolute=False, nan_same=False):; """"""Tests whether two numbers are approximately equal. Examples; --------; >>> hl.eval(hl.approx_equal(0.25, 0.2500001)); True. >>> hl.eval(hl.approx_equal(0.25, 0.251, tolerance=1e-3, absolute=True)); False. Parameters; ----------; x : :class:`.NumericExpression`; y : :class:`.NumericExpression`; tolerance : :class:`.NumericExpression`; absolute : :class:`.BooleanExpression`; If True, compute ``abs(x - y) <= tolerance``. Otherwise, compute; ``abs(x - y) <= max(tolerance * max(abs(x), abs(y)), 2 ** -1022)``.; nan_same : :class:`.BooleanExpression`; If True, then ``NaN == NaN`` will evaluate to True. Otherwise,; it will return False. Returns; -------; :class:`.BooleanExpression`; """""". return _func(""approxEqual"", hl.tbool, x, y, tolerance, absolute, nan_same). def _shift_op(x, y, op):; assert op in ('<<', '>>', '>>>'); t = x.dtype; if t == hl.tint64:; word_size = 64; zero = hl.int64(0); else:; word_size = 32; zero = hl.int",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:176827,Availability,toler,tolerance,176827,"%.3e', 0.09345332)); '9.345e-02'. >>> hl.eval(hl.format('%.4f', hl.missing(hl.tfloat64))); 'null'. >>> hl.eval(hl.format('%s %s %s', 'hello', hl.tuple([3, hl.locus('1', 2453)]), True)); 'hello (3, 1:2453) true'. Notes; -----; See the `Java documentation <https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/util/Formatter.html#syntax>`__; for valid format specifiers and arguments. Missing values are printed as ``'null'`` except when using the; format flags `'b'` and `'B'` (printed as ``'false'`` instead). Parameters; ----------; f : :class:`.StringExpression`; Java `format string <https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/util/Formatter.html#syntax>`__.; args : variable-length arguments of :class:`.Expression`; Arguments to format. Returns; -------; :class:`.StringExpression`; """""". return _func(""format"", hl.tstr, f, hl.tuple(args)). [docs]@typecheck(x=expr_float64, y=expr_float64, tolerance=expr_float64, absolute=expr_bool, nan_same=expr_bool); def approx_equal(x, y, tolerance=1e-6, absolute=False, nan_same=False):; """"""Tests whether two numbers are approximately equal. Examples; --------; >>> hl.eval(hl.approx_equal(0.25, 0.2500001)); True. >>> hl.eval(hl.approx_equal(0.25, 0.251, tolerance=1e-3, absolute=True)); False. Parameters; ----------; x : :class:`.NumericExpression`; y : :class:`.NumericExpression`; tolerance : :class:`.NumericExpression`; absolute : :class:`.BooleanExpression`; If True, compute ``abs(x - y) <= tolerance``. Otherwise, compute; ``abs(x - y) <= max(tolerance * max(abs(x), abs(y)), 2 ** -1022)``.; nan_same : :class:`.BooleanExpression`; If True, then ``NaN == NaN`` will evaluate to True. Otherwise,; it will return False. Returns; -------; :class:`.BooleanExpression`; """""". return _func(""approxEqual"", hl.tbool, x, y, tolerance, absolute, nan_same). def _shift_op(x, y, op):; assert op in ('<<', '>>', '>>>'); t = x.dtype; if t == hl.tint64:; word_size = 64; zero = hl.int64(0); else:; word_size = 32; zero = hl.int",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:177045,Availability,toler,tolerance,177045," <https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/util/Formatter.html#syntax>`__; for valid format specifiers and arguments. Missing values are printed as ``'null'`` except when using the; format flags `'b'` and `'B'` (printed as ``'false'`` instead). Parameters; ----------; f : :class:`.StringExpression`; Java `format string <https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/util/Formatter.html#syntax>`__.; args : variable-length arguments of :class:`.Expression`; Arguments to format. Returns; -------; :class:`.StringExpression`; """""". return _func(""format"", hl.tstr, f, hl.tuple(args)). [docs]@typecheck(x=expr_float64, y=expr_float64, tolerance=expr_float64, absolute=expr_bool, nan_same=expr_bool); def approx_equal(x, y, tolerance=1e-6, absolute=False, nan_same=False):; """"""Tests whether two numbers are approximately equal. Examples; --------; >>> hl.eval(hl.approx_equal(0.25, 0.2500001)); True. >>> hl.eval(hl.approx_equal(0.25, 0.251, tolerance=1e-3, absolute=True)); False. Parameters; ----------; x : :class:`.NumericExpression`; y : :class:`.NumericExpression`; tolerance : :class:`.NumericExpression`; absolute : :class:`.BooleanExpression`; If True, compute ``abs(x - y) <= tolerance``. Otherwise, compute; ``abs(x - y) <= max(tolerance * max(abs(x), abs(y)), 2 ** -1022)``.; nan_same : :class:`.BooleanExpression`; If True, then ``NaN == NaN`` will evaluate to True. Otherwise,; it will return False. Returns; -------; :class:`.BooleanExpression`; """""". return _func(""approxEqual"", hl.tbool, x, y, tolerance, absolute, nan_same). def _shift_op(x, y, op):; assert op in ('<<', '>>', '>>>'); t = x.dtype; if t == hl.tint64:; word_size = 64; zero = hl.int64(0); else:; word_size = 32; zero = hl.int32(0). indices, aggregations = unify_all(x, y); return hl.bind(; lambda x, y: (; hl.case(); .when(y >= word_size, hl.sign(x) if op == '>>' else zero); .when(y >= 0, construct_expr(ir.ApplyBinaryPrimOp(op, x._ir, y._ir), t, indices, aggregations)); .or_",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:177175,Availability,toler,tolerance,177175,"mat specifiers and arguments. Missing values are printed as ``'null'`` except when using the; format flags `'b'` and `'B'` (printed as ``'false'`` instead). Parameters; ----------; f : :class:`.StringExpression`; Java `format string <https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/util/Formatter.html#syntax>`__.; args : variable-length arguments of :class:`.Expression`; Arguments to format. Returns; -------; :class:`.StringExpression`; """""". return _func(""format"", hl.tstr, f, hl.tuple(args)). [docs]@typecheck(x=expr_float64, y=expr_float64, tolerance=expr_float64, absolute=expr_bool, nan_same=expr_bool); def approx_equal(x, y, tolerance=1e-6, absolute=False, nan_same=False):; """"""Tests whether two numbers are approximately equal. Examples; --------; >>> hl.eval(hl.approx_equal(0.25, 0.2500001)); True. >>> hl.eval(hl.approx_equal(0.25, 0.251, tolerance=1e-3, absolute=True)); False. Parameters; ----------; x : :class:`.NumericExpression`; y : :class:`.NumericExpression`; tolerance : :class:`.NumericExpression`; absolute : :class:`.BooleanExpression`; If True, compute ``abs(x - y) <= tolerance``. Otherwise, compute; ``abs(x - y) <= max(tolerance * max(abs(x), abs(y)), 2 ** -1022)``.; nan_same : :class:`.BooleanExpression`; If True, then ``NaN == NaN`` will evaluate to True. Otherwise,; it will return False. Returns; -------; :class:`.BooleanExpression`; """""". return _func(""approxEqual"", hl.tbool, x, y, tolerance, absolute, nan_same). def _shift_op(x, y, op):; assert op in ('<<', '>>', '>>>'); t = x.dtype; if t == hl.tint64:; word_size = 64; zero = hl.int64(0); else:; word_size = 32; zero = hl.int32(0). indices, aggregations = unify_all(x, y); return hl.bind(; lambda x, y: (; hl.case(); .when(y >= word_size, hl.sign(x) if op == '>>' else zero); .when(y >= 0, construct_expr(ir.ApplyBinaryPrimOp(op, x._ir, y._ir), t, indices, aggregations)); .or_error('cannot shift by a negative value: ' + hl.str(x) + f"" {op} "" + hl.str(y)); ),; x,; y,; ). def _bit_op(x, y, ",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:177289,Availability,toler,tolerance,177289," format flags `'b'` and `'B'` (printed as ``'false'`` instead). Parameters; ----------; f : :class:`.StringExpression`; Java `format string <https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/util/Formatter.html#syntax>`__.; args : variable-length arguments of :class:`.Expression`; Arguments to format. Returns; -------; :class:`.StringExpression`; """""". return _func(""format"", hl.tstr, f, hl.tuple(args)). [docs]@typecheck(x=expr_float64, y=expr_float64, tolerance=expr_float64, absolute=expr_bool, nan_same=expr_bool); def approx_equal(x, y, tolerance=1e-6, absolute=False, nan_same=False):; """"""Tests whether two numbers are approximately equal. Examples; --------; >>> hl.eval(hl.approx_equal(0.25, 0.2500001)); True. >>> hl.eval(hl.approx_equal(0.25, 0.251, tolerance=1e-3, absolute=True)); False. Parameters; ----------; x : :class:`.NumericExpression`; y : :class:`.NumericExpression`; tolerance : :class:`.NumericExpression`; absolute : :class:`.BooleanExpression`; If True, compute ``abs(x - y) <= tolerance``. Otherwise, compute; ``abs(x - y) <= max(tolerance * max(abs(x), abs(y)), 2 ** -1022)``.; nan_same : :class:`.BooleanExpression`; If True, then ``NaN == NaN`` will evaluate to True. Otherwise,; it will return False. Returns; -------; :class:`.BooleanExpression`; """""". return _func(""approxEqual"", hl.tbool, x, y, tolerance, absolute, nan_same). def _shift_op(x, y, op):; assert op in ('<<', '>>', '>>>'); t = x.dtype; if t == hl.tint64:; word_size = 64; zero = hl.int64(0); else:; word_size = 32; zero = hl.int32(0). indices, aggregations = unify_all(x, y); return hl.bind(; lambda x, y: (; hl.case(); .when(y >= word_size, hl.sign(x) if op == '>>' else zero); .when(y >= 0, construct_expr(ir.ApplyBinaryPrimOp(op, x._ir, y._ir), t, indices, aggregations)); .or_error('cannot shift by a negative value: ' + hl.str(x) + f"" {op} "" + hl.str(y)); ),; x,; y,; ). def _bit_op(x, y, op):; if x.dtype == hl.tint32 and y.dtype == hl.tint32:; t = hl.tint32; else:; t = hl.tint64;",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:177342,Availability,toler,tolerance,177342,"---------; f : :class:`.StringExpression`; Java `format string <https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/util/Formatter.html#syntax>`__.; args : variable-length arguments of :class:`.Expression`; Arguments to format. Returns; -------; :class:`.StringExpression`; """""". return _func(""format"", hl.tstr, f, hl.tuple(args)). [docs]@typecheck(x=expr_float64, y=expr_float64, tolerance=expr_float64, absolute=expr_bool, nan_same=expr_bool); def approx_equal(x, y, tolerance=1e-6, absolute=False, nan_same=False):; """"""Tests whether two numbers are approximately equal. Examples; --------; >>> hl.eval(hl.approx_equal(0.25, 0.2500001)); True. >>> hl.eval(hl.approx_equal(0.25, 0.251, tolerance=1e-3, absolute=True)); False. Parameters; ----------; x : :class:`.NumericExpression`; y : :class:`.NumericExpression`; tolerance : :class:`.NumericExpression`; absolute : :class:`.BooleanExpression`; If True, compute ``abs(x - y) <= tolerance``. Otherwise, compute; ``abs(x - y) <= max(tolerance * max(abs(x), abs(y)), 2 ** -1022)``.; nan_same : :class:`.BooleanExpression`; If True, then ``NaN == NaN`` will evaluate to True. Otherwise,; it will return False. Returns; -------; :class:`.BooleanExpression`; """""". return _func(""approxEqual"", hl.tbool, x, y, tolerance, absolute, nan_same). def _shift_op(x, y, op):; assert op in ('<<', '>>', '>>>'); t = x.dtype; if t == hl.tint64:; word_size = 64; zero = hl.int64(0); else:; word_size = 32; zero = hl.int32(0). indices, aggregations = unify_all(x, y); return hl.bind(; lambda x, y: (; hl.case(); .when(y >= word_size, hl.sign(x) if op == '>>' else zero); .when(y >= 0, construct_expr(ir.ApplyBinaryPrimOp(op, x._ir, y._ir), t, indices, aggregations)); .or_error('cannot shift by a negative value: ' + hl.str(x) + f"" {op} "" + hl.str(y)); ),; x,; y,; ). def _bit_op(x, y, op):; if x.dtype == hl.tint32 and y.dtype == hl.tint32:; t = hl.tint32; else:; t = hl.tint64; coercer = coercer_from_dtype(t); x = coercer.coerce(x); y = coercer.coerce(",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:177613,Availability,toler,tolerance,177613,"pression`; """""". return _func(""format"", hl.tstr, f, hl.tuple(args)). [docs]@typecheck(x=expr_float64, y=expr_float64, tolerance=expr_float64, absolute=expr_bool, nan_same=expr_bool); def approx_equal(x, y, tolerance=1e-6, absolute=False, nan_same=False):; """"""Tests whether two numbers are approximately equal. Examples; --------; >>> hl.eval(hl.approx_equal(0.25, 0.2500001)); True. >>> hl.eval(hl.approx_equal(0.25, 0.251, tolerance=1e-3, absolute=True)); False. Parameters; ----------; x : :class:`.NumericExpression`; y : :class:`.NumericExpression`; tolerance : :class:`.NumericExpression`; absolute : :class:`.BooleanExpression`; If True, compute ``abs(x - y) <= tolerance``. Otherwise, compute; ``abs(x - y) <= max(tolerance * max(abs(x), abs(y)), 2 ** -1022)``.; nan_same : :class:`.BooleanExpression`; If True, then ``NaN == NaN`` will evaluate to True. Otherwise,; it will return False. Returns; -------; :class:`.BooleanExpression`; """""". return _func(""approxEqual"", hl.tbool, x, y, tolerance, absolute, nan_same). def _shift_op(x, y, op):; assert op in ('<<', '>>', '>>>'); t = x.dtype; if t == hl.tint64:; word_size = 64; zero = hl.int64(0); else:; word_size = 32; zero = hl.int32(0). indices, aggregations = unify_all(x, y); return hl.bind(; lambda x, y: (; hl.case(); .when(y >= word_size, hl.sign(x) if op == '>>' else zero); .when(y >= 0, construct_expr(ir.ApplyBinaryPrimOp(op, x._ir, y._ir), t, indices, aggregations)); .or_error('cannot shift by a negative value: ' + hl.str(x) + f"" {op} "" + hl.str(y)); ),; x,; y,; ). def _bit_op(x, y, op):; if x.dtype == hl.tint32 and y.dtype == hl.tint32:; t = hl.tint32; else:; t = hl.tint64; coercer = coercer_from_dtype(t); x = coercer.coerce(x); y = coercer.coerce(y). indices, aggregations = unify_all(x, y); return construct_expr(ir.ApplyBinaryPrimOp(op, x._ir, y._ir), t, indices, aggregations). [docs]@typecheck(x=expr_oneof(expr_int32, expr_int64), y=expr_oneof(expr_int32, expr_int64)); def bit_and(x, y):; """"""Bitwise and `x` and `y`. E",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:184844,Availability,toler,tolerance,184844,"lement in `array` not smaller; than `elem`. This is a value between 0 and the length of `array`, inclusive; (if all elements in `array` are smaller than `elem`, the returned value is; the length of `array` or the index of the first missing value, if one; exists). If either `elem` or `array` is missing, the result is missing. Examples; --------. >>> a = hl.array([0, 2, 4, 8]). >>> hl.eval(hl.binary_search(a, -1)); 0. >>> hl.eval(hl.binary_search(a, 1)); 1. >>> hl.eval(hl.binary_search(a, 10)); 4. """"""; c = coercer_from_dtype(array.dtype.element_type); if not c.can_coerce(elem.dtype):; raise TypeError(; f""'binary_search': cannot search an array of type {array.dtype} for a value of type {elem.dtype}""; ); elem = c.coerce(elem); return hl.switch(elem).when_missing(hl.missing(hl.tint32)).default(_lower_bound(array, elem)). @typecheck(s=expr_str); def _escape_string(s):; return _func(""escapeString"", hl.tstr, s). @typecheck(left=expr_any, right=expr_any, tolerance=expr_float64, absolute=expr_bool); def _values_similar(left, right, tolerance=1e-6, absolute=False):; assert left.dtype == right.dtype; return (is_missing(left) & is_missing(right)) | (; (is_defined(left) & is_defined(right)) & _func(""valuesSimilar"", hl.tbool, left, right, tolerance, absolute); ). @typecheck(coords=expr_array(expr_array(expr_float64)), radius=expr_float64); def _locus_windows_per_contig(coords, radius):; rt = hl.ttuple(hl.tarray(hl.tint32), hl.tarray(hl.tint32)); return _func(""locus_windows_per_contig"", rt, coords, radius). [docs]@typecheck(a=expr_array(), seed=nullable(builtins.int)); def shuffle(a, seed: Optional[builtins.int] = None) -> ArrayExpression:; """"""Randomly permute an array. Example; -------. >>> hl.reset_global_randomness(); >>> hl.eval(hl.shuffle(hl.range(5))); [4, 0, 2, 1, 3]. Parameters; ----------; a : :class:`.ArrayExpression`; Array to permute.; seed : :obj:`int`, optional; Random seed. Returns; -------; :class:`.ArrayExpression`; """"""; return sorted(a, key=lambda _: hl.rand_unif(0",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:184922,Availability,toler,tolerance,184922,"lement in `array` not smaller; than `elem`. This is a value between 0 and the length of `array`, inclusive; (if all elements in `array` are smaller than `elem`, the returned value is; the length of `array` or the index of the first missing value, if one; exists). If either `elem` or `array` is missing, the result is missing. Examples; --------. >>> a = hl.array([0, 2, 4, 8]). >>> hl.eval(hl.binary_search(a, -1)); 0. >>> hl.eval(hl.binary_search(a, 1)); 1. >>> hl.eval(hl.binary_search(a, 10)); 4. """"""; c = coercer_from_dtype(array.dtype.element_type); if not c.can_coerce(elem.dtype):; raise TypeError(; f""'binary_search': cannot search an array of type {array.dtype} for a value of type {elem.dtype}""; ); elem = c.coerce(elem); return hl.switch(elem).when_missing(hl.missing(hl.tint32)).default(_lower_bound(array, elem)). @typecheck(s=expr_str); def _escape_string(s):; return _func(""escapeString"", hl.tstr, s). @typecheck(left=expr_any, right=expr_any, tolerance=expr_float64, absolute=expr_bool); def _values_similar(left, right, tolerance=1e-6, absolute=False):; assert left.dtype == right.dtype; return (is_missing(left) & is_missing(right)) | (; (is_defined(left) & is_defined(right)) & _func(""valuesSimilar"", hl.tbool, left, right, tolerance, absolute); ). @typecheck(coords=expr_array(expr_array(expr_float64)), radius=expr_float64); def _locus_windows_per_contig(coords, radius):; rt = hl.ttuple(hl.tarray(hl.tint32), hl.tarray(hl.tint32)); return _func(""locus_windows_per_contig"", rt, coords, radius). [docs]@typecheck(a=expr_array(), seed=nullable(builtins.int)); def shuffle(a, seed: Optional[builtins.int] = None) -> ArrayExpression:; """"""Randomly permute an array. Example; -------. >>> hl.reset_global_randomness(); >>> hl.eval(hl.shuffle(hl.range(5))); [4, 0, 2, 1, 3]. Parameters; ----------; a : :class:`.ArrayExpression`; Array to permute.; seed : :obj:`int`, optional; Random seed. Returns; -------; :class:`.ArrayExpression`; """"""; return sorted(a, key=lambda _: hl.rand_unif(0",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:185128,Availability,toler,tolerance,185128," if one; exists). If either `elem` or `array` is missing, the result is missing. Examples; --------. >>> a = hl.array([0, 2, 4, 8]). >>> hl.eval(hl.binary_search(a, -1)); 0. >>> hl.eval(hl.binary_search(a, 1)); 1. >>> hl.eval(hl.binary_search(a, 10)); 4. """"""; c = coercer_from_dtype(array.dtype.element_type); if not c.can_coerce(elem.dtype):; raise TypeError(; f""'binary_search': cannot search an array of type {array.dtype} for a value of type {elem.dtype}""; ); elem = c.coerce(elem); return hl.switch(elem).when_missing(hl.missing(hl.tint32)).default(_lower_bound(array, elem)). @typecheck(s=expr_str); def _escape_string(s):; return _func(""escapeString"", hl.tstr, s). @typecheck(left=expr_any, right=expr_any, tolerance=expr_float64, absolute=expr_bool); def _values_similar(left, right, tolerance=1e-6, absolute=False):; assert left.dtype == right.dtype; return (is_missing(left) & is_missing(right)) | (; (is_defined(left) & is_defined(right)) & _func(""valuesSimilar"", hl.tbool, left, right, tolerance, absolute); ). @typecheck(coords=expr_array(expr_array(expr_float64)), radius=expr_float64); def _locus_windows_per_contig(coords, radius):; rt = hl.ttuple(hl.tarray(hl.tint32), hl.tarray(hl.tint32)); return _func(""locus_windows_per_contig"", rt, coords, radius). [docs]@typecheck(a=expr_array(), seed=nullable(builtins.int)); def shuffle(a, seed: Optional[builtins.int] = None) -> ArrayExpression:; """"""Randomly permute an array. Example; -------. >>> hl.reset_global_randomness(); >>> hl.eval(hl.shuffle(hl.range(5))); [4, 0, 2, 1, 3]. Parameters; ----------; a : :class:`.ArrayExpression`; Array to permute.; seed : :obj:`int`, optional; Random seed. Returns; -------; :class:`.ArrayExpression`; """"""; return sorted(a, key=lambda _: hl.rand_unif(0.0, 1.0)). [docs]@typecheck(path=builtins.str, point_or_interval=expr_any); def query_table(path, point_or_interval):; """"""Query records from a table corresponding to a given point or range of keys. Notes; -----; This function does not dispatch t",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:62490,Deployability,release,release,62490,"ing two heads; out of ten flips:. >>> hl.eval(hl.binom_test(2, 10, 0.5, 'two-sided')); 0.10937499999999994. Test if a coin is biased towards tails after observing four heads out of ten; flips:. >>> hl.eval(hl.binom_test(4, 10, 0.5, 'less')); 0.3769531250000001. Test if a coin is biased towards heads after observing thirty-two heads out; of fifty flips:. >>> hl.eval(hl.binom_test(32, 50, 0.5, 'greater')); 0.03245432353613613. Parameters; ----------; x : int or :class:`.Expression` of type :py:data:`.tint32`; Number of successes.; n : int or :class:`.Expression` of type :py:data:`.tint32`; Number of trials.; p : float or :class:`.Expression` of type :py:data:`.tfloat64`; Probability of success, between 0 and 1.; alternative; : One of, ""two-sided"", ""greater"", ""less"", (deprecated: ""two.sided""). Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`; p-value.; """""". if alternative == 'two.sided':; warning(; '""two.sided"" is a deprecated and will be removed in a future '; 'release, please use ""two-sided"" for the `alternative` parameter '; 'to hl.binom_test'; ); alternative = 'two-sided'. alt_enum = {""two-sided"": 0, ""less"": 1, ""greater"": 2}[alternative]; return _func(""binomTest"", tfloat64, x, n, p, to_expr(alt_enum)). [docs]@typecheck(x=expr_float64, df=expr_float64, ncp=nullable(expr_float64), lower_tail=expr_bool, log_p=expr_bool); def pchisqtail(x, df, ncp=None, lower_tail=False, log_p=False) -> Float64Expression:; """"""Returns the probability under the right-tail starting at x for a chi-squared; distribution with df degrees of freedom. Examples; --------. >>> hl.eval(hl.pchisqtail(5, 1)); 0.025347318677468304. >>> hl.eval(hl.pchisqtail(5, 1, ncp=2)); 0.20571085634347097. >>> hl.eval(hl.pchisqtail(5, 1, lower_tail=True)); 0.9746526813225317. >>> hl.eval(hl.pchisqtail(5, 1, log_p=True)); -3.6750823266311876. Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64`; The value at which to evaluate the CDF.; df : float or :class:`.Expre",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:68494,Deployability,release,released,68494,"a=0).value); 1.0. >>> hl.eval(hl.pgenchisq(-80, w=[1, -10, 2], k=[1, 2, 3], lam=[2, 3, 7], mu=-10, sigma=0).value); 0.14284718767288906; >>> hl.eval(hl.pgenchisq(-20, w=[1, -10, 2], k=[1, 2, 3], lam=[2, 3, 7], mu=-10, sigma=0).value); 0.5950150356303258; >>> hl.eval(hl.pgenchisq(10 , w=[1, -10, 2], k=[1, 2, 3], lam=[2, 3, 7], mu=-10, sigma=0).value); 0.923219534175858; >>> hl.eval(hl.pgenchisq(40 , w=[1, -10, 2], k=[1, 2, 3], lam=[2, 3, 7], mu=-10, sigma=0).value); 0.9971746768781656. Notes; -----. We follow Wikipedia's notational conventions. Some texts refer to the weight vector (our `w`) as; :math:`\lambda` or `lb` and the non-centrality vector (our `lam`) as `nc`. We use the Davies' algorithm which was published as:. `Davies, Robert. ""The distribution of a linear combination of chi-squared random variables.""; Applied Statistics 29 323-333. 1980. <http://www.robertnz.net/pdf/lc_chisq.pdf>`__. Davies included Fortran source code in the original publication. Davies also released a `C; language port <http://www.robertnz.net/QF.htm>`__. Hail's implementation is a fairly direct port; of the C implementation to Scala. Davies provides 39 test cases with the source code. The Hail; tests include all 39 test cases as well as a few additional tests. Davies' website cautions:. The method works well in most situations if you want only modest accuracy, say 0.0001. But; problems may arise if the sum is dominated by one or two terms with a total of only one or; two degrees of freedom and x is small. For an accessible introduction the Generalized Chi-Squared Distribution, we strongly recommend; the introduction of this paper:. `Das, Abhranil; Geisler, Wilson (2020). ""A method to integrate and classify normal; distributions"". <https://arxiv.org/abs/2012.14331>`__. Parameters; ----------; x : :obj:`float` or :class:`.Expression` of type :py:data:`.tfloat64`; The value at which to evaluate the cumulative distribution function (CDF).; w : :obj:`list` of :obj:`float` or :class:`.Expre",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:69202,Deployability,integrat,integrate,69202,"h was published as:. `Davies, Robert. ""The distribution of a linear combination of chi-squared random variables.""; Applied Statistics 29 323-333. 1980. <http://www.robertnz.net/pdf/lc_chisq.pdf>`__. Davies included Fortran source code in the original publication. Davies also released a `C; language port <http://www.robertnz.net/QF.htm>`__. Hail's implementation is a fairly direct port; of the C implementation to Scala. Davies provides 39 test cases with the source code. The Hail; tests include all 39 test cases as well as a few additional tests. Davies' website cautions:. The method works well in most situations if you want only modest accuracy, say 0.0001. But; problems may arise if the sum is dominated by one or two terms with a total of only one or; two degrees of freedom and x is small. For an accessible introduction the Generalized Chi-Squared Distribution, we strongly recommend; the introduction of this paper:. `Das, Abhranil; Geisler, Wilson (2020). ""A method to integrate and classify normal; distributions"". <https://arxiv.org/abs/2012.14331>`__. Parameters; ----------; x : :obj:`float` or :class:`.Expression` of type :py:data:`.tfloat64`; The value at which to evaluate the cumulative distribution function (CDF).; w : :obj:`list` of :obj:`float` or :class:`.Expression` of type :py:class:`.tarray` of :py:data:`.tfloat64`; A weight for each non-central chi-square term.; k : :obj:`list` of :obj:`int` or :class:`.Expression` of type :py:class:`.tarray` of :py:data:`.tint32`; A degrees of freedom parameter for each non-central chi-square term.; lam : :obj:`list` of :obj:`float` or :class:`.Expression` of type :py:class:`.tarray` of :py:data:`.tfloat64`; A non-centrality parameter for each non-central chi-square term. We use `lam` instead; of `lambda` because the latter is a reserved word in Python.; mu : :obj:`float` or :class:`.Expression` of type :py:data:`.tfloat64`; The standard deviation of the normal term.; sigma : :obj:`float` or :class:`.Expression` of typ",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:70416,Deployability,integrat,integration,70416," evaluate the cumulative distribution function (CDF).; w : :obj:`list` of :obj:`float` or :class:`.Expression` of type :py:class:`.tarray` of :py:data:`.tfloat64`; A weight for each non-central chi-square term.; k : :obj:`list` of :obj:`int` or :class:`.Expression` of type :py:class:`.tarray` of :py:data:`.tint32`; A degrees of freedom parameter for each non-central chi-square term.; lam : :obj:`list` of :obj:`float` or :class:`.Expression` of type :py:class:`.tarray` of :py:data:`.tfloat64`; A non-centrality parameter for each non-central chi-square term. We use `lam` instead; of `lambda` because the latter is a reserved word in Python.; mu : :obj:`float` or :class:`.Expression` of type :py:data:`.tfloat64`; The standard deviation of the normal term.; sigma : :obj:`float` or :class:`.Expression` of type :py:data:`.tfloat64`; The standard deviation of the normal term.; max_iterations : :obj:`int` or :class:`.Expression` of type :py:data:`.tint32`; The maximum number of iterations of the numerical integration before raising an error. The; default maximum number of iterations is ``1e5``.; min_accuracy : :obj:`int` or :class:`.Expression` of type :py:data:`.tint32`; The minimum accuracy of the returned value. If the minimum accuracy is not achieved, this; function will raise an error. The default minimum accuracy is ``1e-5``. Returns; -------; :class:`.StructExpression`; This method returns a structure with the value as well as information about the numerical; integration. - value : :class:`.Float64Expression`. If converged is true, the value of the CDF evaluated; at `x`. Otherwise, this is the last value the integration evaluated before aborting. - n_iterations : :class:`.Int32Expression`. The number of iterations before stopping. - converged : :class:`.BooleanExpression`. True if the `min_accuracy` was achieved and round; off error is not likely significant. - fault : :class:`.Int32Expression`. If converged is true, fault is zero. If converged is; false, fault is eith",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:70886,Deployability,integrat,integration,70886,"Expression` of type :py:class:`.tarray` of :py:data:`.tfloat64`; A non-centrality parameter for each non-central chi-square term. We use `lam` instead; of `lambda` because the latter is a reserved word in Python.; mu : :obj:`float` or :class:`.Expression` of type :py:data:`.tfloat64`; The standard deviation of the normal term.; sigma : :obj:`float` or :class:`.Expression` of type :py:data:`.tfloat64`; The standard deviation of the normal term.; max_iterations : :obj:`int` or :class:`.Expression` of type :py:data:`.tint32`; The maximum number of iterations of the numerical integration before raising an error. The; default maximum number of iterations is ``1e5``.; min_accuracy : :obj:`int` or :class:`.Expression` of type :py:data:`.tint32`; The minimum accuracy of the returned value. If the minimum accuracy is not achieved, this; function will raise an error. The default minimum accuracy is ``1e-5``. Returns; -------; :class:`.StructExpression`; This method returns a structure with the value as well as information about the numerical; integration. - value : :class:`.Float64Expression`. If converged is true, the value of the CDF evaluated; at `x`. Otherwise, this is the last value the integration evaluated before aborting. - n_iterations : :class:`.Int32Expression`. The number of iterations before stopping. - converged : :class:`.BooleanExpression`. True if the `min_accuracy` was achieved and round; off error is not likely significant. - fault : :class:`.Int32Expression`. If converged is true, fault is zero. If converged is; false, fault is either one or two. One indicates that the requried accuracy was not; achieved. Two indicates the round-off error is possibly significant. """"""; if max_iterations is None:; max_iterations = hl.literal(10_000); if min_accuracy is None:; min_accuracy = hl.literal(1e-5); return _func(""pgenchisq"", PGENCHISQ_RETURN_TYPE, x - mu, w, k, lam, sigma, max_iterations, min_accuracy). [docs]@typecheck(x=expr_float64, mu=expr_float64, sigma=expr_fl",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:71038,Deployability,integrat,integration,71038,"d in Python.; mu : :obj:`float` or :class:`.Expression` of type :py:data:`.tfloat64`; The standard deviation of the normal term.; sigma : :obj:`float` or :class:`.Expression` of type :py:data:`.tfloat64`; The standard deviation of the normal term.; max_iterations : :obj:`int` or :class:`.Expression` of type :py:data:`.tint32`; The maximum number of iterations of the numerical integration before raising an error. The; default maximum number of iterations is ``1e5``.; min_accuracy : :obj:`int` or :class:`.Expression` of type :py:data:`.tint32`; The minimum accuracy of the returned value. If the minimum accuracy is not achieved, this; function will raise an error. The default minimum accuracy is ``1e-5``. Returns; -------; :class:`.StructExpression`; This method returns a structure with the value as well as information about the numerical; integration. - value : :class:`.Float64Expression`. If converged is true, the value of the CDF evaluated; at `x`. Otherwise, this is the last value the integration evaluated before aborting. - n_iterations : :class:`.Int32Expression`. The number of iterations before stopping. - converged : :class:`.BooleanExpression`. True if the `min_accuracy` was achieved and round; off error is not likely significant. - fault : :class:`.Int32Expression`. If converged is true, fault is zero. If converged is; false, fault is either one or two. One indicates that the requried accuracy was not; achieved. Two indicates the round-off error is possibly significant. """"""; if max_iterations is None:; max_iterations = hl.literal(10_000); if min_accuracy is None:; min_accuracy = hl.literal(1e-5); return _func(""pgenchisq"", PGENCHISQ_RETURN_TYPE, x - mu, w, k, lam, sigma, max_iterations, min_accuracy). [docs]@typecheck(x=expr_float64, mu=expr_float64, sigma=expr_float64, lower_tail=expr_bool, log_p=expr_bool); def pnorm(x, mu=0, sigma=1, lower_tail=True, log_p=False) -> Float64Expression:; """"""The cumulative probability function of a normal distribution with mean",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:188705,Deployability,update,updated,188705,"oerce_endpoint(point):; if point.dtype == key_typ[0]:; point = hl.struct(**{key_names[0]: point}); ts = point.dtype; if isinstance(ts, tstruct):; i = 0; while i < len(ts):; if i >= len(key_typ):; raise ValueError(; f""query_table: queried with {len(ts)} key field(s), but table only has {len(key_typ)} key field(s)""; ); if key_typ[i] != ts[i]:; raise ValueError(; f""query_table: key mismatch at key field {i} ({list(ts.keys())[i]!r}): query type is {ts[i]}, table key type is {key_typ[i]}""; ); i += 1. if i == 0:; raise ValueError(""query_table: cannot query with empty key""). point_size = builtins.len(point.dtype); return hl.tuple([; hl.struct(**{; key_names[i]: (point[i] if i < point_size else hl.missing(key_typ[i])); for i in builtins.range(builtins.len(key_typ)); }),; hl.int32(point_size),; ]); else:; raise ValueError(; f""query_table: key mismatch: cannot query a table with key ""; f""({', '.join(builtins.str(x) for x in key_typ.values())}) with query point type {point.dtype}""; ). if point_or_interval.dtype != key_typ[0] and isinstance(point_or_interval.dtype, hl.tinterval):; partition_interval = hl.interval(; start=coerce_endpoint(point_or_interval.start),; end=coerce_endpoint(point_or_interval.end),; includes_start=point_or_interval.includes_start,; includes_end=point_or_interval.includes_end,; ); else:; point = coerce_endpoint(point_or_interval); partition_interval = hl.interval(start=point, end=point, includes_start=True, includes_end=True); return construct_expr(; ir.ToArray(ir.ReadPartition(partition_interval._ir, reader=ir.PartitionNativeIntervalReader(path, row_typ))),; type=hl.tarray(row_typ),; indices=partition_interval._indices,; aggregations=partition_interval._aggregations,; ). @typecheck(msg=expr_str, result=expr_any); def _console_log(msg, result):; indices, aggregations = unify_all(msg, result); return construct_expr(ir.ConsoleLog(msg._ir, result._ir), result.dtype, indices, aggregations). © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:30544,Energy Efficiency,power,power,30544,"""""""; return _func(""dnorm"", tfloat64, x, mu, sigma, log_p). [docs]@typecheck(x=expr_float64, lamb=expr_float64, log_p=expr_bool); def dpois(x, lamb, log_p=False) -> Float64Expression:; """"""Compute the (log) probability density at x of a Poisson distribution with rate parameter `lamb`. Examples; --------. >>> hl.eval(hl.dpois(5, 3)); 0.10081881344492458. Parameters; ----------; x : :obj:`float` or :class:`.Expression` of type :py:data:`.tfloat64`; Non-negative number at which to compute the probability density.; lamb : :obj:`float` or :class:`.Expression` of type :py:data:`.tfloat64`; Poisson rate parameter. Must be non-negative.; log_p : :obj:`bool` or :class:`.BooleanExpression`; If ``True``, the natural logarithm of the probability density is returned. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`; The (log) probability density.; """"""; return _func(""dpois"", tfloat64, x, lamb, log_p). [docs]@typecheck(x=oneof(expr_float64, expr_ndarray(expr_float64))); @ndarray_broadcasting; def exp(x) -> Float64Expression:; """"""Computes `e` raised to the power `x`. Examples; --------. >>> hl.eval(hl.exp(2)); 7.38905609893065. Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`; """"""; return _func(""exp"", tfloat64, x). [docs]@typecheck(c1=expr_int32, c2=expr_int32, c3=expr_int32, c4=expr_int32); def fisher_exact_test(c1, c2, c3, c4) -> StructExpression:; """"""Calculates the p-value, odds ratio, and 95% confidence interval using; Fisher's exact test for a 2x2 table. Examples; --------. >>> hl.eval(hl.fisher_exact_test(10, 10, 10, 10)); Struct(p_value=1.0000000000000002, odds_ratio=1.0,; ci_95_lower=0.24385796914260355, ci_95_upper=4.100747675033819). >>> hl.eval(hl.fisher_exact_test(51, 43, 22, 92)); Struct(p_value=2.1564999740157304e-07, odds_ratio=4.918058171469967,; ci_95_lower=2.5659373368",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:34323,Energy Efficiency,efficient,efficient,34323," 4.0. Parameters; ----------; x : :class:`.Float32Expression`,:class:`.Float64Expression` or :class:`.NDArrayNumericExpression`. Returns; -------; :class:`.Float32Expression`, :class:`.Float64Expression`, or :class:`.NDArrayNumericExpression`; """"""; return _func(""ceil"", x.dtype, x). [docs]@typecheck(n_hom_ref=expr_int32, n_het=expr_int32, n_hom_var=expr_int32, one_sided=expr_bool); def hardy_weinberg_test(n_hom_ref, n_het, n_hom_var, one_sided=False) -> StructExpression:; """"""Performs test of Hardy-Weinberg equilibrium. Examples; --------. >>> hl.eval(hl.hardy_weinberg_test(250, 500, 250)); Struct(het_freq_hwe=0.5002501250625313, p_value=0.9747844394217698). >>> hl.eval(hl.hardy_weinberg_test(37, 200, 85)); Struct(het_freq_hwe=0.48964964307448583, p_value=1.1337210383168987e-06). Notes; -----; By default, this method performs a two-sided exact test with mid-p-value correction of; `Hardy-Weinberg equilibrium <https://en.wikipedia.org/wiki/Hardy%E2%80%93Weinberg_principle>`__; via an efficient implementation of the; `Levene-Haldane distribution <../_static/LeveneHaldane.pdf>`__,; which models the number of heterozygous individuals under equilibrium. The mean of this distribution is ``(n_ref * n_var) / (2n - 1)``, where; ``n_ref = 2*n_hom_ref + n_het`` is the number of reference alleles,; ``n_var = 2*n_hom_var + n_het`` is the number of variant alleles,; and ``n = n_hom_ref + n_het + n_hom_var`` is the number of individuals.; So the expected frequency of heterozygotes under equilibrium,; `het_freq_hwe`, is this mean divided by ``n``. To perform one-sided exact test of excess heterozygosity with mid-p-value; correction instead, set `one_sided=True` and the p-value returned will be; from the one-sided exact test. Parameters; ----------; n_hom_ref : int or :class:`.Expression` of type :py:data:`.tint32`; Number of homozygous reference genotypes.; n_het : int or :class:`.Expression` of type :py:data:`.tint32`; Number of heterozygous genotypes.; n_hom_var : int or :class:`.Ex",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:109361,Energy Efficiency,reduce,reduce,109361," >>> hl.eval(hl.any([False, True, False])); True. >>> hl.eval(hl.any([False, False, False])); False. The third form:. >>> a = ['The', 'quick', 'brown', 'fox']; >>> s = {1, 3, 5, 6, 7, 9}. >>> hl.eval(hl.any(lambda x: x[-1] == 'x', a)); True. >>> hl.eval(hl.any(lambda x: x % 4 == 0, s)); False. Notes; -----; :func:`~.any` returns ``False`` when given an empty array or empty argument list.; """"""; base = hl.literal(False); if builtins.len(args) == 0:; return base; if builtins.len(args) == 1:; arg = arg_check(args[0], 'any', 'collection', oneof(collection_type, expr_bool)); if arg.dtype == hl.tbool:; return arg; return arg.any(lambda x: x); if builtins.len(args) == 2:; if callable(args[0]):; f = arg_check(args[0], 'any', 'f', any_to_bool_type); collection = arg_check(args[1], 'any', 'collection', collection_type); return collection.any(f); n_args = builtins.len(args); args = [args_check(x, 'any', 'exprs', i, n_args, expr_bool) for i, x in builtins.enumerate(args)]; return functools.reduce(operator.ior, args, base). [docs]def all(*args) -> BooleanExpression:; """"""Check for all ``True`` in boolean expressions or collections of booleans. :func:`~.all` comes in three forms:. 1. ``hl.all(boolean, ...)``. Are all arguments ``True``?. 2. ``hl.all(collection)``. Are all elements of the collection ``True``?. 3. ``hl.all(function, collection)``. Does ``function`` return ``True`` for; all values in this collection?. Examples; --------. The first form:. >>> hl.eval(hl.all()); True. >>> hl.eval(hl.all(True)); True. >>> hl.eval(hl.all(False)); False. >>> hl.eval(hl.all(True, True, True)); True. >>> hl.eval(hl.all(False, False, True, False)); False. The second form:. >>> hl.eval(hl.all([False, True, False])); False. >>> hl.eval(hl.all([True, True, True])); True. The third form:. >>> a = ['The', 'quick', 'brown', 'fox']; >>> s = {1, 3, 5, 6, 7, 9}. >>> hl.eval(hl.all(lambda x: hl.len(x) > 3, a)); False. >>> hl.eval(hl.all(lambda x: x < 10, s)); True. Notes; -----; :func:`~.all` returns `",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:111027,Energy Efficiency,reduce,reduce,111027,"d form:. >>> hl.eval(hl.all([False, True, False])); False. >>> hl.eval(hl.all([True, True, True])); True. The third form:. >>> a = ['The', 'quick', 'brown', 'fox']; >>> s = {1, 3, 5, 6, 7, 9}. >>> hl.eval(hl.all(lambda x: hl.len(x) > 3, a)); False. >>> hl.eval(hl.all(lambda x: x < 10, s)); True. Notes; -----; :func:`~.all` returns ``True`` when given an empty array or empty argument list.; """"""; base = hl.literal(True); if builtins.len(args) == 0:; return base; if builtins.len(args) == 1:; arg = arg_check(args[0], 'any', 'collection', oneof(collection_type, expr_bool)); if arg.dtype == hl.tbool:; return arg; return arg.all(lambda x: x); if builtins.len(args) == 2:; if callable(args[0]):; f = arg_check(args[0], 'all', 'f', any_to_bool_type); collection = arg_check(args[1], 'all', 'collection', collection_type); return collection.all(f); n_args = builtins.len(args); args = [args_check(x, 'all', 'exprs', i, n_args, expr_bool) for i, x in builtins.enumerate(args)]; return functools.reduce(operator.iand, args, base). [docs]@typecheck(f=func_spec(1, expr_bool), collection=expr_oneof(expr_set(), expr_array())); def find(f: Callable, collection):; """"""Returns the first element where `f` returns ``True``. Examples; --------. >>> a = ['The', 'quick', 'brown', 'fox']; >>> s = {1, 3, 5, 6, 7, 9}. >>> hl.eval(hl.find(lambda x: x[-1] == 'x', a)); 'fox'. >>> hl.eval(hl.find(lambda x: x % 4 == 0, s)); None. Notes; -----; If `f` returns ``False`` for every element, then the result is missing. Sets are unordered. If `collection` is of type :class:`.tset`, then the; element returned comes from no guaranteed ordering. Parameters; ----------; f : function ( (arg) -> :class:`.BooleanExpression`); Function to evaluate for each element of the collection. Must return a; :class:`.BooleanExpression`.; collection : :class:`.ArrayExpression` or :class:`.SetExpression`; Collection expression. Returns; -------; :class:`.Expression`; Expression whose type is the element type of the collection.; """""";",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:124815,Energy Efficiency,reduce,reduce,124815,"r} requires at least one argument""); if (; builtins.len(exprs) == 1; and (isinstance(exprs[0].dtype, (tarray, tset))); and is_numeric(exprs[0].dtype.element_type); ):; [e] = exprs; if filter_nan and e.dtype.element_type in (tfloat32, tfloat64):; name = 'nan' + name; return array(e)._filter_missing_method(filter_missing, name, exprs[0].dtype.element_type); else:; if not builtins.all(is_numeric(e.dtype) for e in exprs):; expr_types = ', '.join(""'{}'"".format(e.dtype) for e in exprs); raise TypeError(; f""{name!r} expects a single numeric array expression or multiple numeric expressions\n""; f"" Found {builtins.len(exprs)} arguments with types {expr_types}""; ); unified_typ = unify_types_limited(*(e.dtype for e in exprs)); ec = coercer_from_dtype(unified_typ); indices, aggs = unify_all(*exprs). func_name = name; if filter_missing:; func_name += '_ignore_missing'; if filter_nan and unified_typ in (tfloat32, tfloat64):; func_name = 'nan' + func_name; return construct_expr(; functools.reduce(lambda l, r: ir.Apply(func_name, unified_typ, l, r), [ec.coerce(e)._ir for e in exprs]),; unified_typ,; indices,; aggs,; ). [docs]@typecheck(; exprs=expr_oneof(expr_numeric, expr_set(expr_numeric), expr_array(expr_numeric)), filter_missing=builtins.bool; ); def nanmax(*exprs, filter_missing: builtins.bool = True) -> NumericExpression:; """"""Returns the maximum value of a collection or of given arguments, excluding NaN. Examples; --------. Compute the maximum value of an array:. >>> hl.eval(hl.nanmax([1.1, 50.1, float('nan')])); 50.1. Take the maximum value of arguments:. >>> hl.eval(hl.nanmax(1.1, 50.1, float('nan'))); 50.1. Notes; -----; Like the Python builtin ``max`` function, this function can either take a; single iterable expression (an array or set of numeric elements), or; variable-length arguments of numeric expressions. Note; ----; If `filter_missing` is ``True``, then the result is the maximum of; non-missing arguments or elements. If `filter_missing` is ``False``, then; any missin",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:10126,Integrability,wrap,wrapper,10126,"ef literal(x: Any, dtype: Optional[Union[HailType, str]] = None):; """"""Captures and broadcasts a Python variable or object as an expression. Examples; --------. >>> table = hl.utils.range_table(8); >>> greetings = hl.literal({1: 'Good morning', 4: 'Good afternoon', 6 : 'Good evening'}); >>> table.annotate(greeting = greetings.get(table.idx)).show(); +-------+------------------+; | idx | greeting |; +-------+------------------+; | int32 | str |; +-------+------------------+; | 0 | NA |; | 1 | ""Good morning"" |; | 2 | NA |; | 3 | NA |; | 4 | ""Good afternoon"" |; | 5 | NA |; | 6 | ""Good evening"" |; | 7 | NA |; +-------+------------------+. Notes; -----; Use this function to capture large Python objects for use in expressions. This; function provides an alternative to adding an object as a global annotation on a; :class:`.Table` or :class:`.MatrixTable`. Parameters; ----------; x; Object to capture and broadcast as an expression. Returns; -------; :class:`.Expression`; """"""; wrapper = {'has_expr': False, 'has_free_vars': False}. def typecheck_expr(t, x):; if isinstance(x, Expression):; wrapper['has_expr'] = True; wrapper['has_free_vars'] |= (; builtins.len(x._ir.free_vars) > 0; or builtins.len(x._ir.free_agg_vars) > 0; or builtins.len(x._ir.free_scan_vars) > 0; ). if x.dtype != t:; raise TypeError(f""'literal': type mismatch: expected '{t}', found '{x.dtype}'""); elif x._indices.source is not None:; if x._indices.axes:; raise ExpressionException(; f""'literal' can only accept scalar or global expression arguments,""; f"" found indices {x._indices.axes}""; ); return False; elif x is None or x is pd.NA:; return False; else:; t._typecheck_one_level(x); return True. if dtype is None:; dtype = impute_type(x). # Special handling of numpy. Have to extract from numpy scalars, do nothing on numpy arrays; if isinstance(x, np.generic):; x = x.item(); elif isinstance(x, np.ndarray):; pass; else:; try:; dtype._traverse(x, typecheck_expr); except TypeError as e:; raise TypeError(""'literal': ob",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:10239,Integrability,wrap,wrapper,10239,"hon variable or object as an expression. Examples; --------. >>> table = hl.utils.range_table(8); >>> greetings = hl.literal({1: 'Good morning', 4: 'Good afternoon', 6 : 'Good evening'}); >>> table.annotate(greeting = greetings.get(table.idx)).show(); +-------+------------------+; | idx | greeting |; +-------+------------------+; | int32 | str |; +-------+------------------+; | 0 | NA |; | 1 | ""Good morning"" |; | 2 | NA |; | 3 | NA |; | 4 | ""Good afternoon"" |; | 5 | NA |; | 6 | ""Good evening"" |; | 7 | NA |; +-------+------------------+. Notes; -----; Use this function to capture large Python objects for use in expressions. This; function provides an alternative to adding an object as a global annotation on a; :class:`.Table` or :class:`.MatrixTable`. Parameters; ----------; x; Object to capture and broadcast as an expression. Returns; -------; :class:`.Expression`; """"""; wrapper = {'has_expr': False, 'has_free_vars': False}. def typecheck_expr(t, x):; if isinstance(x, Expression):; wrapper['has_expr'] = True; wrapper['has_free_vars'] |= (; builtins.len(x._ir.free_vars) > 0; or builtins.len(x._ir.free_agg_vars) > 0; or builtins.len(x._ir.free_scan_vars) > 0; ). if x.dtype != t:; raise TypeError(f""'literal': type mismatch: expected '{t}', found '{x.dtype}'""); elif x._indices.source is not None:; if x._indices.axes:; raise ExpressionException(; f""'literal' can only accept scalar or global expression arguments,""; f"" found indices {x._indices.axes}""; ); return False; elif x is None or x is pd.NA:; return False; else:; t._typecheck_one_level(x); return True. if dtype is None:; dtype = impute_type(x). # Special handling of numpy. Have to extract from numpy scalars, do nothing on numpy arrays; if isinstance(x, np.generic):; x = x.item(); elif isinstance(x, np.ndarray):; pass; else:; try:; dtype._traverse(x, typecheck_expr); except TypeError as e:; raise TypeError(""'literal': object did not match the passed type '{}'"".format(dtype)) from e. if wrapper['has_free_vars']:; raise ",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:10267,Integrability,wrap,wrapper,10267,"hon variable or object as an expression. Examples; --------. >>> table = hl.utils.range_table(8); >>> greetings = hl.literal({1: 'Good morning', 4: 'Good afternoon', 6 : 'Good evening'}); >>> table.annotate(greeting = greetings.get(table.idx)).show(); +-------+------------------+; | idx | greeting |; +-------+------------------+; | int32 | str |; +-------+------------------+; | 0 | NA |; | 1 | ""Good morning"" |; | 2 | NA |; | 3 | NA |; | 4 | ""Good afternoon"" |; | 5 | NA |; | 6 | ""Good evening"" |; | 7 | NA |; +-------+------------------+. Notes; -----; Use this function to capture large Python objects for use in expressions. This; function provides an alternative to adding an object as a global annotation on a; :class:`.Table` or :class:`.MatrixTable`. Parameters; ----------; x; Object to capture and broadcast as an expression. Returns; -------; :class:`.Expression`; """"""; wrapper = {'has_expr': False, 'has_free_vars': False}. def typecheck_expr(t, x):; if isinstance(x, Expression):; wrapper['has_expr'] = True; wrapper['has_free_vars'] |= (; builtins.len(x._ir.free_vars) > 0; or builtins.len(x._ir.free_agg_vars) > 0; or builtins.len(x._ir.free_scan_vars) > 0; ). if x.dtype != t:; raise TypeError(f""'literal': type mismatch: expected '{t}', found '{x.dtype}'""); elif x._indices.source is not None:; if x._indices.axes:; raise ExpressionException(; f""'literal' can only accept scalar or global expression arguments,""; f"" found indices {x._indices.axes}""; ); return False; elif x is None or x is pd.NA:; return False; else:; t._typecheck_one_level(x); return True. if dtype is None:; dtype = impute_type(x). # Special handling of numpy. Have to extract from numpy scalars, do nothing on numpy arrays; if isinstance(x, np.generic):; x = x.item(); elif isinstance(x, np.ndarray):; pass; else:; try:; dtype._traverse(x, typecheck_expr); except TypeError as e:; raise TypeError(""'literal': object did not match the passed type '{}'"".format(dtype)) from e. if wrapper['has_free_vars']:; raise ",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:11211,Integrability,wrap,wrapper,11211,"['has_free_vars'] |= (; builtins.len(x._ir.free_vars) > 0; or builtins.len(x._ir.free_agg_vars) > 0; or builtins.len(x._ir.free_scan_vars) > 0; ). if x.dtype != t:; raise TypeError(f""'literal': type mismatch: expected '{t}', found '{x.dtype}'""); elif x._indices.source is not None:; if x._indices.axes:; raise ExpressionException(; f""'literal' can only accept scalar or global expression arguments,""; f"" found indices {x._indices.axes}""; ); return False; elif x is None or x is pd.NA:; return False; else:; t._typecheck_one_level(x); return True. if dtype is None:; dtype = impute_type(x). # Special handling of numpy. Have to extract from numpy scalars, do nothing on numpy arrays; if isinstance(x, np.generic):; x = x.item(); elif isinstance(x, np.ndarray):; pass; else:; try:; dtype._traverse(x, typecheck_expr); except TypeError as e:; raise TypeError(""'literal': object did not match the passed type '{}'"".format(dtype)) from e. if wrapper['has_free_vars']:; raise ValueError(; ""'literal' cannot be used with hail expressions that depend ""; ""on other expressions. Use expression 'x' directly ""; ""instead of passing it to 'literal'.""; ). if wrapper['has_expr']:; return literal(hl.eval(to_expr(x, dtype)), dtype). if x is None or x is pd.NA:; return hl.missing(dtype); elif is_primitive(dtype):; if dtype == tint32:; assert is_int32(x); assert tint32.min_value <= x <= tint32.max_value; return construct_expr(ir.I32(x), tint32); elif dtype == tint64:; assert is_int64(x); assert tint64.min_value <= x <= tint64.max_value; return construct_expr(ir.I64(x), tint64); elif dtype == tfloat32:; assert is_float32(x); return construct_expr(ir.F32(x), tfloat32); elif dtype == tfloat64:; assert is_float64(x); return construct_expr(ir.F64(x), tfloat64); elif dtype == tbool:; assert isinstance(x, builtins.bool); return construct_expr(ir.TrueIR() if x else ir.FalseIR(), tbool); else:; assert dtype == tstr; assert isinstance(x, builtins.str); return construct_expr(ir.Str(x), tstr); else:; return constru",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:11310,Integrability,depend,depend,11310,"['has_free_vars'] |= (; builtins.len(x._ir.free_vars) > 0; or builtins.len(x._ir.free_agg_vars) > 0; or builtins.len(x._ir.free_scan_vars) > 0; ). if x.dtype != t:; raise TypeError(f""'literal': type mismatch: expected '{t}', found '{x.dtype}'""); elif x._indices.source is not None:; if x._indices.axes:; raise ExpressionException(; f""'literal' can only accept scalar or global expression arguments,""; f"" found indices {x._indices.axes}""; ); return False; elif x is None or x is pd.NA:; return False; else:; t._typecheck_one_level(x); return True. if dtype is None:; dtype = impute_type(x). # Special handling of numpy. Have to extract from numpy scalars, do nothing on numpy arrays; if isinstance(x, np.generic):; x = x.item(); elif isinstance(x, np.ndarray):; pass; else:; try:; dtype._traverse(x, typecheck_expr); except TypeError as e:; raise TypeError(""'literal': object did not match the passed type '{}'"".format(dtype)) from e. if wrapper['has_free_vars']:; raise ValueError(; ""'literal' cannot be used with hail expressions that depend ""; ""on other expressions. Use expression 'x' directly ""; ""instead of passing it to 'literal'.""; ). if wrapper['has_expr']:; return literal(hl.eval(to_expr(x, dtype)), dtype). if x is None or x is pd.NA:; return hl.missing(dtype); elif is_primitive(dtype):; if dtype == tint32:; assert is_int32(x); assert tint32.min_value <= x <= tint32.max_value; return construct_expr(ir.I32(x), tint32); elif dtype == tint64:; assert is_int64(x); assert tint64.min_value <= x <= tint64.max_value; return construct_expr(ir.I64(x), tint64); elif dtype == tfloat32:; assert is_float32(x); return construct_expr(ir.F32(x), tfloat32); elif dtype == tfloat64:; assert is_float64(x); return construct_expr(ir.F64(x), tfloat64); elif dtype == tbool:; assert isinstance(x, builtins.bool); return construct_expr(ir.TrueIR() if x else ir.FalseIR(), tbool); else:; assert dtype == tstr; assert isinstance(x, builtins.str); return construct_expr(ir.Str(x), tstr); else:; return constru",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:11419,Integrability,wrap,wrapper,11419,"; raise TypeError(f""'literal': type mismatch: expected '{t}', found '{x.dtype}'""); elif x._indices.source is not None:; if x._indices.axes:; raise ExpressionException(; f""'literal' can only accept scalar or global expression arguments,""; f"" found indices {x._indices.axes}""; ); return False; elif x is None or x is pd.NA:; return False; else:; t._typecheck_one_level(x); return True. if dtype is None:; dtype = impute_type(x). # Special handling of numpy. Have to extract from numpy scalars, do nothing on numpy arrays; if isinstance(x, np.generic):; x = x.item(); elif isinstance(x, np.ndarray):; pass; else:; try:; dtype._traverse(x, typecheck_expr); except TypeError as e:; raise TypeError(""'literal': object did not match the passed type '{}'"".format(dtype)) from e. if wrapper['has_free_vars']:; raise ValueError(; ""'literal' cannot be used with hail expressions that depend ""; ""on other expressions. Use expression 'x' directly ""; ""instead of passing it to 'literal'.""; ). if wrapper['has_expr']:; return literal(hl.eval(to_expr(x, dtype)), dtype). if x is None or x is pd.NA:; return hl.missing(dtype); elif is_primitive(dtype):; if dtype == tint32:; assert is_int32(x); assert tint32.min_value <= x <= tint32.max_value; return construct_expr(ir.I32(x), tint32); elif dtype == tint64:; assert is_int64(x); assert tint64.min_value <= x <= tint64.max_value; return construct_expr(ir.I64(x), tint64); elif dtype == tfloat32:; assert is_float32(x); return construct_expr(ir.F32(x), tfloat32); elif dtype == tfloat64:; assert is_float64(x); return construct_expr(ir.F64(x), tfloat64); elif dtype == tbool:; assert isinstance(x, builtins.bool); return construct_expr(ir.TrueIR() if x else ir.FalseIR(), tbool); else:; assert dtype == tstr; assert isinstance(x, builtins.str); return construct_expr(ir.Str(x), tstr); else:; return construct_expr(ir.EncodedLiteral(dtype, x), dtype). [docs]@deprecated(version=""0.2.59"", reason=""Replaced by hl.if_else""); @typecheck(condition=expr_bool, consequent=expr",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:69202,Integrability,integrat,integrate,69202,"h was published as:. `Davies, Robert. ""The distribution of a linear combination of chi-squared random variables.""; Applied Statistics 29 323-333. 1980. <http://www.robertnz.net/pdf/lc_chisq.pdf>`__. Davies included Fortran source code in the original publication. Davies also released a `C; language port <http://www.robertnz.net/QF.htm>`__. Hail's implementation is a fairly direct port; of the C implementation to Scala. Davies provides 39 test cases with the source code. The Hail; tests include all 39 test cases as well as a few additional tests. Davies' website cautions:. The method works well in most situations if you want only modest accuracy, say 0.0001. But; problems may arise if the sum is dominated by one or two terms with a total of only one or; two degrees of freedom and x is small. For an accessible introduction the Generalized Chi-Squared Distribution, we strongly recommend; the introduction of this paper:. `Das, Abhranil; Geisler, Wilson (2020). ""A method to integrate and classify normal; distributions"". <https://arxiv.org/abs/2012.14331>`__. Parameters; ----------; x : :obj:`float` or :class:`.Expression` of type :py:data:`.tfloat64`; The value at which to evaluate the cumulative distribution function (CDF).; w : :obj:`list` of :obj:`float` or :class:`.Expression` of type :py:class:`.tarray` of :py:data:`.tfloat64`; A weight for each non-central chi-square term.; k : :obj:`list` of :obj:`int` or :class:`.Expression` of type :py:class:`.tarray` of :py:data:`.tint32`; A degrees of freedom parameter for each non-central chi-square term.; lam : :obj:`list` of :obj:`float` or :class:`.Expression` of type :py:class:`.tarray` of :py:data:`.tfloat64`; A non-centrality parameter for each non-central chi-square term. We use `lam` instead; of `lambda` because the latter is a reserved word in Python.; mu : :obj:`float` or :class:`.Expression` of type :py:data:`.tfloat64`; The standard deviation of the normal term.; sigma : :obj:`float` or :class:`.Expression` of typ",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:70416,Integrability,integrat,integration,70416," evaluate the cumulative distribution function (CDF).; w : :obj:`list` of :obj:`float` or :class:`.Expression` of type :py:class:`.tarray` of :py:data:`.tfloat64`; A weight for each non-central chi-square term.; k : :obj:`list` of :obj:`int` or :class:`.Expression` of type :py:class:`.tarray` of :py:data:`.tint32`; A degrees of freedom parameter for each non-central chi-square term.; lam : :obj:`list` of :obj:`float` or :class:`.Expression` of type :py:class:`.tarray` of :py:data:`.tfloat64`; A non-centrality parameter for each non-central chi-square term. We use `lam` instead; of `lambda` because the latter is a reserved word in Python.; mu : :obj:`float` or :class:`.Expression` of type :py:data:`.tfloat64`; The standard deviation of the normal term.; sigma : :obj:`float` or :class:`.Expression` of type :py:data:`.tfloat64`; The standard deviation of the normal term.; max_iterations : :obj:`int` or :class:`.Expression` of type :py:data:`.tint32`; The maximum number of iterations of the numerical integration before raising an error. The; default maximum number of iterations is ``1e5``.; min_accuracy : :obj:`int` or :class:`.Expression` of type :py:data:`.tint32`; The minimum accuracy of the returned value. If the minimum accuracy is not achieved, this; function will raise an error. The default minimum accuracy is ``1e-5``. Returns; -------; :class:`.StructExpression`; This method returns a structure with the value as well as information about the numerical; integration. - value : :class:`.Float64Expression`. If converged is true, the value of the CDF evaluated; at `x`. Otherwise, this is the last value the integration evaluated before aborting. - n_iterations : :class:`.Int32Expression`. The number of iterations before stopping. - converged : :class:`.BooleanExpression`. True if the `min_accuracy` was achieved and round; off error is not likely significant. - fault : :class:`.Int32Expression`. If converged is true, fault is zero. If converged is; false, fault is eith",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:70886,Integrability,integrat,integration,70886,"Expression` of type :py:class:`.tarray` of :py:data:`.tfloat64`; A non-centrality parameter for each non-central chi-square term. We use `lam` instead; of `lambda` because the latter is a reserved word in Python.; mu : :obj:`float` or :class:`.Expression` of type :py:data:`.tfloat64`; The standard deviation of the normal term.; sigma : :obj:`float` or :class:`.Expression` of type :py:data:`.tfloat64`; The standard deviation of the normal term.; max_iterations : :obj:`int` or :class:`.Expression` of type :py:data:`.tint32`; The maximum number of iterations of the numerical integration before raising an error. The; default maximum number of iterations is ``1e5``.; min_accuracy : :obj:`int` or :class:`.Expression` of type :py:data:`.tint32`; The minimum accuracy of the returned value. If the minimum accuracy is not achieved, this; function will raise an error. The default minimum accuracy is ``1e-5``. Returns; -------; :class:`.StructExpression`; This method returns a structure with the value as well as information about the numerical; integration. - value : :class:`.Float64Expression`. If converged is true, the value of the CDF evaluated; at `x`. Otherwise, this is the last value the integration evaluated before aborting. - n_iterations : :class:`.Int32Expression`. The number of iterations before stopping. - converged : :class:`.BooleanExpression`. True if the `min_accuracy` was achieved and round; off error is not likely significant. - fault : :class:`.Int32Expression`. If converged is true, fault is zero. If converged is; false, fault is either one or two. One indicates that the requried accuracy was not; achieved. Two indicates the round-off error is possibly significant. """"""; if max_iterations is None:; max_iterations = hl.literal(10_000); if min_accuracy is None:; min_accuracy = hl.literal(1e-5); return _func(""pgenchisq"", PGENCHISQ_RETURN_TYPE, x - mu, w, k, lam, sigma, max_iterations, min_accuracy). [docs]@typecheck(x=expr_float64, mu=expr_float64, sigma=expr_fl",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:71038,Integrability,integrat,integration,71038,"d in Python.; mu : :obj:`float` or :class:`.Expression` of type :py:data:`.tfloat64`; The standard deviation of the normal term.; sigma : :obj:`float` or :class:`.Expression` of type :py:data:`.tfloat64`; The standard deviation of the normal term.; max_iterations : :obj:`int` or :class:`.Expression` of type :py:data:`.tint32`; The maximum number of iterations of the numerical integration before raising an error. The; default maximum number of iterations is ``1e5``.; min_accuracy : :obj:`int` or :class:`.Expression` of type :py:data:`.tint32`; The minimum accuracy of the returned value. If the minimum accuracy is not achieved, this; function will raise an error. The default minimum accuracy is ``1e-5``. Returns; -------; :class:`.StructExpression`; This method returns a structure with the value as well as information about the numerical; integration. - value : :class:`.Float64Expression`. If converged is true, the value of the CDF evaluated; at `x`. Otherwise, this is the last value the integration evaluated before aborting. - n_iterations : :class:`.Int32Expression`. The number of iterations before stopping. - converged : :class:`.BooleanExpression`. True if the `min_accuracy` was achieved and round; off error is not likely significant. - fault : :class:`.Int32Expression`. If converged is true, fault is zero. If converged is; false, fault is either one or two. One indicates that the requried accuracy was not; achieved. Two indicates the round-off error is possibly significant. """"""; if max_iterations is None:; max_iterations = hl.literal(10_000); if min_accuracy is None:; min_accuracy = hl.literal(1e-5); return _func(""pgenchisq"", PGENCHISQ_RETURN_TYPE, x - mu, w, k, lam, sigma, max_iterations, min_accuracy). [docs]@typecheck(x=expr_float64, mu=expr_float64, sigma=expr_float64, lower_tail=expr_bool, log_p=expr_bool); def pnorm(x, mu=0, sigma=1, lower_tail=True, log_p=False) -> Float64Expression:; """"""The cumulative probability function of a normal distribution with mean",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:9247,Modifiability,variab,variable,9247,"-----; t : :class:`str` or :class:`.HailType`; Type of the missing expression. Returns; -------; :class:`.Expression`; A missing expression of type `t`.; """"""; return construct_expr(ir.NA(t), t). [docs]@deprecated(version=""0.2.62"", reason=""Replaced by hl.missing""); @typecheck(t=hail_type); def null(t: Union[HailType, str]):; """"""Deprecated in favor of :func:`.missing`. Creates an expression representing a missing value of a specified type. Examples; --------. >>> hl.eval(hl.null(hl.tarray(hl.tstr))); None. >>> hl.eval(hl.null('array<str>')); None. Notes; -----; This method is useful for constructing an expression that includes missing; values, since :obj:`None` cannot be interpreted as an expression. Parameters; ----------; t : :class:`str` or :class:`.HailType`; Type of the missing expression. Returns; -------; :class:`.Expression`; A missing expression of type `t`.; """"""; return missing(t). [docs]@typecheck(x=anytype, dtype=nullable(hail_type)); def literal(x: Any, dtype: Optional[Union[HailType, str]] = None):; """"""Captures and broadcasts a Python variable or object as an expression. Examples; --------. >>> table = hl.utils.range_table(8); >>> greetings = hl.literal({1: 'Good morning', 4: 'Good afternoon', 6 : 'Good evening'}); >>> table.annotate(greeting = greetings.get(table.idx)).show(); +-------+------------------+; | idx | greeting |; +-------+------------------+; | int32 | str |; +-------+------------------+; | 0 | NA |; | 1 | ""Good morning"" |; | 2 | NA |; | 3 | NA |; | 4 | ""Good afternoon"" |; | 5 | NA |; | 6 | ""Good evening"" |; | 7 | NA |; +-------+------------------+. Notes; -----; Use this function to capture large Python objects for use in expressions. This; function provides an alternative to adding an object as a global annotation on a; :class:`.Table` or :class:`.MatrixTable`. Parameters; ----------; x; Object to capture and broadcast as an expression. Returns; -------; :class:`.Expression`; """"""; wrapper = {'has_expr': False, 'has_free_vars': False}. def ",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:17062,Modifiability,variab,variable,17062,"es as ``False``. See Also; --------; :class:`.CaseBuilder`, :func:`.switch`, :func:`.cond`. Returns; -------; :class:`.CaseBuilder`.; """"""; from .builders import CaseBuilder. return CaseBuilder(missing_false=missing_false). [docs]@typecheck(expr=expr_any); def switch(expr) -> 'hail.expr.builders.SwitchBuilder':; """"""Build a conditional tree on the value of an expression. Examples; --------. >>> csq = hl.literal('loss of function'); >>> expr = (hl.switch(csq); ... .when('synonymous', 1); ... .when('SYN', 1); ... .when('missense', 2); ... .when('MIS', 2); ... .when('loss of function', 3); ... .when('LOF', 3); ... .or_missing()); >>> hl.eval(expr); 3. See Also; --------; :class:`.SwitchBuilder`, :func:`.case`, :func:`.cond`. Parameters; ----------; expr : :class:`.Expression`; Value to match against. Returns; -------; :class:`.SwitchBuilder`; """"""; from .builders import SwitchBuilder. return SwitchBuilder(expr). [docs]@typecheck(f=anytype, exprs=expr_any, _ctx=nullable(str)); def bind(f: Callable, *exprs, _ctx=None):; """"""Bind a temporary variable and use it in a function. Examples; --------. >>> hl.eval(hl.bind(lambda x: x + 1, 1)); 2. :func:`.bind` also can take multiple arguments:. >>> hl.eval(hl.bind(lambda x, y: x / y, x, x)); 1.0. Parameters; ----------; f : function ( (args) -> :class:`.Expression`); Function of `exprs`.; exprs : variable-length args of :class:`.Expression`; Expressions to bind. Returns; -------; :class:`.Expression`; Result of evaluating `f` with `exprs` as arguments.; """"""; args = []; uids = []; irs = []. for expr in exprs:; uid = Env.get_uid(base=_ctx); args.append(construct_variable(uid, expr._type, expr._indices, expr._aggregations)); uids.append(uid); irs.append(expr._ir). lambda_result = to_expr(f(*args)); if _ctx:; indices, aggregations = unify_all(lambda_result) # FIXME: hacky. May drop field refs from errors?; else:; indices, aggregations = unify_all(*exprs, lambda_result). res_ir = lambda_result._ir; for uid, value_ir in builtins.zip(uids, ",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:17366,Modifiability,variab,variable-length,17366,"ression. Examples; --------. >>> csq = hl.literal('loss of function'); >>> expr = (hl.switch(csq); ... .when('synonymous', 1); ... .when('SYN', 1); ... .when('missense', 2); ... .when('MIS', 2); ... .when('loss of function', 3); ... .when('LOF', 3); ... .or_missing()); >>> hl.eval(expr); 3. See Also; --------; :class:`.SwitchBuilder`, :func:`.case`, :func:`.cond`. Parameters; ----------; expr : :class:`.Expression`; Value to match against. Returns; -------; :class:`.SwitchBuilder`; """"""; from .builders import SwitchBuilder. return SwitchBuilder(expr). [docs]@typecheck(f=anytype, exprs=expr_any, _ctx=nullable(str)); def bind(f: Callable, *exprs, _ctx=None):; """"""Bind a temporary variable and use it in a function. Examples; --------. >>> hl.eval(hl.bind(lambda x: x + 1, 1)); 2. :func:`.bind` also can take multiple arguments:. >>> hl.eval(hl.bind(lambda x, y: x / y, x, x)); 1.0. Parameters; ----------; f : function ( (args) -> :class:`.Expression`); Function of `exprs`.; exprs : variable-length args of :class:`.Expression`; Expressions to bind. Returns; -------; :class:`.Expression`; Result of evaluating `f` with `exprs` as arguments.; """"""; args = []; uids = []; irs = []. for expr in exprs:; uid = Env.get_uid(base=_ctx); args.append(construct_variable(uid, expr._type, expr._indices, expr._aggregations)); uids.append(uid); irs.append(expr._ir). lambda_result = to_expr(f(*args)); if _ctx:; indices, aggregations = unify_all(lambda_result) # FIXME: hacky. May drop field refs from errors?; else:; indices, aggregations = unify_all(*exprs, lambda_result). res_ir = lambda_result._ir; for uid, value_ir in builtins.zip(uids, irs):; if _ctx == 'agg':; res_ir = ir.AggLet(uid, value_ir, res_ir, is_scan=False); elif _ctx == 'scan':; res_ir = ir.AggLet(uid, value_ir, res_ir, is_scan=True); else:; res_ir = ir.Let(uid, value_ir, res_ir). return construct_expr(res_ir, lambda_result.dtype, indices, aggregations). [docs]def rbind(*exprs, _ctx=None):; """"""Bind a temporary variable and use it i",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:18357,Modifiability,variab,variable,18357,"of `exprs`.; exprs : variable-length args of :class:`.Expression`; Expressions to bind. Returns; -------; :class:`.Expression`; Result of evaluating `f` with `exprs` as arguments.; """"""; args = []; uids = []; irs = []. for expr in exprs:; uid = Env.get_uid(base=_ctx); args.append(construct_variable(uid, expr._type, expr._indices, expr._aggregations)); uids.append(uid); irs.append(expr._ir). lambda_result = to_expr(f(*args)); if _ctx:; indices, aggregations = unify_all(lambda_result) # FIXME: hacky. May drop field refs from errors?; else:; indices, aggregations = unify_all(*exprs, lambda_result). res_ir = lambda_result._ir; for uid, value_ir in builtins.zip(uids, irs):; if _ctx == 'agg':; res_ir = ir.AggLet(uid, value_ir, res_ir, is_scan=False); elif _ctx == 'scan':; res_ir = ir.AggLet(uid, value_ir, res_ir, is_scan=True); else:; res_ir = ir.Let(uid, value_ir, res_ir). return construct_expr(res_ir, lambda_result.dtype, indices, aggregations). [docs]def rbind(*exprs, _ctx=None):; """"""Bind a temporary variable and use it in a function. This is :func:`.bind` with flipped argument order. Examples; --------. >>> hl.eval(hl.rbind(1, lambda x: x + 1)); 2. :func:`.rbind` also can take multiple arguments:. >>> hl.eval(hl.rbind(4.0, 2.0, lambda x, y: x / y)); 2.0. Parameters; ----------; exprs : variable-length args of :class:`.Expression`; Expressions to bind.; f : function ( (args) -> :class:`.Expression`); Function of `exprs`. Returns; -------; :class:`.Expression`; Result of evaluating `f` with `exprs` as arguments.; """""". *args, f = exprs; args = [expr_any.check(arg, 'rbind', f'argument {index}') for index, arg in builtins.enumerate(args)]. return hl.bind(f, *args, _ctx=_ctx). [docs]@typecheck(c1=expr_int32, c2=expr_int32, c3=expr_int32, c4=expr_int32); def chi_squared_test(c1, c2, c3, c4) -> StructExpression:; """"""Performs chi-squared test of independence on a 2x2 contingency table. Examples; --------. >>> hl.eval(hl.chi_squared_test(10, 10, 10, 10)); Struct(p_value=1.0, odd",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:18649,Modifiability,variab,variable-length,18649,"expr._type, expr._indices, expr._aggregations)); uids.append(uid); irs.append(expr._ir). lambda_result = to_expr(f(*args)); if _ctx:; indices, aggregations = unify_all(lambda_result) # FIXME: hacky. May drop field refs from errors?; else:; indices, aggregations = unify_all(*exprs, lambda_result). res_ir = lambda_result._ir; for uid, value_ir in builtins.zip(uids, irs):; if _ctx == 'agg':; res_ir = ir.AggLet(uid, value_ir, res_ir, is_scan=False); elif _ctx == 'scan':; res_ir = ir.AggLet(uid, value_ir, res_ir, is_scan=True); else:; res_ir = ir.Let(uid, value_ir, res_ir). return construct_expr(res_ir, lambda_result.dtype, indices, aggregations). [docs]def rbind(*exprs, _ctx=None):; """"""Bind a temporary variable and use it in a function. This is :func:`.bind` with flipped argument order. Examples; --------. >>> hl.eval(hl.rbind(1, lambda x: x + 1)); 2. :func:`.rbind` also can take multiple arguments:. >>> hl.eval(hl.rbind(4.0, 2.0, lambda x, y: x / y)); 2.0. Parameters; ----------; exprs : variable-length args of :class:`.Expression`; Expressions to bind.; f : function ( (args) -> :class:`.Expression`); Function of `exprs`. Returns; -------; :class:`.Expression`; Result of evaluating `f` with `exprs` as arguments.; """""". *args, f = exprs; args = [expr_any.check(arg, 'rbind', f'argument {index}') for index, arg in builtins.enumerate(args)]. return hl.bind(f, *args, _ctx=_ctx). [docs]@typecheck(c1=expr_int32, c2=expr_int32, c3=expr_int32, c4=expr_int32); def chi_squared_test(c1, c2, c3, c4) -> StructExpression:; """"""Performs chi-squared test of independence on a 2x2 contingency table. Examples; --------. >>> hl.eval(hl.chi_squared_test(10, 10, 10, 10)); Struct(p_value=1.0, odds_ratio=1.0). >>> hl.eval(hl.chi_squared_test(51, 43, 22, 92)); Struct(p_value=1.4626257805267089e-07, odds_ratio=4.959830866807611). Notes; -----; The odds ratio is given by ``(c1 / c2) / (c3 / c4)``. Returned fields may be ``nan`` or ``inf``. Parameters; ----------; c1 : int or :class:`.Expression` of",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:24318,Modifiability,variab,variable,24318,".. ]); ... ); >>> hl.eval(hl.cochran_mantel_haenszel_test(a, b, c, d)); Struct(test_statistic=0.2188830334629822, p_value=0.6398923118508772). Notes; -----; See the `Wikipedia article <https://en.m.wikipedia.org/wiki/Cochran%E2%80%93Mantel%E2%80%93Haenszel_statistics>`_; for more details. Parameters; ----------; a : :class:`.ArrayExpression` of type :py:data:`.tint64`; Values for the upper-left cell in the contingency tables.; b : :class:`.ArrayExpression` of type :py:data:`.tint64`; Values for the upper-right cell in the contingency tables.; c : :class:`.ArrayExpression` of type :py:data:`.tint64`; Values for the lower-left cell in the contingency tables.; d : :class:`.ArrayExpression` of type :py:data:`.tint64`; Values for the lower-right cell in the contingency tables. Returns; -------; :class:`.StructExpression`; A :class:`.tstruct` expression with two fields, `test_statistic`; (:py:data:`.tfloat64`) and `p_value` (:py:data:`.tfloat64`).; """"""; # The variable names below correspond to the notation used in the Wikipedia article.; # https://en.m.wikipedia.org/wiki/Cochran%E2%80%93Mantel%E2%80%93Haenszel_statistics; n1 = hl.zip(a, b).map(lambda ab: ab[0] + ab[1]); n2 = hl.zip(c, d).map(lambda cd: cd[0] + cd[1]); m1 = hl.zip(a, c).map(lambda ac: ac[0] + ac[1]); m2 = hl.zip(b, d).map(lambda bd: bd[0] + bd[1]); t = hl.zip(n1, n2).map(lambda nn: nn[0] + nn[1]). def numerator_term(a, n1, m1, t):; return a - n1 * m1 / t. # The numerator comes from the link below, not from the Wikipedia article.; # https://www.biostathandbook.com/cmh.html; numerator = (hl.abs(hl.sum(hl.zip(a, n1, m1, t).map(lambda tup: numerator_term(*tup)))) - 0.5) ** 2. def denominator_term(n1, n2, m1, m2, t):; return n1 * n2 * m1 * m2 / (t**3 - t**2). denominator = hl.sum(hl.zip(n1, n2, m1, m2, t).map(lambda tup: denominator_term(*tup))). test_statistic = numerator / denominator; p_value = pchisqtail(test_statistic, 1); return struct(test_statistic=test_statistic, p_value=p_value). [docs]@typecheck(; col",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:49266,Modifiability,variab,variable-length,49266,"se where the position is ``0`` **AND** the interval is; **left-exclusive** which is normalized to be ``1`` and left-inclusive.; Likewise, in the case where the position is ``END + 1`` **AND**; the interval is **right-exclusive** which is normalized to be ``END``; and right-inclusive. Parameters; ----------; s : str or :class:`.StringExpression`; String to parse.; reference_genome : :class:`str` or :class:`.hail.genetics.ReferenceGenome`; Reference genome to use.; invalid_missing : :class:`.BooleanExpression`; If ``True``, invalid intervals are set to NA rather than causing an exception. Returns; -------; :class:`.IntervalExpression`; """"""; return _func('LocusInterval', tinterval(tlocus(reference_genome)), s, invalid_missing). [docs]@typecheck(alleles=expr_int32, phased=expr_bool); def call(*alleles, phased=False) -> CallExpression:; """"""Construct a call expression. Examples; --------. >>> hl.eval(hl.call(1, 0)); Call(alleles=[0, 1], phased=False). Parameters; ----------; alleles : variable-length args of :obj:`int` or :class:`.Expression` of type :py:data:`.tint32`; List of allele indices.; phased : :obj:`bool`; If ``True``, preserve the order of `alleles`. Returns; -------; :class:`.CallExpression`; """"""; if builtins.len(alleles) > 2:; raise NotImplementedError(""'call' supports a maximum of 2 alleles.""); return _func('Call', tcall, *alleles, phased). [docs]@typecheck(gt_index=expr_int32); def unphased_diploid_gt_index_call(gt_index) -> CallExpression:; """"""Construct an unphased, diploid call from a genotype index. Examples; --------. >>> hl.eval(hl.unphased_diploid_gt_index_call(4)); Call(alleles=[1, 2], phased=False). Parameters; ----------; gt_index : :obj:`int` or :class:`.Expression` of type :py:data:`.tint32`; Unphased, diploid genotype index. Returns; -------; :class:`.CallExpression`; """"""; return _func('UnphasedDiploidGtIndexCall', tcall, to_expr(gt_index)). [docs]@typecheck(s=expr_str); def parse_call(s) -> CallExpression:; """"""Construct a call expression by par",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:58777,Modifiability,variab,variable-length,58777,"xpr_float64))); @ndarray_broadcasting; def expit(x) -> Float64Expression:; """"""The logistic sigmoid function. .. math::. \textrm{expit}(x) = \frac{1}{1 + e^{-x}}. Examples; --------; >>> hl.eval(hl.expit(.01)); 0.5024999791668749; >>> hl.eval(hl.expit(0.0)); 0.5. Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`; """"""; return hl.if_else(x >= 0, 1 / (1 + hl.exp(-x)), hl.rbind(hl.exp(x), lambda exped: exped / (exped + 1))). [docs]@typecheck(args=expr_any); def coalesce(*args):; """"""Returns the first non-missing value of `args`. Examples; --------. >>> x1 = hl.missing('int'); >>> x2 = 2; >>> hl.eval(hl.coalesce(x1, x2)); 2. Notes; -----; All arguments must have the same type, or must be convertible to a common; type (all numeric, for instance). See Also; --------; :func:`.or_else`. Parameters; ----------; args : variable-length args of :class:`.Expression`. Returns; -------; :class:`.Expression`; """"""; if builtins.len(args) < 1:; raise ValueError(""'coalesce' requires at least one expression argument""); *exprs, success = unify_exprs(*args); if not success:; arg_types = ''.join([f""\n argument {i}: type '{arg.dtype}'"" for i, arg in builtins.enumerate(exprs)]); raise TypeError(f""'coalesce' requires all arguments to have the same type or compatible types"" f""{arg_types}""); indices, aggregations = unify_all(*exprs); return construct_expr(ir.Coalesce(*(e._ir for e in exprs)), exprs[0].dtype, indices, aggregations). [docs]@typecheck(a=expr_any, b=expr_any); def or_else(a, b):; """"""If `a` is missing, return `b`. Examples; --------. >>> hl.eval(hl.or_else(5, 7)); 5. >>> hl.eval(hl.or_else(hl.missing(hl.tint32), 7)); 7. See Also; --------; :func:`.coalesce`. Parameters; ----------; a: :class:`.Expression`; b: :class:`.Expression`. Returns; -------; :class:`.Expression`; """"""; a, b, success = unify_exprs(a, b)",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:64929,Modifiability,variab,variables,64929,"-; :class:`.Expression` of type :py:data:`.tfloat64`; """"""; if ncp is None:; return _func(""pchisqtail"", tfloat64, x, df, lower_tail, log_p); else:; return _func(""pnchisqtail"", tfloat64, x, df, ncp, lower_tail, log_p). PGENCHISQ_RETURN_TYPE = tstruct(value=tfloat64, n_iterations=tint32, converged=tbool, fault=tint32). [docs]@typecheck(; x=expr_float64,; w=expr_array(expr_float64),; k=expr_array(expr_int32),; lam=expr_array(expr_float64),; mu=expr_float64,; sigma=expr_float64,; max_iterations=nullable(expr_int32),; min_accuracy=nullable(expr_float64),; ); def pgenchisq(x, w, k, lam, mu, sigma, *, max_iterations=None, min_accuracy=None) -> Float64Expression:; r""""""The cumulative probability function of a `generalized chi-squared distribution; <https://en.wikipedia.org/wiki/Generalized_chi-squared_distribution>`__. The generalized chi-squared distribution has many interpretations. We share here four; interpretations of the values of this distribution:. 1. A linear combination of normal variables and squares of normal variables. 2. A weighted sum of sums of squares of normally distributed values plus a normally distributed; value. 3. A weighted sum of chi-squared distributed values plus a normally distributed value. 4. A `""quadratic form"" <https://en.wikipedia.org/wiki/Quadratic_form_(statistics)>`__ in a vector; of uncorrelated `standard normal; <https://en.wikipedia.org/wiki/Normal_distribution#Standard_normal_distribution>`__ values. The parameters of this function correspond to the parameters of the third interpretation. .. math::. \begin{aligned}; w &: R^n \quad k : Z^n \quad lam : R^n \quad mu : R \quad sigma : R \\; \\; x &\sim N(mu, sigma^2) \\; y_i &\sim \mathrm{NonCentralChiSquared}(k_i, lam_i) \\; \\; Z &= x + w y^T \\; &= x + \sum_i w_i y_i \\; Z &\sim \mathrm{GeneralizedNonCentralChiSquared}(w, k, lam, mu, sigma); \end{aligned}. The generalized chi-squared distribution often arises when working on linear models with standard; normal noise because the sum of th",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:64961,Modifiability,variab,variables,64961,"-; :class:`.Expression` of type :py:data:`.tfloat64`; """"""; if ncp is None:; return _func(""pchisqtail"", tfloat64, x, df, lower_tail, log_p); else:; return _func(""pnchisqtail"", tfloat64, x, df, ncp, lower_tail, log_p). PGENCHISQ_RETURN_TYPE = tstruct(value=tfloat64, n_iterations=tint32, converged=tbool, fault=tint32). [docs]@typecheck(; x=expr_float64,; w=expr_array(expr_float64),; k=expr_array(expr_int32),; lam=expr_array(expr_float64),; mu=expr_float64,; sigma=expr_float64,; max_iterations=nullable(expr_int32),; min_accuracy=nullable(expr_float64),; ); def pgenchisq(x, w, k, lam, mu, sigma, *, max_iterations=None, min_accuracy=None) -> Float64Expression:; r""""""The cumulative probability function of a `generalized chi-squared distribution; <https://en.wikipedia.org/wiki/Generalized_chi-squared_distribution>`__. The generalized chi-squared distribution has many interpretations. We share here four; interpretations of the values of this distribution:. 1. A linear combination of normal variables and squares of normal variables. 2. A weighted sum of sums of squares of normally distributed values plus a normally distributed; value. 3. A weighted sum of chi-squared distributed values plus a normally distributed value. 4. A `""quadratic form"" <https://en.wikipedia.org/wiki/Quadratic_form_(statistics)>`__ in a vector; of uncorrelated `standard normal; <https://en.wikipedia.org/wiki/Normal_distribution#Standard_normal_distribution>`__ values. The parameters of this function correspond to the parameters of the third interpretation. .. math::. \begin{aligned}; w &: R^n \quad k : Z^n \quad lam : R^n \quad mu : R \quad sigma : R \\; \\; x &\sim N(mu, sigma^2) \\; y_i &\sim \mathrm{NonCentralChiSquared}(k_i, lam_i) \\; \\; Z &= x + w y^T \\; &= x + \sum_i w_i y_i \\; Z &\sim \mathrm{GeneralizedNonCentralChiSquared}(w, k, lam, mu, sigma); \end{aligned}. The generalized chi-squared distribution often arises when working on linear models with standard; normal noise because the sum of th",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:68320,Modifiability,variab,variables,68320," 1], mu=-3, sigma=0).value); 0.516439358616939; >>> hl.eval(hl.pgenchisq(10 , w=[-2, -1], k=[5, 2], lam=[3, 1], mu=-3, sigma=0).value); 1.0; >>> hl.eval(hl.pgenchisq(40 , w=[-2, -1], k=[5, 2], lam=[3, 1], mu=-3, sigma=0).value); 1.0. >>> hl.eval(hl.pgenchisq(-80, w=[1, -10, 2], k=[1, 2, 3], lam=[2, 3, 7], mu=-10, sigma=0).value); 0.14284718767288906; >>> hl.eval(hl.pgenchisq(-20, w=[1, -10, 2], k=[1, 2, 3], lam=[2, 3, 7], mu=-10, sigma=0).value); 0.5950150356303258; >>> hl.eval(hl.pgenchisq(10 , w=[1, -10, 2], k=[1, 2, 3], lam=[2, 3, 7], mu=-10, sigma=0).value); 0.923219534175858; >>> hl.eval(hl.pgenchisq(40 , w=[1, -10, 2], k=[1, 2, 3], lam=[2, 3, 7], mu=-10, sigma=0).value); 0.9971746768781656. Notes; -----. We follow Wikipedia's notational conventions. Some texts refer to the weight vector (our `w`) as; :math:`\lambda` or `lb` and the non-centrality vector (our `lam`) as `nc`. We use the Davies' algorithm which was published as:. `Davies, Robert. ""The distribution of a linear combination of chi-squared random variables.""; Applied Statistics 29 323-333. 1980. <http://www.robertnz.net/pdf/lc_chisq.pdf>`__. Davies included Fortran source code in the original publication. Davies also released a `C; language port <http://www.robertnz.net/QF.htm>`__. Hail's implementation is a fairly direct port; of the C implementation to Scala. Davies provides 39 test cases with the source code. The Hail; tests include all 39 test cases as well as a few additional tests. Davies' website cautions:. The method works well in most situations if you want only modest accuracy, say 0.0001. But; problems may arise if the sum is dominated by one or two terms with a total of only one or; two degrees of freedom and x is small. For an accessible introduction the Generalized Chi-Squared Distribution, we strongly recommend; the introduction of this paper:. `Das, Abhranil; Geisler, Wilson (2020). ""A method to integrate and classify normal; distributions"". <https://arxiv.org/abs/2012.14331>`__. Param",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:72499,Modifiability,variab,variable,72499,"d accuracy was not; achieved. Two indicates the round-off error is possibly significant. """"""; if max_iterations is None:; max_iterations = hl.literal(10_000); if min_accuracy is None:; min_accuracy = hl.literal(1e-5); return _func(""pgenchisq"", PGENCHISQ_RETURN_TYPE, x - mu, w, k, lam, sigma, max_iterations, min_accuracy). [docs]@typecheck(x=expr_float64, mu=expr_float64, sigma=expr_float64, lower_tail=expr_bool, log_p=expr_bool); def pnorm(x, mu=0, sigma=1, lower_tail=True, log_p=False) -> Float64Expression:; """"""The cumulative probability function of a normal distribution with mean; `mu` and standard deviation `sigma`. Returns cumulative probability of; standard normal distribution by default. Examples; --------. >>> hl.eval(hl.pnorm(0)); 0.5. >>> hl.eval(hl.pnorm(1, mu=2, sigma=2)); 0.30853753872598694. >>> hl.eval(hl.pnorm(2, lower_tail=False)); 0.022750131948179212. >>> hl.eval(hl.pnorm(2, log_p=True)); -0.023012909328963493. Notes; -----; Returns the left-tail probability `p` = Prob(:math:`Z < x`) with :math:`Z`; a normal random variable. Defaults to a standard normal random variable. Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64`; mu : float or :class:`.Expression` of type :py:data:`.tfloat64`; Mean (default = 0).; sigma: float or :class:`.Expression` of type :py:data:`.tfloat64`; Standard deviation (default = 1).; lower_tail : bool or :class:`.BooleanExpression`; If ``True``, compute the probability of an outcome at or below `x`,; otherwise greater than `x`.; log_p : bool or :class:`.BooleanExpression`; Return the natural logarithm of the probability. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`; """"""; return _func(""pnorm"", tfloat64, x, mu, sigma, lower_tail, log_p). [docs]@typecheck(x=expr_float64, n=expr_float64, lower_tail=expr_bool, log_p=expr_bool); def pT(x, n, lower_tail=True, log_p=False) -> Float64Expression:; r""""""The cumulative probability function of a `t-distribution; <https://en.wikiped",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:72546,Modifiability,variab,variable,72546,"ficant. """"""; if max_iterations is None:; max_iterations = hl.literal(10_000); if min_accuracy is None:; min_accuracy = hl.literal(1e-5); return _func(""pgenchisq"", PGENCHISQ_RETURN_TYPE, x - mu, w, k, lam, sigma, max_iterations, min_accuracy). [docs]@typecheck(x=expr_float64, mu=expr_float64, sigma=expr_float64, lower_tail=expr_bool, log_p=expr_bool); def pnorm(x, mu=0, sigma=1, lower_tail=True, log_p=False) -> Float64Expression:; """"""The cumulative probability function of a normal distribution with mean; `mu` and standard deviation `sigma`. Returns cumulative probability of; standard normal distribution by default. Examples; --------. >>> hl.eval(hl.pnorm(0)); 0.5. >>> hl.eval(hl.pnorm(1, mu=2, sigma=2)); 0.30853753872598694. >>> hl.eval(hl.pnorm(2, lower_tail=False)); 0.022750131948179212. >>> hl.eval(hl.pnorm(2, log_p=True)); -0.023012909328963493. Notes; -----; Returns the left-tail probability `p` = Prob(:math:`Z < x`) with :math:`Z`; a normal random variable. Defaults to a standard normal random variable. Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64`; mu : float or :class:`.Expression` of type :py:data:`.tfloat64`; Mean (default = 0).; sigma: float or :class:`.Expression` of type :py:data:`.tfloat64`; Standard deviation (default = 1).; lower_tail : bool or :class:`.BooleanExpression`; If ``True``, compute the probability of an outcome at or below `x`,; otherwise greater than `x`.; log_p : bool or :class:`.BooleanExpression`; Return the natural logarithm of the probability. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`; """"""; return _func(""pnorm"", tfloat64, x, mu, sigma, lower_tail, log_p). [docs]@typecheck(x=expr_float64, n=expr_float64, lower_tail=expr_bool, log_p=expr_bool); def pT(x, n, lower_tail=True, log_p=False) -> Float64Expression:; r""""""The cumulative probability function of a `t-distribution; <https://en.wikipedia.org/wiki/Student%27s_t-distribution>`__ with; `n` degrees of freedom. Examples;",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:73860,Modifiability,variab,variable,73860,"ault = 1).; lower_tail : bool or :class:`.BooleanExpression`; If ``True``, compute the probability of an outcome at or below `x`,; otherwise greater than `x`.; log_p : bool or :class:`.BooleanExpression`; Return the natural logarithm of the probability. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`; """"""; return _func(""pnorm"", tfloat64, x, mu, sigma, lower_tail, log_p). [docs]@typecheck(x=expr_float64, n=expr_float64, lower_tail=expr_bool, log_p=expr_bool); def pT(x, n, lower_tail=True, log_p=False) -> Float64Expression:; r""""""The cumulative probability function of a `t-distribution; <https://en.wikipedia.org/wiki/Student%27s_t-distribution>`__ with; `n` degrees of freedom. Examples; --------. >>> hl.eval(hl.pT(0, 10)); 0.5. >>> hl.eval(hl.pT(1, 10)); 0.82955343384897. >>> hl.eval(hl.pT(1, 10, lower_tail=False)); 0.17044656615103004. >>> hl.eval(hl.pT(1, 10, log_p=True)); -0.186867754489647. Notes; -----; If `lower_tail` is true, returns Prob(:math:`X \leq` `x`) where :math:`X` is; a t-distributed random variable with `n` degrees of freedom. If `lower_tail`; is false, returns Prob(:math:`X` > `x`). Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64`; n : float or :class:`.Expression` of type :py:data:`.tfloat64`; Degrees of freedom of the t-distribution.; lower_tail : bool or :class:`.BooleanExpression`; If ``True``, compute the probability of an outcome at or below `x`,; otherwise greater than `x`.; log_p : bool or :class:`.BooleanExpression`; Return the natural logarithm of the probability. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`. """"""; return _func(""pT"", tfloat64, x, n, lower_tail, log_p). [docs]@typecheck(x=expr_float64, df1=expr_float64, df2=expr_float64, lower_tail=expr_bool, log_p=expr_bool); def pF(x, df1, df2, lower_tail=True, log_p=False) -> Float64Expression:; r""""""The cumulative probability function of a `F-distribution; <https://en.wikipedia.org/wiki/F-distribution>`__ with ",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:75186,Modifiability,variab,variable,75186,"ail : bool or :class:`.BooleanExpression`; If ``True``, compute the probability of an outcome at or below `x`,; otherwise greater than `x`.; log_p : bool or :class:`.BooleanExpression`; Return the natural logarithm of the probability. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`. """"""; return _func(""pT"", tfloat64, x, n, lower_tail, log_p). [docs]@typecheck(x=expr_float64, df1=expr_float64, df2=expr_float64, lower_tail=expr_bool, log_p=expr_bool); def pF(x, df1, df2, lower_tail=True, log_p=False) -> Float64Expression:; r""""""The cumulative probability function of a `F-distribution; <https://en.wikipedia.org/wiki/F-distribution>`__ with parameters; `df1` and `df2`. Examples; --------. >>> hl.eval(hl.pF(0, 3, 10)); 0.0. >>> hl.eval(hl.pF(1, 3, 10)); 0.5676627969783028. >>> hl.eval(hl.pF(1, 3, 10, lower_tail=False)); 0.4323372030216972. >>> hl.eval(hl.pF(1, 3, 10, log_p=True)); -0.566227703842908. Notes; -----; If `lower_tail` is true, returns Prob(:math:`X \leq` `x`) where :math:`X` is; a random variable with distribution :math:`F`(df1, df2). If `lower_tail`; is false, returns Prob(:math:`X` > `x`). Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64`; df1 : float or :class:`.Expression` of type :py:data:`.tfloat64`; Parameter of the F-distribution; df2 : float or :class:`.Expression` of type :py:data:`.tfloat64`; Parameter of the F-distribution; lower_tail : bool or :class:`.BooleanExpression`; If ``True``, compute the probability of an outcome at or below `x`,; otherwise greater than `x`.; log_p : bool or :class:`.BooleanExpression`; Return the natural logarithm of the probability. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`; """"""; return _func(""pF"", tfloat64, x, df1, df2, lower_tail, log_p). [docs]@typecheck(x=expr_float64, lamb=expr_float64, lower_tail=expr_bool, log_p=expr_bool); def ppois(x, lamb, lower_tail=True, log_p=False) -> Float64Expression:; r""""""The cumulative probability function",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:76365,Modifiability,variab,variable,76365," :class:`.Expression` of type :py:data:`.tfloat64`; df1 : float or :class:`.Expression` of type :py:data:`.tfloat64`; Parameter of the F-distribution; df2 : float or :class:`.Expression` of type :py:data:`.tfloat64`; Parameter of the F-distribution; lower_tail : bool or :class:`.BooleanExpression`; If ``True``, compute the probability of an outcome at or below `x`,; otherwise greater than `x`.; log_p : bool or :class:`.BooleanExpression`; Return the natural logarithm of the probability. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`; """"""; return _func(""pF"", tfloat64, x, df1, df2, lower_tail, log_p). [docs]@typecheck(x=expr_float64, lamb=expr_float64, lower_tail=expr_bool, log_p=expr_bool); def ppois(x, lamb, lower_tail=True, log_p=False) -> Float64Expression:; r""""""The cumulative probability function of a Poisson distribution. Examples; --------. >>> hl.eval(hl.ppois(2, 1)); 0.9196986029286058. Notes; -----; If `lower_tail` is true, returns Prob(:math:`X \leq` `x`) where :math:`X` is a; Poisson random variable with rate parameter `lamb`. If `lower_tail` is false,; returns Prob(:math:`X` > `x`). Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64`; lamb : float or :class:`.Expression` of type :py:data:`.tfloat64`; Rate parameter of Poisson distribution.; lower_tail : bool or :class:`.BooleanExpression`; If ``True``, compute the probability of an outcome at or below `x`,; otherwise greater than `x`.; log_p : bool or :class:`.BooleanExpression`; Return the natural logarithm of the probability. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`; """"""; return _func(""ppois"", tfloat64, x, lamb, lower_tail, log_p). [docs]@typecheck(p=expr_float64, df=expr_float64, ncp=nullable(expr_float64), lower_tail=expr_bool, log_p=expr_bool); def qchisqtail(p, df, ncp=None, lower_tail=False, log_p=False) -> Float64Expression:; """"""The quantile function of a chi-squared distribution with `df` degrees of; freedom, inver",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:77762,Modifiability,variab,variable,77762,"he probability of an outcome at or below `x`,; otherwise greater than `x`.; log_p : bool or :class:`.BooleanExpression`; Return the natural logarithm of the probability. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`; """"""; return _func(""ppois"", tfloat64, x, lamb, lower_tail, log_p). [docs]@typecheck(p=expr_float64, df=expr_float64, ncp=nullable(expr_float64), lower_tail=expr_bool, log_p=expr_bool); def qchisqtail(p, df, ncp=None, lower_tail=False, log_p=False) -> Float64Expression:; """"""The quantile function of a chi-squared distribution with `df` degrees of; freedom, inverts :func:`~.pchisqtail`. Examples; --------. >>> hl.eval(hl.qchisqtail(0.05, 2)); 5.991464547107979. >>> hl.eval(hl.qchisqtail(0.05, 2, ncp=2)); 10.838131614372958. >>> hl.eval(hl.qchisqtail(0.05, 2, lower_tail=True)); 0.10258658877510107. >>> hl.eval(hl.qchisqtail(hl.log(0.05), 2, log_p=True)); 5.991464547107979. Notes; -----; Returns right-quantile `x` for which `p` = Prob(:math:`Z^2` > x) with; :math:`Z^2` a chi-squared random variable with degrees of freedom specified; by `df`. The probability `p` must satisfy 0 < `p` < 1. Parameters; ----------; p : float or :class:`.Expression` of type :py:data:`.tfloat64`; Probability.; df : float or :class:`.Expression` of type :py:data:`.tfloat64`; Degrees of freedom.; ncp: float or :class:`.Expression` of type :py:data:`.tfloat64`; Corresponds to `ncp` parameter in :func:`.pchisqtail`.; lower_tail : bool or :class:`.BooleanExpression`; Corresponds to `lower_tail` parameter in :func:`.pchisqtail`.; log_p : bool or :class:`.BooleanExpression`; Exponentiate `p`, corresponds to `log_p` parameter in :func:`.pchisqtail`. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`; """"""; if ncp is None:; return _func(""qchisqtail"", tfloat64, p, df, lower_tail, log_p); else:; return _func(""qnchisqtail"", tfloat64, p, df, ncp, lower_tail, log_p). [docs]@typecheck(p=expr_float64, mu=expr_float64, sigma=expr_float64, lower_tail=expr_bool, lo",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:79387,Modifiability,variab,variable,79387,"`log_p` parameter in :func:`.pchisqtail`. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`; """"""; if ncp is None:; return _func(""qchisqtail"", tfloat64, p, df, lower_tail, log_p); else:; return _func(""qnchisqtail"", tfloat64, p, df, ncp, lower_tail, log_p). [docs]@typecheck(p=expr_float64, mu=expr_float64, sigma=expr_float64, lower_tail=expr_bool, log_p=expr_bool); def qnorm(p, mu=0, sigma=1, lower_tail=True, log_p=False) -> Float64Expression:; """"""The quantile function of a normal distribution with mean `mu` and; standard deviation `sigma`, inverts :func:`~.pnorm`. Returns quantile of; standard normal distribution by default. Examples; --------. >>> hl.eval(hl.qnorm(0.90)); 1.2815515655446008. >>> hl.eval(hl.qnorm(0.90, mu=1, sigma=2)); 3.5631031310892016. >>> hl.eval(hl.qnorm(0.90, lower_tail=False)); -1.2815515655446008. >>> hl.eval(hl.qnorm(hl.log(0.90), log_p=True)); 1.2815515655446008. Notes; -----; Returns left-quantile `x` for which p = Prob(:math:`Z` < x) with :math:`Z`; a normal random variable with mean `mu` and standard deviation `sigma`.; Defaults to a standard normal random variable, and the probability `p` must; satisfy 0 < `p` < 1. Parameters; ----------; p : float or :class:`.Expression` of type :py:data:`.tfloat64`; Probability.; mu : float or :class:`.Expression` of type :py:data:`.tfloat64`; Mean (default = 0).; sigma: float or :class:`.Expression` of type :py:data:`.tfloat64`; Standard deviation (default = 1).; lower_tail : bool or :class:`.BooleanExpression`; Corresponds to `lower_tail` parameter in :func:`.pnorm`.; log_p : bool or :class:`.BooleanExpression`; Exponentiate `p`, corresponds to `log_p` parameter in :func:`.pnorm`. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`; """"""; return _func(""qnorm"", tfloat64, p, mu, sigma, lower_tail, log_p). [docs]@typecheck(p=expr_float64, lamb=expr_float64, lower_tail=expr_bool, log_p=expr_bool); def qpois(p, lamb, lower_tail=True, log_p=False) -> Float64Expression:; r""",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:79481,Modifiability,variab,variable,79481,":; return _func(""qchisqtail"", tfloat64, p, df, lower_tail, log_p); else:; return _func(""qnchisqtail"", tfloat64, p, df, ncp, lower_tail, log_p). [docs]@typecheck(p=expr_float64, mu=expr_float64, sigma=expr_float64, lower_tail=expr_bool, log_p=expr_bool); def qnorm(p, mu=0, sigma=1, lower_tail=True, log_p=False) -> Float64Expression:; """"""The quantile function of a normal distribution with mean `mu` and; standard deviation `sigma`, inverts :func:`~.pnorm`. Returns quantile of; standard normal distribution by default. Examples; --------. >>> hl.eval(hl.qnorm(0.90)); 1.2815515655446008. >>> hl.eval(hl.qnorm(0.90, mu=1, sigma=2)); 3.5631031310892016. >>> hl.eval(hl.qnorm(0.90, lower_tail=False)); -1.2815515655446008. >>> hl.eval(hl.qnorm(hl.log(0.90), log_p=True)); 1.2815515655446008. Notes; -----; Returns left-quantile `x` for which p = Prob(:math:`Z` < x) with :math:`Z`; a normal random variable with mean `mu` and standard deviation `sigma`.; Defaults to a standard normal random variable, and the probability `p` must; satisfy 0 < `p` < 1. Parameters; ----------; p : float or :class:`.Expression` of type :py:data:`.tfloat64`; Probability.; mu : float or :class:`.Expression` of type :py:data:`.tfloat64`; Mean (default = 0).; sigma: float or :class:`.Expression` of type :py:data:`.tfloat64`; Standard deviation (default = 1).; lower_tail : bool or :class:`.BooleanExpression`; Corresponds to `lower_tail` parameter in :func:`.pnorm`.; log_p : bool or :class:`.BooleanExpression`; Exponentiate `p`, corresponds to `log_p` parameter in :func:`.pnorm`. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`; """"""; return _func(""qnorm"", tfloat64, p, mu, sigma, lower_tail, log_p). [docs]@typecheck(p=expr_float64, lamb=expr_float64, lower_tail=expr_bool, log_p=expr_bool); def qpois(p, lamb, lower_tail=True, log_p=False) -> Float64Expression:; r""""""The quantile function of a Poisson distribution with rate parameter; `lamb`, inverts :func:`~.ppois`. Examples; --------. >>> hl.",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:80660,Modifiability,variab,variable,80660,":py:data:`.tfloat64`; Probability.; mu : float or :class:`.Expression` of type :py:data:`.tfloat64`; Mean (default = 0).; sigma: float or :class:`.Expression` of type :py:data:`.tfloat64`; Standard deviation (default = 1).; lower_tail : bool or :class:`.BooleanExpression`; Corresponds to `lower_tail` parameter in :func:`.pnorm`.; log_p : bool or :class:`.BooleanExpression`; Exponentiate `p`, corresponds to `log_p` parameter in :func:`.pnorm`. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`; """"""; return _func(""qnorm"", tfloat64, p, mu, sigma, lower_tail, log_p). [docs]@typecheck(p=expr_float64, lamb=expr_float64, lower_tail=expr_bool, log_p=expr_bool); def qpois(p, lamb, lower_tail=True, log_p=False) -> Float64Expression:; r""""""The quantile function of a Poisson distribution with rate parameter; `lamb`, inverts :func:`~.ppois`. Examples; --------. >>> hl.eval(hl.qpois(0.99, 1)); 4. Notes; -----; Returns the smallest integer :math:`x` such that Prob(:math:`X \leq x`) :math:`\geq` `p` where :math:`X`; is a Poisson random variable with rate parameter `lambda`. Parameters; ----------; p : float or :class:`.Expression` of type :py:data:`.tfloat64`; lamb : float or :class:`.Expression` of type :py:data:`.tfloat64`; Rate parameter of Poisson distribution.; lower_tail : bool or :class:`.BooleanExpression`; Corresponds to `lower_tail` parameter in inverse :func:`.ppois`.; log_p : bool or :class:`.BooleanExpression`; Exponentiate `p` before testing. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`; """"""; return _func(""qpois"", tint32, p, lamb, lower_tail, log_p). [docs]@typecheck(start=expr_int32, stop=nullable(expr_int32), step=expr_int32); def range(start, stop=None, step=1) -> ArrayNumericExpression:; """"""Returns an array of integers from `start` to `stop` by `step`. Examples; --------. >>> hl.eval(hl.range(10)); [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]. >>> hl.eval(hl.range(3, 10)); [3, 4, 5, 6, 7, 8, 9]. >>> hl.eval(hl.range(0, 10, step=3)); [0, 3, ",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:95512,Modifiability,polymorphi,polymorphism,95512,"mericExpression`. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`; """"""; return _func(""sqrt"", tfloat64, x). [docs]@typecheck(x=expr_array(expr_float64), y=expr_array(expr_float64)); def corr(x, y) -> Float64Expression:; """"""Compute the; `Pearson correlation coefficient <https://en.wikipedia.org/wiki/Pearson_correlation_coefficient>`__; between `x` and `y`. Examples; --------; >>> hl.eval(hl.corr([1, 2, 4], [2, 3, 1])); -0.6546536707079772. Notes; -----; Only indices where both `x` and `y` are non-missing will be included in the; calculation. If `x` and `y` have length zero, then the result is missing. Parameters; ----------; x : :class:`.Expression` of type ``array<tfloat64>``; y : :class:`.Expression` of type ``array<tfloat64>``. Returns; -------; :class:`.Float64Expression`; """"""; return _func(""corr"", tfloat64, x, y). [docs]@typecheck(ref=expr_str, alt=expr_str); @ir.udf(tstr, tstr); def numeric_allele_type(ref, alt) -> Int32Expression:; """"""Returns the type of the polymorphism as an integer. The value returned; is the integer value of :class:`.AlleleType` representing that kind of; polymorphism. Examples; --------. >>> hl.eval(hl.numeric_allele_type('A', 'T')) == AlleleType.SNP; True. Notes; -----; The values of :class:`.AlleleType` are not stable and thus should not be; relied upon across hail versions.; """"""; _base_regex = ""^([ACGTNM])+$""; _symbolic_regex = r""(^\.)|(\.$)|(^<)|(>$)|(\[)|(\])""; return hl.bind(; lambda r, a: hl.if_else(; r.matches(_base_regex),; hl.case(); .when(; a.matches(_base_regex),; hl.case(); .when(; r.length() == a.length(),; hl.if_else(; r.length() == 1,; hl.if_else(r != a, AlleleType.SNP, AlleleType.UNKNOWN),; hl.if_else(hamming(r, a) == 1, AlleleType.SNP, AlleleType.MNP),; ),; ); .when((r.length() < a.length()) & (r[0] == a[0]) & a.endswith(r[1:]), AlleleType.INSERTION); .when((r[0] == a[0]) & r.endswith(a[1:]), AlleleType.DELETION); .default(AlleleType.COMPLEX),; ); .when(a == '*', A",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:95632,Modifiability,polymorphi,polymorphism,95632,"""sqrt"", tfloat64, x). [docs]@typecheck(x=expr_array(expr_float64), y=expr_array(expr_float64)); def corr(x, y) -> Float64Expression:; """"""Compute the; `Pearson correlation coefficient <https://en.wikipedia.org/wiki/Pearson_correlation_coefficient>`__; between `x` and `y`. Examples; --------; >>> hl.eval(hl.corr([1, 2, 4], [2, 3, 1])); -0.6546536707079772. Notes; -----; Only indices where both `x` and `y` are non-missing will be included in the; calculation. If `x` and `y` have length zero, then the result is missing. Parameters; ----------; x : :class:`.Expression` of type ``array<tfloat64>``; y : :class:`.Expression` of type ``array<tfloat64>``. Returns; -------; :class:`.Float64Expression`; """"""; return _func(""corr"", tfloat64, x, y). [docs]@typecheck(ref=expr_str, alt=expr_str); @ir.udf(tstr, tstr); def numeric_allele_type(ref, alt) -> Int32Expression:; """"""Returns the type of the polymorphism as an integer. The value returned; is the integer value of :class:`.AlleleType` representing that kind of; polymorphism. Examples; --------. >>> hl.eval(hl.numeric_allele_type('A', 'T')) == AlleleType.SNP; True. Notes; -----; The values of :class:`.AlleleType` are not stable and thus should not be; relied upon across hail versions.; """"""; _base_regex = ""^([ACGTNM])+$""; _symbolic_regex = r""(^\.)|(\.$)|(^<)|(>$)|(\[)|(\])""; return hl.bind(; lambda r, a: hl.if_else(; r.matches(_base_regex),; hl.case(); .when(; a.matches(_base_regex),; hl.case(); .when(; r.length() == a.length(),; hl.if_else(; r.length() == 1,; hl.if_else(r != a, AlleleType.SNP, AlleleType.UNKNOWN),; hl.if_else(hamming(r, a) == 1, AlleleType.SNP, AlleleType.MNP),; ),; ); .when((r.length() < a.length()) & (r[0] == a[0]) & a.endswith(r[1:]), AlleleType.INSERTION); .when((r[0] == a[0]) & r.endswith(a[1:]), AlleleType.DELETION); .default(AlleleType.COMPLEX),; ); .when(a == '*', AlleleType.STAR); .when(a.matches(_symbolic_regex), AlleleType.SYMBOLIC); .default(AlleleType.UNKNOWN),; AlleleType.UNKNOWN,; ),; ref,; alt,; ).",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:97099,Modifiability,polymorphi,polymorphism,97099,"; .when(; a.matches(_base_regex),; hl.case(); .when(; r.length() == a.length(),; hl.if_else(; r.length() == 1,; hl.if_else(r != a, AlleleType.SNP, AlleleType.UNKNOWN),; hl.if_else(hamming(r, a) == 1, AlleleType.SNP, AlleleType.MNP),; ),; ); .when((r.length() < a.length()) & (r[0] == a[0]) & a.endswith(r[1:]), AlleleType.INSERTION); .when((r[0] == a[0]) & r.endswith(a[1:]), AlleleType.DELETION); .default(AlleleType.COMPLEX),; ); .when(a == '*', AlleleType.STAR); .when(a.matches(_symbolic_regex), AlleleType.SYMBOLIC); .default(AlleleType.UNKNOWN),; AlleleType.UNKNOWN,; ),; ref,; alt,; ). @deprecated(version='0.2.129', reason=""Replaced by the public numeric_allele_type""); @typecheck(ref=expr_str, alt=expr_str); def _num_allele_type(ref, alt) -> Int32Expression:; """"""Provided for backwards compatibility, don't use it in new code, or; within the hail library itself; """"""; return numeric_allele_type(ref, alt). [docs]@typecheck(ref=expr_str, alt=expr_str); def is_snp(ref, alt) -> BooleanExpression:; """"""Returns ``True`` if the alleles constitute a single nucleotide polymorphism. Examples; --------. >>> hl.eval(hl.is_snp('A', 'T')); True. Parameters; ----------; ref : :class:`.StringExpression`; Reference allele.; alt : :class:`.StringExpression`; Alternate allele. Returns; -------; :class:`.BooleanExpression`; """"""; return numeric_allele_type(ref, alt) == AlleleType.SNP. [docs]@typecheck(ref=expr_str, alt=expr_str); def is_mnp(ref, alt) -> BooleanExpression:; """"""Returns ``True`` if the alleles constitute a multiple nucleotide polymorphism. Examples; --------. >>> hl.eval(hl.is_mnp('AA', 'GT')); True. Parameters; ----------; ref : :class:`.StringExpression`; Reference allele.; alt : :class:`.StringExpression`; Alternate allele. Returns; -------; :class:`.BooleanExpression`; """"""; return numeric_allele_type(ref, alt) == AlleleType.MNP. [docs]@typecheck(ref=expr_str, alt=expr_str); def is_transition(ref, alt) -> BooleanExpression:; """"""Returns ``True`` if the alleles constitute a t",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:97568,Modifiability,polymorphi,polymorphism,97568,"hen(a.matches(_symbolic_regex), AlleleType.SYMBOLIC); .default(AlleleType.UNKNOWN),; AlleleType.UNKNOWN,; ),; ref,; alt,; ). @deprecated(version='0.2.129', reason=""Replaced by the public numeric_allele_type""); @typecheck(ref=expr_str, alt=expr_str); def _num_allele_type(ref, alt) -> Int32Expression:; """"""Provided for backwards compatibility, don't use it in new code, or; within the hail library itself; """"""; return numeric_allele_type(ref, alt). [docs]@typecheck(ref=expr_str, alt=expr_str); def is_snp(ref, alt) -> BooleanExpression:; """"""Returns ``True`` if the alleles constitute a single nucleotide polymorphism. Examples; --------. >>> hl.eval(hl.is_snp('A', 'T')); True. Parameters; ----------; ref : :class:`.StringExpression`; Reference allele.; alt : :class:`.StringExpression`; Alternate allele. Returns; -------; :class:`.BooleanExpression`; """"""; return numeric_allele_type(ref, alt) == AlleleType.SNP. [docs]@typecheck(ref=expr_str, alt=expr_str); def is_mnp(ref, alt) -> BooleanExpression:; """"""Returns ``True`` if the alleles constitute a multiple nucleotide polymorphism. Examples; --------. >>> hl.eval(hl.is_mnp('AA', 'GT')); True. Parameters; ----------; ref : :class:`.StringExpression`; Reference allele.; alt : :class:`.StringExpression`; Alternate allele. Returns; -------; :class:`.BooleanExpression`; """"""; return numeric_allele_type(ref, alt) == AlleleType.MNP. [docs]@typecheck(ref=expr_str, alt=expr_str); def is_transition(ref, alt) -> BooleanExpression:; """"""Returns ``True`` if the alleles constitute a transition. Examples; --------. >>> hl.eval(hl.is_transition('A', 'T')); False. >>> hl.eval(hl.is_transition('AAA', 'AGA')); True. Parameters; ----------; ref : :class:`.StringExpression`; Reference allele.; alt : :class:`.StringExpression`; Alternate allele. Returns; -------; :class:`.BooleanExpression`; """"""; return is_snp(ref, alt) & _is_snp_transition(ref, alt). [docs]@typecheck(ref=expr_str, alt=expr_str); def is_transversion(ref, alt) -> BooleanExpression:; """"",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:101363,Modifiability,polymorphi,polymorphism,101363," alt) -> BooleanExpression:; """"""Returns ``True`` if the alleles constitute an insertion or deletion. Examples; --------. >>> hl.eval(hl.is_indel('ATT', 'A')); True. Parameters; ----------; ref : :class:`.StringExpression`; Reference allele.; alt : :class:`.StringExpression`; Alternate allele. Returns; -------; :class:`.BooleanExpression`; """"""; return hl.bind(lambda t: (t == AlleleType.INSERTION) | (t == AlleleType.DELETION), numeric_allele_type(ref, alt)). [docs]@typecheck(ref=expr_str, alt=expr_str); def is_star(ref, alt) -> BooleanExpression:; """"""Returns ``True`` if the alleles constitute an upstream deletion. Examples; --------. >>> hl.eval(hl.is_star('A', '*')); True. Parameters; ----------; ref : :class:`.StringExpression`; Reference allele.; alt : :class:`.StringExpression`; Alternate allele. Returns; -------; :class:`.BooleanExpression`; """"""; return numeric_allele_type(ref, alt) == AlleleType.STAR. [docs]@typecheck(ref=expr_str, alt=expr_str); def is_complex(ref, alt) -> BooleanExpression:; """"""Returns ``True`` if the alleles constitute a complex polymorphism. Examples; --------. >>> hl.eval(hl.is_complex('ATT', 'GCAC')); True. Parameters; ----------; ref : :class:`.StringExpression`; Reference allele.; alt : :class:`.StringExpression`; Alternate allele. Returns; -------; :class:`.BooleanExpression`; """"""; return numeric_allele_type(ref, alt) == AlleleType.COMPLEX. [docs]@typecheck(ref=expr_str, alt=expr_str); def is_strand_ambiguous(ref, alt) -> BooleanExpression:; """"""Returns ``True`` if the alleles are strand ambiguous. Strand ambiguous allele pairs are ``A/T``, ``T/A``,; ``C/G``, and ``G/C`` where the first allele is `ref`; and the second allele is `alt`. Examples; --------. >>> hl.eval(hl.is_strand_ambiguous('A', 'T')); True. Parameters; ----------; ref : :class:`.StringExpression`; Reference allele.; alt : :class:`.StringExpression`; Alternate allele. Returns; -------; :class:`.BooleanExpression`; """"""; alleles = hl.literal({('A', 'T'), ('T', 'A'), ('G', 'C",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:102470,Modifiability,polymorphi,polymorphism,102470,"x('ATT', 'GCAC')); True. Parameters; ----------; ref : :class:`.StringExpression`; Reference allele.; alt : :class:`.StringExpression`; Alternate allele. Returns; -------; :class:`.BooleanExpression`; """"""; return numeric_allele_type(ref, alt) == AlleleType.COMPLEX. [docs]@typecheck(ref=expr_str, alt=expr_str); def is_strand_ambiguous(ref, alt) -> BooleanExpression:; """"""Returns ``True`` if the alleles are strand ambiguous. Strand ambiguous allele pairs are ``A/T``, ``T/A``,; ``C/G``, and ``G/C`` where the first allele is `ref`; and the second allele is `alt`. Examples; --------. >>> hl.eval(hl.is_strand_ambiguous('A', 'T')); True. Parameters; ----------; ref : :class:`.StringExpression`; Reference allele.; alt : :class:`.StringExpression`; Alternate allele. Returns; -------; :class:`.BooleanExpression`; """"""; alleles = hl.literal({('A', 'T'), ('T', 'A'), ('G', 'C'), ('C', 'G')}); return alleles.contains((ref, alt)). [docs]@typecheck(ref=expr_str, alt=expr_str); def allele_type(ref, alt) -> StringExpression:; """"""Returns the type of the polymorphism as a string. Examples; --------. >>> hl.eval(hl.allele_type('A', 'T')); 'SNP'. >>> hl.eval(hl.allele_type('ATT', 'A')); 'Deletion'. Notes; -----; The possible return values are:; - ``""SNP""``; - ``""MNP""``; - ``""Insertion""``; - ``""Deletion""``; - ``""Complex""``; - ``""Star""``; - ``""Symbolic""``; - ``""Unknown""``. Parameters; ----------; ref : :class:`.StringExpression`; Reference allele.; alt : :class:`.StringExpression`; Alternate allele. Returns; -------; :class:`.StringExpression`; """"""; return hl.literal(AlleleType.strings())[numeric_allele_type(ref, alt)]. [docs]@typecheck(s1=expr_str, s2=expr_str); def hamming(s1, s2) -> Int32Expression:; """"""Returns the Hamming distance between the two strings. Examples; --------. >>> hl.eval(hl.hamming('ATATA', 'ATGCA')); 2. >>> hl.eval(hl.hamming('abcdefg', 'zzcdefz')); 3. Notes; -----; This method will fail if the two strings have different length. Parameters; ----------; s1 : :class:`.Strin",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:116743,Modifiability,variab,variable-length,116743,"e in builtins.zip(uids, types)]); indices, aggregations = unify_all(*streams); behavior = 'ExtendNA' if fill_missing else 'TakeMinLength'; return construct_expr(; ir.StreamZip([s._ir for s in streams], uids, body_ir, behavior),; tstream(ttuple(*(s.dtype.element_type for s in streams))),; indices,; aggregations,; ). [docs]@typecheck(arrays=expr_array(), fill_missing=bool); def zip(*arrays, fill_missing: bool = False) -> ArrayExpression:; """"""Zip together arrays into a single array. Examples; --------. >>> hl.eval(hl.zip([1, 2, 3], [4, 5, 6])); [(1, 4), (2, 5), (3, 6)]. If the arrays are different lengths, the behavior is decided by the `fill_missing` parameter. >>> hl.eval(hl.zip([1], [10, 20], [100, 200, 300])); [(1, 10, 100)]. >>> hl.eval(hl.zip([1], [10, 20], [100, 200, 300], fill_missing=True)); [(1, 10, 100), (None, 20, 200), (None, None, 300)]. Notes; -----; The element type of the resulting array is a :class:`.ttuple` with a field; for each array. Parameters; ----------; arrays: : variable-length args of :class:`.ArrayExpression`; Array expressions.; fill_missing : :obj:`bool`; If ``False``, return an array with length equal to the shortest length; of the `arrays`. If ``True``, return an array equal to the longest; length of the `arrays`, by extending the shorter arrays with missing; values. Returns; -------; :class:`.ArrayExpression`; """"""; return _zip_streams(*(a._to_stream() for a in arrays), fill_missing=fill_missing).to_array(). def _zip_func(*arrays, fill_missing=False, f):; n_arrays = builtins.len(arrays); uids = [Env.get_uid() for _ in builtins.range(n_arrays)]; refs = [; construct_expr(ir.Ref(uid, a.dtype.element_type), a.dtype.element_type, a._indices, a._aggregations); for uid, a in builtins.zip(uids, arrays); ]; body_result = f(*refs); indices, aggregations = unify_all(*arrays, body_result); behavior = 'ExtendNA' if fill_missing else 'TakeMinLength'; return construct_expr(; ir.toArray(ir.StreamZip([ir.toStream(a._ir) for a in arrays], uids, body_resu",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:117009,Modifiability,extend,extending,117009,"e.element_type for s in streams))),; indices,; aggregations,; ). [docs]@typecheck(arrays=expr_array(), fill_missing=bool); def zip(*arrays, fill_missing: bool = False) -> ArrayExpression:; """"""Zip together arrays into a single array. Examples; --------. >>> hl.eval(hl.zip([1, 2, 3], [4, 5, 6])); [(1, 4), (2, 5), (3, 6)]. If the arrays are different lengths, the behavior is decided by the `fill_missing` parameter. >>> hl.eval(hl.zip([1], [10, 20], [100, 200, 300])); [(1, 10, 100)]. >>> hl.eval(hl.zip([1], [10, 20], [100, 200, 300], fill_missing=True)); [(1, 10, 100), (None, 20, 200), (None, None, 300)]. Notes; -----; The element type of the resulting array is a :class:`.ttuple` with a field; for each array. Parameters; ----------; arrays: : variable-length args of :class:`.ArrayExpression`; Array expressions.; fill_missing : :obj:`bool`; If ``False``, return an array with length equal to the shortest length; of the `arrays`. If ``True``, return an array equal to the longest; length of the `arrays`, by extending the shorter arrays with missing; values. Returns; -------; :class:`.ArrayExpression`; """"""; return _zip_streams(*(a._to_stream() for a in arrays), fill_missing=fill_missing).to_array(). def _zip_func(*arrays, fill_missing=False, f):; n_arrays = builtins.len(arrays); uids = [Env.get_uid() for _ in builtins.range(n_arrays)]; refs = [; construct_expr(ir.Ref(uid, a.dtype.element_type), a.dtype.element_type, a._indices, a._aggregations); for uid, a in builtins.zip(uids, arrays); ]; body_result = f(*refs); indices, aggregations = unify_all(*arrays, body_result); behavior = 'ExtendNA' if fill_missing else 'TakeMinLength'; return construct_expr(; ir.toArray(ir.StreamZip([ir.toStream(a._ir) for a in arrays], uids, body_result._ir, behavior)),; tarray(body_result.dtype),; indices,; aggregations,; ). [docs]@typecheck(a=expr_array(), start=expr_int32, index_first=bool); def enumerate(a, start=0, *, index_first=True):; """"""Returns an array of (index, element) tuples. Examples;",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:125612,Modifiability,variab,variable-length,125612,"coercer_from_dtype(unified_typ); indices, aggs = unify_all(*exprs). func_name = name; if filter_missing:; func_name += '_ignore_missing'; if filter_nan and unified_typ in (tfloat32, tfloat64):; func_name = 'nan' + func_name; return construct_expr(; functools.reduce(lambda l, r: ir.Apply(func_name, unified_typ, l, r), [ec.coerce(e)._ir for e in exprs]),; unified_typ,; indices,; aggs,; ). [docs]@typecheck(; exprs=expr_oneof(expr_numeric, expr_set(expr_numeric), expr_array(expr_numeric)), filter_missing=builtins.bool; ); def nanmax(*exprs, filter_missing: builtins.bool = True) -> NumericExpression:; """"""Returns the maximum value of a collection or of given arguments, excluding NaN. Examples; --------. Compute the maximum value of an array:. >>> hl.eval(hl.nanmax([1.1, 50.1, float('nan')])); 50.1. Take the maximum value of arguments:. >>> hl.eval(hl.nanmax(1.1, 50.1, float('nan'))); 50.1. Notes; -----; Like the Python builtin ``max`` function, this function can either take a; single iterable expression (an array or set of numeric elements), or; variable-length arguments of numeric expressions. Note; ----; If `filter_missing` is ``True``, then the result is the maximum of; non-missing arguments or elements. If `filter_missing` is ``False``, then; any missing argument or element causes the result to be missing. NaN arguments / array elements are ignored; the maximum value of `NaN` and; any non-`NaN` value `x` is `x`. See Also; --------; :func:`max`, :func:`min`, :func:`nanmin`. Parameters; ----------; exprs : :class:`.ArrayExpression` or :class:`.SetExpression` or varargs of :class:`.NumericExpression`; Single numeric array or set, or multiple numeric values.; filter_missing : :obj:`bool`; Remove missing arguments/elements before computing maximum. Returns; -------; :class:`.NumericExpression`; """""". return _comparison_func('max', exprs, filter_missing, filter_nan=True). [docs]@typecheck(; exprs=expr_oneof(expr_numeric, expr_set(expr_numeric), expr_array(expr_numeric)), filt",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:127073,Modifiability,variab,variable-length,127073,"max`, :func:`min`, :func:`nanmin`. Parameters; ----------; exprs : :class:`.ArrayExpression` or :class:`.SetExpression` or varargs of :class:`.NumericExpression`; Single numeric array or set, or multiple numeric values.; filter_missing : :obj:`bool`; Remove missing arguments/elements before computing maximum. Returns; -------; :class:`.NumericExpression`; """""". return _comparison_func('max', exprs, filter_missing, filter_nan=True). [docs]@typecheck(; exprs=expr_oneof(expr_numeric, expr_set(expr_numeric), expr_array(expr_numeric)), filter_missing=builtins.bool; ); def max(*exprs, filter_missing: builtins.bool = True) -> NumericExpression:; """"""Returns the maximum element of a collection or of given numeric expressions. Examples; --------. Take the maximum value of an array:. >>> hl.eval(hl.max([1, 3, 5, 6, 7, 9])); 9. Take the maximum value of values:. >>> hl.eval(hl.max(1, 50, 2)); 50. Notes; -----; Like the Python builtin ``max`` function, this function can either take a; single iterable expression (an array or set of numeric elements), or; variable-length arguments of numeric expressions. Note; ----; If `filter_missing` is ``True``, then the result is the maximum of; non-missing arguments or elements. If `filter_missing` is ``False``, then; any missing argument or element causes the result to be missing. If any element or argument is `NaN`, then the result is `NaN`. See Also; --------; :func:`nanmax`, :func:`min`, :func:`nanmin`. Parameters; ----------; exprs : :class:`.ArrayExpression` or :class:`.SetExpression` or varargs of :class:`.NumericExpression`; Single numeric array or set, or multiple numeric values.; filter_missing : :obj:`bool`; Remove missing arguments/elements before computing maximum. Returns; -------; :class:`.NumericExpression`; """"""; return _comparison_func('max', exprs, filter_missing, filter_nan=False). [docs]@typecheck(; exprs=expr_oneof(expr_numeric, expr_set(expr_numeric), expr_array(expr_numeric)), filter_missing=builtins.bool; ); def nanmin(*",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:128536,Modifiability,variab,variable-length,128536,"s; ----------; exprs : :class:`.ArrayExpression` or :class:`.SetExpression` or varargs of :class:`.NumericExpression`; Single numeric array or set, or multiple numeric values.; filter_missing : :obj:`bool`; Remove missing arguments/elements before computing maximum. Returns; -------; :class:`.NumericExpression`; """"""; return _comparison_func('max', exprs, filter_missing, filter_nan=False). [docs]@typecheck(; exprs=expr_oneof(expr_numeric, expr_set(expr_numeric), expr_array(expr_numeric)), filter_missing=builtins.bool; ); def nanmin(*exprs, filter_missing: builtins.bool = True) -> NumericExpression:; """"""Returns the minimum value of a collection or of given arguments, excluding NaN. Examples; --------. Compute the minimum value of an array:. >>> hl.eval(hl.nanmin([1.1, 50.1, float('nan')])); 1.1. Take the minimum value of arguments:. >>> hl.eval(hl.nanmin(1.1, 50.1, float('nan'))); 1.1. Notes; -----; Like the Python builtin ``min`` function, this function can either take a; single iterable expression (an array or set of numeric elements), or; variable-length arguments of numeric expressions. Note; ----; If `filter_missing` is ``True``, then the result is the minimum of; non-missing arguments or elements. If `filter_missing` is ``False``, then; any missing argument or element causes the result to be missing. NaN arguments / array elements are ignored; the minimum value of `NaN` and; any non-`NaN` value `x` is `x`. See Also; --------; :func:`min`, :func:`max`, :func:`nanmax`. Parameters; ----------; exprs : :class:`.ArrayExpression` or :class:`.SetExpression` or varargs of :class:`.NumericExpression`; Single numeric array or set, or multiple numeric values.; filter_missing : :obj:`bool`; Remove missing arguments/elements before computing minimum. Returns; -------; :class:`.NumericExpression`; """""". return _comparison_func('min', exprs, filter_missing, filter_nan=True). [docs]@typecheck(; exprs=expr_oneof(expr_numeric, expr_set(expr_numeric), expr_array(expr_numeric)), filt",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:129999,Modifiability,variab,variable-length,129999,"n`, :func:`max`, :func:`nanmax`. Parameters; ----------; exprs : :class:`.ArrayExpression` or :class:`.SetExpression` or varargs of :class:`.NumericExpression`; Single numeric array or set, or multiple numeric values.; filter_missing : :obj:`bool`; Remove missing arguments/elements before computing minimum. Returns; -------; :class:`.NumericExpression`; """""". return _comparison_func('min', exprs, filter_missing, filter_nan=True). [docs]@typecheck(; exprs=expr_oneof(expr_numeric, expr_set(expr_numeric), expr_array(expr_numeric)), filter_missing=builtins.bool; ); def min(*exprs, filter_missing: builtins.bool = True) -> NumericExpression:; """"""Returns the minimum element of a collection or of given numeric expressions. Examples; --------. Take the minimum value of an array:. >>> hl.eval(hl.min([1, 3, 5, 6, 7, 9])); 1. Take the minimum value of arguments:. >>> hl.eval(hl.min(1, 50, 2)); 1. Notes; -----; Like the Python builtin ``min`` function, this function can either take a; single iterable expression (an array or set of numeric elements), or; variable-length arguments of numeric expressions. Note; ----; If `filter_missing` is ``True``, then the result is the minimum of; non-missing arguments or elements. If `filter_missing` is ``False``, then; any missing argument or element causes the result to be missing. If any element or argument is `NaN`, then the result is `NaN`. See Also; --------; :func:`nanmin`, :func:`max`, :func:`nanmax`. Parameters; ----------; exprs : :class:`.ArrayExpression` or :class:`.SetExpression` or varargs of :class:`.NumericExpression`; Single numeric array or set, or multiple numeric values.; filter_missing : :obj:`bool`; Remove missing arguments/elements before computing minimum. Returns; -------; :class:`.NumericExpression`; """"""; return _comparison_func('min', exprs, filter_missing, filter_nan=False). [docs]@typecheck(x=expr_oneof(expr_numeric, expr_array(expr_numeric), expr_ndarray(expr_numeric))); def abs(x):; """"""Take the absolute value of a n",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:168248,Modifiability,polymorphi,polymorphism,168248,"& (child_n == 1), 1); .when((father_n == 0) & (mother_n == 0) & (child_n == 1), 2); .when((father_n == 0) & (mother_n == 0) & (child_n == 2), 5); .when((father_n == 2) & (mother_n == 2) & (child_n == 0), 8); .when((father_n == 0) & (child_n == 2), 3); .when((mother_n == 0) & (child_n == 2), 4); .when((father_n == 2) & (child_n == 0), 6); .when((mother_n == 2) & (child_n == 0), 7); .or_missing(); ). hemi_x_cond = (; hl.case(missing_false=True); .when((mother_n == 2) & (child_n == 0), 9); .when((mother_n == 0) & (child_n > 0), 10); .or_missing(); ). hemi_y_cond = (; hl.case(missing_false=True); .when((father_n > 0) & (child_n == 0), 11); .when((father_n == 0) & (child_n > 0), 12); .or_missing(); ). return (; hl.case(); .when(locus.in_autosome_or_par() | is_female, auto_cond); .when(locus.in_x_nonpar() & (~is_female), hemi_x_cond); .when(locus.in_y_nonpar() & (~is_female), hemi_y_cond); .or_missing(); ). [docs]@typecheck(locus=expr_locus(), alleles=expr_array(expr_str)); def min_rep(locus, alleles):; """"""Computes the minimal representation of a (locus, alleles) polymorphism. Examples; --------. >>> hl.eval(hl.min_rep(hl.locus('1', 100000), ['TAA', 'TA'])); Struct(locus=Locus(contig=1, position=100000, reference_genome=GRCh37), alleles=['TA', 'T']). >>> hl.eval(hl.min_rep(hl.locus('1', 100000), ['AATAA', 'AACAA'])); Struct(locus=Locus(contig=1, position=100002, reference_genome=GRCh37), alleles=['T', 'C']). Notes; -----; Computing the minimal representation can cause the locus shift right (the; position can increase). Parameters; ----------; locus : :class:`.LocusExpression`; alleles : :class:`.ArrayExpression` of type :py:data:`.tstr`. Returns; -------; :class:`.StructExpression`; A :class:`.tstruct` expression with two fields, `locus`; (:class:`.LocusExpression`) and `alleles`; (:class:`.ArrayExpression` of type :py:data:`.tstr`).; """"""; ret_type = tstruct(locus=locus.dtype, alleles=alleles.dtype); return _func('min_rep', ret_type, locus, alleles). [docs]@typecheck(; x=o",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:176515,Modifiability,variab,variable-length,176515,"ot': min must be less than max in call to uniroot, got: min %.1e, max %.1e"", min, max)); ). [docs]@typecheck(f=expr_str, args=expr_any); def format(f, *args):; """"""Returns a formatted string using a specified format string and arguments. Examples; --------. >>> hl.eval(hl.format('%.3e', 0.09345332)); '9.345e-02'. >>> hl.eval(hl.format('%.4f', hl.missing(hl.tfloat64))); 'null'. >>> hl.eval(hl.format('%s %s %s', 'hello', hl.tuple([3, hl.locus('1', 2453)]), True)); 'hello (3, 1:2453) true'. Notes; -----; See the `Java documentation <https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/util/Formatter.html#syntax>`__; for valid format specifiers and arguments. Missing values are printed as ``'null'`` except when using the; format flags `'b'` and `'B'` (printed as ``'false'`` instead). Parameters; ----------; f : :class:`.StringExpression`; Java `format string <https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/util/Formatter.html#syntax>`__.; args : variable-length arguments of :class:`.Expression`; Arguments to format. Returns; -------; :class:`.StringExpression`; """""". return _func(""format"", hl.tstr, f, hl.tuple(args)). [docs]@typecheck(x=expr_float64, y=expr_float64, tolerance=expr_float64, absolute=expr_bool, nan_same=expr_bool); def approx_equal(x, y, tolerance=1e-6, absolute=False, nan_same=False):; """"""Tests whether two numbers are approximately equal. Examples; --------; >>> hl.eval(hl.approx_equal(0.25, 0.2500001)); True. >>> hl.eval(hl.approx_equal(0.25, 0.251, tolerance=1e-3, absolute=True)); False. Parameters; ----------; x : :class:`.NumericExpression`; y : :class:`.NumericExpression`; tolerance : :class:`.NumericExpression`; absolute : :class:`.BooleanExpression`; If True, compute ``abs(x - y) <= tolerance``. Otherwise, compute; ``abs(x - y) <= max(tolerance * max(abs(x), abs(y)), 2 ** -1022)``.; nan_same : :class:`.BooleanExpression`; If True, then ``NaN == NaN`` will evaluate to True. Otherwise,; it will return False. Returns; ----",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:180505,Modifiability,extend,extended,180505,"ion` or :class:`.Int64Expression`. Returns; -------; :class:`.Int32Expression` or :class:`.Int64Expression`; """"""; return _bit_op(x, y, '|'). [docs]@typecheck(x=expr_oneof(expr_int32, expr_int64), y=expr_oneof(expr_int32, expr_int64)); def bit_xor(x, y):; """"""Bitwise exclusive-or `x` and `y`. Examples; --------; >>> hl.eval(hl.bit_xor(5, 3)); 6. Notes; -----; See `the Python wiki <https://wiki.python.org/moin/BitwiseOperators>`__; for more information about bit operators. Parameters; ----------; x : :class:`.Int32Expression` or :class:`.Int64Expression`; y : :class:`.Int32Expression` or :class:`.Int64Expression`. Returns; -------; :class:`.Int32Expression` or :class:`.Int64Expression`; """"""; return _bit_op(x, y, '^'). [docs]@typecheck(x=expr_oneof(expr_int32, expr_int64), y=expr_int32); def bit_lshift(x, y):; """"""Bitwise left-shift `x` by `y`. Examples; --------; >>> hl.eval(hl.bit_lshift(5, 3)); 40. >>> hl.eval(hl.bit_lshift(1, 8)); 256. Unlike Python, Hail integers are fixed-size (32 or 64 bits),; and bits extended beyond will be ignored:. >>> hl.eval(hl.bit_lshift(1, 31)); -2147483648. >>> hl.eval(hl.bit_lshift(1, 32)); 0. >>> hl.eval(hl.bit_lshift(hl.int64(1), 32)); 4294967296. >>> hl.eval(hl.bit_lshift(hl.int64(1), 64)); 0. Notes; -----; See `the Python wiki <https://wiki.python.org/moin/BitwiseOperators>`__; for more information about bit operators. Parameters; ----------; x : :class:`.Int32Expression` or :class:`.Int64Expression`; y : :class:`.Int32Expression` or :class:`.Int64Expression`. Returns; -------; :class:`.Int32Expression` or :class:`.Int64Expression`; """"""; return _shift_op(x, y, '<<'). [docs]@typecheck(x=expr_oneof(expr_int32, expr_int64), y=expr_int32, logical=builtins.bool); def bit_rshift(x, y, logical=False):; """"""Bitwise right-shift `x` by `y`. Examples; --------; >>> hl.eval(hl.bit_rshift(256, 3)); 32. With ``logical=False`` (default), the sign is preserved:. >>> hl.eval(hl.bit_rshift(-1, 1)); -1. With ``logical=True``, the sign bit is treated as a",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:34155,Performance,perform,performs,34155,"oadcasting; def ceil(x):; """"""The smallest integral value that is greater than or equal to `x`. Examples; --------. >>> hl.eval(hl.ceil(3.1)); 4.0. Parameters; ----------; x : :class:`.Float32Expression`,:class:`.Float64Expression` or :class:`.NDArrayNumericExpression`. Returns; -------; :class:`.Float32Expression`, :class:`.Float64Expression`, or :class:`.NDArrayNumericExpression`; """"""; return _func(""ceil"", x.dtype, x). [docs]@typecheck(n_hom_ref=expr_int32, n_het=expr_int32, n_hom_var=expr_int32, one_sided=expr_bool); def hardy_weinberg_test(n_hom_ref, n_het, n_hom_var, one_sided=False) -> StructExpression:; """"""Performs test of Hardy-Weinberg equilibrium. Examples; --------. >>> hl.eval(hl.hardy_weinberg_test(250, 500, 250)); Struct(het_freq_hwe=0.5002501250625313, p_value=0.9747844394217698). >>> hl.eval(hl.hardy_weinberg_test(37, 200, 85)); Struct(het_freq_hwe=0.48964964307448583, p_value=1.1337210383168987e-06). Notes; -----; By default, this method performs a two-sided exact test with mid-p-value correction of; `Hardy-Weinberg equilibrium <https://en.wikipedia.org/wiki/Hardy%E2%80%93Weinberg_principle>`__; via an efficient implementation of the; `Levene-Haldane distribution <../_static/LeveneHaldane.pdf>`__,; which models the number of heterozygous individuals under equilibrium. The mean of this distribution is ``(n_ref * n_var) / (2n - 1)``, where; ``n_ref = 2*n_hom_ref + n_het`` is the number of reference alleles,; ``n_var = 2*n_hom_var + n_het`` is the number of variant alleles,; and ``n = n_hom_ref + n_het + n_hom_var`` is the number of individuals.; So the expected frequency of heterozygotes under equilibrium,; `het_freq_hwe`, is this mean divided by ``n``. To perform one-sided exact test of excess heterozygosity with mid-p-value; correction instead, set `one_sided=True` and the p-value returned will be; from the one-sided exact test. Parameters; ----------; n_hom_ref : int or :class:`.Expression` of type :py:data:`.tint32`; Number of homozygous reference g",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:34886,Performance,perform,perform,34886,"0.9747844394217698). >>> hl.eval(hl.hardy_weinberg_test(37, 200, 85)); Struct(het_freq_hwe=0.48964964307448583, p_value=1.1337210383168987e-06). Notes; -----; By default, this method performs a two-sided exact test with mid-p-value correction of; `Hardy-Weinberg equilibrium <https://en.wikipedia.org/wiki/Hardy%E2%80%93Weinberg_principle>`__; via an efficient implementation of the; `Levene-Haldane distribution <../_static/LeveneHaldane.pdf>`__,; which models the number of heterozygous individuals under equilibrium. The mean of this distribution is ``(n_ref * n_var) / (2n - 1)``, where; ``n_ref = 2*n_hom_ref + n_het`` is the number of reference alleles,; ``n_var = 2*n_hom_var + n_het`` is the number of variant alleles,; and ``n = n_hom_ref + n_het + n_hom_var`` is the number of individuals.; So the expected frequency of heterozygotes under equilibrium,; `het_freq_hwe`, is this mean divided by ``n``. To perform one-sided exact test of excess heterozygosity with mid-p-value; correction instead, set `one_sided=True` and the p-value returned will be; from the one-sided exact test. Parameters; ----------; n_hom_ref : int or :class:`.Expression` of type :py:data:`.tint32`; Number of homozygous reference genotypes.; n_het : int or :class:`.Expression` of type :py:data:`.tint32`; Number of heterozygous genotypes.; n_hom_var : int or :class:`.Expression` of type :py:data:`.tint32`; Number of homozygous variant genotypes.; one_sided : :obj:`bool`; ``False`` by default. When ``True``, perform one-sided test for excess heterozygosity. Returns; -------; :class:`.StructExpression`; A struct expression with two fields, `het_freq_hwe`; (:py:data:`.tfloat64`) and `p_value` (:py:data:`.tfloat64`).; """"""; ret_type = tstruct(het_freq_hwe=tfloat64, p_value=tfloat64); return _func(""hardy_weinberg_test"", ret_type, n_hom_ref, n_het, n_hom_var, one_sided). [docs]@typecheck(contig=expr_str, pos=expr_int32, reference_genome=reference_genome_type); def locus(contig, pos, reference_genome: Union[st",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:35469,Performance,perform,perform,35469,"brium. The mean of this distribution is ``(n_ref * n_var) / (2n - 1)``, where; ``n_ref = 2*n_hom_ref + n_het`` is the number of reference alleles,; ``n_var = 2*n_hom_var + n_het`` is the number of variant alleles,; and ``n = n_hom_ref + n_het + n_hom_var`` is the number of individuals.; So the expected frequency of heterozygotes under equilibrium,; `het_freq_hwe`, is this mean divided by ``n``. To perform one-sided exact test of excess heterozygosity with mid-p-value; correction instead, set `one_sided=True` and the p-value returned will be; from the one-sided exact test. Parameters; ----------; n_hom_ref : int or :class:`.Expression` of type :py:data:`.tint32`; Number of homozygous reference genotypes.; n_het : int or :class:`.Expression` of type :py:data:`.tint32`; Number of heterozygous genotypes.; n_hom_var : int or :class:`.Expression` of type :py:data:`.tint32`; Number of homozygous variant genotypes.; one_sided : :obj:`bool`; ``False`` by default. When ``True``, perform one-sided test for excess heterozygosity. Returns; -------; :class:`.StructExpression`; A struct expression with two fields, `het_freq_hwe`; (:py:data:`.tfloat64`) and `p_value` (:py:data:`.tfloat64`).; """"""; ret_type = tstruct(het_freq_hwe=tfloat64, p_value=tfloat64); return _func(""hardy_weinberg_test"", ret_type, n_hom_ref, n_het, n_hom_var, one_sided). [docs]@typecheck(contig=expr_str, pos=expr_int32, reference_genome=reference_genome_type); def locus(contig, pos, reference_genome: Union[str, ReferenceGenome] = 'default') -> LocusExpression:; """"""Construct a locus expression from a chromosome and position. Examples; --------. >>> hl.eval(hl.locus(""1"", 10000, reference_genome='GRCh37')); Locus(contig=1, position=10000, reference_genome=GRCh37). Parameters; ----------; contig : str or :class:`.StringExpression`; Chromosome.; pos : int or :class:`.Expression` of type :py:data:`.tint32`; Base position along the chromosome.; reference_genome : :class:`str` or :class:`.ReferenceGenome`; Reference gen",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:160651,Performance,load,load,160651,", pair adenine (A) with uracil (U) instead of thymine (T). Returns; -------; :class:`.StringExpression`; """"""; s = s.reverse(). if rna:; pairs = [('A', 'U'), ('U', 'A'), ('T', 'A'), ('G', 'C'), ('C', 'G')]; else:; pairs = [('A', 'T'), ('T', 'A'), ('G', 'C'), ('C', 'G')]. d = {}; for b1, b2 in pairs:; d[b1] = b2; d[b1.lower()] = b2.lower(). return s.translate(d). [docs]@typecheck(; contig=expr_str, position=expr_int32, before=expr_int32, after=expr_int32, reference_genome=reference_genome_type; ); def get_sequence(contig, position, before=0, after=0, reference_genome='default') -> StringExpression:; """"""Return the reference sequence at a given locus. Examples; --------. Return the reference allele for ``'GRCh37'`` at the locus ``'1:45323'``:. >>> hl.eval(hl.get_sequence('1', 45323, reference_genome='GRCh37')) # doctest: +SKIP; ""T"". Notes; -----; This function requires `reference genome` has an attached; reference sequence. Use :meth:`.ReferenceGenome.add_sequence` to; load and attach a reference sequence to a reference genome. Returns ``None`` if `contig` and `position` are not valid coordinates in; `reference_genome`. Parameters; ----------; contig : :class:`.Expression` of type :py:data:`.tstr`; Locus contig.; position : :class:`.Expression` of type :py:data:`.tint32`; Locus position.; before : :class:`.Expression` of type :py:data:`.tint32`, optional; Number of bases to include before the locus of interest. Truncates at; contig boundary.; after : :class:`.Expression` of type :py:data:`.tint32`, optional; Number of bases to include after the locus of interest. Truncates at; contig boundary.; reference_genome : :class:`str` or :class:`.ReferenceGenome`; Reference genome to use. Must have a reference sequence available. Returns; -------; :class:`.StringExpression`; """""". if not reference_genome.has_sequence():; raise TypeError(; ""Reference genome '{}' does not have a sequence loaded. Use 'add_sequence' to load the sequence from a FASTA file."".format(; reference_genome.na",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:161576,Performance,load,loaded,161576,"n requires `reference genome` has an attached; reference sequence. Use :meth:`.ReferenceGenome.add_sequence` to; load and attach a reference sequence to a reference genome. Returns ``None`` if `contig` and `position` are not valid coordinates in; `reference_genome`. Parameters; ----------; contig : :class:`.Expression` of type :py:data:`.tstr`; Locus contig.; position : :class:`.Expression` of type :py:data:`.tint32`; Locus position.; before : :class:`.Expression` of type :py:data:`.tint32`, optional; Number of bases to include before the locus of interest. Truncates at; contig boundary.; after : :class:`.Expression` of type :py:data:`.tint32`, optional; Number of bases to include after the locus of interest. Truncates at; contig boundary.; reference_genome : :class:`str` or :class:`.ReferenceGenome`; Reference genome to use. Must have a reference sequence available. Returns; -------; :class:`.StringExpression`; """""". if not reference_genome.has_sequence():; raise TypeError(; ""Reference genome '{}' does not have a sequence loaded. Use 'add_sequence' to load the sequence from a FASTA file."".format(; reference_genome.name; ); ). return _func(""getReferenceSequence"", tstr, contig, position, before, after, type_args=(tlocus(reference_genome),)). [docs]@typecheck(contig=expr_str, reference_genome=reference_genome_type); def is_valid_contig(contig, reference_genome='default') -> BooleanExpression:; """"""Returns ``True`` if `contig` is a valid contig name in `reference_genome`. Examples; --------. >>> hl.eval(hl.is_valid_contig('1', reference_genome='GRCh37')); True. >>> hl.eval(hl.is_valid_contig('chr1', reference_genome='GRCh37')); False. Parameters; ----------; contig : :class:`.Expression` of type :py:data:`.tstr`; reference_genome : :class:`str` or :class:`.ReferenceGenome`. Returns; -------; :class:`.BooleanExpression`; """"""; return _func(""isValidContig"", tbool, contig, type_args=(tlocus(reference_genome),)). [docs]@typecheck(contig=expr_str, reference_genome=reference_ge",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:161606,Performance,load,load,161606,"th:`.ReferenceGenome.add_sequence` to; load and attach a reference sequence to a reference genome. Returns ``None`` if `contig` and `position` are not valid coordinates in; `reference_genome`. Parameters; ----------; contig : :class:`.Expression` of type :py:data:`.tstr`; Locus contig.; position : :class:`.Expression` of type :py:data:`.tint32`; Locus position.; before : :class:`.Expression` of type :py:data:`.tint32`, optional; Number of bases to include before the locus of interest. Truncates at; contig boundary.; after : :class:`.Expression` of type :py:data:`.tint32`, optional; Number of bases to include after the locus of interest. Truncates at; contig boundary.; reference_genome : :class:`str` or :class:`.ReferenceGenome`; Reference genome to use. Must have a reference sequence available. Returns; -------; :class:`.StringExpression`; """""". if not reference_genome.has_sequence():; raise TypeError(; ""Reference genome '{}' does not have a sequence loaded. Use 'add_sequence' to load the sequence from a FASTA file."".format(; reference_genome.name; ); ). return _func(""getReferenceSequence"", tstr, contig, position, before, after, type_args=(tlocus(reference_genome),)). [docs]@typecheck(contig=expr_str, reference_genome=reference_genome_type); def is_valid_contig(contig, reference_genome='default') -> BooleanExpression:; """"""Returns ``True`` if `contig` is a valid contig name in `reference_genome`. Examples; --------. >>> hl.eval(hl.is_valid_contig('1', reference_genome='GRCh37')); True. >>> hl.eval(hl.is_valid_contig('chr1', reference_genome='GRCh37')); False. Parameters; ----------; contig : :class:`.Expression` of type :py:data:`.tstr`; reference_genome : :class:`str` or :class:`.ReferenceGenome`. Returns; -------; :class:`.BooleanExpression`; """"""; return _func(""isValidContig"", tbool, contig, type_args=(tlocus(reference_genome),)). [docs]@typecheck(contig=expr_str, reference_genome=reference_genome_type); def contig_length(contig, reference_genome='default') -> Int32E",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:170267,Performance,load,loaded,170267,"ome=reference_genome_type,; min_match=builtins.float,; include_strand=builtins.bool,; ); def liftover(x, dest_reference_genome, min_match=0.95, include_strand=False):; """"""Lift over coordinates to a different reference genome. Examples; --------. Lift over the locus coordinates from reference genome ``'GRCh37'`` to; ``'GRCh38'``:. >>> hl.eval(hl.liftover(hl.locus('1', 1034245, 'GRCh37'), 'GRCh38')) # doctest: +SKIP; Locus(contig='chr1', position=1098865, reference_genome='GRCh38'). Lift over the locus interval coordinates from reference genome ``'GRCh37'``; to ``'GRCh38'``:. >>> hl.eval(hl.liftover(hl.locus_interval('20', 60001, 82456, True, True, 'GRCh37'), 'GRCh38')) # doctest: +SKIP; Interval(Locus(contig='chr20', position=79360, reference_genome='GRCh38'),; Locus(contig='chr20', position=101815, reference_genome='GRCh38'),; True,; True). See :ref:`liftover_howto` for more instructions on lifting over a Table; or MatrixTable. Notes; -----; This function requires the reference genome of `x` has a chain file loaded; for `dest_reference_genome`. Use :meth:`.ReferenceGenome.add_liftover` to; load and attach a chain file to a reference genome. Returns ``None`` if `x` could not be converted. Warning; -------; Before using the result of :func:`.liftover` as a new row key or column; key, be sure to filter out missing values. Parameters; ----------; x : :class:`.Expression` of type :class:`.tlocus` or :class:`.tinterval` of :class:`.tlocus`; Locus or locus interval to lift over.; dest_reference_genome : :class:`str` or :class:`.ReferenceGenome`; Reference genome to convert to.; min_match : :obj:`float`; Minimum ratio of bases that must remap.; include_strand : :obj:`bool`; If True, output the result as a :class:`.StructExpression` with the first field `result` being; the locus or locus interval and the second field `is_negative_strand` is a boolean indicating; whether the locus or locus interval has been mapped to the negative strand of the destination; reference genome. Ot",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:170350,Performance,load,load,170350,"ome, min_match=0.95, include_strand=False):; """"""Lift over coordinates to a different reference genome. Examples; --------. Lift over the locus coordinates from reference genome ``'GRCh37'`` to; ``'GRCh38'``:. >>> hl.eval(hl.liftover(hl.locus('1', 1034245, 'GRCh37'), 'GRCh38')) # doctest: +SKIP; Locus(contig='chr1', position=1098865, reference_genome='GRCh38'). Lift over the locus interval coordinates from reference genome ``'GRCh37'``; to ``'GRCh38'``:. >>> hl.eval(hl.liftover(hl.locus_interval('20', 60001, 82456, True, True, 'GRCh37'), 'GRCh38')) # doctest: +SKIP; Interval(Locus(contig='chr20', position=79360, reference_genome='GRCh38'),; Locus(contig='chr20', position=101815, reference_genome='GRCh38'),; True,; True). See :ref:`liftover_howto` for more instructions on lifting over a Table; or MatrixTable. Notes; -----; This function requires the reference genome of `x` has a chain file loaded; for `dest_reference_genome`. Use :meth:`.ReferenceGenome.add_liftover` to; load and attach a chain file to a reference genome. Returns ``None`` if `x` could not be converted. Warning; -------; Before using the result of :func:`.liftover` as a new row key or column; key, be sure to filter out missing values. Parameters; ----------; x : :class:`.Expression` of type :class:`.tlocus` or :class:`.tinterval` of :class:`.tlocus`; Locus or locus interval to lift over.; dest_reference_genome : :class:`str` or :class:`.ReferenceGenome`; Reference genome to convert to.; min_match : :obj:`float`; Minimum ratio of bases that must remap.; include_strand : :obj:`bool`; If True, output the result as a :class:`.StructExpression` with the first field `result` being; the locus or locus interval and the second field `is_negative_strand` is a boolean indicating; whether the locus or locus interval has been mapped to the negative strand of the destination; reference genome. Otherwise, output the converted locus or locus interval. Returns; -------; :class:`.Expression`; A locus or locus interval co",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:172050,Performance,load,load,172050,"s interval and the second field `is_negative_strand` is a boolean indicating; whether the locus or locus interval has been mapped to the negative strand of the destination; reference genome. Otherwise, output the converted locus or locus interval. Returns; -------; :class:`.Expression`; A locus or locus interval converted to `dest_reference_genome`.; """""". if not 0.0 <= min_match <= 1.0:; raise TypeError(""'liftover' requires 'min_match' is in the range [0, 1]. Got {}"".format(min_match)). if isinstance(x.dtype, tlocus):; rg = x.dtype.reference_genome; method_name = ""liftoverLocus""; rtype = tstruct(result=tlocus(dest_reference_genome), is_negative_strand=tbool); else:; rg = x.dtype.point_type.reference_genome; method_name = ""liftoverLocusInterval""; rtype = tstruct(result=tinterval(tlocus(dest_reference_genome)), is_negative_strand=tbool). if not rg.has_liftover(dest_reference_genome.name):; raise TypeError(; """"""Reference genome '{}' does not have liftover to '{}'.; Use 'add_liftover' to load a liftover chain file."""""".format(rg.name, dest_reference_genome.name); ). expr = _func(method_name, rtype, x, to_expr(min_match, tfloat64)); if not include_strand:; expr = expr.result; return expr. [docs]@typecheck(; f=func_spec(1, expr_float64),; min=expr_float64,; max=expr_float64,; max_iter=builtins.int,; epsilon=builtins.float,; tolerance=builtins.float,; ); def uniroot(f: Callable, min, max, *, max_iter=1000, epsilon=2.2204460492503131e-16, tolerance=1.220703e-4):; """"""Finds a root of the function `f` within the interval `[min, max]`. Examples; --------. >>> hl.eval(hl.uniroot(lambda x: x - 1, -5, 5)); 1.0. Notes; -----; `f(min)` and `f(max)` must not have the same sign. If no root can be found, the result of this call will be `NA` (missing). :func:`.uniroot` returns an estimate for a root with accuracy; `4 * epsilon * abs(x) + tolerance`. 4*EPSILON*abs(x) + tol. Parameters; ----------; f : function ( (arg) -> :class:`.Float64Expression`); Must return a :class:`.Float64Expressio",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:183705,Performance,perform,perform,183705,"~', x._ir), x.dtype, x._indices, x._aggregations). [docs]@typecheck(x=expr_oneof(expr_int32, expr_int64)); def bit_count(x):; """"""Count the number of 1s in the in the `two's complement <https://en.wikipedia.org/wiki/Two%27s_complement>`__ binary representation of `x`. Examples; --------; The binary representation of `7` is `111`, so:. >>> hl.eval(hl.bit_count(7)); 3. Parameters; ----------; x : :class:`.Int32Expression` or :class:`.Int64Expression`. Returns; ----------; :class:`.Int32Expression`; """"""; return construct_expr(ir.ApplyUnaryPrimOp('BitCount', x._ir), tint32, x._indices, x._aggregations). [docs]@typecheck(array=expr_array(expr_numeric), elem=expr_numeric); def binary_search(array, elem) -> Int32Expression:; """"""Binary search `array` for the insertion point of `elem`. Parameters; ----------; array : :class:`.Expression` of type :class:`.tarray`; elem : :class:`.Expression`. Returns; -------; :class:`.Int32Expression`. Notes; -----; This function assumes that `array` is sorted in ascending order, and does; not perform any sortedness check. Missing values sort last. The returned index is the lower bound on the insertion point of `elem` into; the ordered array, or the index of the first element in `array` not smaller; than `elem`. This is a value between 0 and the length of `array`, inclusive; (if all elements in `array` are smaller than `elem`, the returned value is; the length of `array` or the index of the first missing value, if one; exists). If either `elem` or `array` is missing, the result is missing. Examples; --------. >>> a = hl.array([0, 2, 4, 8]). >>> hl.eval(hl.binary_search(a, -1)); 0. >>> hl.eval(hl.binary_search(a, 1)); 1. >>> hl.eval(hl.binary_search(a, 10)); 4. """"""; c = coercer_from_dtype(array.dtype.element_type); if not c.can_coerce(elem.dtype):; raise TypeError(; f""'binary_search': cannot search an array of type {array.dtype} for a value of type {elem.dtype}""; ); elem = c.coerce(elem); return hl.switch(elem).when_missing(hl.missing(hl.tint32",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:71067,Safety,abort,aborting,71067,"d in Python.; mu : :obj:`float` or :class:`.Expression` of type :py:data:`.tfloat64`; The standard deviation of the normal term.; sigma : :obj:`float` or :class:`.Expression` of type :py:data:`.tfloat64`; The standard deviation of the normal term.; max_iterations : :obj:`int` or :class:`.Expression` of type :py:data:`.tint32`; The maximum number of iterations of the numerical integration before raising an error. The; default maximum number of iterations is ``1e5``.; min_accuracy : :obj:`int` or :class:`.Expression` of type :py:data:`.tint32`; The minimum accuracy of the returned value. If the minimum accuracy is not achieved, this; function will raise an error. The default minimum accuracy is ``1e-5``. Returns; -------; :class:`.StructExpression`; This method returns a structure with the value as well as information about the numerical; integration. - value : :class:`.Float64Expression`. If converged is true, the value of the CDF evaluated; at `x`. Otherwise, this is the last value the integration evaluated before aborting. - n_iterations : :class:`.Int32Expression`. The number of iterations before stopping. - converged : :class:`.BooleanExpression`. True if the `min_accuracy` was achieved and round; off error is not likely significant. - fault : :class:`.Int32Expression`. If converged is true, fault is zero. If converged is; false, fault is either one or two. One indicates that the requried accuracy was not; achieved. Two indicates the round-off error is possibly significant. """"""; if max_iterations is None:; max_iterations = hl.literal(10_000); if min_accuracy is None:; min_accuracy = hl.literal(1e-5); return _func(""pgenchisq"", PGENCHISQ_RETURN_TYPE, x - mu, w, k, lam, sigma, max_iterations, min_accuracy). [docs]@typecheck(x=expr_float64, mu=expr_float64, sigma=expr_float64, lower_tail=expr_bool, log_p=expr_bool); def pnorm(x, mu=0, sigma=1, lower_tail=True, log_p=False) -> Float64Expression:; """"""The cumulative probability function of a normal distribution with mean",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:186286,Safety,safe,safeguards,186286,"rray(hl.tint32), hl.tarray(hl.tint32)); return _func(""locus_windows_per_contig"", rt, coords, radius). [docs]@typecheck(a=expr_array(), seed=nullable(builtins.int)); def shuffle(a, seed: Optional[builtins.int] = None) -> ArrayExpression:; """"""Randomly permute an array. Example; -------. >>> hl.reset_global_randomness(); >>> hl.eval(hl.shuffle(hl.range(5))); [4, 0, 2, 1, 3]. Parameters; ----------; a : :class:`.ArrayExpression`; Array to permute.; seed : :obj:`int`, optional; Random seed. Returns; -------; :class:`.ArrayExpression`; """"""; return sorted(a, key=lambda _: hl.rand_unif(0.0, 1.0)). [docs]@typecheck(path=builtins.str, point_or_interval=expr_any); def query_table(path, point_or_interval):; """"""Query records from a table corresponding to a given point or range of keys. Notes; -----; This function does not dispatch to a distributed runtime; it can be used inside; already-distributed queries such as in :meth:`.Table.annotate`. Warning; -------; This function contains no safeguards against reading large amounts of data; using a single thread. Parameters; ----------; path : :class:`str`; Table path.; point_or_interval; Point or interval to query. Returns; -------; :class:`.ArrayExpression`; """"""; table = hl.read_table(path); row_typ = table.row.dtype. key_typ = table.key.dtype; key_names = list(key_typ); len = builtins.len; if len(key_typ) == 0:; raise ValueError(""query_table: cannot query unkeyed table""). def coerce_endpoint(point):; if point.dtype == key_typ[0]:; point = hl.struct(**{key_names[0]: point}); ts = point.dtype; if isinstance(ts, tstruct):; i = 0; while i < len(ts):; if i >= len(key_typ):; raise ValueError(; f""query_table: queried with {len(ts)} key field(s), but table only has {len(key_typ)} key field(s)""; ); if key_typ[i] != ts[i]:; raise ValueError(; f""query_table: key mismatch at key field {i} ({list(ts.keys())[i]!r}): query type is {ts[i]}, table key type is {key_typ[i]}""; ); i += 1. if i == 0:; raise ValueError(""query_table: cannot query with empty",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:69027,Security,access,accessible,69027,"eight vector (our `w`) as; :math:`\lambda` or `lb` and the non-centrality vector (our `lam`) as `nc`. We use the Davies' algorithm which was published as:. `Davies, Robert. ""The distribution of a linear combination of chi-squared random variables.""; Applied Statistics 29 323-333. 1980. <http://www.robertnz.net/pdf/lc_chisq.pdf>`__. Davies included Fortran source code in the original publication. Davies also released a `C; language port <http://www.robertnz.net/QF.htm>`__. Hail's implementation is a fairly direct port; of the C implementation to Scala. Davies provides 39 test cases with the source code. The Hail; tests include all 39 test cases as well as a few additional tests. Davies' website cautions:. The method works well in most situations if you want only modest accuracy, say 0.0001. But; problems may arise if the sum is dominated by one or two terms with a total of only one or; two degrees of freedom and x is small. For an accessible introduction the Generalized Chi-Squared Distribution, we strongly recommend; the introduction of this paper:. `Das, Abhranil; Geisler, Wilson (2020). ""A method to integrate and classify normal; distributions"". <https://arxiv.org/abs/2012.14331>`__. Parameters; ----------; x : :obj:`float` or :class:`.Expression` of type :py:data:`.tfloat64`; The value at which to evaluate the cumulative distribution function (CDF).; w : :obj:`list` of :obj:`float` or :class:`.Expression` of type :py:class:`.tarray` of :py:data:`.tfloat64`; A weight for each non-central chi-square term.; k : :obj:`list` of :obj:`int` or :class:`.Expression` of type :py:class:`.tarray` of :py:data:`.tint32`; A degrees of freedom parameter for each non-central chi-square term.; lam : :obj:`list` of :obj:`float` or :class:`.Expression` of type :py:class:`.tarray` of :py:data:`.tfloat64`; A non-centrality parameter for each non-central chi-square term. We use `lam` instead; of `lambda` because the latter is a reserved word in Python.; mu : :obj:`float` or :class:`.Exp",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:5904,Testability,log,log,5904,"int32)); return _func('approxCDFCombine', t, k, left, right). @typecheck(cdf=expr_struct(), failure_prob=expr_oneof(expr_float32, expr_float64), all_quantiles=bool); def _error_from_cdf(cdf, failure_prob, all_quantiles=False):; """"""Estimates error of approx_cdf aggregator, using Hoeffding's inequality. Parameters; ----------; cdf : :class:`.StructExpression`; Result of :func:`.approx_cdf` aggregator; failure_prob: :class:`.NumericExpression`; Upper bound on probability of true error being greater than estimated error.; all_quantiles: :obj:`bool`; If ``True``, with probability 1 - `failure_prob`, error estimate applies; to all quantiles simultaneously. Returns; -------; :class:`.NumericExpression`; Upper bound on error of quantile estimates.; """""". def compute_sum(cdf):; s = hl.sum(; hl.range(0, hl.len(cdf._compaction_counts)).map(lambda i: cdf._compaction_counts[i] * (2 ** (2 * i))); ); return s / (cdf.ranks[-1] ** 2). def update_grid_size(p, s):; return 4 * hl.sqrt(hl.log(2 * p / failure_prob) / (2 * s)). def compute_grid_size(s):; return hl.fold(lambda p, i: update_grid_size(p, s), 1 / failure_prob, hl.range(0, 5)). def compute_single_error(s, failure_prob=failure_prob):; return hl.sqrt(hl.log(2 / failure_prob) * s / 2). def compute_global_error(s):; return hl.rbind(compute_grid_size(s), lambda p: 1 / p + compute_single_error(s, failure_prob / p)). if all_quantiles:; return hl.rbind(cdf, lambda cdf: hl.rbind(compute_sum(cdf), compute_global_error)); else:; return hl.rbind(cdf, lambda cdf: hl.rbind(compute_sum(cdf), compute_single_error)). def _error_from_cdf_python(cdf, failure_prob, all_quantiles=False):; """"""Estimates error of approx_cdf aggregator, using Hoeffding's inequality. Parameters; ----------; cdf : :obj:`dict`; Result of :func:`.approx_cdf` aggregator, evaluated to a python dict; failure_prob: :obj:`float`; Upper bound on probability of true error being greater than estimated error.; all_quantiles: :obj:`bool`; If ``True``, with probability 1 - `failure_pr",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:6131,Testability,log,log,6131,"):; """"""Estimates error of approx_cdf aggregator, using Hoeffding's inequality. Parameters; ----------; cdf : :class:`.StructExpression`; Result of :func:`.approx_cdf` aggregator; failure_prob: :class:`.NumericExpression`; Upper bound on probability of true error being greater than estimated error.; all_quantiles: :obj:`bool`; If ``True``, with probability 1 - `failure_prob`, error estimate applies; to all quantiles simultaneously. Returns; -------; :class:`.NumericExpression`; Upper bound on error of quantile estimates.; """""". def compute_sum(cdf):; s = hl.sum(; hl.range(0, hl.len(cdf._compaction_counts)).map(lambda i: cdf._compaction_counts[i] * (2 ** (2 * i))); ); return s / (cdf.ranks[-1] ** 2). def update_grid_size(p, s):; return 4 * hl.sqrt(hl.log(2 * p / failure_prob) / (2 * s)). def compute_grid_size(s):; return hl.fold(lambda p, i: update_grid_size(p, s), 1 / failure_prob, hl.range(0, 5)). def compute_single_error(s, failure_prob=failure_prob):; return hl.sqrt(hl.log(2 / failure_prob) * s / 2). def compute_global_error(s):; return hl.rbind(compute_grid_size(s), lambda p: 1 / p + compute_single_error(s, failure_prob / p)). if all_quantiles:; return hl.rbind(cdf, lambda cdf: hl.rbind(compute_sum(cdf), compute_global_error)); else:; return hl.rbind(cdf, lambda cdf: hl.rbind(compute_sum(cdf), compute_single_error)). def _error_from_cdf_python(cdf, failure_prob, all_quantiles=False):; """"""Estimates error of approx_cdf aggregator, using Hoeffding's inequality. Parameters; ----------; cdf : :obj:`dict`; Result of :func:`.approx_cdf` aggregator, evaluated to a python dict; failure_prob: :obj:`float`; Upper bound on probability of true error being greater than estimated error.; all_quantiles: :obj:`bool`; If ``True``, with probability 1 - `failure_prob`, error estimate applies; to all quantiles simultaneously. Returns; -------; :obj:`float`; Upper bound on error of quantile estimates.; """"""; import math. s = 0; for i in builtins.range(builtins.len(cdf._compaction_counts)",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:7276,Testability,log,log,7276,"f all_quantiles:; return hl.rbind(cdf, lambda cdf: hl.rbind(compute_sum(cdf), compute_global_error)); else:; return hl.rbind(cdf, lambda cdf: hl.rbind(compute_sum(cdf), compute_single_error)). def _error_from_cdf_python(cdf, failure_prob, all_quantiles=False):; """"""Estimates error of approx_cdf aggregator, using Hoeffding's inequality. Parameters; ----------; cdf : :obj:`dict`; Result of :func:`.approx_cdf` aggregator, evaluated to a python dict; failure_prob: :obj:`float`; Upper bound on probability of true error being greater than estimated error.; all_quantiles: :obj:`bool`; If ``True``, with probability 1 - `failure_prob`, error estimate applies; to all quantiles simultaneously. Returns; -------; :obj:`float`; Upper bound on error of quantile estimates.; """"""; import math. s = 0; for i in builtins.range(builtins.len(cdf._compaction_counts)):; s += cdf._compaction_counts[i] << (2 * i); s = s / (cdf.ranks[-1] ** 2). def update_grid_size(p):; return 4 * math.sqrt(math.log(2 * p / failure_prob) / (2 * s)). def compute_grid_size(s):; p = 1 / failure_prob; for _ in builtins.range(5):; p = update_grid_size(p); return p. def compute_single_error(s, failure_prob=failure_prob):; return math.sqrt(math.log(2 / failure_prob) * s / 2). if s == 0:; # no compactions ergo no error; return 0; elif all_quantiles:; p = compute_grid_size(s); return 1 / p + compute_single_error(s, failure_prob / p); else:; return compute_single_error(s, failure_prob). [docs]@typecheck(t=hail_type); def missing(t: Union[HailType, str]):; """"""Creates an expression representing a missing value of a specified type. Examples; --------. >>> hl.eval(hl.missing(hl.tarray(hl.tstr))); None. >>> hl.eval(hl.missing('array<str>')); None. Notes; -----; This method is useful for constructing an expression that includes missing; values, since :obj:`None` cannot be interpreted as an expression. Parameters; ----------; t : :class:`str` or :class:`.HailType`; Type of the missing expression. Returns; -------; :class:`.Expre",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:7506,Testability,log,log,7506,"ilure_prob, all_quantiles=False):; """"""Estimates error of approx_cdf aggregator, using Hoeffding's inequality. Parameters; ----------; cdf : :obj:`dict`; Result of :func:`.approx_cdf` aggregator, evaluated to a python dict; failure_prob: :obj:`float`; Upper bound on probability of true error being greater than estimated error.; all_quantiles: :obj:`bool`; If ``True``, with probability 1 - `failure_prob`, error estimate applies; to all quantiles simultaneously. Returns; -------; :obj:`float`; Upper bound on error of quantile estimates.; """"""; import math. s = 0; for i in builtins.range(builtins.len(cdf._compaction_counts)):; s += cdf._compaction_counts[i] << (2 * i); s = s / (cdf.ranks[-1] ** 2). def update_grid_size(p):; return 4 * math.sqrt(math.log(2 * p / failure_prob) / (2 * s)). def compute_grid_size(s):; p = 1 / failure_prob; for _ in builtins.range(5):; p = update_grid_size(p); return p. def compute_single_error(s, failure_prob=failure_prob):; return math.sqrt(math.log(2 / failure_prob) * s / 2). if s == 0:; # no compactions ergo no error; return 0; elif all_quantiles:; p = compute_grid_size(s); return 1 / p + compute_single_error(s, failure_prob / p); else:; return compute_single_error(s, failure_prob). [docs]@typecheck(t=hail_type); def missing(t: Union[HailType, str]):; """"""Creates an expression representing a missing value of a specified type. Examples; --------. >>> hl.eval(hl.missing(hl.tarray(hl.tstr))); None. >>> hl.eval(hl.missing('array<str>')); None. Notes; -----; This method is useful for constructing an expression that includes missing; values, since :obj:`None` cannot be interpreted as an expression. Parameters; ----------; t : :class:`str` or :class:`.HailType`; Type of the missing expression. Returns; -------; :class:`.Expression`; A missing expression of type `t`.; """"""; return construct_expr(ir.NA(t), t). [docs]@deprecated(version=""0.2.62"", reason=""Replaced by hl.missing""); @typecheck(t=hail_type); def null(t: Union[HailType, str]):; """"""Deprecate",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:11595,Testability,assert,assert,11595,"ise ExpressionException(; f""'literal' can only accept scalar or global expression arguments,""; f"" found indices {x._indices.axes}""; ); return False; elif x is None or x is pd.NA:; return False; else:; t._typecheck_one_level(x); return True. if dtype is None:; dtype = impute_type(x). # Special handling of numpy. Have to extract from numpy scalars, do nothing on numpy arrays; if isinstance(x, np.generic):; x = x.item(); elif isinstance(x, np.ndarray):; pass; else:; try:; dtype._traverse(x, typecheck_expr); except TypeError as e:; raise TypeError(""'literal': object did not match the passed type '{}'"".format(dtype)) from e. if wrapper['has_free_vars']:; raise ValueError(; ""'literal' cannot be used with hail expressions that depend ""; ""on other expressions. Use expression 'x' directly ""; ""instead of passing it to 'literal'.""; ). if wrapper['has_expr']:; return literal(hl.eval(to_expr(x, dtype)), dtype). if x is None or x is pd.NA:; return hl.missing(dtype); elif is_primitive(dtype):; if dtype == tint32:; assert is_int32(x); assert tint32.min_value <= x <= tint32.max_value; return construct_expr(ir.I32(x), tint32); elif dtype == tint64:; assert is_int64(x); assert tint64.min_value <= x <= tint64.max_value; return construct_expr(ir.I64(x), tint64); elif dtype == tfloat32:; assert is_float32(x); return construct_expr(ir.F32(x), tfloat32); elif dtype == tfloat64:; assert is_float64(x); return construct_expr(ir.F64(x), tfloat64); elif dtype == tbool:; assert isinstance(x, builtins.bool); return construct_expr(ir.TrueIR() if x else ir.FalseIR(), tbool); else:; assert dtype == tstr; assert isinstance(x, builtins.str); return construct_expr(ir.Str(x), tstr); else:; return construct_expr(ir.EncodedLiteral(dtype, x), dtype). [docs]@deprecated(version=""0.2.59"", reason=""Replaced by hl.if_else""); @typecheck(condition=expr_bool, consequent=expr_any, alternate=expr_any, missing_false=bool); def cond(condition, consequent, alternate, missing_false: bool = False):; """"""Deprecated in favor",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:11615,Testability,assert,assert,11615,"ise ExpressionException(; f""'literal' can only accept scalar or global expression arguments,""; f"" found indices {x._indices.axes}""; ); return False; elif x is None or x is pd.NA:; return False; else:; t._typecheck_one_level(x); return True. if dtype is None:; dtype = impute_type(x). # Special handling of numpy. Have to extract from numpy scalars, do nothing on numpy arrays; if isinstance(x, np.generic):; x = x.item(); elif isinstance(x, np.ndarray):; pass; else:; try:; dtype._traverse(x, typecheck_expr); except TypeError as e:; raise TypeError(""'literal': object did not match the passed type '{}'"".format(dtype)) from e. if wrapper['has_free_vars']:; raise ValueError(; ""'literal' cannot be used with hail expressions that depend ""; ""on other expressions. Use expression 'x' directly ""; ""instead of passing it to 'literal'.""; ). if wrapper['has_expr']:; return literal(hl.eval(to_expr(x, dtype)), dtype). if x is None or x is pd.NA:; return hl.missing(dtype); elif is_primitive(dtype):; if dtype == tint32:; assert is_int32(x); assert tint32.min_value <= x <= tint32.max_value; return construct_expr(ir.I32(x), tint32); elif dtype == tint64:; assert is_int64(x); assert tint64.min_value <= x <= tint64.max_value; return construct_expr(ir.I64(x), tint64); elif dtype == tfloat32:; assert is_float32(x); return construct_expr(ir.F32(x), tfloat32); elif dtype == tfloat64:; assert is_float64(x); return construct_expr(ir.F64(x), tfloat64); elif dtype == tbool:; assert isinstance(x, builtins.bool); return construct_expr(ir.TrueIR() if x else ir.FalseIR(), tbool); else:; assert dtype == tstr; assert isinstance(x, builtins.str); return construct_expr(ir.Str(x), tstr); else:; return construct_expr(ir.EncodedLiteral(dtype, x), dtype). [docs]@deprecated(version=""0.2.59"", reason=""Replaced by hl.if_else""); @typecheck(condition=expr_bool, consequent=expr_any, alternate=expr_any, missing_false=bool); def cond(condition, consequent, alternate, missing_false: bool = False):; """"""Deprecated in favor",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:11730,Testability,assert,assert,11730,"; elif x is None or x is pd.NA:; return False; else:; t._typecheck_one_level(x); return True. if dtype is None:; dtype = impute_type(x). # Special handling of numpy. Have to extract from numpy scalars, do nothing on numpy arrays; if isinstance(x, np.generic):; x = x.item(); elif isinstance(x, np.ndarray):; pass; else:; try:; dtype._traverse(x, typecheck_expr); except TypeError as e:; raise TypeError(""'literal': object did not match the passed type '{}'"".format(dtype)) from e. if wrapper['has_free_vars']:; raise ValueError(; ""'literal' cannot be used with hail expressions that depend ""; ""on other expressions. Use expression 'x' directly ""; ""instead of passing it to 'literal'.""; ). if wrapper['has_expr']:; return literal(hl.eval(to_expr(x, dtype)), dtype). if x is None or x is pd.NA:; return hl.missing(dtype); elif is_primitive(dtype):; if dtype == tint32:; assert is_int32(x); assert tint32.min_value <= x <= tint32.max_value; return construct_expr(ir.I32(x), tint32); elif dtype == tint64:; assert is_int64(x); assert tint64.min_value <= x <= tint64.max_value; return construct_expr(ir.I64(x), tint64); elif dtype == tfloat32:; assert is_float32(x); return construct_expr(ir.F32(x), tfloat32); elif dtype == tfloat64:; assert is_float64(x); return construct_expr(ir.F64(x), tfloat64); elif dtype == tbool:; assert isinstance(x, builtins.bool); return construct_expr(ir.TrueIR() if x else ir.FalseIR(), tbool); else:; assert dtype == tstr; assert isinstance(x, builtins.str); return construct_expr(ir.Str(x), tstr); else:; return construct_expr(ir.EncodedLiteral(dtype, x), dtype). [docs]@deprecated(version=""0.2.59"", reason=""Replaced by hl.if_else""); @typecheck(condition=expr_bool, consequent=expr_any, alternate=expr_any, missing_false=bool); def cond(condition, consequent, alternate, missing_false: bool = False):; """"""Deprecated in favor of :func:`.if_else`. Expression for an if/else statement; tests a condition and returns one of two options based on the result. Examples; --------",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:11750,Testability,assert,assert,11750,"; elif x is None or x is pd.NA:; return False; else:; t._typecheck_one_level(x); return True. if dtype is None:; dtype = impute_type(x). # Special handling of numpy. Have to extract from numpy scalars, do nothing on numpy arrays; if isinstance(x, np.generic):; x = x.item(); elif isinstance(x, np.ndarray):; pass; else:; try:; dtype._traverse(x, typecheck_expr); except TypeError as e:; raise TypeError(""'literal': object did not match the passed type '{}'"".format(dtype)) from e. if wrapper['has_free_vars']:; raise ValueError(; ""'literal' cannot be used with hail expressions that depend ""; ""on other expressions. Use expression 'x' directly ""; ""instead of passing it to 'literal'.""; ). if wrapper['has_expr']:; return literal(hl.eval(to_expr(x, dtype)), dtype). if x is None or x is pd.NA:; return hl.missing(dtype); elif is_primitive(dtype):; if dtype == tint32:; assert is_int32(x); assert tint32.min_value <= x <= tint32.max_value; return construct_expr(ir.I32(x), tint32); elif dtype == tint64:; assert is_int64(x); assert tint64.min_value <= x <= tint64.max_value; return construct_expr(ir.I64(x), tint64); elif dtype == tfloat32:; assert is_float32(x); return construct_expr(ir.F32(x), tfloat32); elif dtype == tfloat64:; assert is_float64(x); return construct_expr(ir.F64(x), tfloat64); elif dtype == tbool:; assert isinstance(x, builtins.bool); return construct_expr(ir.TrueIR() if x else ir.FalseIR(), tbool); else:; assert dtype == tstr; assert isinstance(x, builtins.str); return construct_expr(ir.Str(x), tstr); else:; return construct_expr(ir.EncodedLiteral(dtype, x), dtype). [docs]@deprecated(version=""0.2.59"", reason=""Replaced by hl.if_else""); @typecheck(condition=expr_bool, consequent=expr_any, alternate=expr_any, missing_false=bool); def cond(condition, consequent, alternate, missing_false: bool = False):; """"""Deprecated in favor of :func:`.if_else`. Expression for an if/else statement; tests a condition and returns one of two options based on the result. Examples; --------",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:11867,Testability,assert,assert,11867,"cial handling of numpy. Have to extract from numpy scalars, do nothing on numpy arrays; if isinstance(x, np.generic):; x = x.item(); elif isinstance(x, np.ndarray):; pass; else:; try:; dtype._traverse(x, typecheck_expr); except TypeError as e:; raise TypeError(""'literal': object did not match the passed type '{}'"".format(dtype)) from e. if wrapper['has_free_vars']:; raise ValueError(; ""'literal' cannot be used with hail expressions that depend ""; ""on other expressions. Use expression 'x' directly ""; ""instead of passing it to 'literal'.""; ). if wrapper['has_expr']:; return literal(hl.eval(to_expr(x, dtype)), dtype). if x is None or x is pd.NA:; return hl.missing(dtype); elif is_primitive(dtype):; if dtype == tint32:; assert is_int32(x); assert tint32.min_value <= x <= tint32.max_value; return construct_expr(ir.I32(x), tint32); elif dtype == tint64:; assert is_int64(x); assert tint64.min_value <= x <= tint64.max_value; return construct_expr(ir.I64(x), tint64); elif dtype == tfloat32:; assert is_float32(x); return construct_expr(ir.F32(x), tfloat32); elif dtype == tfloat64:; assert is_float64(x); return construct_expr(ir.F64(x), tfloat64); elif dtype == tbool:; assert isinstance(x, builtins.bool); return construct_expr(ir.TrueIR() if x else ir.FalseIR(), tbool); else:; assert dtype == tstr; assert isinstance(x, builtins.str); return construct_expr(ir.Str(x), tstr); else:; return construct_expr(ir.EncodedLiteral(dtype, x), dtype). [docs]@deprecated(version=""0.2.59"", reason=""Replaced by hl.if_else""); @typecheck(condition=expr_bool, consequent=expr_any, alternate=expr_any, missing_false=bool); def cond(condition, consequent, alternate, missing_false: bool = False):; """"""Deprecated in favor of :func:`.if_else`. Expression for an if/else statement; tests a condition and returns one of two options based on the result. Examples; --------. >>> x = 5; >>> hl.eval(hl.cond(x < 2, 'Hi', 'Bye')); 'Bye'. >>> a = hl.literal([1, 2, 3, 4]); >>> hl.eval(hl.cond(hl.len(a) > 0, 2.0 * a, a /",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:11958,Testability,assert,assert,11958," isinstance(x, np.generic):; x = x.item(); elif isinstance(x, np.ndarray):; pass; else:; try:; dtype._traverse(x, typecheck_expr); except TypeError as e:; raise TypeError(""'literal': object did not match the passed type '{}'"".format(dtype)) from e. if wrapper['has_free_vars']:; raise ValueError(; ""'literal' cannot be used with hail expressions that depend ""; ""on other expressions. Use expression 'x' directly ""; ""instead of passing it to 'literal'.""; ). if wrapper['has_expr']:; return literal(hl.eval(to_expr(x, dtype)), dtype). if x is None or x is pd.NA:; return hl.missing(dtype); elif is_primitive(dtype):; if dtype == tint32:; assert is_int32(x); assert tint32.min_value <= x <= tint32.max_value; return construct_expr(ir.I32(x), tint32); elif dtype == tint64:; assert is_int64(x); assert tint64.min_value <= x <= tint64.max_value; return construct_expr(ir.I64(x), tint64); elif dtype == tfloat32:; assert is_float32(x); return construct_expr(ir.F32(x), tfloat32); elif dtype == tfloat64:; assert is_float64(x); return construct_expr(ir.F64(x), tfloat64); elif dtype == tbool:; assert isinstance(x, builtins.bool); return construct_expr(ir.TrueIR() if x else ir.FalseIR(), tbool); else:; assert dtype == tstr; assert isinstance(x, builtins.str); return construct_expr(ir.Str(x), tstr); else:; return construct_expr(ir.EncodedLiteral(dtype, x), dtype). [docs]@deprecated(version=""0.2.59"", reason=""Replaced by hl.if_else""); @typecheck(condition=expr_bool, consequent=expr_any, alternate=expr_any, missing_false=bool); def cond(condition, consequent, alternate, missing_false: bool = False):; """"""Deprecated in favor of :func:`.if_else`. Expression for an if/else statement; tests a condition and returns one of two options based on the result. Examples; --------. >>> x = 5; >>> hl.eval(hl.cond(x < 2, 'Hi', 'Bye')); 'Bye'. >>> a = hl.literal([1, 2, 3, 4]); >>> hl.eval(hl.cond(hl.len(a) > 0, 2.0 * a, a / 2.0)); [2.0, 4.0, 6.0, 8.0]. Notes; -----. If `condition` evaluates to ``True``, returns ",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:12046,Testability,assert,assert,12046," else:; try:; dtype._traverse(x, typecheck_expr); except TypeError as e:; raise TypeError(""'literal': object did not match the passed type '{}'"".format(dtype)) from e. if wrapper['has_free_vars']:; raise ValueError(; ""'literal' cannot be used with hail expressions that depend ""; ""on other expressions. Use expression 'x' directly ""; ""instead of passing it to 'literal'.""; ). if wrapper['has_expr']:; return literal(hl.eval(to_expr(x, dtype)), dtype). if x is None or x is pd.NA:; return hl.missing(dtype); elif is_primitive(dtype):; if dtype == tint32:; assert is_int32(x); assert tint32.min_value <= x <= tint32.max_value; return construct_expr(ir.I32(x), tint32); elif dtype == tint64:; assert is_int64(x); assert tint64.min_value <= x <= tint64.max_value; return construct_expr(ir.I64(x), tint64); elif dtype == tfloat32:; assert is_float32(x); return construct_expr(ir.F32(x), tfloat32); elif dtype == tfloat64:; assert is_float64(x); return construct_expr(ir.F64(x), tfloat64); elif dtype == tbool:; assert isinstance(x, builtins.bool); return construct_expr(ir.TrueIR() if x else ir.FalseIR(), tbool); else:; assert dtype == tstr; assert isinstance(x, builtins.str); return construct_expr(ir.Str(x), tstr); else:; return construct_expr(ir.EncodedLiteral(dtype, x), dtype). [docs]@deprecated(version=""0.2.59"", reason=""Replaced by hl.if_else""); @typecheck(condition=expr_bool, consequent=expr_any, alternate=expr_any, missing_false=bool); def cond(condition, consequent, alternate, missing_false: bool = False):; """"""Deprecated in favor of :func:`.if_else`. Expression for an if/else statement; tests a condition and returns one of two options based on the result. Examples; --------. >>> x = 5; >>> hl.eval(hl.cond(x < 2, 'Hi', 'Bye')); 'Bye'. >>> a = hl.literal([1, 2, 3, 4]); >>> hl.eval(hl.cond(hl.len(a) > 0, 2.0 * a, a / 2.0)); [2.0, 4.0, 6.0, 8.0]. Notes; -----. If `condition` evaluates to ``True``, returns `consequent`. If `condition`; evaluates to ``False``, returns `alternate`. If `pr",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:12156,Testability,assert,assert,12156,"ssed type '{}'"".format(dtype)) from e. if wrapper['has_free_vars']:; raise ValueError(; ""'literal' cannot be used with hail expressions that depend ""; ""on other expressions. Use expression 'x' directly ""; ""instead of passing it to 'literal'.""; ). if wrapper['has_expr']:; return literal(hl.eval(to_expr(x, dtype)), dtype). if x is None or x is pd.NA:; return hl.missing(dtype); elif is_primitive(dtype):; if dtype == tint32:; assert is_int32(x); assert tint32.min_value <= x <= tint32.max_value; return construct_expr(ir.I32(x), tint32); elif dtype == tint64:; assert is_int64(x); assert tint64.min_value <= x <= tint64.max_value; return construct_expr(ir.I64(x), tint64); elif dtype == tfloat32:; assert is_float32(x); return construct_expr(ir.F32(x), tfloat32); elif dtype == tfloat64:; assert is_float64(x); return construct_expr(ir.F64(x), tfloat64); elif dtype == tbool:; assert isinstance(x, builtins.bool); return construct_expr(ir.TrueIR() if x else ir.FalseIR(), tbool); else:; assert dtype == tstr; assert isinstance(x, builtins.str); return construct_expr(ir.Str(x), tstr); else:; return construct_expr(ir.EncodedLiteral(dtype, x), dtype). [docs]@deprecated(version=""0.2.59"", reason=""Replaced by hl.if_else""); @typecheck(condition=expr_bool, consequent=expr_any, alternate=expr_any, missing_false=bool); def cond(condition, consequent, alternate, missing_false: bool = False):; """"""Deprecated in favor of :func:`.if_else`. Expression for an if/else statement; tests a condition and returns one of two options based on the result. Examples; --------. >>> x = 5; >>> hl.eval(hl.cond(x < 2, 'Hi', 'Bye')); 'Bye'. >>> a = hl.literal([1, 2, 3, 4]); >>> hl.eval(hl.cond(hl.len(a) > 0, 2.0 * a, a / 2.0)); [2.0, 4.0, 6.0, 8.0]. Notes; -----. If `condition` evaluates to ``True``, returns `consequent`. If `condition`; evaluates to ``False``, returns `alternate`. If `predicate` is missing, returns; missing. Note; ----; The type of `consequent` and `alternate` must be the same. Parameters; ------",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:12178,Testability,assert,assert,12178,"ssed type '{}'"".format(dtype)) from e. if wrapper['has_free_vars']:; raise ValueError(; ""'literal' cannot be used with hail expressions that depend ""; ""on other expressions. Use expression 'x' directly ""; ""instead of passing it to 'literal'.""; ). if wrapper['has_expr']:; return literal(hl.eval(to_expr(x, dtype)), dtype). if x is None or x is pd.NA:; return hl.missing(dtype); elif is_primitive(dtype):; if dtype == tint32:; assert is_int32(x); assert tint32.min_value <= x <= tint32.max_value; return construct_expr(ir.I32(x), tint32); elif dtype == tint64:; assert is_int64(x); assert tint64.min_value <= x <= tint64.max_value; return construct_expr(ir.I64(x), tint64); elif dtype == tfloat32:; assert is_float32(x); return construct_expr(ir.F32(x), tfloat32); elif dtype == tfloat64:; assert is_float64(x); return construct_expr(ir.F64(x), tfloat64); elif dtype == tbool:; assert isinstance(x, builtins.bool); return construct_expr(ir.TrueIR() if x else ir.FalseIR(), tbool); else:; assert dtype == tstr; assert isinstance(x, builtins.str); return construct_expr(ir.Str(x), tstr); else:; return construct_expr(ir.EncodedLiteral(dtype, x), dtype). [docs]@deprecated(version=""0.2.59"", reason=""Replaced by hl.if_else""); @typecheck(condition=expr_bool, consequent=expr_any, alternate=expr_any, missing_false=bool); def cond(condition, consequent, alternate, missing_false: bool = False):; """"""Deprecated in favor of :func:`.if_else`. Expression for an if/else statement; tests a condition and returns one of two options based on the result. Examples; --------. >>> x = 5; >>> hl.eval(hl.cond(x < 2, 'Hi', 'Bye')); 'Bye'. >>> a = hl.literal([1, 2, 3, 4]); >>> hl.eval(hl.cond(hl.len(a) > 0, 2.0 * a, a / 2.0)); [2.0, 4.0, 6.0, 8.0]. Notes; -----. If `condition` evaluates to ``True``, returns `consequent`. If `condition`; evaluates to ``False``, returns `alternate`. If `predicate` is missing, returns; missing. Note; ----; The type of `consequent` and `alternate` must be the same. Parameters; ------",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:12639,Testability,test,tests,12639,"max_value; return construct_expr(ir.I32(x), tint32); elif dtype == tint64:; assert is_int64(x); assert tint64.min_value <= x <= tint64.max_value; return construct_expr(ir.I64(x), tint64); elif dtype == tfloat32:; assert is_float32(x); return construct_expr(ir.F32(x), tfloat32); elif dtype == tfloat64:; assert is_float64(x); return construct_expr(ir.F64(x), tfloat64); elif dtype == tbool:; assert isinstance(x, builtins.bool); return construct_expr(ir.TrueIR() if x else ir.FalseIR(), tbool); else:; assert dtype == tstr; assert isinstance(x, builtins.str); return construct_expr(ir.Str(x), tstr); else:; return construct_expr(ir.EncodedLiteral(dtype, x), dtype). [docs]@deprecated(version=""0.2.59"", reason=""Replaced by hl.if_else""); @typecheck(condition=expr_bool, consequent=expr_any, alternate=expr_any, missing_false=bool); def cond(condition, consequent, alternate, missing_false: bool = False):; """"""Deprecated in favor of :func:`.if_else`. Expression for an if/else statement; tests a condition and returns one of two options based on the result. Examples; --------. >>> x = 5; >>> hl.eval(hl.cond(x < 2, 'Hi', 'Bye')); 'Bye'. >>> a = hl.literal([1, 2, 3, 4]); >>> hl.eval(hl.cond(hl.len(a) > 0, 2.0 * a, a / 2.0)); [2.0, 4.0, 6.0, 8.0]. Notes; -----. If `condition` evaluates to ``True``, returns `consequent`. If `condition`; evaluates to ``False``, returns `alternate`. If `predicate` is missing, returns; missing. Note; ----; The type of `consequent` and `alternate` must be the same. Parameters; ----------; condition : :class:`.BooleanExpression`; Condition to test.; consequent : :class:`.Expression`; Branch to return if the condition is ``True``.; alternate : :class:`.Expression`; Branch to return if the condition is ``False``.; missing_false : :obj:`.bool`; If ``True``, treat missing `condition` as ``False``. See Also; --------; :func:`.case`, :func:`.switch`, :func:`.if_else`. Returns; -------; :class:`.Expression`; One of `consequent`, `alternate`, or missing, based on `cond",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:13229,Testability,test,test,13229,"eturn construct_expr(ir.Str(x), tstr); else:; return construct_expr(ir.EncodedLiteral(dtype, x), dtype). [docs]@deprecated(version=""0.2.59"", reason=""Replaced by hl.if_else""); @typecheck(condition=expr_bool, consequent=expr_any, alternate=expr_any, missing_false=bool); def cond(condition, consequent, alternate, missing_false: bool = False):; """"""Deprecated in favor of :func:`.if_else`. Expression for an if/else statement; tests a condition and returns one of two options based on the result. Examples; --------. >>> x = 5; >>> hl.eval(hl.cond(x < 2, 'Hi', 'Bye')); 'Bye'. >>> a = hl.literal([1, 2, 3, 4]); >>> hl.eval(hl.cond(hl.len(a) > 0, 2.0 * a, a / 2.0)); [2.0, 4.0, 6.0, 8.0]. Notes; -----. If `condition` evaluates to ``True``, returns `consequent`. If `condition`; evaluates to ``False``, returns `alternate`. If `predicate` is missing, returns; missing. Note; ----; The type of `consequent` and `alternate` must be the same. Parameters; ----------; condition : :class:`.BooleanExpression`; Condition to test.; consequent : :class:`.Expression`; Branch to return if the condition is ``True``.; alternate : :class:`.Expression`; Branch to return if the condition is ``False``.; missing_false : :obj:`.bool`; If ``True``, treat missing `condition` as ``False``. See Also; --------; :func:`.case`, :func:`.switch`, :func:`.if_else`. Returns; -------; :class:`.Expression`; One of `consequent`, `alternate`, or missing, based on `condition`.; """"""; return if_else(condition, consequent, alternate, missing_false). [docs]@typecheck(condition=expr_bool, consequent=expr_any, alternate=expr_any, missing_false=bool); def if_else(condition, consequent, alternate, missing_false: bool = False):; """"""Expression for an if/else statement; tests a condition and returns one of two options based on the result. Examples; --------. >>> x = 5; >>> hl.eval(hl.if_else(x < 2, 'Hi', 'Bye')); 'Bye'. >>> a = hl.literal([1, 2, 3, 4]); >>> hl.eval(hl.if_else(hl.len(a) > 0, 2.0 * a, a / 2.0)); [2.0, 4.0, 6.0, 8.0",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:13951,Testability,test,tests,13951,"; [2.0, 4.0, 6.0, 8.0]. Notes; -----. If `condition` evaluates to ``True``, returns `consequent`. If `condition`; evaluates to ``False``, returns `alternate`. If `predicate` is missing, returns; missing. Note; ----; The type of `consequent` and `alternate` must be the same. Parameters; ----------; condition : :class:`.BooleanExpression`; Condition to test.; consequent : :class:`.Expression`; Branch to return if the condition is ``True``.; alternate : :class:`.Expression`; Branch to return if the condition is ``False``.; missing_false : :obj:`.bool`; If ``True``, treat missing `condition` as ``False``. See Also; --------; :func:`.case`, :func:`.switch`, :func:`.if_else`. Returns; -------; :class:`.Expression`; One of `consequent`, `alternate`, or missing, based on `condition`.; """"""; return if_else(condition, consequent, alternate, missing_false). [docs]@typecheck(condition=expr_bool, consequent=expr_any, alternate=expr_any, missing_false=bool); def if_else(condition, consequent, alternate, missing_false: bool = False):; """"""Expression for an if/else statement; tests a condition and returns one of two options based on the result. Examples; --------. >>> x = 5; >>> hl.eval(hl.if_else(x < 2, 'Hi', 'Bye')); 'Bye'. >>> a = hl.literal([1, 2, 3, 4]); >>> hl.eval(hl.if_else(hl.len(a) > 0, 2.0 * a, a / 2.0)); [2.0, 4.0, 6.0, 8.0]. Notes; -----. If `condition` evaluates to ``True``, returns `consequent`. If `condition`; evaluates to ``False``, returns `alternate`. If `predicate` is missing, returns; missing. Note; ----; The type of `consequent` and `alternate` must be the same. Parameters; ----------; condition : :class:`.BooleanExpression`; Condition to test.; consequent : :class:`.Expression`; Branch to return if the condition is ``True``.; alternate : :class:`.Expression`; Branch to return if the condition is ``False``.; missing_false : :obj:`.bool`; If ``True``, treat missing `condition` as ``False``. See Also; --------; :func:`.case`, :func:`.switch`. Returns; -------; :cla",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:14547,Testability,test,test,14547,"h`, :func:`.if_else`. Returns; -------; :class:`.Expression`; One of `consequent`, `alternate`, or missing, based on `condition`.; """"""; return if_else(condition, consequent, alternate, missing_false). [docs]@typecheck(condition=expr_bool, consequent=expr_any, alternate=expr_any, missing_false=bool); def if_else(condition, consequent, alternate, missing_false: bool = False):; """"""Expression for an if/else statement; tests a condition and returns one of two options based on the result. Examples; --------. >>> x = 5; >>> hl.eval(hl.if_else(x < 2, 'Hi', 'Bye')); 'Bye'. >>> a = hl.literal([1, 2, 3, 4]); >>> hl.eval(hl.if_else(hl.len(a) > 0, 2.0 * a, a / 2.0)); [2.0, 4.0, 6.0, 8.0]. Notes; -----. If `condition` evaluates to ``True``, returns `consequent`. If `condition`; evaluates to ``False``, returns `alternate`. If `predicate` is missing, returns; missing. Note; ----; The type of `consequent` and `alternate` must be the same. Parameters; ----------; condition : :class:`.BooleanExpression`; Condition to test.; consequent : :class:`.Expression`; Branch to return if the condition is ``True``.; alternate : :class:`.Expression`; Branch to return if the condition is ``False``.; missing_false : :obj:`.bool`; If ``True``, treat missing `condition` as ``False``. See Also; --------; :func:`.case`, :func:`.switch`. Returns; -------; :class:`.Expression`; One of `consequent`, `alternate`, or missing, based on `condition`.; """"""; if missing_false:; condition = hl.bind(lambda x: hl.is_defined(x) & x, condition); indices, aggregations = unify_all(condition, consequent, alternate). consequent, alternate, success = unify_exprs(consequent, alternate); if not success:; raise TypeError(; f""'if_else' and 'cond' require the 'consequent' and 'alternate' arguments to have the same type\n""; f"" consequent: type '{consequent.dtype}'\n""; f"" alternate: type '{alternate.dtype}'""; ); assert consequent.dtype == alternate.dtype. return construct_expr(ir.If(condition._ir, consequent._ir, alternate._ir), ",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:15414,Testability,assert,assert,15414,"pe of `consequent` and `alternate` must be the same. Parameters; ----------; condition : :class:`.BooleanExpression`; Condition to test.; consequent : :class:`.Expression`; Branch to return if the condition is ``True``.; alternate : :class:`.Expression`; Branch to return if the condition is ``False``.; missing_false : :obj:`.bool`; If ``True``, treat missing `condition` as ``False``. See Also; --------; :func:`.case`, :func:`.switch`. Returns; -------; :class:`.Expression`; One of `consequent`, `alternate`, or missing, based on `condition`.; """"""; if missing_false:; condition = hl.bind(lambda x: hl.is_defined(x) & x, condition); indices, aggregations = unify_all(condition, consequent, alternate). consequent, alternate, success = unify_exprs(consequent, alternate); if not success:; raise TypeError(; f""'if_else' and 'cond' require the 'consequent' and 'alternate' arguments to have the same type\n""; f"" consequent: type '{consequent.dtype}'\n""; f"" alternate: type '{alternate.dtype}'""; ); assert consequent.dtype == alternate.dtype. return construct_expr(ir.If(condition._ir, consequent._ir, alternate._ir), consequent.dtype, indices, aggregations). [docs]def case(missing_false: bool = False) -> 'hail.expr.builders.CaseBuilder':; """"""Chain multiple if-else statements with a :class:`.CaseBuilder`. Examples; --------. >>> x = hl.literal('foo bar baz'); >>> expr = (hl.case(); ... .when(x[:3] == 'FOO', 1); ... .when(hl.len(x) == 11, 2); ... .when(x == 'secret phrase', 3); ... .default(0)); >>> hl.eval(expr); 2. Parameters; ----------; missing_false : :obj:`bool`; Treat missing predicates as ``False``. See Also; --------; :class:`.CaseBuilder`, :func:`.switch`, :func:`.cond`. Returns; -------; :class:`.CaseBuilder`.; """"""; from .builders import CaseBuilder. return CaseBuilder(missing_false=missing_false). [docs]@typecheck(expr=expr_any); def switch(expr) -> 'hail.expr.builders.SwitchBuilder':; """"""Build a conditional tree on the value of an expression. Examples; --------. >>> csq = h",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:19203,Testability,test,test,19203,"alue_ir, res_ir, is_scan=True); else:; res_ir = ir.Let(uid, value_ir, res_ir). return construct_expr(res_ir, lambda_result.dtype, indices, aggregations). [docs]def rbind(*exprs, _ctx=None):; """"""Bind a temporary variable and use it in a function. This is :func:`.bind` with flipped argument order. Examples; --------. >>> hl.eval(hl.rbind(1, lambda x: x + 1)); 2. :func:`.rbind` also can take multiple arguments:. >>> hl.eval(hl.rbind(4.0, 2.0, lambda x, y: x / y)); 2.0. Parameters; ----------; exprs : variable-length args of :class:`.Expression`; Expressions to bind.; f : function ( (args) -> :class:`.Expression`); Function of `exprs`. Returns; -------; :class:`.Expression`; Result of evaluating `f` with `exprs` as arguments.; """""". *args, f = exprs; args = [expr_any.check(arg, 'rbind', f'argument {index}') for index, arg in builtins.enumerate(args)]. return hl.bind(f, *args, _ctx=_ctx). [docs]@typecheck(c1=expr_int32, c2=expr_int32, c3=expr_int32, c4=expr_int32); def chi_squared_test(c1, c2, c3, c4) -> StructExpression:; """"""Performs chi-squared test of independence on a 2x2 contingency table. Examples; --------. >>> hl.eval(hl.chi_squared_test(10, 10, 10, 10)); Struct(p_value=1.0, odds_ratio=1.0). >>> hl.eval(hl.chi_squared_test(51, 43, 22, 92)); Struct(p_value=1.4626257805267089e-07, odds_ratio=4.959830866807611). Notes; -----; The odds ratio is given by ``(c1 / c2) / (c3 / c4)``. Returned fields may be ``nan`` or ``inf``. Parameters; ----------; c1 : int or :class:`.Expression` of type :py:data:`.tint32`; Value for cell 1.; c2 : int or :class:`.Expression` of type :py:data:`.tint32`; Value for cell 2.; c3 : int or :class:`.Expression` of type :py:data:`.tint32`; Value for cell 3.; c4 : int or :class:`.Expression` of type :py:data:`.tint32`; Value for cell 4. Returns; -------; :class:`.StructExpression`; A :class:`.tstruct` expression with two fields, `p_value`; (:py:data:`.tfloat64`) and `odds_ratio` (:py:data:`.tfloat64`).; """"""; ret_type = tstruct(p_value=tfloat64, o",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:20455,Testability,test,test,20455,".eval(hl.chi_squared_test(51, 43, 22, 92)); Struct(p_value=1.4626257805267089e-07, odds_ratio=4.959830866807611). Notes; -----; The odds ratio is given by ``(c1 / c2) / (c3 / c4)``. Returned fields may be ``nan`` or ``inf``. Parameters; ----------; c1 : int or :class:`.Expression` of type :py:data:`.tint32`; Value for cell 1.; c2 : int or :class:`.Expression` of type :py:data:`.tint32`; Value for cell 2.; c3 : int or :class:`.Expression` of type :py:data:`.tint32`; Value for cell 3.; c4 : int or :class:`.Expression` of type :py:data:`.tint32`; Value for cell 4. Returns; -------; :class:`.StructExpression`; A :class:`.tstruct` expression with two fields, `p_value`; (:py:data:`.tfloat64`) and `odds_ratio` (:py:data:`.tfloat64`).; """"""; ret_type = tstruct(p_value=tfloat64, odds_ratio=tfloat64); return _func(""chi_squared_test"", ret_type, c1, c2, c3, c4). [docs]@typecheck(c1=expr_int32, c2=expr_int32, c3=expr_int32, c4=expr_int32, min_cell_count=expr_int32); def contingency_table_test(c1, c2, c3, c4, min_cell_count) -> StructExpression:; """"""Performs chi-squared or Fisher's exact test of independence on a 2x2; contingency table. Examples; --------. >>> hl.eval(hl.contingency_table_test(51, 43, 22, 92, min_cell_count=22)); Struct(p_value=1.4626257805267089e-07, odds_ratio=4.959830866807611). >>> hl.eval(hl.contingency_table_test(51, 43, 22, 92, min_cell_count=23)); Struct(p_value=2.1564999740157304e-07, odds_ratio=4.918058171469967). Notes; -----; If all cell counts are at least `min_cell_count`, the chi-squared test is; used. Otherwise, Fisher's exact test is used. Returned fields may be ``nan`` or ``inf``. Parameters; ----------; c1 : int or :class:`.Expression` of type :py:data:`.tint32`; Value for cell 1.; c2 : int or :class:`.Expression` of type :py:data:`.tint32`; Value for cell 2.; c3 : int or :class:`.Expression` of type :py:data:`.tint32`; Value for cell 3.; c4 : int or :class:`.Expression` of type :py:data:`.tint32`; Value for cell 4.; min_cell_count : int or :cla",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:20895,Testability,test,test,20895,"t or :class:`.Expression` of type :py:data:`.tint32`; Value for cell 4. Returns; -------; :class:`.StructExpression`; A :class:`.tstruct` expression with two fields, `p_value`; (:py:data:`.tfloat64`) and `odds_ratio` (:py:data:`.tfloat64`).; """"""; ret_type = tstruct(p_value=tfloat64, odds_ratio=tfloat64); return _func(""chi_squared_test"", ret_type, c1, c2, c3, c4). [docs]@typecheck(c1=expr_int32, c2=expr_int32, c3=expr_int32, c4=expr_int32, min_cell_count=expr_int32); def contingency_table_test(c1, c2, c3, c4, min_cell_count) -> StructExpression:; """"""Performs chi-squared or Fisher's exact test of independence on a 2x2; contingency table. Examples; --------. >>> hl.eval(hl.contingency_table_test(51, 43, 22, 92, min_cell_count=22)); Struct(p_value=1.4626257805267089e-07, odds_ratio=4.959830866807611). >>> hl.eval(hl.contingency_table_test(51, 43, 22, 92, min_cell_count=23)); Struct(p_value=2.1564999740157304e-07, odds_ratio=4.918058171469967). Notes; -----; If all cell counts are at least `min_cell_count`, the chi-squared test is; used. Otherwise, Fisher's exact test is used. Returned fields may be ``nan`` or ``inf``. Parameters; ----------; c1 : int or :class:`.Expression` of type :py:data:`.tint32`; Value for cell 1.; c2 : int or :class:`.Expression` of type :py:data:`.tint32`; Value for cell 2.; c3 : int or :class:`.Expression` of type :py:data:`.tint32`; Value for cell 3.; c4 : int or :class:`.Expression` of type :py:data:`.tint32`; Value for cell 4.; min_cell_count : int or :class:`.Expression` of type :py:data:`.tint32`; Minimum count in every cell to use the chi-squared test. Returns; -------; :class:`.StructExpression`; A :class:`.tstruct` expression with two fields, `p_value`; (:py:data:`.tfloat64`) and `odds_ratio` (:py:data:`.tfloat64`).; """"""; ret_type = tstruct(p_value=tfloat64, odds_ratio=tfloat64); return _func(""contingency_table_test"", ret_type, c1, c2, c3, c4, min_cell_count). # We use 64-bit integers.; # It is relatively easy to encounter an integer over",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:20936,Testability,test,test,20936," 4. Returns; -------; :class:`.StructExpression`; A :class:`.tstruct` expression with two fields, `p_value`; (:py:data:`.tfloat64`) and `odds_ratio` (:py:data:`.tfloat64`).; """"""; ret_type = tstruct(p_value=tfloat64, odds_ratio=tfloat64); return _func(""chi_squared_test"", ret_type, c1, c2, c3, c4). [docs]@typecheck(c1=expr_int32, c2=expr_int32, c3=expr_int32, c4=expr_int32, min_cell_count=expr_int32); def contingency_table_test(c1, c2, c3, c4, min_cell_count) -> StructExpression:; """"""Performs chi-squared or Fisher's exact test of independence on a 2x2; contingency table. Examples; --------. >>> hl.eval(hl.contingency_table_test(51, 43, 22, 92, min_cell_count=22)); Struct(p_value=1.4626257805267089e-07, odds_ratio=4.959830866807611). >>> hl.eval(hl.contingency_table_test(51, 43, 22, 92, min_cell_count=23)); Struct(p_value=2.1564999740157304e-07, odds_ratio=4.918058171469967). Notes; -----; If all cell counts are at least `min_cell_count`, the chi-squared test is; used. Otherwise, Fisher's exact test is used. Returned fields may be ``nan`` or ``inf``. Parameters; ----------; c1 : int or :class:`.Expression` of type :py:data:`.tint32`; Value for cell 1.; c2 : int or :class:`.Expression` of type :py:data:`.tint32`; Value for cell 2.; c3 : int or :class:`.Expression` of type :py:data:`.tint32`; Value for cell 3.; c4 : int or :class:`.Expression` of type :py:data:`.tint32`; Value for cell 4.; min_cell_count : int or :class:`.Expression` of type :py:data:`.tint32`; Minimum count in every cell to use the chi-squared test. Returns; -------; :class:`.StructExpression`; A :class:`.tstruct` expression with two fields, `p_value`; (:py:data:`.tfloat64`) and `odds_ratio` (:py:data:`.tfloat64`).; """"""; ret_type = tstruct(p_value=tfloat64, odds_ratio=tfloat64); return _func(""contingency_table_test"", ret_type, c1, c2, c3, c4, min_cell_count). # We use 64-bit integers.; # It is relatively easy to encounter an integer overflow bug with 32-bit integers.; [docs]@typecheck(a=expr_array(expr_",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:21461,Testability,test,test,21461,"red or Fisher's exact test of independence on a 2x2; contingency table. Examples; --------. >>> hl.eval(hl.contingency_table_test(51, 43, 22, 92, min_cell_count=22)); Struct(p_value=1.4626257805267089e-07, odds_ratio=4.959830866807611). >>> hl.eval(hl.contingency_table_test(51, 43, 22, 92, min_cell_count=23)); Struct(p_value=2.1564999740157304e-07, odds_ratio=4.918058171469967). Notes; -----; If all cell counts are at least `min_cell_count`, the chi-squared test is; used. Otherwise, Fisher's exact test is used. Returned fields may be ``nan`` or ``inf``. Parameters; ----------; c1 : int or :class:`.Expression` of type :py:data:`.tint32`; Value for cell 1.; c2 : int or :class:`.Expression` of type :py:data:`.tint32`; Value for cell 2.; c3 : int or :class:`.Expression` of type :py:data:`.tint32`; Value for cell 3.; c4 : int or :class:`.Expression` of type :py:data:`.tint32`; Value for cell 4.; min_cell_count : int or :class:`.Expression` of type :py:data:`.tint32`; Minimum count in every cell to use the chi-squared test. Returns; -------; :class:`.StructExpression`; A :class:`.tstruct` expression with two fields, `p_value`; (:py:data:`.tfloat64`) and `odds_ratio` (:py:data:`.tfloat64`).; """"""; ret_type = tstruct(p_value=tfloat64, odds_ratio=tfloat64); return _func(""contingency_table_test"", ret_type, c1, c2, c3, c4, min_cell_count). # We use 64-bit integers.; # It is relatively easy to encounter an integer overflow bug with 32-bit integers.; [docs]@typecheck(a=expr_array(expr_int64), b=expr_array(expr_int64), c=expr_array(expr_int64), d=expr_array(expr_int64)); def cochran_mantel_haenszel_test(; a: Union[tarray, list], b: Union[tarray, list], c: Union[tarray, list], d: Union[tarray, list]; ) -> StructExpression:; """"""Perform the Cochran-Mantel-Haenszel test for association. Examples; --------; >>> a = [56, 61, 73, 71]; >>> b = [69, 257, 65, 48]; >>> c = [40, 57, 71, 55]; >>> d = [77, 301, 79, 48]; >>> hl.eval(hl.cochran_mantel_haenszel_test(a, b, c, d)); Struct(test_statis",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:22210,Testability,test,test,22210,":data:`.tint32`; Value for cell 1.; c2 : int or :class:`.Expression` of type :py:data:`.tint32`; Value for cell 2.; c3 : int or :class:`.Expression` of type :py:data:`.tint32`; Value for cell 3.; c4 : int or :class:`.Expression` of type :py:data:`.tint32`; Value for cell 4.; min_cell_count : int or :class:`.Expression` of type :py:data:`.tint32`; Minimum count in every cell to use the chi-squared test. Returns; -------; :class:`.StructExpression`; A :class:`.tstruct` expression with two fields, `p_value`; (:py:data:`.tfloat64`) and `odds_ratio` (:py:data:`.tfloat64`).; """"""; ret_type = tstruct(p_value=tfloat64, odds_ratio=tfloat64); return _func(""contingency_table_test"", ret_type, c1, c2, c3, c4, min_cell_count). # We use 64-bit integers.; # It is relatively easy to encounter an integer overflow bug with 32-bit integers.; [docs]@typecheck(a=expr_array(expr_int64), b=expr_array(expr_int64), c=expr_array(expr_int64), d=expr_array(expr_int64)); def cochran_mantel_haenszel_test(; a: Union[tarray, list], b: Union[tarray, list], c: Union[tarray, list], d: Union[tarray, list]; ) -> StructExpression:; """"""Perform the Cochran-Mantel-Haenszel test for association. Examples; --------; >>> a = [56, 61, 73, 71]; >>> b = [69, 257, 65, 48]; >>> c = [40, 57, 71, 55]; >>> d = [77, 301, 79, 48]; >>> hl.eval(hl.cochran_mantel_haenszel_test(a, b, c, d)); Struct(test_statistic=5.0496881823306765, p_value=0.024630370456863417). >>> mt = ds.filter_rows(mt.locus == hl.Locus(20, 10633237)); >>> mt.count_rows(); 1; >>> a, b, c, d = mt.aggregate_entries(; ... hl.tuple([; ... hl.array([hl.agg.count_where(mt.GT.is_non_ref() & mt.pheno.is_case & mt.pheno.is_female), hl.agg.count_where(mt.GT.is_non_ref() & mt.pheno.is_case & ~mt.pheno.is_female)]),; ... hl.array([hl.agg.count_where(mt.GT.is_non_ref() & ~mt.pheno.is_case & mt.pheno.is_female), hl.agg.count_where(mt.GT.is_non_ref() & ~mt.pheno.is_case & ~mt.pheno.is_female)]),; ... hl.array([hl.agg.count_where(~mt.GT.is_non_ref() & mt.pheno.is_case & ",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:26198,Testability,assert,assert,26198,"*tup))). test_statistic = numerator / denominator; p_value = pchisqtail(test_statistic, 1); return struct(test_statistic=test_statistic, p_value=p_value). [docs]@typecheck(; collection=expr_oneof(; expr_dict(), expr_set(expr_tuple([expr_any, expr_any])), expr_array(expr_tuple([expr_any, expr_any])); ); ); def dict(collection) -> DictExpression:; """"""Creates a dictionary. Examples; --------. >>> hl.eval(hl.dict([('foo', 1), ('bar', 2), ('baz', 3)])); {'bar': 2, 'baz': 3, 'foo': 1}. Notes; -----; This method expects arrays or sets with elements of type :class:`.ttuple`; with 2 fields. The first field of the tuple becomes the key, and the second; field becomes the value. Parameters; ----------; collection : :class:`.DictExpression` or :class:`.ArrayExpression` or :class:`.SetExpression`. Returns; -------; :class:`.DictExpression`; """"""; if isinstance(collection.dtype, (tarray, tset)):; key_type, value_type = collection.dtype.element_type.types; return _func('dict', tdict(key_type, value_type), collection); else:; assert isinstance(collection.dtype, tdict); return collection. [docs]@typecheck(x=expr_float64, a=expr_float64, b=expr_float64); def dbeta(x, a, b) -> Float64Expression:; """"""; Returns the probability density at `x` of a `beta distribution; <https://en.wikipedia.org/wiki/Beta_distribution>`__ with parameters `a`; (alpha) and `b` (beta). Examples; --------. >>> hl.eval(hl.dbeta(.2, 5, 20)); 4.900377563180943. Parameters; ----------; x : :obj:`float` or :class:`.Expression` of type :py:data:`.tfloat64`; Point in [0,1] at which to sample. If a < 1 then x must be positive.; If b < 1 then x must be less than 1.; a : :obj:`float` or :class:`.Expression` of type :py:data:`.tfloat64`; The alpha parameter in the beta distribution. The result is undefined; for non-positive a.; b : :obj:`float` or :class:`.Expression` of type :py:data:`.tfloat64`; The beta parameter in the beta distribution. The result is undefined; for non-positive b. Returns; -------; :class:`.Float64Expr",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:28115,Testability,log,logarithm,28115,"or non-positive b. Returns; -------; :class:`.Float64Expression`; """"""; return _func(""dbeta"", tfloat64, x, a, b). [docs]@typecheck(x=expr_float64, df=expr_float64, ncp=nullable(expr_float64), log_p=expr_bool); def dchisq(x, df, ncp=None, log_p=False) -> Float64Expression:; """"""Compute the probability density at `x` of a chi-squared distribution with `df`; degrees of freedom. Examples; --------. >>> hl.eval(hl.dchisq(1, 2)); 0.3032653298563167. >>> hl.eval(hl.dchisq(1, 2, ncp=2)); 0.17472016746112667. >>> hl.eval(hl.dchisq(1, 2, log_p=True)); -1.1931471805599454. Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64`; Non-negative number at which to compute the probability density.; df : float or :class:`.Expression` of type :py:data:`.tfloat64`; Degrees of freedom.; ncp: float or :class:`.Expression` of type :py:data:`.tfloat64`; Noncentrality parameter, defaults to 0 if unspecified.; log_p : bool or :class:`.BooleanExpression`; If ``True``, the natural logarithm of the probability density is returned. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`; The probability density.; """"""; if ncp is None:; return _func(""dchisq"", tfloat64, x, df, log_p); else:; return _func(""dnchisq"", tfloat64, x, df, ncp, log_p). [docs]@typecheck(x=expr_float64, mu=expr_float64, sigma=expr_float64, log_p=expr_bool); def dnorm(x, mu=0, sigma=1, log_p=False) -> Float64Expression:; """"""Compute the probability density at `x` of a normal distribution with mean; `mu` and standard deviation `sigma`. Returns density of standard normal; distribution by default. Examples; --------. >>> hl.eval(hl.dnorm(1)); 0.24197072451914337. >>> hl.eval(hl.dnorm(1, mu=1, sigma=2)); 0.19947114020071635. >>> hl.eval(hl.dnorm(1, log_p=True)); -1.4189385332046727. Parameters; ----------; x : :obj:`float` or :class:`.Expression` of type :py:data:`.tfloat64`; Real number at which to compute the probability density.; mu : float or :class:`.Expression` of type :py:data:`.tfl",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:29325,Testability,log,logarithm,29325,"); else:; return _func(""dnchisq"", tfloat64, x, df, ncp, log_p). [docs]@typecheck(x=expr_float64, mu=expr_float64, sigma=expr_float64, log_p=expr_bool); def dnorm(x, mu=0, sigma=1, log_p=False) -> Float64Expression:; """"""Compute the probability density at `x` of a normal distribution with mean; `mu` and standard deviation `sigma`. Returns density of standard normal; distribution by default. Examples; --------. >>> hl.eval(hl.dnorm(1)); 0.24197072451914337. >>> hl.eval(hl.dnorm(1, mu=1, sigma=2)); 0.19947114020071635. >>> hl.eval(hl.dnorm(1, log_p=True)); -1.4189385332046727. Parameters; ----------; x : :obj:`float` or :class:`.Expression` of type :py:data:`.tfloat64`; Real number at which to compute the probability density.; mu : float or :class:`.Expression` of type :py:data:`.tfloat64`; Mean (default = 0).; sigma: float or :class:`.Expression` of type :py:data:`.tfloat64`; Standard deviation (default = 1).; log_p : :obj:`bool` or :class:`.BooleanExpression`; If ``True``, the natural logarithm of the probability density is returned. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`; The probability density.; """"""; return _func(""dnorm"", tfloat64, x, mu, sigma, log_p). [docs]@typecheck(x=expr_float64, lamb=expr_float64, log_p=expr_bool); def dpois(x, lamb, log_p=False) -> Float64Expression:; """"""Compute the (log) probability density at x of a Poisson distribution with rate parameter `lamb`. Examples; --------. >>> hl.eval(hl.dpois(5, 3)); 0.10081881344492458. Parameters; ----------; x : :obj:`float` or :class:`.Expression` of type :py:data:`.tfloat64`; Non-negative number at which to compute the probability density.; lamb : :obj:`float` or :class:`.Expression` of type :py:data:`.tfloat64`; Poisson rate parameter. Must be non-negative.; log_p : :obj:`bool` or :class:`.BooleanExpression`; If ``True``, the natural logarithm of the probability density is returned. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`; The (log) probability den",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:29670,Testability,log,log,29670,"eviation `sigma`. Returns density of standard normal; distribution by default. Examples; --------. >>> hl.eval(hl.dnorm(1)); 0.24197072451914337. >>> hl.eval(hl.dnorm(1, mu=1, sigma=2)); 0.19947114020071635. >>> hl.eval(hl.dnorm(1, log_p=True)); -1.4189385332046727. Parameters; ----------; x : :obj:`float` or :class:`.Expression` of type :py:data:`.tfloat64`; Real number at which to compute the probability density.; mu : float or :class:`.Expression` of type :py:data:`.tfloat64`; Mean (default = 0).; sigma: float or :class:`.Expression` of type :py:data:`.tfloat64`; Standard deviation (default = 1).; log_p : :obj:`bool` or :class:`.BooleanExpression`; If ``True``, the natural logarithm of the probability density is returned. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`; The probability density.; """"""; return _func(""dnorm"", tfloat64, x, mu, sigma, log_p). [docs]@typecheck(x=expr_float64, lamb=expr_float64, log_p=expr_bool); def dpois(x, lamb, log_p=False) -> Float64Expression:; """"""Compute the (log) probability density at x of a Poisson distribution with rate parameter `lamb`. Examples; --------. >>> hl.eval(hl.dpois(5, 3)); 0.10081881344492458. Parameters; ----------; x : :obj:`float` or :class:`.Expression` of type :py:data:`.tfloat64`; Non-negative number at which to compute the probability density.; lamb : :obj:`float` or :class:`.Expression` of type :py:data:`.tfloat64`; Poisson rate parameter. Must be non-negative.; log_p : :obj:`bool` or :class:`.BooleanExpression`; If ``True``, the natural logarithm of the probability density is returned. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`; The (log) probability density.; """"""; return _func(""dpois"", tfloat64, x, lamb, log_p). [docs]@typecheck(x=oneof(expr_float64, expr_ndarray(expr_float64))); @ndarray_broadcasting; def exp(x) -> Float64Expression:; """"""Computes `e` raised to the power `x`. Examples; --------. >>> hl.eval(hl.exp(2)); 7.38905609893065. Parameters; ----------; ",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:30183,Testability,log,logarithm,30183," type :py:data:`.tfloat64`; Standard deviation (default = 1).; log_p : :obj:`bool` or :class:`.BooleanExpression`; If ``True``, the natural logarithm of the probability density is returned. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`; The probability density.; """"""; return _func(""dnorm"", tfloat64, x, mu, sigma, log_p). [docs]@typecheck(x=expr_float64, lamb=expr_float64, log_p=expr_bool); def dpois(x, lamb, log_p=False) -> Float64Expression:; """"""Compute the (log) probability density at x of a Poisson distribution with rate parameter `lamb`. Examples; --------. >>> hl.eval(hl.dpois(5, 3)); 0.10081881344492458. Parameters; ----------; x : :obj:`float` or :class:`.Expression` of type :py:data:`.tfloat64`; Non-negative number at which to compute the probability density.; lamb : :obj:`float` or :class:`.Expression` of type :py:data:`.tfloat64`; Poisson rate parameter. Must be non-negative.; log_p : :obj:`bool` or :class:`.BooleanExpression`; If ``True``, the natural logarithm of the probability density is returned. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`; The (log) probability density.; """"""; return _func(""dpois"", tfloat64, x, lamb, log_p). [docs]@typecheck(x=oneof(expr_float64, expr_ndarray(expr_float64))); @ndarray_broadcasting; def exp(x) -> Float64Expression:; """"""Computes `e` raised to the power `x`. Examples; --------. >>> hl.eval(hl.exp(2)); 7.38905609893065. Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`; """"""; return _func(""exp"", tfloat64, x). [docs]@typecheck(c1=expr_int32, c2=expr_int32, c3=expr_int32, c4=expr_int32); def fisher_exact_test(c1, c2, c3, c4) -> StructExpression:; """"""Calculates the p-value, odds ratio, and 95% confidence interval using; Fisher's exact test for a 2x2 table. Examples; --------. >>> hl.eval(hl.fisher_exact",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:30307,Testability,log,log,30307,", the natural logarithm of the probability density is returned. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`; The probability density.; """"""; return _func(""dnorm"", tfloat64, x, mu, sigma, log_p). [docs]@typecheck(x=expr_float64, lamb=expr_float64, log_p=expr_bool); def dpois(x, lamb, log_p=False) -> Float64Expression:; """"""Compute the (log) probability density at x of a Poisson distribution with rate parameter `lamb`. Examples; --------. >>> hl.eval(hl.dpois(5, 3)); 0.10081881344492458. Parameters; ----------; x : :obj:`float` or :class:`.Expression` of type :py:data:`.tfloat64`; Non-negative number at which to compute the probability density.; lamb : :obj:`float` or :class:`.Expression` of type :py:data:`.tfloat64`; Poisson rate parameter. Must be non-negative.; log_p : :obj:`bool` or :class:`.BooleanExpression`; If ``True``, the natural logarithm of the probability density is returned. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`; The (log) probability density.; """"""; return _func(""dpois"", tfloat64, x, lamb, log_p). [docs]@typecheck(x=oneof(expr_float64, expr_ndarray(expr_float64))); @ndarray_broadcasting; def exp(x) -> Float64Expression:; """"""Computes `e` raised to the power `x`. Examples; --------. >>> hl.eval(hl.exp(2)); 7.38905609893065. Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`; """"""; return _func(""exp"", tfloat64, x). [docs]@typecheck(c1=expr_int32, c2=expr_int32, c3=expr_int32, c4=expr_int32); def fisher_exact_test(c1, c2, c3, c4) -> StructExpression:; """"""Calculates the p-value, odds ratio, and 95% confidence interval using; Fisher's exact test for a 2x2 table. Examples; --------. >>> hl.eval(hl.fisher_exact_test(10, 10, 10, 10)); Struct(p_value=1.0000000000000002, odds_ratio=1.0,; ci_95_lower=0.24385796914260355, ci_95_upper=4.1007",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:31116,Testability,test,test,31116,"ss:`.Expression` of type :py:data:`.tfloat64`; Poisson rate parameter. Must be non-negative.; log_p : :obj:`bool` or :class:`.BooleanExpression`; If ``True``, the natural logarithm of the probability density is returned. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`; The (log) probability density.; """"""; return _func(""dpois"", tfloat64, x, lamb, log_p). [docs]@typecheck(x=oneof(expr_float64, expr_ndarray(expr_float64))); @ndarray_broadcasting; def exp(x) -> Float64Expression:; """"""Computes `e` raised to the power `x`. Examples; --------. >>> hl.eval(hl.exp(2)); 7.38905609893065. Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`; """"""; return _func(""exp"", tfloat64, x). [docs]@typecheck(c1=expr_int32, c2=expr_int32, c3=expr_int32, c4=expr_int32); def fisher_exact_test(c1, c2, c3, c4) -> StructExpression:; """"""Calculates the p-value, odds ratio, and 95% confidence interval using; Fisher's exact test for a 2x2 table. Examples; --------. >>> hl.eval(hl.fisher_exact_test(10, 10, 10, 10)); Struct(p_value=1.0000000000000002, odds_ratio=1.0,; ci_95_lower=0.24385796914260355, ci_95_upper=4.100747675033819). >>> hl.eval(hl.fisher_exact_test(51, 43, 22, 92)); Struct(p_value=2.1564999740157304e-07, odds_ratio=4.918058171469967,; ci_95_lower=2.5659373368248444, ci_95_upper=9.677929632035475). Notes; -----; This method is identical to the version implemented in; `R <https://stat.ethz.ch/R-manual/R-devel/library/stats/html/fisher.test.html>`_ with default; parameters (two-sided, alpha = 0.05, null hypothesis that the odds ratio equals 1). Returned fields may be ``nan`` or ``inf``. Parameters; ----------; c1 : int or :class:`.Expression` of type :py:data:`.tint32`; Value for cell 1.; c2 : int or :class:`.Expression` of type :py:data:`.tint32`; Value for cell 2.; c3 : int or :class:`.Expre",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:31649,Testability,test,test,31649,"or :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`; """"""; return _func(""exp"", tfloat64, x). [docs]@typecheck(c1=expr_int32, c2=expr_int32, c3=expr_int32, c4=expr_int32); def fisher_exact_test(c1, c2, c3, c4) -> StructExpression:; """"""Calculates the p-value, odds ratio, and 95% confidence interval using; Fisher's exact test for a 2x2 table. Examples; --------. >>> hl.eval(hl.fisher_exact_test(10, 10, 10, 10)); Struct(p_value=1.0000000000000002, odds_ratio=1.0,; ci_95_lower=0.24385796914260355, ci_95_upper=4.100747675033819). >>> hl.eval(hl.fisher_exact_test(51, 43, 22, 92)); Struct(p_value=2.1564999740157304e-07, odds_ratio=4.918058171469967,; ci_95_lower=2.5659373368248444, ci_95_upper=9.677929632035475). Notes; -----; This method is identical to the version implemented in; `R <https://stat.ethz.ch/R-manual/R-devel/library/stats/html/fisher.test.html>`_ with default; parameters (two-sided, alpha = 0.05, null hypothesis that the odds ratio equals 1). Returned fields may be ``nan`` or ``inf``. Parameters; ----------; c1 : int or :class:`.Expression` of type :py:data:`.tint32`; Value for cell 1.; c2 : int or :class:`.Expression` of type :py:data:`.tint32`; Value for cell 2.; c3 : int or :class:`.Expression` of type :py:data:`.tint32`; Value for cell 3.; c4 : int or :class:`.Expression` of type :py:data:`.tint32`; Value for cell 4. Returns; -------; :class:`.StructExpression`; A :class:`.tstruct` expression with four fields, `p_value`; (:py:data:`.tfloat64`), `odds_ratio` (:py:data:`.tfloat64`),; `ci_95_lower (:py:data:`.tfloat64`), and `ci_95_upper`; (:py:data:`.tfloat64`).; """"""; ret_type = tstruct(p_value=tfloat64, odds_ratio=tfloat64, ci_95_lower=tfloat64, ci_95_upper=tfloat64); return _func(""fisher_exact_test"", ret_type, c1, c2, c3, c4). [docs]@typecheck(x=expr_oneof(expr_float32, expr_float64, expr_ndarray(expr_float64))); ",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:33816,Testability,test,test,33816,"ss than or equal to `x`. Examples; --------. >>> hl.eval(hl.floor(3.1)); 3.0. Parameters; ----------; x : :class:`.Float32Expression`, :class:`.Float64Expression`, or :class:`.NDArrayNumericExpression`. Returns; -------; :class:`.Float32Expression`, :class:`.Float64Expression`, or :class:`.NDArrayNumericExpression`; """"""; return _func(""floor"", x.dtype, x). [docs]@typecheck(x=expr_oneof(expr_float32, expr_float64, expr_ndarray(expr_float64))); @ndarray_broadcasting; def ceil(x):; """"""The smallest integral value that is greater than or equal to `x`. Examples; --------. >>> hl.eval(hl.ceil(3.1)); 4.0. Parameters; ----------; x : :class:`.Float32Expression`,:class:`.Float64Expression` or :class:`.NDArrayNumericExpression`. Returns; -------; :class:`.Float32Expression`, :class:`.Float64Expression`, or :class:`.NDArrayNumericExpression`; """"""; return _func(""ceil"", x.dtype, x). [docs]@typecheck(n_hom_ref=expr_int32, n_het=expr_int32, n_hom_var=expr_int32, one_sided=expr_bool); def hardy_weinberg_test(n_hom_ref, n_het, n_hom_var, one_sided=False) -> StructExpression:; """"""Performs test of Hardy-Weinberg equilibrium. Examples; --------. >>> hl.eval(hl.hardy_weinberg_test(250, 500, 250)); Struct(het_freq_hwe=0.5002501250625313, p_value=0.9747844394217698). >>> hl.eval(hl.hardy_weinberg_test(37, 200, 85)); Struct(het_freq_hwe=0.48964964307448583, p_value=1.1337210383168987e-06). Notes; -----; By default, this method performs a two-sided exact test with mid-p-value correction of; `Hardy-Weinberg equilibrium <https://en.wikipedia.org/wiki/Hardy%E2%80%93Weinberg_principle>`__; via an efficient implementation of the; `Levene-Haldane distribution <../_static/LeveneHaldane.pdf>`__,; which models the number of heterozygous individuals under equilibrium. The mean of this distribution is ``(n_ref * n_var) / (2n - 1)``, where; ``n_ref = 2*n_hom_ref + n_het`` is the number of reference alleles,; ``n_var = 2*n_hom_var + n_het`` is the number of variant alleles,; and ``n = n_hom_ref + n_het + n",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:34182,Testability,test,test,34182,"oadcasting; def ceil(x):; """"""The smallest integral value that is greater than or equal to `x`. Examples; --------. >>> hl.eval(hl.ceil(3.1)); 4.0. Parameters; ----------; x : :class:`.Float32Expression`,:class:`.Float64Expression` or :class:`.NDArrayNumericExpression`. Returns; -------; :class:`.Float32Expression`, :class:`.Float64Expression`, or :class:`.NDArrayNumericExpression`; """"""; return _func(""ceil"", x.dtype, x). [docs]@typecheck(n_hom_ref=expr_int32, n_het=expr_int32, n_hom_var=expr_int32, one_sided=expr_bool); def hardy_weinberg_test(n_hom_ref, n_het, n_hom_var, one_sided=False) -> StructExpression:; """"""Performs test of Hardy-Weinberg equilibrium. Examples; --------. >>> hl.eval(hl.hardy_weinberg_test(250, 500, 250)); Struct(het_freq_hwe=0.5002501250625313, p_value=0.9747844394217698). >>> hl.eval(hl.hardy_weinberg_test(37, 200, 85)); Struct(het_freq_hwe=0.48964964307448583, p_value=1.1337210383168987e-06). Notes; -----; By default, this method performs a two-sided exact test with mid-p-value correction of; `Hardy-Weinberg equilibrium <https://en.wikipedia.org/wiki/Hardy%E2%80%93Weinberg_principle>`__; via an efficient implementation of the; `Levene-Haldane distribution <../_static/LeveneHaldane.pdf>`__,; which models the number of heterozygous individuals under equilibrium. The mean of this distribution is ``(n_ref * n_var) / (2n - 1)``, where; ``n_ref = 2*n_hom_ref + n_het`` is the number of reference alleles,; ``n_var = 2*n_hom_var + n_het`` is the number of variant alleles,; and ``n = n_hom_ref + n_het + n_hom_var`` is the number of individuals.; So the expected frequency of heterozygotes under equilibrium,; `het_freq_hwe`, is this mean divided by ``n``. To perform one-sided exact test of excess heterozygosity with mid-p-value; correction instead, set `one_sided=True` and the p-value returned will be; from the one-sided exact test. Parameters; ----------; n_hom_ref : int or :class:`.Expression` of type :py:data:`.tint32`; Number of homozygous reference g",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:34910,Testability,test,test,34910,"0.9747844394217698). >>> hl.eval(hl.hardy_weinberg_test(37, 200, 85)); Struct(het_freq_hwe=0.48964964307448583, p_value=1.1337210383168987e-06). Notes; -----; By default, this method performs a two-sided exact test with mid-p-value correction of; `Hardy-Weinberg equilibrium <https://en.wikipedia.org/wiki/Hardy%E2%80%93Weinberg_principle>`__; via an efficient implementation of the; `Levene-Haldane distribution <../_static/LeveneHaldane.pdf>`__,; which models the number of heterozygous individuals under equilibrium. The mean of this distribution is ``(n_ref * n_var) / (2n - 1)``, where; ``n_ref = 2*n_hom_ref + n_het`` is the number of reference alleles,; ``n_var = 2*n_hom_var + n_het`` is the number of variant alleles,; and ``n = n_hom_ref + n_het + n_hom_var`` is the number of individuals.; So the expected frequency of heterozygotes under equilibrium,; `het_freq_hwe`, is this mean divided by ``n``. To perform one-sided exact test of excess heterozygosity with mid-p-value; correction instead, set `one_sided=True` and the p-value returned will be; from the one-sided exact test. Parameters; ----------; n_hom_ref : int or :class:`.Expression` of type :py:data:`.tint32`; Number of homozygous reference genotypes.; n_het : int or :class:`.Expression` of type :py:data:`.tint32`; Number of heterozygous genotypes.; n_hom_var : int or :class:`.Expression` of type :py:data:`.tint32`; Number of homozygous variant genotypes.; one_sided : :obj:`bool`; ``False`` by default. When ``True``, perform one-sided test for excess heterozygosity. Returns; -------; :class:`.StructExpression`; A struct expression with two fields, `het_freq_hwe`; (:py:data:`.tfloat64`) and `p_value` (:py:data:`.tfloat64`).; """"""; ret_type = tstruct(het_freq_hwe=tfloat64, p_value=tfloat64); return _func(""hardy_weinberg_test"", ret_type, n_hom_ref, n_het, n_hom_var, one_sided). [docs]@typecheck(contig=expr_str, pos=expr_int32, reference_genome=reference_genome_type); def locus(contig, pos, reference_genome: Union[st",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:35058,Testability,test,test,35058,"0.9747844394217698). >>> hl.eval(hl.hardy_weinberg_test(37, 200, 85)); Struct(het_freq_hwe=0.48964964307448583, p_value=1.1337210383168987e-06). Notes; -----; By default, this method performs a two-sided exact test with mid-p-value correction of; `Hardy-Weinberg equilibrium <https://en.wikipedia.org/wiki/Hardy%E2%80%93Weinberg_principle>`__; via an efficient implementation of the; `Levene-Haldane distribution <../_static/LeveneHaldane.pdf>`__,; which models the number of heterozygous individuals under equilibrium. The mean of this distribution is ``(n_ref * n_var) / (2n - 1)``, where; ``n_ref = 2*n_hom_ref + n_het`` is the number of reference alleles,; ``n_var = 2*n_hom_var + n_het`` is the number of variant alleles,; and ``n = n_hom_ref + n_het + n_hom_var`` is the number of individuals.; So the expected frequency of heterozygotes under equilibrium,; `het_freq_hwe`, is this mean divided by ``n``. To perform one-sided exact test of excess heterozygosity with mid-p-value; correction instead, set `one_sided=True` and the p-value returned will be; from the one-sided exact test. Parameters; ----------; n_hom_ref : int or :class:`.Expression` of type :py:data:`.tint32`; Number of homozygous reference genotypes.; n_het : int or :class:`.Expression` of type :py:data:`.tint32`; Number of heterozygous genotypes.; n_hom_var : int or :class:`.Expression` of type :py:data:`.tint32`; Number of homozygous variant genotypes.; one_sided : :obj:`bool`; ``False`` by default. When ``True``, perform one-sided test for excess heterozygosity. Returns; -------; :class:`.StructExpression`; A struct expression with two fields, `het_freq_hwe`; (:py:data:`.tfloat64`) and `p_value` (:py:data:`.tfloat64`).; """"""; ret_type = tstruct(het_freq_hwe=tfloat64, p_value=tfloat64); return _func(""hardy_weinberg_test"", ret_type, n_hom_ref, n_het, n_hom_var, one_sided). [docs]@typecheck(contig=expr_str, pos=expr_int32, reference_genome=reference_genome_type); def locus(contig, pos, reference_genome: Union[st",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:35487,Testability,test,test,35487,"brium. The mean of this distribution is ``(n_ref * n_var) / (2n - 1)``, where; ``n_ref = 2*n_hom_ref + n_het`` is the number of reference alleles,; ``n_var = 2*n_hom_var + n_het`` is the number of variant alleles,; and ``n = n_hom_ref + n_het + n_hom_var`` is the number of individuals.; So the expected frequency of heterozygotes under equilibrium,; `het_freq_hwe`, is this mean divided by ``n``. To perform one-sided exact test of excess heterozygosity with mid-p-value; correction instead, set `one_sided=True` and the p-value returned will be; from the one-sided exact test. Parameters; ----------; n_hom_ref : int or :class:`.Expression` of type :py:data:`.tint32`; Number of homozygous reference genotypes.; n_het : int or :class:`.Expression` of type :py:data:`.tint32`; Number of heterozygous genotypes.; n_hom_var : int or :class:`.Expression` of type :py:data:`.tint32`; Number of homozygous variant genotypes.; one_sided : :obj:`bool`; ``False`` by default. When ``True``, perform one-sided test for excess heterozygosity. Returns; -------; :class:`.StructExpression`; A struct expression with two fields, `het_freq_hwe`; (:py:data:`.tfloat64`) and `p_value` (:py:data:`.tfloat64`).; """"""; ret_type = tstruct(het_freq_hwe=tfloat64, p_value=tfloat64); return _func(""hardy_weinberg_test"", ret_type, n_hom_ref, n_het, n_hom_var, one_sided). [docs]@typecheck(contig=expr_str, pos=expr_int32, reference_genome=reference_genome_type); def locus(contig, pos, reference_genome: Union[str, ReferenceGenome] = 'default') -> LocusExpression:; """"""Construct a locus expression from a chromosome and position. Examples; --------. >>> hl.eval(hl.locus(""1"", 10000, reference_genome='GRCh37')); Locus(contig=1, position=10000, reference_genome=GRCh37). Parameters; ----------; contig : str or :class:`.StringExpression`; Chromosome.; pos : int or :class:`.Expression` of type :py:data:`.tint32`; Base position along the chromosome.; reference_genome : :class:`str` or :class:`.ReferenceGenome`; Reference gen",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:51512,Testability,test,test,51512,"----+-----------------+; | ploidy | Phased | Unphased |; +========+=================+=================+; | 0 | ``|-`` | ``-`` |; +--------+-----------------+-----------------+; | 1 | ``|i`` | ``i`` |; +--------+-----------------+-----------------+; | 2 | ``i|j`` | ``i/j`` |; +--------+-----------------+-----------------+; | 3 | ``i|j|k`` | ``i/j/k`` |; +--------+-----------------+-----------------+; | N | ``i|j|k|...|N`` | ``i/j/k/.../N`` |; +--------+-----------------+-----------------+. Parameters; ----------; s : str or :class:`.StringExpression`; String to parse. Returns; -------; :class:`.CallExpression`; """"""; return _func('Call', tcall, s). [docs]@typecheck(expression=expr_any); def is_defined(expression) -> BooleanExpression:; """"""Returns ``True`` if the argument is not missing. Examples; --------. >>> hl.eval(hl.is_defined(5)); True. >>> hl.eval(hl.is_defined(hl.missing(hl.tstr))); False. >>> hl.eval(hl.is_defined(hl.missing(hl.tbool) & True)); False. Parameters; ----------; expression; Expression to test. Returns; -------; :class:`.BooleanExpression`; ``True`` if `expression` is not missing, ``False`` otherwise.; """"""; return ~apply_expr(lambda x: ir.IsNA(x), tbool, expression). [docs]@typecheck(expression=expr_any); def is_missing(expression) -> BooleanExpression:; """"""Returns ``True`` if the argument is missing. Examples; --------. >>> hl.eval(hl.is_missing(5)); False. >>> hl.eval(hl.is_missing(hl.missing(hl.tstr))); True. >>> hl.eval(hl.is_missing(hl.missing(hl.tbool) & True)); True. Parameters; ----------; expression; Expression to test. Returns; -------; :class:`.BooleanExpression`; ``True`` if `expression` is missing, ``False`` otherwise.; """"""; return apply_expr(lambda x: ir.IsNA(x), tbool, expression). [docs]@typecheck(x=expr_oneof(expr_float32, expr_float64, expr_ndarray(expr_float64))); @ndarray_broadcasting; def is_nan(x) -> BooleanExpression:; """"""Returns ``True`` if the argument is ``nan`` (not a number). Examples; --------. >>> hl.eval(hl.is_nan(0)",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:52057,Testability,test,test,52057,"xpression`; String to parse. Returns; -------; :class:`.CallExpression`; """"""; return _func('Call', tcall, s). [docs]@typecheck(expression=expr_any); def is_defined(expression) -> BooleanExpression:; """"""Returns ``True`` if the argument is not missing. Examples; --------. >>> hl.eval(hl.is_defined(5)); True. >>> hl.eval(hl.is_defined(hl.missing(hl.tstr))); False. >>> hl.eval(hl.is_defined(hl.missing(hl.tbool) & True)); False. Parameters; ----------; expression; Expression to test. Returns; -------; :class:`.BooleanExpression`; ``True`` if `expression` is not missing, ``False`` otherwise.; """"""; return ~apply_expr(lambda x: ir.IsNA(x), tbool, expression). [docs]@typecheck(expression=expr_any); def is_missing(expression) -> BooleanExpression:; """"""Returns ``True`` if the argument is missing. Examples; --------. >>> hl.eval(hl.is_missing(5)); False. >>> hl.eval(hl.is_missing(hl.missing(hl.tstr))); True. >>> hl.eval(hl.is_missing(hl.missing(hl.tbool) & True)); True. Parameters; ----------; expression; Expression to test. Returns; -------; :class:`.BooleanExpression`; ``True`` if `expression` is missing, ``False`` otherwise.; """"""; return apply_expr(lambda x: ir.IsNA(x), tbool, expression). [docs]@typecheck(x=expr_oneof(expr_float32, expr_float64, expr_ndarray(expr_float64))); @ndarray_broadcasting; def is_nan(x) -> BooleanExpression:; """"""Returns ``True`` if the argument is ``nan`` (not a number). Examples; --------. >>> hl.eval(hl.is_nan(0)); False. >>> hl.eval(hl.is_nan(hl.literal(0) / 0)); True. >>> hl.eval(hl.is_nan(hl.literal(0) / hl.missing(hl.tfloat64))); None. Notes; -----; Note that :func:`~.is_missing` will return ``False`` on ``nan`` since ``nan``; is a defined value. Additionally, this method will return missing if `x` is; missing. Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64`; Expression to test or or :class:`.NDArrayNumericExpression`. Returns; -------; :class:`.BooleanExpression`; ``True`` if `x` is ``nan``, ``False`` ot",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:52900,Testability,test,test,52900,"val(hl.is_missing(hl.missing(hl.tstr))); True. >>> hl.eval(hl.is_missing(hl.missing(hl.tbool) & True)); True. Parameters; ----------; expression; Expression to test. Returns; -------; :class:`.BooleanExpression`; ``True`` if `expression` is missing, ``False`` otherwise.; """"""; return apply_expr(lambda x: ir.IsNA(x), tbool, expression). [docs]@typecheck(x=expr_oneof(expr_float32, expr_float64, expr_ndarray(expr_float64))); @ndarray_broadcasting; def is_nan(x) -> BooleanExpression:; """"""Returns ``True`` if the argument is ``nan`` (not a number). Examples; --------. >>> hl.eval(hl.is_nan(0)); False. >>> hl.eval(hl.is_nan(hl.literal(0) / 0)); True. >>> hl.eval(hl.is_nan(hl.literal(0) / hl.missing(hl.tfloat64))); None. Notes; -----; Note that :func:`~.is_missing` will return ``False`` on ``nan`` since ``nan``; is a defined value. Additionally, this method will return missing if `x` is; missing. Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64`; Expression to test or or :class:`.NDArrayNumericExpression`. Returns; -------; :class:`.BooleanExpression`; ``True`` if `x` is ``nan``, ``False`` otherwise or; :class:`.NDArrayNumericExpression` filled with such values; """"""; return _func(""isnan"", tbool, x). [docs]@typecheck(x=expr_oneof(expr_float32, expr_float64, expr_ndarray(expr_float64))); @ndarray_broadcasting; def is_finite(x) -> BooleanExpression:; """"""Returns ``True`` if the argument is a finite floating-point number. Examples; --------; >>> hl.eval(hl.is_finite(0)); True. >>> hl.eval(hl.is_finite(float('nan'))); False. >>> hl.eval(hl.is_finite(float('inf'))); False. >>> hl.eval(hl.is_finite(hl.missing('float32'))); None. Notes; -----; This method will return missing, not ``True``, if `x` is missing. Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`. Returns; -------; :class:`.BooleanExpression` or :class:`.NDArrayNumericExpression` filled with such expressions; """""";",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:55872,Testability,log,log,55872,"; --------. >>> hl.eval(hl.json([1,2,3,4,5])); '[1,2,3,4,5]'. >>> hl.eval(hl.json(hl.struct(a='Hello', b=0.12345, c=[1,2], d={'hi', 'bye'}))); '{""a"":""Hello"",""b"":0.12345,""c"":[1,2],""d"":[""bye"",""hi""]}'. Parameters; ----------; x; Expression to convert. Returns; -------; :class:`.StringExpression`; String expression with JSON representation of `x`.; """"""; return _func(""json"", tstr, x). [docs]@typecheck(x=expr_str, dtype=hail_type); def parse_json(x, dtype):; """"""Convert a JSON string to a structured expression. Examples; --------; >>> json_str = '{""a"": 5, ""b"": 1.1, ""c"": ""foo""}'; >>> parsed = hl.parse_json(json_str, dtype='struct{a: int32, b: float64, c: str}'); >>> hl.eval(parsed.a); 5. Parameters; ----------; x : :class:`.StringExpression`; JSON string.; dtype; Type of value to parse. Returns; -------; :class:`.Expression`; """"""; return _func(""parse_json"", ttuple(dtype), x, type_args=(dtype,))[0]. [docs]@typecheck(x=oneof(expr_float64, expr_ndarray(expr_float64)), base=nullable(expr_float64)); def log(x, base=None) -> Float64Expression:; """"""Take the logarithm of the `x` with base `base`. Examples; --------. >>> hl.eval(hl.log(10)); 2.302585092994046. >>> hl.eval(hl.log(10, 10)); 1.0. >>> hl.eval(hl.log(1024, 2)); 10.0. Notes; -----; If the `base` argument is not supplied, then the natural logarithm is used. Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64`; base : float or :class:`.Expression` of type :py:data:`.tfloat64`. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`; """""". def scalar_log(x):; if base is not None:; return _func(""log"", tfloat64, x, to_expr(base)); else:; return _func(""log"", tfloat64, x). x = to_expr(x); if isinstance(x.dtype, tndarray):; return x.map(scalar_log); return scalar_log(x). [docs]@typecheck(x=oneof(expr_float64, expr_ndarray(expr_float64))); @ndarray_broadcasting; def log10(x) -> Float64Expression:; """"""Take the logarithm of the `x` with base 10. Examples; --------. >>> hl.eval(hl.log10(10",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:55925,Testability,log,logarithm,55925,"; --------. >>> hl.eval(hl.json([1,2,3,4,5])); '[1,2,3,4,5]'. >>> hl.eval(hl.json(hl.struct(a='Hello', b=0.12345, c=[1,2], d={'hi', 'bye'}))); '{""a"":""Hello"",""b"":0.12345,""c"":[1,2],""d"":[""bye"",""hi""]}'. Parameters; ----------; x; Expression to convert. Returns; -------; :class:`.StringExpression`; String expression with JSON representation of `x`.; """"""; return _func(""json"", tstr, x). [docs]@typecheck(x=expr_str, dtype=hail_type); def parse_json(x, dtype):; """"""Convert a JSON string to a structured expression. Examples; --------; >>> json_str = '{""a"": 5, ""b"": 1.1, ""c"": ""foo""}'; >>> parsed = hl.parse_json(json_str, dtype='struct{a: int32, b: float64, c: str}'); >>> hl.eval(parsed.a); 5. Parameters; ----------; x : :class:`.StringExpression`; JSON string.; dtype; Type of value to parse. Returns; -------; :class:`.Expression`; """"""; return _func(""parse_json"", ttuple(dtype), x, type_args=(dtype,))[0]. [docs]@typecheck(x=oneof(expr_float64, expr_ndarray(expr_float64)), base=nullable(expr_float64)); def log(x, base=None) -> Float64Expression:; """"""Take the logarithm of the `x` with base `base`. Examples; --------. >>> hl.eval(hl.log(10)); 2.302585092994046. >>> hl.eval(hl.log(10, 10)); 1.0. >>> hl.eval(hl.log(1024, 2)); 10.0. Notes; -----; If the `base` argument is not supplied, then the natural logarithm is used. Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64`; base : float or :class:`.Expression` of type :py:data:`.tfloat64`. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`; """""". def scalar_log(x):; if base is not None:; return _func(""log"", tfloat64, x, to_expr(base)); else:; return _func(""log"", tfloat64, x). x = to_expr(x); if isinstance(x.dtype, tndarray):; return x.map(scalar_log); return scalar_log(x). [docs]@typecheck(x=oneof(expr_float64, expr_ndarray(expr_float64))); @ndarray_broadcasting; def log10(x) -> Float64Expression:; """"""Take the logarithm of the `x` with base 10. Examples; --------. >>> hl.eval(hl.log10(10",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:55999,Testability,log,log,55999,")); '{""a"":""Hello"",""b"":0.12345,""c"":[1,2],""d"":[""bye"",""hi""]}'. Parameters; ----------; x; Expression to convert. Returns; -------; :class:`.StringExpression`; String expression with JSON representation of `x`.; """"""; return _func(""json"", tstr, x). [docs]@typecheck(x=expr_str, dtype=hail_type); def parse_json(x, dtype):; """"""Convert a JSON string to a structured expression. Examples; --------; >>> json_str = '{""a"": 5, ""b"": 1.1, ""c"": ""foo""}'; >>> parsed = hl.parse_json(json_str, dtype='struct{a: int32, b: float64, c: str}'); >>> hl.eval(parsed.a); 5. Parameters; ----------; x : :class:`.StringExpression`; JSON string.; dtype; Type of value to parse. Returns; -------; :class:`.Expression`; """"""; return _func(""parse_json"", ttuple(dtype), x, type_args=(dtype,))[0]. [docs]@typecheck(x=oneof(expr_float64, expr_ndarray(expr_float64)), base=nullable(expr_float64)); def log(x, base=None) -> Float64Expression:; """"""Take the logarithm of the `x` with base `base`. Examples; --------. >>> hl.eval(hl.log(10)); 2.302585092994046. >>> hl.eval(hl.log(10, 10)); 1.0. >>> hl.eval(hl.log(1024, 2)); 10.0. Notes; -----; If the `base` argument is not supplied, then the natural logarithm is used. Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64`; base : float or :class:`.Expression` of type :py:data:`.tfloat64`. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`; """""". def scalar_log(x):; if base is not None:; return _func(""log"", tfloat64, x, to_expr(base)); else:; return _func(""log"", tfloat64, x). x = to_expr(x); if isinstance(x.dtype, tndarray):; return x.map(scalar_log); return scalar_log(x). [docs]@typecheck(x=oneof(expr_float64, expr_ndarray(expr_float64))); @ndarray_broadcasting; def log10(x) -> Float64Expression:; """"""Take the logarithm of the `x` with base 10. Examples; --------. >>> hl.eval(hl.log10(1000)); 3.0. >>> hl.eval(hl.log10(0.0001123)); -3.949620243738542. Parameters; ----------; x : float or :class:`.Expression` of type :py:data",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:56043,Testability,log,log,56043,"bye"",""hi""]}'. Parameters; ----------; x; Expression to convert. Returns; -------; :class:`.StringExpression`; String expression with JSON representation of `x`.; """"""; return _func(""json"", tstr, x). [docs]@typecheck(x=expr_str, dtype=hail_type); def parse_json(x, dtype):; """"""Convert a JSON string to a structured expression. Examples; --------; >>> json_str = '{""a"": 5, ""b"": 1.1, ""c"": ""foo""}'; >>> parsed = hl.parse_json(json_str, dtype='struct{a: int32, b: float64, c: str}'); >>> hl.eval(parsed.a); 5. Parameters; ----------; x : :class:`.StringExpression`; JSON string.; dtype; Type of value to parse. Returns; -------; :class:`.Expression`; """"""; return _func(""parse_json"", ttuple(dtype), x, type_args=(dtype,))[0]. [docs]@typecheck(x=oneof(expr_float64, expr_ndarray(expr_float64)), base=nullable(expr_float64)); def log(x, base=None) -> Float64Expression:; """"""Take the logarithm of the `x` with base `base`. Examples; --------. >>> hl.eval(hl.log(10)); 2.302585092994046. >>> hl.eval(hl.log(10, 10)); 1.0. >>> hl.eval(hl.log(1024, 2)); 10.0. Notes; -----; If the `base` argument is not supplied, then the natural logarithm is used. Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64`; base : float or :class:`.Expression` of type :py:data:`.tfloat64`. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`; """""". def scalar_log(x):; if base is not None:; return _func(""log"", tfloat64, x, to_expr(base)); else:; return _func(""log"", tfloat64, x). x = to_expr(x); if isinstance(x.dtype, tndarray):; return x.map(scalar_log); return scalar_log(x). [docs]@typecheck(x=oneof(expr_float64, expr_ndarray(expr_float64))); @ndarray_broadcasting; def log10(x) -> Float64Expression:; """"""Take the logarithm of the `x` with base 10. Examples; --------. >>> hl.eval(hl.log10(1000)); 3.0. >>> hl.eval(hl.log10(0.0001123)); -3.949620243738542. Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpress",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:56077,Testability,log,log,56077,"-; x; Expression to convert. Returns; -------; :class:`.StringExpression`; String expression with JSON representation of `x`.; """"""; return _func(""json"", tstr, x). [docs]@typecheck(x=expr_str, dtype=hail_type); def parse_json(x, dtype):; """"""Convert a JSON string to a structured expression. Examples; --------; >>> json_str = '{""a"": 5, ""b"": 1.1, ""c"": ""foo""}'; >>> parsed = hl.parse_json(json_str, dtype='struct{a: int32, b: float64, c: str}'); >>> hl.eval(parsed.a); 5. Parameters; ----------; x : :class:`.StringExpression`; JSON string.; dtype; Type of value to parse. Returns; -------; :class:`.Expression`; """"""; return _func(""parse_json"", ttuple(dtype), x, type_args=(dtype,))[0]. [docs]@typecheck(x=oneof(expr_float64, expr_ndarray(expr_float64)), base=nullable(expr_float64)); def log(x, base=None) -> Float64Expression:; """"""Take the logarithm of the `x` with base `base`. Examples; --------. >>> hl.eval(hl.log(10)); 2.302585092994046. >>> hl.eval(hl.log(10, 10)); 1.0. >>> hl.eval(hl.log(1024, 2)); 10.0. Notes; -----; If the `base` argument is not supplied, then the natural logarithm is used. Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64`; base : float or :class:`.Expression` of type :py:data:`.tfloat64`. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`; """""". def scalar_log(x):; if base is not None:; return _func(""log"", tfloat64, x, to_expr(base)); else:; return _func(""log"", tfloat64, x). x = to_expr(x); if isinstance(x.dtype, tndarray):; return x.map(scalar_log); return scalar_log(x). [docs]@typecheck(x=oneof(expr_float64, expr_ndarray(expr_float64))); @ndarray_broadcasting; def log10(x) -> Float64Expression:; """"""Take the logarithm of the `x` with base 10. Examples; --------. >>> hl.eval(hl.log10(1000)); 3.0. >>> hl.eval(hl.log10(0.0001123)); -3.949620243738542. Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`. Returns; -------; :class:`.Ex",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:56169,Testability,log,logarithm,56169,"StringExpression`; String expression with JSON representation of `x`.; """"""; return _func(""json"", tstr, x). [docs]@typecheck(x=expr_str, dtype=hail_type); def parse_json(x, dtype):; """"""Convert a JSON string to a structured expression. Examples; --------; >>> json_str = '{""a"": 5, ""b"": 1.1, ""c"": ""foo""}'; >>> parsed = hl.parse_json(json_str, dtype='struct{a: int32, b: float64, c: str}'); >>> hl.eval(parsed.a); 5. Parameters; ----------; x : :class:`.StringExpression`; JSON string.; dtype; Type of value to parse. Returns; -------; :class:`.Expression`; """"""; return _func(""parse_json"", ttuple(dtype), x, type_args=(dtype,))[0]. [docs]@typecheck(x=oneof(expr_float64, expr_ndarray(expr_float64)), base=nullable(expr_float64)); def log(x, base=None) -> Float64Expression:; """"""Take the logarithm of the `x` with base `base`. Examples; --------. >>> hl.eval(hl.log(10)); 2.302585092994046. >>> hl.eval(hl.log(10, 10)); 1.0. >>> hl.eval(hl.log(1024, 2)); 10.0. Notes; -----; If the `base` argument is not supplied, then the natural logarithm is used. Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64`; base : float or :class:`.Expression` of type :py:data:`.tfloat64`. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`; """""". def scalar_log(x):; if base is not None:; return _func(""log"", tfloat64, x, to_expr(base)); else:; return _func(""log"", tfloat64, x). x = to_expr(x); if isinstance(x.dtype, tndarray):; return x.map(scalar_log); return scalar_log(x). [docs]@typecheck(x=oneof(expr_float64, expr_ndarray(expr_float64))); @ndarray_broadcasting; def log10(x) -> Float64Expression:; """"""Take the logarithm of the `x` with base 10. Examples; --------. >>> hl.eval(hl.log10(1000)); 3.0. >>> hl.eval(hl.log10(0.0001123)); -3.949620243738542. Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArr",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:56473,Testability,log,log,56473,"dtype='struct{a: int32, b: float64, c: str}'); >>> hl.eval(parsed.a); 5. Parameters; ----------; x : :class:`.StringExpression`; JSON string.; dtype; Type of value to parse. Returns; -------; :class:`.Expression`; """"""; return _func(""parse_json"", ttuple(dtype), x, type_args=(dtype,))[0]. [docs]@typecheck(x=oneof(expr_float64, expr_ndarray(expr_float64)), base=nullable(expr_float64)); def log(x, base=None) -> Float64Expression:; """"""Take the logarithm of the `x` with base `base`. Examples; --------. >>> hl.eval(hl.log(10)); 2.302585092994046. >>> hl.eval(hl.log(10, 10)); 1.0. >>> hl.eval(hl.log(1024, 2)); 10.0. Notes; -----; If the `base` argument is not supplied, then the natural logarithm is used. Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64`; base : float or :class:`.Expression` of type :py:data:`.tfloat64`. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`; """""". def scalar_log(x):; if base is not None:; return _func(""log"", tfloat64, x, to_expr(base)); else:; return _func(""log"", tfloat64, x). x = to_expr(x); if isinstance(x.dtype, tndarray):; return x.map(scalar_log); return scalar_log(x). [docs]@typecheck(x=oneof(expr_float64, expr_ndarray(expr_float64))); @ndarray_broadcasting; def log10(x) -> Float64Expression:; """"""Take the logarithm of the `x` with base 10. Examples; --------. >>> hl.eval(hl.log10(1000)); 3.0. >>> hl.eval(hl.log10(0.0001123)); -3.949620243738542. Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`; """"""; return _func(""log10"", tfloat64, x). [docs]@typecheck(x=oneof(expr_float64, expr_ndarray(expr_float64))); @ndarray_broadcasting; def logit(x) -> Float64Expression:; """"""The logistic function. Examples; --------; >>> hl.eval(hl.logit(.01)); -4.59511985013459; >>> hl.eval(hl.logit(.5)); 0.0. Parameters; ----------; ",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:56529,Testability,log,log,56529,"dtype='struct{a: int32, b: float64, c: str}'); >>> hl.eval(parsed.a); 5. Parameters; ----------; x : :class:`.StringExpression`; JSON string.; dtype; Type of value to parse. Returns; -------; :class:`.Expression`; """"""; return _func(""parse_json"", ttuple(dtype), x, type_args=(dtype,))[0]. [docs]@typecheck(x=oneof(expr_float64, expr_ndarray(expr_float64)), base=nullable(expr_float64)); def log(x, base=None) -> Float64Expression:; """"""Take the logarithm of the `x` with base `base`. Examples; --------. >>> hl.eval(hl.log(10)); 2.302585092994046. >>> hl.eval(hl.log(10, 10)); 1.0. >>> hl.eval(hl.log(1024, 2)); 10.0. Notes; -----; If the `base` argument is not supplied, then the natural logarithm is used. Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64`; base : float or :class:`.Expression` of type :py:data:`.tfloat64`. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`; """""". def scalar_log(x):; if base is not None:; return _func(""log"", tfloat64, x, to_expr(base)); else:; return _func(""log"", tfloat64, x). x = to_expr(x); if isinstance(x.dtype, tndarray):; return x.map(scalar_log); return scalar_log(x). [docs]@typecheck(x=oneof(expr_float64, expr_ndarray(expr_float64))); @ndarray_broadcasting; def log10(x) -> Float64Expression:; """"""Take the logarithm of the `x` with base 10. Examples; --------. >>> hl.eval(hl.log10(1000)); 3.0. >>> hl.eval(hl.log10(0.0001123)); -3.949620243738542. Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`; """"""; return _func(""log10"", tfloat64, x). [docs]@typecheck(x=oneof(expr_float64, expr_ndarray(expr_float64))); @ndarray_broadcasting; def logit(x) -> Float64Expression:; """"""The logistic function. Examples; --------; >>> hl.eval(hl.logit(.01)); -4.59511985013459; >>> hl.eval(hl.logit(.5)); 0.0. Parameters; ----------; ",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:56788,Testability,log,logarithm,56788,"(dtype), x, type_args=(dtype,))[0]. [docs]@typecheck(x=oneof(expr_float64, expr_ndarray(expr_float64)), base=nullable(expr_float64)); def log(x, base=None) -> Float64Expression:; """"""Take the logarithm of the `x` with base `base`. Examples; --------. >>> hl.eval(hl.log(10)); 2.302585092994046. >>> hl.eval(hl.log(10, 10)); 1.0. >>> hl.eval(hl.log(1024, 2)); 10.0. Notes; -----; If the `base` argument is not supplied, then the natural logarithm is used. Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64`; base : float or :class:`.Expression` of type :py:data:`.tfloat64`. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`; """""". def scalar_log(x):; if base is not None:; return _func(""log"", tfloat64, x, to_expr(base)); else:; return _func(""log"", tfloat64, x). x = to_expr(x); if isinstance(x.dtype, tndarray):; return x.map(scalar_log); return scalar_log(x). [docs]@typecheck(x=oneof(expr_float64, expr_ndarray(expr_float64))); @ndarray_broadcasting; def log10(x) -> Float64Expression:; """"""Take the logarithm of the `x` with base 10. Examples; --------. >>> hl.eval(hl.log10(1000)); 3.0. >>> hl.eval(hl.log10(0.0001123)); -3.949620243738542. Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`; """"""; return _func(""log10"", tfloat64, x). [docs]@typecheck(x=oneof(expr_float64, expr_ndarray(expr_float64))); @ndarray_broadcasting; def logit(x) -> Float64Expression:; """"""The logistic function. Examples; --------; >>> hl.eval(hl.logit(.01)); -4.59511985013459; >>> hl.eval(hl.logit(.5)); 0.0. Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`; """"""; return hl.log(x / (1 - x)). [docs]@type",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:57301,Testability,log,logit,57301,": float or :class:`.Expression` of type :py:data:`.tfloat64`. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`; """""". def scalar_log(x):; if base is not None:; return _func(""log"", tfloat64, x, to_expr(base)); else:; return _func(""log"", tfloat64, x). x = to_expr(x); if isinstance(x.dtype, tndarray):; return x.map(scalar_log); return scalar_log(x). [docs]@typecheck(x=oneof(expr_float64, expr_ndarray(expr_float64))); @ndarray_broadcasting; def log10(x) -> Float64Expression:; """"""Take the logarithm of the `x` with base 10. Examples; --------. >>> hl.eval(hl.log10(1000)); 3.0. >>> hl.eval(hl.log10(0.0001123)); -3.949620243738542. Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`; """"""; return _func(""log10"", tfloat64, x). [docs]@typecheck(x=oneof(expr_float64, expr_ndarray(expr_float64))); @ndarray_broadcasting; def logit(x) -> Float64Expression:; """"""The logistic function. Examples; --------; >>> hl.eval(hl.logit(.01)); -4.59511985013459; >>> hl.eval(hl.logit(.5)); 0.0. Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`; """"""; return hl.log(x / (1 - x)). [docs]@typecheck(x=oneof(expr_float64, expr_ndarray(expr_float64))); @ndarray_broadcasting; def expit(x) -> Float64Expression:; """"""The logistic sigmoid function. .. math::. \textrm{expit}(x) = \frac{1}{1 + e^{-x}}. Examples; --------; >>> hl.eval(hl.expit(.01)); 0.5024999791668749; >>> hl.eval(hl.expit(0.0)); 0.5. Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`; """"""; ret",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:57340,Testability,log,logistic,57340,": float or :class:`.Expression` of type :py:data:`.tfloat64`. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`; """""". def scalar_log(x):; if base is not None:; return _func(""log"", tfloat64, x, to_expr(base)); else:; return _func(""log"", tfloat64, x). x = to_expr(x); if isinstance(x.dtype, tndarray):; return x.map(scalar_log); return scalar_log(x). [docs]@typecheck(x=oneof(expr_float64, expr_ndarray(expr_float64))); @ndarray_broadcasting; def log10(x) -> Float64Expression:; """"""Take the logarithm of the `x` with base 10. Examples; --------. >>> hl.eval(hl.log10(1000)); 3.0. >>> hl.eval(hl.log10(0.0001123)); -3.949620243738542. Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`; """"""; return _func(""log10"", tfloat64, x). [docs]@typecheck(x=oneof(expr_float64, expr_ndarray(expr_float64))); @ndarray_broadcasting; def logit(x) -> Float64Expression:; """"""The logistic function. Examples; --------; >>> hl.eval(hl.logit(.01)); -4.59511985013459; >>> hl.eval(hl.logit(.5)); 0.0. Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`; """"""; return hl.log(x / (1 - x)). [docs]@typecheck(x=oneof(expr_float64, expr_ndarray(expr_float64))); @ndarray_broadcasting; def expit(x) -> Float64Expression:; """"""The logistic sigmoid function. .. math::. \textrm{expit}(x) = \frac{1}{1 + e^{-x}}. Examples; --------; >>> hl.eval(hl.expit(.01)); 0.5024999791668749; >>> hl.eval(hl.expit(0.0)); 0.5. Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`; """"""; ret",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:57394,Testability,log,logit,57394,"a:`.tfloat64`; """""". def scalar_log(x):; if base is not None:; return _func(""log"", tfloat64, x, to_expr(base)); else:; return _func(""log"", tfloat64, x). x = to_expr(x); if isinstance(x.dtype, tndarray):; return x.map(scalar_log); return scalar_log(x). [docs]@typecheck(x=oneof(expr_float64, expr_ndarray(expr_float64))); @ndarray_broadcasting; def log10(x) -> Float64Expression:; """"""Take the logarithm of the `x` with base 10. Examples; --------. >>> hl.eval(hl.log10(1000)); 3.0. >>> hl.eval(hl.log10(0.0001123)); -3.949620243738542. Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`; """"""; return _func(""log10"", tfloat64, x). [docs]@typecheck(x=oneof(expr_float64, expr_ndarray(expr_float64))); @ndarray_broadcasting; def logit(x) -> Float64Expression:; """"""The logistic function. Examples; --------; >>> hl.eval(hl.logit(.01)); -4.59511985013459; >>> hl.eval(hl.logit(.5)); 0.0. Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`; """"""; return hl.log(x / (1 - x)). [docs]@typecheck(x=oneof(expr_float64, expr_ndarray(expr_float64))); @ndarray_broadcasting; def expit(x) -> Float64Expression:; """"""The logistic sigmoid function. .. math::. \textrm{expit}(x) = \frac{1}{1 + e^{-x}}. Examples; --------; >>> hl.eval(hl.expit(.01)); 0.5024999791668749; >>> hl.eval(hl.expit(0.0)); 0.5. Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`; """"""; return hl.if_else(x >= 0, 1 / (1 + hl.exp(-x)), hl.rbind(hl.exp(x), lambda exped: exped / (exped + 1))). [docs]@typechec",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:57441,Testability,log,logit,57441," is not None:; return _func(""log"", tfloat64, x, to_expr(base)); else:; return _func(""log"", tfloat64, x). x = to_expr(x); if isinstance(x.dtype, tndarray):; return x.map(scalar_log); return scalar_log(x). [docs]@typecheck(x=oneof(expr_float64, expr_ndarray(expr_float64))); @ndarray_broadcasting; def log10(x) -> Float64Expression:; """"""Take the logarithm of the `x` with base 10. Examples; --------. >>> hl.eval(hl.log10(1000)); 3.0. >>> hl.eval(hl.log10(0.0001123)); -3.949620243738542. Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`; """"""; return _func(""log10"", tfloat64, x). [docs]@typecheck(x=oneof(expr_float64, expr_ndarray(expr_float64))); @ndarray_broadcasting; def logit(x) -> Float64Expression:; """"""The logistic function. Examples; --------; >>> hl.eval(hl.logit(.01)); -4.59511985013459; >>> hl.eval(hl.logit(.5)); 0.0. Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`; """"""; return hl.log(x / (1 - x)). [docs]@typecheck(x=oneof(expr_float64, expr_ndarray(expr_float64))); @ndarray_broadcasting; def expit(x) -> Float64Expression:; """"""The logistic sigmoid function. .. math::. \textrm{expit}(x) = \frac{1}{1 + e^{-x}}. Examples; --------; >>> hl.eval(hl.expit(.01)); 0.5024999791668749; >>> hl.eval(hl.expit(0.0)); 0.5. Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`; """"""; return hl.if_else(x >= 0, 1 / (1 + hl.exp(-x)), hl.rbind(hl.exp(x), lambda exped: exped / (exped + 1))). [docs]@typecheck(args=expr_any); def coalesce(*args):; """"""Retu",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:57706,Testability,log,log,57706,"); @ndarray_broadcasting; def log10(x) -> Float64Expression:; """"""Take the logarithm of the `x` with base 10. Examples; --------. >>> hl.eval(hl.log10(1000)); 3.0. >>> hl.eval(hl.log10(0.0001123)); -3.949620243738542. Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`; """"""; return _func(""log10"", tfloat64, x). [docs]@typecheck(x=oneof(expr_float64, expr_ndarray(expr_float64))); @ndarray_broadcasting; def logit(x) -> Float64Expression:; """"""The logistic function. Examples; --------; >>> hl.eval(hl.logit(.01)); -4.59511985013459; >>> hl.eval(hl.logit(.5)); 0.0. Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`; """"""; return hl.log(x / (1 - x)). [docs]@typecheck(x=oneof(expr_float64, expr_ndarray(expr_float64))); @ndarray_broadcasting; def expit(x) -> Float64Expression:; """"""The logistic sigmoid function. .. math::. \textrm{expit}(x) = \frac{1}{1 + e^{-x}}. Examples; --------; >>> hl.eval(hl.expit(.01)); 0.5024999791668749; >>> hl.eval(hl.expit(0.0)); 0.5. Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`; """"""; return hl.if_else(x >= 0, 1 / (1 + hl.exp(-x)), hl.rbind(hl.exp(x), lambda exped: exped / (exped + 1))). [docs]@typecheck(args=expr_any); def coalesce(*args):; """"""Returns the first non-missing value of `args`. Examples; --------. >>> x1 = hl.missing('int'); >>> x2 = 2; >>> hl.eval(hl.coalesce(x1, x2)); 2. Notes; -----; All arguments must have the same type, or must be convertible to a common; type (all numeric, for instance). See Als",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:57859,Testability,log,logistic,57859," `x` with base 10. Examples; --------. >>> hl.eval(hl.log10(1000)); 3.0. >>> hl.eval(hl.log10(0.0001123)); -3.949620243738542. Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`; """"""; return _func(""log10"", tfloat64, x). [docs]@typecheck(x=oneof(expr_float64, expr_ndarray(expr_float64))); @ndarray_broadcasting; def logit(x) -> Float64Expression:; """"""The logistic function. Examples; --------; >>> hl.eval(hl.logit(.01)); -4.59511985013459; >>> hl.eval(hl.logit(.5)); 0.0. Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`; """"""; return hl.log(x / (1 - x)). [docs]@typecheck(x=oneof(expr_float64, expr_ndarray(expr_float64))); @ndarray_broadcasting; def expit(x) -> Float64Expression:; """"""The logistic sigmoid function. .. math::. \textrm{expit}(x) = \frac{1}{1 + e^{-x}}. Examples; --------; >>> hl.eval(hl.expit(.01)); 0.5024999791668749; >>> hl.eval(hl.expit(0.0)); 0.5. Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64` or :class:`.NDArrayNumericExpression`; """"""; return hl.if_else(x >= 0, 1 / (1 + hl.exp(-x)), hl.rbind(hl.exp(x), lambda exped: exped / (exped + 1))). [docs]@typecheck(args=expr_any); def coalesce(*args):; """"""Returns the first non-missing value of `args`. Examples; --------. >>> x1 = hl.missing('int'); >>> x2 = 2; >>> hl.eval(hl.coalesce(x1, x2)); 2. Notes; -----; All arguments must have the same type, or must be convertible to a common; type (all numeric, for instance). See Also; --------; :func:`.or_else`. Parameters; ----------; args : variable-length args of :cl",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:60747,Testability,test,test,60747,"rns; -------; :class:`.Expression`; """"""; a, b, success = unify_exprs(a, b); if not success:; raise TypeError(; f""'or_else' requires the 'a' and 'b' arguments to have the same type\n""; f"" a: type '{a.dtype}'\n""; f"" b: type '{b.dtype}'""; ); return coalesce(a, b). [docs]@typecheck(predicate=expr_bool, value=expr_any); def or_missing(predicate, value):; """"""Returns `value` if `predicate` is ``True``, otherwise returns missing. Examples; --------. >>> hl.eval(hl.or_missing(True, 5)); 5. >>> hl.eval(hl.or_missing(False, 5)); None. Parameters; ----------; predicate : :class:`.BooleanExpression`; value : :class:`.Expression`; Value to return if `predicate` is ``True``. Returns; -------; :class:`.Expression`; This expression has the same type as `b`.; """""". return hl.if_else(predicate, value, hl.missing(value.dtype)). [docs]@typecheck(; x=expr_int32, n=expr_int32, p=expr_float64, alternative=enumeration(""two.sided"", ""two-sided"", ""greater"", ""less""); ); def binom_test(x, n, p, alternative: str) -> Float64Expression:; """"""Performs a binomial test on `p` given `x` successes in `n` trials. Returns the p-value from the `exact binomial test; <https://en.wikipedia.org/wiki/Binomial_test>`__ of the null hypothesis that; success has probability `p`, given `x` successes in `n` trials. The alternatives are interpreted as follows:; - ``'less'``: a one-tailed test of the significance of `x` or fewer successes,; - ``'greater'``: a one-tailed test of the significance of `x` or more successes, and; - ``'two-sided'``: a two-tailed test of the significance of `x` or any equivalent or more unlikely outcome. Examples; --------. All the examples below use a fair coin as the null hypothesis. Zero is; interpreted as tail and one as heads. Test if a coin is biased towards heads or tails after observing two heads; out of ten flips:. >>> hl.eval(hl.binom_test(2, 10, 0.5, 'two-sided')); 0.10937499999999994. Test if a coin is biased towards tails after observing four heads out of ten; flips:. >>> hl.eval(h",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:60839,Testability,test,test,60839,"' requires the 'a' and 'b' arguments to have the same type\n""; f"" a: type '{a.dtype}'\n""; f"" b: type '{b.dtype}'""; ); return coalesce(a, b). [docs]@typecheck(predicate=expr_bool, value=expr_any); def or_missing(predicate, value):; """"""Returns `value` if `predicate` is ``True``, otherwise returns missing. Examples; --------. >>> hl.eval(hl.or_missing(True, 5)); 5. >>> hl.eval(hl.or_missing(False, 5)); None. Parameters; ----------; predicate : :class:`.BooleanExpression`; value : :class:`.Expression`; Value to return if `predicate` is ``True``. Returns; -------; :class:`.Expression`; This expression has the same type as `b`.; """""". return hl.if_else(predicate, value, hl.missing(value.dtype)). [docs]@typecheck(; x=expr_int32, n=expr_int32, p=expr_float64, alternative=enumeration(""two.sided"", ""two-sided"", ""greater"", ""less""); ); def binom_test(x, n, p, alternative: str) -> Float64Expression:; """"""Performs a binomial test on `p` given `x` successes in `n` trials. Returns the p-value from the `exact binomial test; <https://en.wikipedia.org/wiki/Binomial_test>`__ of the null hypothesis that; success has probability `p`, given `x` successes in `n` trials. The alternatives are interpreted as follows:; - ``'less'``: a one-tailed test of the significance of `x` or fewer successes,; - ``'greater'``: a one-tailed test of the significance of `x` or more successes, and; - ``'two-sided'``: a two-tailed test of the significance of `x` or any equivalent or more unlikely outcome. Examples; --------. All the examples below use a fair coin as the null hypothesis. Zero is; interpreted as tail and one as heads. Test if a coin is biased towards heads or tails after observing two heads; out of ten flips:. >>> hl.eval(hl.binom_test(2, 10, 0.5, 'two-sided')); 0.10937499999999994. Test if a coin is biased towards tails after observing four heads out of ten; flips:. >>> hl.eval(hl.binom_test(4, 10, 0.5, 'less')); 0.3769531250000001. Test if a coin is biased towards heads after observing thirty-two ",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:61060,Testability,test,test,61060,"--. >>> hl.eval(hl.or_missing(True, 5)); 5. >>> hl.eval(hl.or_missing(False, 5)); None. Parameters; ----------; predicate : :class:`.BooleanExpression`; value : :class:`.Expression`; Value to return if `predicate` is ``True``. Returns; -------; :class:`.Expression`; This expression has the same type as `b`.; """""". return hl.if_else(predicate, value, hl.missing(value.dtype)). [docs]@typecheck(; x=expr_int32, n=expr_int32, p=expr_float64, alternative=enumeration(""two.sided"", ""two-sided"", ""greater"", ""less""); ); def binom_test(x, n, p, alternative: str) -> Float64Expression:; """"""Performs a binomial test on `p` given `x` successes in `n` trials. Returns the p-value from the `exact binomial test; <https://en.wikipedia.org/wiki/Binomial_test>`__ of the null hypothesis that; success has probability `p`, given `x` successes in `n` trials. The alternatives are interpreted as follows:; - ``'less'``: a one-tailed test of the significance of `x` or fewer successes,; - ``'greater'``: a one-tailed test of the significance of `x` or more successes, and; - ``'two-sided'``: a two-tailed test of the significance of `x` or any equivalent or more unlikely outcome. Examples; --------. All the examples below use a fair coin as the null hypothesis. Zero is; interpreted as tail and one as heads. Test if a coin is biased towards heads or tails after observing two heads; out of ten flips:. >>> hl.eval(hl.binom_test(2, 10, 0.5, 'two-sided')); 0.10937499999999994. Test if a coin is biased towards tails after observing four heads out of ten; flips:. >>> hl.eval(hl.binom_test(4, 10, 0.5, 'less')); 0.3769531250000001. Test if a coin is biased towards heads after observing thirty-two heads out; of fifty flips:. >>> hl.eval(hl.binom_test(32, 50, 0.5, 'greater')); 0.03245432353613613. Parameters; ----------; x : int or :class:`.Expression` of type :py:data:`.tint32`; Number of successes.; n : int or :class:`.Expression` of type :py:data:`.tint32`; Number of trials.; p : float or :class:`.Expression` o",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:61143,Testability,test,test,61143,"--. >>> hl.eval(hl.or_missing(True, 5)); 5. >>> hl.eval(hl.or_missing(False, 5)); None. Parameters; ----------; predicate : :class:`.BooleanExpression`; value : :class:`.Expression`; Value to return if `predicate` is ``True``. Returns; -------; :class:`.Expression`; This expression has the same type as `b`.; """""". return hl.if_else(predicate, value, hl.missing(value.dtype)). [docs]@typecheck(; x=expr_int32, n=expr_int32, p=expr_float64, alternative=enumeration(""two.sided"", ""two-sided"", ""greater"", ""less""); ); def binom_test(x, n, p, alternative: str) -> Float64Expression:; """"""Performs a binomial test on `p` given `x` successes in `n` trials. Returns the p-value from the `exact binomial test; <https://en.wikipedia.org/wiki/Binomial_test>`__ of the null hypothesis that; success has probability `p`, given `x` successes in `n` trials. The alternatives are interpreted as follows:; - ``'less'``: a one-tailed test of the significance of `x` or fewer successes,; - ``'greater'``: a one-tailed test of the significance of `x` or more successes, and; - ``'two-sided'``: a two-tailed test of the significance of `x` or any equivalent or more unlikely outcome. Examples; --------. All the examples below use a fair coin as the null hypothesis. Zero is; interpreted as tail and one as heads. Test if a coin is biased towards heads or tails after observing two heads; out of ten flips:. >>> hl.eval(hl.binom_test(2, 10, 0.5, 'two-sided')); 0.10937499999999994. Test if a coin is biased towards tails after observing four heads out of ten; flips:. >>> hl.eval(hl.binom_test(4, 10, 0.5, 'less')); 0.3769531250000001. Test if a coin is biased towards heads after observing thirty-two heads out; of fifty flips:. >>> hl.eval(hl.binom_test(32, 50, 0.5, 'greater')); 0.03245432353613613. Parameters; ----------; x : int or :class:`.Expression` of type :py:data:`.tint32`; Number of successes.; n : int or :class:`.Expression` of type :py:data:`.tint32`; Number of trials.; p : float or :class:`.Expression` o",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:61231,Testability,test,test,61231,"--. >>> hl.eval(hl.or_missing(True, 5)); 5. >>> hl.eval(hl.or_missing(False, 5)); None. Parameters; ----------; predicate : :class:`.BooleanExpression`; value : :class:`.Expression`; Value to return if `predicate` is ``True``. Returns; -------; :class:`.Expression`; This expression has the same type as `b`.; """""". return hl.if_else(predicate, value, hl.missing(value.dtype)). [docs]@typecheck(; x=expr_int32, n=expr_int32, p=expr_float64, alternative=enumeration(""two.sided"", ""two-sided"", ""greater"", ""less""); ); def binom_test(x, n, p, alternative: str) -> Float64Expression:; """"""Performs a binomial test on `p` given `x` successes in `n` trials. Returns the p-value from the `exact binomial test; <https://en.wikipedia.org/wiki/Binomial_test>`__ of the null hypothesis that; success has probability `p`, given `x` successes in `n` trials. The alternatives are interpreted as follows:; - ``'less'``: a one-tailed test of the significance of `x` or fewer successes,; - ``'greater'``: a one-tailed test of the significance of `x` or more successes, and; - ``'two-sided'``: a two-tailed test of the significance of `x` or any equivalent or more unlikely outcome. Examples; --------. All the examples below use a fair coin as the null hypothesis. Zero is; interpreted as tail and one as heads. Test if a coin is biased towards heads or tails after observing two heads; out of ten flips:. >>> hl.eval(hl.binom_test(2, 10, 0.5, 'two-sided')); 0.10937499999999994. Test if a coin is biased towards tails after observing four heads out of ten; flips:. >>> hl.eval(hl.binom_test(4, 10, 0.5, 'less')); 0.3769531250000001. Test if a coin is biased towards heads after observing thirty-two heads out; of fifty flips:. >>> hl.eval(hl.binom_test(32, 50, 0.5, 'greater')); 0.03245432353613613. Parameters; ----------; x : int or :class:`.Expression` of type :py:data:`.tint32`; Number of successes.; n : int or :class:`.Expression` of type :py:data:`.tint32`; Number of trials.; p : float or :class:`.Expression` o",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:63889,Testability,log,logarithm,63889,"one, lower_tail=False, log_p=False) -> Float64Expression:; """"""Returns the probability under the right-tail starting at x for a chi-squared; distribution with df degrees of freedom. Examples; --------. >>> hl.eval(hl.pchisqtail(5, 1)); 0.025347318677468304. >>> hl.eval(hl.pchisqtail(5, 1, ncp=2)); 0.20571085634347097. >>> hl.eval(hl.pchisqtail(5, 1, lower_tail=True)); 0.9746526813225317. >>> hl.eval(hl.pchisqtail(5, 1, log_p=True)); -3.6750823266311876. Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64`; The value at which to evaluate the CDF.; df : float or :class:`.Expression` of type :py:data:`.tfloat64`; Degrees of freedom.; ncp: float or :class:`.Expression` of type :py:data:`.tfloat64`; Noncentrality parameter, defaults to 0 if unspecified.; lower_tail : bool or :class:`.BooleanExpression`; If ``True``, compute the probability of an outcome at or below `x`,; otherwise greater than `x`.; log_p : bool or :class:`.BooleanExpression`; Return the natural logarithm of the probability. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`; """"""; if ncp is None:; return _func(""pchisqtail"", tfloat64, x, df, lower_tail, log_p); else:; return _func(""pnchisqtail"", tfloat64, x, df, ncp, lower_tail, log_p). PGENCHISQ_RETURN_TYPE = tstruct(value=tfloat64, n_iterations=tint32, converged=tbool, fault=tint32). [docs]@typecheck(; x=expr_float64,; w=expr_array(expr_float64),; k=expr_array(expr_int32),; lam=expr_array(expr_float64),; mu=expr_float64,; sigma=expr_float64,; max_iterations=nullable(expr_int32),; min_accuracy=nullable(expr_float64),; ); def pgenchisq(x, w, k, lam, mu, sigma, *, max_iterations=None, min_accuracy=None) -> Float64Expression:; r""""""The cumulative probability function of a `generalized chi-squared distribution; <https://en.wikipedia.org/wiki/Generalized_chi-squared_distribution>`__. The generalized chi-squared distribution has many interpretations. We share here four; interpretations of the values of this dist",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:68660,Testability,test,test,68660,"isq(-20, w=[1, -10, 2], k=[1, 2, 3], lam=[2, 3, 7], mu=-10, sigma=0).value); 0.5950150356303258; >>> hl.eval(hl.pgenchisq(10 , w=[1, -10, 2], k=[1, 2, 3], lam=[2, 3, 7], mu=-10, sigma=0).value); 0.923219534175858; >>> hl.eval(hl.pgenchisq(40 , w=[1, -10, 2], k=[1, 2, 3], lam=[2, 3, 7], mu=-10, sigma=0).value); 0.9971746768781656. Notes; -----. We follow Wikipedia's notational conventions. Some texts refer to the weight vector (our `w`) as; :math:`\lambda` or `lb` and the non-centrality vector (our `lam`) as `nc`. We use the Davies' algorithm which was published as:. `Davies, Robert. ""The distribution of a linear combination of chi-squared random variables.""; Applied Statistics 29 323-333. 1980. <http://www.robertnz.net/pdf/lc_chisq.pdf>`__. Davies included Fortran source code in the original publication. Davies also released a `C; language port <http://www.robertnz.net/QF.htm>`__. Hail's implementation is a fairly direct port; of the C implementation to Scala. Davies provides 39 test cases with the source code. The Hail; tests include all 39 test cases as well as a few additional tests. Davies' website cautions:. The method works well in most situations if you want only modest accuracy, say 0.0001. But; problems may arise if the sum is dominated by one or two terms with a total of only one or; two degrees of freedom and x is small. For an accessible introduction the Generalized Chi-Squared Distribution, we strongly recommend; the introduction of this paper:. `Das, Abhranil; Geisler, Wilson (2020). ""A method to integrate and classify normal; distributions"". <https://arxiv.org/abs/2012.14331>`__. Parameters; ----------; x : :obj:`float` or :class:`.Expression` of type :py:data:`.tfloat64`; The value at which to evaluate the cumulative distribution function (CDF).; w : :obj:`list` of :obj:`float` or :class:`.Expression` of type :py:class:`.tarray` of :py:data:`.tfloat64`; A weight for each non-central chi-square term.; k : :obj:`list` of :obj:`int` or :class:`.Expressi",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:68703,Testability,test,tests,68703,"a=0).value); 0.5950150356303258; >>> hl.eval(hl.pgenchisq(10 , w=[1, -10, 2], k=[1, 2, 3], lam=[2, 3, 7], mu=-10, sigma=0).value); 0.923219534175858; >>> hl.eval(hl.pgenchisq(40 , w=[1, -10, 2], k=[1, 2, 3], lam=[2, 3, 7], mu=-10, sigma=0).value); 0.9971746768781656. Notes; -----. We follow Wikipedia's notational conventions. Some texts refer to the weight vector (our `w`) as; :math:`\lambda` or `lb` and the non-centrality vector (our `lam`) as `nc`. We use the Davies' algorithm which was published as:. `Davies, Robert. ""The distribution of a linear combination of chi-squared random variables.""; Applied Statistics 29 323-333. 1980. <http://www.robertnz.net/pdf/lc_chisq.pdf>`__. Davies included Fortran source code in the original publication. Davies also released a `C; language port <http://www.robertnz.net/QF.htm>`__. Hail's implementation is a fairly direct port; of the C implementation to Scala. Davies provides 39 test cases with the source code. The Hail; tests include all 39 test cases as well as a few additional tests. Davies' website cautions:. The method works well in most situations if you want only modest accuracy, say 0.0001. But; problems may arise if the sum is dominated by one or two terms with a total of only one or; two degrees of freedom and x is small. For an accessible introduction the Generalized Chi-Squared Distribution, we strongly recommend; the introduction of this paper:. `Das, Abhranil; Geisler, Wilson (2020). ""A method to integrate and classify normal; distributions"". <https://arxiv.org/abs/2012.14331>`__. Parameters; ----------; x : :obj:`float` or :class:`.Expression` of type :py:data:`.tfloat64`; The value at which to evaluate the cumulative distribution function (CDF).; w : :obj:`list` of :obj:`float` or :class:`.Expression` of type :py:class:`.tarray` of :py:data:`.tfloat64`; A weight for each non-central chi-square term.; k : :obj:`list` of :obj:`int` or :class:`.Expression` of type :py:class:`.tarray` of :py:data:`.tint32`; A degrees ",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:68724,Testability,test,test,68724,"a=0).value); 0.5950150356303258; >>> hl.eval(hl.pgenchisq(10 , w=[1, -10, 2], k=[1, 2, 3], lam=[2, 3, 7], mu=-10, sigma=0).value); 0.923219534175858; >>> hl.eval(hl.pgenchisq(40 , w=[1, -10, 2], k=[1, 2, 3], lam=[2, 3, 7], mu=-10, sigma=0).value); 0.9971746768781656. Notes; -----. We follow Wikipedia's notational conventions. Some texts refer to the weight vector (our `w`) as; :math:`\lambda` or `lb` and the non-centrality vector (our `lam`) as `nc`. We use the Davies' algorithm which was published as:. `Davies, Robert. ""The distribution of a linear combination of chi-squared random variables.""; Applied Statistics 29 323-333. 1980. <http://www.robertnz.net/pdf/lc_chisq.pdf>`__. Davies included Fortran source code in the original publication. Davies also released a `C; language port <http://www.robertnz.net/QF.htm>`__. Hail's implementation is a fairly direct port; of the C implementation to Scala. Davies provides 39 test cases with the source code. The Hail; tests include all 39 test cases as well as a few additional tests. Davies' website cautions:. The method works well in most situations if you want only modest accuracy, say 0.0001. But; problems may arise if the sum is dominated by one or two terms with a total of only one or; two degrees of freedom and x is small. For an accessible introduction the Generalized Chi-Squared Distribution, we strongly recommend; the introduction of this paper:. `Das, Abhranil; Geisler, Wilson (2020). ""A method to integrate and classify normal; distributions"". <https://arxiv.org/abs/2012.14331>`__. Parameters; ----------; x : :obj:`float` or :class:`.Expression` of type :py:data:`.tfloat64`; The value at which to evaluate the cumulative distribution function (CDF).; w : :obj:`list` of :obj:`float` or :class:`.Expression` of type :py:class:`.tarray` of :py:data:`.tfloat64`; A weight for each non-central chi-square term.; k : :obj:`list` of :obj:`int` or :class:`.Expression` of type :py:class:`.tarray` of :py:data:`.tint32`; A degrees ",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:68763,Testability,test,tests,68763,"a=0).value); 0.5950150356303258; >>> hl.eval(hl.pgenchisq(10 , w=[1, -10, 2], k=[1, 2, 3], lam=[2, 3, 7], mu=-10, sigma=0).value); 0.923219534175858; >>> hl.eval(hl.pgenchisq(40 , w=[1, -10, 2], k=[1, 2, 3], lam=[2, 3, 7], mu=-10, sigma=0).value); 0.9971746768781656. Notes; -----. We follow Wikipedia's notational conventions. Some texts refer to the weight vector (our `w`) as; :math:`\lambda` or `lb` and the non-centrality vector (our `lam`) as `nc`. We use the Davies' algorithm which was published as:. `Davies, Robert. ""The distribution of a linear combination of chi-squared random variables.""; Applied Statistics 29 323-333. 1980. <http://www.robertnz.net/pdf/lc_chisq.pdf>`__. Davies included Fortran source code in the original publication. Davies also released a `C; language port <http://www.robertnz.net/QF.htm>`__. Hail's implementation is a fairly direct port; of the C implementation to Scala. Davies provides 39 test cases with the source code. The Hail; tests include all 39 test cases as well as a few additional tests. Davies' website cautions:. The method works well in most situations if you want only modest accuracy, say 0.0001. But; problems may arise if the sum is dominated by one or two terms with a total of only one or; two degrees of freedom and x is small. For an accessible introduction the Generalized Chi-Squared Distribution, we strongly recommend; the introduction of this paper:. `Das, Abhranil; Geisler, Wilson (2020). ""A method to integrate and classify normal; distributions"". <https://arxiv.org/abs/2012.14331>`__. Parameters; ----------; x : :obj:`float` or :class:`.Expression` of type :py:data:`.tfloat64`; The value at which to evaluate the cumulative distribution function (CDF).; w : :obj:`list` of :obj:`float` or :class:`.Expression` of type :py:class:`.tarray` of :py:data:`.tfloat64`; A weight for each non-central chi-square term.; k : :obj:`list` of :obj:`int` or :class:`.Expression` of type :py:class:`.tarray` of :py:data:`.tint32`; A degrees ",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:73044,Testability,log,logarithm,73044," `mu` and standard deviation `sigma`. Returns cumulative probability of; standard normal distribution by default. Examples; --------. >>> hl.eval(hl.pnorm(0)); 0.5. >>> hl.eval(hl.pnorm(1, mu=2, sigma=2)); 0.30853753872598694. >>> hl.eval(hl.pnorm(2, lower_tail=False)); 0.022750131948179212. >>> hl.eval(hl.pnorm(2, log_p=True)); -0.023012909328963493. Notes; -----; Returns the left-tail probability `p` = Prob(:math:`Z < x`) with :math:`Z`; a normal random variable. Defaults to a standard normal random variable. Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64`; mu : float or :class:`.Expression` of type :py:data:`.tfloat64`; Mean (default = 0).; sigma: float or :class:`.Expression` of type :py:data:`.tfloat64`; Standard deviation (default = 1).; lower_tail : bool or :class:`.BooleanExpression`; If ``True``, compute the probability of an outcome at or below `x`,; otherwise greater than `x`.; log_p : bool or :class:`.BooleanExpression`; Return the natural logarithm of the probability. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`; """"""; return _func(""pnorm"", tfloat64, x, mu, sigma, lower_tail, log_p). [docs]@typecheck(x=expr_float64, n=expr_float64, lower_tail=expr_bool, log_p=expr_bool); def pT(x, n, lower_tail=True, log_p=False) -> Float64Expression:; r""""""The cumulative probability function of a `t-distribution; <https://en.wikipedia.org/wiki/Student%27s_t-distribution>`__ with; `n` degrees of freedom. Examples; --------. >>> hl.eval(hl.pT(0, 10)); 0.5. >>> hl.eval(hl.pT(1, 10)); 0.82955343384897. >>> hl.eval(hl.pT(1, 10, lower_tail=False)); 0.17044656615103004. >>> hl.eval(hl.pT(1, 10, log_p=True)); -0.186867754489647. Notes; -----; If `lower_tail` is true, returns Prob(:math:`X \leq` `x`) where :math:`X` is; a t-distributed random variable with `n` degrees of freedom. If `lower_tail`; is false, returns Prob(:math:`X` > `x`). Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:74363,Testability,log,logarithm,74363,"pression:; r""""""The cumulative probability function of a `t-distribution; <https://en.wikipedia.org/wiki/Student%27s_t-distribution>`__ with; `n` degrees of freedom. Examples; --------. >>> hl.eval(hl.pT(0, 10)); 0.5. >>> hl.eval(hl.pT(1, 10)); 0.82955343384897. >>> hl.eval(hl.pT(1, 10, lower_tail=False)); 0.17044656615103004. >>> hl.eval(hl.pT(1, 10, log_p=True)); -0.186867754489647. Notes; -----; If `lower_tail` is true, returns Prob(:math:`X \leq` `x`) where :math:`X` is; a t-distributed random variable with `n` degrees of freedom. If `lower_tail`; is false, returns Prob(:math:`X` > `x`). Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64`; n : float or :class:`.Expression` of type :py:data:`.tfloat64`; Degrees of freedom of the t-distribution.; lower_tail : bool or :class:`.BooleanExpression`; If ``True``, compute the probability of an outcome at or below `x`,; otherwise greater than `x`.; log_p : bool or :class:`.BooleanExpression`; Return the natural logarithm of the probability. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`. """"""; return _func(""pT"", tfloat64, x, n, lower_tail, log_p). [docs]@typecheck(x=expr_float64, df1=expr_float64, df2=expr_float64, lower_tail=expr_bool, log_p=expr_bool); def pF(x, df1, df2, lower_tail=True, log_p=False) -> Float64Expression:; r""""""The cumulative probability function of a `F-distribution; <https://en.wikipedia.org/wiki/F-distribution>`__ with parameters; `df1` and `df2`. Examples; --------. >>> hl.eval(hl.pF(0, 3, 10)); 0.0. >>> hl.eval(hl.pF(1, 3, 10)); 0.5676627969783028. >>> hl.eval(hl.pF(1, 3, 10, lower_tail=False)); 0.4323372030216972. >>> hl.eval(hl.pF(1, 3, 10, log_p=True)); -0.566227703842908. Notes; -----; If `lower_tail` is true, returns Prob(:math:`X \leq` `x`) where :math:`X` is; a random variable with distribution :math:`F`(df1, df2). If `lower_tail`; is false, returns Prob(:math:`X` > `x`). Parameters; ----------; x : float or :class:`.Expression` of type ",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:75790,Testability,log,logarithm,75790,"ia.org/wiki/F-distribution>`__ with parameters; `df1` and `df2`. Examples; --------. >>> hl.eval(hl.pF(0, 3, 10)); 0.0. >>> hl.eval(hl.pF(1, 3, 10)); 0.5676627969783028. >>> hl.eval(hl.pF(1, 3, 10, lower_tail=False)); 0.4323372030216972. >>> hl.eval(hl.pF(1, 3, 10, log_p=True)); -0.566227703842908. Notes; -----; If `lower_tail` is true, returns Prob(:math:`X \leq` `x`) where :math:`X` is; a random variable with distribution :math:`F`(df1, df2). If `lower_tail`; is false, returns Prob(:math:`X` > `x`). Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64`; df1 : float or :class:`.Expression` of type :py:data:`.tfloat64`; Parameter of the F-distribution; df2 : float or :class:`.Expression` of type :py:data:`.tfloat64`; Parameter of the F-distribution; lower_tail : bool or :class:`.BooleanExpression`; If ``True``, compute the probability of an outcome at or below `x`,; otherwise greater than `x`.; log_p : bool or :class:`.BooleanExpression`; Return the natural logarithm of the probability. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`; """"""; return _func(""pF"", tfloat64, x, df1, df2, lower_tail, log_p). [docs]@typecheck(x=expr_float64, lamb=expr_float64, lower_tail=expr_bool, log_p=expr_bool); def ppois(x, lamb, lower_tail=True, log_p=False) -> Float64Expression:; r""""""The cumulative probability function of a Poisson distribution. Examples; --------. >>> hl.eval(hl.ppois(2, 1)); 0.9196986029286058. Notes; -----; If `lower_tail` is true, returns Prob(:math:`X \leq` `x`) where :math:`X` is a; Poisson random variable with rate parameter `lamb`. If `lower_tail` is false,; returns Prob(:math:`X` > `x`). Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64`; lamb : float or :class:`.Expression` of type :py:data:`.tfloat64`; Rate parameter of Poisson distribution.; lower_tail : bool or :class:`.BooleanExpression`; If ``True``, compute the probability of an outcome at or below `x`,; otherwise ",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:76868,Testability,log,logarithm,76868,"ype :py:data:`.tfloat64`; """"""; return _func(""pF"", tfloat64, x, df1, df2, lower_tail, log_p). [docs]@typecheck(x=expr_float64, lamb=expr_float64, lower_tail=expr_bool, log_p=expr_bool); def ppois(x, lamb, lower_tail=True, log_p=False) -> Float64Expression:; r""""""The cumulative probability function of a Poisson distribution. Examples; --------. >>> hl.eval(hl.ppois(2, 1)); 0.9196986029286058. Notes; -----; If `lower_tail` is true, returns Prob(:math:`X \leq` `x`) where :math:`X` is a; Poisson random variable with rate parameter `lamb`. If `lower_tail` is false,; returns Prob(:math:`X` > `x`). Parameters; ----------; x : float or :class:`.Expression` of type :py:data:`.tfloat64`; lamb : float or :class:`.Expression` of type :py:data:`.tfloat64`; Rate parameter of Poisson distribution.; lower_tail : bool or :class:`.BooleanExpression`; If ``True``, compute the probability of an outcome at or below `x`,; otherwise greater than `x`.; log_p : bool or :class:`.BooleanExpression`; Return the natural logarithm of the probability. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`; """"""; return _func(""ppois"", tfloat64, x, lamb, lower_tail, log_p). [docs]@typecheck(p=expr_float64, df=expr_float64, ncp=nullable(expr_float64), lower_tail=expr_bool, log_p=expr_bool); def qchisqtail(p, df, ncp=None, lower_tail=False, log_p=False) -> Float64Expression:; """"""The quantile function of a chi-squared distribution with `df` degrees of; freedom, inverts :func:`~.pchisqtail`. Examples; --------. >>> hl.eval(hl.qchisqtail(0.05, 2)); 5.991464547107979. >>> hl.eval(hl.qchisqtail(0.05, 2, ncp=2)); 10.838131614372958. >>> hl.eval(hl.qchisqtail(0.05, 2, lower_tail=True)); 0.10258658877510107. >>> hl.eval(hl.qchisqtail(hl.log(0.05), 2, log_p=True)); 5.991464547107979. Notes; -----; Returns right-quantile `x` for which `p` = Prob(:math:`Z^2` > x) with; :math:`Z^2` a chi-squared random variable with degrees of freedom specified; by `df`. The probability `p` must satisfy 0 < `p` < 1. Pa",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:77597,Testability,log,log,77597,"a:`.tfloat64`; Rate parameter of Poisson distribution.; lower_tail : bool or :class:`.BooleanExpression`; If ``True``, compute the probability of an outcome at or below `x`,; otherwise greater than `x`.; log_p : bool or :class:`.BooleanExpression`; Return the natural logarithm of the probability. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`; """"""; return _func(""ppois"", tfloat64, x, lamb, lower_tail, log_p). [docs]@typecheck(p=expr_float64, df=expr_float64, ncp=nullable(expr_float64), lower_tail=expr_bool, log_p=expr_bool); def qchisqtail(p, df, ncp=None, lower_tail=False, log_p=False) -> Float64Expression:; """"""The quantile function of a chi-squared distribution with `df` degrees of; freedom, inverts :func:`~.pchisqtail`. Examples; --------. >>> hl.eval(hl.qchisqtail(0.05, 2)); 5.991464547107979. >>> hl.eval(hl.qchisqtail(0.05, 2, ncp=2)); 10.838131614372958. >>> hl.eval(hl.qchisqtail(0.05, 2, lower_tail=True)); 0.10258658877510107. >>> hl.eval(hl.qchisqtail(hl.log(0.05), 2, log_p=True)); 5.991464547107979. Notes; -----; Returns right-quantile `x` for which `p` = Prob(:math:`Z^2` > x) with; :math:`Z^2` a chi-squared random variable with degrees of freedom specified; by `df`. The probability `p` must satisfy 0 < `p` < 1. Parameters; ----------; p : float or :class:`.Expression` of type :py:data:`.tfloat64`; Probability.; df : float or :class:`.Expression` of type :py:data:`.tfloat64`; Degrees of freedom.; ncp: float or :class:`.Expression` of type :py:data:`.tfloat64`; Corresponds to `ncp` parameter in :func:`.pchisqtail`.; lower_tail : bool or :class:`.BooleanExpression`; Corresponds to `lower_tail` parameter in :func:`.pchisqtail`.; log_p : bool or :class:`.BooleanExpression`; Exponentiate `p`, corresponds to `log_p` parameter in :func:`.pchisqtail`. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`; """"""; if ncp is None:; return _func(""qchisqtail"", tfloat64, p, df, lower_tail, log_p); else:; return _func(""qnchisqtail"", tfloat6",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:79236,Testability,log,log,79236,"er_tail` parameter in :func:`.pchisqtail`.; log_p : bool or :class:`.BooleanExpression`; Exponentiate `p`, corresponds to `log_p` parameter in :func:`.pchisqtail`. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`; """"""; if ncp is None:; return _func(""qchisqtail"", tfloat64, p, df, lower_tail, log_p); else:; return _func(""qnchisqtail"", tfloat64, p, df, ncp, lower_tail, log_p). [docs]@typecheck(p=expr_float64, mu=expr_float64, sigma=expr_float64, lower_tail=expr_bool, log_p=expr_bool); def qnorm(p, mu=0, sigma=1, lower_tail=True, log_p=False) -> Float64Expression:; """"""The quantile function of a normal distribution with mean `mu` and; standard deviation `sigma`, inverts :func:`~.pnorm`. Returns quantile of; standard normal distribution by default. Examples; --------. >>> hl.eval(hl.qnorm(0.90)); 1.2815515655446008. >>> hl.eval(hl.qnorm(0.90, mu=1, sigma=2)); 3.5631031310892016. >>> hl.eval(hl.qnorm(0.90, lower_tail=False)); -1.2815515655446008. >>> hl.eval(hl.qnorm(hl.log(0.90), log_p=True)); 1.2815515655446008. Notes; -----; Returns left-quantile `x` for which p = Prob(:math:`Z` < x) with :math:`Z`; a normal random variable with mean `mu` and standard deviation `sigma`.; Defaults to a standard normal random variable, and the probability `p` must; satisfy 0 < `p` < 1. Parameters; ----------; p : float or :class:`.Expression` of type :py:data:`.tfloat64`; Probability.; mu : float or :class:`.Expression` of type :py:data:`.tfloat64`; Mean (default = 0).; sigma: float or :class:`.Expression` of type :py:data:`.tfloat64`; Standard deviation (default = 1).; lower_tail : bool or :class:`.BooleanExpression`; Corresponds to `lower_tail` parameter in :func:`.pnorm`.; log_p : bool or :class:`.BooleanExpression`; Exponentiate `p`, corresponds to `log_p` parameter in :func:`.pnorm`. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`; """"""; return _func(""qnorm"", tfloat64, p, mu, sigma, lower_tail, log_p). [docs]@typecheck(p=expr_float64, lamb=expr_f",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:81080,Testability,test,testing,81080,"; -------; :class:`.Expression` of type :py:data:`.tfloat64`; """"""; return _func(""qnorm"", tfloat64, p, mu, sigma, lower_tail, log_p). [docs]@typecheck(p=expr_float64, lamb=expr_float64, lower_tail=expr_bool, log_p=expr_bool); def qpois(p, lamb, lower_tail=True, log_p=False) -> Float64Expression:; r""""""The quantile function of a Poisson distribution with rate parameter; `lamb`, inverts :func:`~.ppois`. Examples; --------. >>> hl.eval(hl.qpois(0.99, 1)); 4. Notes; -----; Returns the smallest integer :math:`x` such that Prob(:math:`X \leq x`) :math:`\geq` `p` where :math:`X`; is a Poisson random variable with rate parameter `lambda`. Parameters; ----------; p : float or :class:`.Expression` of type :py:data:`.tfloat64`; lamb : float or :class:`.Expression` of type :py:data:`.tfloat64`; Rate parameter of Poisson distribution.; lower_tail : bool or :class:`.BooleanExpression`; Corresponds to `lower_tail` parameter in inverse :func:`.ppois`.; log_p : bool or :class:`.BooleanExpression`; Exponentiate `p` before testing. Returns; -------; :class:`.Expression` of type :py:data:`.tfloat64`; """"""; return _func(""qpois"", tint32, p, lamb, lower_tail, log_p). [docs]@typecheck(start=expr_int32, stop=nullable(expr_int32), step=expr_int32); def range(start, stop=None, step=1) -> ArrayNumericExpression:; """"""Returns an array of integers from `start` to `stop` by `step`. Examples; --------. >>> hl.eval(hl.range(10)); [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]. >>> hl.eval(hl.range(3, 10)); [3, 4, 5, 6, 7, 8, 9]. >>> hl.eval(hl.range(0, 10, step=3)); [0, 3, 6, 9]. Notes; -----; The range includes `start`, but excludes `stop`. If provided exactly one argument, the argument is interpreted as `stop` and; `start` is set to zero. This matches the behavior of Python's ``range``. Parameters; ----------; start : int or :class:`.Expression` of type :py:data:`.tint32`; Start of range.; stop : int or :class:`.Expression` of type :py:data:`.tint32`; End of range.; step : int or :class:`.Expression` of type :py:dat",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:138771,Testability,assert,assert,138771,"` or :class:`.HailType`; Type of the set elements. Returns; -------; :class:`.SetExpression`; """"""; return hl.set(empty_array(t)). [docs]@typecheck(collection=expr_oneof(expr_set(), expr_array(), expr_dict(), expr_ndarray())); def array(collection) -> ArrayExpression:; """"""Construct an array expression. Examples; --------. >>> s = {'Bob', 'Charlie', 'Alice'}. >>> hl.eval(hl.array(s)); ['Alice', 'Bob', 'Charlie']. Parameters; ----------; collection : :class:`.ArrayExpression` or :class:`.SetExpression` or :class:`.DictExpression`. Returns; -------; :class:`.ArrayExpression`; """"""; if isinstance(collection.dtype, tarray):; return collection; elif isinstance(collection.dtype, tset):; return apply_expr(lambda c: ir.CastToArray(c), tarray(collection.dtype.element_type), collection); elif isinstance(collection.dtype, tndarray):; if collection.dtype.ndim != 1:; raise ValueError(f'array: only one dimensional ndarrays are supported: {collection.dtype}'); return collection._data_array(); else:; assert isinstance(collection.dtype, tdict); return _func('dictToArray', tarray(ttuple(collection.dtype.key_type, collection.dtype.value_type)), collection). [docs]@typecheck(t=hail_type); def empty_array(t: Union[HailType, builtins.str]) -> ArrayExpression:; """"""Returns an empty array of elements of a type `t`. Examples; --------. >>> hl.eval(hl.empty_array(hl.tint32)); []. Parameters; ----------; t : :class:`str` or :class:`.HailType`; Type of the array elements. Returns; -------; :class:`.ArrayExpression`; """"""; array_t = hl.tarray(t); a = ir.MakeArray([], array_t); return construct_expr(a, array_t). def _ndarray(collection, row_major=None, dtype=None):; """"""Construct a Hail ndarray from either a flat Hail array, a `NumPy` ndarray or python value/nested lists. Parameters; ----------; collection : :class:`numpy.ndarray` or :obj:`numeric` or :obj: `list` of `numeric`; Type of the array elements.; row_major : :obj: `bool` or None. Returns; -------; :class:`.NDArrayExpression`; """""". def list_sh",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:177671,Testability,assert,assert,177671,"uple(args)). [docs]@typecheck(x=expr_float64, y=expr_float64, tolerance=expr_float64, absolute=expr_bool, nan_same=expr_bool); def approx_equal(x, y, tolerance=1e-6, absolute=False, nan_same=False):; """"""Tests whether two numbers are approximately equal. Examples; --------; >>> hl.eval(hl.approx_equal(0.25, 0.2500001)); True. >>> hl.eval(hl.approx_equal(0.25, 0.251, tolerance=1e-3, absolute=True)); False. Parameters; ----------; x : :class:`.NumericExpression`; y : :class:`.NumericExpression`; tolerance : :class:`.NumericExpression`; absolute : :class:`.BooleanExpression`; If True, compute ``abs(x - y) <= tolerance``. Otherwise, compute; ``abs(x - y) <= max(tolerance * max(abs(x), abs(y)), 2 ** -1022)``.; nan_same : :class:`.BooleanExpression`; If True, then ``NaN == NaN`` will evaluate to True. Otherwise,; it will return False. Returns; -------; :class:`.BooleanExpression`; """""". return _func(""approxEqual"", hl.tbool, x, y, tolerance, absolute, nan_same). def _shift_op(x, y, op):; assert op in ('<<', '>>', '>>>'); t = x.dtype; if t == hl.tint64:; word_size = 64; zero = hl.int64(0); else:; word_size = 32; zero = hl.int32(0). indices, aggregations = unify_all(x, y); return hl.bind(; lambda x, y: (; hl.case(); .when(y >= word_size, hl.sign(x) if op == '>>' else zero); .when(y >= 0, construct_expr(ir.ApplyBinaryPrimOp(op, x._ir, y._ir), t, indices, aggregations)); .or_error('cannot shift by a negative value: ' + hl.str(x) + f"" {op} "" + hl.str(y)); ),; x,; y,; ). def _bit_op(x, y, op):; if x.dtype == hl.tint32 and y.dtype == hl.tint32:; t = hl.tint32; else:; t = hl.tint64; coercer = coercer_from_dtype(t); x = coercer.coerce(x); y = coercer.coerce(y). indices, aggregations = unify_all(x, y); return construct_expr(ir.ApplyBinaryPrimOp(op, x._ir, y._ir), t, indices, aggregations). [docs]@typecheck(x=expr_oneof(expr_int32, expr_int64), y=expr_oneof(expr_int32, expr_int64)); def bit_and(x, y):; """"""Bitwise and `x` and `y`. Examples; --------; >>> hl.eval(hl.bit_and(5, 3)); 1. Not",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:181181,Testability,log,logical,181181,"ass:`.Int64Expression`; """"""; return _bit_op(x, y, '^'). [docs]@typecheck(x=expr_oneof(expr_int32, expr_int64), y=expr_int32); def bit_lshift(x, y):; """"""Bitwise left-shift `x` by `y`. Examples; --------; >>> hl.eval(hl.bit_lshift(5, 3)); 40. >>> hl.eval(hl.bit_lshift(1, 8)); 256. Unlike Python, Hail integers are fixed-size (32 or 64 bits),; and bits extended beyond will be ignored:. >>> hl.eval(hl.bit_lshift(1, 31)); -2147483648. >>> hl.eval(hl.bit_lshift(1, 32)); 0. >>> hl.eval(hl.bit_lshift(hl.int64(1), 32)); 4294967296. >>> hl.eval(hl.bit_lshift(hl.int64(1), 64)); 0. Notes; -----; See `the Python wiki <https://wiki.python.org/moin/BitwiseOperators>`__; for more information about bit operators. Parameters; ----------; x : :class:`.Int32Expression` or :class:`.Int64Expression`; y : :class:`.Int32Expression` or :class:`.Int64Expression`. Returns; -------; :class:`.Int32Expression` or :class:`.Int64Expression`; """"""; return _shift_op(x, y, '<<'). [docs]@typecheck(x=expr_oneof(expr_int32, expr_int64), y=expr_int32, logical=builtins.bool); def bit_rshift(x, y, logical=False):; """"""Bitwise right-shift `x` by `y`. Examples; --------; >>> hl.eval(hl.bit_rshift(256, 3)); 32. With ``logical=False`` (default), the sign is preserved:. >>> hl.eval(hl.bit_rshift(-1, 1)); -1. With ``logical=True``, the sign bit is treated as any other:. >>> hl.eval(hl.bit_rshift(-1, 1, logical=True)); 2147483647. Notes; -----; If `logical` is ``False``, then the shift is a sign-preserving right shift.; If `logical` is ``True``, then the shift is logical, with the sign bit; treated as any other bit. See `the Python wiki <https://wiki.python.org/moin/BitwiseOperators>`__; for more information about bit operators. Parameters; ----------; x : :class:`.Int32Expression` or :class:`.Int64Expression`; y : :class:`.Int32Expression` or :class:`.Int64Expression`; logical : :obj:`bool`. Returns; -------; :class:`.Int32Expression` or :class:`.Int64Expression`; """"""; if logical:; return _shift_op(x, y, '>>>'); els",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:181226,Testability,log,logical,181226,"of(expr_int32, expr_int64), y=expr_int32); def bit_lshift(x, y):; """"""Bitwise left-shift `x` by `y`. Examples; --------; >>> hl.eval(hl.bit_lshift(5, 3)); 40. >>> hl.eval(hl.bit_lshift(1, 8)); 256. Unlike Python, Hail integers are fixed-size (32 or 64 bits),; and bits extended beyond will be ignored:. >>> hl.eval(hl.bit_lshift(1, 31)); -2147483648. >>> hl.eval(hl.bit_lshift(1, 32)); 0. >>> hl.eval(hl.bit_lshift(hl.int64(1), 32)); 4294967296. >>> hl.eval(hl.bit_lshift(hl.int64(1), 64)); 0. Notes; -----; See `the Python wiki <https://wiki.python.org/moin/BitwiseOperators>`__; for more information about bit operators. Parameters; ----------; x : :class:`.Int32Expression` or :class:`.Int64Expression`; y : :class:`.Int32Expression` or :class:`.Int64Expression`. Returns; -------; :class:`.Int32Expression` or :class:`.Int64Expression`; """"""; return _shift_op(x, y, '<<'). [docs]@typecheck(x=expr_oneof(expr_int32, expr_int64), y=expr_int32, logical=builtins.bool); def bit_rshift(x, y, logical=False):; """"""Bitwise right-shift `x` by `y`. Examples; --------; >>> hl.eval(hl.bit_rshift(256, 3)); 32. With ``logical=False`` (default), the sign is preserved:. >>> hl.eval(hl.bit_rshift(-1, 1)); -1. With ``logical=True``, the sign bit is treated as any other:. >>> hl.eval(hl.bit_rshift(-1, 1, logical=True)); 2147483647. Notes; -----; If `logical` is ``False``, then the shift is a sign-preserving right shift.; If `logical` is ``True``, then the shift is logical, with the sign bit; treated as any other bit. See `the Python wiki <https://wiki.python.org/moin/BitwiseOperators>`__; for more information about bit operators. Parameters; ----------; x : :class:`.Int32Expression` or :class:`.Int64Expression`; y : :class:`.Int32Expression` or :class:`.Int64Expression`; logical : :obj:`bool`. Returns; -------; :class:`.Int32Expression` or :class:`.Int64Expression`; """"""; if logical:; return _shift_op(x, y, '>>>'); else:; return _shift_op(x, y, '>>'). [docs]@typecheck(x=expr_oneof(expr_int32, expr_in",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:181345,Testability,log,logical,181345,"al(hl.bit_lshift(5, 3)); 40. >>> hl.eval(hl.bit_lshift(1, 8)); 256. Unlike Python, Hail integers are fixed-size (32 or 64 bits),; and bits extended beyond will be ignored:. >>> hl.eval(hl.bit_lshift(1, 31)); -2147483648. >>> hl.eval(hl.bit_lshift(1, 32)); 0. >>> hl.eval(hl.bit_lshift(hl.int64(1), 32)); 4294967296. >>> hl.eval(hl.bit_lshift(hl.int64(1), 64)); 0. Notes; -----; See `the Python wiki <https://wiki.python.org/moin/BitwiseOperators>`__; for more information about bit operators. Parameters; ----------; x : :class:`.Int32Expression` or :class:`.Int64Expression`; y : :class:`.Int32Expression` or :class:`.Int64Expression`. Returns; -------; :class:`.Int32Expression` or :class:`.Int64Expression`; """"""; return _shift_op(x, y, '<<'). [docs]@typecheck(x=expr_oneof(expr_int32, expr_int64), y=expr_int32, logical=builtins.bool); def bit_rshift(x, y, logical=False):; """"""Bitwise right-shift `x` by `y`. Examples; --------; >>> hl.eval(hl.bit_rshift(256, 3)); 32. With ``logical=False`` (default), the sign is preserved:. >>> hl.eval(hl.bit_rshift(-1, 1)); -1. With ``logical=True``, the sign bit is treated as any other:. >>> hl.eval(hl.bit_rshift(-1, 1, logical=True)); 2147483647. Notes; -----; If `logical` is ``False``, then the shift is a sign-preserving right shift.; If `logical` is ``True``, then the shift is logical, with the sign bit; treated as any other bit. See `the Python wiki <https://wiki.python.org/moin/BitwiseOperators>`__; for more information about bit operators. Parameters; ----------; x : :class:`.Int32Expression` or :class:`.Int64Expression`; y : :class:`.Int32Expression` or :class:`.Int64Expression`; logical : :obj:`bool`. Returns; -------; :class:`.Int32Expression` or :class:`.Int64Expression`; """"""; if logical:; return _shift_op(x, y, '>>>'); else:; return _shift_op(x, y, '>>'). [docs]@typecheck(x=expr_oneof(expr_int32, expr_int64)); def bit_not(x):; """"""Bitwise invert `x`. Examples; --------; >>> hl.eval(hl.bit_not(0)); -1. Notes; -----; See `the Python",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:181442,Testability,log,logical,181442,"e fixed-size (32 or 64 bits),; and bits extended beyond will be ignored:. >>> hl.eval(hl.bit_lshift(1, 31)); -2147483648. >>> hl.eval(hl.bit_lshift(1, 32)); 0. >>> hl.eval(hl.bit_lshift(hl.int64(1), 32)); 4294967296. >>> hl.eval(hl.bit_lshift(hl.int64(1), 64)); 0. Notes; -----; See `the Python wiki <https://wiki.python.org/moin/BitwiseOperators>`__; for more information about bit operators. Parameters; ----------; x : :class:`.Int32Expression` or :class:`.Int64Expression`; y : :class:`.Int32Expression` or :class:`.Int64Expression`. Returns; -------; :class:`.Int32Expression` or :class:`.Int64Expression`; """"""; return _shift_op(x, y, '<<'). [docs]@typecheck(x=expr_oneof(expr_int32, expr_int64), y=expr_int32, logical=builtins.bool); def bit_rshift(x, y, logical=False):; """"""Bitwise right-shift `x` by `y`. Examples; --------; >>> hl.eval(hl.bit_rshift(256, 3)); 32. With ``logical=False`` (default), the sign is preserved:. >>> hl.eval(hl.bit_rshift(-1, 1)); -1. With ``logical=True``, the sign bit is treated as any other:. >>> hl.eval(hl.bit_rshift(-1, 1, logical=True)); 2147483647. Notes; -----; If `logical` is ``False``, then the shift is a sign-preserving right shift.; If `logical` is ``True``, then the shift is logical, with the sign bit; treated as any other bit. See `the Python wiki <https://wiki.python.org/moin/BitwiseOperators>`__; for more information about bit operators. Parameters; ----------; x : :class:`.Int32Expression` or :class:`.Int64Expression`; y : :class:`.Int32Expression` or :class:`.Int64Expression`; logical : :obj:`bool`. Returns; -------; :class:`.Int32Expression` or :class:`.Int64Expression`; """"""; if logical:; return _shift_op(x, y, '>>>'); else:; return _shift_op(x, y, '>>'). [docs]@typecheck(x=expr_oneof(expr_int32, expr_int64)); def bit_not(x):; """"""Bitwise invert `x`. Examples; --------; >>> hl.eval(hl.bit_not(0)); -1. Notes; -----; See `the Python wiki <https://wiki.python.org/moin/BitwiseOperators>`__; for more information about bit operators.",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:181530,Testability,log,logical,181530,"ed:. >>> hl.eval(hl.bit_lshift(1, 31)); -2147483648. >>> hl.eval(hl.bit_lshift(1, 32)); 0. >>> hl.eval(hl.bit_lshift(hl.int64(1), 32)); 4294967296. >>> hl.eval(hl.bit_lshift(hl.int64(1), 64)); 0. Notes; -----; See `the Python wiki <https://wiki.python.org/moin/BitwiseOperators>`__; for more information about bit operators. Parameters; ----------; x : :class:`.Int32Expression` or :class:`.Int64Expression`; y : :class:`.Int32Expression` or :class:`.Int64Expression`. Returns; -------; :class:`.Int32Expression` or :class:`.Int64Expression`; """"""; return _shift_op(x, y, '<<'). [docs]@typecheck(x=expr_oneof(expr_int32, expr_int64), y=expr_int32, logical=builtins.bool); def bit_rshift(x, y, logical=False):; """"""Bitwise right-shift `x` by `y`. Examples; --------; >>> hl.eval(hl.bit_rshift(256, 3)); 32. With ``logical=False`` (default), the sign is preserved:. >>> hl.eval(hl.bit_rshift(-1, 1)); -1. With ``logical=True``, the sign bit is treated as any other:. >>> hl.eval(hl.bit_rshift(-1, 1, logical=True)); 2147483647. Notes; -----; If `logical` is ``False``, then the shift is a sign-preserving right shift.; If `logical` is ``True``, then the shift is logical, with the sign bit; treated as any other bit. See `the Python wiki <https://wiki.python.org/moin/BitwiseOperators>`__; for more information about bit operators. Parameters; ----------; x : :class:`.Int32Expression` or :class:`.Int64Expression`; y : :class:`.Int32Expression` or :class:`.Int64Expression`; logical : :obj:`bool`. Returns; -------; :class:`.Int32Expression` or :class:`.Int64Expression`; """"""; if logical:; return _shift_op(x, y, '>>>'); else:; return _shift_op(x, y, '>>'). [docs]@typecheck(x=expr_oneof(expr_int32, expr_int64)); def bit_not(x):; """"""Bitwise invert `x`. Examples; --------; >>> hl.eval(hl.bit_not(0)); -1. Notes; -----; See `the Python wiki <https://wiki.python.org/moin/BitwiseOperators>`__; for more information about bit operators. Parameters; ----------; x : :class:`.Int32Expression` or :class:`.Int",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:181576,Testability,log,logical,181576,"bit_lshift(1, 32)); 0. >>> hl.eval(hl.bit_lshift(hl.int64(1), 32)); 4294967296. >>> hl.eval(hl.bit_lshift(hl.int64(1), 64)); 0. Notes; -----; See `the Python wiki <https://wiki.python.org/moin/BitwiseOperators>`__; for more information about bit operators. Parameters; ----------; x : :class:`.Int32Expression` or :class:`.Int64Expression`; y : :class:`.Int32Expression` or :class:`.Int64Expression`. Returns; -------; :class:`.Int32Expression` or :class:`.Int64Expression`; """"""; return _shift_op(x, y, '<<'). [docs]@typecheck(x=expr_oneof(expr_int32, expr_int64), y=expr_int32, logical=builtins.bool); def bit_rshift(x, y, logical=False):; """"""Bitwise right-shift `x` by `y`. Examples; --------; >>> hl.eval(hl.bit_rshift(256, 3)); 32. With ``logical=False`` (default), the sign is preserved:. >>> hl.eval(hl.bit_rshift(-1, 1)); -1. With ``logical=True``, the sign bit is treated as any other:. >>> hl.eval(hl.bit_rshift(-1, 1, logical=True)); 2147483647. Notes; -----; If `logical` is ``False``, then the shift is a sign-preserving right shift.; If `logical` is ``True``, then the shift is logical, with the sign bit; treated as any other bit. See `the Python wiki <https://wiki.python.org/moin/BitwiseOperators>`__; for more information about bit operators. Parameters; ----------; x : :class:`.Int32Expression` or :class:`.Int64Expression`; y : :class:`.Int32Expression` or :class:`.Int64Expression`; logical : :obj:`bool`. Returns; -------; :class:`.Int32Expression` or :class:`.Int64Expression`; """"""; if logical:; return _shift_op(x, y, '>>>'); else:; return _shift_op(x, y, '>>'). [docs]@typecheck(x=expr_oneof(expr_int32, expr_int64)); def bit_not(x):; """"""Bitwise invert `x`. Examples; --------; >>> hl.eval(hl.bit_not(0)); -1. Notes; -----; See `the Python wiki <https://wiki.python.org/moin/BitwiseOperators>`__; for more information about bit operators. Parameters; ----------; x : :class:`.Int32Expression` or :class:`.Int64Expression`. Returns; -------; :class:`.Int32Expression` or :clas",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:181653,Testability,log,logical,181653,".bit_lshift(hl.int64(1), 64)); 0. Notes; -----; See `the Python wiki <https://wiki.python.org/moin/BitwiseOperators>`__; for more information about bit operators. Parameters; ----------; x : :class:`.Int32Expression` or :class:`.Int64Expression`; y : :class:`.Int32Expression` or :class:`.Int64Expression`. Returns; -------; :class:`.Int32Expression` or :class:`.Int64Expression`; """"""; return _shift_op(x, y, '<<'). [docs]@typecheck(x=expr_oneof(expr_int32, expr_int64), y=expr_int32, logical=builtins.bool); def bit_rshift(x, y, logical=False):; """"""Bitwise right-shift `x` by `y`. Examples; --------; >>> hl.eval(hl.bit_rshift(256, 3)); 32. With ``logical=False`` (default), the sign is preserved:. >>> hl.eval(hl.bit_rshift(-1, 1)); -1. With ``logical=True``, the sign bit is treated as any other:. >>> hl.eval(hl.bit_rshift(-1, 1, logical=True)); 2147483647. Notes; -----; If `logical` is ``False``, then the shift is a sign-preserving right shift.; If `logical` is ``True``, then the shift is logical, with the sign bit; treated as any other bit. See `the Python wiki <https://wiki.python.org/moin/BitwiseOperators>`__; for more information about bit operators. Parameters; ----------; x : :class:`.Int32Expression` or :class:`.Int64Expression`; y : :class:`.Int32Expression` or :class:`.Int64Expression`; logical : :obj:`bool`. Returns; -------; :class:`.Int32Expression` or :class:`.Int64Expression`; """"""; if logical:; return _shift_op(x, y, '>>>'); else:; return _shift_op(x, y, '>>'). [docs]@typecheck(x=expr_oneof(expr_int32, expr_int64)); def bit_not(x):; """"""Bitwise invert `x`. Examples; --------; >>> hl.eval(hl.bit_not(0)); -1. Notes; -----; See `the Python wiki <https://wiki.python.org/moin/BitwiseOperators>`__; for more information about bit operators. Parameters; ----------; x : :class:`.Int32Expression` or :class:`.Int64Expression`. Returns; -------; :class:`.Int32Expression` or :class:`.Int64Expression`; """"""; return construct_expr(ir.ApplyUnaryPrimOp('~', x._ir), x.dtype, x._i",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:181693,Testability,log,logical,181693,".bit_lshift(hl.int64(1), 64)); 0. Notes; -----; See `the Python wiki <https://wiki.python.org/moin/BitwiseOperators>`__; for more information about bit operators. Parameters; ----------; x : :class:`.Int32Expression` or :class:`.Int64Expression`; y : :class:`.Int32Expression` or :class:`.Int64Expression`. Returns; -------; :class:`.Int32Expression` or :class:`.Int64Expression`; """"""; return _shift_op(x, y, '<<'). [docs]@typecheck(x=expr_oneof(expr_int32, expr_int64), y=expr_int32, logical=builtins.bool); def bit_rshift(x, y, logical=False):; """"""Bitwise right-shift `x` by `y`. Examples; --------; >>> hl.eval(hl.bit_rshift(256, 3)); 32. With ``logical=False`` (default), the sign is preserved:. >>> hl.eval(hl.bit_rshift(-1, 1)); -1. With ``logical=True``, the sign bit is treated as any other:. >>> hl.eval(hl.bit_rshift(-1, 1, logical=True)); 2147483647. Notes; -----; If `logical` is ``False``, then the shift is a sign-preserving right shift.; If `logical` is ``True``, then the shift is logical, with the sign bit; treated as any other bit. See `the Python wiki <https://wiki.python.org/moin/BitwiseOperators>`__; for more information about bit operators. Parameters; ----------; x : :class:`.Int32Expression` or :class:`.Int64Expression`; y : :class:`.Int32Expression` or :class:`.Int64Expression`; logical : :obj:`bool`. Returns; -------; :class:`.Int32Expression` or :class:`.Int64Expression`; """"""; if logical:; return _shift_op(x, y, '>>>'); else:; return _shift_op(x, y, '>>'). [docs]@typecheck(x=expr_oneof(expr_int32, expr_int64)); def bit_not(x):; """"""Bitwise invert `x`. Examples; --------; >>> hl.eval(hl.bit_not(0)); -1. Notes; -----; See `the Python wiki <https://wiki.python.org/moin/BitwiseOperators>`__; for more information about bit operators. Parameters; ----------; x : :class:`.Int32Expression` or :class:`.Int64Expression`. Returns; -------; :class:`.Int32Expression` or :class:`.Int64Expression`; """"""; return construct_expr(ir.ApplyUnaryPrimOp('~', x._ir), x.dtype, x._i",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:182006,Testability,log,logical,182006,"ns; -------; :class:`.Int32Expression` or :class:`.Int64Expression`; """"""; return _shift_op(x, y, '<<'). [docs]@typecheck(x=expr_oneof(expr_int32, expr_int64), y=expr_int32, logical=builtins.bool); def bit_rshift(x, y, logical=False):; """"""Bitwise right-shift `x` by `y`. Examples; --------; >>> hl.eval(hl.bit_rshift(256, 3)); 32. With ``logical=False`` (default), the sign is preserved:. >>> hl.eval(hl.bit_rshift(-1, 1)); -1. With ``logical=True``, the sign bit is treated as any other:. >>> hl.eval(hl.bit_rshift(-1, 1, logical=True)); 2147483647. Notes; -----; If `logical` is ``False``, then the shift is a sign-preserving right shift.; If `logical` is ``True``, then the shift is logical, with the sign bit; treated as any other bit. See `the Python wiki <https://wiki.python.org/moin/BitwiseOperators>`__; for more information about bit operators. Parameters; ----------; x : :class:`.Int32Expression` or :class:`.Int64Expression`; y : :class:`.Int32Expression` or :class:`.Int64Expression`; logical : :obj:`bool`. Returns; -------; :class:`.Int32Expression` or :class:`.Int64Expression`; """"""; if logical:; return _shift_op(x, y, '>>>'); else:; return _shift_op(x, y, '>>'). [docs]@typecheck(x=expr_oneof(expr_int32, expr_int64)); def bit_not(x):; """"""Bitwise invert `x`. Examples; --------; >>> hl.eval(hl.bit_not(0)); -1. Notes; -----; See `the Python wiki <https://wiki.python.org/moin/BitwiseOperators>`__; for more information about bit operators. Parameters; ----------; x : :class:`.Int32Expression` or :class:`.Int64Expression`. Returns; -------; :class:`.Int32Expression` or :class:`.Int64Expression`; """"""; return construct_expr(ir.ApplyUnaryPrimOp('~', x._ir), x.dtype, x._indices, x._aggregations). [docs]@typecheck(x=expr_oneof(expr_int32, expr_int64)); def bit_count(x):; """"""Count the number of 1s in the in the `two's complement <https://en.wikipedia.org/wiki/Two%27s_complement>`__ binary representation of `x`. Examples; --------; The binary representation of `7` is `111`, so:. ",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:182111,Testability,log,logical,182111,"oneof(expr_int32, expr_int64), y=expr_int32, logical=builtins.bool); def bit_rshift(x, y, logical=False):; """"""Bitwise right-shift `x` by `y`. Examples; --------; >>> hl.eval(hl.bit_rshift(256, 3)); 32. With ``logical=False`` (default), the sign is preserved:. >>> hl.eval(hl.bit_rshift(-1, 1)); -1. With ``logical=True``, the sign bit is treated as any other:. >>> hl.eval(hl.bit_rshift(-1, 1, logical=True)); 2147483647. Notes; -----; If `logical` is ``False``, then the shift is a sign-preserving right shift.; If `logical` is ``True``, then the shift is logical, with the sign bit; treated as any other bit. See `the Python wiki <https://wiki.python.org/moin/BitwiseOperators>`__; for more information about bit operators. Parameters; ----------; x : :class:`.Int32Expression` or :class:`.Int64Expression`; y : :class:`.Int32Expression` or :class:`.Int64Expression`; logical : :obj:`bool`. Returns; -------; :class:`.Int32Expression` or :class:`.Int64Expression`; """"""; if logical:; return _shift_op(x, y, '>>>'); else:; return _shift_op(x, y, '>>'). [docs]@typecheck(x=expr_oneof(expr_int32, expr_int64)); def bit_not(x):; """"""Bitwise invert `x`. Examples; --------; >>> hl.eval(hl.bit_not(0)); -1. Notes; -----; See `the Python wiki <https://wiki.python.org/moin/BitwiseOperators>`__; for more information about bit operators. Parameters; ----------; x : :class:`.Int32Expression` or :class:`.Int64Expression`. Returns; -------; :class:`.Int32Expression` or :class:`.Int64Expression`; """"""; return construct_expr(ir.ApplyUnaryPrimOp('~', x._ir), x.dtype, x._indices, x._aggregations). [docs]@typecheck(x=expr_oneof(expr_int32, expr_int64)); def bit_count(x):; """"""Count the number of 1s in the in the `two's complement <https://en.wikipedia.org/wiki/Two%27s_complement>`__ binary representation of `x`. Examples; --------; The binary representation of `7` is `111`, so:. >>> hl.eval(hl.bit_count(7)); 3. Parameters; ----------; x : :class:`.Int32Expression` or :class:`.Int64Expression`. Returns; ---",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/functions.html:184956,Testability,assert,assert,184956,"lement in `array` not smaller; than `elem`. This is a value between 0 and the length of `array`, inclusive; (if all elements in `array` are smaller than `elem`, the returned value is; the length of `array` or the index of the first missing value, if one; exists). If either `elem` or `array` is missing, the result is missing. Examples; --------. >>> a = hl.array([0, 2, 4, 8]). >>> hl.eval(hl.binary_search(a, -1)); 0. >>> hl.eval(hl.binary_search(a, 1)); 1. >>> hl.eval(hl.binary_search(a, 10)); 4. """"""; c = coercer_from_dtype(array.dtype.element_type); if not c.can_coerce(elem.dtype):; raise TypeError(; f""'binary_search': cannot search an array of type {array.dtype} for a value of type {elem.dtype}""; ); elem = c.coerce(elem); return hl.switch(elem).when_missing(hl.missing(hl.tint32)).default(_lower_bound(array, elem)). @typecheck(s=expr_str); def _escape_string(s):; return _func(""escapeString"", hl.tstr, s). @typecheck(left=expr_any, right=expr_any, tolerance=expr_float64, absolute=expr_bool); def _values_similar(left, right, tolerance=1e-6, absolute=False):; assert left.dtype == right.dtype; return (is_missing(left) & is_missing(right)) | (; (is_defined(left) & is_defined(right)) & _func(""valuesSimilar"", hl.tbool, left, right, tolerance, absolute); ). @typecheck(coords=expr_array(expr_array(expr_float64)), radius=expr_float64); def _locus_windows_per_contig(coords, radius):; rt = hl.ttuple(hl.tarray(hl.tint32), hl.tarray(hl.tint32)); return _func(""locus_windows_per_contig"", rt, coords, radius). [docs]@typecheck(a=expr_array(), seed=nullable(builtins.int)); def shuffle(a, seed: Optional[builtins.int] = None) -> ArrayExpression:; """"""Randomly permute an array. Example; -------. >>> hl.reset_global_randomness(); >>> hl.eval(hl.shuffle(hl.range(5))); [4, 0, 2, 1, 3]. Parameters; ----------; a : :class:`.ArrayExpression`; Array to permute.; seed : :obj:`int`, optional; Random seed. Returns; -------; :class:`.ArrayExpression`; """"""; return sorted(a, key=lambda _: hl.rand_unif(0",MatchSource.WIKI,docs/0.2/_modules/hail/expr/functions.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/functions.html
https://hail.is/docs/0.2/_modules/hail/expr/types.html:34727,Deployability,update,update,34727,"ich_missing_bit = i % 8; if which_missing_bit == 0:; current_missing_byte = missing_bytes[i // 8]. if lookup_bit(current_missing_byte, which_missing_bit):; kwargs[f] = None; else:; field_decoded = t._convert_from_encoding(byte_reader, _should_freeze); kwargs[f] = field_decoded. return Struct(**kwargs). def _convert_to_encoding(self, byte_writer: ByteWriter, value):; keys = list(self.keys()); length = len(keys); i = 0; while i < length:; missing_byte = 0; for j in range(min(8, length - i)):; if HailType._missing(value[keys[i + j]]):; missing_byte |= 1 << j; byte_writer.write_byte(missing_byte); i += 8. for f, t in self.items():; if not HailType._missing(value[f]):; t._convert_to_encoding(byte_writer, value[f]). def _is_prefix_of(self, other):; return (; isinstance(other, tstruct); and len(self._fields) <= len(other._fields); and all(x == y for x, y in zip(self._field_types.values(), other._field_types.values())); ). def _concat(self, other):; new_field_types = {}; new_field_types.update(self._field_types); new_field_types.update(other._field_types); return tstruct(**new_field_types). def _insert(self, path, t):; if not path:; return t. key = path[0]; keyt = self.get(key); if not (keyt and isinstance(keyt, tstruct)):; keyt = tstruct(); return self._insert_fields(**{key: keyt._insert(path[1:], t)}). def _insert_field(self, field, typ):; return self._insert_fields(**{field: typ}). def _insert_fields(self, **new_fields):; new_field_types = {}; new_field_types.update(self._field_types); new_field_types.update(new_fields); return tstruct(**new_field_types). def _drop_fields(self, fields):; return tstruct(**{f: t for f, t in self.items() if f not in fields}). def _select_fields(self, fields):; return tstruct(**{f: self[f] for f in fields}). def _index_path(self, path):; t = self; for p in path:; t = t[p]; return t. def _rename(self, map):; seen = {}; new_field_types = {}. for f0, t in self.items():; f = map.get(f0, f0); if f in seen:; raise ValueError(; ""Cannot rename two f",MatchSource.WIKI,docs/0.2/_modules/hail/expr/types.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html
https://hail.is/docs/0.2/_modules/hail/expr/types.html:34770,Deployability,update,update,34770,"it == 0:; current_missing_byte = missing_bytes[i // 8]. if lookup_bit(current_missing_byte, which_missing_bit):; kwargs[f] = None; else:; field_decoded = t._convert_from_encoding(byte_reader, _should_freeze); kwargs[f] = field_decoded. return Struct(**kwargs). def _convert_to_encoding(self, byte_writer: ByteWriter, value):; keys = list(self.keys()); length = len(keys); i = 0; while i < length:; missing_byte = 0; for j in range(min(8, length - i)):; if HailType._missing(value[keys[i + j]]):; missing_byte |= 1 << j; byte_writer.write_byte(missing_byte); i += 8. for f, t in self.items():; if not HailType._missing(value[f]):; t._convert_to_encoding(byte_writer, value[f]). def _is_prefix_of(self, other):; return (; isinstance(other, tstruct); and len(self._fields) <= len(other._fields); and all(x == y for x, y in zip(self._field_types.values(), other._field_types.values())); ). def _concat(self, other):; new_field_types = {}; new_field_types.update(self._field_types); new_field_types.update(other._field_types); return tstruct(**new_field_types). def _insert(self, path, t):; if not path:; return t. key = path[0]; keyt = self.get(key); if not (keyt and isinstance(keyt, tstruct)):; keyt = tstruct(); return self._insert_fields(**{key: keyt._insert(path[1:], t)}). def _insert_field(self, field, typ):; return self._insert_fields(**{field: typ}). def _insert_fields(self, **new_fields):; new_field_types = {}; new_field_types.update(self._field_types); new_field_types.update(new_fields); return tstruct(**new_field_types). def _drop_fields(self, fields):; return tstruct(**{f: t for f, t in self.items() if f not in fields}). def _select_fields(self, fields):; return tstruct(**{f: self[f] for f in fields}). def _index_path(self, path):; t = self; for p in path:; t = t[p]; return t. def _rename(self, map):; seen = {}; new_field_types = {}. for f0, t in self.items():; f = map.get(f0, f0); if f in seen:; raise ValueError(; ""Cannot rename two fields to the same name: attempted to rename ",MatchSource.WIKI,docs/0.2/_modules/hail/expr/types.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html
https://hail.is/docs/0.2/_modules/hail/expr/types.html:35212,Deployability,update,update,35212,"th - i)):; if HailType._missing(value[keys[i + j]]):; missing_byte |= 1 << j; byte_writer.write_byte(missing_byte); i += 8. for f, t in self.items():; if not HailType._missing(value[f]):; t._convert_to_encoding(byte_writer, value[f]). def _is_prefix_of(self, other):; return (; isinstance(other, tstruct); and len(self._fields) <= len(other._fields); and all(x == y for x, y in zip(self._field_types.values(), other._field_types.values())); ). def _concat(self, other):; new_field_types = {}; new_field_types.update(self._field_types); new_field_types.update(other._field_types); return tstruct(**new_field_types). def _insert(self, path, t):; if not path:; return t. key = path[0]; keyt = self.get(key); if not (keyt and isinstance(keyt, tstruct)):; keyt = tstruct(); return self._insert_fields(**{key: keyt._insert(path[1:], t)}). def _insert_field(self, field, typ):; return self._insert_fields(**{field: typ}). def _insert_fields(self, **new_fields):; new_field_types = {}; new_field_types.update(self._field_types); new_field_types.update(new_fields); return tstruct(**new_field_types). def _drop_fields(self, fields):; return tstruct(**{f: t for f, t in self.items() if f not in fields}). def _select_fields(self, fields):; return tstruct(**{f: self[f] for f in fields}). def _index_path(self, path):; t = self; for p in path:; t = t[p]; return t. def _rename(self, map):; seen = {}; new_field_types = {}. for f0, t in self.items():; f = map.get(f0, f0); if f in seen:; raise ValueError(; ""Cannot rename two fields to the same name: attempted to rename {} and {} both to {}"".format(; repr(seen[f]), repr(f0), repr(f); ); ); else:; seen[f] = f0; new_field_types[f] = t. return tstruct(**new_field_types). def unify(self, t):; if not (isinstance(t, tstruct) and len(self) == len(t)):; return False; for (f1, t1), (f2, t2) in zip(self.items(), t.items()):; if not (f1 == f2 and t1.unify(t2)):; return False; return True. def subst(self):; return tstruct(**{f: t.subst() for f, t in self.items()}).",MatchSource.WIKI,docs/0.2/_modules/hail/expr/types.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html
https://hail.is/docs/0.2/_modules/hail/expr/types.html:35255,Deployability,update,update,35255,"te |= 1 << j; byte_writer.write_byte(missing_byte); i += 8. for f, t in self.items():; if not HailType._missing(value[f]):; t._convert_to_encoding(byte_writer, value[f]). def _is_prefix_of(self, other):; return (; isinstance(other, tstruct); and len(self._fields) <= len(other._fields); and all(x == y for x, y in zip(self._field_types.values(), other._field_types.values())); ). def _concat(self, other):; new_field_types = {}; new_field_types.update(self._field_types); new_field_types.update(other._field_types); return tstruct(**new_field_types). def _insert(self, path, t):; if not path:; return t. key = path[0]; keyt = self.get(key); if not (keyt and isinstance(keyt, tstruct)):; keyt = tstruct(); return self._insert_fields(**{key: keyt._insert(path[1:], t)}). def _insert_field(self, field, typ):; return self._insert_fields(**{field: typ}). def _insert_fields(self, **new_fields):; new_field_types = {}; new_field_types.update(self._field_types); new_field_types.update(new_fields); return tstruct(**new_field_types). def _drop_fields(self, fields):; return tstruct(**{f: t for f, t in self.items() if f not in fields}). def _select_fields(self, fields):; return tstruct(**{f: self[f] for f in fields}). def _index_path(self, path):; t = self; for p in path:; t = t[p]; return t. def _rename(self, map):; seen = {}; new_field_types = {}. for f0, t in self.items():; f = map.get(f0, f0); if f in seen:; raise ValueError(; ""Cannot rename two fields to the same name: attempted to rename {} and {} both to {}"".format(; repr(seen[f]), repr(f0), repr(f); ); ); else:; seen[f] = f0; new_field_types[f] = t. return tstruct(**new_field_types). def unify(self, t):; if not (isinstance(t, tstruct) and len(self) == len(t)):; return False; for (f1, t1), (f2, t2) in zip(self.items(), t.items()):; if not (f1 == f2 and t1.unify(t2)):; return False; return True. def subst(self):; return tstruct(**{f: t.subst() for f, t in self.items()}). def clear(self):; for f, t in self.items():; t.clear(). def _ge",MatchSource.WIKI,docs/0.2/_modules/hail/expr/types.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html
https://hail.is/docs/0.2/_modules/hail/expr/types.html:56984,Deployability,patch,patch,56984,"np_dtype} could not be converted to a hail type.""). def dtypes_from_pandas(pd_dtype):; if type(pd_dtype) == pd.StringDtype:; return hl.tstr; elif pd_dtype == np.int64:; return hl.tint64; elif pd_dtype == np.uint64:; # Hail does *not* support unsigned integers but the next condition,; # pd.api.types.is_integer_dtype(pd_dtype) would return true on unsigned 64-bit ints; return None; # For some reason pandas doesn't have `is_int32_dtype`, so we use `is_integer_dtype` if first branch failed.; elif pd.api.types.is_integer_dtype(pd_dtype):; return hl.tint32; elif pd_dtype == np.float32:; return hl.tfloat32; elif pd_dtype == np.float64:; return hl.tfloat64; elif pd_dtype == bool:; return hl.tbool; return None. class tvariable(HailType):; _cond_map: ClassVar = {; 'numeric': is_numeric,; 'int32': lambda x: x == tint32,; 'int64': lambda x: x == tint64,; 'float32': lambda x: x == tfloat32,; 'float64': lambda x: x == tfloat64,; 'locus': lambda x: isinstance(x, tlocus),; 'struct': lambda x: isinstance(x, tstruct),; 'union': lambda x: isinstance(x, tunion),; 'tuple': lambda x: isinstance(x, ttuple),; }. def __init__(self, name, cond):; self.name = name; self.cond = cond; self.condf = tvariable._cond_map[cond] if cond else None; self.box = Box.from_name(name). def unify(self, t):; if self.condf and not self.condf(t):; return False; return self.box.unify(t). def clear(self):; self.box.clear(). def subst(self):; return self.box.get(). def __str__(self):; s = '?' + self.name; if self.cond:; s = s + ':' + self.cond; return s. _old_printer = pprint.PrettyPrinter. class TypePrettyPrinter(pprint.PrettyPrinter):; def _format(self, object, stream, indent, allowance, context, level):; if isinstance(object, HailType):; stream.write(object.pretty(self._indent_per_level)); else:; return _old_printer._format(self, object, stream, indent, allowance, context, level). pprint.PrettyPrinter = TypePrettyPrinter # monkey-patch pprint. © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,docs/0.2/_modules/hail/expr/types.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html
https://hail.is/docs/0.2/_modules/hail/expr/types.html:57038,Deployability,update,updated,57038,"np_dtype} could not be converted to a hail type.""). def dtypes_from_pandas(pd_dtype):; if type(pd_dtype) == pd.StringDtype:; return hl.tstr; elif pd_dtype == np.int64:; return hl.tint64; elif pd_dtype == np.uint64:; # Hail does *not* support unsigned integers but the next condition,; # pd.api.types.is_integer_dtype(pd_dtype) would return true on unsigned 64-bit ints; return None; # For some reason pandas doesn't have `is_int32_dtype`, so we use `is_integer_dtype` if first branch failed.; elif pd.api.types.is_integer_dtype(pd_dtype):; return hl.tint32; elif pd_dtype == np.float32:; return hl.tfloat32; elif pd_dtype == np.float64:; return hl.tfloat64; elif pd_dtype == bool:; return hl.tbool; return None. class tvariable(HailType):; _cond_map: ClassVar = {; 'numeric': is_numeric,; 'int32': lambda x: x == tint32,; 'int64': lambda x: x == tint64,; 'float32': lambda x: x == tfloat32,; 'float64': lambda x: x == tfloat64,; 'locus': lambda x: isinstance(x, tlocus),; 'struct': lambda x: isinstance(x, tstruct),; 'union': lambda x: isinstance(x, tunion),; 'tuple': lambda x: isinstance(x, ttuple),; }. def __init__(self, name, cond):; self.name = name; self.cond = cond; self.condf = tvariable._cond_map[cond] if cond else None; self.box = Box.from_name(name). def unify(self, t):; if self.condf and not self.condf(t):; return False; return self.box.unify(t). def clear(self):; self.box.clear(). def subst(self):; return self.box.get(). def __str__(self):; s = '?' + self.name; if self.cond:; s = s + ':' + self.cond; return s. _old_printer = pprint.PrettyPrinter. class TypePrettyPrinter(pprint.PrettyPrinter):; def _format(self, object, stream, indent, allowance, context, level):; if isinstance(object, HailType):; stream.write(object.pretty(self._indent_per_level)); else:; return _old_printer._format(self, object, stream, indent, allowance, context, level). pprint.PrettyPrinter = TypePrettyPrinter # monkey-patch pprint. © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,docs/0.2/_modules/hail/expr/types.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html
https://hail.is/docs/0.2/_modules/hail/expr/types.html:28604,Integrability,wrap,wrapper,28604,"eturn isinstance(other, tdict) and self.key_type == other.key_type and self.value_type == other.value_type. def _pretty(self, b, indent, increment):; b.append('dict<'); self.key_type._pretty(b, indent, increment); b.append(', '); self.value_type._pretty(b, indent, increment); b.append('>'). def _parsable_string(self):; return ""Dict[{},{}]"".format(self.key_type._parsable_string(), self.value_type._parsable_string()). def _convert_from_json(self, x, _should_freeze: bool = False) -> Union[dict, frozendict]:; d = {; self.key_type._convert_from_json_na(elt['key'], _should_freeze=True): self.value_type._convert_from_json_na(; elt['value'], _should_freeze=_should_freeze; ); for elt in x; }; if _should_freeze:; return frozendict(d); return d. def _convert_to_json(self, x):; return [; {'key': self.key_type._convert_to_json(k), 'value': self.value_type._convert_to_json(v)}; for k, v in x.items(); ]. def _convert_from_encoding(self, byte_reader, _should_freeze: bool = False) -> Union[dict, frozendict]:; # NB: We ensure the key is always frozen with a wrapper on the key_type in the _array_repr.; d = {}; length = byte_reader.read_int32(); for _ in range(length):; element = self._array_repr.element_type._convert_from_encoding(byte_reader, _should_freeze); d[element.key] = element.value. if _should_freeze:; return frozendict(d); return d. def _convert_to_encoding(self, byte_writer: ByteWriter, value):; length = len(value); byte_writer.write_int32(length); for k, v in value.items():; self._array_repr.element_type._convert_to_encoding(byte_writer, {'key': k, 'value': v}). def _propagate_jtypes(self, jtype):; self._key_type._add_jtype(jtype.keyType()); self._value_type._add_jtype(jtype.valueType()). def unify(self, t):; return isinstance(t, tdict) and self.key_type.unify(t.key_type) and self.value_type.unify(t.value_type). def subst(self):; return tdict(self._key_type.subst(), self._value_type.subst()). def clear(self):; self.key_type.clear(); self.value_type.clear(). def _get_context",MatchSource.WIKI,docs/0.2/_modules/hail/expr/types.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html
https://hail.is/docs/0.2/_modules/hail/expr/types.html:14412,Modifiability,parameteriz,parameterized,14412,"_tbool). def _parsable_string(self):; return ""Boolean"". def unify(self, t):; return t == tbool. def subst(self):; return self. def clear(self):; pass. def to_numpy(self):; return bool. def _byte_size(self):; return 1. def _convert_from_encoding(self, byte_reader, _should_freeze: bool = False) -> bool:; return byte_reader.read_bool(). def _convert_to_encoding(self, byte_writer: ByteWriter, value):; byte_writer.write_bool(value). class _trngstate(HailType):; def __init__(self):; super(_trngstate, self).__init__(). def __str__(self):; return ""rng_state"". def _eq(self, other):; return isinstance(other, _trngstate). def _parsable_string(self):; return ""RNGState"". def unify(self, t):; return t == trngstate. def subst(self):; return self. def clear(self):; pass. [docs]class tndarray(HailType):; """"""Hail type for n-dimensional arrays. .. include:: _templates/experimental.rst. In Python, these are represented as NumPy :obj:`numpy.ndarray`. Notes; -----. NDArrays contain elements of only one type, which is parameterized by; `element_type`. Parameters; ----------; element_type : :class:`.HailType`; Element type of array.; ndim : int32; Number of dimensions. See Also; --------; :class:`.NDArrayExpression`, :obj:`.nd.array`; """""". @typecheck_method(element_type=hail_type, ndim=oneof(NatBase, int)); def __init__(self, element_type, ndim):; self._element_type = element_type; self._ndim = NatLiteral(ndim) if isinstance(ndim, int) else ndim; super(tndarray, self).__init__(). @property; def element_type(self):; """"""NDArray element type. Returns; -------; :class:`.HailType`; Element type.; """"""; return self._element_type. @property; def ndim(self):; """"""NDArray number of dimensions. Returns; -------; :obj:`int`; Number of dimensions.; """"""; assert isinstance(self._ndim, NatLiteral), ""tndarray must be realized with a concrete number of dimensions""; return self._ndim.n. def _traverse(self, obj, f):; if f(self, obj):; for elt in np.nditer(obj, ['zerosize_ok']):; self.element_type._traverse(elt.",MatchSource.WIKI,docs/0.2/_modules/hail/expr/types.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html
https://hail.is/docs/0.2/_modules/hail/expr/types.html:18290,Modifiability,variab,variable-length,18290,"ndim)]; total_num_elements = np.product(shape, dtype=np.int64). if self.element_type in _numeric_types:; element_byte_size = self.element_type._byte_size; bytes_to_read = element_byte_size * total_num_elements; buffer = byte_reader.read_bytes_view(bytes_to_read); return np.frombuffer(buffer, self.element_type.to_numpy, count=total_num_elements).reshape(shape); else:; elements = [; self.element_type._convert_from_encoding(byte_reader, _should_freeze) for i in range(total_num_elements); ]; np_type = self.element_type.to_numpy(); return np.ndarray(shape=shape, buffer=np.array(elements, dtype=np_type), dtype=np_type, order=""F""). def _convert_to_encoding(self, byte_writer, value: np.ndarray):; for dim in value.shape:; byte_writer.write_int64(dim). if value.size > 0:; if self.element_type in _numeric_types:; byte_writer.write_bytes(value.data); else:; for elem in np.nditer(value, order='F'):; self.element_type._convert_to_encoding(byte_writer, elem). [docs]class tarray(HailType):; """"""Hail type for variable-length arrays of elements. In Python, these are represented as :obj:`list`. Notes; -----; Arrays contain elements of only one type, which is parameterized by; `element_type`. Parameters; ----------; element_type : :class:`.HailType`; Element type of array. See Also; --------; :class:`.ArrayExpression`, :class:`.CollectionExpression`,; :func:`~hail.expr.functions.array`, :ref:`sec-collection-functions`; """""". @typecheck_method(element_type=hail_type); def __init__(self, element_type):; self._element_type = element_type; super(tarray, self).__init__(). @property; def element_type(self):; """"""Array element type. Returns; -------; :class:`.HailType`; Element type.; """"""; return self._element_type. def _traverse(self, obj, f):; if f(self, obj):; for elt in obj:; self.element_type._traverse(elt, f). def _typecheck_one_level(self, annotation):; if annotation is not None:; if not isinstance(annotation, Sequence):; raise TypeError(""type 'array' expected Python 'list', but found typ",MatchSource.WIKI,docs/0.2/_modules/hail/expr/types.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html
https://hail.is/docs/0.2/_modules/hail/expr/types.html:18440,Modifiability,parameteriz,parameterized,18440,"pe._byte_size; bytes_to_read = element_byte_size * total_num_elements; buffer = byte_reader.read_bytes_view(bytes_to_read); return np.frombuffer(buffer, self.element_type.to_numpy, count=total_num_elements).reshape(shape); else:; elements = [; self.element_type._convert_from_encoding(byte_reader, _should_freeze) for i in range(total_num_elements); ]; np_type = self.element_type.to_numpy(); return np.ndarray(shape=shape, buffer=np.array(elements, dtype=np_type), dtype=np_type, order=""F""). def _convert_to_encoding(self, byte_writer, value: np.ndarray):; for dim in value.shape:; byte_writer.write_int64(dim). if value.size > 0:; if self.element_type in _numeric_types:; byte_writer.write_bytes(value.data); else:; for elem in np.nditer(value, order='F'):; self.element_type._convert_to_encoding(byte_writer, elem). [docs]class tarray(HailType):; """"""Hail type for variable-length arrays of elements. In Python, these are represented as :obj:`list`. Notes; -----; Arrays contain elements of only one type, which is parameterized by; `element_type`. Parameters; ----------; element_type : :class:`.HailType`; Element type of array. See Also; --------; :class:`.ArrayExpression`, :class:`.CollectionExpression`,; :func:`~hail.expr.functions.array`, :ref:`sec-collection-functions`; """""". @typecheck_method(element_type=hail_type); def __init__(self, element_type):; self._element_type = element_type; super(tarray, self).__init__(). @property; def element_type(self):; """"""Array element type. Returns; -------; :class:`.HailType`; Element type.; """"""; return self._element_type. def _traverse(self, obj, f):; if f(self, obj):; for elt in obj:; self.element_type._traverse(elt, f). def _typecheck_one_level(self, annotation):; if annotation is not None:; if not isinstance(annotation, Sequence):; raise TypeError(""type 'array' expected Python 'list', but found type '%s'"" % type(annotation)). def __str__(self):; return ""array<{}>"".format(self.element_type). def _eq(self, other):; return isinstance(other",MatchSource.WIKI,docs/0.2/_modules/hail/expr/types.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html
https://hail.is/docs/0.2/_modules/hail/expr/types.html:23288,Modifiability,parameteriz,parameterized,23288,"urn ""Stream["" + self.element_type._parsable_string() + ""]"". def _convert_from_json(self, x, _should_freeze: bool = False) -> Union[list, frozenlist]:; ls = [self.element_type._convert_from_json_na(elt, _should_freeze) for elt in x]; if _should_freeze:; return frozenlist(ls); return ls. def _convert_to_json(self, x):; return [self.element_type._convert_to_json_na(elt) for elt in x]. def _propagate_jtypes(self, jtype):; self._element_type._add_jtype(jtype.elementType()). def unify(self, t):; return isinstance(t, tstream) and self.element_type.unify(t.element_type). def subst(self):; return tstream(self.element_type.subst()). def clear(self):; self.element_type.clear(). def _get_context(self):; return self.element_type.get_context(). def is_setlike(maybe_setlike):; return isinstance(maybe_setlike, (set, frozenset)). [docs]class tset(HailType):; """"""Hail type for collections of distinct elements. In Python, these are represented as :obj:`set`. Notes; -----; Sets contain elements of only one type, which is parameterized by; `element_type`. Parameters; ----------; element_type : :class:`.HailType`; Element type of set. See Also; --------; :class:`.SetExpression`, :class:`.CollectionExpression`,; :func:`.set`, :ref:`sec-collection-functions`; """""". @typecheck_method(element_type=hail_type); def __init__(self, element_type):; self._element_type = element_type; self._array_repr = tarray(element_type); super(tset, self).__init__(). @property; def element_type(self):; """"""Set element type. Returns; -------; :class:`.HailType`; Element type.; """"""; return self._element_type. def _traverse(self, obj, f):; if f(self, obj):; for elt in obj:; self.element_type._traverse(elt, f). def _typecheck_one_level(self, annotation):; if annotation is not None:; if not is_setlike(annotation):; raise TypeError(""type 'set' expected Python 'set', but found type '%s'"" % type(annotation)). def __str__(self):; return ""set<{}>"".format(self.element_type). def _eq(self, other):; return isinstance(other, tse",MatchSource.WIKI,docs/0.2/_modules/hail/expr/types.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html
https://hail.is/docs/0.2/_modules/hail/expr/types.html:26159,Modifiability,parameteriz,parameterize,26159,"ncoding(byte_writer, list(value)). def _propagate_jtypes(self, jtype):; self._element_type._add_jtype(jtype.elementType()). def unify(self, t):; return isinstance(t, tset) and self.element_type.unify(t.element_type). def subst(self):; return tset(self.element_type.subst()). def clear(self):; self.element_type.clear(). def _get_context(self):; return self.element_type.get_context(). class _freeze_this_type(HailType):; def __init__(self, t):; self.t = t. def _convert_from_json_na(self, x, _should_freeze: bool = False):; return self.t._convert_from_json_na(x, _should_freeze=True). def _convert_from_encoding(self, byte_reader, _should_freeze: bool = False):; return self.t._convert_from_encoding(byte_reader, _should_freeze=True). def _convert_to_encoding(self, byte_writer, x):; return self.t._convert_to_encoding(byte_writer, x). [docs]class tdict(HailType):; """"""Hail type for key-value maps. In Python, these are represented as :obj:`dict`. Notes; -----; Dicts parameterize the type of both their keys and values with; `key_type` and `value_type`. Parameters; ----------; key_type: :class:`.HailType`; Key type.; value_type: :class:`.HailType`; Value type. See Also; --------; :class:`.DictExpression`, :func:`.dict`, :ref:`sec-collection-functions`; """""". @typecheck_method(key_type=hail_type, value_type=hail_type); def __init__(self, key_type, value_type):; self._key_type = key_type; self._value_type = value_type; self._array_repr = tarray(tstruct(key=_freeze_this_type(key_type), value=value_type)); super(tdict, self).__init__(). @property; def key_type(self):; """"""Dict key type. Returns; -------; :class:`.HailType`; Key type.; """"""; return self._key_type. @property; def value_type(self):; """"""Dict value type. Returns; -------; :class:`.HailType`; Value type.; """"""; return self._value_type. @property; def element_type(self):; return tstruct(key=self._key_type, value=self._value_type). def _traverse(self, obj, f):; if f(self, obj):; for k, v in obj.items():; self.key_type._traverse(k,",MatchSource.WIKI,docs/0.2/_modules/hail/expr/types.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html
https://hail.is/docs/0.2/_modules/hail/expr/types.html:5224,Performance,load,loads,5224,"formatted string representation of the type. Parameters; ----------; indent : :obj:`int`; Spaces to indent. Returns; -------; :class:`str`; """"""; b = []; b.append(' ' * indent); self._pretty(b, indent, increment); return ''.join(b). def _pretty(self, b, indent, increment):; b.append(str(self)). @abc.abstractmethod; def _parsable_string(self) -> str:; raise NotImplementedError. def typecheck(self, value):; """"""Check that `value` matches a type. Parameters; ----------; value; Value to check. Raises; ------; :obj:`TypeError`; """""". def check(t, obj):; t._typecheck_one_level(obj); return True. self._traverse(value, check). @abc.abstractmethod; def _typecheck_one_level(self, annotation):; raise NotImplementedError. def _to_json(self, x):; converted = self._convert_to_json_na(x); return json.dumps(converted). def _convert_to_json_na(self, x):; if x is None:; return x; else:; return self._convert_to_json(x). def _convert_to_json(self, x):; return x. def _from_json(self, s):; x = json.loads(s); return self._convert_from_json_na(x). def _convert_from_json_na(self, x, _should_freeze: bool = False):; if x is None:; return x; else:; return self._convert_from_json(x, _should_freeze). def _convert_from_json(self, x, _should_freeze: bool = False):; return x. def _from_encoding(self, encoding):; return self._convert_from_encoding(ByteReader(memoryview(encoding))). def _to_encoding(self, value) -> bytes:; buf = bytearray(); self._convert_to_encoding(ByteWriter(buf), value); return bytes(buf). def _convert_from_encoding(self, byte_reader, _should_freeze: bool = False):; raise ValueError(""Not implemented yet""). def _convert_to_encoding(self, byte_writer, value):; raise ValueError(""Not implemented yet""). @staticmethod; def _missing(value):; return value is None or value is pd.NA. def _traverse(self, obj, f):; """"""Traverse a nested type and object. Parameters; ----------; obj : Any; f : Callable[[HailType, Any], bool]; Function to evaluate on the type and object. Traverse children if; the f",MatchSource.WIKI,docs/0.2/_modules/hail/expr/types.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html
https://hail.is/docs/0.2/_modules/hail/expr/types.html:4154,Security,hash,hash,4154,"ferences) == 0. def _to_json_context(self):; if self._json is None:; self._json = {'reference_genomes': {r: hl.get_reference(r)._config for r in self.references}}; return self._json. @classmethod; def union(cls, *types):; ctxs = [t.get_context() for t in types if not t.get_context().is_empty]; if len(ctxs) == 0:; return _empty_context; if len(ctxs) == 1:; return ctxs[0]; refs = ctxs[0].references.union(*[ctx.references for ctx in ctxs[1:]]); return HailTypeContext(refs). _empty_context = HailTypeContext(). [docs]class HailType(object):; """"""; Hail type superclass.; """""". def __init__(self):; super(HailType, self).__init__(); self._context = None. def __repr__(self):; s = str(self).replace(""'"", ""\\'""); return ""dtype('{}')"".format(s). @abc.abstractmethod; def _eq(self, other):; raise NotImplementedError. def __eq__(self, other):; return isinstance(other, HailType) and self._eq(other). @abc.abstractmethod; def __str__(self):; raise NotImplementedError. def __hash__(self):; # FIXME this is a bit weird; return 43 + hash(str(self)). def pretty(self, indent=0, increment=4):; """"""Returns a prettily formatted string representation of the type. Parameters; ----------; indent : :obj:`int`; Spaces to indent. Returns; -------; :class:`str`; """"""; b = []; b.append(' ' * indent); self._pretty(b, indent, increment); return ''.join(b). def _pretty(self, b, indent, increment):; b.append(str(self)). @abc.abstractmethod; def _parsable_string(self) -> str:; raise NotImplementedError. def typecheck(self, value):; """"""Check that `value` matches a type. Parameters; ----------; value; Value to check. Raises; ------; :obj:`TypeError`; """""". def check(t, obj):; t._typecheck_one_level(obj); return True. self._traverse(value, check). @abc.abstractmethod; def _typecheck_one_level(self, annotation):; raise NotImplementedError. def _to_json(self, x):; converted = self._convert_to_json_na(x); return json.dumps(converted). def _convert_to_json_na(self, x):; if x is None:; return x; else:; return self._conv",MatchSource.WIKI,docs/0.2/_modules/hail/expr/types.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html
https://hail.is/docs/0.2/_modules/hail/expr/types.html:15147,Testability,assert,assert,15147,"lf):; pass. [docs]class tndarray(HailType):; """"""Hail type for n-dimensional arrays. .. include:: _templates/experimental.rst. In Python, these are represented as NumPy :obj:`numpy.ndarray`. Notes; -----. NDArrays contain elements of only one type, which is parameterized by; `element_type`. Parameters; ----------; element_type : :class:`.HailType`; Element type of array.; ndim : int32; Number of dimensions. See Also; --------; :class:`.NDArrayExpression`, :obj:`.nd.array`; """""". @typecheck_method(element_type=hail_type, ndim=oneof(NatBase, int)); def __init__(self, element_type, ndim):; self._element_type = element_type; self._ndim = NatLiteral(ndim) if isinstance(ndim, int) else ndim; super(tndarray, self).__init__(). @property; def element_type(self):; """"""NDArray element type. Returns; -------; :class:`.HailType`; Element type.; """"""; return self._element_type. @property; def ndim(self):; """"""NDArray number of dimensions. Returns; -------; :obj:`int`; Number of dimensions.; """"""; assert isinstance(self._ndim, NatLiteral), ""tndarray must be realized with a concrete number of dimensions""; return self._ndim.n. def _traverse(self, obj, f):; if f(self, obj):; for elt in np.nditer(obj, ['zerosize_ok']):; self.element_type._traverse(elt.item(), f). def _typecheck_one_level(self, annotation):; if annotation is not None and not isinstance(annotation, np.ndarray):; raise TypeError(""type 'ndarray' expected Python 'numpy.ndarray', but found type '%s'"" % type(annotation)). def __str__(self):; return ""ndarray<{}, {}>"".format(self.element_type, self.ndim). def _eq(self, other):; return isinstance(other, tndarray) and self.element_type == other.element_type and self.ndim == other.ndim. def _pretty(self, b, indent, increment):; b.append('ndarray<'); self._element_type._pretty(b, indent, increment); b.append(', '); b.append(str(self.ndim)); b.append('>'). def _parsable_string(self):; return f'NDArray[{self._element_type._parsable_string()},{self.ndim}]'. def _convert_from_json(self, x, ",MatchSource.WIKI,docs/0.2/_modules/hail/expr/types.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html
https://hail.is/docs/0.2/_modules/hail/expr/types.html:41865,Testability,assert,assert,41865,"ng_byte, which_missing_bit):; answer.append(None); else:; field_decoded = t._convert_from_encoding(byte_reader, _should_freeze); answer.append(field_decoded). return tuple(answer). def _convert_to_encoding(self, byte_writer, value):; length = len(self); i = 0; while i < length:; missing_byte = 0; for j in range(min(8, length - i)):; if HailType._missing(value[i + j]):; missing_byte |= 1 << j; byte_writer.write_byte(missing_byte); i += 8; for i, t in enumerate(self.types):; if not HailType._missing(value[i]):; t._convert_to_encoding(byte_writer, value[i]). def unify(self, t):; if not (isinstance(t, ttuple) and len(self.types) == len(t.types)):; return False; for t1, t2 in zip(self.types, t.types):; if not t1.unify(t2):; return False; return True. def subst(self):; return ttuple(*[t.subst() for t in self.types]). def clear(self):; for t in self.types:; t.clear(). def _get_context(self):; return HailTypeContext.union(*self.types). def allele_pair(j: int, k: int):; assert j >= 0 and j <= 0xFFFF; assert k >= 0 and k <= 0xFFFF; return j | (k << 16). def allele_pair_sqrt(i):; k = int(math.sqrt(8 * float(i) + 1) / 2 - 0.5); assert k * (k + 1) // 2 <= i; j = i - k * (k + 1) // 2; # TODO another assert; return allele_pair(j, k). small_allele_pair = [; allele_pair(0, 0),; allele_pair(0, 1),; allele_pair(1, 1),; allele_pair(0, 2),; allele_pair(1, 2),; allele_pair(2, 2),; allele_pair(0, 3),; allele_pair(1, 3),; allele_pair(2, 3),; allele_pair(3, 3),; allele_pair(0, 4),; allele_pair(1, 4),; allele_pair(2, 4),; allele_pair(3, 4),; allele_pair(4, 4),; allele_pair(0, 5),; allele_pair(1, 5),; allele_pair(2, 5),; allele_pair(3, 5),; allele_pair(4, 5),; allele_pair(5, 5),; allele_pair(0, 6),; allele_pair(1, 6),; allele_pair(2, 6),; allele_pair(3, 6),; allele_pair(4, 6),; allele_pair(5, 6),; allele_pair(6, 6),; allele_pair(0, 7),; allele_pair(1, 7),; allele_pair(2, 7),; allele_pair(3, 7),; allele_pair(4, 7),; allele_pair(5, 7),; allele_pair(6, 7),; allele_pair(7, 7),; ]. class _tcall(Ha",MatchSource.WIKI,docs/0.2/_modules/hail/expr/types.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html
https://hail.is/docs/0.2/_modules/hail/expr/types.html:41896,Testability,assert,assert,41896,"ng_byte, which_missing_bit):; answer.append(None); else:; field_decoded = t._convert_from_encoding(byte_reader, _should_freeze); answer.append(field_decoded). return tuple(answer). def _convert_to_encoding(self, byte_writer, value):; length = len(self); i = 0; while i < length:; missing_byte = 0; for j in range(min(8, length - i)):; if HailType._missing(value[i + j]):; missing_byte |= 1 << j; byte_writer.write_byte(missing_byte); i += 8; for i, t in enumerate(self.types):; if not HailType._missing(value[i]):; t._convert_to_encoding(byte_writer, value[i]). def unify(self, t):; if not (isinstance(t, ttuple) and len(self.types) == len(t.types)):; return False; for t1, t2 in zip(self.types, t.types):; if not t1.unify(t2):; return False; return True. def subst(self):; return ttuple(*[t.subst() for t in self.types]). def clear(self):; for t in self.types:; t.clear(). def _get_context(self):; return HailTypeContext.union(*self.types). def allele_pair(j: int, k: int):; assert j >= 0 and j <= 0xFFFF; assert k >= 0 and k <= 0xFFFF; return j | (k << 16). def allele_pair_sqrt(i):; k = int(math.sqrt(8 * float(i) + 1) / 2 - 0.5); assert k * (k + 1) // 2 <= i; j = i - k * (k + 1) // 2; # TODO another assert; return allele_pair(j, k). small_allele_pair = [; allele_pair(0, 0),; allele_pair(0, 1),; allele_pair(1, 1),; allele_pair(0, 2),; allele_pair(1, 2),; allele_pair(2, 2),; allele_pair(0, 3),; allele_pair(1, 3),; allele_pair(2, 3),; allele_pair(3, 3),; allele_pair(0, 4),; allele_pair(1, 4),; allele_pair(2, 4),; allele_pair(3, 4),; allele_pair(4, 4),; allele_pair(0, 5),; allele_pair(1, 5),; allele_pair(2, 5),; allele_pair(3, 5),; allele_pair(4, 5),; allele_pair(5, 5),; allele_pair(0, 6),; allele_pair(1, 6),; allele_pair(2, 6),; allele_pair(3, 6),; allele_pair(4, 6),; allele_pair(5, 6),; allele_pair(6, 6),; allele_pair(0, 7),; allele_pair(1, 7),; allele_pair(2, 7),; allele_pair(3, 7),; allele_pair(4, 7),; allele_pair(5, 7),; allele_pair(6, 7),; allele_pair(7, 7),; ]. class _tcall(Ha",MatchSource.WIKI,docs/0.2/_modules/hail/expr/types.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html
https://hail.is/docs/0.2/_modules/hail/expr/types.html:42023,Testability,assert,assert,42023," _convert_to_encoding(self, byte_writer, value):; length = len(self); i = 0; while i < length:; missing_byte = 0; for j in range(min(8, length - i)):; if HailType._missing(value[i + j]):; missing_byte |= 1 << j; byte_writer.write_byte(missing_byte); i += 8; for i, t in enumerate(self.types):; if not HailType._missing(value[i]):; t._convert_to_encoding(byte_writer, value[i]). def unify(self, t):; if not (isinstance(t, ttuple) and len(self.types) == len(t.types)):; return False; for t1, t2 in zip(self.types, t.types):; if not t1.unify(t2):; return False; return True. def subst(self):; return ttuple(*[t.subst() for t in self.types]). def clear(self):; for t in self.types:; t.clear(). def _get_context(self):; return HailTypeContext.union(*self.types). def allele_pair(j: int, k: int):; assert j >= 0 and j <= 0xFFFF; assert k >= 0 and k <= 0xFFFF; return j | (k << 16). def allele_pair_sqrt(i):; k = int(math.sqrt(8 * float(i) + 1) / 2 - 0.5); assert k * (k + 1) // 2 <= i; j = i - k * (k + 1) // 2; # TODO another assert; return allele_pair(j, k). small_allele_pair = [; allele_pair(0, 0),; allele_pair(0, 1),; allele_pair(1, 1),; allele_pair(0, 2),; allele_pair(1, 2),; allele_pair(2, 2),; allele_pair(0, 3),; allele_pair(1, 3),; allele_pair(2, 3),; allele_pair(3, 3),; allele_pair(0, 4),; allele_pair(1, 4),; allele_pair(2, 4),; allele_pair(3, 4),; allele_pair(4, 4),; allele_pair(0, 5),; allele_pair(1, 5),; allele_pair(2, 5),; allele_pair(3, 5),; allele_pair(4, 5),; allele_pair(5, 5),; allele_pair(0, 6),; allele_pair(1, 6),; allele_pair(2, 6),; allele_pair(3, 6),; allele_pair(4, 6),; allele_pair(5, 6),; allele_pair(6, 6),; allele_pair(0, 7),; allele_pair(1, 7),; allele_pair(2, 7),; allele_pair(3, 7),; allele_pair(4, 7),; allele_pair(5, 7),; allele_pair(6, 7),; allele_pair(7, 7),; ]. class _tcall(HailType):; """"""Hail type for a diploid genotype. In Python, these are represented by :class:`.Call`.; """""". def __init__(self):; super(_tcall, self).__init__(). def _typecheck_one_level(s",MatchSource.WIKI,docs/0.2/_modules/hail/expr/types.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html
https://hail.is/docs/0.2/_modules/hail/expr/types.html:42094,Testability,assert,assert,42094," _convert_to_encoding(self, byte_writer, value):; length = len(self); i = 0; while i < length:; missing_byte = 0; for j in range(min(8, length - i)):; if HailType._missing(value[i + j]):; missing_byte |= 1 << j; byte_writer.write_byte(missing_byte); i += 8; for i, t in enumerate(self.types):; if not HailType._missing(value[i]):; t._convert_to_encoding(byte_writer, value[i]). def unify(self, t):; if not (isinstance(t, ttuple) and len(self.types) == len(t.types)):; return False; for t1, t2 in zip(self.types, t.types):; if not t1.unify(t2):; return False; return True. def subst(self):; return ttuple(*[t.subst() for t in self.types]). def clear(self):; for t in self.types:; t.clear(). def _get_context(self):; return HailTypeContext.union(*self.types). def allele_pair(j: int, k: int):; assert j >= 0 and j <= 0xFFFF; assert k >= 0 and k <= 0xFFFF; return j | (k << 16). def allele_pair_sqrt(i):; k = int(math.sqrt(8 * float(i) + 1) / 2 - 0.5); assert k * (k + 1) // 2 <= i; j = i - k * (k + 1) // 2; # TODO another assert; return allele_pair(j, k). small_allele_pair = [; allele_pair(0, 0),; allele_pair(0, 1),; allele_pair(1, 1),; allele_pair(0, 2),; allele_pair(1, 2),; allele_pair(2, 2),; allele_pair(0, 3),; allele_pair(1, 3),; allele_pair(2, 3),; allele_pair(3, 3),; allele_pair(0, 4),; allele_pair(1, 4),; allele_pair(2, 4),; allele_pair(3, 4),; allele_pair(4, 4),; allele_pair(0, 5),; allele_pair(1, 5),; allele_pair(2, 5),; allele_pair(3, 5),; allele_pair(4, 5),; allele_pair(5, 5),; allele_pair(0, 6),; allele_pair(1, 6),; allele_pair(2, 6),; allele_pair(3, 6),; allele_pair(4, 6),; allele_pair(5, 6),; allele_pair(6, 6),; allele_pair(0, 7),; allele_pair(1, 7),; allele_pair(2, 7),; allele_pair(3, 7),; allele_pair(4, 7),; allele_pair(5, 7),; allele_pair(6, 7),; allele_pair(7, 7),; ]. class _tcall(HailType):; """"""Hail type for a diploid genotype. In Python, these are represented by :class:`.Call`.; """""". def __init__(self):; super(_tcall, self).__init__(). def _typecheck_one_level(s",MatchSource.WIKI,docs/0.2/_modules/hail/expr/types.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html
https://hail.is/docs/0.2/_modules/hail/expr/types.html:44262,Testability,assert,assert,44262," return isinstance(other, _tcall). def _parsable_string(self):; return ""Call"". def _convert_from_json(self, x, _should_freeze: bool = False) -> genetics.Call:; if x == '-':; return genetics.Call([]); if x == '|-':; return genetics.Call([], phased=True); if x[0] == '|':; return genetics.Call([int(x[1:])], phased=True). n = len(x); i = 0; while i < n:; c = x[i]; if c in '|/':; break; i += 1. if i == n:; return genetics.Call([int(x)]). return genetics.Call([int(x[0:i]), int(x[i + 1 :])], phased=(c == '|')). def _convert_to_json(self, x):; return str(x). def _convert_from_encoding(self, byte_reader, _should_freeze: bool = False) -> genetics.Call:; int_rep = byte_reader.read_int32(); int_rep = int_rep if int_rep >= 0 else int_rep + 2**32. ploidy = (int_rep >> 1) & 0x3; phased = (int_rep & 1) == 1. def allele_repr(c):; return c >> 3. def ap_j(p):; return p & 0xFFFF. def ap_k(p):; return (p >> 16) & 0xFFFF. def gt_allele_pair(i):; assert i >= 0, ""allele pair value should never be negative""; if i < len(small_allele_pair):; return small_allele_pair[i]; return allele_pair_sqrt(i). def call_allele_pair(i):; if phased:; rep = allele_repr(i); p = gt_allele_pair(rep); j = ap_j(p); k = ap_k(p); return allele_pair(j, k - j); else:; rep = allele_repr(i); return gt_allele_pair(rep). if ploidy == 0:; alleles = []; elif ploidy == 1:; alleles = [allele_repr(int_rep)]; elif ploidy == 2:; p = call_allele_pair(int_rep); alleles = [ap_j(p), ap_k(p)]; else:; raise ValueError(""Unsupported Ploidy""). return genetics.Call(alleles, phased). def _convert_to_encoding(self, byte_writer, value: genetics.Call):; int_rep = 0. int_rep |= value.ploidy << 1; if value.phased:; int_rep |= 1. def diploid_gt_index(j: int, k: int):; assert j <= k; return k * (k + 1) // 2 + j. def allele_pair_rep(c: genetics.Call):; [j, k] = c.alleles; if c.phased:; return diploid_gt_index(j, j + k); return diploid_gt_index(j, k). assert value.ploidy <= 2; if value.ploidy == 1:; int_rep |= value.alleles[0] << 3; elif value.ploi",MatchSource.WIKI,docs/0.2/_modules/hail/expr/types.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html
https://hail.is/docs/0.2/_modules/hail/expr/types.html:45042,Testability,assert,assert,45042," 0 else int_rep + 2**32. ploidy = (int_rep >> 1) & 0x3; phased = (int_rep & 1) == 1. def allele_repr(c):; return c >> 3. def ap_j(p):; return p & 0xFFFF. def ap_k(p):; return (p >> 16) & 0xFFFF. def gt_allele_pair(i):; assert i >= 0, ""allele pair value should never be negative""; if i < len(small_allele_pair):; return small_allele_pair[i]; return allele_pair_sqrt(i). def call_allele_pair(i):; if phased:; rep = allele_repr(i); p = gt_allele_pair(rep); j = ap_j(p); k = ap_k(p); return allele_pair(j, k - j); else:; rep = allele_repr(i); return gt_allele_pair(rep). if ploidy == 0:; alleles = []; elif ploidy == 1:; alleles = [allele_repr(int_rep)]; elif ploidy == 2:; p = call_allele_pair(int_rep); alleles = [ap_j(p), ap_k(p)]; else:; raise ValueError(""Unsupported Ploidy""). return genetics.Call(alleles, phased). def _convert_to_encoding(self, byte_writer, value: genetics.Call):; int_rep = 0. int_rep |= value.ploidy << 1; if value.phased:; int_rep |= 1. def diploid_gt_index(j: int, k: int):; assert j <= k; return k * (k + 1) // 2 + j. def allele_pair_rep(c: genetics.Call):; [j, k] = c.alleles; if c.phased:; return diploid_gt_index(j, j + k); return diploid_gt_index(j, k). assert value.ploidy <= 2; if value.ploidy == 1:; int_rep |= value.alleles[0] << 3; elif value.ploidy == 2:; int_rep |= allele_pair_rep(value) << 3; int_rep = int_rep if 0 <= int_rep < 2**31 - 1 else int_rep - 2**32. byte_writer.write_int32(int_rep). def unify(self, t):; return t == tcall. def subst(self):; return self. def clear(self):; pass. [docs]class tlocus(HailType):; """"""Hail type for a genomic coordinate with a contig and a position. In Python, these are represented by :class:`.Locus`. Parameters; ----------; reference_genome: :class:`.ReferenceGenome` or :class:`str`; Reference genome to use. See Also; --------; :class:`.LocusExpression`, :func:`.locus`, :func:`.parse_locus`,; :class:`.Locus`; """""". struct_repr = tstruct(contig=_tstr(), pos=_tint32()). @classmethod; @typecheck_method(reference_genome=",MatchSource.WIKI,docs/0.2/_modules/hail/expr/types.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html
https://hail.is/docs/0.2/_modules/hail/expr/types.html:45226,Testability,assert,assert,45226,"FFFF. def gt_allele_pair(i):; assert i >= 0, ""allele pair value should never be negative""; if i < len(small_allele_pair):; return small_allele_pair[i]; return allele_pair_sqrt(i). def call_allele_pair(i):; if phased:; rep = allele_repr(i); p = gt_allele_pair(rep); j = ap_j(p); k = ap_k(p); return allele_pair(j, k - j); else:; rep = allele_repr(i); return gt_allele_pair(rep). if ploidy == 0:; alleles = []; elif ploidy == 1:; alleles = [allele_repr(int_rep)]; elif ploidy == 2:; p = call_allele_pair(int_rep); alleles = [ap_j(p), ap_k(p)]; else:; raise ValueError(""Unsupported Ploidy""). return genetics.Call(alleles, phased). def _convert_to_encoding(self, byte_writer, value: genetics.Call):; int_rep = 0. int_rep |= value.ploidy << 1; if value.phased:; int_rep |= 1. def diploid_gt_index(j: int, k: int):; assert j <= k; return k * (k + 1) // 2 + j. def allele_pair_rep(c: genetics.Call):; [j, k] = c.alleles; if c.phased:; return diploid_gt_index(j, j + k); return diploid_gt_index(j, k). assert value.ploidy <= 2; if value.ploidy == 1:; int_rep |= value.alleles[0] << 3; elif value.ploidy == 2:; int_rep |= allele_pair_rep(value) << 3; int_rep = int_rep if 0 <= int_rep < 2**31 - 1 else int_rep - 2**32. byte_writer.write_int32(int_rep). def unify(self, t):; return t == tcall. def subst(self):; return self. def clear(self):; pass. [docs]class tlocus(HailType):; """"""Hail type for a genomic coordinate with a contig and a position. In Python, these are represented by :class:`.Locus`. Parameters; ----------; reference_genome: :class:`.ReferenceGenome` or :class:`str`; Reference genome to use. See Also; --------; :class:`.LocusExpression`, :func:`.locus`, :func:`.parse_locus`,; :class:`.Locus`; """""". struct_repr = tstruct(contig=_tstr(), pos=_tint32()). @classmethod; @typecheck_method(reference_genome=nullable(reference_genome_type)); def _schema_from_rg(cls, reference_genome='default'):; # must match TLocus.schemaFromRG; if reference_genome is None:; return hl.tstruct(contig=hl.tstr, p",MatchSource.WIKI,docs/0.2/_modules/hail/expr/types.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html
https://hail.is/docs/0.2/_modules/hail/expr/types.html:51911,Testability,assert,assert,51911,"terval_as_struct.includes_end,; point_type=self.point_type,; ). def _convert_to_encoding(self, byte_writer, value):; interval_dict = {; 'start': value.start,; 'end': value.end,; 'includes_start': value.includes_start,; 'includes_end': value.includes_end,; }; self._struct_repr._convert_to_encoding(byte_writer, interval_dict). def unify(self, t):; return isinstance(t, tinterval) and self.point_type.unify(t.point_type). def subst(self):; return tinterval(self.point_type.subst()). def clear(self):; self.point_type.clear(). def _get_context(self):; return self.point_type.get_context(). class Box(object):; named_boxes: ClassVar = {}. @staticmethod; def from_name(name):; if name in Box.named_boxes:; return Box.named_boxes[name]; b = Box(); Box.named_boxes[name] = b; return b. def __init__(self):; pass. def unify(self, v):; if hasattr(self, 'value'):; return self.value == v; self.value = v; return True. def clear(self):; if hasattr(self, 'value'):; del self.value. def get(self):; assert hasattr(self, 'value'); return self.value. tvoid = _tvoid(). tint32 = _tint32(); """"""Hail type for signed 32-bit integers. Their values can range from :math:`-2^{31}` to :math:`2^{31} - 1`; (approximately 2.15 billion). In Python, these are represented as :obj:`int`. See Also; --------; :class:`.Int32Expression`, :func:`.int`, :func:`.int32`; """""". tint64 = _tint64(); """"""Hail type for signed 64-bit integers. Their values can range from :math:`-2^{63}` to :math:`2^{63} - 1`. In Python, these are represented as :obj:`int`. See Also; --------; :class:`.Int64Expression`, :func:`.int64`; """""". tint = tint32; """"""Alias for :py:data:`.tint32`."""""". tfloat32 = _tfloat32(); """"""Hail type for 32-bit floating point numbers. In Python, these are represented as :obj:`float`. See Also; --------; :class:`.Float32Expression`, :func:`.float64`; """""". tfloat64 = _tfloat64(); """"""Hail type for 64-bit floating point numbers. In Python, these are represented as :obj:`float`. See Also; --------; :class:`.Float64Expressio",MatchSource.WIKI,docs/0.2/_modules/hail/expr/types.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html
https://hail.is/docs/0.2/_modules/hail/expr/types.html:6441,Usability,clear,clear,6441,"x, _should_freeze: bool = False):; return x. def _from_encoding(self, encoding):; return self._convert_from_encoding(ByteReader(memoryview(encoding))). def _to_encoding(self, value) -> bytes:; buf = bytearray(); self._convert_to_encoding(ByteWriter(buf), value); return bytes(buf). def _convert_from_encoding(self, byte_reader, _should_freeze: bool = False):; raise ValueError(""Not implemented yet""). def _convert_to_encoding(self, byte_writer, value):; raise ValueError(""Not implemented yet""). @staticmethod; def _missing(value):; return value is None or value is pd.NA. def _traverse(self, obj, f):; """"""Traverse a nested type and object. Parameters; ----------; obj : Any; f : Callable[[HailType, Any], bool]; Function to evaluate on the type and object. Traverse children if; the function returns ``True``.; """"""; f(self, obj). @abc.abstractmethod; def unify(self, t):; raise NotImplementedError. @abc.abstractmethod; def subst(self):; raise NotImplementedError. @abc.abstractmethod; def clear(self):; raise NotImplementedError. def _get_context(self):; return _empty_context. def get_context(self):; if self._context is None:; self._context = self._get_context(); return self._context. def to_numpy(self):; return object. hail_type = oneof(HailType, transformed((str, dtype)), type(None)). class _tvoid(HailType):; def __init__(self):; super(_tvoid, self).__init__(). def __str__(self):; return ""void"". def _eq(self, other):; return isinstance(other, _tvoid). def _parsable_string(self):; return ""Void"". def unify(self, t):; return t == tvoid. def subst(self):; return self. def clear(self):; pass. def _convert_from_encoding(self, *_):; raise ValueError(""Cannot decode void type""). def _convert_to_encoding(self, *_):; raise ValueError(""Cannot encode void type""). class _tint32(HailType):; """"""Hail type for signed 32-bit integers. Their values can range from :math:`-2^{31}` to :math:`2^{31} - 1`; (approximately 2.15 billion). In Python, these are represented as :obj:`int`.; """""". def __init__(s",MatchSource.WIKI,docs/0.2/_modules/hail/expr/types.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html
https://hail.is/docs/0.2/_modules/hail/expr/types.html:7033,Usability,clear,clear,7033,"f, obj, f):; """"""Traverse a nested type and object. Parameters; ----------; obj : Any; f : Callable[[HailType, Any], bool]; Function to evaluate on the type and object. Traverse children if; the function returns ``True``.; """"""; f(self, obj). @abc.abstractmethod; def unify(self, t):; raise NotImplementedError. @abc.abstractmethod; def subst(self):; raise NotImplementedError. @abc.abstractmethod; def clear(self):; raise NotImplementedError. def _get_context(self):; return _empty_context. def get_context(self):; if self._context is None:; self._context = self._get_context(); return self._context. def to_numpy(self):; return object. hail_type = oneof(HailType, transformed((str, dtype)), type(None)). class _tvoid(HailType):; def __init__(self):; super(_tvoid, self).__init__(). def __str__(self):; return ""void"". def _eq(self, other):; return isinstance(other, _tvoid). def _parsable_string(self):; return ""Void"". def unify(self, t):; return t == tvoid. def subst(self):; return self. def clear(self):; pass. def _convert_from_encoding(self, *_):; raise ValueError(""Cannot decode void type""). def _convert_to_encoding(self, *_):; raise ValueError(""Cannot encode void type""). class _tint32(HailType):; """"""Hail type for signed 32-bit integers. Their values can range from :math:`-2^{31}` to :math:`2^{31} - 1`; (approximately 2.15 billion). In Python, these are represented as :obj:`int`.; """""". def __init__(self):; super(_tint32, self).__init__(). def _typecheck_one_level(self, annotation):; if annotation is not None:; if not is_int32(annotation):; raise TypeError(""type 'tint32' expected Python 'int', but found type '%s'"" % type(annotation)); elif not self.min_value <= annotation <= self.max_value:; raise TypeError(; f""Value out of range for 32-bit integer: ""; f""expected [{self.min_value}, {self.max_value}], found {annotation}""; ). def __str__(self):; return ""int32"". def _eq(self, other):; return isinstance(other, _tint32). def _parsable_string(self):; return ""Int32"". @property; def min",MatchSource.WIKI,docs/0.2/_modules/hail/expr/types.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html
https://hail.is/docs/0.2/_modules/hail/expr/types.html:8205,Usability,clear,clear,8205,"ype""). class _tint32(HailType):; """"""Hail type for signed 32-bit integers. Their values can range from :math:`-2^{31}` to :math:`2^{31} - 1`; (approximately 2.15 billion). In Python, these are represented as :obj:`int`.; """""". def __init__(self):; super(_tint32, self).__init__(). def _typecheck_one_level(self, annotation):; if annotation is not None:; if not is_int32(annotation):; raise TypeError(""type 'tint32' expected Python 'int', but found type '%s'"" % type(annotation)); elif not self.min_value <= annotation <= self.max_value:; raise TypeError(; f""Value out of range for 32-bit integer: ""; f""expected [{self.min_value}, {self.max_value}], found {annotation}""; ). def __str__(self):; return ""int32"". def _eq(self, other):; return isinstance(other, _tint32). def _parsable_string(self):; return ""Int32"". @property; def min_value(self):; return -(1 << 31). @property; def max_value(self):; return (1 << 31) - 1. def unify(self, t):; return t == tint32. def subst(self):; return self. def clear(self):; pass. def to_numpy(self):; return np.int32. def _convert_from_encoding(self, byte_reader, _should_freeze: bool = False) -> int:; return byte_reader.read_int32(). def _convert_to_encoding(self, byte_writer: ByteWriter, value):; byte_writer.write_int32(value). def _byte_size(self):; return 4. class _tint64(HailType):; """"""Hail type for signed 64-bit integers. Their values can range from :math:`-2^{63}` to :math:`2^{63} - 1`. In Python, these are represented as :obj:`int`.; """""". def __init__(self):; super(_tint64, self).__init__(). def _typecheck_one_level(self, annotation):; if annotation is not None:; if not is_int64(annotation):; raise TypeError(""type 'int64' expected Python 'int', but found type '%s'"" % type(annotation)); if not self.min_value <= annotation <= self.max_value:; raise TypeError(; f""Value out of range for 64-bit integer: ""; f""expected [{self.min_value}, {self.max_value}], found {annotation}""; ). def __str__(self):; return ""int64"". def _eq(self, other):; return isin",MatchSource.WIKI,docs/0.2/_modules/hail/expr/types.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html
https://hail.is/docs/0.2/_modules/hail/expr/types.html:9464,Usability,clear,clear,9464,"alue). def _byte_size(self):; return 4. class _tint64(HailType):; """"""Hail type for signed 64-bit integers. Their values can range from :math:`-2^{63}` to :math:`2^{63} - 1`. In Python, these are represented as :obj:`int`.; """""". def __init__(self):; super(_tint64, self).__init__(). def _typecheck_one_level(self, annotation):; if annotation is not None:; if not is_int64(annotation):; raise TypeError(""type 'int64' expected Python 'int', but found type '%s'"" % type(annotation)); if not self.min_value <= annotation <= self.max_value:; raise TypeError(; f""Value out of range for 64-bit integer: ""; f""expected [{self.min_value}, {self.max_value}], found {annotation}""; ). def __str__(self):; return ""int64"". def _eq(self, other):; return isinstance(other, _tint64). def _parsable_string(self):; return ""Int64"". @property; def min_value(self):; return -(1 << 63). @property; def max_value(self):; return (1 << 63) - 1. def unify(self, t):; return t == tint64. def subst(self):; return self. def clear(self):; pass. def to_numpy(self):; return np.int64. def _convert_from_encoding(self, byte_reader, _should_freeze: bool = False) -> int:; return byte_reader.read_int64(). def _convert_to_encoding(self, byte_writer: ByteWriter, value):; byte_writer.write_int64(value). def _byte_size(self):; return 8. class _tfloat32(HailType):; """"""Hail type for 32-bit floating point numbers. In Python, these are represented as :obj:`float`.; """""". def __init__(self):; super(_tfloat32, self).__init__(). def _typecheck_one_level(self, annotation):; if annotation is not None and not is_float32(annotation):; raise TypeError(""type 'float32' expected Python 'float', but found type '%s'"" % type(annotation)). def __str__(self):; return ""float32"". def _eq(self, other):; return isinstance(other, _tfloat32). def _parsable_string(self):; return ""Float32"". def _convert_from_json(self, x, _should_freeze: bool = False):; return float(x). def _convert_to_json(self, x):; if math.isfinite(x):; return x; else:; return str(x)",MatchSource.WIKI,docs/0.2/_modules/hail/expr/types.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html
https://hail.is/docs/0.2/_modules/hail/expr/types.html:10772,Usability,clear,clear,10772,"loat32(HailType):; """"""Hail type for 32-bit floating point numbers. In Python, these are represented as :obj:`float`.; """""". def __init__(self):; super(_tfloat32, self).__init__(). def _typecheck_one_level(self, annotation):; if annotation is not None and not is_float32(annotation):; raise TypeError(""type 'float32' expected Python 'float', but found type '%s'"" % type(annotation)). def __str__(self):; return ""float32"". def _eq(self, other):; return isinstance(other, _tfloat32). def _parsable_string(self):; return ""Float32"". def _convert_from_json(self, x, _should_freeze: bool = False):; return float(x). def _convert_to_json(self, x):; if math.isfinite(x):; return x; else:; return str(x). def _convert_from_encoding(self, byte_reader, _should_freeze: bool = False) -> float:; return byte_reader.read_float32(). def _convert_to_encoding(self, byte_writer: ByteWriter, value):; byte_writer.write_float32(value). def unify(self, t):; return t == tfloat32. def subst(self):; return self. def clear(self):; pass. def to_numpy(self):; return np.float32. def _byte_size(self):; return 4. class _tfloat64(HailType):; """"""Hail type for 64-bit floating point numbers. In Python, these are represented as :obj:`float`.; """""". def __init__(self):; super(_tfloat64, self).__init__(). def _typecheck_one_level(self, annotation):; if annotation is not None and not is_float64(annotation):; raise TypeError(""type 'float64' expected Python 'float', but found type '%s'"" % type(annotation)). def __str__(self):; return ""float64"". def _eq(self, other):; return isinstance(other, _tfloat64). def _parsable_string(self):; return ""Float64"". def _convert_from_json(self, x, _should_freeze: bool = False):; return float(x). def _convert_to_json(self, x):; if math.isfinite(x):; return x; else:; return str(x). def unify(self, t):; return t == tfloat64. def subst(self):; return self. def clear(self):; pass. def to_numpy(self):; return np.float64. def _convert_from_encoding(self, byte_reader, _should_freeze: bool = Fals",MatchSource.WIKI,docs/0.2/_modules/hail/expr/types.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html
https://hail.is/docs/0.2/_modules/hail/expr/types.html:11646,Usability,clear,clear,11646,"lue):; byte_writer.write_float32(value). def unify(self, t):; return t == tfloat32. def subst(self):; return self. def clear(self):; pass. def to_numpy(self):; return np.float32. def _byte_size(self):; return 4. class _tfloat64(HailType):; """"""Hail type for 64-bit floating point numbers. In Python, these are represented as :obj:`float`.; """""". def __init__(self):; super(_tfloat64, self).__init__(). def _typecheck_one_level(self, annotation):; if annotation is not None and not is_float64(annotation):; raise TypeError(""type 'float64' expected Python 'float', but found type '%s'"" % type(annotation)). def __str__(self):; return ""float64"". def _eq(self, other):; return isinstance(other, _tfloat64). def _parsable_string(self):; return ""Float64"". def _convert_from_json(self, x, _should_freeze: bool = False):; return float(x). def _convert_to_json(self, x):; if math.isfinite(x):; return x; else:; return str(x). def unify(self, t):; return t == tfloat64. def subst(self):; return self. def clear(self):; pass. def to_numpy(self):; return np.float64. def _convert_from_encoding(self, byte_reader, _should_freeze: bool = False) -> float:; return byte_reader.read_float64(). def _convert_to_encoding(self, byte_writer: ByteWriter, value):; byte_writer.write_float64(value). def _byte_size(self):; return 8. class _tstr(HailType):; """"""Hail type for text strings. In Python, these are represented as strings.; """""". def __init__(self):; super(_tstr, self).__init__(). def _typecheck_one_level(self, annotation):; if annotation and not isinstance(annotation, str):; raise TypeError(""type 'str' expected Python 'str', but found type '%s'"" % type(annotation)). def __str__(self):; return ""str"". def _eq(self, other):; return isinstance(other, _tstr). def _parsable_string(self):; return ""String"". def unify(self, t):; return t == tstr. def subst(self):; return self. def clear(self):; pass. def _convert_from_encoding(self, byte_reader, _should_freeze: bool = False) -> str:; length = byte_reader.read_int3",MatchSource.WIKI,docs/0.2/_modules/hail/expr/types.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html
https://hail.is/docs/0.2/_modules/hail/expr/types.html:12518,Usability,clear,clear,12518,"inite(x):; return x; else:; return str(x). def unify(self, t):; return t == tfloat64. def subst(self):; return self. def clear(self):; pass. def to_numpy(self):; return np.float64. def _convert_from_encoding(self, byte_reader, _should_freeze: bool = False) -> float:; return byte_reader.read_float64(). def _convert_to_encoding(self, byte_writer: ByteWriter, value):; byte_writer.write_float64(value). def _byte_size(self):; return 8. class _tstr(HailType):; """"""Hail type for text strings. In Python, these are represented as strings.; """""". def __init__(self):; super(_tstr, self).__init__(). def _typecheck_one_level(self, annotation):; if annotation and not isinstance(annotation, str):; raise TypeError(""type 'str' expected Python 'str', but found type '%s'"" % type(annotation)). def __str__(self):; return ""str"". def _eq(self, other):; return isinstance(other, _tstr). def _parsable_string(self):; return ""String"". def unify(self, t):; return t == tstr. def subst(self):; return self. def clear(self):; pass. def _convert_from_encoding(self, byte_reader, _should_freeze: bool = False) -> str:; length = byte_reader.read_int32(); str_literal = byte_reader.read_bytes(length).decode('utf-8'). return str_literal. def _convert_to_encoding(self, byte_writer: ByteWriter, value):; value_bytes = value.encode('utf-8'); byte_writer.write_int32(len(value_bytes)); byte_writer.write_bytes(value_bytes). class _tbool(HailType):; """"""Hail type for Boolean (``True`` or ``False``) values. In Python, these are represented as :obj:`bool`.; """""". def __init__(self):; super(_tbool, self).__init__(). def _typecheck_one_level(self, annotation):; if annotation is not None and not isinstance(annotation, bool):; raise TypeError(""type 'bool' expected Python 'bool', but found type '%s'"" % type(annotation)). def __str__(self):; return ""bool"". def _eq(self, other):; return isinstance(other, _tbool). def _parsable_string(self):; return ""Boolean"". def unify(self, t):; return t == tbool. def subst(self):; return sel",MatchSource.WIKI,docs/0.2/_modules/hail/expr/types.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html
https://hail.is/docs/0.2/_modules/hail/expr/types.html:13532,Usability,clear,clear,13532,"ef _convert_from_encoding(self, byte_reader, _should_freeze: bool = False) -> str:; length = byte_reader.read_int32(); str_literal = byte_reader.read_bytes(length).decode('utf-8'). return str_literal. def _convert_to_encoding(self, byte_writer: ByteWriter, value):; value_bytes = value.encode('utf-8'); byte_writer.write_int32(len(value_bytes)); byte_writer.write_bytes(value_bytes). class _tbool(HailType):; """"""Hail type for Boolean (``True`` or ``False``) values. In Python, these are represented as :obj:`bool`.; """""". def __init__(self):; super(_tbool, self).__init__(). def _typecheck_one_level(self, annotation):; if annotation is not None and not isinstance(annotation, bool):; raise TypeError(""type 'bool' expected Python 'bool', but found type '%s'"" % type(annotation)). def __str__(self):; return ""bool"". def _eq(self, other):; return isinstance(other, _tbool). def _parsable_string(self):; return ""Boolean"". def unify(self, t):; return t == tbool. def subst(self):; return self. def clear(self):; pass. def to_numpy(self):; return bool. def _byte_size(self):; return 1. def _convert_from_encoding(self, byte_reader, _should_freeze: bool = False) -> bool:; return byte_reader.read_bool(). def _convert_to_encoding(self, byte_writer: ByteWriter, value):; byte_writer.write_bool(value). class _trngstate(HailType):; def __init__(self):; super(_trngstate, self).__init__(). def __str__(self):; return ""rng_state"". def _eq(self, other):; return isinstance(other, _trngstate). def _parsable_string(self):; return ""RNGState"". def unify(self, t):; return t == trngstate. def subst(self):; return self. def clear(self):; pass. [docs]class tndarray(HailType):; """"""Hail type for n-dimensional arrays. .. include:: _templates/experimental.rst. In Python, these are represented as NumPy :obj:`numpy.ndarray`. Notes; -----. NDArrays contain elements of only one type, which is parameterized by; `element_type`. Parameters; ----------; element_type : :class:`.HailType`; Element type of array.; ndim : int",MatchSource.WIKI,docs/0.2/_modules/hail/expr/types.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html
https://hail.is/docs/0.2/_modules/hail/expr/types.html:14147,Usability,clear,clear,14147,"):; if annotation is not None and not isinstance(annotation, bool):; raise TypeError(""type 'bool' expected Python 'bool', but found type '%s'"" % type(annotation)). def __str__(self):; return ""bool"". def _eq(self, other):; return isinstance(other, _tbool). def _parsable_string(self):; return ""Boolean"". def unify(self, t):; return t == tbool. def subst(self):; return self. def clear(self):; pass. def to_numpy(self):; return bool. def _byte_size(self):; return 1. def _convert_from_encoding(self, byte_reader, _should_freeze: bool = False) -> bool:; return byte_reader.read_bool(). def _convert_to_encoding(self, byte_writer: ByteWriter, value):; byte_writer.write_bool(value). class _trngstate(HailType):; def __init__(self):; super(_trngstate, self).__init__(). def __str__(self):; return ""rng_state"". def _eq(self, other):; return isinstance(other, _trngstate). def _parsable_string(self):; return ""RNGState"". def unify(self, t):; return t == trngstate. def subst(self):; return self. def clear(self):; pass. [docs]class tndarray(HailType):; """"""Hail type for n-dimensional arrays. .. include:: _templates/experimental.rst. In Python, these are represented as NumPy :obj:`numpy.ndarray`. Notes; -----. NDArrays contain elements of only one type, which is parameterized by; `element_type`. Parameters; ----------; element_type : :class:`.HailType`; Element type of array.; ndim : int32; Number of dimensions. See Also; --------; :class:`.NDArrayExpression`, :obj:`.nd.array`; """""". @typecheck_method(element_type=hail_type, ndim=oneof(NatBase, int)); def __init__(self, element_type, ndim):; self._element_type = element_type; self._ndim = NatLiteral(ndim) if isinstance(ndim, int) else ndim; super(tndarray, self).__init__(). @property; def element_type(self):; """"""NDArray element type. Returns; -------; :class:`.HailType`; Element type.; """"""; return self._element_type. @property; def ndim(self):; """"""NDArray number of dimensions. Returns; -------; :obj:`int`; Number of dimensions.; """"""; assert ",MatchSource.WIKI,docs/0.2/_modules/hail/expr/types.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html
https://hail.is/docs/0.2/_modules/hail/expr/types.html:16798,Usability,clear,clear,16798,"her.element_type and self.ndim == other.ndim. def _pretty(self, b, indent, increment):; b.append('ndarray<'); self._element_type._pretty(b, indent, increment); b.append(', '); b.append(str(self.ndim)); b.append('>'). def _parsable_string(self):; return f'NDArray[{self._element_type._parsable_string()},{self.ndim}]'. def _convert_from_json(self, x, _should_freeze: bool = False) -> np.ndarray:; if is_numeric(self._element_type):; np_type = self.element_type.to_numpy(); return np.ndarray(shape=x['shape'], buffer=np.array(x['data'], dtype=np_type), dtype=np_type); else:; raise TypeError(""Hail cannot currently return ndarrays of non-numeric or boolean type.""). def _convert_to_json(self, x):; data = x.flatten(""C"").tolist(). strides = []; axis_one_step_byte_size = x.itemsize; for dimension_size in x.shape:; strides.append(axis_one_step_byte_size); axis_one_step_byte_size *= dimension_size if dimension_size > 0 else 1. json_dict = {""shape"": x.shape, ""data"": data}; return json_dict. def clear(self):; self._element_type.clear(); self._ndim.clear(). def unify(self, t):; return isinstance(t, tndarray) and self._element_type.unify(t._element_type) and self._ndim.unify(t._ndim). def subst(self):; return tndarray(self._element_type.subst(), self._ndim.subst()). def _get_context(self):; return self.element_type.get_context(). def _convert_from_encoding(self, byte_reader, _should_freeze: bool = False) -> np.ndarray:; shape = [byte_reader.read_int64() for i in range(self.ndim)]; total_num_elements = np.product(shape, dtype=np.int64). if self.element_type in _numeric_types:; element_byte_size = self.element_type._byte_size; bytes_to_read = element_byte_size * total_num_elements; buffer = byte_reader.read_bytes_view(bytes_to_read); return np.frombuffer(buffer, self.element_type.to_numpy, count=total_num_elements).reshape(shape); else:; elements = [; self.element_type._convert_from_encoding(byte_reader, _should_freeze) for i in range(total_num_elements); ]; np_type = self.element_type.t",MatchSource.WIKI,docs/0.2/_modules/hail/expr/types.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html
https://hail.is/docs/0.2/_modules/hail/expr/types.html:16831,Usability,clear,clear,16831," other.ndim. def _pretty(self, b, indent, increment):; b.append('ndarray<'); self._element_type._pretty(b, indent, increment); b.append(', '); b.append(str(self.ndim)); b.append('>'). def _parsable_string(self):; return f'NDArray[{self._element_type._parsable_string()},{self.ndim}]'. def _convert_from_json(self, x, _should_freeze: bool = False) -> np.ndarray:; if is_numeric(self._element_type):; np_type = self.element_type.to_numpy(); return np.ndarray(shape=x['shape'], buffer=np.array(x['data'], dtype=np_type), dtype=np_type); else:; raise TypeError(""Hail cannot currently return ndarrays of non-numeric or boolean type.""). def _convert_to_json(self, x):; data = x.flatten(""C"").tolist(). strides = []; axis_one_step_byte_size = x.itemsize; for dimension_size in x.shape:; strides.append(axis_one_step_byte_size); axis_one_step_byte_size *= dimension_size if dimension_size > 0 else 1. json_dict = {""shape"": x.shape, ""data"": data}; return json_dict. def clear(self):; self._element_type.clear(); self._ndim.clear(). def unify(self, t):; return isinstance(t, tndarray) and self._element_type.unify(t._element_type) and self._ndim.unify(t._ndim). def subst(self):; return tndarray(self._element_type.subst(), self._ndim.subst()). def _get_context(self):; return self.element_type.get_context(). def _convert_from_encoding(self, byte_reader, _should_freeze: bool = False) -> np.ndarray:; shape = [byte_reader.read_int64() for i in range(self.ndim)]; total_num_elements = np.product(shape, dtype=np.int64). if self.element_type in _numeric_types:; element_byte_size = self.element_type._byte_size; bytes_to_read = element_byte_size * total_num_elements; buffer = byte_reader.read_bytes_view(bytes_to_read); return np.frombuffer(buffer, self.element_type.to_numpy, count=total_num_elements).reshape(shape); else:; elements = [; self.element_type._convert_from_encoding(byte_reader, _should_freeze) for i in range(total_num_elements); ]; np_type = self.element_type.to_numpy(); return np.ndarray(shap",MatchSource.WIKI,docs/0.2/_modules/hail/expr/types.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html
https://hail.is/docs/0.2/_modules/hail/expr/types.html:16851,Usability,clear,clear,16851,"_pretty(self, b, indent, increment):; b.append('ndarray<'); self._element_type._pretty(b, indent, increment); b.append(', '); b.append(str(self.ndim)); b.append('>'). def _parsable_string(self):; return f'NDArray[{self._element_type._parsable_string()},{self.ndim}]'. def _convert_from_json(self, x, _should_freeze: bool = False) -> np.ndarray:; if is_numeric(self._element_type):; np_type = self.element_type.to_numpy(); return np.ndarray(shape=x['shape'], buffer=np.array(x['data'], dtype=np_type), dtype=np_type); else:; raise TypeError(""Hail cannot currently return ndarrays of non-numeric or boolean type.""). def _convert_to_json(self, x):; data = x.flatten(""C"").tolist(). strides = []; axis_one_step_byte_size = x.itemsize; for dimension_size in x.shape:; strides.append(axis_one_step_byte_size); axis_one_step_byte_size *= dimension_size if dimension_size > 0 else 1. json_dict = {""shape"": x.shape, ""data"": data}; return json_dict. def clear(self):; self._element_type.clear(); self._ndim.clear(). def unify(self, t):; return isinstance(t, tndarray) and self._element_type.unify(t._element_type) and self._ndim.unify(t._ndim). def subst(self):; return tndarray(self._element_type.subst(), self._ndim.subst()). def _get_context(self):; return self.element_type.get_context(). def _convert_from_encoding(self, byte_reader, _should_freeze: bool = False) -> np.ndarray:; shape = [byte_reader.read_int64() for i in range(self.ndim)]; total_num_elements = np.product(shape, dtype=np.int64). if self.element_type in _numeric_types:; element_byte_size = self.element_type._byte_size; bytes_to_read = element_byte_size * total_num_elements; buffer = byte_reader.read_bytes_view(bytes_to_read); return np.frombuffer(buffer, self.element_type.to_numpy, count=total_num_elements).reshape(shape); else:; elements = [; self.element_type._convert_from_encoding(byte_reader, _should_freeze) for i in range(total_num_elements); ]; np_type = self.element_type.to_numpy(); return np.ndarray(shape=shape, buffer=n",MatchSource.WIKI,docs/0.2/_modules/hail/expr/types.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html
https://hail.is/docs/0.2/_modules/hail/expr/types.html:20269,Usability,clear,clear,20269,"und type '%s'"" % type(annotation)). def __str__(self):; return ""array<{}>"".format(self.element_type). def _eq(self, other):; return isinstance(other, tarray) and self.element_type == other.element_type. def _pretty(self, b, indent, increment):; b.append('array<'); self.element_type._pretty(b, indent, increment); b.append('>'). def _parsable_string(self):; return ""Array["" + self.element_type._parsable_string() + ""]"". def _convert_from_json(self, x, _should_freeze: bool = False) -> Union[list, frozenlist]:; ls = [self.element_type._convert_from_json_na(elt, _should_freeze) for elt in x]; if _should_freeze:; return frozenlist(ls); return ls. def _convert_to_json(self, x):; return [self.element_type._convert_to_json_na(elt) for elt in x]. def _propagate_jtypes(self, jtype):; self._element_type._add_jtype(jtype.elementType()). def unify(self, t):; return isinstance(t, tarray) and self.element_type.unify(t.element_type). def subst(self):; return tarray(self.element_type.subst()). def clear(self):; self.element_type.clear(). def _get_context(self):; return self.element_type.get_context(). def _convert_from_encoding(self, byte_reader, _should_freeze: bool = False) -> Union[list, frozenlist]:; length = byte_reader.read_int32(). num_missing_bytes = math.ceil(length / 8); missing_bytes = byte_reader.read_bytes_view(num_missing_bytes). decoded = []; i = 0; current_missing_byte = None; while i < length:; which_missing_bit = i % 8; if which_missing_bit == 0:; current_missing_byte = missing_bytes[i // 8]. if lookup_bit(current_missing_byte, which_missing_bit):; decoded.append(None); else:; element_decoded = self.element_type._convert_from_encoding(byte_reader, _should_freeze); decoded.append(element_decoded); i += 1; if _should_freeze:; return frozenlist(decoded); return decoded. def _convert_to_encoding(self, byte_writer: ByteWriter, value):; length = len(value); byte_writer.write_int32(length); i = 0; while i < length:; missing_byte = 0; for j in range(min(8, length - i)):; if H",MatchSource.WIKI,docs/0.2/_modules/hail/expr/types.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html
https://hail.is/docs/0.2/_modules/hail/expr/types.html:20301,Usability,clear,clear,20301,"ion)). def __str__(self):; return ""array<{}>"".format(self.element_type). def _eq(self, other):; return isinstance(other, tarray) and self.element_type == other.element_type. def _pretty(self, b, indent, increment):; b.append('array<'); self.element_type._pretty(b, indent, increment); b.append('>'). def _parsable_string(self):; return ""Array["" + self.element_type._parsable_string() + ""]"". def _convert_from_json(self, x, _should_freeze: bool = False) -> Union[list, frozenlist]:; ls = [self.element_type._convert_from_json_na(elt, _should_freeze) for elt in x]; if _should_freeze:; return frozenlist(ls); return ls. def _convert_to_json(self, x):; return [self.element_type._convert_to_json_na(elt) for elt in x]. def _propagate_jtypes(self, jtype):; self._element_type._add_jtype(jtype.elementType()). def unify(self, t):; return isinstance(t, tarray) and self.element_type.unify(t.element_type). def subst(self):; return tarray(self.element_type.subst()). def clear(self):; self.element_type.clear(). def _get_context(self):; return self.element_type.get_context(). def _convert_from_encoding(self, byte_reader, _should_freeze: bool = False) -> Union[list, frozenlist]:; length = byte_reader.read_int32(). num_missing_bytes = math.ceil(length / 8); missing_bytes = byte_reader.read_bytes_view(num_missing_bytes). decoded = []; i = 0; current_missing_byte = None; while i < length:; which_missing_bit = i % 8; if which_missing_bit == 0:; current_missing_byte = missing_bytes[i // 8]. if lookup_bit(current_missing_byte, which_missing_bit):; decoded.append(None); else:; element_decoded = self.element_type._convert_from_encoding(byte_reader, _should_freeze); decoded.append(element_decoded); i += 1; if _should_freeze:; return frozenlist(decoded); return decoded. def _convert_to_encoding(self, byte_writer: ByteWriter, value):; length = len(value); byte_writer.write_int32(length); i = 0; while i < length:; missing_byte = 0; for j in range(min(8, length - i)):; if HailType._missing(value[i + j]",MatchSource.WIKI,docs/0.2/_modules/hail/expr/types.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html
https://hail.is/docs/0.2/_modules/hail/expr/types.html:22907,Usability,clear,clear,22907,"s not realizable in Python""). def __str__(self):; return ""stream<{}>"".format(self.element_type). def _eq(self, other):; return isinstance(other, tstream) and self.element_type == other.element_type. def _pretty(self, b, indent, increment):; b.append('stream<'); self.element_type._pretty(b, indent, increment); b.append('>'). def _parsable_string(self):; return ""Stream["" + self.element_type._parsable_string() + ""]"". def _convert_from_json(self, x, _should_freeze: bool = False) -> Union[list, frozenlist]:; ls = [self.element_type._convert_from_json_na(elt, _should_freeze) for elt in x]; if _should_freeze:; return frozenlist(ls); return ls. def _convert_to_json(self, x):; return [self.element_type._convert_to_json_na(elt) for elt in x]. def _propagate_jtypes(self, jtype):; self._element_type._add_jtype(jtype.elementType()). def unify(self, t):; return isinstance(t, tstream) and self.element_type.unify(t.element_type). def subst(self):; return tstream(self.element_type.subst()). def clear(self):; self.element_type.clear(). def _get_context(self):; return self.element_type.get_context(). def is_setlike(maybe_setlike):; return isinstance(maybe_setlike, (set, frozenset)). [docs]class tset(HailType):; """"""Hail type for collections of distinct elements. In Python, these are represented as :obj:`set`. Notes; -----; Sets contain elements of only one type, which is parameterized by; `element_type`. Parameters; ----------; element_type : :class:`.HailType`; Element type of set. See Also; --------; :class:`.SetExpression`, :class:`.CollectionExpression`,; :func:`.set`, :ref:`sec-collection-functions`; """""". @typecheck_method(element_type=hail_type); def __init__(self, element_type):; self._element_type = element_type; self._array_repr = tarray(element_type); super(tset, self).__init__(). @property; def element_type(self):; """"""Set element type. Returns; -------; :class:`.HailType`; Element type.; """"""; return self._element_type. def _traverse(self, obj, f):; if f(self, obj):; for elt ",MatchSource.WIKI,docs/0.2/_modules/hail/expr/types.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html
https://hail.is/docs/0.2/_modules/hail/expr/types.html:22939,Usability,clear,clear,22939," def __str__(self):; return ""stream<{}>"".format(self.element_type). def _eq(self, other):; return isinstance(other, tstream) and self.element_type == other.element_type. def _pretty(self, b, indent, increment):; b.append('stream<'); self.element_type._pretty(b, indent, increment); b.append('>'). def _parsable_string(self):; return ""Stream["" + self.element_type._parsable_string() + ""]"". def _convert_from_json(self, x, _should_freeze: bool = False) -> Union[list, frozenlist]:; ls = [self.element_type._convert_from_json_na(elt, _should_freeze) for elt in x]; if _should_freeze:; return frozenlist(ls); return ls. def _convert_to_json(self, x):; return [self.element_type._convert_to_json_na(elt) for elt in x]. def _propagate_jtypes(self, jtype):; self._element_type._add_jtype(jtype.elementType()). def unify(self, t):; return isinstance(t, tstream) and self.element_type.unify(t.element_type). def subst(self):; return tstream(self.element_type.subst()). def clear(self):; self.element_type.clear(). def _get_context(self):; return self.element_type.get_context(). def is_setlike(maybe_setlike):; return isinstance(maybe_setlike, (set, frozenset)). [docs]class tset(HailType):; """"""Hail type for collections of distinct elements. In Python, these are represented as :obj:`set`. Notes; -----; Sets contain elements of only one type, which is parameterized by; `element_type`. Parameters; ----------; element_type : :class:`.HailType`; Element type of set. See Also; --------; :class:`.SetExpression`, :class:`.CollectionExpression`,; :func:`.set`, :ref:`sec-collection-functions`; """""". @typecheck_method(element_type=hail_type); def __init__(self, element_type):; self._element_type = element_type; self._array_repr = tarray(element_type); super(tset, self).__init__(). @property; def element_type(self):; """"""Set element type. Returns; -------; :class:`.HailType`; Element type.; """"""; return self._element_type. def _traverse(self, obj, f):; if f(self, obj):; for elt in obj:; self.element_type._t",MatchSource.WIKI,docs/0.2/_modules/hail/expr/types.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html
https://hail.is/docs/0.2/_modules/hail/expr/types.html:25470,Usability,clear,clear,25470,"urn ""Set["" + self.element_type._parsable_string() + ""]"". def _convert_from_json(self, x, _should_freeze: bool = False) -> Union[set, frozenset]:; s = {self.element_type._convert_from_json_na(elt, _should_freeze=True) for elt in x}; if _should_freeze:; return frozenset(s); return s. def _convert_to_json(self, x):; return [self.element_type._convert_to_json_na(elt) for elt in x]. def _convert_from_encoding(self, byte_reader, _should_freeze: bool = False) -> Union[set, frozenset]:; s = self._array_repr._convert_from_encoding(byte_reader, _should_freeze=True); if _should_freeze:; return frozenset(s); return set(s). def _convert_to_encoding(self, byte_writer: ByteWriter, value):; self._array_repr._convert_to_encoding(byte_writer, list(value)). def _propagate_jtypes(self, jtype):; self._element_type._add_jtype(jtype.elementType()). def unify(self, t):; return isinstance(t, tset) and self.element_type.unify(t.element_type). def subst(self):; return tset(self.element_type.subst()). def clear(self):; self.element_type.clear(). def _get_context(self):; return self.element_type.get_context(). class _freeze_this_type(HailType):; def __init__(self, t):; self.t = t. def _convert_from_json_na(self, x, _should_freeze: bool = False):; return self.t._convert_from_json_na(x, _should_freeze=True). def _convert_from_encoding(self, byte_reader, _should_freeze: bool = False):; return self.t._convert_from_encoding(byte_reader, _should_freeze=True). def _convert_to_encoding(self, byte_writer, x):; return self.t._convert_to_encoding(byte_writer, x). [docs]class tdict(HailType):; """"""Hail type for key-value maps. In Python, these are represented as :obj:`dict`. Notes; -----; Dicts parameterize the type of both their keys and values with; `key_type` and `value_type`. Parameters; ----------; key_type: :class:`.HailType`; Key type.; value_type: :class:`.HailType`; Value type. See Also; --------; :class:`.DictExpression`, :func:`.dict`, :ref:`sec-collection-functions`; """""". @typecheck_method(key_t",MatchSource.WIKI,docs/0.2/_modules/hail/expr/types.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html
https://hail.is/docs/0.2/_modules/hail/expr/types.html:25502,Usability,clear,clear,25502,"e._parsable_string() + ""]"". def _convert_from_json(self, x, _should_freeze: bool = False) -> Union[set, frozenset]:; s = {self.element_type._convert_from_json_na(elt, _should_freeze=True) for elt in x}; if _should_freeze:; return frozenset(s); return s. def _convert_to_json(self, x):; return [self.element_type._convert_to_json_na(elt) for elt in x]. def _convert_from_encoding(self, byte_reader, _should_freeze: bool = False) -> Union[set, frozenset]:; s = self._array_repr._convert_from_encoding(byte_reader, _should_freeze=True); if _should_freeze:; return frozenset(s); return set(s). def _convert_to_encoding(self, byte_writer: ByteWriter, value):; self._array_repr._convert_to_encoding(byte_writer, list(value)). def _propagate_jtypes(self, jtype):; self._element_type._add_jtype(jtype.elementType()). def unify(self, t):; return isinstance(t, tset) and self.element_type.unify(t.element_type). def subst(self):; return tset(self.element_type.subst()). def clear(self):; self.element_type.clear(). def _get_context(self):; return self.element_type.get_context(). class _freeze_this_type(HailType):; def __init__(self, t):; self.t = t. def _convert_from_json_na(self, x, _should_freeze: bool = False):; return self.t._convert_from_json_na(x, _should_freeze=True). def _convert_from_encoding(self, byte_reader, _should_freeze: bool = False):; return self.t._convert_from_encoding(byte_reader, _should_freeze=True). def _convert_to_encoding(self, byte_writer, x):; return self.t._convert_to_encoding(byte_writer, x). [docs]class tdict(HailType):; """"""Hail type for key-value maps. In Python, these are represented as :obj:`dict`. Notes; -----; Dicts parameterize the type of both their keys and values with; `key_type` and `value_type`. Parameters; ----------; key_type: :class:`.HailType`; Key type.; value_type: :class:`.HailType`; Value type. See Also; --------; :class:`.DictExpression`, :func:`.dict`, :ref:`sec-collection-functions`; """""". @typecheck_method(key_type=hail_type, value_type=hai",MatchSource.WIKI,docs/0.2/_modules/hail/expr/types.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html
https://hail.is/docs/0.2/_modules/hail/expr/types.html:29471,Usability,clear,clear,29471,"self, byte_reader, _should_freeze: bool = False) -> Union[dict, frozendict]:; # NB: We ensure the key is always frozen with a wrapper on the key_type in the _array_repr.; d = {}; length = byte_reader.read_int32(); for _ in range(length):; element = self._array_repr.element_type._convert_from_encoding(byte_reader, _should_freeze); d[element.key] = element.value. if _should_freeze:; return frozendict(d); return d. def _convert_to_encoding(self, byte_writer: ByteWriter, value):; length = len(value); byte_writer.write_int32(length); for k, v in value.items():; self._array_repr.element_type._convert_to_encoding(byte_writer, {'key': k, 'value': v}). def _propagate_jtypes(self, jtype):; self._key_type._add_jtype(jtype.keyType()); self._value_type._add_jtype(jtype.valueType()). def unify(self, t):; return isinstance(t, tdict) and self.key_type.unify(t.key_type) and self.value_type.unify(t.value_type). def subst(self):; return tdict(self._key_type.subst(), self._value_type.subst()). def clear(self):; self.key_type.clear(); self.value_type.clear(). def _get_context(self):; return HailTypeContext.union(self.key_type, self.value_type). [docs]class tstruct(HailType, Mapping):; """"""Hail type for structured groups of heterogeneous fields. In Python, these are represented as :class:`.Struct`. Hail's :class:`.tstruct` type is commonly used to compose types together to form nested; structures. Structs can contain any combination of types, and are ordered mappings; from field name to field type. Each field name must be unique. Structs are very common in Hail. Each component of a :class:`.Table` and :class:`.MatrixTable`; is a struct:. - :meth:`.Table.row`; - :meth:`.Table.globals`; - :meth:`.MatrixTable.row`; - :meth:`.MatrixTable.col`; - :meth:`.MatrixTable.entry`; - :meth:`.MatrixTable.globals`. Structs appear below the top-level component types as well. Consider the following join:. >>> new_table = table1.annotate(table2_fields = table2.index(table1.key)). This snippet adds a field ",MatchSource.WIKI,docs/0.2/_modules/hail/expr/types.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html
https://hail.is/docs/0.2/_modules/hail/expr/types.html:29499,Usability,clear,clear,29499,"reeze: bool = False) -> Union[dict, frozendict]:; # NB: We ensure the key is always frozen with a wrapper on the key_type in the _array_repr.; d = {}; length = byte_reader.read_int32(); for _ in range(length):; element = self._array_repr.element_type._convert_from_encoding(byte_reader, _should_freeze); d[element.key] = element.value. if _should_freeze:; return frozendict(d); return d. def _convert_to_encoding(self, byte_writer: ByteWriter, value):; length = len(value); byte_writer.write_int32(length); for k, v in value.items():; self._array_repr.element_type._convert_to_encoding(byte_writer, {'key': k, 'value': v}). def _propagate_jtypes(self, jtype):; self._key_type._add_jtype(jtype.keyType()); self._value_type._add_jtype(jtype.valueType()). def unify(self, t):; return isinstance(t, tdict) and self.key_type.unify(t.key_type) and self.value_type.unify(t.value_type). def subst(self):; return tdict(self._key_type.subst(), self._value_type.subst()). def clear(self):; self.key_type.clear(); self.value_type.clear(). def _get_context(self):; return HailTypeContext.union(self.key_type, self.value_type). [docs]class tstruct(HailType, Mapping):; """"""Hail type for structured groups of heterogeneous fields. In Python, these are represented as :class:`.Struct`. Hail's :class:`.tstruct` type is commonly used to compose types together to form nested; structures. Structs can contain any combination of types, and are ordered mappings; from field name to field type. Each field name must be unique. Structs are very common in Hail. Each component of a :class:`.Table` and :class:`.MatrixTable`; is a struct:. - :meth:`.Table.row`; - :meth:`.Table.globals`; - :meth:`.MatrixTable.row`; - :meth:`.MatrixTable.col`; - :meth:`.MatrixTable.entry`; - :meth:`.MatrixTable.globals`. Structs appear below the top-level component types as well. Consider the following join:. >>> new_table = table1.annotate(table2_fields = table2.index(table1.key)). This snippet adds a field to ``table1`` called ``table",MatchSource.WIKI,docs/0.2/_modules/hail/expr/types.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html
https://hail.is/docs/0.2/_modules/hail/expr/types.html:29524,Usability,clear,clear,29524,"> Union[dict, frozendict]:; # NB: We ensure the key is always frozen with a wrapper on the key_type in the _array_repr.; d = {}; length = byte_reader.read_int32(); for _ in range(length):; element = self._array_repr.element_type._convert_from_encoding(byte_reader, _should_freeze); d[element.key] = element.value. if _should_freeze:; return frozendict(d); return d. def _convert_to_encoding(self, byte_writer: ByteWriter, value):; length = len(value); byte_writer.write_int32(length); for k, v in value.items():; self._array_repr.element_type._convert_to_encoding(byte_writer, {'key': k, 'value': v}). def _propagate_jtypes(self, jtype):; self._key_type._add_jtype(jtype.keyType()); self._value_type._add_jtype(jtype.valueType()). def unify(self, t):; return isinstance(t, tdict) and self.key_type.unify(t.key_type) and self.value_type.unify(t.value_type). def subst(self):; return tdict(self._key_type.subst(), self._value_type.subst()). def clear(self):; self.key_type.clear(); self.value_type.clear(). def _get_context(self):; return HailTypeContext.union(self.key_type, self.value_type). [docs]class tstruct(HailType, Mapping):; """"""Hail type for structured groups of heterogeneous fields. In Python, these are represented as :class:`.Struct`. Hail's :class:`.tstruct` type is commonly used to compose types together to form nested; structures. Structs can contain any combination of types, and are ordered mappings; from field name to field type. Each field name must be unique. Structs are very common in Hail. Each component of a :class:`.Table` and :class:`.MatrixTable`; is a struct:. - :meth:`.Table.row`; - :meth:`.Table.globals`; - :meth:`.MatrixTable.row`; - :meth:`.MatrixTable.col`; - :meth:`.MatrixTable.entry`; - :meth:`.MatrixTable.globals`. Structs appear below the top-level component types as well. Consider the following join:. >>> new_table = table1.annotate(table2_fields = table2.index(table1.key)). This snippet adds a field to ``table1`` called ``table2_fields``. In the new",MatchSource.WIKI,docs/0.2/_modules/hail/expr/types.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html
https://hail.is/docs/0.2/_modules/hail/expr/types.html:36223,Usability,clear,clear,36223,"); new_field_types.update(new_fields); return tstruct(**new_field_types). def _drop_fields(self, fields):; return tstruct(**{f: t for f, t in self.items() if f not in fields}). def _select_fields(self, fields):; return tstruct(**{f: self[f] for f in fields}). def _index_path(self, path):; t = self; for p in path:; t = t[p]; return t. def _rename(self, map):; seen = {}; new_field_types = {}. for f0, t in self.items():; f = map.get(f0, f0); if f in seen:; raise ValueError(; ""Cannot rename two fields to the same name: attempted to rename {} and {} both to {}"".format(; repr(seen[f]), repr(f0), repr(f); ); ); else:; seen[f] = f0; new_field_types[f] = t. return tstruct(**new_field_types). def unify(self, t):; if not (isinstance(t, tstruct) and len(self) == len(t)):; return False; for (f1, t1), (f2, t2) in zip(self.items(), t.items()):; if not (f1 == f2 and t1.unify(t2)):; return False; return True. def subst(self):; return tstruct(**{f: t.subst() for f, t in self.items()}). def clear(self):; for f, t in self.items():; t.clear(). def _get_context(self):; return HailTypeContext.union(*self.values()). class tunion(HailType, Mapping):; @typecheck_method(case_types=hail_type); def __init__(self, **case_types):; """"""Tagged union type. Values of type union represent one of several; heterogenous, named cases. Parameters; ----------; cases : keyword args of :class:`.HailType`; The union cases. """""". super(tunion, self).__init__(); self._case_types = case_types; self._cases = tuple(case_types). @property; def cases(self):; """"""Return union case names. Returns; -------; :obj:`tuple` of :class:`str`; Tuple of union case names; """"""; return self._cases. @typecheck_method(item=oneof(int, str)); def __getitem__(self, item):; if isinstance(item, int):; item = self._cases[item]; return self._case_types[item]. def __iter__(self):; return iter(self._case_types). def __len__(self):; return len(self._cases). def __str__(self):; return ""union{{{}}}"".format(', '.join('{}: {}'.format(escape_parsable",MatchSource.WIKI,docs/0.2/_modules/hail/expr/types.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html
https://hail.is/docs/0.2/_modules/hail/expr/types.html:36266,Usability,clear,clear,36266,"ds); return tstruct(**new_field_types). def _drop_fields(self, fields):; return tstruct(**{f: t for f, t in self.items() if f not in fields}). def _select_fields(self, fields):; return tstruct(**{f: self[f] for f in fields}). def _index_path(self, path):; t = self; for p in path:; t = t[p]; return t. def _rename(self, map):; seen = {}; new_field_types = {}. for f0, t in self.items():; f = map.get(f0, f0); if f in seen:; raise ValueError(; ""Cannot rename two fields to the same name: attempted to rename {} and {} both to {}"".format(; repr(seen[f]), repr(f0), repr(f); ); ); else:; seen[f] = f0; new_field_types[f] = t. return tstruct(**new_field_types). def unify(self, t):; if not (isinstance(t, tstruct) and len(self) == len(t)):; return False; for (f1, t1), (f2, t2) in zip(self.items(), t.items()):; if not (f1 == f2 and t1.unify(t2)):; return False; return True. def subst(self):; return tstruct(**{f: t.subst() for f, t in self.items()}). def clear(self):; for f, t in self.items():; t.clear(). def _get_context(self):; return HailTypeContext.union(*self.values()). class tunion(HailType, Mapping):; @typecheck_method(case_types=hail_type); def __init__(self, **case_types):; """"""Tagged union type. Values of type union represent one of several; heterogenous, named cases. Parameters; ----------; cases : keyword args of :class:`.HailType`; The union cases. """""". super(tunion, self).__init__(); self._case_types = case_types; self._cases = tuple(case_types). @property; def cases(self):; """"""Return union case names. Returns; -------; :obj:`tuple` of :class:`str`; Tuple of union case names; """"""; return self._cases. @typecheck_method(item=oneof(int, str)); def __getitem__(self, item):; if isinstance(item, int):; item = self._cases[item]; return self._case_types[item]. def __iter__(self):; return iter(self._case_types). def __len__(self):; return len(self._cases). def __str__(self):; return ""union{{{}}}"".format(', '.join('{}: {}'.format(escape_parsable(f), str(t)) for f, t in self.item",MatchSource.WIKI,docs/0.2/_modules/hail/expr/types.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html
https://hail.is/docs/0.2/_modules/hail/expr/types.html:38273,Usability,clear,clear,38273,"elf, other):; return (; isinstance(other, tunion) and self._cases == other._cases and all(self[c] == other[c] for c in self._cases); ). def _pretty(self, b, indent, increment):; if not self._cases:; b.append('union {}'); return. pre_indent = indent; indent += increment; b.append('union {'); for i, (f, t) in enumerate(self.items()):; if i > 0:; b.append(', '); b.append('\n'); b.append(' ' * indent); b.append('{}: '.format(escape_parsable(f))); t._pretty(b, indent, increment); b.append('\n'); b.append(' ' * pre_indent); b.append('}'). def _parsable_string(self):; return ""Union{{{}}}"".format(; ','.join('{}:{}'.format(escape_parsable(f), t._parsable_string()) for f, t in self.items()); ). def unify(self, t):; if not (isinstance(t, tunion) and len(self) == len(t)):; return False; for (f1, t1), (f2, t2) in zip(self.items(), t.items()):; if not (f1 == f2 and t1.unify(t2)):; return False; return True. def subst(self):; return tunion(**{f: t.subst() for f, t in self.items()}). def clear(self):; for f, t in self.items():; t.clear(). def _get_context(self):; return HailTypeContext.union(*self.values()). [docs]class ttuple(HailType, Sequence):; """"""Hail type for tuples. In Python, these are represented as :obj:`tuple`. Parameters; ----------; types: varargs of :class:`.HailType`; Element types. See Also; --------; :class:`.TupleExpression`; """""". @typecheck_method(types=hail_type); def __init__(self, *types):; self._types = types; super(ttuple, self).__init__(). @property; def types(self):; """"""Tuple element types. Returns; -------; :obj:`tuple` of :class:`.HailType`; """"""; return self._types. def _traverse(self, obj, f):; if f(self, obj):; for t, elt in zip(self.types, obj):; t._traverse(elt, f). def _typecheck_one_level(self, annotation):; if annotation:; if not isinstance(annotation, tuple):; raise TypeError(""type 'tuple' expected Python tuple, but found '%s'"" % type(annotation)); if len(annotation) != len(self.types):; raise TypeError(""%s expected tuple of size '%i', but found ",MatchSource.WIKI,docs/0.2/_modules/hail/expr/types.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html
https://hail.is/docs/0.2/_modules/hail/expr/types.html:38316,Usability,clear,clear,38316,"(other, tunion) and self._cases == other._cases and all(self[c] == other[c] for c in self._cases); ). def _pretty(self, b, indent, increment):; if not self._cases:; b.append('union {}'); return. pre_indent = indent; indent += increment; b.append('union {'); for i, (f, t) in enumerate(self.items()):; if i > 0:; b.append(', '); b.append('\n'); b.append(' ' * indent); b.append('{}: '.format(escape_parsable(f))); t._pretty(b, indent, increment); b.append('\n'); b.append(' ' * pre_indent); b.append('}'). def _parsable_string(self):; return ""Union{{{}}}"".format(; ','.join('{}:{}'.format(escape_parsable(f), t._parsable_string()) for f, t in self.items()); ). def unify(self, t):; if not (isinstance(t, tunion) and len(self) == len(t)):; return False; for (f1, t1), (f2, t2) in zip(self.items(), t.items()):; if not (f1 == f2 and t1.unify(t2)):; return False; return True. def subst(self):; return tunion(**{f: t.subst() for f, t in self.items()}). def clear(self):; for f, t in self.items():; t.clear(). def _get_context(self):; return HailTypeContext.union(*self.values()). [docs]class ttuple(HailType, Sequence):; """"""Hail type for tuples. In Python, these are represented as :obj:`tuple`. Parameters; ----------; types: varargs of :class:`.HailType`; Element types. See Also; --------; :class:`.TupleExpression`; """""". @typecheck_method(types=hail_type); def __init__(self, *types):; self._types = types; super(ttuple, self).__init__(). @property; def types(self):; """"""Tuple element types. Returns; -------; :obj:`tuple` of :class:`.HailType`; """"""; return self._types. def _traverse(self, obj, f):; if f(self, obj):; for t, elt in zip(self.types, obj):; t._traverse(elt, f). def _typecheck_one_level(self, annotation):; if annotation:; if not isinstance(annotation, tuple):; raise TypeError(""type 'tuple' expected Python tuple, but found '%s'"" % type(annotation)); if len(annotation) != len(self.types):; raise TypeError(""%s expected tuple of size '%i', but found '%s'"" % (self, len(self.types), an",MatchSource.WIKI,docs/0.2/_modules/hail/expr/types.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html
https://hail.is/docs/0.2/_modules/hail/expr/types.html:41716,Usability,clear,clear,41716,"r i, t in enumerate(self.types):; which_missing_bit = i % 8; if which_missing_bit == 0:; current_missing_byte = missing_bytes[i // 8]. if lookup_bit(current_missing_byte, which_missing_bit):; answer.append(None); else:; field_decoded = t._convert_from_encoding(byte_reader, _should_freeze); answer.append(field_decoded). return tuple(answer). def _convert_to_encoding(self, byte_writer, value):; length = len(self); i = 0; while i < length:; missing_byte = 0; for j in range(min(8, length - i)):; if HailType._missing(value[i + j]):; missing_byte |= 1 << j; byte_writer.write_byte(missing_byte); i += 8; for i, t in enumerate(self.types):; if not HailType._missing(value[i]):; t._convert_to_encoding(byte_writer, value[i]). def unify(self, t):; if not (isinstance(t, ttuple) and len(self.types) == len(t.types)):; return False; for t1, t2 in zip(self.types, t.types):; if not t1.unify(t2):; return False; return True. def subst(self):; return ttuple(*[t.subst() for t in self.types]). def clear(self):; for t in self.types:; t.clear(). def _get_context(self):; return HailTypeContext.union(*self.types). def allele_pair(j: int, k: int):; assert j >= 0 and j <= 0xFFFF; assert k >= 0 and k <= 0xFFFF; return j | (k << 16). def allele_pair_sqrt(i):; k = int(math.sqrt(8 * float(i) + 1) / 2 - 0.5); assert k * (k + 1) // 2 <= i; j = i - k * (k + 1) // 2; # TODO another assert; return allele_pair(j, k). small_allele_pair = [; allele_pair(0, 0),; allele_pair(0, 1),; allele_pair(1, 1),; allele_pair(0, 2),; allele_pair(1, 2),; allele_pair(2, 2),; allele_pair(0, 3),; allele_pair(1, 3),; allele_pair(2, 3),; allele_pair(3, 3),; allele_pair(0, 4),; allele_pair(1, 4),; allele_pair(2, 4),; allele_pair(3, 4),; allele_pair(4, 4),; allele_pair(0, 5),; allele_pair(1, 5),; allele_pair(2, 5),; allele_pair(3, 5),; allele_pair(4, 5),; allele_pair(5, 5),; allele_pair(0, 6),; allele_pair(1, 6),; allele_pair(2, 6),; allele_pair(3, 6),; allele_pair(4, 6),; allele_pair(5, 6),; allele_pair(6, 6),; allele_pair(0, 7)",MatchSource.WIKI,docs/0.2/_modules/hail/expr/types.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html
https://hail.is/docs/0.2/_modules/hail/expr/types.html:41754,Usability,clear,clear,41754,":; which_missing_bit = i % 8; if which_missing_bit == 0:; current_missing_byte = missing_bytes[i // 8]. if lookup_bit(current_missing_byte, which_missing_bit):; answer.append(None); else:; field_decoded = t._convert_from_encoding(byte_reader, _should_freeze); answer.append(field_decoded). return tuple(answer). def _convert_to_encoding(self, byte_writer, value):; length = len(self); i = 0; while i < length:; missing_byte = 0; for j in range(min(8, length - i)):; if HailType._missing(value[i + j]):; missing_byte |= 1 << j; byte_writer.write_byte(missing_byte); i += 8; for i, t in enumerate(self.types):; if not HailType._missing(value[i]):; t._convert_to_encoding(byte_writer, value[i]). def unify(self, t):; if not (isinstance(t, ttuple) and len(self.types) == len(t.types)):; return False; for t1, t2 in zip(self.types, t.types):; if not t1.unify(t2):; return False; return True. def subst(self):; return ttuple(*[t.subst() for t in self.types]). def clear(self):; for t in self.types:; t.clear(). def _get_context(self):; return HailTypeContext.union(*self.types). def allele_pair(j: int, k: int):; assert j >= 0 and j <= 0xFFFF; assert k >= 0 and k <= 0xFFFF; return j | (k << 16). def allele_pair_sqrt(i):; k = int(math.sqrt(8 * float(i) + 1) / 2 - 0.5); assert k * (k + 1) // 2 <= i; j = i - k * (k + 1) // 2; # TODO another assert; return allele_pair(j, k). small_allele_pair = [; allele_pair(0, 0),; allele_pair(0, 1),; allele_pair(1, 1),; allele_pair(0, 2),; allele_pair(1, 2),; allele_pair(2, 2),; allele_pair(0, 3),; allele_pair(1, 3),; allele_pair(2, 3),; allele_pair(3, 3),; allele_pair(0, 4),; allele_pair(1, 4),; allele_pair(2, 4),; allele_pair(3, 4),; allele_pair(4, 4),; allele_pair(0, 5),; allele_pair(1, 5),; allele_pair(2, 5),; allele_pair(3, 5),; allele_pair(4, 5),; allele_pair(5, 5),; allele_pair(0, 6),; allele_pair(1, 6),; allele_pair(2, 6),; allele_pair(3, 6),; allele_pair(4, 6),; allele_pair(5, 6),; allele_pair(6, 6),; allele_pair(0, 7),; allele_pair(1, 7),; allele_",MatchSource.WIKI,docs/0.2/_modules/hail/expr/types.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html
https://hail.is/docs/0.2/_modules/hail/expr/types.html:45551,Usability,clear,clear,45551,"; rep = allele_repr(i); return gt_allele_pair(rep). if ploidy == 0:; alleles = []; elif ploidy == 1:; alleles = [allele_repr(int_rep)]; elif ploidy == 2:; p = call_allele_pair(int_rep); alleles = [ap_j(p), ap_k(p)]; else:; raise ValueError(""Unsupported Ploidy""). return genetics.Call(alleles, phased). def _convert_to_encoding(self, byte_writer, value: genetics.Call):; int_rep = 0. int_rep |= value.ploidy << 1; if value.phased:; int_rep |= 1. def diploid_gt_index(j: int, k: int):; assert j <= k; return k * (k + 1) // 2 + j. def allele_pair_rep(c: genetics.Call):; [j, k] = c.alleles; if c.phased:; return diploid_gt_index(j, j + k); return diploid_gt_index(j, k). assert value.ploidy <= 2; if value.ploidy == 1:; int_rep |= value.alleles[0] << 3; elif value.ploidy == 2:; int_rep |= allele_pair_rep(value) << 3; int_rep = int_rep if 0 <= int_rep < 2**31 - 1 else int_rep - 2**32. byte_writer.write_int32(int_rep). def unify(self, t):; return t == tcall. def subst(self):; return self. def clear(self):; pass. [docs]class tlocus(HailType):; """"""Hail type for a genomic coordinate with a contig and a position. In Python, these are represented by :class:`.Locus`. Parameters; ----------; reference_genome: :class:`.ReferenceGenome` or :class:`str`; Reference genome to use. See Also; --------; :class:`.LocusExpression`, :func:`.locus`, :func:`.parse_locus`,; :class:`.Locus`; """""". struct_repr = tstruct(contig=_tstr(), pos=_tint32()). @classmethod; @typecheck_method(reference_genome=nullable(reference_genome_type)); def _schema_from_rg(cls, reference_genome='default'):; # must match TLocus.schemaFromRG; if reference_genome is None:; return hl.tstruct(contig=hl.tstr, position=hl.tint32); return cls(reference_genome). @typecheck_method(reference_genome=reference_genome_type); def __init__(self, reference_genome='default'):; self._rg = reference_genome; super(tlocus, self).__init__(). def _typecheck_one_level(self, annotation):; if annotation is not None:; if not isinstance(annotation, gene",MatchSource.WIKI,docs/0.2/_modules/hail/expr/types.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html
https://hail.is/docs/0.2/_modules/hail/expr/types.html:48310,Usability,clear,clear,48310,"lf._rg is None:; self._rg = hl.default_reference(); return self._rg. def _pretty(self, b, indent, increment):; b.append('locus<{}>'.format(escape_parsable(self.reference_genome.name))). def _convert_from_json(self, x, _should_freeze: bool = False) -> genetics.Locus:; return genetics.Locus(x['contig'], x['position'], reference_genome=self.reference_genome). def _convert_to_json(self, x):; return {'contig': x.contig, 'position': x.position}. def _convert_from_encoding(self, byte_reader, _should_freeze: bool = False) -> genetics.Locus:; as_struct = tlocus.struct_repr._convert_from_encoding(byte_reader); return genetics.Locus(as_struct.contig, as_struct.pos, self.reference_genome). def _convert_to_encoding(self, byte_writer, value: genetics.Locus):; tlocus.struct_repr._convert_to_encoding(byte_writer, {'contig': value.contig, 'pos': value.position}). def unify(self, t):; return isinstance(t, tlocus) and self.reference_genome == t.reference_genome. def subst(self):; return self. def clear(self):; pass. def _get_context(self):; return HailTypeContext(references={self.reference_genome.name}). [docs]class tinterval(HailType):; """"""Hail type for intervals of ordered values. In Python, these are represented by :class:`.Interval`. Parameters; ----------; point_type: :class:`.HailType`; Interval point type. See Also; --------; :class:`.IntervalExpression`, :class:`.Interval`, :func:`.interval`,; :func:`.parse_locus_interval`; """""". @typecheck_method(point_type=hail_type); def __init__(self, point_type):; self._point_type = point_type; self._struct_repr = tstruct(start=point_type, end=point_type, includes_start=hl.tbool, includes_end=hl.tbool); super(tinterval, self).__init__(). @property; def point_type(self):; """"""Interval point type. Returns; -------; :class:`.HailType`; Interval point type.; """"""; return self._point_type. def _traverse(self, obj, f):; if f(self, obj):; self.point_type._traverse(obj.start, f); self.point_type._traverse(obj.end, f). def _typecheck_one_level(self, ",MatchSource.WIKI,docs/0.2/_modules/hail/expr/types.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html
https://hail.is/docs/0.2/_modules/hail/expr/types.html:51410,Usability,clear,clear,51410,"e,; ). def _convert_to_json(self, x):; return {; 'start': self.point_type._convert_to_json_na(x.start),; 'end': self.point_type._convert_to_json_na(x.end),; 'includeStart': x.includes_start,; 'includeEnd': x.includes_end,; }. def _convert_from_encoding(self, byte_reader, _should_freeze: bool = False):; interval_as_struct = self._struct_repr._convert_from_encoding(byte_reader, _should_freeze); return hl.Interval(; interval_as_struct.start,; interval_as_struct.end,; interval_as_struct.includes_start,; interval_as_struct.includes_end,; point_type=self.point_type,; ). def _convert_to_encoding(self, byte_writer, value):; interval_dict = {; 'start': value.start,; 'end': value.end,; 'includes_start': value.includes_start,; 'includes_end': value.includes_end,; }; self._struct_repr._convert_to_encoding(byte_writer, interval_dict). def unify(self, t):; return isinstance(t, tinterval) and self.point_type.unify(t.point_type). def subst(self):; return tinterval(self.point_type.subst()). def clear(self):; self.point_type.clear(). def _get_context(self):; return self.point_type.get_context(). class Box(object):; named_boxes: ClassVar = {}. @staticmethod; def from_name(name):; if name in Box.named_boxes:; return Box.named_boxes[name]; b = Box(); Box.named_boxes[name] = b; return b. def __init__(self):; pass. def unify(self, v):; if hasattr(self, 'value'):; return self.value == v; self.value = v; return True. def clear(self):; if hasattr(self, 'value'):; del self.value. def get(self):; assert hasattr(self, 'value'); return self.value. tvoid = _tvoid(). tint32 = _tint32(); """"""Hail type for signed 32-bit integers. Their values can range from :math:`-2^{31}` to :math:`2^{31} - 1`; (approximately 2.15 billion). In Python, these are represented as :obj:`int`. See Also; --------; :class:`.Int32Expression`, :func:`.int`, :func:`.int32`; """""". tint64 = _tint64(); """"""Hail type for signed 64-bit integers. Their values can range from :math:`-2^{63}` to :math:`2^{63} - 1`. In Python, these are r",MatchSource.WIKI,docs/0.2/_modules/hail/expr/types.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html
https://hail.is/docs/0.2/_modules/hail/expr/types.html:51440,Usability,clear,clear,51440,"(self, x):; return {; 'start': self.point_type._convert_to_json_na(x.start),; 'end': self.point_type._convert_to_json_na(x.end),; 'includeStart': x.includes_start,; 'includeEnd': x.includes_end,; }. def _convert_from_encoding(self, byte_reader, _should_freeze: bool = False):; interval_as_struct = self._struct_repr._convert_from_encoding(byte_reader, _should_freeze); return hl.Interval(; interval_as_struct.start,; interval_as_struct.end,; interval_as_struct.includes_start,; interval_as_struct.includes_end,; point_type=self.point_type,; ). def _convert_to_encoding(self, byte_writer, value):; interval_dict = {; 'start': value.start,; 'end': value.end,; 'includes_start': value.includes_start,; 'includes_end': value.includes_end,; }; self._struct_repr._convert_to_encoding(byte_writer, interval_dict). def unify(self, t):; return isinstance(t, tinterval) and self.point_type.unify(t.point_type). def subst(self):; return tinterval(self.point_type.subst()). def clear(self):; self.point_type.clear(). def _get_context(self):; return self.point_type.get_context(). class Box(object):; named_boxes: ClassVar = {}. @staticmethod; def from_name(name):; if name in Box.named_boxes:; return Box.named_boxes[name]; b = Box(); Box.named_boxes[name] = b; return b. def __init__(self):; pass. def unify(self, v):; if hasattr(self, 'value'):; return self.value == v; self.value = v; return True. def clear(self):; if hasattr(self, 'value'):; del self.value. def get(self):; assert hasattr(self, 'value'); return self.value. tvoid = _tvoid(). tint32 = _tint32(); """"""Hail type for signed 32-bit integers. Their values can range from :math:`-2^{31}` to :math:`2^{31} - 1`; (approximately 2.15 billion). In Python, these are represented as :obj:`int`. See Also; --------; :class:`.Int32Expression`, :func:`.int`, :func:`.int32`; """""". tint64 = _tint64(); """"""Hail type for signed 64-bit integers. Their values can range from :math:`-2^{63}` to :math:`2^{63} - 1`. In Python, these are represented as :obj:`int`. S",MatchSource.WIKI,docs/0.2/_modules/hail/expr/types.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html
https://hail.is/docs/0.2/_modules/hail/expr/types.html:51837,Usability,clear,clear,51837," interval_as_struct.end,; interval_as_struct.includes_start,; interval_as_struct.includes_end,; point_type=self.point_type,; ). def _convert_to_encoding(self, byte_writer, value):; interval_dict = {; 'start': value.start,; 'end': value.end,; 'includes_start': value.includes_start,; 'includes_end': value.includes_end,; }; self._struct_repr._convert_to_encoding(byte_writer, interval_dict). def unify(self, t):; return isinstance(t, tinterval) and self.point_type.unify(t.point_type). def subst(self):; return tinterval(self.point_type.subst()). def clear(self):; self.point_type.clear(). def _get_context(self):; return self.point_type.get_context(). class Box(object):; named_boxes: ClassVar = {}. @staticmethod; def from_name(name):; if name in Box.named_boxes:; return Box.named_boxes[name]; b = Box(); Box.named_boxes[name] = b; return b. def __init__(self):; pass. def unify(self, v):; if hasattr(self, 'value'):; return self.value == v; self.value = v; return True. def clear(self):; if hasattr(self, 'value'):; del self.value. def get(self):; assert hasattr(self, 'value'); return self.value. tvoid = _tvoid(). tint32 = _tint32(); """"""Hail type for signed 32-bit integers. Their values can range from :math:`-2^{31}` to :math:`2^{31} - 1`; (approximately 2.15 billion). In Python, these are represented as :obj:`int`. See Also; --------; :class:`.Int32Expression`, :func:`.int`, :func:`.int32`; """""". tint64 = _tint64(); """"""Hail type for signed 64-bit integers. Their values can range from :math:`-2^{63}` to :math:`2^{63} - 1`. In Python, these are represented as :obj:`int`. See Also; --------; :class:`.Int64Expression`, :func:`.int64`; """""". tint = tint32; """"""Alias for :py:data:`.tint32`."""""". tfloat32 = _tfloat32(); """"""Hail type for 32-bit floating point numbers. In Python, these are represented as :obj:`float`. See Also; --------; :class:`.Float32Expression`, :func:`.float64`; """""". tfloat64 = _tfloat64(); """"""Hail type for 64-bit floating point numbers. In Python, these are represente",MatchSource.WIKI,docs/0.2/_modules/hail/expr/types.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html
https://hail.is/docs/0.2/_modules/hail/expr/types.html:56434,Usability,clear,clear,56434,"np_dtype} could not be converted to a hail type.""). def dtypes_from_pandas(pd_dtype):; if type(pd_dtype) == pd.StringDtype:; return hl.tstr; elif pd_dtype == np.int64:; return hl.tint64; elif pd_dtype == np.uint64:; # Hail does *not* support unsigned integers but the next condition,; # pd.api.types.is_integer_dtype(pd_dtype) would return true on unsigned 64-bit ints; return None; # For some reason pandas doesn't have `is_int32_dtype`, so we use `is_integer_dtype` if first branch failed.; elif pd.api.types.is_integer_dtype(pd_dtype):; return hl.tint32; elif pd_dtype == np.float32:; return hl.tfloat32; elif pd_dtype == np.float64:; return hl.tfloat64; elif pd_dtype == bool:; return hl.tbool; return None. class tvariable(HailType):; _cond_map: ClassVar = {; 'numeric': is_numeric,; 'int32': lambda x: x == tint32,; 'int64': lambda x: x == tint64,; 'float32': lambda x: x == tfloat32,; 'float64': lambda x: x == tfloat64,; 'locus': lambda x: isinstance(x, tlocus),; 'struct': lambda x: isinstance(x, tstruct),; 'union': lambda x: isinstance(x, tunion),; 'tuple': lambda x: isinstance(x, ttuple),; }. def __init__(self, name, cond):; self.name = name; self.cond = cond; self.condf = tvariable._cond_map[cond] if cond else None; self.box = Box.from_name(name). def unify(self, t):; if self.condf and not self.condf(t):; return False; return self.box.unify(t). def clear(self):; self.box.clear(). def subst(self):; return self.box.get(). def __str__(self):; s = '?' + self.name; if self.cond:; s = s + ':' + self.cond; return s. _old_printer = pprint.PrettyPrinter. class TypePrettyPrinter(pprint.PrettyPrinter):; def _format(self, object, stream, indent, allowance, context, level):; if isinstance(object, HailType):; stream.write(object.pretty(self._indent_per_level)); else:; return _old_printer._format(self, object, stream, indent, allowance, context, level). pprint.PrettyPrinter = TypePrettyPrinter # monkey-patch pprint. © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,docs/0.2/_modules/hail/expr/types.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html
https://hail.is/docs/0.2/_modules/hail/expr/types.html:56457,Usability,clear,clear,56457,"np_dtype} could not be converted to a hail type.""). def dtypes_from_pandas(pd_dtype):; if type(pd_dtype) == pd.StringDtype:; return hl.tstr; elif pd_dtype == np.int64:; return hl.tint64; elif pd_dtype == np.uint64:; # Hail does *not* support unsigned integers but the next condition,; # pd.api.types.is_integer_dtype(pd_dtype) would return true on unsigned 64-bit ints; return None; # For some reason pandas doesn't have `is_int32_dtype`, so we use `is_integer_dtype` if first branch failed.; elif pd.api.types.is_integer_dtype(pd_dtype):; return hl.tint32; elif pd_dtype == np.float32:; return hl.tfloat32; elif pd_dtype == np.float64:; return hl.tfloat64; elif pd_dtype == bool:; return hl.tbool; return None. class tvariable(HailType):; _cond_map: ClassVar = {; 'numeric': is_numeric,; 'int32': lambda x: x == tint32,; 'int64': lambda x: x == tint64,; 'float32': lambda x: x == tfloat32,; 'float64': lambda x: x == tfloat64,; 'locus': lambda x: isinstance(x, tlocus),; 'struct': lambda x: isinstance(x, tstruct),; 'union': lambda x: isinstance(x, tunion),; 'tuple': lambda x: isinstance(x, ttuple),; }. def __init__(self, name, cond):; self.name = name; self.cond = cond; self.condf = tvariable._cond_map[cond] if cond else None; self.box = Box.from_name(name). def unify(self, t):; if self.condf and not self.condf(t):; return False; return self.box.unify(t). def clear(self):; self.box.clear(). def subst(self):; return self.box.get(). def __str__(self):; s = '?' + self.name; if self.cond:; s = s + ':' + self.cond; return s. _old_printer = pprint.PrettyPrinter. class TypePrettyPrinter(pprint.PrettyPrinter):; def _format(self, object, stream, indent, allowance, context, level):; if isinstance(object, HailType):; stream.write(object.pretty(self._indent_per_level)); else:; return _old_printer._format(self, object, stream, indent, allowance, context, level). pprint.PrettyPrinter = TypePrettyPrinter # monkey-patch pprint. © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,docs/0.2/_modules/hail/expr/types.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/expr/types.html
https://hail.is/docs/0.2/_modules/hail/genetics/allele_type.html:2400,Deployability,update,updated,2400,"code; hail.genetics.allele_type. Source code for hail.genetics.allele_type; from enum import IntEnum, auto. _ALLELE_STRS = (; ""Unknown"",; ""SNP"",; ""MNP"",; ""Insertion"",; ""Deletion"",; ""Complex"",; ""Star"",; ""Symbolic"",; ""Transition"",; ""Transversion"",; ). [docs]class AlleleType(IntEnum):; """"""An enumeration for allele type. Notes; -----; The precise values of the enumeration constants are not guarenteed; to be stable and must not be relied upon.; """""". UNKNOWN = 0; """"""Unknown Allele Type""""""; SNP = auto(); """"""Single-nucleotide Polymorphism (SNP)""""""; MNP = auto(); """"""Multi-nucleotide Polymorphism (MNP)""""""; INSERTION = auto(); """"""Insertion""""""; DELETION = auto(); """"""Deletion""""""; COMPLEX = auto(); """"""Complex Polymorphism""""""; STAR = auto(); """"""Star Allele (``alt=*``)""""""; SYMBOLIC = auto(); """"""Symbolic Allele. e.g. ``alt=<INS>``; """"""; TRANSITION = auto(); """"""Transition SNP. e.g. ``ref=A alt=G``. Note; ----; This is only really used internally in :func:`hail.vds.sample_qc` and; :func:`hail.methods.sample_qc`.; """"""; TRANSVERSION = auto(); """"""Transversion SNP. e.g. ``ref=A alt=C``. Note; ----; This is only really used internally in :func:`hail.vds.sample_qc` and; :func:`hail.methods.sample_qc`.; """""". def __str__(self):; return str(self.value). @property; def pretty_name(self):; """"""A formatted (as opposed to uppercase) version of the member's name,; to match :func:`~hail.expr.functions.allele_type`. Examples; --------; >>> AlleleType.INSERTION.pretty_name; 'Insertion'; >>> at = AlleleType(hl.eval(hl.numeric_allele_type('a', 'att'))); >>> at.pretty_name == hl.eval(hl.allele_type('a', 'att')); True; """"""; return _ALLELE_STRS[self]. @classmethod; def _missing_(cls, value):; if not isinstance(value, str):; return None; return cls.__members__.get(value.upper()). [docs] @staticmethod; def strings():; """"""Returns the names of the allele types, for use with; :func:`~hail.expr.functions.literal`; """"""; return list(_ALLELE_STRS). © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,docs/0.2/_modules/hail/genetics/allele_type.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/genetics/allele_type.html
https://hail.is/docs/0.2/_modules/hail/genetics/call.html:5872,Deployability,update,updated,5872," the call contains two different alternate alleles. :rtype: bool; """"""; n = self.ploidy; if n < 2:; return False. assert n == 2; a0 = self._alleles[0]; a1 = self._alleles[1]; return a0 > 0 and a1 > 0 and a0 != a1. [docs] def is_het_ref(self):; """"""True if the call contains one reference and one alternate allele. :rtype: bool; """"""; n = self.ploidy; if n < 2:; return False. assert n == 2; a0 = self._alleles[0]; a1 = self._alleles[1]; return (a0 == 0 and a1 > 0) or (a0 > 0 and a1 == 0). [docs] def n_alt_alleles(self):; """"""Returns the count of non-reference alleles. :rtype: int; """"""; n = 0; for a in self._alleles:; if a > 0:; n += 1; return n. [docs] @typecheck_method(n_alleles=int); def one_hot_alleles(self, n_alleles):; """"""Returns a list containing the one-hot encoded representation of the; called alleles. Examples; --------. >>> n_alleles = 2; >>> hom_ref = hl.Call([0, 0]); >>> het = hl.Call([0, 1]); >>> hom_var = hl.Call([1, 1]). >>> het.one_hot_alleles(n_alleles); [1, 1]. >>> hom_var.one_hot_alleles(n_alleles); [0, 2]. Notes; -----; This one-hot representation is the positional sum of the one-hot; encoding for each called allele. For a biallelic variant, the; one-hot encoding for a reference allele is [1, 0] and the one-hot; encoding for an alternate allele is [0, 1]. Parameters; ----------; n_alleles : :obj:`int`; Number of total alleles, including the reference. Returns; -------; :obj:`list` of :obj:`int`; """"""; r = [0] * n_alleles; for a in self._alleles:; r[a] += 1; return r. [docs] def unphased_diploid_gt_index(self):; """"""Return the genotype index for unphased, diploid calls. Returns; -------; :obj:`int`; """"""; from hail.utils import FatalError. if self.ploidy != 2 or self.phased:; raise FatalError(; ""'unphased_diploid_gt_index' is only valid for unphased, diploid calls. Found {}."".format(repr(self)); ); a0 = self._alleles[0]; a1 = self._alleles[1]; assert a0 <= a1; return a1 * (a1 + 1) / 2 + a0. © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,docs/0.2/_modules/hail/genetics/call.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/genetics/call.html
https://hail.is/docs/0.2/_modules/hail/genetics/call.html:2313,Security,hash,hash,2313," check annotations which are too slow.; assert isinstance(alleles, Sequence); assert isinstance(phased, bool). if len(alleles) > 2:; raise NotImplementedError(""Calls with greater than 2 alleles are not supported.""); self._phased = phased; ploidy = len(alleles); if phased or ploidy < 2:; self._alleles = alleles; else:; assert ploidy == 2; a0 = alleles[0]; a1 = alleles[1]; if a1 < a0:; a0, a1 = a1, a0; self._alleles = [a0, a1]. def __str__(self):; n = self.ploidy; if n == 0:; if self._phased:; return '|-'; return '-'. if n == 1:; if self._phased:; return f'|{self._alleles[0]}'; return str(self._alleles[0]). assert n == 2; a0 = self._alleles[0]; a1 = self._alleles[1]; if self._phased:; return f'{a0}|{a1}'; return f'{a0}/{a1}'. def __repr__(self):; return 'Call(alleles=%s, phased=%s)' % (self._alleles, self._phased). def __eq__(self, other):; return (; (self._phased == other._phased and self._alleles == other._alleles); if isinstance(other, Call); else NotImplemented; ). def __hash__(self):; return hash(self._phased) ^ hash(tuple(self._alleles)). def __getitem__(self, item):; """"""Get the i*th* allele. Returns; -------; :obj:`int`; """"""; return self._alleles[item]. @property; def alleles(self) -> Sequence[int]:; """"""Get the alleles of this call. Returns; -------; :obj:`list` of :obj:`int`; """"""; return self._alleles. @property; def ploidy(self):; """"""The number of alleles for this call. Returns; -------; :obj:`int`; """"""; return len(self._alleles). @property; def phased(self):; """"""True if the call is phased. Returns; -------; :obj:`bool`; """"""; return self._phased. [docs] def is_haploid(self):; """"""True if the ploidy == 1. :rtype: bool; """"""; return self.ploidy == 1. [docs] def is_diploid(self):; """"""True if the ploidy == 2. :rtype: bool; """"""; return self.ploidy == 2. [docs] def is_hom_ref(self):; """"""True if the call has no alternate alleles. :rtype: bool; """"""; if self.ploidy == 0:; return False. return all(a == 0 for a in self._alleles). [docs] def is_het(self):; """"""True if the ca",MatchSource.WIKI,docs/0.2/_modules/hail/genetics/call.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/genetics/call.html
https://hail.is/docs/0.2/_modules/hail/genetics/call.html:2334,Security,hash,hash,2334,"slow.; assert isinstance(alleles, Sequence); assert isinstance(phased, bool). if len(alleles) > 2:; raise NotImplementedError(""Calls with greater than 2 alleles are not supported.""); self._phased = phased; ploidy = len(alleles); if phased or ploidy < 2:; self._alleles = alleles; else:; assert ploidy == 2; a0 = alleles[0]; a1 = alleles[1]; if a1 < a0:; a0, a1 = a1, a0; self._alleles = [a0, a1]. def __str__(self):; n = self.ploidy; if n == 0:; if self._phased:; return '|-'; return '-'. if n == 1:; if self._phased:; return f'|{self._alleles[0]}'; return str(self._alleles[0]). assert n == 2; a0 = self._alleles[0]; a1 = self._alleles[1]; if self._phased:; return f'{a0}|{a1}'; return f'{a0}/{a1}'. def __repr__(self):; return 'Call(alleles=%s, phased=%s)' % (self._alleles, self._phased). def __eq__(self, other):; return (; (self._phased == other._phased and self._alleles == other._alleles); if isinstance(other, Call); else NotImplemented; ). def __hash__(self):; return hash(self._phased) ^ hash(tuple(self._alleles)). def __getitem__(self, item):; """"""Get the i*th* allele. Returns; -------; :obj:`int`; """"""; return self._alleles[item]. @property; def alleles(self) -> Sequence[int]:; """"""Get the alleles of this call. Returns; -------; :obj:`list` of :obj:`int`; """"""; return self._alleles. @property; def ploidy(self):; """"""The number of alleles for this call. Returns; -------; :obj:`int`; """"""; return len(self._alleles). @property; def phased(self):; """"""True if the call is phased. Returns; -------; :obj:`bool`; """"""; return self._phased. [docs] def is_haploid(self):; """"""True if the ploidy == 1. :rtype: bool; """"""; return self.ploidy == 1. [docs] def is_diploid(self):; """"""True if the ploidy == 2. :rtype: bool; """"""; return self.ploidy == 2. [docs] def is_hom_ref(self):; """"""True if the call has no alternate alleles. :rtype: bool; """"""; if self.ploidy == 0:; return False. return all(a == 0 for a in self._alleles). [docs] def is_het(self):; """"""True if the call contains two different alleles",MatchSource.WIKI,docs/0.2/_modules/hail/genetics/call.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/genetics/call.html
https://hail.is/docs/0.2/_modules/hail/genetics/call.html:1343,Testability,assert,assert,1343," Log And Version Policy. menu; Hail. Module code; hail.genetics.call. Source code for hail.genetics.call; from collections.abc import Sequence. from hail.typecheck import typecheck_method. [docs]class Call(object):; """"""; An object that represents an individual's call at a genomic locus. Parameters; ----------; alleles : :obj:`list` of :obj:`int`; List of alleles that compose the call.; phased : :obj:`bool`; If ``True``, the alleles are phased and the order is specified by; `alleles`. Note; ----; This object refers to the Python value returned by taking or collecting; Hail expressions, e.g. ``mt.GT.take(5`)``. This is rare; it is much; more common to manipulate the :class:`.CallExpression` object, which is; constructed using the following functions:. - :func:`.call`; - :func:`.unphased_diploid_gt_index_call`; - :func:`.parse_call`; """""". def __init__(self, alleles, phased=False):; # Intentionally not using the type check annotations which are too slow.; assert isinstance(alleles, Sequence); assert isinstance(phased, bool). if len(alleles) > 2:; raise NotImplementedError(""Calls with greater than 2 alleles are not supported.""); self._phased = phased; ploidy = len(alleles); if phased or ploidy < 2:; self._alleles = alleles; else:; assert ploidy == 2; a0 = alleles[0]; a1 = alleles[1]; if a1 < a0:; a0, a1 = a1, a0; self._alleles = [a0, a1]. def __str__(self):; n = self.ploidy; if n == 0:; if self._phased:; return '|-'; return '-'. if n == 1:; if self._phased:; return f'|{self._alleles[0]}'; return str(self._alleles[0]). assert n == 2; a0 = self._alleles[0]; a1 = self._alleles[1]; if self._phased:; return f'{a0}|{a1}'; return f'{a0}/{a1}'. def __repr__(self):; return 'Call(alleles=%s, phased=%s)' % (self._alleles, self._phased). def __eq__(self, other):; return (; (self._phased == other._phased and self._alleles == other._alleles); if isinstance(other, Call); else NotImplemented; ). def __hash__(self):; return hash(self._phased) ^ hash(tuple(self._alleles)). def __getitem__",MatchSource.WIKI,docs/0.2/_modules/hail/genetics/call.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/genetics/call.html
https://hail.is/docs/0.2/_modules/hail/genetics/call.html:1381,Testability,assert,assert,1381," Log And Version Policy. menu; Hail. Module code; hail.genetics.call. Source code for hail.genetics.call; from collections.abc import Sequence. from hail.typecheck import typecheck_method. [docs]class Call(object):; """"""; An object that represents an individual's call at a genomic locus. Parameters; ----------; alleles : :obj:`list` of :obj:`int`; List of alleles that compose the call.; phased : :obj:`bool`; If ``True``, the alleles are phased and the order is specified by; `alleles`. Note; ----; This object refers to the Python value returned by taking or collecting; Hail expressions, e.g. ``mt.GT.take(5`)``. This is rare; it is much; more common to manipulate the :class:`.CallExpression` object, which is; constructed using the following functions:. - :func:`.call`; - :func:`.unphased_diploid_gt_index_call`; - :func:`.parse_call`; """""". def __init__(self, alleles, phased=False):; # Intentionally not using the type check annotations which are too slow.; assert isinstance(alleles, Sequence); assert isinstance(phased, bool). if len(alleles) > 2:; raise NotImplementedError(""Calls with greater than 2 alleles are not supported.""); self._phased = phased; ploidy = len(alleles); if phased or ploidy < 2:; self._alleles = alleles; else:; assert ploidy == 2; a0 = alleles[0]; a1 = alleles[1]; if a1 < a0:; a0, a1 = a1, a0; self._alleles = [a0, a1]. def __str__(self):; n = self.ploidy; if n == 0:; if self._phased:; return '|-'; return '-'. if n == 1:; if self._phased:; return f'|{self._alleles[0]}'; return str(self._alleles[0]). assert n == 2; a0 = self._alleles[0]; a1 = self._alleles[1]; if self._phased:; return f'{a0}|{a1}'; return f'{a0}/{a1}'. def __repr__(self):; return 'Call(alleles=%s, phased=%s)' % (self._alleles, self._phased). def __eq__(self, other):; return (; (self._phased == other._phased and self._alleles == other._alleles); if isinstance(other, Call); else NotImplemented; ). def __hash__(self):; return hash(self._phased) ^ hash(tuple(self._alleles)). def __getitem__",MatchSource.WIKI,docs/0.2/_modules/hail/genetics/call.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/genetics/call.html
https://hail.is/docs/0.2/_modules/hail/genetics/call.html:1623,Testability,assert,assert,1623,"mic locus. Parameters; ----------; alleles : :obj:`list` of :obj:`int`; List of alleles that compose the call.; phased : :obj:`bool`; If ``True``, the alleles are phased and the order is specified by; `alleles`. Note; ----; This object refers to the Python value returned by taking or collecting; Hail expressions, e.g. ``mt.GT.take(5`)``. This is rare; it is much; more common to manipulate the :class:`.CallExpression` object, which is; constructed using the following functions:. - :func:`.call`; - :func:`.unphased_diploid_gt_index_call`; - :func:`.parse_call`; """""". def __init__(self, alleles, phased=False):; # Intentionally not using the type check annotations which are too slow.; assert isinstance(alleles, Sequence); assert isinstance(phased, bool). if len(alleles) > 2:; raise NotImplementedError(""Calls with greater than 2 alleles are not supported.""); self._phased = phased; ploidy = len(alleles); if phased or ploidy < 2:; self._alleles = alleles; else:; assert ploidy == 2; a0 = alleles[0]; a1 = alleles[1]; if a1 < a0:; a0, a1 = a1, a0; self._alleles = [a0, a1]. def __str__(self):; n = self.ploidy; if n == 0:; if self._phased:; return '|-'; return '-'. if n == 1:; if self._phased:; return f'|{self._alleles[0]}'; return str(self._alleles[0]). assert n == 2; a0 = self._alleles[0]; a1 = self._alleles[1]; if self._phased:; return f'{a0}|{a1}'; return f'{a0}/{a1}'. def __repr__(self):; return 'Call(alleles=%s, phased=%s)' % (self._alleles, self._phased). def __eq__(self, other):; return (; (self._phased == other._phased and self._alleles == other._alleles); if isinstance(other, Call); else NotImplemented; ). def __hash__(self):; return hash(self._phased) ^ hash(tuple(self._alleles)). def __getitem__(self, item):; """"""Get the i*th* allele. Returns; -------; :obj:`int`; """"""; return self._alleles[item]. @property; def alleles(self) -> Sequence[int]:; """"""Get the alleles of this call. Returns; -------; :obj:`list` of :obj:`int`; """"""; return self._alleles. @property; def ploidy",MatchSource.WIKI,docs/0.2/_modules/hail/genetics/call.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/genetics/call.html
https://hail.is/docs/0.2/_modules/hail/genetics/call.html:1916,Testability,assert,assert,1916," taking or collecting; Hail expressions, e.g. ``mt.GT.take(5`)``. This is rare; it is much; more common to manipulate the :class:`.CallExpression` object, which is; constructed using the following functions:. - :func:`.call`; - :func:`.unphased_diploid_gt_index_call`; - :func:`.parse_call`; """""". def __init__(self, alleles, phased=False):; # Intentionally not using the type check annotations which are too slow.; assert isinstance(alleles, Sequence); assert isinstance(phased, bool). if len(alleles) > 2:; raise NotImplementedError(""Calls with greater than 2 alleles are not supported.""); self._phased = phased; ploidy = len(alleles); if phased or ploidy < 2:; self._alleles = alleles; else:; assert ploidy == 2; a0 = alleles[0]; a1 = alleles[1]; if a1 < a0:; a0, a1 = a1, a0; self._alleles = [a0, a1]. def __str__(self):; n = self.ploidy; if n == 0:; if self._phased:; return '|-'; return '-'. if n == 1:; if self._phased:; return f'|{self._alleles[0]}'; return str(self._alleles[0]). assert n == 2; a0 = self._alleles[0]; a1 = self._alleles[1]; if self._phased:; return f'{a0}|{a1}'; return f'{a0}/{a1}'. def __repr__(self):; return 'Call(alleles=%s, phased=%s)' % (self._alleles, self._phased). def __eq__(self, other):; return (; (self._phased == other._phased and self._alleles == other._alleles); if isinstance(other, Call); else NotImplemented; ). def __hash__(self):; return hash(self._phased) ^ hash(tuple(self._alleles)). def __getitem__(self, item):; """"""Get the i*th* allele. Returns; -------; :obj:`int`; """"""; return self._alleles[item]. @property; def alleles(self) -> Sequence[int]:; """"""Get the alleles of this call. Returns; -------; :obj:`list` of :obj:`int`; """"""; return self._alleles. @property; def ploidy(self):; """"""The number of alleles for this call. Returns; -------; :obj:`int`; """"""; return len(self._alleles). @property; def phased(self):; """"""True if the call is phased. Returns; -------; :obj:`bool`; """"""; return self._phased. [docs] def is_haploid(self):; """"""True if the ",MatchSource.WIKI,docs/0.2/_modules/hail/genetics/call.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/genetics/call.html
https://hail.is/docs/0.2/_modules/hail/genetics/call.html:3663,Testability,assert,assert,3663," of alleles for this call. Returns; -------; :obj:`int`; """"""; return len(self._alleles). @property; def phased(self):; """"""True if the call is phased. Returns; -------; :obj:`bool`; """"""; return self._phased. [docs] def is_haploid(self):; """"""True if the ploidy == 1. :rtype: bool; """"""; return self.ploidy == 1. [docs] def is_diploid(self):; """"""True if the ploidy == 2. :rtype: bool; """"""; return self.ploidy == 2. [docs] def is_hom_ref(self):; """"""True if the call has no alternate alleles. :rtype: bool; """"""; if self.ploidy == 0:; return False. return all(a == 0 for a in self._alleles). [docs] def is_het(self):; """"""True if the call contains two different alleles. :rtype: bool; """"""; if self.ploidy < 2:; return False; return self._alleles[0] != self._alleles[1]. [docs] def is_hom_var(self):; """"""True if the call contains identical alternate alleles. :rtype: bool; """"""; n = self.ploidy; if n == 0:; return False. a0 = self._alleles[0]; if a0 == 0:; return False. if n == 1:; return True. assert n == 2; return self._alleles[1] == a0. [docs] def is_non_ref(self):; """"""True if the call contains any non-reference alleles. :rtype: bool; """"""; return any(a > 0 for a in self._alleles). [docs] def is_het_non_ref(self):; """"""True if the call contains two different alternate alleles. :rtype: bool; """"""; n = self.ploidy; if n < 2:; return False. assert n == 2; a0 = self._alleles[0]; a1 = self._alleles[1]; return a0 > 0 and a1 > 0 and a0 != a1. [docs] def is_het_ref(self):; """"""True if the call contains one reference and one alternate allele. :rtype: bool; """"""; n = self.ploidy; if n < 2:; return False. assert n == 2; a0 = self._alleles[0]; a1 = self._alleles[1]; return (a0 == 0 and a1 > 0) or (a0 > 0 and a1 == 0). [docs] def n_alt_alleles(self):; """"""Returns the count of non-reference alleles. :rtype: int; """"""; n = 0; for a in self._alleles:; if a > 0:; n += 1; return n. [docs] @typecheck_method(n_alleles=int); def one_hot_alleles(self, n_alleles):; """"""Returns a list containing the one-hot encoded r",MatchSource.WIKI,docs/0.2/_modules/hail/genetics/call.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/genetics/call.html
https://hail.is/docs/0.2/_modules/hail/genetics/call.html:4013,Testability,assert,assert,4013," the ploidy == 2. :rtype: bool; """"""; return self.ploidy == 2. [docs] def is_hom_ref(self):; """"""True if the call has no alternate alleles. :rtype: bool; """"""; if self.ploidy == 0:; return False. return all(a == 0 for a in self._alleles). [docs] def is_het(self):; """"""True if the call contains two different alleles. :rtype: bool; """"""; if self.ploidy < 2:; return False; return self._alleles[0] != self._alleles[1]. [docs] def is_hom_var(self):; """"""True if the call contains identical alternate alleles. :rtype: bool; """"""; n = self.ploidy; if n == 0:; return False. a0 = self._alleles[0]; if a0 == 0:; return False. if n == 1:; return True. assert n == 2; return self._alleles[1] == a0. [docs] def is_non_ref(self):; """"""True if the call contains any non-reference alleles. :rtype: bool; """"""; return any(a > 0 for a in self._alleles). [docs] def is_het_non_ref(self):; """"""True if the call contains two different alternate alleles. :rtype: bool; """"""; n = self.ploidy; if n < 2:; return False. assert n == 2; a0 = self._alleles[0]; a1 = self._alleles[1]; return a0 > 0 and a1 > 0 and a0 != a1. [docs] def is_het_ref(self):; """"""True if the call contains one reference and one alternate allele. :rtype: bool; """"""; n = self.ploidy; if n < 2:; return False. assert n == 2; a0 = self._alleles[0]; a1 = self._alleles[1]; return (a0 == 0 and a1 > 0) or (a0 > 0 and a1 == 0). [docs] def n_alt_alleles(self):; """"""Returns the count of non-reference alleles. :rtype: int; """"""; n = 0; for a in self._alleles:; if a > 0:; n += 1; return n. [docs] @typecheck_method(n_alleles=int); def one_hot_alleles(self, n_alleles):; """"""Returns a list containing the one-hot encoded representation of the; called alleles. Examples; --------. >>> n_alleles = 2; >>> hom_ref = hl.Call([0, 0]); >>> het = hl.Call([0, 1]); >>> hom_var = hl.Call([1, 1]). >>> het.one_hot_alleles(n_alleles); [1, 1]. >>> hom_var.one_hot_alleles(n_alleles); [0, 2]. Notes; -----; This one-hot representation is the positional sum of the one-hot; encoding fo",MatchSource.WIKI,docs/0.2/_modules/hail/genetics/call.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/genetics/call.html
https://hail.is/docs/0.2/_modules/hail/genetics/call.html:4273,Testability,assert,assert,4273,"; """"""True if the call contains two different alleles. :rtype: bool; """"""; if self.ploidy < 2:; return False; return self._alleles[0] != self._alleles[1]. [docs] def is_hom_var(self):; """"""True if the call contains identical alternate alleles. :rtype: bool; """"""; n = self.ploidy; if n == 0:; return False. a0 = self._alleles[0]; if a0 == 0:; return False. if n == 1:; return True. assert n == 2; return self._alleles[1] == a0. [docs] def is_non_ref(self):; """"""True if the call contains any non-reference alleles. :rtype: bool; """"""; return any(a > 0 for a in self._alleles). [docs] def is_het_non_ref(self):; """"""True if the call contains two different alternate alleles. :rtype: bool; """"""; n = self.ploidy; if n < 2:; return False. assert n == 2; a0 = self._alleles[0]; a1 = self._alleles[1]; return a0 > 0 and a1 > 0 and a0 != a1. [docs] def is_het_ref(self):; """"""True if the call contains one reference and one alternate allele. :rtype: bool; """"""; n = self.ploidy; if n < 2:; return False. assert n == 2; a0 = self._alleles[0]; a1 = self._alleles[1]; return (a0 == 0 and a1 > 0) or (a0 > 0 and a1 == 0). [docs] def n_alt_alleles(self):; """"""Returns the count of non-reference alleles. :rtype: int; """"""; n = 0; for a in self._alleles:; if a > 0:; n += 1; return n. [docs] @typecheck_method(n_alleles=int); def one_hot_alleles(self, n_alleles):; """"""Returns a list containing the one-hot encoded representation of the; called alleles. Examples; --------. >>> n_alleles = 2; >>> hom_ref = hl.Call([0, 0]); >>> het = hl.Call([0, 1]); >>> hom_var = hl.Call([1, 1]). >>> het.one_hot_alleles(n_alleles); [1, 1]. >>> hom_var.one_hot_alleles(n_alleles); [0, 2]. Notes; -----; This one-hot representation is the positional sum of the one-hot; encoding for each called allele. For a biallelic variant, the; one-hot encoding for a reference allele is [1, 0] and the one-hot; encoding for an alternate allele is [0, 1]. Parameters; ----------; n_alleles : :obj:`int`; Number of total alleles, including the reference.",MatchSource.WIKI,docs/0.2/_modules/hail/genetics/call.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/genetics/call.html
https://hail.is/docs/0.2/_modules/hail/genetics/call.html:5784,Testability,assert,assert,5784," the call contains two different alternate alleles. :rtype: bool; """"""; n = self.ploidy; if n < 2:; return False. assert n == 2; a0 = self._alleles[0]; a1 = self._alleles[1]; return a0 > 0 and a1 > 0 and a0 != a1. [docs] def is_het_ref(self):; """"""True if the call contains one reference and one alternate allele. :rtype: bool; """"""; n = self.ploidy; if n < 2:; return False. assert n == 2; a0 = self._alleles[0]; a1 = self._alleles[1]; return (a0 == 0 and a1 > 0) or (a0 > 0 and a1 == 0). [docs] def n_alt_alleles(self):; """"""Returns the count of non-reference alleles. :rtype: int; """"""; n = 0; for a in self._alleles:; if a > 0:; n += 1; return n. [docs] @typecheck_method(n_alleles=int); def one_hot_alleles(self, n_alleles):; """"""Returns a list containing the one-hot encoded representation of the; called alleles. Examples; --------. >>> n_alleles = 2; >>> hom_ref = hl.Call([0, 0]); >>> het = hl.Call([0, 1]); >>> hom_var = hl.Call([1, 1]). >>> het.one_hot_alleles(n_alleles); [1, 1]. >>> hom_var.one_hot_alleles(n_alleles); [0, 2]. Notes; -----; This one-hot representation is the positional sum of the one-hot; encoding for each called allele. For a biallelic variant, the; one-hot encoding for a reference allele is [1, 0] and the one-hot; encoding for an alternate allele is [0, 1]. Parameters; ----------; n_alleles : :obj:`int`; Number of total alleles, including the reference. Returns; -------; :obj:`list` of :obj:`int`; """"""; r = [0] * n_alleles; for a in self._alleles:; r[a] += 1; return r. [docs] def unphased_diploid_gt_index(self):; """"""Return the genotype index for unphased, diploid calls. Returns; -------; :obj:`int`; """"""; from hail.utils import FatalError. if self.ploidy != 2 or self.phased:; raise FatalError(; ""'unphased_diploid_gt_index' is only valid for unphased, diploid calls. Found {}."".format(repr(self)); ); a0 = self._alleles[0]; a1 = self._alleles[1]; assert a0 <= a1; return a1 * (a1 + 1) / 2 + a0. © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,docs/0.2/_modules/hail/genetics/call.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/genetics/call.html
https://hail.is/docs/0.2/_modules/hail/genetics/locus.html:3272,Deployability,update,updated,3272,"l_position`; """""". def __init__(self, contig, position, reference_genome: Union[str, ReferenceGenome] = 'default'):; if isinstance(contig, int):; contig = str(contig). if isinstance(reference_genome, str):; reference_genome = hl.get_reference(reference_genome). assert isinstance(contig, str); assert isinstance(position, int); assert isinstance(reference_genome, ReferenceGenome). self._contig = contig; self._position = position; self._rg = reference_genome. def __str__(self):; return f'{self._contig}:{self._position}'. def __repr__(self):; return 'Locus(contig=%s, position=%s, reference_genome=%s)' % (self.contig, self.position, self._rg). def __eq__(self, other):; return (; (self._contig == other._contig and self._position == other._position and self._rg == other._rg); if isinstance(other, Locus); else NotImplemented; ). def __hash__(self):; return hash(self._contig) ^ hash(self._position) ^ hash(self._rg). [docs] @classmethod; @typecheck_method(string=str, reference_genome=reference_genome_type); def parse(cls, string, reference_genome='default'):; """"""Parses a locus object from a CHR:POS string. **Examples**. >>> l1 = hl.Locus.parse('1:101230'); >>> l2 = hl.Locus.parse('X:4201230'). :param str string: String to parse.; :param reference_genome: Reference genome to use. Default is :func:`~hail.default_reference`.; :type reference_genome: :class:`str` or :class:`.ReferenceGenome`. :rtype: :class:`.Locus`; """"""; contig, pos = string.split(':'); if pos.lower() == 'end':; pos = reference_genome.contig_length(contig); else:; pos = int(pos); return Locus(contig, pos, reference_genome). @property; def contig(self):; """"""; Chromosome identifier.; :rtype: str; """"""; return self._contig. @property; def position(self):; """"""; Chromosomal position (1-based).; :rtype: int; """"""; return self._position. @property; def reference_genome(self):; """"""Reference genome. :return: :class:`.ReferenceGenome`; """"""; return self._rg. © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,docs/0.2/_modules/hail/genetics/locus.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/genetics/locus.html
https://hail.is/docs/0.2/_modules/hail/genetics/locus.html:2160,Security,hash,hash,2160,":`.LocusExpression` object, which is; constructed using the following functions:. - :func:`.locus`; - :func:`.parse_locus`; - :func:`.locus_from_global_position`; """""". def __init__(self, contig, position, reference_genome: Union[str, ReferenceGenome] = 'default'):; if isinstance(contig, int):; contig = str(contig). if isinstance(reference_genome, str):; reference_genome = hl.get_reference(reference_genome). assert isinstance(contig, str); assert isinstance(position, int); assert isinstance(reference_genome, ReferenceGenome). self._contig = contig; self._position = position; self._rg = reference_genome. def __str__(self):; return f'{self._contig}:{self._position}'. def __repr__(self):; return 'Locus(contig=%s, position=%s, reference_genome=%s)' % (self.contig, self.position, self._rg). def __eq__(self, other):; return (; (self._contig == other._contig and self._position == other._position and self._rg == other._rg); if isinstance(other, Locus); else NotImplemented; ). def __hash__(self):; return hash(self._contig) ^ hash(self._position) ^ hash(self._rg). [docs] @classmethod; @typecheck_method(string=str, reference_genome=reference_genome_type); def parse(cls, string, reference_genome='default'):; """"""Parses a locus object from a CHR:POS string. **Examples**. >>> l1 = hl.Locus.parse('1:101230'); >>> l2 = hl.Locus.parse('X:4201230'). :param str string: String to parse.; :param reference_genome: Reference genome to use. Default is :func:`~hail.default_reference`.; :type reference_genome: :class:`str` or :class:`.ReferenceGenome`. :rtype: :class:`.Locus`; """"""; contig, pos = string.split(':'); if pos.lower() == 'end':; pos = reference_genome.contig_length(contig); else:; pos = int(pos); return Locus(contig, pos, reference_genome). @property; def contig(self):; """"""; Chromosome identifier.; :rtype: str; """"""; return self._contig. @property; def position(self):; """"""; Chromosomal position (1-based).; :rtype: int; """"""; return self._position. @property; def reference_genome(self):",MatchSource.WIKI,docs/0.2/_modules/hail/genetics/locus.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/genetics/locus.html
https://hail.is/docs/0.2/_modules/hail/genetics/locus.html:2181,Security,hash,hash,2181,"ich is; constructed using the following functions:. - :func:`.locus`; - :func:`.parse_locus`; - :func:`.locus_from_global_position`; """""". def __init__(self, contig, position, reference_genome: Union[str, ReferenceGenome] = 'default'):; if isinstance(contig, int):; contig = str(contig). if isinstance(reference_genome, str):; reference_genome = hl.get_reference(reference_genome). assert isinstance(contig, str); assert isinstance(position, int); assert isinstance(reference_genome, ReferenceGenome). self._contig = contig; self._position = position; self._rg = reference_genome. def __str__(self):; return f'{self._contig}:{self._position}'. def __repr__(self):; return 'Locus(contig=%s, position=%s, reference_genome=%s)' % (self.contig, self.position, self._rg). def __eq__(self, other):; return (; (self._contig == other._contig and self._position == other._position and self._rg == other._rg); if isinstance(other, Locus); else NotImplemented; ). def __hash__(self):; return hash(self._contig) ^ hash(self._position) ^ hash(self._rg). [docs] @classmethod; @typecheck_method(string=str, reference_genome=reference_genome_type); def parse(cls, string, reference_genome='default'):; """"""Parses a locus object from a CHR:POS string. **Examples**. >>> l1 = hl.Locus.parse('1:101230'); >>> l2 = hl.Locus.parse('X:4201230'). :param str string: String to parse.; :param reference_genome: Reference genome to use. Default is :func:`~hail.default_reference`.; :type reference_genome: :class:`str` or :class:`.ReferenceGenome`. :rtype: :class:`.Locus`; """"""; contig, pos = string.split(':'); if pos.lower() == 'end':; pos = reference_genome.contig_length(contig); else:; pos = int(pos); return Locus(contig, pos, reference_genome). @property; def contig(self):; """"""; Chromosome identifier.; :rtype: str; """"""; return self._contig. @property; def position(self):; """"""; Chromosomal position (1-based).; :rtype: int; """"""; return self._position. @property; def reference_genome(self):; """"""Reference genome. :return",MatchSource.WIKI,docs/0.2/_modules/hail/genetics/locus.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/genetics/locus.html
https://hail.is/docs/0.2/_modules/hail/genetics/locus.html:2204,Security,hash,hash,2204,"ing the following functions:. - :func:`.locus`; - :func:`.parse_locus`; - :func:`.locus_from_global_position`; """""". def __init__(self, contig, position, reference_genome: Union[str, ReferenceGenome] = 'default'):; if isinstance(contig, int):; contig = str(contig). if isinstance(reference_genome, str):; reference_genome = hl.get_reference(reference_genome). assert isinstance(contig, str); assert isinstance(position, int); assert isinstance(reference_genome, ReferenceGenome). self._contig = contig; self._position = position; self._rg = reference_genome. def __str__(self):; return f'{self._contig}:{self._position}'. def __repr__(self):; return 'Locus(contig=%s, position=%s, reference_genome=%s)' % (self.contig, self.position, self._rg). def __eq__(self, other):; return (; (self._contig == other._contig and self._position == other._position and self._rg == other._rg); if isinstance(other, Locus); else NotImplemented; ). def __hash__(self):; return hash(self._contig) ^ hash(self._position) ^ hash(self._rg). [docs] @classmethod; @typecheck_method(string=str, reference_genome=reference_genome_type); def parse(cls, string, reference_genome='default'):; """"""Parses a locus object from a CHR:POS string. **Examples**. >>> l1 = hl.Locus.parse('1:101230'); >>> l2 = hl.Locus.parse('X:4201230'). :param str string: String to parse.; :param reference_genome: Reference genome to use. Default is :func:`~hail.default_reference`.; :type reference_genome: :class:`str` or :class:`.ReferenceGenome`. :rtype: :class:`.Locus`; """"""; contig, pos = string.split(':'); if pos.lower() == 'end':; pos = reference_genome.contig_length(contig); else:; pos = int(pos); return Locus(contig, pos, reference_genome). @property; def contig(self):; """"""; Chromosome identifier.; :rtype: str; """"""; return self._contig. @property; def position(self):; """"""; Chromosomal position (1-based).; :rtype: int; """"""; return self._position. @property; def reference_genome(self):; """"""Reference genome. :return: :class:`.ReferenceGe",MatchSource.WIKI,docs/0.2/_modules/hail/genetics/locus.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/genetics/locus.html
https://hail.is/docs/0.2/_modules/hail/genetics/locus.html:1561,Testability,assert,assert,1561,"ail.typecheck import typecheck_method. [docs]class Locus(object):; """"""An object that represents a location in the genome. Parameters; ----------; contig : :class:`str`; Chromosome identifier.; position : :obj:`int`; Chromosomal position (1-indexed).; reference_genome : :class:`str` or :class:`.ReferenceGenome`; Reference genome to use. Note; ----; This object refers to the Python value returned by taking or collecting; Hail expressions, e.g. ``mt.locus.take(5)``. This is rare; it is much; more common to manipulate the :class:`.LocusExpression` object, which is; constructed using the following functions:. - :func:`.locus`; - :func:`.parse_locus`; - :func:`.locus_from_global_position`; """""". def __init__(self, contig, position, reference_genome: Union[str, ReferenceGenome] = 'default'):; if isinstance(contig, int):; contig = str(contig). if isinstance(reference_genome, str):; reference_genome = hl.get_reference(reference_genome). assert isinstance(contig, str); assert isinstance(position, int); assert isinstance(reference_genome, ReferenceGenome). self._contig = contig; self._position = position; self._rg = reference_genome. def __str__(self):; return f'{self._contig}:{self._position}'. def __repr__(self):; return 'Locus(contig=%s, position=%s, reference_genome=%s)' % (self.contig, self.position, self._rg). def __eq__(self, other):; return (; (self._contig == other._contig and self._position == other._position and self._rg == other._rg); if isinstance(other, Locus); else NotImplemented; ). def __hash__(self):; return hash(self._contig) ^ hash(self._position) ^ hash(self._rg). [docs] @classmethod; @typecheck_method(string=str, reference_genome=reference_genome_type); def parse(cls, string, reference_genome='default'):; """"""Parses a locus object from a CHR:POS string. **Examples**. >>> l1 = hl.Locus.parse('1:101230'); >>> l2 = hl.Locus.parse('X:4201230'). :param str string: String to parse.; :param reference_genome: Reference genome to use. Default is :func:`~hail.default",MatchSource.WIKI,docs/0.2/_modules/hail/genetics/locus.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/genetics/locus.html
https://hail.is/docs/0.2/_modules/hail/genetics/locus.html:1593,Testability,assert,assert,1593,"ail.typecheck import typecheck_method. [docs]class Locus(object):; """"""An object that represents a location in the genome. Parameters; ----------; contig : :class:`str`; Chromosome identifier.; position : :obj:`int`; Chromosomal position (1-indexed).; reference_genome : :class:`str` or :class:`.ReferenceGenome`; Reference genome to use. Note; ----; This object refers to the Python value returned by taking or collecting; Hail expressions, e.g. ``mt.locus.take(5)``. This is rare; it is much; more common to manipulate the :class:`.LocusExpression` object, which is; constructed using the following functions:. - :func:`.locus`; - :func:`.parse_locus`; - :func:`.locus_from_global_position`; """""". def __init__(self, contig, position, reference_genome: Union[str, ReferenceGenome] = 'default'):; if isinstance(contig, int):; contig = str(contig). if isinstance(reference_genome, str):; reference_genome = hl.get_reference(reference_genome). assert isinstance(contig, str); assert isinstance(position, int); assert isinstance(reference_genome, ReferenceGenome). self._contig = contig; self._position = position; self._rg = reference_genome. def __str__(self):; return f'{self._contig}:{self._position}'. def __repr__(self):; return 'Locus(contig=%s, position=%s, reference_genome=%s)' % (self.contig, self.position, self._rg). def __eq__(self, other):; return (; (self._contig == other._contig and self._position == other._position and self._rg == other._rg); if isinstance(other, Locus); else NotImplemented; ). def __hash__(self):; return hash(self._contig) ^ hash(self._position) ^ hash(self._rg). [docs] @classmethod; @typecheck_method(string=str, reference_genome=reference_genome_type); def parse(cls, string, reference_genome='default'):; """"""Parses a locus object from a CHR:POS string. **Examples**. >>> l1 = hl.Locus.parse('1:101230'); >>> l2 = hl.Locus.parse('X:4201230'). :param str string: String to parse.; :param reference_genome: Reference genome to use. Default is :func:`~hail.default",MatchSource.WIKI,docs/0.2/_modules/hail/genetics/locus.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/genetics/locus.html
https://hail.is/docs/0.2/_modules/hail/genetics/locus.html:1627,Testability,assert,assert,1627,"ail.typecheck import typecheck_method. [docs]class Locus(object):; """"""An object that represents a location in the genome. Parameters; ----------; contig : :class:`str`; Chromosome identifier.; position : :obj:`int`; Chromosomal position (1-indexed).; reference_genome : :class:`str` or :class:`.ReferenceGenome`; Reference genome to use. Note; ----; This object refers to the Python value returned by taking or collecting; Hail expressions, e.g. ``mt.locus.take(5)``. This is rare; it is much; more common to manipulate the :class:`.LocusExpression` object, which is; constructed using the following functions:. - :func:`.locus`; - :func:`.parse_locus`; - :func:`.locus_from_global_position`; """""". def __init__(self, contig, position, reference_genome: Union[str, ReferenceGenome] = 'default'):; if isinstance(contig, int):; contig = str(contig). if isinstance(reference_genome, str):; reference_genome = hl.get_reference(reference_genome). assert isinstance(contig, str); assert isinstance(position, int); assert isinstance(reference_genome, ReferenceGenome). self._contig = contig; self._position = position; self._rg = reference_genome. def __str__(self):; return f'{self._contig}:{self._position}'. def __repr__(self):; return 'Locus(contig=%s, position=%s, reference_genome=%s)' % (self.contig, self.position, self._rg). def __eq__(self, other):; return (; (self._contig == other._contig and self._position == other._position and self._rg == other._rg); if isinstance(other, Locus); else NotImplemented; ). def __hash__(self):; return hash(self._contig) ^ hash(self._position) ^ hash(self._rg). [docs] @classmethod; @typecheck_method(string=str, reference_genome=reference_genome_type); def parse(cls, string, reference_genome='default'):; """"""Parses a locus object from a CHR:POS string. **Examples**. >>> l1 = hl.Locus.parse('1:101230'); >>> l2 = hl.Locus.parse('X:4201230'). :param str string: String to parse.; :param reference_genome: Reference genome to use. Default is :func:`~hail.default",MatchSource.WIKI,docs/0.2/_modules/hail/genetics/locus.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/genetics/locus.html
https://hail.is/docs/0.2/_modules/hail/genetics/pedigree.html:8020,Deployability,update,updated,8020,"}]"".format(; missing_sex_count, missing_sex_values; ); ). return Pedigree(trios). @property; def trios(self):; """"""List of trio objects in this pedigree. :rtype: list of :class:`.Trio`; """"""; return self._trios. [docs] def complete_trios(self):; """"""List of trio objects that have a defined father and mother. :rtype: list of :class:`.Trio`; """"""; return list(filter(lambda t: t.is_complete(), self.trios)). [docs] @typecheck_method(samples=sequenceof(nullable(str))); def filter_to(self, samples):; """"""Filter the pedigree to a given list of sample IDs. **Notes**. For any trio, the following steps will be applied:. - If the proband is not in the list of samples provided, the trio is removed.; - If the father is not in the list of samples provided, `pat_id` is set to ``None``.; - If the mother is not in the list of samples provided, `mat_id` is set to ``None``. Parameters; ----------; samples: :obj:`list` [:obj:`str`]; Sample IDs to keep. Returns; -------; :class:`.Pedigree`; """"""; sample_set = set(samples). filtered_trios = []; for trio in self._trios:; restricted_trio = trio._restrict_to(sample_set); if restricted_trio is not None:; filtered_trios.append(restricted_trio). return Pedigree(filtered_trios). [docs] @typecheck_method(path=str); def write(self, path):; """"""Write a .fam file to the given path. **Examples**. >>> ped = hl.Pedigree.read('data/test.fam'); >>> ped.write('output/out.fam'). **Notes**. This method writes a `PLINK .fam file <https://www.cog-genomics.org/plink2/formats#fam>`_. .. caution::. Phenotype information is not preserved in the Pedigree data; structure in Hail. Reading and writing a PLINK .fam file will; result in loss of this information. Use :func:`~.import_fam` to; manipulate this information. :param path: output path; :type path: str; """""". lines = [t._to_fam_file_line() for t in self._trios]. with Env.fs().open(path, mode=""w"") as file:; for line in lines:; file.write(line + ""\n""). © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,docs/0.2/_modules/hail/genetics/pedigree.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/genetics/pedigree.html
https://hail.is/docs/0.2/_modules/hail/genetics/pedigree.html:2003,Security,hash,hash,2003,"e: Sex of proband.; :type is_female: bool or None; """""". @typecheck_method(s=str, fam_id=nullable(str), pat_id=nullable(str), mat_id=nullable(str), is_female=nullable(bool)); def __init__(self, s, fam_id=None, pat_id=None, mat_id=None, is_female=None):; self._fam_id = fam_id; self._s = s; self._pat_id = pat_id; self._mat_id = mat_id; self._is_female = is_female. def __repr__(self):; return 'Trio(s=%s, fam_id=%s, pat_id=%s, mat_id=%s, is_female=%s)' % (; repr(self.s),; repr(self.fam_id),; repr(self.pat_id),; repr(self.mat_id),; repr(self.is_female),; ). def __str__(self):; return 'Trio(s=%s, fam_id=%s, pat_id=%s, mat_id=%s, is_female=%s)' % (; str(self.s),; str(self.fam_id),; str(self.pat_id),; str(self.mat_id),; str(self.is_female),; ). def __eq__(self, other):; return (; isinstance(other, Trio); and self._s == other._s; and self._mat_id == other._mat_id; and self._pat_id == other._pat_id; and self._fam_id == other._fam_id; and self._is_female == other._is_female; ). def __hash__(self):; return hash((self._s, self._pat_id, self._mat_id, self._fam_id, self._is_female)). @property; def s(self):; """"""ID of proband in trio, never missing. :rtype: str; """""". return self._s. @property; def pat_id(self):; """"""ID of father in trio, may be missing. :rtype: str or None; """""". return self._pat_id. @property; def mat_id(self):; """"""ID of mother in trio, may be missing. :rtype: str or None; """""". return self._mat_id. @property; def fam_id(self):; """"""Family ID. :rtype: str or None; """""". return self._fam_id. @property; def is_male(self):; """"""Returns ``True`` if the proband is a reported male,; ``False`` if reported female, and ``None`` if no sex is defined. :rtype: bool or None; """""". if self._is_female is None:; return None. return self._is_female is False. @property; def is_female(self):; """"""Returns ``True`` if the proband is a reported female,; ``False`` if reported male, and ``None`` if no sex is defined. :rtype: bool or None; """""". if self._is_female is None:; return None. return self",MatchSource.WIKI,docs/0.2/_modules/hail/genetics/pedigree.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/genetics/pedigree.html
https://hail.is/docs/0.2/_modules/hail/genetics/pedigree.html:4463,Security,hash,hash,4463,"; self._s,; self._fam_id,; self._pat_id if self._pat_id in ids else None,; self._mat_id if self._mat_id in ids else None,; self._is_female,; ). def _sex_as_numeric_string(self):; if self._is_female is None:; return ""0""; return ""2"" if self.is_female else ""1"". def _to_fam_file_line(self):; def sample_id_or_else_zero(sample_id):; if sample_id is None:; return ""0""; return sample_id. line_list = [; sample_id_or_else_zero(self._fam_id),; self._s,; sample_id_or_else_zero(self._pat_id),; sample_id_or_else_zero(self._mat_id),; self._sex_as_numeric_string(),; ""0"",; ]; return ""\t"".join(line_list). [docs]class Pedigree(object):; """"""Class containing a list of trios, with extra functionality. :param trios: list of trio objects to include in pedigree; :type trios: list of :class:`.Trio`; """""". @typecheck_method(trios=sequenceof(Trio)); def __init__(self, trios):; self._trios = tuple(trios). def __eq__(self, other):; return isinstance(other, Pedigree) and self._trios == other._trios. def __hash__(self):; return hash(self._trios). def __iter__(self):; return self._trios.__iter__(). [docs] @classmethod; @typecheck_method(fam_path=str, delimiter=str); def read(cls, fam_path, delimiter='\\s+') -> 'Pedigree':; """"""Read a PLINK .fam file and return a pedigree object. **Examples**. >>> ped = hl.Pedigree.read('data/test.fam'). Notes; -------. See `PLINK .fam file <https://www.cog-genomics.org/plink2/formats#fam>`_ for; the required format. :param str fam_path: path to .fam file. :param str delimiter: Field delimiter. :rtype: :class:`.Pedigree`; """""". trios = []; missing_sex_count = 0; missing_sex_values = set(); with Env.fs().open(fam_path) as file:; for line in file:; split_line = re.split(delimiter, line.strip()); num_fields = len(split_line); if num_fields != 6:; raise FatalError(; ""Require 6 fields per line in .fam, but this line has {}: {}"".format(num_fields, line); ); (fam, kid, dad, mom, sex, _) = tuple(split_line); # 1 is male, 2 is female, 0 is unknown.; is_female = sex == ""2"" if sex ",MatchSource.WIKI,docs/0.2/_modules/hail/genetics/pedigree.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/genetics/pedigree.html
https://hail.is/docs/0.2/_modules/hail/genetics/pedigree.html:4764,Testability,test,test,4764,"se_zero(sample_id):; if sample_id is None:; return ""0""; return sample_id. line_list = [; sample_id_or_else_zero(self._fam_id),; self._s,; sample_id_or_else_zero(self._pat_id),; sample_id_or_else_zero(self._mat_id),; self._sex_as_numeric_string(),; ""0"",; ]; return ""\t"".join(line_list). [docs]class Pedigree(object):; """"""Class containing a list of trios, with extra functionality. :param trios: list of trio objects to include in pedigree; :type trios: list of :class:`.Trio`; """""". @typecheck_method(trios=sequenceof(Trio)); def __init__(self, trios):; self._trios = tuple(trios). def __eq__(self, other):; return isinstance(other, Pedigree) and self._trios == other._trios. def __hash__(self):; return hash(self._trios). def __iter__(self):; return self._trios.__iter__(). [docs] @classmethod; @typecheck_method(fam_path=str, delimiter=str); def read(cls, fam_path, delimiter='\\s+') -> 'Pedigree':; """"""Read a PLINK .fam file and return a pedigree object. **Examples**. >>> ped = hl.Pedigree.read('data/test.fam'). Notes; -------. See `PLINK .fam file <https://www.cog-genomics.org/plink2/formats#fam>`_ for; the required format. :param str fam_path: path to .fam file. :param str delimiter: Field delimiter. :rtype: :class:`.Pedigree`; """""". trios = []; missing_sex_count = 0; missing_sex_values = set(); with Env.fs().open(fam_path) as file:; for line in file:; split_line = re.split(delimiter, line.strip()); num_fields = len(split_line); if num_fields != 6:; raise FatalError(; ""Require 6 fields per line in .fam, but this line has {}: {}"".format(num_fields, line); ); (fam, kid, dad, mom, sex, _) = tuple(split_line); # 1 is male, 2 is female, 0 is unknown.; is_female = sex == ""2"" if sex in {'1', '2'} else None. if is_female is None:; missing_sex_count += 1; missing_sex_values.add(kid). trio = Trio(; kid,; fam if fam != ""0"" else None,; dad if dad != ""0"" else None,; mom if mom != ""0"" else None,; is_female,; ); trios.append(trio). only_ids = [trio.s for trio in trios]; duplicate_ids = [id fo",MatchSource.WIKI,docs/0.2/_modules/hail/genetics/pedigree.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/genetics/pedigree.html
https://hail.is/docs/0.2/_modules/hail/genetics/pedigree.html:7409,Testability,test,test,7409,"}]"".format(; missing_sex_count, missing_sex_values; ); ). return Pedigree(trios). @property; def trios(self):; """"""List of trio objects in this pedigree. :rtype: list of :class:`.Trio`; """"""; return self._trios. [docs] def complete_trios(self):; """"""List of trio objects that have a defined father and mother. :rtype: list of :class:`.Trio`; """"""; return list(filter(lambda t: t.is_complete(), self.trios)). [docs] @typecheck_method(samples=sequenceof(nullable(str))); def filter_to(self, samples):; """"""Filter the pedigree to a given list of sample IDs. **Notes**. For any trio, the following steps will be applied:. - If the proband is not in the list of samples provided, the trio is removed.; - If the father is not in the list of samples provided, `pat_id` is set to ``None``.; - If the mother is not in the list of samples provided, `mat_id` is set to ``None``. Parameters; ----------; samples: :obj:`list` [:obj:`str`]; Sample IDs to keep. Returns; -------; :class:`.Pedigree`; """"""; sample_set = set(samples). filtered_trios = []; for trio in self._trios:; restricted_trio = trio._restrict_to(sample_set); if restricted_trio is not None:; filtered_trios.append(restricted_trio). return Pedigree(filtered_trios). [docs] @typecheck_method(path=str); def write(self, path):; """"""Write a .fam file to the given path. **Examples**. >>> ped = hl.Pedigree.read('data/test.fam'); >>> ped.write('output/out.fam'). **Notes**. This method writes a `PLINK .fam file <https://www.cog-genomics.org/plink2/formats#fam>`_. .. caution::. Phenotype information is not preserved in the Pedigree data; structure in Hail. Reading and writing a PLINK .fam file will; result in loss of this information. Use :func:`~.import_fam` to; manipulate this information. :param path: output path; :type path: str; """""". lines = [t._to_fam_file_line() for t in self._trios]. with Env.fs().open(path, mode=""w"") as file:; for line in lines:; file.write(line + ""\n""). © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,docs/0.2/_modules/hail/genetics/pedigree.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/genetics/pedigree.html
https://hail.is/docs/0.2/_modules/hail/genetics/reference_genome.html:10326,Availability,down,download,10326,"ce genome using :func:`~hail.get_reference`:. >>> rg = hl.get_reference('GRCh37') # doctest: +SKIP. Add a sequence file:. >>> rg.add_sequence('gs://hail-common/references/human_g1k_v37.fasta.gz',; ... 'gs://hail-common/references/human_g1k_v37.fasta.fai') # doctest: +SKIP. Add a sequence file with the default index location:. >>> rg.add_sequence('gs://hail-common/references/human_g1k_v37.fasta.gz') # doctest: +SKIP. Notes; -----; This method can only be run once per reference genome. Use; :meth:`~has_sequence` to test whether a sequence is loaded. FASTA and index files are hosted on google cloud for some of Hail's built-in; references:. **GRCh37**. - FASTA file: ``gs://hail-common/references/human_g1k_v37.fasta.gz``; - Index file: ``gs://hail-common/references/human_g1k_v37.fasta.fai``. **GRCh38**. - FASTA file: ``gs://hail-common/references/Homo_sapiens_assembly38.fasta.gz``; - Index file: ``gs://hail-common/references/Homo_sapiens_assembly38.fasta.fai``. Public download links are available; `here <https://console.cloud.google.com/storage/browser/hail-common/references/>`__. Parameters; ----------; fasta_file : :class:`str`; Path to FASTA file. Can be compressed (GZIP) or uncompressed.; index_file : :obj:`None` or :class:`str`; Path to FASTA index file. Must be uncompressed. If `None`, replace; the fasta_file's extension with `fai`.; """"""; if index_file is None:; index_file = re.sub(r'\.[^.]*$', '.fai', fasta_file); Env.backend().add_sequence(self.name, fasta_file, index_file); self._sequence_files = (fasta_file, index_file). [docs] def has_sequence(self):; """"""True if the reference sequence has been loaded. Returns; -------; :obj:`bool`; """"""; return self._sequence_files is not None. [docs] def remove_sequence(self):; """"""Remove the reference sequence.""""""; self._sequence_files = None; Env.backend().remove_sequence(self.name). [docs] @classmethod; @typecheck_method(; name=str,; fasta_file=str,; index_file=str,; x_contigs=oneof(str, sequenceof(str)),; y_contigs=oneof(str",MatchSource.WIKI,docs/0.2/_modules/hail/genetics/reference_genome.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/genetics/reference_genome.html
https://hail.is/docs/0.2/_modules/hail/genetics/reference_genome.html:10345,Availability,avail,available,10345,"ce genome using :func:`~hail.get_reference`:. >>> rg = hl.get_reference('GRCh37') # doctest: +SKIP. Add a sequence file:. >>> rg.add_sequence('gs://hail-common/references/human_g1k_v37.fasta.gz',; ... 'gs://hail-common/references/human_g1k_v37.fasta.fai') # doctest: +SKIP. Add a sequence file with the default index location:. >>> rg.add_sequence('gs://hail-common/references/human_g1k_v37.fasta.gz') # doctest: +SKIP. Notes; -----; This method can only be run once per reference genome. Use; :meth:`~has_sequence` to test whether a sequence is loaded. FASTA and index files are hosted on google cloud for some of Hail's built-in; references:. **GRCh37**. - FASTA file: ``gs://hail-common/references/human_g1k_v37.fasta.gz``; - Index file: ``gs://hail-common/references/human_g1k_v37.fasta.fai``. **GRCh38**. - FASTA file: ``gs://hail-common/references/Homo_sapiens_assembly38.fasta.gz``; - Index file: ``gs://hail-common/references/Homo_sapiens_assembly38.fasta.fai``. Public download links are available; `here <https://console.cloud.google.com/storage/browser/hail-common/references/>`__. Parameters; ----------; fasta_file : :class:`str`; Path to FASTA file. Can be compressed (GZIP) or uncompressed.; index_file : :obj:`None` or :class:`str`; Path to FASTA index file. Must be uncompressed. If `None`, replace; the fasta_file's extension with `fai`.; """"""; if index_file is None:; index_file = re.sub(r'\.[^.]*$', '.fai', fasta_file); Env.backend().add_sequence(self.name, fasta_file, index_file); self._sequence_files = (fasta_file, index_file). [docs] def has_sequence(self):; """"""True if the reference sequence has been loaded. Returns; -------; :obj:`bool`; """"""; return self._sequence_files is not None. [docs] def remove_sequence(self):; """"""Remove the reference sequence.""""""; self._sequence_files = None; Env.backend().remove_sequence(self.name). [docs] @classmethod; @typecheck_method(; name=str,; fasta_file=str,; index_file=str,; x_contigs=oneof(str, sequenceof(str)),; y_contigs=oneof(str",MatchSource.WIKI,docs/0.2/_modules/hail/genetics/reference_genome.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/genetics/reference_genome.html
https://hail.is/docs/0.2/_modules/hail/genetics/reference_genome.html:12758,Availability,avail,available,12758,"`str`; Path to FASTA file. Can be compressed (GZIP) or uncompressed.; index_file : :class:`str`; Path to FASTA index file. Must be uncompressed.; x_contigs : :class:`str` or :obj:`list` of :obj:`str`; Contigs to be treated as X chromosomes.; y_contigs : :class:`str` or :obj:`list` of :obj:`str`; Contigs to be treated as Y chromosomes.; mt_contigs : :class:`str` or :obj:`list` of :obj:`str`; Contigs to be treated as mitochondrial DNA.; par : :obj:`list` of :obj:`tuple` of (str, int, int); List of tuples with (contig, start, end). Returns; -------; :class:`.ReferenceGenome`; """"""; par_strings = [""{}:{}-{}"".format(contig, start, end) for (contig, start, end) in par]; config = Env.backend().from_fasta_file(; name, fasta_file, index_file, x_contigs, y_contigs, mt_contigs, par_strings; ). rg = ReferenceGenome._from_config(config); rg.add_sequence(fasta_file, index_file); return rg. [docs] @typecheck_method(dest_reference_genome=reference_genome_type); def has_liftover(self, dest_reference_genome):; """"""``True`` if a liftover chain file is available from this reference; genome to the destination reference. Parameters; ----------; dest_reference_genome : :class:`str` or :class:`.ReferenceGenome`. Returns; -------; :obj:`bool`; """"""; return dest_reference_genome.name in self._liftovers. [docs] @typecheck_method(dest_reference_genome=reference_genome_type); def remove_liftover(self, dest_reference_genome):; """"""Remove liftover to `dest_reference_genome`. Parameters; ----------; dest_reference_genome : :class:`str` or :class:`.ReferenceGenome`; """"""; if dest_reference_genome.name in self._liftovers:; del self._liftovers[dest_reference_genome.name]; Env.backend().remove_liftover(self.name, dest_reference_genome.name). [docs] @typecheck_method(chain_file=str, dest_reference_genome=reference_genome_type); def add_liftover(self, chain_file, dest_reference_genome):; """"""Register a chain file for liftover. Examples; --------; Access GRCh37 and GRCh38 using :func:`~hail.get_reference`:. >>>",MatchSource.WIKI,docs/0.2/_modules/hail/genetics/reference_genome.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/genetics/reference_genome.html
https://hail.is/docs/0.2/_modules/hail/genetics/reference_genome.html:14459,Availability,down,download,14459,", dest_reference_genome=reference_genome_type); def add_liftover(self, chain_file, dest_reference_genome):; """"""Register a chain file for liftover. Examples; --------; Access GRCh37 and GRCh38 using :func:`~hail.get_reference`:. >>> rg37 = hl.get_reference('GRCh37') # doctest: +SKIP; >>> rg38 = hl.get_reference('GRCh38') # doctest: +SKIP. Add a chain file from 37 to 38:. >>> rg37.add_liftover('gs://hail-common/references/grch37_to_grch38.over.chain.gz', rg38) # doctest: +SKIP. Notes; -----; This method can only be run once per reference genome. Use; :meth:`~has_liftover` to test whether a chain file has been registered. The chain file format is described; `here <https://genome.ucsc.edu/goldenpath/help/chain.html>`__. Chain files are hosted on google cloud for some of Hail's built-in; references:. **GRCh37 to GRCh38**; gs://hail-common/references/grch37_to_grch38.over.chain.gz. **GRCh38 to GRCh37**; gs://hail-common/references/grch38_to_grch37.over.chain.gz. Public download links are available; `here <https://console.cloud.google.com/storage/browser/hail-common/references/>`__. Parameters; ----------; chain_file : :class:`str`; Path to chain file. Can be compressed (GZIP) or uncompressed.; dest_reference_genome : :class:`str` or :class:`.ReferenceGenome`; Reference genome to convert to.; """""". Env.backend().add_liftover(self.name, chain_file, dest_reference_genome.name); if dest_reference_genome.name in self._liftovers:; raise KeyError(f""Liftover already exists from {self.name} to {dest_reference_genome.name}.""); if dest_reference_genome.name == self.name:; raise ValueError(f'Destination reference genome cannot have the same name as this reference {self.name}.'); self._liftovers[dest_reference_genome.name] = chain_file. [docs] @typecheck_method(global_pos=int); def locus_from_global_position(self, global_pos: int) -> 'hl.Locus':; """""" ""; Constructs a locus from a global position in reference genome.; The inverse of :meth:`.Locus.position`. Examples; --------; >>> rg = hl",MatchSource.WIKI,docs/0.2/_modules/hail/genetics/reference_genome.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/genetics/reference_genome.html
https://hail.is/docs/0.2/_modules/hail/genetics/reference_genome.html:14478,Availability,avail,available,14478,", dest_reference_genome=reference_genome_type); def add_liftover(self, chain_file, dest_reference_genome):; """"""Register a chain file for liftover. Examples; --------; Access GRCh37 and GRCh38 using :func:`~hail.get_reference`:. >>> rg37 = hl.get_reference('GRCh37') # doctest: +SKIP; >>> rg38 = hl.get_reference('GRCh38') # doctest: +SKIP. Add a chain file from 37 to 38:. >>> rg37.add_liftover('gs://hail-common/references/grch37_to_grch38.over.chain.gz', rg38) # doctest: +SKIP. Notes; -----; This method can only be run once per reference genome. Use; :meth:`~has_liftover` to test whether a chain file has been registered. The chain file format is described; `here <https://genome.ucsc.edu/goldenpath/help/chain.html>`__. Chain files are hosted on google cloud for some of Hail's built-in; references:. **GRCh37 to GRCh38**; gs://hail-common/references/grch37_to_grch38.over.chain.gz. **GRCh38 to GRCh37**; gs://hail-common/references/grch38_to_grch37.over.chain.gz. Public download links are available; `here <https://console.cloud.google.com/storage/browser/hail-common/references/>`__. Parameters; ----------; chain_file : :class:`str`; Path to chain file. Can be compressed (GZIP) or uncompressed.; dest_reference_genome : :class:`str` or :class:`.ReferenceGenome`; Reference genome to convert to.; """""". Env.backend().add_liftover(self.name, chain_file, dest_reference_genome.name); if dest_reference_genome.name in self._liftovers:; raise KeyError(f""Liftover already exists from {self.name} to {dest_reference_genome.name}.""); if dest_reference_genome.name == self.name:; raise ValueError(f'Destination reference genome cannot have the same name as this reference {self.name}.'); self._liftovers[dest_reference_genome.name] = chain_file. [docs] @typecheck_method(global_pos=int); def locus_from_global_position(self, global_pos: int) -> 'hl.Locus':; """""" ""; Constructs a locus from a global position in reference genome.; The inverse of :meth:`.Locus.position`. Examples; --------; >>> rg = hl",MatchSource.WIKI,docs/0.2/_modules/hail/genetics/reference_genome.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/genetics/reference_genome.html
https://hail.is/docs/0.2/_modules/hail/genetics/reference_genome.html:16681,Deployability,update,updated,16681," : :class:`str` or :class:`.ReferenceGenome`; Reference genome to convert to.; """""". Env.backend().add_liftover(self.name, chain_file, dest_reference_genome.name); if dest_reference_genome.name in self._liftovers:; raise KeyError(f""Liftover already exists from {self.name} to {dest_reference_genome.name}.""); if dest_reference_genome.name == self.name:; raise ValueError(f'Destination reference genome cannot have the same name as this reference {self.name}.'); self._liftovers[dest_reference_genome.name] = chain_file. [docs] @typecheck_method(global_pos=int); def locus_from_global_position(self, global_pos: int) -> 'hl.Locus':; """""" ""; Constructs a locus from a global position in reference genome.; The inverse of :meth:`.Locus.position`. Examples; --------; >>> rg = hl.get_reference('GRCh37'); >>> rg.locus_from_global_position(0); Locus(contig=1, position=1, reference_genome=GRCh37). >>> rg.locus_from_global_position(2824183054); Locus(contig=21, position=42584230, reference_genome=GRCh37). >>> rg = hl.get_reference('GRCh38'); >>> rg.locus_from_global_position(2824183054); Locus(contig=chr22, position=1, reference_genome=GRCh38). Parameters; ----------; global_pos : int; Zero-based global base position along the reference genome. Returns; -------; :class:`.Locus`; """"""; if global_pos < 0:; raise ValueError(f""global_pos must be non-negative, got {global_pos}""). if self._global_positions_list is None:; # dicts are in insertion order as of 3.7; self._global_positions_list = list(self.global_positions_dict.values()). global_positions = self._global_positions_list; contig = self.contigs[bisect_right(global_positions, global_pos) - 1]; contig_pos = self.global_positions_dict[contig]. if global_pos >= contig_pos + self.lengths[contig]:; raise ValueError(f""global_pos {global_pos} exceeds length of reference genome {self}.""). return hl.Locus(contig, global_pos - contig_pos + 1, self). rg_type.set(ReferenceGenome). © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,docs/0.2/_modules/hail/genetics/reference_genome.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/genetics/reference_genome.html
https://hail.is/docs/0.2/_modules/hail/genetics/reference_genome.html:3419,Modifiability,config,config,3419,"`. In order to set a custom reference genome as default,; pass the reference as an argument to :func:`~hail.default_reference` after; initializing Hail. Parameters; ----------; name : :class:`str`; Name of reference. Must be unique and NOT one of Hail's; predefined references: ``'GRCh37'``, ``'GRCh38'``, ``'GRCm38'``,; ``'CanFam3'`` and ``'default'``.; contigs : :obj:`list` of :class:`str`; Contig names.; lengths : :obj:`dict` of :class:`str` to :obj:`int`; Dict of contig names to contig lengths.; x_contigs : :class:`str` or :obj:`list` of :obj:`str`; Contigs to be treated as X chromosomes.; y_contigs : :class:`str` or :obj:`list` of :obj:`str`; Contigs to be treated as Y chromosomes.; mt_contigs : :class:`str` or :obj:`list` of :obj:`str`; Contigs to be treated as mitochondrial DNA.; par : :obj:`list` of :obj:`tuple` of (str, int, int); List of tuples with (contig, start, end); """""". @classmethod; def _from_config(cls, config, _builtin=False):; def par_tuple(p):; assert p['start']['contig'] == p['end']['contig']; return (p['start']['contig'], p['start']['position'], p['end']['position']). contigs = config['contigs']; return ReferenceGenome(; config['name'],; [c['name'] for c in contigs],; {c['name']: c['length'] for c in contigs},; config['xContigs'],; config['yContigs'],; config['mtContigs'],; [par_tuple(p) for p in config['par']],; _builtin,; ). @typecheck_method(; name=str,; contigs=sequenceof(str),; lengths=dictof(str, int),; x_contigs=oneof(str, sequenceof(str)),; y_contigs=oneof(str, sequenceof(str)),; mt_contigs=oneof(str, sequenceof(str)),; par=sequenceof(sized_tupleof(str, int, int)),; _builtin=bool,; ); def __init__(self, name, contigs, lengths, x_contigs=[], y_contigs=[], mt_contigs=[], par=[], _builtin=False):; contigs = wrap_to_list(contigs); x_contigs = wrap_to_list(x_contigs); y_contigs = wrap_to_list(y_contigs); mt_contigs = wrap_to_list(mt_contigs). self._config = {; 'name': name,; 'contigs': [{'name': c, 'length': l} for c, l in lengths.items()],; '",MatchSource.WIKI,docs/0.2/_modules/hail/genetics/reference_genome.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/genetics/reference_genome.html
https://hail.is/docs/0.2/_modules/hail/genetics/reference_genome.html:3602,Modifiability,config,config,3602,"OT one of Hail's; predefined references: ``'GRCh37'``, ``'GRCh38'``, ``'GRCm38'``,; ``'CanFam3'`` and ``'default'``.; contigs : :obj:`list` of :class:`str`; Contig names.; lengths : :obj:`dict` of :class:`str` to :obj:`int`; Dict of contig names to contig lengths.; x_contigs : :class:`str` or :obj:`list` of :obj:`str`; Contigs to be treated as X chromosomes.; y_contigs : :class:`str` or :obj:`list` of :obj:`str`; Contigs to be treated as Y chromosomes.; mt_contigs : :class:`str` or :obj:`list` of :obj:`str`; Contigs to be treated as mitochondrial DNA.; par : :obj:`list` of :obj:`tuple` of (str, int, int); List of tuples with (contig, start, end); """""". @classmethod; def _from_config(cls, config, _builtin=False):; def par_tuple(p):; assert p['start']['contig'] == p['end']['contig']; return (p['start']['contig'], p['start']['position'], p['end']['position']). contigs = config['contigs']; return ReferenceGenome(; config['name'],; [c['name'] for c in contigs],; {c['name']: c['length'] for c in contigs},; config['xContigs'],; config['yContigs'],; config['mtContigs'],; [par_tuple(p) for p in config['par']],; _builtin,; ). @typecheck_method(; name=str,; contigs=sequenceof(str),; lengths=dictof(str, int),; x_contigs=oneof(str, sequenceof(str)),; y_contigs=oneof(str, sequenceof(str)),; mt_contigs=oneof(str, sequenceof(str)),; par=sequenceof(sized_tupleof(str, int, int)),; _builtin=bool,; ); def __init__(self, name, contigs, lengths, x_contigs=[], y_contigs=[], mt_contigs=[], par=[], _builtin=False):; contigs = wrap_to_list(contigs); x_contigs = wrap_to_list(x_contigs); y_contigs = wrap_to_list(y_contigs); mt_contigs = wrap_to_list(mt_contigs). self._config = {; 'name': name,; 'contigs': [{'name': c, 'length': l} for c, l in lengths.items()],; 'xContigs': x_contigs,; 'yContigs': y_contigs,; 'mtContigs': mt_contigs,; 'par': [{'start': {'contig': c, 'position': s}, 'end': {'contig': c, 'position': e}} for (c, s, e) in par],; }. self._contigs = contigs; self._lengths = lengths; s",MatchSource.WIKI,docs/0.2/_modules/hail/genetics/reference_genome.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/genetics/reference_genome.html
https://hail.is/docs/0.2/_modules/hail/genetics/reference_genome.html:3646,Modifiability,config,config,3646,"OT one of Hail's; predefined references: ``'GRCh37'``, ``'GRCh38'``, ``'GRCm38'``,; ``'CanFam3'`` and ``'default'``.; contigs : :obj:`list` of :class:`str`; Contig names.; lengths : :obj:`dict` of :class:`str` to :obj:`int`; Dict of contig names to contig lengths.; x_contigs : :class:`str` or :obj:`list` of :obj:`str`; Contigs to be treated as X chromosomes.; y_contigs : :class:`str` or :obj:`list` of :obj:`str`; Contigs to be treated as Y chromosomes.; mt_contigs : :class:`str` or :obj:`list` of :obj:`str`; Contigs to be treated as mitochondrial DNA.; par : :obj:`list` of :obj:`tuple` of (str, int, int); List of tuples with (contig, start, end); """""". @classmethod; def _from_config(cls, config, _builtin=False):; def par_tuple(p):; assert p['start']['contig'] == p['end']['contig']; return (p['start']['contig'], p['start']['position'], p['end']['position']). contigs = config['contigs']; return ReferenceGenome(; config['name'],; [c['name'] for c in contigs],; {c['name']: c['length'] for c in contigs},; config['xContigs'],; config['yContigs'],; config['mtContigs'],; [par_tuple(p) for p in config['par']],; _builtin,; ). @typecheck_method(; name=str,; contigs=sequenceof(str),; lengths=dictof(str, int),; x_contigs=oneof(str, sequenceof(str)),; y_contigs=oneof(str, sequenceof(str)),; mt_contigs=oneof(str, sequenceof(str)),; par=sequenceof(sized_tupleof(str, int, int)),; _builtin=bool,; ); def __init__(self, name, contigs, lengths, x_contigs=[], y_contigs=[], mt_contigs=[], par=[], _builtin=False):; contigs = wrap_to_list(contigs); x_contigs = wrap_to_list(x_contigs); y_contigs = wrap_to_list(y_contigs); mt_contigs = wrap_to_list(mt_contigs). self._config = {; 'name': name,; 'contigs': [{'name': c, 'length': l} for c, l in lengths.items()],; 'xContigs': x_contigs,; 'yContigs': y_contigs,; 'mtContigs': mt_contigs,; 'par': [{'start': {'contig': c, 'position': s}, 'end': {'contig': c, 'position': e}} for (c, s, e) in par],; }. self._contigs = contigs; self._lengths = lengths; s",MatchSource.WIKI,docs/0.2/_modules/hail/genetics/reference_genome.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/genetics/reference_genome.html
https://hail.is/docs/0.2/_modules/hail/genetics/reference_genome.html:3738,Modifiability,config,config,3738,"OT one of Hail's; predefined references: ``'GRCh37'``, ``'GRCh38'``, ``'GRCm38'``,; ``'CanFam3'`` and ``'default'``.; contigs : :obj:`list` of :class:`str`; Contig names.; lengths : :obj:`dict` of :class:`str` to :obj:`int`; Dict of contig names to contig lengths.; x_contigs : :class:`str` or :obj:`list` of :obj:`str`; Contigs to be treated as X chromosomes.; y_contigs : :class:`str` or :obj:`list` of :obj:`str`; Contigs to be treated as Y chromosomes.; mt_contigs : :class:`str` or :obj:`list` of :obj:`str`; Contigs to be treated as mitochondrial DNA.; par : :obj:`list` of :obj:`tuple` of (str, int, int); List of tuples with (contig, start, end); """""". @classmethod; def _from_config(cls, config, _builtin=False):; def par_tuple(p):; assert p['start']['contig'] == p['end']['contig']; return (p['start']['contig'], p['start']['position'], p['end']['position']). contigs = config['contigs']; return ReferenceGenome(; config['name'],; [c['name'] for c in contigs],; {c['name']: c['length'] for c in contigs},; config['xContigs'],; config['yContigs'],; config['mtContigs'],; [par_tuple(p) for p in config['par']],; _builtin,; ). @typecheck_method(; name=str,; contigs=sequenceof(str),; lengths=dictof(str, int),; x_contigs=oneof(str, sequenceof(str)),; y_contigs=oneof(str, sequenceof(str)),; mt_contigs=oneof(str, sequenceof(str)),; par=sequenceof(sized_tupleof(str, int, int)),; _builtin=bool,; ); def __init__(self, name, contigs, lengths, x_contigs=[], y_contigs=[], mt_contigs=[], par=[], _builtin=False):; contigs = wrap_to_list(contigs); x_contigs = wrap_to_list(x_contigs); y_contigs = wrap_to_list(y_contigs); mt_contigs = wrap_to_list(mt_contigs). self._config = {; 'name': name,; 'contigs': [{'name': c, 'length': l} for c, l in lengths.items()],; 'xContigs': x_contigs,; 'yContigs': y_contigs,; 'mtContigs': mt_contigs,; 'par': [{'start': {'contig': c, 'position': s}, 'end': {'contig': c, 'position': e}} for (c, s, e) in par],; }. self._contigs = contigs; self._lengths = lengths; s",MatchSource.WIKI,docs/0.2/_modules/hail/genetics/reference_genome.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/genetics/reference_genome.html
https://hail.is/docs/0.2/_modules/hail/genetics/reference_genome.html:3759,Modifiability,config,config,3759,"OT one of Hail's; predefined references: ``'GRCh37'``, ``'GRCh38'``, ``'GRCm38'``,; ``'CanFam3'`` and ``'default'``.; contigs : :obj:`list` of :class:`str`; Contig names.; lengths : :obj:`dict` of :class:`str` to :obj:`int`; Dict of contig names to contig lengths.; x_contigs : :class:`str` or :obj:`list` of :obj:`str`; Contigs to be treated as X chromosomes.; y_contigs : :class:`str` or :obj:`list` of :obj:`str`; Contigs to be treated as Y chromosomes.; mt_contigs : :class:`str` or :obj:`list` of :obj:`str`; Contigs to be treated as mitochondrial DNA.; par : :obj:`list` of :obj:`tuple` of (str, int, int); List of tuples with (contig, start, end); """""". @classmethod; def _from_config(cls, config, _builtin=False):; def par_tuple(p):; assert p['start']['contig'] == p['end']['contig']; return (p['start']['contig'], p['start']['position'], p['end']['position']). contigs = config['contigs']; return ReferenceGenome(; config['name'],; [c['name'] for c in contigs],; {c['name']: c['length'] for c in contigs},; config['xContigs'],; config['yContigs'],; config['mtContigs'],; [par_tuple(p) for p in config['par']],; _builtin,; ). @typecheck_method(; name=str,; contigs=sequenceof(str),; lengths=dictof(str, int),; x_contigs=oneof(str, sequenceof(str)),; y_contigs=oneof(str, sequenceof(str)),; mt_contigs=oneof(str, sequenceof(str)),; par=sequenceof(sized_tupleof(str, int, int)),; _builtin=bool,; ); def __init__(self, name, contigs, lengths, x_contigs=[], y_contigs=[], mt_contigs=[], par=[], _builtin=False):; contigs = wrap_to_list(contigs); x_contigs = wrap_to_list(x_contigs); y_contigs = wrap_to_list(y_contigs); mt_contigs = wrap_to_list(mt_contigs). self._config = {; 'name': name,; 'contigs': [{'name': c, 'length': l} for c, l in lengths.items()],; 'xContigs': x_contigs,; 'yContigs': y_contigs,; 'mtContigs': mt_contigs,; 'par': [{'start': {'contig': c, 'position': s}, 'end': {'contig': c, 'position': e}} for (c, s, e) in par],; }. self._contigs = contigs; self._lengths = lengths; s",MatchSource.WIKI,docs/0.2/_modules/hail/genetics/reference_genome.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/genetics/reference_genome.html
https://hail.is/docs/0.2/_modules/hail/genetics/reference_genome.html:3780,Modifiability,config,config,3780,"OT one of Hail's; predefined references: ``'GRCh37'``, ``'GRCh38'``, ``'GRCm38'``,; ``'CanFam3'`` and ``'default'``.; contigs : :obj:`list` of :class:`str`; Contig names.; lengths : :obj:`dict` of :class:`str` to :obj:`int`; Dict of contig names to contig lengths.; x_contigs : :class:`str` or :obj:`list` of :obj:`str`; Contigs to be treated as X chromosomes.; y_contigs : :class:`str` or :obj:`list` of :obj:`str`; Contigs to be treated as Y chromosomes.; mt_contigs : :class:`str` or :obj:`list` of :obj:`str`; Contigs to be treated as mitochondrial DNA.; par : :obj:`list` of :obj:`tuple` of (str, int, int); List of tuples with (contig, start, end); """""". @classmethod; def _from_config(cls, config, _builtin=False):; def par_tuple(p):; assert p['start']['contig'] == p['end']['contig']; return (p['start']['contig'], p['start']['position'], p['end']['position']). contigs = config['contigs']; return ReferenceGenome(; config['name'],; [c['name'] for c in contigs],; {c['name']: c['length'] for c in contigs},; config['xContigs'],; config['yContigs'],; config['mtContigs'],; [par_tuple(p) for p in config['par']],; _builtin,; ). @typecheck_method(; name=str,; contigs=sequenceof(str),; lengths=dictof(str, int),; x_contigs=oneof(str, sequenceof(str)),; y_contigs=oneof(str, sequenceof(str)),; mt_contigs=oneof(str, sequenceof(str)),; par=sequenceof(sized_tupleof(str, int, int)),; _builtin=bool,; ); def __init__(self, name, contigs, lengths, x_contigs=[], y_contigs=[], mt_contigs=[], par=[], _builtin=False):; contigs = wrap_to_list(contigs); x_contigs = wrap_to_list(x_contigs); y_contigs = wrap_to_list(y_contigs); mt_contigs = wrap_to_list(mt_contigs). self._config = {; 'name': name,; 'contigs': [{'name': c, 'length': l} for c, l in lengths.items()],; 'xContigs': x_contigs,; 'yContigs': y_contigs,; 'mtContigs': mt_contigs,; 'par': [{'start': {'contig': c, 'position': s}, 'end': {'contig': c, 'position': e}} for (c, s, e) in par],; }. self._contigs = contigs; self._lengths = lengths; s",MatchSource.WIKI,docs/0.2/_modules/hail/genetics/reference_genome.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/genetics/reference_genome.html
https://hail.is/docs/0.2/_modules/hail/genetics/reference_genome.html:3825,Modifiability,config,config,3825,"OT one of Hail's; predefined references: ``'GRCh37'``, ``'GRCh38'``, ``'GRCm38'``,; ``'CanFam3'`` and ``'default'``.; contigs : :obj:`list` of :class:`str`; Contig names.; lengths : :obj:`dict` of :class:`str` to :obj:`int`; Dict of contig names to contig lengths.; x_contigs : :class:`str` or :obj:`list` of :obj:`str`; Contigs to be treated as X chromosomes.; y_contigs : :class:`str` or :obj:`list` of :obj:`str`; Contigs to be treated as Y chromosomes.; mt_contigs : :class:`str` or :obj:`list` of :obj:`str`; Contigs to be treated as mitochondrial DNA.; par : :obj:`list` of :obj:`tuple` of (str, int, int); List of tuples with (contig, start, end); """""". @classmethod; def _from_config(cls, config, _builtin=False):; def par_tuple(p):; assert p['start']['contig'] == p['end']['contig']; return (p['start']['contig'], p['start']['position'], p['end']['position']). contigs = config['contigs']; return ReferenceGenome(; config['name'],; [c['name'] for c in contigs],; {c['name']: c['length'] for c in contigs},; config['xContigs'],; config['yContigs'],; config['mtContigs'],; [par_tuple(p) for p in config['par']],; _builtin,; ). @typecheck_method(; name=str,; contigs=sequenceof(str),; lengths=dictof(str, int),; x_contigs=oneof(str, sequenceof(str)),; y_contigs=oneof(str, sequenceof(str)),; mt_contigs=oneof(str, sequenceof(str)),; par=sequenceof(sized_tupleof(str, int, int)),; _builtin=bool,; ); def __init__(self, name, contigs, lengths, x_contigs=[], y_contigs=[], mt_contigs=[], par=[], _builtin=False):; contigs = wrap_to_list(contigs); x_contigs = wrap_to_list(x_contigs); y_contigs = wrap_to_list(y_contigs); mt_contigs = wrap_to_list(mt_contigs). self._config = {; 'name': name,; 'contigs': [{'name': c, 'length': l} for c, l in lengths.items()],; 'xContigs': x_contigs,; 'yContigs': y_contigs,; 'mtContigs': mt_contigs,; 'par': [{'start': {'contig': c, 'position': s}, 'end': {'contig': c, 'position': e}} for (c, s, e) in par],; }. self._contigs = contigs; self._lengths = lengths; s",MatchSource.WIKI,docs/0.2/_modules/hail/genetics/reference_genome.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/genetics/reference_genome.html
https://hail.is/docs/0.2/_modules/hail/genetics/reference_genome.html:12383,Modifiability,config,config,12383,"of(str)),; mt_contigs=oneof(str, sequenceof(str)),; par=sequenceof(sized_tupleof(str, int, int)),; ); def from_fasta_file(cls, name, fasta_file, index_file, x_contigs=[], y_contigs=[], mt_contigs=[], par=[]):; """"""Create reference genome from a FASTA file. Parameters; ----------; name: :class:`str`; Name for new reference genome.; fasta_file : :class:`str`; Path to FASTA file. Can be compressed (GZIP) or uncompressed.; index_file : :class:`str`; Path to FASTA index file. Must be uncompressed.; x_contigs : :class:`str` or :obj:`list` of :obj:`str`; Contigs to be treated as X chromosomes.; y_contigs : :class:`str` or :obj:`list` of :obj:`str`; Contigs to be treated as Y chromosomes.; mt_contigs : :class:`str` or :obj:`list` of :obj:`str`; Contigs to be treated as mitochondrial DNA.; par : :obj:`list` of :obj:`tuple` of (str, int, int); List of tuples with (contig, start, end). Returns; -------; :class:`.ReferenceGenome`; """"""; par_strings = [""{}:{}-{}"".format(contig, start, end) for (contig, start, end) in par]; config = Env.backend().from_fasta_file(; name, fasta_file, index_file, x_contigs, y_contigs, mt_contigs, par_strings; ). rg = ReferenceGenome._from_config(config); rg.add_sequence(fasta_file, index_file); return rg. [docs] @typecheck_method(dest_reference_genome=reference_genome_type); def has_liftover(self, dest_reference_genome):; """"""``True`` if a liftover chain file is available from this reference; genome to the destination reference. Parameters; ----------; dest_reference_genome : :class:`str` or :class:`.ReferenceGenome`. Returns; -------; :obj:`bool`; """"""; return dest_reference_genome.name in self._liftovers. [docs] @typecheck_method(dest_reference_genome=reference_genome_type); def remove_liftover(self, dest_reference_genome):; """"""Remove liftover to `dest_reference_genome`. Parameters; ----------; dest_reference_genome : :class:`str` or :class:`.ReferenceGenome`; """"""; if dest_reference_genome.name in self._liftovers:; del self._liftovers[dest_reference_g",MatchSource.WIKI,docs/0.2/_modules/hail/genetics/reference_genome.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/genetics/reference_genome.html
https://hail.is/docs/0.2/_modules/hail/genetics/reference_genome.html:12538,Modifiability,config,config,12538,"gs=[], mt_contigs=[], par=[]):; """"""Create reference genome from a FASTA file. Parameters; ----------; name: :class:`str`; Name for new reference genome.; fasta_file : :class:`str`; Path to FASTA file. Can be compressed (GZIP) or uncompressed.; index_file : :class:`str`; Path to FASTA index file. Must be uncompressed.; x_contigs : :class:`str` or :obj:`list` of :obj:`str`; Contigs to be treated as X chromosomes.; y_contigs : :class:`str` or :obj:`list` of :obj:`str`; Contigs to be treated as Y chromosomes.; mt_contigs : :class:`str` or :obj:`list` of :obj:`str`; Contigs to be treated as mitochondrial DNA.; par : :obj:`list` of :obj:`tuple` of (str, int, int); List of tuples with (contig, start, end). Returns; -------; :class:`.ReferenceGenome`; """"""; par_strings = [""{}:{}-{}"".format(contig, start, end) for (contig, start, end) in par]; config = Env.backend().from_fasta_file(; name, fasta_file, index_file, x_contigs, y_contigs, mt_contigs, par_strings; ). rg = ReferenceGenome._from_config(config); rg.add_sequence(fasta_file, index_file); return rg. [docs] @typecheck_method(dest_reference_genome=reference_genome_type); def has_liftover(self, dest_reference_genome):; """"""``True`` if a liftover chain file is available from this reference; genome to the destination reference. Parameters; ----------; dest_reference_genome : :class:`str` or :class:`.ReferenceGenome`. Returns; -------; :obj:`bool`; """"""; return dest_reference_genome.name in self._liftovers. [docs] @typecheck_method(dest_reference_genome=reference_genome_type); def remove_liftover(self, dest_reference_genome):; """"""Remove liftover to `dest_reference_genome`. Parameters; ----------; dest_reference_genome : :class:`str` or :class:`.ReferenceGenome`; """"""; if dest_reference_genome.name in self._liftovers:; del self._liftovers[dest_reference_genome.name]; Env.backend().remove_liftover(self.name, dest_reference_genome.name). [docs] @typecheck_method(chain_file=str, dest_reference_genome=reference_genome_type); def add_l",MatchSource.WIKI,docs/0.2/_modules/hail/genetics/reference_genome.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/genetics/reference_genome.html
https://hail.is/docs/0.2/_modules/hail/genetics/reference_genome.html:8543,Performance,load,load,8543,"},; {""name"": ""2"", ""length"": 20000000},; {""name"": ""X"", ""length"": 19856300},; {""name"": ""Y"", ""length"": 78140000},; {""name"": ""MT"", ""length"": 532}],; ""xContigs"": [""X""],; ""yContigs"": [""Y""],; ""mtContigs"": [""MT""],; ""par"": [{""start"": {""contig"": ""X"",""position"": 60001},""end"": {""contig"": ""X"",""position"": 2699521}},; {""start"": {""contig"": ""Y"",""position"": 10001},""end"": {""contig"": ""Y"",""position"": 2649521}}]; }. `name` must be unique and not overlap with Hail's pre-instantiated; references: ``'GRCh37'``, ``'GRCh38'``, ``'GRCm38'``, ``'CanFam3'``, and; ``'default'``.; The contig names in `xContigs`, `yContigs`, and `mtContigs` must be; present in `contigs`. The intervals listed in `par` must have contigs in; either `xContigs` or `yContigs` and must have positions between 0 and; the contig length given in `contigs`. Parameters; ----------; path : :class:`str`; Path to JSON file. Returns; -------; :class:`.ReferenceGenome`; """"""; with hl.hadoop_open(path) as f:; return ReferenceGenome._from_config(json.load(f)). [docs] @typecheck_method(output=str); def write(self, output):; """""" ""Write this reference genome to a file in JSON format. Examples; --------. >>> my_rg = hl.ReferenceGenome(""new_reference"", [""x"", ""y"", ""z""], {""x"": 500, ""y"": 300, ""z"": 200}); >>> my_rg.write(f""output/new_reference.json""). Notes; -----. Use :meth:`~hail.genetics.ReferenceGenome.read` to reimport the exported; reference genome in a new HailContext session. Parameters; ----------; output : :class:`str`; Path of JSON file to write.; """"""; with hl.utils.hadoop_open(output, 'w') as f:; json.dump(self._config, f). [docs] @typecheck_method(fasta_file=str, index_file=nullable(str)); def add_sequence(self, fasta_file, index_file=None):; """"""Load the reference sequence from a FASTA file. Examples; --------; Access the GRCh37 reference genome using :func:`~hail.get_reference`:. >>> rg = hl.get_reference('GRCh37') # doctest: +SKIP. Add a sequence file:. >>> rg.add_sequence('gs://hail-common/references/human_g1k_v37.fasta.gz',; ...",MatchSource.WIKI,docs/0.2/_modules/hail/genetics/reference_genome.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/genetics/reference_genome.html
https://hail.is/docs/0.2/_modules/hail/genetics/reference_genome.html:9894,Performance,load,loaded,9894,"ail.genetics.ReferenceGenome.read` to reimport the exported; reference genome in a new HailContext session. Parameters; ----------; output : :class:`str`; Path of JSON file to write.; """"""; with hl.utils.hadoop_open(output, 'w') as f:; json.dump(self._config, f). [docs] @typecheck_method(fasta_file=str, index_file=nullable(str)); def add_sequence(self, fasta_file, index_file=None):; """"""Load the reference sequence from a FASTA file. Examples; --------; Access the GRCh37 reference genome using :func:`~hail.get_reference`:. >>> rg = hl.get_reference('GRCh37') # doctest: +SKIP. Add a sequence file:. >>> rg.add_sequence('gs://hail-common/references/human_g1k_v37.fasta.gz',; ... 'gs://hail-common/references/human_g1k_v37.fasta.fai') # doctest: +SKIP. Add a sequence file with the default index location:. >>> rg.add_sequence('gs://hail-common/references/human_g1k_v37.fasta.gz') # doctest: +SKIP. Notes; -----; This method can only be run once per reference genome. Use; :meth:`~has_sequence` to test whether a sequence is loaded. FASTA and index files are hosted on google cloud for some of Hail's built-in; references:. **GRCh37**. - FASTA file: ``gs://hail-common/references/human_g1k_v37.fasta.gz``; - Index file: ``gs://hail-common/references/human_g1k_v37.fasta.fai``. **GRCh38**. - FASTA file: ``gs://hail-common/references/Homo_sapiens_assembly38.fasta.gz``; - Index file: ``gs://hail-common/references/Homo_sapiens_assembly38.fasta.fai``. Public download links are available; `here <https://console.cloud.google.com/storage/browser/hail-common/references/>`__. Parameters; ----------; fasta_file : :class:`str`; Path to FASTA file. Can be compressed (GZIP) or uncompressed.; index_file : :obj:`None` or :class:`str`; Path to FASTA index file. Must be uncompressed. If `None`, replace; the fasta_file's extension with `fai`.; """"""; if index_file is None:; index_file = re.sub(r'\.[^.]*$', '.fai', fasta_file); Env.backend().add_sequence(self.name, fasta_file, index_file); self._sequence_fil",MatchSource.WIKI,docs/0.2/_modules/hail/genetics/reference_genome.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/genetics/reference_genome.html
https://hail.is/docs/0.2/_modules/hail/genetics/reference_genome.html:10975,Performance,load,loaded,10975,"ogle cloud for some of Hail's built-in; references:. **GRCh37**. - FASTA file: ``gs://hail-common/references/human_g1k_v37.fasta.gz``; - Index file: ``gs://hail-common/references/human_g1k_v37.fasta.fai``. **GRCh38**. - FASTA file: ``gs://hail-common/references/Homo_sapiens_assembly38.fasta.gz``; - Index file: ``gs://hail-common/references/Homo_sapiens_assembly38.fasta.fai``. Public download links are available; `here <https://console.cloud.google.com/storage/browser/hail-common/references/>`__. Parameters; ----------; fasta_file : :class:`str`; Path to FASTA file. Can be compressed (GZIP) or uncompressed.; index_file : :obj:`None` or :class:`str`; Path to FASTA index file. Must be uncompressed. If `None`, replace; the fasta_file's extension with `fai`.; """"""; if index_file is None:; index_file = re.sub(r'\.[^.]*$', '.fai', fasta_file); Env.backend().add_sequence(self.name, fasta_file, index_file); self._sequence_files = (fasta_file, index_file). [docs] def has_sequence(self):; """"""True if the reference sequence has been loaded. Returns; -------; :obj:`bool`; """"""; return self._sequence_files is not None. [docs] def remove_sequence(self):; """"""Remove the reference sequence.""""""; self._sequence_files = None; Env.backend().remove_sequence(self.name). [docs] @classmethod; @typecheck_method(; name=str,; fasta_file=str,; index_file=str,; x_contigs=oneof(str, sequenceof(str)),; y_contigs=oneof(str, sequenceof(str)),; mt_contigs=oneof(str, sequenceof(str)),; par=sequenceof(sized_tupleof(str, int, int)),; ); def from_fasta_file(cls, name, fasta_file, index_file, x_contigs=[], y_contigs=[], mt_contigs=[], par=[]):; """"""Create reference genome from a FASTA file. Parameters; ----------; name: :class:`str`; Name for new reference genome.; fasta_file : :class:`str`; Path to FASTA file. Can be compressed (GZIP) or uncompressed.; index_file : :class:`str`; Path to FASTA index file. Must be uncompressed.; x_contigs : :class:`str` or :obj:`list` of :obj:`str`; Contigs to be treated as X ch",MatchSource.WIKI,docs/0.2/_modules/hail/genetics/reference_genome.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/genetics/reference_genome.html
https://hail.is/docs/0.2/_modules/hail/genetics/reference_genome.html:1567,Security,access,access,1567,"hl; from hail.typecheck import dictof, lazy, nullable, oneof, sequenceof, sized_tupleof, transformed, typecheck_method; from hail.utils.java import Env; from hail.utils.misc import wrap_to_list. rg_type = lazy(); reference_genome_type = oneof(transformed((str, lambda x: hl.get_reference(x))), rg_type). [docs]class ReferenceGenome:; """"""An object that represents a `reference genome <https://en.wikipedia.org/wiki/Reference_genome>`__. Examples; --------. >>> contigs = [""1"", ""X"", ""Y"", ""MT""]; >>> lengths = {""1"": 249250621, ""X"": 155270560, ""Y"": 59373566, ""MT"": 16569}; >>> par = [(""X"", 60001, 2699521)]; >>> my_ref = hl.ReferenceGenome(""my_ref"", contigs, lengths, ""X"", ""Y"", ""MT"", par). Notes; -----; Hail comes with predefined reference genomes (case sensitive!):. - GRCh37, Genome Reference Consortium Human Build 37; - GRCh38, Genome Reference Consortium Human Build 38; - GRCm38, Genome Reference Consortium Mouse Build 38; - CanFam3, Canis lupus familiaris (dog). You can access these reference genome objects using :func:`~hail.get_reference`:. >>> rg = hl.get_reference('GRCh37'); >>> rg = hl.get_reference('GRCh38'); >>> rg = hl.get_reference('GRCm38'); >>> rg = hl.get_reference('CanFam3'). Note that constructing a new reference genome, either by using the class; constructor or by using `read` will add the reference genome to the list of; known references; it is possible to access the reference genome using; :func:`~hail.get_reference` anytime afterwards. Note; ----; Reference genome names must be unique. It is not possible to overwrite the; built-in reference genomes. Note; ----; Hail allows setting a default reference so that the ``reference_genome``; argument of :func:`~hail.methods.import_vcf` does not need to be used; constantly. It is a current limitation of Hail that a custom reference; genome cannot be used as the ``default_reference`` argument of; :func:`~hail.init`. In order to set a custom reference genome as default,; pass the reference as an argument to :func:`~ha",MatchSource.WIKI,docs/0.2/_modules/hail/genetics/reference_genome.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/genetics/reference_genome.html
https://hail.is/docs/0.2/_modules/hail/genetics/reference_genome.html:1977,Security,access,access,1977,"ReferenceGenome:; """"""An object that represents a `reference genome <https://en.wikipedia.org/wiki/Reference_genome>`__. Examples; --------. >>> contigs = [""1"", ""X"", ""Y"", ""MT""]; >>> lengths = {""1"": 249250621, ""X"": 155270560, ""Y"": 59373566, ""MT"": 16569}; >>> par = [(""X"", 60001, 2699521)]; >>> my_ref = hl.ReferenceGenome(""my_ref"", contigs, lengths, ""X"", ""Y"", ""MT"", par). Notes; -----; Hail comes with predefined reference genomes (case sensitive!):. - GRCh37, Genome Reference Consortium Human Build 37; - GRCh38, Genome Reference Consortium Human Build 38; - GRCm38, Genome Reference Consortium Mouse Build 38; - CanFam3, Canis lupus familiaris (dog). You can access these reference genome objects using :func:`~hail.get_reference`:. >>> rg = hl.get_reference('GRCh37'); >>> rg = hl.get_reference('GRCh38'); >>> rg = hl.get_reference('GRCm38'); >>> rg = hl.get_reference('CanFam3'). Note that constructing a new reference genome, either by using the class; constructor or by using `read` will add the reference genome to the list of; known references; it is possible to access the reference genome using; :func:`~hail.get_reference` anytime afterwards. Note; ----; Reference genome names must be unique. It is not possible to overwrite the; built-in reference genomes. Note; ----; Hail allows setting a default reference so that the ``reference_genome``; argument of :func:`~hail.methods.import_vcf` does not need to be used; constantly. It is a current limitation of Hail that a custom reference; genome cannot be used as the ``default_reference`` argument of; :func:`~hail.init`. In order to set a custom reference genome as default,; pass the reference as an argument to :func:`~hail.default_reference` after; initializing Hail. Parameters; ----------; name : :class:`str`; Name of reference. Must be unique and NOT one of Hail's; predefined references: ``'GRCh37'``, ``'GRCh38'``, ``'GRCm38'``,; ``'CanFam3'`` and ``'default'``.; contigs : :obj:`list` of :class:`str`; Contig names.; lengths : :o",MatchSource.WIKI,docs/0.2/_modules/hail/genetics/reference_genome.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/genetics/reference_genome.html
https://hail.is/docs/0.2/_modules/hail/genetics/reference_genome.html:5442,Security,hash,hash,5442,"name': c, 'length': l} for c, l in lengths.items()],; 'xContigs': x_contigs,; 'yContigs': y_contigs,; 'mtContigs': mt_contigs,; 'par': [{'start': {'contig': c, 'position': s}, 'end': {'contig': c, 'position': e}} for (c, s, e) in par],; }. self._contigs = contigs; self._lengths = lengths; self._par_tuple = par; self._par = [hl.Interval(hl.Locus(c, s, self), hl.Locus(c, e, self)) for (c, s, e) in par]; self._global_positions = None; self._global_positions_list = None. if not _builtin:; Env.backend().add_reference(self). self._sequence_files = None; self._liftovers = dict(). def __str__(self):; return self._config['name']. def __repr__(self):; return 'ReferenceGenome(name=%s, contigs=%s, lengths=%s, x_contigs=%s, y_contigs=%s, mt_contigs=%s, par=%s)' % (; self.name,; self.contigs,; self.lengths,; self.x_contigs,; self.y_contigs,; self.mt_contigs,; self._par_tuple,; ). def __eq__(self, other):; return isinstance(other, ReferenceGenome) and self._config == other._config. def __hash__(self):; return hash(self.name). @property; def name(self):; """"""Name of reference genome. Returns; -------; :class:`str`; """"""; return self._config['name']. @property; def contigs(self):; """"""Contig names. Returns; -------; :obj:`list` of :class:`str`; """"""; return self._contigs. @property; def lengths(self):; """"""Dict of contig name to contig length. Returns; -------; :obj:`dict` of :class:`str` to :obj:`int`; """"""; return self._lengths. @property; def x_contigs(self):; """"""X contigs. Returns; -------; :obj:`list` of :class:`str`; """"""; return self._config['xContigs']. @property; def y_contigs(self):; """"""Y contigs. Returns; -------; :obj:`list` of :class:`str`; """"""; return self._config['yContigs']. @property; def mt_contigs(self):; """"""Mitochondrial contigs. Returns; -------; :obj:`list` of :class:`str`; """"""; return self._config['mtContigs']. @property; def par(self):; """"""Pseudoautosomal regions. Returns; -------; :obj:`list` of :class:`.Interval`; """""". return self._par. [docs] @typecheck_method(con",MatchSource.WIKI,docs/0.2/_modules/hail/genetics/reference_genome.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/genetics/reference_genome.html
https://hail.is/docs/0.2/_modules/hail/genetics/reference_genome.html:3464,Testability,assert,assert,3464,"`. In order to set a custom reference genome as default,; pass the reference as an argument to :func:`~hail.default_reference` after; initializing Hail. Parameters; ----------; name : :class:`str`; Name of reference. Must be unique and NOT one of Hail's; predefined references: ``'GRCh37'``, ``'GRCh38'``, ``'GRCm38'``,; ``'CanFam3'`` and ``'default'``.; contigs : :obj:`list` of :class:`str`; Contig names.; lengths : :obj:`dict` of :class:`str` to :obj:`int`; Dict of contig names to contig lengths.; x_contigs : :class:`str` or :obj:`list` of :obj:`str`; Contigs to be treated as X chromosomes.; y_contigs : :class:`str` or :obj:`list` of :obj:`str`; Contigs to be treated as Y chromosomes.; mt_contigs : :class:`str` or :obj:`list` of :obj:`str`; Contigs to be treated as mitochondrial DNA.; par : :obj:`list` of :obj:`tuple` of (str, int, int); List of tuples with (contig, start, end); """""". @classmethod; def _from_config(cls, config, _builtin=False):; def par_tuple(p):; assert p['start']['contig'] == p['end']['contig']; return (p['start']['contig'], p['start']['position'], p['end']['position']). contigs = config['contigs']; return ReferenceGenome(; config['name'],; [c['name'] for c in contigs],; {c['name']: c['length'] for c in contigs},; config['xContigs'],; config['yContigs'],; config['mtContigs'],; [par_tuple(p) for p in config['par']],; _builtin,; ). @typecheck_method(; name=str,; contigs=sequenceof(str),; lengths=dictof(str, int),; x_contigs=oneof(str, sequenceof(str)),; y_contigs=oneof(str, sequenceof(str)),; mt_contigs=oneof(str, sequenceof(str)),; par=sequenceof(sized_tupleof(str, int, int)),; _builtin=bool,; ); def __init__(self, name, contigs, lengths, x_contigs=[], y_contigs=[], mt_contigs=[], par=[], _builtin=False):; contigs = wrap_to_list(contigs); x_contigs = wrap_to_list(x_contigs); y_contigs = wrap_to_list(y_contigs); mt_contigs = wrap_to_list(mt_contigs). self._config = {; 'name': name,; 'contigs': [{'name': c, 'length': l} for c, l in lengths.items()],; '",MatchSource.WIKI,docs/0.2/_modules/hail/genetics/reference_genome.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/genetics/reference_genome.html
https://hail.is/docs/0.2/_modules/hail/genetics/reference_genome.html:9867,Testability,test,test,9867,"ail.genetics.ReferenceGenome.read` to reimport the exported; reference genome in a new HailContext session. Parameters; ----------; output : :class:`str`; Path of JSON file to write.; """"""; with hl.utils.hadoop_open(output, 'w') as f:; json.dump(self._config, f). [docs] @typecheck_method(fasta_file=str, index_file=nullable(str)); def add_sequence(self, fasta_file, index_file=None):; """"""Load the reference sequence from a FASTA file. Examples; --------; Access the GRCh37 reference genome using :func:`~hail.get_reference`:. >>> rg = hl.get_reference('GRCh37') # doctest: +SKIP. Add a sequence file:. >>> rg.add_sequence('gs://hail-common/references/human_g1k_v37.fasta.gz',; ... 'gs://hail-common/references/human_g1k_v37.fasta.fai') # doctest: +SKIP. Add a sequence file with the default index location:. >>> rg.add_sequence('gs://hail-common/references/human_g1k_v37.fasta.gz') # doctest: +SKIP. Notes; -----; This method can only be run once per reference genome. Use; :meth:`~has_sequence` to test whether a sequence is loaded. FASTA and index files are hosted on google cloud for some of Hail's built-in; references:. **GRCh37**. - FASTA file: ``gs://hail-common/references/human_g1k_v37.fasta.gz``; - Index file: ``gs://hail-common/references/human_g1k_v37.fasta.fai``. **GRCh38**. - FASTA file: ``gs://hail-common/references/Homo_sapiens_assembly38.fasta.gz``; - Index file: ``gs://hail-common/references/Homo_sapiens_assembly38.fasta.fai``. Public download links are available; `here <https://console.cloud.google.com/storage/browser/hail-common/references/>`__. Parameters; ----------; fasta_file : :class:`str`; Path to FASTA file. Can be compressed (GZIP) or uncompressed.; index_file : :obj:`None` or :class:`str`; Path to FASTA index file. Must be uncompressed. If `None`, replace; the fasta_file's extension with `fai`.; """"""; if index_file is None:; index_file = re.sub(r'\.[^.]*$', '.fai', fasta_file); Env.backend().add_sequence(self.name, fasta_file, index_file); self._sequence_fil",MatchSource.WIKI,docs/0.2/_modules/hail/genetics/reference_genome.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/genetics/reference_genome.html
https://hail.is/docs/0.2/_modules/hail/genetics/reference_genome.html:14061,Testability,test,test,14061,"me_type); def remove_liftover(self, dest_reference_genome):; """"""Remove liftover to `dest_reference_genome`. Parameters; ----------; dest_reference_genome : :class:`str` or :class:`.ReferenceGenome`; """"""; if dest_reference_genome.name in self._liftovers:; del self._liftovers[dest_reference_genome.name]; Env.backend().remove_liftover(self.name, dest_reference_genome.name). [docs] @typecheck_method(chain_file=str, dest_reference_genome=reference_genome_type); def add_liftover(self, chain_file, dest_reference_genome):; """"""Register a chain file for liftover. Examples; --------; Access GRCh37 and GRCh38 using :func:`~hail.get_reference`:. >>> rg37 = hl.get_reference('GRCh37') # doctest: +SKIP; >>> rg38 = hl.get_reference('GRCh38') # doctest: +SKIP. Add a chain file from 37 to 38:. >>> rg37.add_liftover('gs://hail-common/references/grch37_to_grch38.over.chain.gz', rg38) # doctest: +SKIP. Notes; -----; This method can only be run once per reference genome. Use; :meth:`~has_liftover` to test whether a chain file has been registered. The chain file format is described; `here <https://genome.ucsc.edu/goldenpath/help/chain.html>`__. Chain files are hosted on google cloud for some of Hail's built-in; references:. **GRCh37 to GRCh38**; gs://hail-common/references/grch37_to_grch38.over.chain.gz. **GRCh38 to GRCh37**; gs://hail-common/references/grch38_to_grch37.over.chain.gz. Public download links are available; `here <https://console.cloud.google.com/storage/browser/hail-common/references/>`__. Parameters; ----------; chain_file : :class:`str`; Path to chain file. Can be compressed (GZIP) or uncompressed.; dest_reference_genome : :class:`str` or :class:`.ReferenceGenome`; Reference genome to convert to.; """""". Env.backend().add_liftover(self.name, chain_file, dest_reference_genome.name); if dest_reference_genome.name in self._liftovers:; raise KeyError(f""Liftover already exists from {self.name} to {dest_reference_genome.name}.""); if dest_reference_genome.name == self.name:; raise V",MatchSource.WIKI,docs/0.2/_modules/hail/genetics/reference_genome.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/genetics/reference_genome.html
https://hail.is/docs/0.2/_modules/hail/ggplot/aes.html:1477,Deployability,update,updated,1477,"﻿. Hail | ; hail.ggplot.aes. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.ggplot.aes. Source code for hail.ggplot.aes; from collections.abc import Mapping. from hail.expr import Expression, literal. [docs]class Aesthetic(Mapping):; def __init__(self, properties):; self.properties = properties. def __getitem__(self, item):; return self.properties[item]. def __len__(self):; return len(self.properties). def __contains__(self, item):; return item in self.properties. def __iter__(self):; return iter(self.properties). def __repr__(self):; return self.properties.__repr__(). def merge(self, other):; return Aesthetic({**self.properties, **other.properties}). [docs]def aes(**kwargs):; """"""Create an aesthetic mapping. Parameters; ----------; kwargs:; Map aesthetic names to hail expressions based on table's plot. Returns; -------; :class:`.Aesthetic`; The aesthetic mapping to be applied. """"""; hail_field_properties = {}. for k, v in kwargs.items():; _v = v; if not isinstance(v, Expression):; _v = literal(v); hail_field_properties[k] = _v; return Aesthetic(hail_field_properties). © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,docs/0.2/_modules/hail/ggplot/aes.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/ggplot/aes.html
https://hail.is/docs/0.2/_modules/hail/ggplot/coord_cartesian.html:1291,Deployability,update,updated,1291,"﻿. Hail | ; hail.ggplot.coord_cartesian. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.ggplot.coord_cartesian. Source code for hail.ggplot.coord_cartesian; from .geoms import FigureAttribute. class CoordCartesian(FigureAttribute):; def __init__(self, xlim, ylim):; self.xlim = xlim; self.ylim = ylim. def apply_to_fig(self, fig_so_far):; if self.xlim is not None:; fig_so_far.update_xaxes(range=list(self.xlim)); if self.ylim is not None:; fig_so_far.update_yaxes(range=list(self.ylim)). [docs]def coord_cartesian(xlim=None, ylim=None):; """"""Set the boundaries of the plot. Parameters; ----------; xlim : :obj:`tuple` with two int; The minimum and maximum x value to show on the plot.; ylim : :obj:`tuple` with two int; The minimum and maximum y value to show on the plot. Returns; -------; :class:`.FigureAttribute`; The coordinate attribute to be applied. """"""; return CoordCartesian(xlim, ylim). © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,docs/0.2/_modules/hail/ggplot/coord_cartesian.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/ggplot/coord_cartesian.html
https://hail.is/docs/0.2/_modules/hail/ggplot/facets.html:3484,Deployability,update,updated,3484,"he facets will be spread.; scales: :class:`str`; Whether the scales are the same across facets. For more information and a list of supported options, see `the ggplot documentation <https://ggplot2-book.org/facet.html#controlling-scales>`__. Returns; -------; :class:`FigureAttribute`; The faceter. """"""; return FacetWrap(facets, nrow, ncol, scales). class Faceter(FigureAttribute):; @abc.abstractmethod; def get_expr_to_group_by(self) -> StructExpression:; pass. class FacetWrap(Faceter):; _base_scale_mappings: ClassVar = {; ""shared_xaxes"": ""all"",; ""shared_yaxes"": ""all"",; }. _scale_mappings: ClassVar = {; ""fixed"": _base_scale_mappings,; ""free_x"": {; **_base_scale_mappings,; ""shared_xaxes"": False,; },; ""free_y"": {; **_base_scale_mappings,; ""shared_yaxes"": False,; },; ""free"": {; ""shared_xaxes"": False,; ""shared_yaxes"": False,; },; }. def __init__(; self, facets: StructExpression, nrow: Optional[int] = None, ncol: Optional[int] = None, scales: str = ""fixed""; ):; if nrow is not None and ncol is not None:; raise ValueError(""Both `nrow` and `ncol` were specified. "" ""Please specify only one of these values.""); if scales not in self._scale_mappings:; raise ValueError(; f""An unsupported value ({scales}) was provided for `scales`. ""; f""Supported values are: {[k for k in self._scale_mappings.keys()]}.""; ); self.nrow = nrow; self.ncol = ncol; self.facets = facets; self.scales = scales. def get_expr_to_group_by(self) -> StructExpression:; return self.facets. def get_facet_nrows_and_ncols(self, num_facet_values: int) -> Tuple[int, int]:; if self.ncol is not None:; return (n_partitions(num_facet_values, self.ncol), self.ncol); elif self.nrow is not None:; return (self.nrow, n_partitions(num_facet_values, self.nrow)); else:; ncol = int(math.ceil(math.sqrt(num_facet_values))); return (n_partitions(num_facet_values, ncol), ncol). def get_shared_axis_kwargs(self) -> Dict[str, str]:; return self._scale_mappings[self.scales]. © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,docs/0.2/_modules/hail/ggplot/facets.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/ggplot/facets.html
https://hail.is/docs/0.2/_modules/hail/ggplot/geoms.html:14237,Availability,down,down,14237,"n 0 and 1.; position: :class:`str`; Tells how to deal with different groups of data at same point. Options are ""stack"" and ""dodge"". Returns; -------; :class:`FigureAttribute`; The geom to be applied.; """"""; return GeomHistogram(; mapping,; min_val=min_val,; max_val=max_val,; bins=bins,; fill=fill,; color=color,; alpha=alpha,; position=position,; size=size,; ). # Computes the maximum entropy distribution whose cdf is within +- e of the; # staircase-shaped cdf encoded by min_x, max_x, x, y.; #; # x is an array of n x-coordinates between min_x and max_x, and y is an array; # of (n+1) y-coordinates between 0 and 1, both sorted. Together they encode a; # staircase-shaped cdf.; # For example, if min_x = 1, max_x=4, x=[2], y=[.2, .6], then the cdf is the; # staircase tracing the points; # (1, 0) - (1, .2) - (2, .2) - (2, .6) - (4, .6) - (4, 1); #; # Now consider the set of all possible cdfs within +-e of the one above. In; # other words, shift the staircase both up and down by e, capping above and; # below at 1 and 0, and consider all possible cdfs that lie in between. The; # distribution with maximum entropy whose cdf is between the two staircases; # is the one whose cdf is the graph constructed as follows: tie a rubber band; # to the points (min_x, 0) and (max_x, 1), place the middle between the two; # staircases, and let it contract. In other words, it will be the shortest; # path between the staircases.; #; # It's easy to see this path must be piecewise linear, and the points where the; # slopes change will be either; # * bending up at a point of the form (x[i], y[i]+e), or; # * bending down at a point of the form (x[i], y[i+1]-e); #; # Returns (new_y, keep).; # keep is the array of indices i at which the piecewise linear max-ent cdf; # changes slope, as described in the previous paragraph.; # new_y is an array the same length as x. For each i in keep, new_y[i] is the; # y coordinate of the point on the max-ent cdf.; def _max_entropy_cdf(min_x, max_x, x, y, e):; def poin",MatchSource.WIKI,docs/0.2/_modules/hail/ggplot/geoms.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/ggplot/geoms.html
https://hail.is/docs/0.2/_modules/hail/ggplot/geoms.html:14871,Availability,down,down,14871,"x_x, and y is an array; # of (n+1) y-coordinates between 0 and 1, both sorted. Together they encode a; # staircase-shaped cdf.; # For example, if min_x = 1, max_x=4, x=[2], y=[.2, .6], then the cdf is the; # staircase tracing the points; # (1, 0) - (1, .2) - (2, .2) - (2, .6) - (4, .6) - (4, 1); #; # Now consider the set of all possible cdfs within +-e of the one above. In; # other words, shift the staircase both up and down by e, capping above and; # below at 1 and 0, and consider all possible cdfs that lie in between. The; # distribution with maximum entropy whose cdf is between the two staircases; # is the one whose cdf is the graph constructed as follows: tie a rubber band; # to the points (min_x, 0) and (max_x, 1), place the middle between the two; # staircases, and let it contract. In other words, it will be the shortest; # path between the staircases.; #; # It's easy to see this path must be piecewise linear, and the points where the; # slopes change will be either; # * bending up at a point of the form (x[i], y[i]+e), or; # * bending down at a point of the form (x[i], y[i+1]-e); #; # Returns (new_y, keep).; # keep is the array of indices i at which the piecewise linear max-ent cdf; # changes slope, as described in the previous paragraph.; # new_y is an array the same length as x. For each i in keep, new_y[i] is the; # y coordinate of the point on the max-ent cdf.; def _max_entropy_cdf(min_x, max_x, x, y, e):; def point_on_bound(i, upper):; if i == len(x):; return max_x, 1; else:; yi = y[i] + e if upper else y[i + 1] - e; return x[i], yi. # Result variables:; new_y = np.full_like(x, 0.0, dtype=np.float64); keep = np.full_like(x, False, dtype=np.bool_). # State variables:; # (fx, fy) is most recently fixed point on max-ent cdf; fx, fy = min_x, 0; li, ui = 0, 0; j = 1. def slope_from_fixed(i, upper):; xi, yi = point_on_bound(i, upper); return (yi - fy) / (xi - fx). def fix_point_on_result(i, upper):; nonlocal fx, fy, new_y, keep; xi, yi = point_on_bound(i, upper",MatchSource.WIKI,docs/0.2/_modules/hail/ggplot/geoms.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/ggplot/geoms.html
https://hail.is/docs/0.2/_modules/hail/ggplot/geoms.html:16513,Availability,down,down,16513,"p.float64); keep = np.full_like(x, False, dtype=np.bool_). # State variables:; # (fx, fy) is most recently fixed point on max-ent cdf; fx, fy = min_x, 0; li, ui = 0, 0; j = 1. def slope_from_fixed(i, upper):; xi, yi = point_on_bound(i, upper); return (yi - fy) / (xi - fx). def fix_point_on_result(i, upper):; nonlocal fx, fy, new_y, keep; xi, yi = point_on_bound(i, upper); fx, fy = xi, yi; new_y[i] = fy; keep[i] = True. min_slope = slope_from_fixed(li, upper=False); max_slope = slope_from_fixed(ui, upper=True). # Consider a line l from (fx, fy) to (x[j], y?). As we increase y?, l first; # bumps into the upper staircase at (x[ui], y[ui] + e), and as we decrease; # y?, l first bumps into the lower staircase at (x[li], y[li+1] - e).; # We track the min and max slopes l can have while staying between the; # staircases, as well as the points li and ui where the line must bend if; # forced too high or too low. while True:; lower_slope = slope_from_fixed(j, upper=False); upper_slope = slope_from_fixed(j, upper=True); if upper_slope < min_slope:; # Line must bend down at x[li]. We know the max-entropy cdf passes; # through this point, so record it in new_y, keep.; # This becomes the new fixed point, and we must restart the scan; # from there.; fix_point_on_result(li, upper=False); j = li + 1; if j >= len(x):; break; li, ui = j, j; min_slope = slope_from_fixed(li, upper=False); max_slope = slope_from_fixed(ui, upper=True); j += 1; continue; elif lower_slope > max_slope:; # Line must bend up at x[ui]. We know the max-entropy cdf passes; # through this point, so record it in new_y, keep.; # This becomes the new fixed point, and we must restart the scan; # from there.; fix_point_on_result(ui, upper=True); j = ui + 1; if j >= len(x):; break; li, ui = j, j; min_slope = slope_from_fixed(li, upper=False); max_slope = slope_from_fixed(ui, upper=True); j += 1; continue; if j >= len(x):; break; if upper_slope < max_slope:; ui = j; max_slope = upper_slope; if lower_slope > min_slope:; li",MatchSource.WIKI,docs/0.2/_modules/hail/ggplot/geoms.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/ggplot/geoms.html
https://hail.is/docs/0.2/_modules/hail/ggplot/geoms.html:28060,Deployability,update,updated,28060,"is facing side, none by default. Overrides ``color`` aesthetic. Returns; -------; :class:`FigureAttribute`; The geom to be applied.; """"""; return GeomArea(mapping, fill=fill, color=color). class GeomRibbon(Geom):; aes_to_arg: ClassVar = {; ""fill"": (""fillcolor"", ""black""),; ""color"": (""line_color"", ""rgba(0, 0, 0, 0)""),; ""tooltip"": (""hovertext"", None),; ""fill_legend"": (""name"", None),; }. def __init__(self, aes, fill, color):; super().__init__(aes); self.fill = fill; self.color = color. def apply_to_fig(; self, grouped_data, fig_so_far: go.Figure, precomputed, facet_row, facet_col, legend_cache, is_faceted: bool; ):; def plot_group(df):; trace_args_bottom = {; ""x"": df.x,; ""y"": df.ymin,; ""row"": facet_row,; ""col"": facet_col,; ""mode"": ""lines"",; ""showlegend"": False,; }; self._add_aesthetics_to_trace_args(trace_args_bottom, df); self._update_legend_trace_args(trace_args_bottom, legend_cache). trace_args_top = {; ""x"": df.x,; ""y"": df.ymax,; ""row"": facet_row,; ""col"": facet_col,; ""mode"": ""lines"",; ""fill"": 'tonexty',; }; self._add_aesthetics_to_trace_args(trace_args_top, df); self._update_legend_trace_args(trace_args_top, legend_cache). fig_so_far.add_scatter(**trace_args_bottom); fig_so_far.add_scatter(**trace_args_top). for group_df in grouped_data:; plot_group(group_df). def get_stat(self):; return StatIdentity(). [docs]def geom_ribbon(mapping=aes(), fill=None, color=None):; """"""Creates filled in area between two lines specified by x, ymin, and ymax. Supported aesthetics: ``x``, ``ymin``, ``ymax``, ``color``, ``fill``, ``tooltip``. Parameters; ----------; mapping: :class:`Aesthetic`; Any aesthetics specific to this geom.; fill:; Color of fill to draw, black by default. Overrides ``fill`` aesthetic.; color:; Color of line to draw outlining both side, none by default. Overrides ``color`` aesthetic. :return:; :class:`FigureAttribute`; The geom to be applied.; """"""; return GeomRibbon(mapping, fill=fill, color=color). © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,docs/0.2/_modules/hail/ggplot/geoms.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/ggplot/geoms.html
https://hail.is/docs/0.2/_modules/hail/ggplot/geoms.html:18612,Energy Efficiency,power,power,18612,"one),; ""tooltip"": (""hovertext"", None),; ""fill_legend"": (""name"", None),; ""alpha"": (""marker_opacity"", None),; }. def __init__(self, aes, k=1000, smoothing=0.5, fill=None, color=None, alpha=None, smoothed=False):; super().__init__(aes); self.k = k; self.smoothing = smoothing; self.fill = fill; self.color = color; self.alpha = alpha; self.smoothed = smoothed. def apply_to_fig(; self, grouped_data, fig_so_far: go.Figure, precomputed, facet_row, facet_col, legend_cache, is_faceted: bool; ):; from hail.expr.functions import _error_from_cdf_python. def plot_group(df, idx):; data = df.attrs['data']. if self.smoothed:; n = data['ranks'][-1]; weights = np.diff(data['ranks'][1:-1]); min = data['values'][0]; max = data['values'][-1]; values = np.array(data['values'][1:-1]); slope = 1 / (max - min). def f(x, prev):; inv_scale = (np.sqrt(n * slope) / self.smoothing) * np.sqrt(prev / weights); diff = x[:, np.newaxis] - values; grid = (; (3 / (4 * n)) * weights * np.maximum(0, inv_scale - np.power(diff, 2) * np.power(inv_scale, 3)); ); return np.sum(grid, axis=1). round1 = f(values, np.full(len(values), slope)); x_d = np.linspace(min, max, 1000); final = f(x_d, round1). trace_args = {; ""x"": x_d,; ""y"": final,; ""mode"": ""lines"",; ""fill"": ""tozeroy"",; ""row"": facet_row,; ""col"": facet_col,; }. self._add_aesthetics_to_trace_args(trace_args, df); self._update_legend_trace_args(trace_args, legend_cache). fig_so_far.add_scatter(**trace_args); else:; confidence = 5. y = np.array(data['ranks'][1:-1]) / data['ranks'][-1]; x = np.array(data['values'][1:-1]); min_x = data['values'][0]; max_x = data['values'][-1]; err = _error_from_cdf_python(data, 10 ** (-confidence), all_quantiles=True). new_y, keep = _max_entropy_cdf(min_x, max_x, x, y, err); slopes = np.diff([0, *new_y[keep], 1]) / np.diff([min_x, *x[keep], max_x]). left = np.concatenate([[min_x], x[keep]]); right = np.concatenate([x[keep], [max_x]]); widths = right - left. trace_args = {; ""x"": [min_x, *x[keep]],; ""y"": slopes,; ""row"": facet_row,",MatchSource.WIKI,docs/0.2/_modules/hail/ggplot/geoms.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/ggplot/geoms.html
https://hail.is/docs/0.2/_modules/hail/ggplot/geoms.html:18632,Energy Efficiency,power,power,18632,"xt"", None),; ""fill_legend"": (""name"", None),; ""alpha"": (""marker_opacity"", None),; }. def __init__(self, aes, k=1000, smoothing=0.5, fill=None, color=None, alpha=None, smoothed=False):; super().__init__(aes); self.k = k; self.smoothing = smoothing; self.fill = fill; self.color = color; self.alpha = alpha; self.smoothed = smoothed. def apply_to_fig(; self, grouped_data, fig_so_far: go.Figure, precomputed, facet_row, facet_col, legend_cache, is_faceted: bool; ):; from hail.expr.functions import _error_from_cdf_python. def plot_group(df, idx):; data = df.attrs['data']. if self.smoothed:; n = data['ranks'][-1]; weights = np.diff(data['ranks'][1:-1]); min = data['values'][0]; max = data['values'][-1]; values = np.array(data['values'][1:-1]); slope = 1 / (max - min). def f(x, prev):; inv_scale = (np.sqrt(n * slope) / self.smoothing) * np.sqrt(prev / weights); diff = x[:, np.newaxis] - values; grid = (; (3 / (4 * n)) * weights * np.maximum(0, inv_scale - np.power(diff, 2) * np.power(inv_scale, 3)); ); return np.sum(grid, axis=1). round1 = f(values, np.full(len(values), slope)); x_d = np.linspace(min, max, 1000); final = f(x_d, round1). trace_args = {; ""x"": x_d,; ""y"": final,; ""mode"": ""lines"",; ""fill"": ""tozeroy"",; ""row"": facet_row,; ""col"": facet_col,; }. self._add_aesthetics_to_trace_args(trace_args, df); self._update_legend_trace_args(trace_args, legend_cache). fig_so_far.add_scatter(**trace_args); else:; confidence = 5. y = np.array(data['ranks'][1:-1]) / data['ranks'][-1]; x = np.array(data['values'][1:-1]); min_x = data['values'][0]; max_x = data['values'][-1]; err = _error_from_cdf_python(data, 10 ** (-confidence), all_quantiles=True). new_y, keep = _max_entropy_cdf(min_x, max_x, x, y, err); slopes = np.diff([0, *new_y[keep], 1]) / np.diff([min_x, *x[keep], max_x]). left = np.concatenate([[min_x], x[keep]]); right = np.concatenate([x[keep], [max_x]]); widths = right - left. trace_args = {; ""x"": [min_x, *x[keep]],; ""y"": slopes,; ""row"": facet_row,; ""col"": facet_col,; ""width""",MatchSource.WIKI,docs/0.2/_modules/hail/ggplot/geoms.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/ggplot/geoms.html
https://hail.is/docs/0.2/_modules/hail/ggplot/geoms.html:12686,Integrability,interface,interface,12686,"width / 2; bar_width = bin_width; else:; raise ValueError(f""Histogram does not support position = {self.position}""). right_xs = left_xs + bin_width. trace_args = {; ""x"": x,; ""y"": df.y,; ""row"": facet_row,; ""col"": facet_col,; ""customdata"": list(zip(left_xs, right_xs)),; ""width"": bar_width,; ""hovertemplate"": ""Range: [%{customdata[0]:.3f}-%{customdata[1]:.3f})<br>""; ""Count: %{y}<br>""; ""<extra></extra>"",; }. self._add_aesthetics_to_trace_args(trace_args, df); self._update_legend_trace_args(trace_args, legend_cache). fig_so_far.add_bar(**trace_args). for idx, group_df in enumerate(grouped_data):; plot_group(group_df, idx). fig_so_far.update_layout(barmode=bar_position_plotly_to_gg(self.position)). def get_stat(self):; return StatBin(self.min_val, self.max_val, self.bins). [docs]def geom_histogram(; mapping=aes(),; *,; min_val=None,; max_val=None,; bins=None,; fill=None,; color=None,; alpha=None,; position='stack',; size=None,; ):; """"""Creates a histogram. Note: this function currently does not support same interface as R's ggplot. Supported aesthetics: ``x``, ``color``, ``fill``. Parameters; ----------; mapping: :class:`Aesthetic`; Any aesthetics specific to this geom.; min_val: `int` or `float`; Minimum value to include in histogram; max_val: `int` or `float`; Maximum value to include in histogram; bins: `int`; Number of bins to plot. 30 by default.; fill:; A single fill color for all bars of histogram, overrides ``fill`` aesthetic.; color:; A single outline color for all bars of histogram, overrides ``color`` aesthetic.; alpha: `float`; A measure of transparency between 0 and 1.; position: :class:`str`; Tells how to deal with different groups of data at same point. Options are ""stack"" and ""dodge"". Returns; -------; :class:`FigureAttribute`; The geom to be applied.; """"""; return GeomHistogram(; mapping,; min_val=min_val,; max_val=max_val,; bins=bins,; fill=fill,; color=color,; alpha=alpha,; position=position,; size=size,; ). # Computes the maximum entropy distribution whose",MatchSource.WIKI,docs/0.2/_modules/hail/ggplot/geoms.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/ggplot/geoms.html
https://hail.is/docs/0.2/_modules/hail/ggplot/geoms.html:14602,Integrability,contract,contract,14602,"GeomHistogram(; mapping,; min_val=min_val,; max_val=max_val,; bins=bins,; fill=fill,; color=color,; alpha=alpha,; position=position,; size=size,; ). # Computes the maximum entropy distribution whose cdf is within +- e of the; # staircase-shaped cdf encoded by min_x, max_x, x, y.; #; # x is an array of n x-coordinates between min_x and max_x, and y is an array; # of (n+1) y-coordinates between 0 and 1, both sorted. Together they encode a; # staircase-shaped cdf.; # For example, if min_x = 1, max_x=4, x=[2], y=[.2, .6], then the cdf is the; # staircase tracing the points; # (1, 0) - (1, .2) - (2, .2) - (2, .6) - (4, .6) - (4, 1); #; # Now consider the set of all possible cdfs within +-e of the one above. In; # other words, shift the staircase both up and down by e, capping above and; # below at 1 and 0, and consider all possible cdfs that lie in between. The; # distribution with maximum entropy whose cdf is between the two staircases; # is the one whose cdf is the graph constructed as follows: tie a rubber band; # to the points (min_x, 0) and (max_x, 1), place the middle between the two; # staircases, and let it contract. In other words, it will be the shortest; # path between the staircases.; #; # It's easy to see this path must be piecewise linear, and the points where the; # slopes change will be either; # * bending up at a point of the form (x[i], y[i]+e), or; # * bending down at a point of the form (x[i], y[i+1]-e); #; # Returns (new_y, keep).; # keep is the array of indices i at which the piecewise linear max-ent cdf; # changes slope, as described in the previous paragraph.; # new_y is an array the same length as x. For each i in keep, new_y[i] is the; # y coordinate of the point on the max-ent cdf.; def _max_entropy_cdf(min_x, max_x, x, y, e):; def point_on_bound(i, upper):; if i == len(x):; return max_x, 1; else:; yi = y[i] + e if upper else y[i + 1] - e; return x[i], yi. # Result variables:; new_y = np.full_like(x, 0.0, dtype=np.float64); keep = np.full_like(x",MatchSource.WIKI,docs/0.2/_modules/hail/ggplot/geoms.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/ggplot/geoms.html
https://hail.is/docs/0.2/_modules/hail/ggplot/geoms.html:20345,Integrability,interface,interface,20345,"opy_cdf(min_x, max_x, x, y, err); slopes = np.diff([0, *new_y[keep], 1]) / np.diff([min_x, *x[keep], max_x]). left = np.concatenate([[min_x], x[keep]]); right = np.concatenate([x[keep], [max_x]]); widths = right - left. trace_args = {; ""x"": [min_x, *x[keep]],; ""y"": slopes,; ""row"": facet_row,; ""col"": facet_col,; ""width"": widths,; ""offset"": 0,; }. self._add_aesthetics_to_trace_args(trace_args, df); self._update_legend_trace_args(trace_args, legend_cache). fig_so_far.add_bar(**trace_args). for idx, group_df in enumerate(grouped_data):; plot_group(group_df, idx). def get_stat(self):; return StatCDF(self.k). [docs]def geom_density(mapping=aes(), *, k=1000, smoothing=0.5, fill=None, color=None, alpha=None, smoothed=False):; """"""Creates a smoothed density plot. This method uses the `hl.agg.approx_cdf` aggregator to compute a sketch; of the distribution of the values of `x`. It then uses an ad hoc method to; estimate a smoothed pdf consistent with that cdf. Note: this function currently does not support same interface as R's ggplot. Supported aesthetics: ``x``, ``color``, ``fill``. Parameters; ----------; mapping: :class:`Aesthetic`; Any aesthetics specific to this geom.; k: `int`; Passed to the `approx_cdf` aggregator. The size of the aggregator scales; linearly with `k`. The default value of `1000` is likely sufficient for; most uses.; smoothing: `float`; Controls the amount of smoothing applied.; fill:; A single fill color for all density plots, overrides ``fill`` aesthetic.; color:; A single line color for all density plots, overrides ``color`` aesthetic.; alpha: `float`; A measure of transparency between 0 and 1.; smoothed: `boolean`; If true, attempts to fit a smooth kernel density estimator.; If false, uses a custom method do generate a variable width histogram; directly from the approx_cdf results. Returns; -------; :class:`FigureAttribute`; The geom to be applied.; """"""; return GeomDensity(mapping, k, smoothing, fill, color, alpha, smoothed). class GeomHLine(Geom):; d",MatchSource.WIKI,docs/0.2/_modules/hail/ggplot/geoms.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/ggplot/geoms.html
https://hail.is/docs/0.2/_modules/hail/ggplot/geoms.html:15394,Modifiability,variab,variables,15394," the two staircases; # is the one whose cdf is the graph constructed as follows: tie a rubber band; # to the points (min_x, 0) and (max_x, 1), place the middle between the two; # staircases, and let it contract. In other words, it will be the shortest; # path between the staircases.; #; # It's easy to see this path must be piecewise linear, and the points where the; # slopes change will be either; # * bending up at a point of the form (x[i], y[i]+e), or; # * bending down at a point of the form (x[i], y[i+1]-e); #; # Returns (new_y, keep).; # keep is the array of indices i at which the piecewise linear max-ent cdf; # changes slope, as described in the previous paragraph.; # new_y is an array the same length as x. For each i in keep, new_y[i] is the; # y coordinate of the point on the max-ent cdf.; def _max_entropy_cdf(min_x, max_x, x, y, e):; def point_on_bound(i, upper):; if i == len(x):; return max_x, 1; else:; yi = y[i] + e if upper else y[i + 1] - e; return x[i], yi. # Result variables:; new_y = np.full_like(x, 0.0, dtype=np.float64); keep = np.full_like(x, False, dtype=np.bool_). # State variables:; # (fx, fy) is most recently fixed point on max-ent cdf; fx, fy = min_x, 0; li, ui = 0, 0; j = 1. def slope_from_fixed(i, upper):; xi, yi = point_on_bound(i, upper); return (yi - fy) / (xi - fx). def fix_point_on_result(i, upper):; nonlocal fx, fy, new_y, keep; xi, yi = point_on_bound(i, upper); fx, fy = xi, yi; new_y[i] = fy; keep[i] = True. min_slope = slope_from_fixed(li, upper=False); max_slope = slope_from_fixed(ui, upper=True). # Consider a line l from (fx, fy) to (x[j], y?). As we increase y?, l first; # bumps into the upper staircase at (x[ui], y[ui] + e), and as we decrease; # y?, l first bumps into the lower staircase at (x[li], y[li+1] - e).; # We track the min and max slopes l can have while staying between the; # staircases, as well as the points li and ui where the line must bend if; # forced too high or too low. while True:; lower_slope = slope_from_fixe",MatchSource.WIKI,docs/0.2/_modules/hail/ggplot/geoms.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/ggplot/geoms.html
https://hail.is/docs/0.2/_modules/hail/ggplot/geoms.html:15509,Modifiability,variab,variables,15509,"e between the two; # staircases, and let it contract. In other words, it will be the shortest; # path between the staircases.; #; # It's easy to see this path must be piecewise linear, and the points where the; # slopes change will be either; # * bending up at a point of the form (x[i], y[i]+e), or; # * bending down at a point of the form (x[i], y[i+1]-e); #; # Returns (new_y, keep).; # keep is the array of indices i at which the piecewise linear max-ent cdf; # changes slope, as described in the previous paragraph.; # new_y is an array the same length as x. For each i in keep, new_y[i] is the; # y coordinate of the point on the max-ent cdf.; def _max_entropy_cdf(min_x, max_x, x, y, e):; def point_on_bound(i, upper):; if i == len(x):; return max_x, 1; else:; yi = y[i] + e if upper else y[i + 1] - e; return x[i], yi. # Result variables:; new_y = np.full_like(x, 0.0, dtype=np.float64); keep = np.full_like(x, False, dtype=np.bool_). # State variables:; # (fx, fy) is most recently fixed point on max-ent cdf; fx, fy = min_x, 0; li, ui = 0, 0; j = 1. def slope_from_fixed(i, upper):; xi, yi = point_on_bound(i, upper); return (yi - fy) / (xi - fx). def fix_point_on_result(i, upper):; nonlocal fx, fy, new_y, keep; xi, yi = point_on_bound(i, upper); fx, fy = xi, yi; new_y[i] = fy; keep[i] = True. min_slope = slope_from_fixed(li, upper=False); max_slope = slope_from_fixed(ui, upper=True). # Consider a line l from (fx, fy) to (x[j], y?). As we increase y?, l first; # bumps into the upper staircase at (x[ui], y[ui] + e), and as we decrease; # y?, l first bumps into the lower staircase at (x[li], y[li+1] - e).; # We track the min and max slopes l can have while staying between the; # staircases, as well as the points li and ui where the line must bend if; # forced too high or too low. while True:; lower_slope = slope_from_fixed(j, upper=False); upper_slope = slope_from_fixed(j, upper=True); if upper_slope < min_slope:; # Line must bend down at x[li]. We know the max-entropy cdf pas",MatchSource.WIKI,docs/0.2/_modules/hail/ggplot/geoms.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/ggplot/geoms.html
https://hail.is/docs/0.2/_modules/hail/ggplot/geoms.html:21095,Modifiability,variab,variable,21095,"od uses the `hl.agg.approx_cdf` aggregator to compute a sketch; of the distribution of the values of `x`. It then uses an ad hoc method to; estimate a smoothed pdf consistent with that cdf. Note: this function currently does not support same interface as R's ggplot. Supported aesthetics: ``x``, ``color``, ``fill``. Parameters; ----------; mapping: :class:`Aesthetic`; Any aesthetics specific to this geom.; k: `int`; Passed to the `approx_cdf` aggregator. The size of the aggregator scales; linearly with `k`. The default value of `1000` is likely sufficient for; most uses.; smoothing: `float`; Controls the amount of smoothing applied.; fill:; A single fill color for all density plots, overrides ``fill`` aesthetic.; color:; A single line color for all density plots, overrides ``color`` aesthetic.; alpha: `float`; A measure of transparency between 0 and 1.; smoothed: `boolean`; If true, attempts to fit a smooth kernel density estimator.; If false, uses a custom method do generate a variable width histogram; directly from the approx_cdf results. Returns; -------; :class:`FigureAttribute`; The geom to be applied.; """"""; return GeomDensity(mapping, k, smoothing, fill, color, alpha, smoothed). class GeomHLine(Geom):; def __init__(self, yintercept, linetype=""solid"", color=None):; self.yintercept = yintercept; self.aes = aes(); self.linetype = linetype; self.color = color. def apply_to_fig(; self, agg_result, fig_so_far: go.Figure, precomputed, facet_row, facet_col, legend_cache, is_faceted: bool; ):; line_attributes = {""y"": self.yintercept, ""line_dash"": linetype_plotly_to_gg(self.linetype)}; if self.color is not None:; line_attributes[""line_color""] = self.color. fig_so_far.add_hline(**line_attributes). def get_stat(self):; return StatNone(). [docs]def geom_hline(yintercept, *, linetype=""solid"", color=None):; """"""Plots a horizontal line at ``yintercept``. Parameters; ----------; yintercept : :class:`float`; Location to draw line.; linetype : :class:`str`; Type of line to draw. C",MatchSource.WIKI,docs/0.2/_modules/hail/ggplot/geoms.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/ggplot/geoms.html
https://hail.is/docs/0.2/_modules/hail/ggplot/ggplot.html:3599,Deployability,continuous,continuous,3599,"les.; if aesthetic_str == ""x"":; if is_continuous:; self.scales[""x""] = scale_x_continuous(); elif is_genomic_type(dtype):; self.scales[""x""] = scale_x_genomic(reference_genome=dtype.reference_genome); else:; self.scales[""x""] = scale_x_discrete(); elif aesthetic_str == ""y"":; if is_continuous:; self.scales[""y""] = scale_y_continuous(); elif is_genomic_type(dtype):; raise ValueError(""Don't yet support y axis genomic""); else:; self.scales[""y""] = scale_y_discrete(); elif aesthetic_str == ""color"" and not is_continuous:; self.scales[""color""] = scale_color_discrete(); elif aesthetic_str == ""color"" and is_continuous:; self.scales[""color""] = scale_color_continuous(); elif aesthetic_str == ""fill"" and not is_continuous:; self.scales[""fill""] = scale_fill_discrete(); elif aesthetic_str == ""fill"" and is_continuous:; self.scales[""fill""] = scale_fill_continuous(); elif aesthetic_str == ""shape"" and not is_continuous:; self.scales[""shape""] = scale_shape_auto(); elif aesthetic_str == ""shape"" and is_continuous:; raise ValueError(; ""The 'shape' aesthetic does not support continuous ""; ""types. Specify values of a discrete type instead.""; ); elif is_continuous:; self.scales[aesthetic_str] = ScaleContinuous(aesthetic_str); else:; self.scales[aesthetic_str] = ScaleDiscrete(aesthetic_str). def copy(self):; return GGPlot(self.ht, self.aes, self.geoms[:], self.labels, self.coord_cartesian, self.scales, self.facet). def verify_scales(self):; for aes_key in self.aes.keys():; check_scale_continuity(self.scales[aes_key], self.aes[aes_key].dtype, aes_key); for geom in self.geoms:; aesthetic_dict = geom.aes.properties; for aes_key in aesthetic_dict.keys():; check_scale_continuity(self.scales[aes_key], aesthetic_dict[aes_key].dtype, aes_key). [docs] def to_plotly(self):; """"""Turn the hail plot into a Plotly plot. Returns; -------; A Plotly figure that can be updated with plotly methods.; """""". def make_geom_label(geom_idx):; return f""geom{geom_idx}"". def select_table():; fields_to_select = {""figure_mapping",MatchSource.WIKI,docs/0.2/_modules/hail/ggplot/ggplot.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/ggplot/ggplot.html
https://hail.is/docs/0.2/_modules/hail/ggplot/ggplot.html:4387,Deployability,update,updated,4387,"l_continuous(); elif aesthetic_str == ""shape"" and not is_continuous:; self.scales[""shape""] = scale_shape_auto(); elif aesthetic_str == ""shape"" and is_continuous:; raise ValueError(; ""The 'shape' aesthetic does not support continuous ""; ""types. Specify values of a discrete type instead.""; ); elif is_continuous:; self.scales[aesthetic_str] = ScaleContinuous(aesthetic_str); else:; self.scales[aesthetic_str] = ScaleDiscrete(aesthetic_str). def copy(self):; return GGPlot(self.ht, self.aes, self.geoms[:], self.labels, self.coord_cartesian, self.scales, self.facet). def verify_scales(self):; for aes_key in self.aes.keys():; check_scale_continuity(self.scales[aes_key], self.aes[aes_key].dtype, aes_key); for geom in self.geoms:; aesthetic_dict = geom.aes.properties; for aes_key in aesthetic_dict.keys():; check_scale_continuity(self.scales[aes_key], aesthetic_dict[aes_key].dtype, aes_key). [docs] def to_plotly(self):; """"""Turn the hail plot into a Plotly plot. Returns; -------; A Plotly figure that can be updated with plotly methods.; """""". def make_geom_label(geom_idx):; return f""geom{geom_idx}"". def select_table():; fields_to_select = {""figure_mapping"": hl.struct(**self.aes)}; if self.facet is not None:; fields_to_select[""facet""] = self.facet.get_expr_to_group_by(). for geom_idx, geom in enumerate(self.geoms):; geom_label = make_geom_label(geom_idx); fields_to_select[geom_label] = hl.struct(**geom.aes.properties). name, ht = hl.struct(**fields_to_select)._to_table('__fallback'); return ht.select(**{field: ht[name][field] for field in fields_to_select}). def collect_mappings_and_precomputed(selected):; mapping_per_geom = []; precomputes = {}; for geom_idx, geom in enumerate(self.geoms):; geom_label = make_geom_label(geom_idx). combined_mapping = selected[""figure_mapping""].annotate(**selected[geom_label]). for key in combined_mapping:; if key in self.scales:; combined_mapping = combined_mapping.annotate(**{; key: self.scales[key].transform_data(combined_mapping[key]); }); mappin",MatchSource.WIKI,docs/0.2/_modules/hail/ggplot/ggplot.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/ggplot/ggplot.html
https://hail.is/docs/0.2/_modules/hail/ggplot/ggplot.html:9337,Deployability,update,update,9337,"red_axis_kwargs(),; }; else:; n_facet_rows = 1; n_facet_cols = 1; subplot_args = {; ""rows"": 1,; ""cols"": 1,; }; fig = make_subplots(**subplot_args). # Need to know what I've added to legend already so we don't do it more than once.; legend_cache = {}. for geom, geom_label, facet_to_grouped_dfs in geoms_and_grouped_dfs_by_facet_idx:; for facet_idx, grouped_dfs in facet_to_grouped_dfs.items():; scaled_grouped_dfs = []; for df in grouped_dfs:; scales_to_consider = list(df.columns) + list(df.attrs); relevant_aesthetics = [scale_name for scale_name in scales_to_consider if scale_name in self.scales]; scaled_df = df; for relevant_aesthetic in relevant_aesthetics:; scaled_df = transformers[relevant_aesthetic](scaled_df); scaled_grouped_dfs.append(scaled_df). facet_row = facet_idx // n_facet_cols + 1; facet_col = facet_idx % n_facet_cols + 1; geom.apply_to_fig(; scaled_grouped_dfs, fig, precomputed[geom_label], facet_row, facet_col, legend_cache, is_faceted; ). # Important to update axes after labels, axes names take precedence.; self.labels.apply_to_fig(fig); if self.scales.get(""x"") is not None:; self.scales[""x""].apply_to_fig(self, fig); if self.scales.get(""y"") is not None:; self.scales[""y""].apply_to_fig(self, fig); if self.coord_cartesian is not None:; self.coord_cartesian.apply_to_fig(fig). fig = fig.update_xaxes(title_font_size=18, ticks=""outside""); fig = fig.update_yaxes(title_font_size=18, ticks=""outside""); fig.update_layout(; plot_bgcolor=""white"",; font_family='Arial, ""Open Sans"", verdana, sans-serif',; title_font_size=26,; xaxis=dict(linecolor=""black"", showticklabels=True),; yaxis=dict(linecolor=""black"", showticklabels=True),; # axes for plotly subplots are numbered following the pattern [xaxis, xaxis2, xaxis3, ...]; **{; f""{var}axis{idx}"": {""linecolor"": ""black"", ""showticklabels"": True}; for idx in range(2, n_facet_rows + n_facet_cols + 1); for var in [""x"", ""y""]; },; ). return fig. [docs] def show(self):; """"""Render and show the plot, either in a browser or notebook.""""",MatchSource.WIKI,docs/0.2/_modules/hail/ggplot/ggplot.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/ggplot/ggplot.html
https://hail.is/docs/0.2/_modules/hail/ggplot/ggplot.html:10483,Deployability,install,installed,10483,"lf, fig); if self.scales.get(""y"") is not None:; self.scales[""y""].apply_to_fig(self, fig); if self.coord_cartesian is not None:; self.coord_cartesian.apply_to_fig(fig). fig = fig.update_xaxes(title_font_size=18, ticks=""outside""); fig = fig.update_yaxes(title_font_size=18, ticks=""outside""); fig.update_layout(; plot_bgcolor=""white"",; font_family='Arial, ""Open Sans"", verdana, sans-serif',; title_font_size=26,; xaxis=dict(linecolor=""black"", showticklabels=True),; yaxis=dict(linecolor=""black"", showticklabels=True),; # axes for plotly subplots are numbered following the pattern [xaxis, xaxis2, xaxis3, ...]; **{; f""{var}axis{idx}"": {""linecolor"": ""black"", ""showticklabels"": True}; for idx in range(2, n_facet_rows + n_facet_cols + 1); for var in [""x"", ""y""]; },; ). return fig. [docs] def show(self):; """"""Render and show the plot, either in a browser or notebook.""""""; self.to_plotly().show(). [docs] def write_image(self, path):; """"""Write out this plot as an image. This requires you to have installed the python package kaleido from pypi. Parameters; ----------; path: :class:`str`; The path to write the file to.; """"""; self.to_plotly().write_image(path). def _repr_html_(self):; return self.to_plotly()._repr_html_(). def _debug_print(self):; print(""Ggplot Object:""); print(""Aesthetics""); pprint(self.aes); pprint(""Scales:""); pprint(self.scales); print(""Geoms:""); pprint(self.geoms). [docs]def ggplot(table, mapping=aes()):; """"""Create the initial plot object. This function is the beginning of all plots using the ``hail.ggplot`` interface. Plots are constructed; by calling this function, then adding attributes to the plot to get the desired result. Examples; --------. Create a y = x^2 scatter plot. >>> ht = hl.utils.range_table(10); >>> ht = ht.annotate(squared = ht.idx**2); >>> my_plot = hl.ggplot.ggplot(ht, hl.ggplot.aes(x=ht.idx, y=ht.squared)) + hl.ggplot.geom_point(). Parameters; ----------; table; The table containing the data to plot.; mapping; Default list of aesthetic mappings from",MatchSource.WIKI,docs/0.2/_modules/hail/ggplot/ggplot.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/ggplot/ggplot.html
https://hail.is/docs/0.2/_modules/hail/ggplot/ggplot.html:11676,Deployability,update,updated,11676,"ticks=""outside""); fig = fig.update_yaxes(title_font_size=18, ticks=""outside""); fig.update_layout(; plot_bgcolor=""white"",; font_family='Arial, ""Open Sans"", verdana, sans-serif',; title_font_size=26,; xaxis=dict(linecolor=""black"", showticklabels=True),; yaxis=dict(linecolor=""black"", showticklabels=True),; # axes for plotly subplots are numbered following the pattern [xaxis, xaxis2, xaxis3, ...]; **{; f""{var}axis{idx}"": {""linecolor"": ""black"", ""showticklabels"": True}; for idx in range(2, n_facet_rows + n_facet_cols + 1); for var in [""x"", ""y""]; },; ). return fig. [docs] def show(self):; """"""Render and show the plot, either in a browser or notebook.""""""; self.to_plotly().show(). [docs] def write_image(self, path):; """"""Write out this plot as an image. This requires you to have installed the python package kaleido from pypi. Parameters; ----------; path: :class:`str`; The path to write the file to.; """"""; self.to_plotly().write_image(path). def _repr_html_(self):; return self.to_plotly()._repr_html_(). def _debug_print(self):; print(""Ggplot Object:""); print(""Aesthetics""); pprint(self.aes); pprint(""Scales:""); pprint(self.scales); print(""Geoms:""); pprint(self.geoms). [docs]def ggplot(table, mapping=aes()):; """"""Create the initial plot object. This function is the beginning of all plots using the ``hail.ggplot`` interface. Plots are constructed; by calling this function, then adding attributes to the plot to get the desired result. Examples; --------. Create a y = x^2 scatter plot. >>> ht = hl.utils.range_table(10); >>> ht = ht.annotate(squared = ht.idx**2); >>> my_plot = hl.ggplot.ggplot(ht, hl.ggplot.aes(x=ht.idx, y=ht.squared)) + hl.ggplot.geom_point(). Parameters; ----------; table; The table containing the data to plot.; mapping; Default list of aesthetic mappings from table data to plot attributes. Returns; -------; :class:`.GGPlot`; """"""; assert isinstance(mapping, Aesthetic); return GGPlot(table, mapping). © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,docs/0.2/_modules/hail/ggplot/ggplot.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/ggplot/ggplot.html
https://hail.is/docs/0.2/_modules/hail/ggplot/ggplot.html:11023,Integrability,interface,interface,11023,"ticks=""outside""); fig = fig.update_yaxes(title_font_size=18, ticks=""outside""); fig.update_layout(; plot_bgcolor=""white"",; font_family='Arial, ""Open Sans"", verdana, sans-serif',; title_font_size=26,; xaxis=dict(linecolor=""black"", showticklabels=True),; yaxis=dict(linecolor=""black"", showticklabels=True),; # axes for plotly subplots are numbered following the pattern [xaxis, xaxis2, xaxis3, ...]; **{; f""{var}axis{idx}"": {""linecolor"": ""black"", ""showticklabels"": True}; for idx in range(2, n_facet_rows + n_facet_cols + 1); for var in [""x"", ""y""]; },; ). return fig. [docs] def show(self):; """"""Render and show the plot, either in a browser or notebook.""""""; self.to_plotly().show(). [docs] def write_image(self, path):; """"""Write out this plot as an image. This requires you to have installed the python package kaleido from pypi. Parameters; ----------; path: :class:`str`; The path to write the file to.; """"""; self.to_plotly().write_image(path). def _repr_html_(self):; return self.to_plotly()._repr_html_(). def _debug_print(self):; print(""Ggplot Object:""); print(""Aesthetics""); pprint(self.aes); pprint(""Scales:""); pprint(self.scales); print(""Geoms:""); pprint(self.geoms). [docs]def ggplot(table, mapping=aes()):; """"""Create the initial plot object. This function is the beginning of all plots using the ``hail.ggplot`` interface. Plots are constructed; by calling this function, then adding attributes to the plot to get the desired result. Examples; --------. Create a y = x^2 scatter plot. >>> ht = hl.utils.range_table(10); >>> ht = ht.annotate(squared = ht.idx**2); >>> my_plot = hl.ggplot.ggplot(ht, hl.ggplot.aes(x=ht.idx, y=ht.squared)) + hl.ggplot.geom_point(). Parameters; ----------; table; The table containing the data to plot.; mapping; Default list of aesthetic mappings from table data to plot attributes. Returns; -------; :class:`.GGPlot`; """"""; assert isinstance(mapping, Aesthetic); return GGPlot(table, mapping). © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,docs/0.2/_modules/hail/ggplot/ggplot.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/ggplot/ggplot.html
https://hail.is/docs/0.2/_modules/hail/ggplot/ggplot.html:1691,Testability,assert,assert,1691,"eoms import FigureAttribute, Geom; from .labels import Labels; from .scale import (; Scale,; ScaleContinuous,; ScaleDiscrete,; scale_color_continuous,; scale_color_discrete,; scale_fill_continuous,; scale_fill_discrete,; scale_shape_auto,; scale_x_continuous,; scale_x_discrete,; scale_x_genomic,; scale_y_continuous,; scale_y_discrete,; ); from .utils import check_scale_continuity, is_continuous_type, is_genomic_type. [docs]class GGPlot:; """"""The class representing a figure created using the ``hail.ggplot`` module. Create one by using :func:`.ggplot`. .. automethod:: to_plotly; .. automethod:: show; .. automethod:: write_image; """""". def __init__(self, ht, aes, geoms=[], labels=Labels(), coord_cartesian=None, scales=None, facet=None):; if scales is None:; scales = {}. self.ht = ht; self.aes = aes; self.geoms = geoms; self.labels = labels; self.coord_cartesian = coord_cartesian; self.scales = scales; self.facet = facet. self.add_default_scales(aes). def __add__(self, other):; assert isinstance(other, (FigureAttribute, Aesthetic)). copied = self.copy(); if isinstance(other, Geom):; copied.geoms.append(other); copied.add_default_scales(other.aes); elif isinstance(other, Labels):; copied.labels = copied.labels.merge(other); elif isinstance(other, CoordCartesian):; copied.coord_cartesian = other; elif isinstance(other, Scale):; copied.scales[other.aesthetic_name] = other; elif isinstance(other, Aesthetic):; copied.aes = copied.aes.merge(other); elif isinstance(other, Faceter):; copied.facet = other; else:; raise ValueError(""Not implemented""). return copied. def add_default_scales(self, aesthetic):; for aesthetic_str, mapped_expr in aesthetic.items():; dtype = mapped_expr.dtype; if aesthetic_str not in self.scales:; is_continuous = is_continuous_type(dtype); # We only know how to come up with a few default scales.; if aesthetic_str == ""x"":; if is_continuous:; self.scales[""x""] = scale_x_continuous(); elif is_genomic_type(dtype):; self.scales[""x""] = scale_x_genomic(reference_ge",MatchSource.WIKI,docs/0.2/_modules/hail/ggplot/ggplot.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/ggplot/ggplot.html
https://hail.is/docs/0.2/_modules/hail/ggplot/ggplot.html:11566,Testability,assert,assert,11566,"ticks=""outside""); fig = fig.update_yaxes(title_font_size=18, ticks=""outside""); fig.update_layout(; plot_bgcolor=""white"",; font_family='Arial, ""Open Sans"", verdana, sans-serif',; title_font_size=26,; xaxis=dict(linecolor=""black"", showticklabels=True),; yaxis=dict(linecolor=""black"", showticklabels=True),; # axes for plotly subplots are numbered following the pattern [xaxis, xaxis2, xaxis3, ...]; **{; f""{var}axis{idx}"": {""linecolor"": ""black"", ""showticklabels"": True}; for idx in range(2, n_facet_rows + n_facet_cols + 1); for var in [""x"", ""y""]; },; ). return fig. [docs] def show(self):; """"""Render and show the plot, either in a browser or notebook.""""""; self.to_plotly().show(). [docs] def write_image(self, path):; """"""Write out this plot as an image. This requires you to have installed the python package kaleido from pypi. Parameters; ----------; path: :class:`str`; The path to write the file to.; """"""; self.to_plotly().write_image(path). def _repr_html_(self):; return self.to_plotly()._repr_html_(). def _debug_print(self):; print(""Ggplot Object:""); print(""Aesthetics""); pprint(self.aes); pprint(""Scales:""); pprint(self.scales); print(""Geoms:""); pprint(self.geoms). [docs]def ggplot(table, mapping=aes()):; """"""Create the initial plot object. This function is the beginning of all plots using the ``hail.ggplot`` interface. Plots are constructed; by calling this function, then adding attributes to the plot to get the desired result. Examples; --------. Create a y = x^2 scatter plot. >>> ht = hl.utils.range_table(10); >>> ht = ht.annotate(squared = ht.idx**2); >>> my_plot = hl.ggplot.ggplot(ht, hl.ggplot.aes(x=ht.idx, y=ht.squared)) + hl.ggplot.geom_point(). Parameters; ----------; table; The table containing the data to plot.; mapping; Default list of aesthetic mappings from table data to plot attributes. Returns; -------; :class:`.GGPlot`; """"""; assert isinstance(mapping, Aesthetic); return GGPlot(table, mapping). © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,docs/0.2/_modules/hail/ggplot/ggplot.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/ggplot/ggplot.html
https://hail.is/docs/0.2/_modules/hail/ggplot/labels.html:3286,Deployability,update,updated,3286,"l if other.xlabel is not None else self.xlabel; new_ylabel = other.ylabel if other.ylabel is not None else self.ylabel; new_group_labels = {**self.group_labels, **other.group_labels}. return Labels(title=new_title, xlabel=new_xlabel, ylabel=new_ylabel, group_labels=new_group_labels). [docs]def ggtitle(label):; """"""Sets the title of a plot. Parameters; ----------; label : :class:`str`; The desired title of the plot. Returns; -------; :class:`.FigureAttribute`; Label object to change the title.; """"""; return Labels(title=label). [docs]def xlab(label):; """"""Sets the x-axis label of a plot. Parameters; ----------; label : :class:`str`; The desired x-axis label of the plot. Returns; -------; :class:`.FigureAttribute`; Label object to change the x-axis label.; """"""; return Labels(xlabel=label). [docs]def ylab(label):; """"""Sets the y-axis label of a plot. Parameters; ----------; label : :class:`str`; The desired y-axis label of the plot. Returns; -------; :class:`.FigureAttribute`; Label object to change the y-axis label.; """"""; return Labels(ylabel=label). def labs(**group_labels):; """"""Sets the labels for the legend groups of a plot. Examples; --------. Create a scatterplot and label the legend groups according to their field names:. >>> ht = hl.utils.range_table(10); >>> ht = ht.annotate(squared=ht.idx ** 2); >>> ht = ht.annotate(even=hl.if_else(ht.idx % 2 == 0, ""yes"", ""no"")); >>> ht = ht.annotate(threeven=hl.if_else(ht.idx % 3 == 0, ""good"", ""bad"")); >>> fig = (; ... hl.ggplot.ggplot(ht, hl.ggplot.aes(x=ht.idx, y=ht.squared)); ... + hl.ggplot.geom_point(hl.ggplot.aes(color=ht.even, shape=ht.threeven)); ... + hl.ggplot.labs(color=""Even"", shape=""Threeven""); ... ). Parameters; ----------; group_labels:; Map names of plotly ``legendgroup``s to the desired replacement labels. Returns; -------; :class:`.FigureAttribute`; Label object to change the legend group labels.; """"""; return Labels(group_labels=group_labels). © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,docs/0.2/_modules/hail/ggplot/labels.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/ggplot/labels.html
https://hail.is/docs/0.2/_modules/hail/ggplot/scale.html:6813,Availability,down,down,6813,"ax(series_max, overall_max). color_mapping = continuous_nums_to_colors(overall_min, overall_max, plotly.colors.sequential.Viridis). def transform(df):; df[self.aesthetic_name] = df[self.aesthetic_name].map(lambda i: color_mapping(i)); return df. return transform. class ScaleColorHue(ScaleDiscrete):; def get_values(self, categories):; num_categories = len(categories); step = 1.0 / num_categories; interpolation_values = [step * i for i in range(num_categories)]; hsv_scale = px.colors.get_colorscale(""HSV""); return px.colors.sample_colorscale(hsv_scale, interpolation_values). class ScaleShapeAuto(ScaleDiscrete):; def get_values(self, categories):; return [; ""circle"",; ""square"",; ""diamond"",; ""cross"",; ""x"",; ""triangle-up"",; ""triangle-down"",; ""triangle-left"",; ""triangle-right"",; ""triangle-ne"",; ""triangle-se"",; ""triangle-sw"",; ""triangle-nw"",; ""pentagon"",; ""hexagon"",; ""hexagon2"",; ""octagon"",; ""star"",; ""hexagram"",; ""star-triangle-up"",; ""star-triangle-down"",; ""star-square"",; ""star-diamond"",; ""diamond-tall"",; ""diamond-wide"",; ""hourglass"",; ""bowtie"",; ""circle-cross"",; ""circle-x"",; ""square-cross"",; ""square-x"",; ""diamond-cross"",; ""diamond-x"",; ""cross-thin"",; ""x-thin"",; ""asterisk"",; ""hash"",; ""y-up"",; ""y-down"",; ""y-left"",; ""y-right"",; ""line-ew"",; ""line-ns"",; ""line-ne"",; ""line-nw"",; ""arrow-up"",; ""arrow-down"",; ""arrow-left"",; ""arrow-right"",; ""arrow-bar-up"",; ""arrow-bar-down"",; ""arrow-bar-left"",; ""arrow-bar-right"",; ]. class ScaleColorContinuousIdentity(ScaleContinuous):; def valid_dtype(self, dtype):; return dtype == tstr. [docs]def scale_x_log10(name=None):; """"""Transforms x axis to be log base 10 scaled. Parameters; ----------; name: :class:`str`; The label to show on x-axis. Returns; -------; :class:`.FigureAttribute`; The scale to be applied.; """"""; return PositionScaleContinuous(""x"", name=name, transformation=""log10""). [docs]def scale_y_log10(name=None):; """"""Transforms y-axis to be log base 10 scaled. Parameters; ----------; name: :class:`str`; The label to show on y-axis. Returns;",MatchSource.WIKI,docs/0.2/_modules/hail/ggplot/scale.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/ggplot/scale.html
https://hail.is/docs/0.2/_modules/hail/ggplot/scale.html:7030,Availability,down,down,7030,"ax(series_max, overall_max). color_mapping = continuous_nums_to_colors(overall_min, overall_max, plotly.colors.sequential.Viridis). def transform(df):; df[self.aesthetic_name] = df[self.aesthetic_name].map(lambda i: color_mapping(i)); return df. return transform. class ScaleColorHue(ScaleDiscrete):; def get_values(self, categories):; num_categories = len(categories); step = 1.0 / num_categories; interpolation_values = [step * i for i in range(num_categories)]; hsv_scale = px.colors.get_colorscale(""HSV""); return px.colors.sample_colorscale(hsv_scale, interpolation_values). class ScaleShapeAuto(ScaleDiscrete):; def get_values(self, categories):; return [; ""circle"",; ""square"",; ""diamond"",; ""cross"",; ""x"",; ""triangle-up"",; ""triangle-down"",; ""triangle-left"",; ""triangle-right"",; ""triangle-ne"",; ""triangle-se"",; ""triangle-sw"",; ""triangle-nw"",; ""pentagon"",; ""hexagon"",; ""hexagon2"",; ""octagon"",; ""star"",; ""hexagram"",; ""star-triangle-up"",; ""star-triangle-down"",; ""star-square"",; ""star-diamond"",; ""diamond-tall"",; ""diamond-wide"",; ""hourglass"",; ""bowtie"",; ""circle-cross"",; ""circle-x"",; ""square-cross"",; ""square-x"",; ""diamond-cross"",; ""diamond-x"",; ""cross-thin"",; ""x-thin"",; ""asterisk"",; ""hash"",; ""y-up"",; ""y-down"",; ""y-left"",; ""y-right"",; ""line-ew"",; ""line-ns"",; ""line-ne"",; ""line-nw"",; ""arrow-up"",; ""arrow-down"",; ""arrow-left"",; ""arrow-right"",; ""arrow-bar-up"",; ""arrow-bar-down"",; ""arrow-bar-left"",; ""arrow-bar-right"",; ]. class ScaleColorContinuousIdentity(ScaleContinuous):; def valid_dtype(self, dtype):; return dtype == tstr. [docs]def scale_x_log10(name=None):; """"""Transforms x axis to be log base 10 scaled. Parameters; ----------; name: :class:`str`; The label to show on x-axis. Returns; -------; :class:`.FigureAttribute`; The scale to be applied.; """"""; return PositionScaleContinuous(""x"", name=name, transformation=""log10""). [docs]def scale_y_log10(name=None):; """"""Transforms y-axis to be log base 10 scaled. Parameters; ----------; name: :class:`str`; The label to show on y-axis. Returns;",MatchSource.WIKI,docs/0.2/_modules/hail/ggplot/scale.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/ggplot/scale.html
https://hail.is/docs/0.2/_modules/hail/ggplot/scale.html:7282,Availability,down,down,7282,"ax(series_max, overall_max). color_mapping = continuous_nums_to_colors(overall_min, overall_max, plotly.colors.sequential.Viridis). def transform(df):; df[self.aesthetic_name] = df[self.aesthetic_name].map(lambda i: color_mapping(i)); return df. return transform. class ScaleColorHue(ScaleDiscrete):; def get_values(self, categories):; num_categories = len(categories); step = 1.0 / num_categories; interpolation_values = [step * i for i in range(num_categories)]; hsv_scale = px.colors.get_colorscale(""HSV""); return px.colors.sample_colorscale(hsv_scale, interpolation_values). class ScaleShapeAuto(ScaleDiscrete):; def get_values(self, categories):; return [; ""circle"",; ""square"",; ""diamond"",; ""cross"",; ""x"",; ""triangle-up"",; ""triangle-down"",; ""triangle-left"",; ""triangle-right"",; ""triangle-ne"",; ""triangle-se"",; ""triangle-sw"",; ""triangle-nw"",; ""pentagon"",; ""hexagon"",; ""hexagon2"",; ""octagon"",; ""star"",; ""hexagram"",; ""star-triangle-up"",; ""star-triangle-down"",; ""star-square"",; ""star-diamond"",; ""diamond-tall"",; ""diamond-wide"",; ""hourglass"",; ""bowtie"",; ""circle-cross"",; ""circle-x"",; ""square-cross"",; ""square-x"",; ""diamond-cross"",; ""diamond-x"",; ""cross-thin"",; ""x-thin"",; ""asterisk"",; ""hash"",; ""y-up"",; ""y-down"",; ""y-left"",; ""y-right"",; ""line-ew"",; ""line-ns"",; ""line-ne"",; ""line-nw"",; ""arrow-up"",; ""arrow-down"",; ""arrow-left"",; ""arrow-right"",; ""arrow-bar-up"",; ""arrow-bar-down"",; ""arrow-bar-left"",; ""arrow-bar-right"",; ]. class ScaleColorContinuousIdentity(ScaleContinuous):; def valid_dtype(self, dtype):; return dtype == tstr. [docs]def scale_x_log10(name=None):; """"""Transforms x axis to be log base 10 scaled. Parameters; ----------; name: :class:`str`; The label to show on x-axis. Returns; -------; :class:`.FigureAttribute`; The scale to be applied.; """"""; return PositionScaleContinuous(""x"", name=name, transformation=""log10""). [docs]def scale_y_log10(name=None):; """"""Transforms y-axis to be log base 10 scaled. Parameters; ----------; name: :class:`str`; The label to show on y-axis. Returns;",MatchSource.WIKI,docs/0.2/_modules/hail/ggplot/scale.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/ggplot/scale.html
https://hail.is/docs/0.2/_modules/hail/ggplot/scale.html:7381,Availability,down,down,7381,"ax(series_max, overall_max). color_mapping = continuous_nums_to_colors(overall_min, overall_max, plotly.colors.sequential.Viridis). def transform(df):; df[self.aesthetic_name] = df[self.aesthetic_name].map(lambda i: color_mapping(i)); return df. return transform. class ScaleColorHue(ScaleDiscrete):; def get_values(self, categories):; num_categories = len(categories); step = 1.0 / num_categories; interpolation_values = [step * i for i in range(num_categories)]; hsv_scale = px.colors.get_colorscale(""HSV""); return px.colors.sample_colorscale(hsv_scale, interpolation_values). class ScaleShapeAuto(ScaleDiscrete):; def get_values(self, categories):; return [; ""circle"",; ""square"",; ""diamond"",; ""cross"",; ""x"",; ""triangle-up"",; ""triangle-down"",; ""triangle-left"",; ""triangle-right"",; ""triangle-ne"",; ""triangle-se"",; ""triangle-sw"",; ""triangle-nw"",; ""pentagon"",; ""hexagon"",; ""hexagon2"",; ""octagon"",; ""star"",; ""hexagram"",; ""star-triangle-up"",; ""star-triangle-down"",; ""star-square"",; ""star-diamond"",; ""diamond-tall"",; ""diamond-wide"",; ""hourglass"",; ""bowtie"",; ""circle-cross"",; ""circle-x"",; ""square-cross"",; ""square-x"",; ""diamond-cross"",; ""diamond-x"",; ""cross-thin"",; ""x-thin"",; ""asterisk"",; ""hash"",; ""y-up"",; ""y-down"",; ""y-left"",; ""y-right"",; ""line-ew"",; ""line-ns"",; ""line-ne"",; ""line-nw"",; ""arrow-up"",; ""arrow-down"",; ""arrow-left"",; ""arrow-right"",; ""arrow-bar-up"",; ""arrow-bar-down"",; ""arrow-bar-left"",; ""arrow-bar-right"",; ]. class ScaleColorContinuousIdentity(ScaleContinuous):; def valid_dtype(self, dtype):; return dtype == tstr. [docs]def scale_x_log10(name=None):; """"""Transforms x axis to be log base 10 scaled. Parameters; ----------; name: :class:`str`; The label to show on x-axis. Returns; -------; :class:`.FigureAttribute`; The scale to be applied.; """"""; return PositionScaleContinuous(""x"", name=name, transformation=""log10""). [docs]def scale_y_log10(name=None):; """"""Transforms y-axis to be log base 10 scaled. Parameters; ----------; name: :class:`str`; The label to show on y-axis. Returns;",MatchSource.WIKI,docs/0.2/_modules/hail/ggplot/scale.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/ggplot/scale.html
https://hail.is/docs/0.2/_modules/hail/ggplot/scale.html:7448,Availability,down,down,7448,"ax(series_max, overall_max). color_mapping = continuous_nums_to_colors(overall_min, overall_max, plotly.colors.sequential.Viridis). def transform(df):; df[self.aesthetic_name] = df[self.aesthetic_name].map(lambda i: color_mapping(i)); return df. return transform. class ScaleColorHue(ScaleDiscrete):; def get_values(self, categories):; num_categories = len(categories); step = 1.0 / num_categories; interpolation_values = [step * i for i in range(num_categories)]; hsv_scale = px.colors.get_colorscale(""HSV""); return px.colors.sample_colorscale(hsv_scale, interpolation_values). class ScaleShapeAuto(ScaleDiscrete):; def get_values(self, categories):; return [; ""circle"",; ""square"",; ""diamond"",; ""cross"",; ""x"",; ""triangle-up"",; ""triangle-down"",; ""triangle-left"",; ""triangle-right"",; ""triangle-ne"",; ""triangle-se"",; ""triangle-sw"",; ""triangle-nw"",; ""pentagon"",; ""hexagon"",; ""hexagon2"",; ""octagon"",; ""star"",; ""hexagram"",; ""star-triangle-up"",; ""star-triangle-down"",; ""star-square"",; ""star-diamond"",; ""diamond-tall"",; ""diamond-wide"",; ""hourglass"",; ""bowtie"",; ""circle-cross"",; ""circle-x"",; ""square-cross"",; ""square-x"",; ""diamond-cross"",; ""diamond-x"",; ""cross-thin"",; ""x-thin"",; ""asterisk"",; ""hash"",; ""y-up"",; ""y-down"",; ""y-left"",; ""y-right"",; ""line-ew"",; ""line-ns"",; ""line-ne"",; ""line-nw"",; ""arrow-up"",; ""arrow-down"",; ""arrow-left"",; ""arrow-right"",; ""arrow-bar-up"",; ""arrow-bar-down"",; ""arrow-bar-left"",; ""arrow-bar-right"",; ]. class ScaleColorContinuousIdentity(ScaleContinuous):; def valid_dtype(self, dtype):; return dtype == tstr. [docs]def scale_x_log10(name=None):; """"""Transforms x axis to be log base 10 scaled. Parameters; ----------; name: :class:`str`; The label to show on x-axis. Returns; -------; :class:`.FigureAttribute`; The scale to be applied.; """"""; return PositionScaleContinuous(""x"", name=name, transformation=""log10""). [docs]def scale_y_log10(name=None):; """"""Transforms y-axis to be log base 10 scaled. Parameters; ----------; name: :class:`str`; The label to show on y-axis. Returns;",MatchSource.WIKI,docs/0.2/_modules/hail/ggplot/scale.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/ggplot/scale.html
https://hail.is/docs/0.2/_modules/hail/ggplot/scale.html:1509,Deployability,continuous,continuous,1509,"otly; import plotly.express as px. from hail.context import get_reference; from hail.expr.types import tstr. from .geoms import FigureAttribute; from .utils import continuous_nums_to_colors, is_continuous_type, is_discrete_type. class Scale(FigureAttribute):; def __init__(self, aesthetic_name):; self.aesthetic_name = aesthetic_name. @abc.abstractmethod; def transform_data(self, field_expr):; pass. def create_local_transformer(self, groups_of_dfs):; return lambda x: x. @abc.abstractmethod; def is_discrete(self):; pass. @abc.abstractmethod; def is_continuous(self):; pass. def valid_dtype(self, dtype):; pass. class PositionScale(Scale):; def __init__(self, aesthetic_name, name, breaks, labels):; super().__init__(aesthetic_name); self.name = name; self.breaks = breaks; self.labels = labels. def update_axis(self, fig):; if self.aesthetic_name == ""x"":; return fig.update_xaxes; elif self.aesthetic_name == ""y"":; return fig.update_yaxes. # What else do discrete and continuous scales have in common?; def apply_to_fig(self, parent, fig_so_far):; if self.name is not None:; self.update_axis(fig_so_far)(title=self.name). if self.breaks is not None:; self.update_axis(fig_so_far)(tickvals=self.breaks). if self.labels is not None:; self.update_axis(fig_so_far)(ticktext=self.labels). def valid_dtype(self, dtype):; return True. class PositionScaleGenomic(PositionScale):; def __init__(self, aesthetic_name, reference_genome, name=None):; super().__init__(aesthetic_name, name, None, None). if isinstance(reference_genome, str):; reference_genome = get_reference(reference_genome); self.reference_genome = reference_genome. def apply_to_fig(self, parent, fig_so_far):; contig_offsets = dict(list(self.reference_genome.global_positions_dict.items())[:24]); breaks = list(contig_offsets.values()); labels = list(contig_offsets.keys()); self.update_axis(fig_so_far)(tickvals=breaks, ticktext=labels). def transform_data(self, field_expr):; return field_expr.global_position(). def is_discrete(self):; r",MatchSource.WIKI,docs/0.2/_modules/hail/ggplot/scale.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/ggplot/scale.html
https://hail.is/docs/0.2/_modules/hail/ggplot/scale.html:8936,Deployability,continuous,continuous,8936,"ation=""log10""). [docs]def scale_y_log10(name=None):; """"""Transforms y-axis to be log base 10 scaled. Parameters; ----------; name: :class:`str`; The label to show on y-axis. Returns; -------; :class:`.FigureAttribute`; The scale to be applied.; """"""; return PositionScaleContinuous(""y"", name=name, transformation=""log10""). [docs]def scale_x_reverse(name=None):; """"""Transforms x-axis to be vertically reversed. Parameters; ----------; name: :class:`str`; The label to show on x-axis. Returns; -------; :class:`.FigureAttribute`; The scale to be applied.; """"""; return PositionScaleContinuous(""x"", name=name, transformation=""reverse""). [docs]def scale_y_reverse(name=None):; """"""Transforms y-axis to be vertically reversed. Parameters; ----------; name: :class:`str`; The label to show on y-axis. Returns; -------; :class:`.FigureAttribute`; The scale to be applied.; """"""; return PositionScaleContinuous(""y"", name=name, transformation=""reverse""). [docs]def scale_x_continuous(name=None, breaks=None, labels=None, trans=""identity""):; """"""The default continuous x scale. Parameters; ----------; name: :class:`str`; The label to show on x-axis; breaks: :class:`list` of :class:`float`; The locations to draw ticks on the x-axis.; labels: :class:`list` of :class:`str`; The labels of the ticks on the axis.; trans: :class:`str`; The transformation to apply to the x-axis. Supports ""identity"", ""reverse"", ""log10"". Returns; -------; :class:`.FigureAttribute`; The scale to be applied.; """"""; return PositionScaleContinuous(""x"", name=name, breaks=breaks, labels=labels, transformation=trans). [docs]def scale_y_continuous(name=None, breaks=None, labels=None, trans=""identity""):; """"""The default continuous y scale. Parameters; ----------; name: :class:`str`; The label to show on y-axis; breaks: :class:`list` of :class:`float`; The locations to draw ticks on the y-axis.; labels: :class:`list` of :class:`str`; The labels of the ticks on the axis.; trans: :class:`str`; The transformation to apply to the y-axis. Sup",MatchSource.WIKI,docs/0.2/_modules/hail/ggplot/scale.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/ggplot/scale.html
https://hail.is/docs/0.2/_modules/hail/ggplot/scale.html:9573,Deployability,continuous,continuous,9573,"def scale_y_reverse(name=None):; """"""Transforms y-axis to be vertically reversed. Parameters; ----------; name: :class:`str`; The label to show on y-axis. Returns; -------; :class:`.FigureAttribute`; The scale to be applied.; """"""; return PositionScaleContinuous(""y"", name=name, transformation=""reverse""). [docs]def scale_x_continuous(name=None, breaks=None, labels=None, trans=""identity""):; """"""The default continuous x scale. Parameters; ----------; name: :class:`str`; The label to show on x-axis; breaks: :class:`list` of :class:`float`; The locations to draw ticks on the x-axis.; labels: :class:`list` of :class:`str`; The labels of the ticks on the axis.; trans: :class:`str`; The transformation to apply to the x-axis. Supports ""identity"", ""reverse"", ""log10"". Returns; -------; :class:`.FigureAttribute`; The scale to be applied.; """"""; return PositionScaleContinuous(""x"", name=name, breaks=breaks, labels=labels, transformation=trans). [docs]def scale_y_continuous(name=None, breaks=None, labels=None, trans=""identity""):; """"""The default continuous y scale. Parameters; ----------; name: :class:`str`; The label to show on y-axis; breaks: :class:`list` of :class:`float`; The locations to draw ticks on the y-axis.; labels: :class:`list` of :class:`str`; The labels of the ticks on the axis.; trans: :class:`str`; The transformation to apply to the y-axis. Supports ""identity"", ""reverse"", ""log10"". Returns; -------; :class:`.FigureAttribute`; The scale to be applied.; """"""; return PositionScaleContinuous(""y"", name=name, breaks=breaks, labels=labels, transformation=trans). [docs]def scale_x_discrete(name=None, breaks=None, labels=None):; """"""The default discrete x scale. Parameters; ----------; name: :class:`str`; The label to show on x-axis; breaks: :class:`list` of :class:`str`; The locations to draw ticks on the x-axis.; labels: :class:`list` of :class:`str`; The labels of the ticks on the axis. Returns; -------; :class:`.FigureAttribute`; The scale to be applied.; """"""; return PositionS",MatchSource.WIKI,docs/0.2/_modules/hail/ggplot/scale.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/ggplot/scale.html
https://hail.is/docs/0.2/_modules/hail/ggplot/scale.html:12020,Deployability,continuous,continuous,12020," PositionScaleDiscrete(""y"", name=name, breaks=breaks, labels=labels). [docs]def scale_x_genomic(reference_genome, name=None):; """"""The default genomic x scale. This is used when the ``x`` aesthetic corresponds to a :class:`.LocusExpression`. Parameters; ----------; reference_genome:; The reference genome being used.; name: :class:`str`; The label to show on y-axis. Returns; -------; :class:`.FigureAttribute`; The scale to be applied.; """"""; return PositionScaleGenomic(""x"", reference_genome, name=name). [docs]def scale_color_discrete():; """"""The default discrete color scale. This maps each discrete value to a color. Equivalent to scale_color_hue. Returns; -------; :class:`.FigureAttribute`; The scale to be applied.; """"""; return scale_color_hue(). [docs]def scale_color_hue():; """"""Map discrete colors to evenly placed positions around the color wheel. Returns; -------; :class:`.FigureAttribute`; The scale to be applied. """"""; return ScaleColorHue(""color""). [docs]def scale_color_continuous():; """"""The default continuous color scale. This linearly interpolates colors between the min and max observed values. Returns; -------; :class:`.FigureAttribute`; The scale to be applied.; """"""; return ScaleColorContinuous(""color""). [docs]def scale_color_identity():; """"""A color scale that assumes the expression specified in the ``color`` aesthetic can be used as a color. Returns; -------; :class:`.FigureAttribute`; The scale to be applied.; """"""; return ScaleColorContinuousIdentity(""color""). [docs]def scale_color_manual(*, values):; """"""A color scale that assigns strings to colors using the pool of colors specified as `values`. Parameters; ----------; values: :class:`list` of :class:`str`; The colors to choose when assigning values to colors. Returns; -------; :class:`.FigureAttribute`; The scale to be applied.; """"""; return ScaleDiscreteManual(""color"", values=values). [docs]def scale_fill_discrete():; """"""The default discrete fill scale. This maps each discrete value to a fill color. Returns; ",MatchSource.WIKI,docs/0.2/_modules/hail/ggplot/scale.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/ggplot/scale.html
https://hail.is/docs/0.2/_modules/hail/ggplot/scale.html:13148,Deployability,continuous,continuous,13148,"--; :class:`.FigureAttribute`; The scale to be applied.; """"""; return ScaleColorContinuous(""color""). [docs]def scale_color_identity():; """"""A color scale that assumes the expression specified in the ``color`` aesthetic can be used as a color. Returns; -------; :class:`.FigureAttribute`; The scale to be applied.; """"""; return ScaleColorContinuousIdentity(""color""). [docs]def scale_color_manual(*, values):; """"""A color scale that assigns strings to colors using the pool of colors specified as `values`. Parameters; ----------; values: :class:`list` of :class:`str`; The colors to choose when assigning values to colors. Returns; -------; :class:`.FigureAttribute`; The scale to be applied.; """"""; return ScaleDiscreteManual(""color"", values=values). [docs]def scale_fill_discrete():; """"""The default discrete fill scale. This maps each discrete value to a fill color. Returns; -------; :class:`.FigureAttribute`; The scale to be applied.; """"""; return scale_fill_hue(). [docs]def scale_fill_continuous():; """"""The default continuous fill scale. This linearly interpolates colors between the min and max observed values. Returns; -------; :class:`.FigureAttribute`; The scale to be applied.; """"""; return ScaleColorContinuous(""fill""). [docs]def scale_fill_identity():; """"""A color scale that assumes the expression specified in the ``fill`` aesthetic can be used as a fill color. Returns; -------; :class:`.FigureAttribute`; The scale to be applied.; """"""; return ScaleColorContinuousIdentity(""fill""). [docs]def scale_fill_hue():; """"""Map discrete fill colors to evenly placed positions around the color wheel. Returns; -------; :class:`.FigureAttribute`; The scale to be applied. """"""; return ScaleColorHue(""fill""). [docs]def scale_fill_manual(*, values):; """"""A color scale that assigns strings to fill colors using the pool of colors specified as `values`. Parameters; ----------; values: :class:`list` of :class:`str`; The colors to choose when assigning values to colors. Returns; -------; :class:`.FigureAttr",MatchSource.WIKI,docs/0.2/_modules/hail/ggplot/scale.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/ggplot/scale.html
https://hail.is/docs/0.2/_modules/hail/ggplot/scale.html:14974,Deployability,update,updated,14974,"s; -------; :class:`.FigureAttribute`; The scale to be applied.; """"""; return scale_fill_hue(). [docs]def scale_fill_continuous():; """"""The default continuous fill scale. This linearly interpolates colors between the min and max observed values. Returns; -------; :class:`.FigureAttribute`; The scale to be applied.; """"""; return ScaleColorContinuous(""fill""). [docs]def scale_fill_identity():; """"""A color scale that assumes the expression specified in the ``fill`` aesthetic can be used as a fill color. Returns; -------; :class:`.FigureAttribute`; The scale to be applied.; """"""; return ScaleColorContinuousIdentity(""fill""). [docs]def scale_fill_hue():; """"""Map discrete fill colors to evenly placed positions around the color wheel. Returns; -------; :class:`.FigureAttribute`; The scale to be applied. """"""; return ScaleColorHue(""fill""). [docs]def scale_fill_manual(*, values):; """"""A color scale that assigns strings to fill colors using the pool of colors specified as `values`. Parameters; ----------; values: :class:`list` of :class:`str`; The colors to choose when assigning values to colors. Returns; -------; :class:`.FigureAttribute`; The scale to be applied.; """"""; return ScaleDiscreteManual(""fill"", values=values). def scale_shape_manual(*, values):; """"""A scale that assigns shapes to discrete aesthetics. See `the plotly documentation <https://plotly.com/python-api-reference/generated/plotly.graph_objects.scatter.html#plotly.graph_objects.scatter.Marker.symbol>`__ for a list of supported shapes. Parameters; ----------; values: :class:`list` of :class:`str`; The shapes from which to choose. Returns; -------; :class:`.FigureAttribute`; The scale to be applied.; """"""; return ScaleDiscreteManual(""shape"", values=values). def scale_shape_auto():; """"""A scale that automatically assigns shapes to discrete aesthetics. Returns; -------; :class:`.FigureAttribute`; The scale to be applied.; """"""; return ScaleShapeAuto(""shape""). © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,docs/0.2/_modules/hail/ggplot/scale.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/ggplot/scale.html
https://hail.is/docs/0.2/_modules/hail/ggplot/scale.html:7262,Security,hash,hash,7262,"ax(series_max, overall_max). color_mapping = continuous_nums_to_colors(overall_min, overall_max, plotly.colors.sequential.Viridis). def transform(df):; df[self.aesthetic_name] = df[self.aesthetic_name].map(lambda i: color_mapping(i)); return df. return transform. class ScaleColorHue(ScaleDiscrete):; def get_values(self, categories):; num_categories = len(categories); step = 1.0 / num_categories; interpolation_values = [step * i for i in range(num_categories)]; hsv_scale = px.colors.get_colorscale(""HSV""); return px.colors.sample_colorscale(hsv_scale, interpolation_values). class ScaleShapeAuto(ScaleDiscrete):; def get_values(self, categories):; return [; ""circle"",; ""square"",; ""diamond"",; ""cross"",; ""x"",; ""triangle-up"",; ""triangle-down"",; ""triangle-left"",; ""triangle-right"",; ""triangle-ne"",; ""triangle-se"",; ""triangle-sw"",; ""triangle-nw"",; ""pentagon"",; ""hexagon"",; ""hexagon2"",; ""octagon"",; ""star"",; ""hexagram"",; ""star-triangle-up"",; ""star-triangle-down"",; ""star-square"",; ""star-diamond"",; ""diamond-tall"",; ""diamond-wide"",; ""hourglass"",; ""bowtie"",; ""circle-cross"",; ""circle-x"",; ""square-cross"",; ""square-x"",; ""diamond-cross"",; ""diamond-x"",; ""cross-thin"",; ""x-thin"",; ""asterisk"",; ""hash"",; ""y-up"",; ""y-down"",; ""y-left"",; ""y-right"",; ""line-ew"",; ""line-ns"",; ""line-ne"",; ""line-nw"",; ""arrow-up"",; ""arrow-down"",; ""arrow-left"",; ""arrow-right"",; ""arrow-bar-up"",; ""arrow-bar-down"",; ""arrow-bar-left"",; ""arrow-bar-right"",; ]. class ScaleColorContinuousIdentity(ScaleContinuous):; def valid_dtype(self, dtype):; return dtype == tstr. [docs]def scale_x_log10(name=None):; """"""Transforms x axis to be log base 10 scaled. Parameters; ----------; name: :class:`str`; The label to show on x-axis. Returns; -------; :class:`.FigureAttribute`; The scale to be applied.; """"""; return PositionScaleContinuous(""x"", name=name, transformation=""log10""). [docs]def scale_y_log10(name=None):; """"""Transforms y-axis to be log base 10 scaled. Parameters; ----------; name: :class:`str`; The label to show on y-axis. Returns;",MatchSource.WIKI,docs/0.2/_modules/hail/ggplot/scale.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/ggplot/scale.html
https://hail.is/docs/0.2/_modules/hail/ggplot/scale.html:3024,Testability,log,log,3024," None, None). if isinstance(reference_genome, str):; reference_genome = get_reference(reference_genome); self.reference_genome = reference_genome. def apply_to_fig(self, parent, fig_so_far):; contig_offsets = dict(list(self.reference_genome.global_positions_dict.items())[:24]); breaks = list(contig_offsets.values()); labels = list(contig_offsets.keys()); self.update_axis(fig_so_far)(tickvals=breaks, ticktext=labels). def transform_data(self, field_expr):; return field_expr.global_position(). def is_discrete(self):; return False. def is_continuous(self):; return False. class PositionScaleContinuous(PositionScale):; def __init__(self, axis=None, name=None, breaks=None, labels=None, transformation=""identity""):; super().__init__(axis, name, breaks, labels); self.transformation = transformation. def apply_to_fig(self, parent, fig_so_far):; super().apply_to_fig(parent, fig_so_far); if self.transformation == ""identity"":; pass; elif self.transformation == ""log10"":; self.update_axis(fig_so_far)(type=""log""); elif self.transformation == ""reverse"":; self.update_axis(fig_so_far)(autorange=""reversed""); else:; raise ValueError(f""Unrecognized transformation {self.transformation}""). def transform_data(self, field_expr):; return field_expr. def is_discrete(self):; return False. def is_continuous(self):; return True. class PositionScaleDiscrete(PositionScale):; def __init__(self, axis=None, name=None, breaks=None, labels=None):; super().__init__(axis, name, breaks, labels). def apply_to_fig(self, parent, fig_so_far):; super().apply_to_fig(parent, fig_so_far). def transform_data(self, field_expr):; return field_expr. def is_discrete(self):; return True. def is_continuous(self):; return False. class ScaleContinuous(Scale):; def __init__(self, aesthetic_name):; super().__init__(aesthetic_name). def transform_data(self, field_expr):; return field_expr. def is_discrete(self):; return False. def is_continuous(self):; return True. def valid_dtype(self, dtype):; return is_continuous_type(dtype",MatchSource.WIKI,docs/0.2/_modules/hail/ggplot/scale.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/ggplot/scale.html
https://hail.is/docs/0.2/_modules/hail/ggplot/scale.html:7669,Testability,log,log,7669,"alues). class ScaleShapeAuto(ScaleDiscrete):; def get_values(self, categories):; return [; ""circle"",; ""square"",; ""diamond"",; ""cross"",; ""x"",; ""triangle-up"",; ""triangle-down"",; ""triangle-left"",; ""triangle-right"",; ""triangle-ne"",; ""triangle-se"",; ""triangle-sw"",; ""triangle-nw"",; ""pentagon"",; ""hexagon"",; ""hexagon2"",; ""octagon"",; ""star"",; ""hexagram"",; ""star-triangle-up"",; ""star-triangle-down"",; ""star-square"",; ""star-diamond"",; ""diamond-tall"",; ""diamond-wide"",; ""hourglass"",; ""bowtie"",; ""circle-cross"",; ""circle-x"",; ""square-cross"",; ""square-x"",; ""diamond-cross"",; ""diamond-x"",; ""cross-thin"",; ""x-thin"",; ""asterisk"",; ""hash"",; ""y-up"",; ""y-down"",; ""y-left"",; ""y-right"",; ""line-ew"",; ""line-ns"",; ""line-ne"",; ""line-nw"",; ""arrow-up"",; ""arrow-down"",; ""arrow-left"",; ""arrow-right"",; ""arrow-bar-up"",; ""arrow-bar-down"",; ""arrow-bar-left"",; ""arrow-bar-right"",; ]. class ScaleColorContinuousIdentity(ScaleContinuous):; def valid_dtype(self, dtype):; return dtype == tstr. [docs]def scale_x_log10(name=None):; """"""Transforms x axis to be log base 10 scaled. Parameters; ----------; name: :class:`str`; The label to show on x-axis. Returns; -------; :class:`.FigureAttribute`; The scale to be applied.; """"""; return PositionScaleContinuous(""x"", name=name, transformation=""log10""). [docs]def scale_y_log10(name=None):; """"""Transforms y-axis to be log base 10 scaled. Parameters; ----------; name: :class:`str`; The label to show on y-axis. Returns; -------; :class:`.FigureAttribute`; The scale to be applied.; """"""; return PositionScaleContinuous(""y"", name=name, transformation=""log10""). [docs]def scale_x_reverse(name=None):; """"""Transforms x-axis to be vertically reversed. Parameters; ----------; name: :class:`str`; The label to show on x-axis. Returns; -------; :class:`.FigureAttribute`; The scale to be applied.; """"""; return PositionScaleContinuous(""x"", name=name, transformation=""reverse""). [docs]def scale_y_reverse(name=None):; """"""Transforms y-axis to be vertically reversed. Parameters; ----------; name: :cla",MatchSource.WIKI,docs/0.2/_modules/hail/ggplot/scale.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/ggplot/scale.html
https://hail.is/docs/0.2/_modules/hail/ggplot/scale.html:7974,Testability,log,log,7974,"agon2"",; ""octagon"",; ""star"",; ""hexagram"",; ""star-triangle-up"",; ""star-triangle-down"",; ""star-square"",; ""star-diamond"",; ""diamond-tall"",; ""diamond-wide"",; ""hourglass"",; ""bowtie"",; ""circle-cross"",; ""circle-x"",; ""square-cross"",; ""square-x"",; ""diamond-cross"",; ""diamond-x"",; ""cross-thin"",; ""x-thin"",; ""asterisk"",; ""hash"",; ""y-up"",; ""y-down"",; ""y-left"",; ""y-right"",; ""line-ew"",; ""line-ns"",; ""line-ne"",; ""line-nw"",; ""arrow-up"",; ""arrow-down"",; ""arrow-left"",; ""arrow-right"",; ""arrow-bar-up"",; ""arrow-bar-down"",; ""arrow-bar-left"",; ""arrow-bar-right"",; ]. class ScaleColorContinuousIdentity(ScaleContinuous):; def valid_dtype(self, dtype):; return dtype == tstr. [docs]def scale_x_log10(name=None):; """"""Transforms x axis to be log base 10 scaled. Parameters; ----------; name: :class:`str`; The label to show on x-axis. Returns; -------; :class:`.FigureAttribute`; The scale to be applied.; """"""; return PositionScaleContinuous(""x"", name=name, transformation=""log10""). [docs]def scale_y_log10(name=None):; """"""Transforms y-axis to be log base 10 scaled. Parameters; ----------; name: :class:`str`; The label to show on y-axis. Returns; -------; :class:`.FigureAttribute`; The scale to be applied.; """"""; return PositionScaleContinuous(""y"", name=name, transformation=""log10""). [docs]def scale_x_reverse(name=None):; """"""Transforms x-axis to be vertically reversed. Parameters; ----------; name: :class:`str`; The label to show on x-axis. Returns; -------; :class:`.FigureAttribute`; The scale to be applied.; """"""; return PositionScaleContinuous(""x"", name=name, transformation=""reverse""). [docs]def scale_y_reverse(name=None):; """"""Transforms y-axis to be vertically reversed. Parameters; ----------; name: :class:`str`; The label to show on y-axis. Returns; -------; :class:`.FigureAttribute`; The scale to be applied.; """"""; return PositionScaleContinuous(""y"", name=name, transformation=""reverse""). [docs]def scale_x_continuous(name=None, breaks=None, labels=None, trans=""identity""):; """"""The default continuous x sc",MatchSource.WIKI,docs/0.2/_modules/hail/ggplot/scale.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/ggplot/scale.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:5169,Availability,resilien,resilience,5169,"s, if the first operand is an ndarray and the; second operand is a block matrix, the result will be a ndarray of block; matrices. To achieve the desired behavior for ``+`` and ``*``, place the; block matrix operand first; for ``-``, ``/``, and ``@``, first convert; the ndarray to a block matrix using :meth:`.from_numpy`. Warning; -------. Block matrix multiplication requires special care due to each block; of each operand being a dependency of multiple blocks in the product. The :math:`(i, j)`-block in the product ``a @ b`` is computed by summing; the products of corresponding blocks in block row :math:`i` of ``a`` and; block column :math:`j` of ``b``. So overall, in addition to this; multiplication and addition, the evaluation of ``a @ b`` realizes each; block of ``a`` as many times as the number of block columns of ``b``; and realizes each block of ``b`` as many times as the number of; block rows of ``a``. This becomes a performance and resilience issue whenever ``a`` or ``b``; is defined in terms of pending transformations (such as linear; algebra operations). For example, evaluating ``a @ (c @ d)`` will; effectively evaluate ``c @ d`` as many times as the number of block rows; in ``a``. To limit re-computation, write or cache transformed block matrix; operands before feeding them into matrix multiplication:. >>> c = BlockMatrix.read('c.bm') # doctest: +SKIP; >>> d = BlockMatrix.read('d.bm') # doctest: +SKIP; >>> (c @ d).write('cd.bm') # doctest: +SKIP; >>> a = BlockMatrix.read('a.bm') # doctest: +SKIP; >>> e = a @ BlockMatrix.read('cd.bm') # doctest: +SKIP. **Indexing and slicing**. Block matrices also support NumPy-style 2-dimensional; `indexing and slicing <https://docs.scipy.org/doc/numpy/user/basics.indexing.html>`__,; with two differences.; First, slices ``start:stop:step`` must be non-empty with positive ``step``.; Second, even if only one index is a slice, the resulting block matrix is still; 2-dimensional. For example, for a block matrix ``bm`` with 10 r",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:7495,Availability,down,downstream,7495,"2, :]`` is a block matrix with 1 row, 10 columns,; and elements from row 2 of ``bm``. - ``bm[:3, -1]`` is a block matrix with 3 rows, 1 column,; and the first 3 elements of the last column of ``bm``. - ``bm[::2, ::2]`` is a block matrix with 5 rows, 5 columns,; and all evenly-indexed elements of ``bm``. Use :meth:`filter`, :meth:`filter_rows`, and :meth:`filter_cols` to; subset to non-slice subsets of rows and columns, e.g. to rows ``[0, 2, 5]``. **Block-sparse representation**. By default, block matrices compute and store all blocks explicitly.; However, some applications involve block matrices in which:. - some blocks consist entirely of zeroes. - some blocks are not of interest. For example, statistical geneticists often want to compute and manipulate a; banded correlation matrix capturing ""linkage disequilibrium"" between nearby; variants along the genome. In this case, working with the full correlation; matrix for tens of millions of variants would be prohibitively expensive,; and in any case, entries far from the diagonal are either not of interest or; ought to be zeroed out before downstream linear algebra. To enable such computations, block matrices do not require that all blocks; be realized explicitly. Implicit (dropped) blocks behave as blocks of; zeroes, so we refer to a block matrix in which at least one block is; implicitly zero as a **block-sparse matrix**. Otherwise, we say the matrix; is block-dense. The property :meth:`is_sparse` encodes this state. Dropped blocks are not stored in memory or on :meth:`write`. In fact,; blocks that are dropped prior to an action like :meth:`export` or; :meth:`to_numpy` are never computed in the first place, nor are any blocks; of upstream operands on which only dropped blocks depend! In addition,; linear algebra is accelerated by avoiding, for example, explicit addition of; or multiplication by blocks of zeroes. Block-sparse matrices may be created with; :meth:`sparsify_band`,; :meth:`sparsify_rectangles`,; :meth:`spa",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:14365,Availability,error,error,14365,"; normalize=bool,; axis=nullable(enumeration('rows', 'cols')),; block_size=nullable(int),; ); def from_entry_expr(; cls, entry_expr, mean_impute=False, center=False, normalize=False, axis='rows', block_size=None; ):; """"""Creates a block matrix using a matrix table entry expression. Examples; --------; >>> mt = hl.balding_nichols_model(3, 25, 50); >>> bm = BlockMatrix.from_entry_expr(mt.GT.n_alt_alleles()). Notes; -----; This convenience method writes the block matrix to a temporary file on; persistent disk and then reads the file. If you want to store the; resulting block matrix, use :meth:`write_from_entry_expr` directly to; avoid writing the result twice. See :meth:`write_from_entry_expr` for; further documentation. Warning; -------; If the rows of the matrix table have been filtered to a small fraction,; then :meth:`.MatrixTable.repartition` before this method to improve; performance. If you encounter a Hadoop write/replication error, increase the; number of persistent workers or the disk size per persistent worker,; or use :meth:`write_from_entry_expr` to write to external storage. This method opens ``n_cols / block_size`` files concurrently per task.; To not blow out memory when the number of columns is very large,; limit the Hadoop write buffer size; e.g. on GCP, set this property on; cluster startup (the default is 64MB):; ``--properties 'core:fs.gs.io.buffersize.write=1048576``. Parameters; ----------; entry_expr: :class:`.Float64Expression`; Entry expression for numeric matrix entries.; mean_impute: :obj:`bool`; If true, set missing values to the row mean before centering or; normalizing. If false, missing values will raise an error.; center: :obj:`bool`; If true, subtract the row mean.; normalize: :obj:`bool`; If true and ``center=False``, divide by the row magnitude.; If true and ``center=True``, divide the centered value by the; centered row magnitude.; axis: :class:`str`; One of ""rows"" or ""cols"": axis by which to normalize or center.; block_size: :obj:`i",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:15084,Availability,error,error,15084," the result twice. See :meth:`write_from_entry_expr` for; further documentation. Warning; -------; If the rows of the matrix table have been filtered to a small fraction,; then :meth:`.MatrixTable.repartition` before this method to improve; performance. If you encounter a Hadoop write/replication error, increase the; number of persistent workers or the disk size per persistent worker,; or use :meth:`write_from_entry_expr` to write to external storage. This method opens ``n_cols / block_size`` files concurrently per task.; To not blow out memory when the number of columns is very large,; limit the Hadoop write buffer size; e.g. on GCP, set this property on; cluster startup (the default is 64MB):; ``--properties 'core:fs.gs.io.buffersize.write=1048576``. Parameters; ----------; entry_expr: :class:`.Float64Expression`; Entry expression for numeric matrix entries.; mean_impute: :obj:`bool`; If true, set missing values to the row mean before centering or; normalizing. If false, missing values will raise an error.; center: :obj:`bool`; If true, subtract the row mean.; normalize: :obj:`bool`; If true and ``center=False``, divide by the row magnitude.; If true and ``center=True``, divide the centered value by the; centered row magnitude.; axis: :class:`str`; One of ""rows"" or ""cols"": axis by which to normalize or center.; block_size: :obj:`int`, optional; Block size. Default given by :meth:`.BlockMatrix.default_block_size`.; """"""; path = new_temp_file(); cls.write_from_entry_expr(; entry_expr,; path,; overwrite=False,; mean_impute=mean_impute,; center=center,; normalize=normalize,; axis=axis,; block_size=block_size,; ); return cls.read(path). [docs] @classmethod; @typecheck_method(n_rows=int, n_cols=int, block_size=nullable(int), seed=nullable(int), gaussian=bool); def random(cls, n_rows, n_cols, block_size=None, seed=None, gaussian=True) -> 'BlockMatrix':; """"""Creates a block matrix with standard normal or uniform random entries. Examples; --------; Create a block matrix with",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:20913,Availability,checkpoint,checkpoint,20913,"check_method(path=str, overwrite=bool, force_row_major=bool, stage_locally=bool); def write(self, path, overwrite=False, force_row_major=False, stage_locally=False):; """"""Writes the block matrix. .. include:: ../_templates/write_warning.rst. Parameters; ----------; path: :class:`str`; Path for output file.; overwrite : :obj:`bool`; If ``True``, overwrite an existing file at the destination.; force_row_major: :obj:`bool`; If ``True``, transform blocks in column-major format; to row-major format before writing.; If ``False``, write blocks in their current format.; stage_locally: :obj:`bool`; If ``True``, major output will be written to temporary local storage; before being copied to ``output``.; """"""; hl.current_backend().validate_file(path). writer = BlockMatrixNativeWriter(path, overwrite, force_row_major, stage_locally); Env.backend().execute(BlockMatrixWrite(self._bmir, writer)). [docs] @typecheck_method(path=str, overwrite=bool, force_row_major=bool, stage_locally=bool); def checkpoint(self, path, overwrite=False, force_row_major=False, stage_locally=False):; """"""Checkpoint the block matrix. .. include:: ../_templates/write_warning.rst. Parameters; ----------; path: :class:`str`; Path for output file.; overwrite : :obj:`bool`; If ``True``, overwrite an existing file at the destination.; force_row_major: :obj:`bool`; If ``True``, transform blocks in column-major format; to row-major format before checkpointing.; If ``False``, checkpoint blocks in their current format.; stage_locally: :obj:`bool`; If ``True``, major output will be written to temporary local storage; before being copied to ``output``.; """"""; hl.current_backend().validate_file(path); self.write(path, overwrite, force_row_major, stage_locally); return BlockMatrix.read(path, _assert_type=self._bmir._type). [docs] @staticmethod; @typecheck(; entry_expr=expr_float64,; path=str,; overwrite=bool,; mean_impute=bool,; center=bool,; normalize=bool,; axis=nullable(enumeration('rows', 'cols')),; block_size=nullable",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:21341,Availability,checkpoint,checkpointing,21341,"ile at the destination.; force_row_major: :obj:`bool`; If ``True``, transform blocks in column-major format; to row-major format before writing.; If ``False``, write blocks in their current format.; stage_locally: :obj:`bool`; If ``True``, major output will be written to temporary local storage; before being copied to ``output``.; """"""; hl.current_backend().validate_file(path). writer = BlockMatrixNativeWriter(path, overwrite, force_row_major, stage_locally); Env.backend().execute(BlockMatrixWrite(self._bmir, writer)). [docs] @typecheck_method(path=str, overwrite=bool, force_row_major=bool, stage_locally=bool); def checkpoint(self, path, overwrite=False, force_row_major=False, stage_locally=False):; """"""Checkpoint the block matrix. .. include:: ../_templates/write_warning.rst. Parameters; ----------; path: :class:`str`; Path for output file.; overwrite : :obj:`bool`; If ``True``, overwrite an existing file at the destination.; force_row_major: :obj:`bool`; If ``True``, transform blocks in column-major format; to row-major format before checkpointing.; If ``False``, checkpoint blocks in their current format.; stage_locally: :obj:`bool`; If ``True``, major output will be written to temporary local storage; before being copied to ``output``.; """"""; hl.current_backend().validate_file(path); self.write(path, overwrite, force_row_major, stage_locally); return BlockMatrix.read(path, _assert_type=self._bmir._type). [docs] @staticmethod; @typecheck(; entry_expr=expr_float64,; path=str,; overwrite=bool,; mean_impute=bool,; center=bool,; normalize=bool,; axis=nullable(enumeration('rows', 'cols')),; block_size=nullable(int),; ); def write_from_entry_expr(; entry_expr,; path,; overwrite=False,; mean_impute=False,; center=False,; normalize=False,; axis='rows',; block_size=None,; ):; """"""Writes a block matrix from a matrix table entry expression. Examples; --------; >>> mt = hl.balding_nichols_model(3, 25, 50); >>> BlockMatrix.write_from_entry_expr(mt.GT.n_alt_alleles(),; ... 'output/m",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:21371,Availability,checkpoint,checkpoint,21371,"n-major format; to row-major format before writing.; If ``False``, write blocks in their current format.; stage_locally: :obj:`bool`; If ``True``, major output will be written to temporary local storage; before being copied to ``output``.; """"""; hl.current_backend().validate_file(path). writer = BlockMatrixNativeWriter(path, overwrite, force_row_major, stage_locally); Env.backend().execute(BlockMatrixWrite(self._bmir, writer)). [docs] @typecheck_method(path=str, overwrite=bool, force_row_major=bool, stage_locally=bool); def checkpoint(self, path, overwrite=False, force_row_major=False, stage_locally=False):; """"""Checkpoint the block matrix. .. include:: ../_templates/write_warning.rst. Parameters; ----------; path: :class:`str`; Path for output file.; overwrite : :obj:`bool`; If ``True``, overwrite an existing file at the destination.; force_row_major: :obj:`bool`; If ``True``, transform blocks in column-major format; to row-major format before checkpointing.; If ``False``, checkpoint blocks in their current format.; stage_locally: :obj:`bool`; If ``True``, major output will be written to temporary local storage; before being copied to ``output``.; """"""; hl.current_backend().validate_file(path); self.write(path, overwrite, force_row_major, stage_locally); return BlockMatrix.read(path, _assert_type=self._bmir._type). [docs] @staticmethod; @typecheck(; entry_expr=expr_float64,; path=str,; overwrite=bool,; mean_impute=bool,; center=bool,; normalize=bool,; axis=nullable(enumeration('rows', 'cols')),; block_size=nullable(int),; ); def write_from_entry_expr(; entry_expr,; path,; overwrite=False,; mean_impute=False,; center=False,; normalize=False,; axis='rows',; block_size=None,; ):; """"""Writes a block matrix from a matrix table entry expression. Examples; --------; >>> mt = hl.balding_nichols_model(3, 25, 50); >>> BlockMatrix.write_from_entry_expr(mt.GT.n_alt_alleles(),; ... 'output/model.bm'). Notes; -----; The resulting file can be loaded with :meth:`BlockMatrix.read`.; Bl",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:22455,Availability,down,downsamples,22455,"rage; before being copied to ``output``.; """"""; hl.current_backend().validate_file(path); self.write(path, overwrite, force_row_major, stage_locally); return BlockMatrix.read(path, _assert_type=self._bmir._type). [docs] @staticmethod; @typecheck(; entry_expr=expr_float64,; path=str,; overwrite=bool,; mean_impute=bool,; center=bool,; normalize=bool,; axis=nullable(enumeration('rows', 'cols')),; block_size=nullable(int),; ); def write_from_entry_expr(; entry_expr,; path,; overwrite=False,; mean_impute=False,; center=False,; normalize=False,; axis='rows',; block_size=None,; ):; """"""Writes a block matrix from a matrix table entry expression. Examples; --------; >>> mt = hl.balding_nichols_model(3, 25, 50); >>> BlockMatrix.write_from_entry_expr(mt.GT.n_alt_alleles(),; ... 'output/model.bm'). Notes; -----; The resulting file can be loaded with :meth:`BlockMatrix.read`.; Blocks are stored row-major. If a pipelined transformation significantly downsamples the rows of the; underlying matrix table, then repartitioning the matrix table ahead of; this method will greatly improve its performance. By default, this method will fail if any values are missing (to be clear,; special float values like ``nan`` are not missing values). - Set `mean_impute` to replace missing values with the row mean before; possibly centering or normalizing. If all values are missing, the row; mean is ``nan``. - Set `center` to shift each row to have mean zero before possibly; normalizing. - Set `normalize` to normalize each row to have unit length. To standardize each row, regarded as an empirical distribution, to have; mean 0 and variance 1, set `center` and `normalize` and then multiply; the result by ``sqrt(n_cols)``. Warning; -------; If the rows of the matrix table have been filtered to a small fraction,; then :meth:`.MatrixTable.repartition` before this method to improve; performance. This method opens ``n_cols / block_size`` files concurrently per task.; To not blow out memory when the number of col",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:24076,Availability,error,error,24076,"ch row, regarded as an empirical distribution, to have; mean 0 and variance 1, set `center` and `normalize` and then multiply; the result by ``sqrt(n_cols)``. Warning; -------; If the rows of the matrix table have been filtered to a small fraction,; then :meth:`.MatrixTable.repartition` before this method to improve; performance. This method opens ``n_cols / block_size`` files concurrently per task.; To not blow out memory when the number of columns is very large,; limit the Hadoop write buffer size; e.g. on GCP, set this property on; cluster startup (the default is 64MB):; ``--properties 'core:fs.gs.io.buffersize.write=1048576``. Parameters; ----------; entry_expr: :class:`.Float64Expression`; Entry expression for numeric matrix entries.; path: :class:`str`; Path for output.; overwrite : :obj:`bool`; If ``True``, overwrite an existing file at the destination.; mean_impute: :obj:`bool`; If true, set missing values to the row mean before centering or; normalizing. If false, missing values will raise an error.; center: :obj:`bool`; If true, subtract the row mean.; normalize: :obj:`bool`; If true and ``center=False``, divide by the row magnitude.; If true and ``center=True``, divide the centered value by the; centered row magnitude.; axis: :class:`str`; One of ""rows"" or ""cols"": axis by which to normalize or center.; block_size: :obj:`int`, optional; Block size. Default given by :meth:`.BlockMatrix.default_block_size`.; """"""; hl.current_backend().validate_file(path). if not block_size:; block_size = BlockMatrix.default_block_size(). raise_unless_entry_indexed('BlockMatrix.write_from_entry_expr', entry_expr); mt = matrix_table_source('BlockMatrix.write_from_entry_expr', entry_expr). if not (mean_impute or center or normalize):; if entry_expr in mt._fields_inverse:; field = mt._fields_inverse[entry_expr]; mt.select_entries(field)._write_block_matrix(path, overwrite, field, block_size); else:; field = Env.get_uid(); mt.select_entries(**{field: entry_expr})._write_block_matr",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:42406,Availability,redundant,redundant,42406,"n self. if self.n_rows == 1:; index_expr = [0]; elif self.n_cols == 1:; index_expr = [1]; else:; index_expr = [1, 0]. return BlockMatrix(BlockMatrixBroadcast(self._bmir, index_expr, [self.n_cols, self.n_rows], self.block_size)). [docs] def densify(self):; """"""Restore all dropped blocks as explicit blocks of zeros. Returns; -------; :class:`.BlockMatrix`; """"""; return BlockMatrix(BlockMatrixDensify(self._bmir)). [docs] def cache(self):; """"""Persist this block matrix in memory. Notes; -----; This method is an alias for :meth:`persist(""MEMORY_ONLY"") <hail.linalg.BlockMatrix.persist>`. Returns; -------; :class:`.BlockMatrix`; Cached block matrix.; """"""; return self.persist('MEMORY_ONLY'). [docs] @typecheck_method(storage_level=storage_level); def persist(self, storage_level='MEMORY_AND_DISK'):; """"""Persists this block matrix in memory or on disk. Notes; -----; The :meth:`.BlockMatrix.persist` and :meth:`.BlockMatrix.cache`; methods store the current block matrix on disk or in memory temporarily; to avoid redundant computation and improve the performance of Hail; pipelines. This method is not a substitution for; :meth:`.BlockMatrix.write`, which stores a permanent file. Most users should use the ""MEMORY_AND_DISK"" storage level. See the `Spark; documentation; <http://spark.apache.org/docs/latest/programming-guide.html#rdd-persistence>`__; for a more in-depth discussion of persisting data. Parameters; ----------; storage_level : str; Storage level. One of: NONE, DISK_ONLY,; DISK_ONLY_2, MEMORY_ONLY, MEMORY_ONLY_2, MEMORY_ONLY_SER,; MEMORY_ONLY_SER_2, MEMORY_AND_DISK, MEMORY_AND_DISK_2,; MEMORY_AND_DISK_SER, MEMORY_AND_DISK_SER_2, OFF_HEAP. Returns; -------; :class:`.BlockMatrix`; Persisted block matrix.; """"""; return Env.backend().persist_blockmatrix(self). [docs] def unpersist(self):; """"""Unpersists this block matrix from memory/disk. Notes; -----; This function will have no effect on a block matrix that was not previously; persisted. Returns; -------; :class:`.BlockMatrix`; Unpe",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:49079,Availability,checkpoint,checkpoints,49079," self.block_size + (; self._last_col_block_width if stop_bcol == self._n_block_cols else self.block_size; ). return self[start_row:stop_row, start_col:stop_col]. @typecheck_method(b=oneof(np.ndarray, block_matrix_type)); def __matmul__(self, b):; """"""Matrix multiplication: a @ b. Parameters; ----------; b: :class:`numpy.ndarray` or :class:`BlockMatrix`. Returns; -------; :class:`.BlockMatrix`; """"""; if isinstance(b, np.ndarray):; b = BlockMatrix(_to_bmir(b, self.block_size)). if self.n_cols != b.n_rows:; raise ValueError(f'incompatible shapes for matrix multiplication: {self.shape} and {b.shape}'). return BlockMatrix(BlockMatrixDot(self._bmir, b._bmir)). [docs] @typecheck_method(b=oneof(np.ndarray, block_matrix_type), splits=int, path_prefix=nullable(str)); def tree_matmul(self, b, *, splits, path_prefix=None):; """"""Matrix multiplication in situations with large inner dimension. This function splits a single matrix multiplication into `split_on_inner` smaller matrix multiplications,; does the smaller multiplications, checkpoints them with names defined by `file_name_prefix`, and adds them; together. This is useful in cases when the multiplication of two large matrices results in a much smaller matrix. Parameters; ----------; b: :class:`numpy.ndarray` or :class:`BlockMatrix`; splits: :obj:`int` (keyword only argument); The number of smaller multiplications to do.; path_prefix: :class:`str` (keyword only argument); The prefix of the path to write the block matrices to. If unspecified, writes to a tmpdir. Returns; -------; :class:`.BlockMatrix`; """"""; if isinstance(b, np.ndarray):; b = BlockMatrix(_to_bmir(b, self.block_size)). if self.n_cols != b.n_rows:; raise ValueError(f'incompatible shapes for matrix multiplication: {self.shape} and {b.shape}'). if path_prefix is None:; path_prefix = new_temp_file(""tree_matmul_tmp""). if splits != 1:; inner_brange_size = int(math.ceil(self._n_block_cols / splits)); split_points = [*list(range(0, self._n_block_cols, inner_brange_size)), ",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:22416,Deployability,pipeline,pipelined,22416,"rage; before being copied to ``output``.; """"""; hl.current_backend().validate_file(path); self.write(path, overwrite, force_row_major, stage_locally); return BlockMatrix.read(path, _assert_type=self._bmir._type). [docs] @staticmethod; @typecheck(; entry_expr=expr_float64,; path=str,; overwrite=bool,; mean_impute=bool,; center=bool,; normalize=bool,; axis=nullable(enumeration('rows', 'cols')),; block_size=nullable(int),; ); def write_from_entry_expr(; entry_expr,; path,; overwrite=False,; mean_impute=False,; center=False,; normalize=False,; axis='rows',; block_size=None,; ):; """"""Writes a block matrix from a matrix table entry expression. Examples; --------; >>> mt = hl.balding_nichols_model(3, 25, 50); >>> BlockMatrix.write_from_entry_expr(mt.GT.n_alt_alleles(),; ... 'output/model.bm'). Notes; -----; The resulting file can be loaded with :meth:`BlockMatrix.read`.; Blocks are stored row-major. If a pipelined transformation significantly downsamples the rows of the; underlying matrix table, then repartitioning the matrix table ahead of; this method will greatly improve its performance. By default, this method will fail if any values are missing (to be clear,; special float values like ``nan`` are not missing values). - Set `mean_impute` to replace missing values with the row mean before; possibly centering or normalizing. If all values are missing, the row; mean is ``nan``. - Set `center` to shift each row to have mean zero before possibly; normalizing. - Set `normalize` to normalize each row to have unit length. To standardize each row, regarded as an empirical distribution, to have; mean 0 and variance 1, set `center` and `normalize` and then multiply; the result by ``sqrt(n_cols)``. Warning; -------; If the rows of the matrix table have been filtered to a small fraction,; then :meth:`.MatrixTable.repartition` before this method to improve; performance. This method opens ``n_cols / block_size`` files concurrently per task.; To not blow out memory when the number of col",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:42465,Deployability,pipeline,pipelines,42465,"n self. if self.n_rows == 1:; index_expr = [0]; elif self.n_cols == 1:; index_expr = [1]; else:; index_expr = [1, 0]. return BlockMatrix(BlockMatrixBroadcast(self._bmir, index_expr, [self.n_cols, self.n_rows], self.block_size)). [docs] def densify(self):; """"""Restore all dropped blocks as explicit blocks of zeros. Returns; -------; :class:`.BlockMatrix`; """"""; return BlockMatrix(BlockMatrixDensify(self._bmir)). [docs] def cache(self):; """"""Persist this block matrix in memory. Notes; -----; This method is an alias for :meth:`persist(""MEMORY_ONLY"") <hail.linalg.BlockMatrix.persist>`. Returns; -------; :class:`.BlockMatrix`; Cached block matrix.; """"""; return self.persist('MEMORY_ONLY'). [docs] @typecheck_method(storage_level=storage_level); def persist(self, storage_level='MEMORY_AND_DISK'):; """"""Persists this block matrix in memory or on disk. Notes; -----; The :meth:`.BlockMatrix.persist` and :meth:`.BlockMatrix.cache`; methods store the current block matrix on disk or in memory temporarily; to avoid redundant computation and improve the performance of Hail; pipelines. This method is not a substitution for; :meth:`.BlockMatrix.write`, which stores a permanent file. Most users should use the ""MEMORY_AND_DISK"" storage level. See the `Spark; documentation; <http://spark.apache.org/docs/latest/programming-guide.html#rdd-persistence>`__; for a more in-depth discussion of persisting data. Parameters; ----------; storage_level : str; Storage level. One of: NONE, DISK_ONLY,; DISK_ONLY_2, MEMORY_ONLY, MEMORY_ONLY_2, MEMORY_ONLY_SER,; MEMORY_ONLY_SER_2, MEMORY_AND_DISK, MEMORY_AND_DISK_2,; MEMORY_AND_DISK_SER, MEMORY_AND_DISK_SER_2, OFF_HEAP. Returns; -------; :class:`.BlockMatrix`; Persisted block matrix.; """"""; return Env.backend().persist_blockmatrix(self). [docs] def unpersist(self):; """"""Unpersists this block matrix from memory/disk. Notes; -----; This function will have no effect on a block matrix that was not previously; persisted. Returns; -------; :class:`.BlockMatrix`; Unpe",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:76454,Deployability,configurat,configuration,76454,"finite; precision, the zero eigenvalues of :math:`X^T X` or :math:`X X^T` will; only be approximately zero. If the rank is not known ahead, examining the relative sizes of the; trailing singular values should reveal where the spectrum switches from; non-zero to ""zero"" eigenvalues. With 64-bit floating point, zero; eigenvalues are typically about 1e-16 times the largest eigenvalue.; The corresponding singular vectors should be sliced away **before** an; action which realizes the block-matrix-side singular vectors. :meth:`svd` sets the singular values corresponding to negative; eigenvalues to exactly ``0.0``. Warning; -------; The first and third stages invoke distributed matrix multiplication with; parallelism bounded by the number of resulting blocks, whereas the; second stage is executed on the leader (master) node. For matrices of; large minimum dimension, it may be preferable to run these stages; separately. The performance of the second stage depends critically on the number of; leader (master) cores and the NumPy / SciPy configuration, viewable with; ``np.show_config()``. For Intel machines, we recommend installing the; `MKL <https://anaconda.org/anaconda/mkl>`__ package for Anaconda. Consequently, the optimal value of `complexity_bound` is highly; configuration-dependent. Parameters; ----------; compute_uv: :obj:`bool`; If False, only compute the singular values (or eigenvalues).; complexity_bound: :obj:`int`; Maximum value of :math:`\sqrt[3]{nmr}` for which; :func:`scipy.linalg.svd` is used. Returns; -------; u: :class:`numpy.ndarray` or :class:`BlockMatrix`; Left singular vectors :math:`U`, as a block matrix if :math:`n > m` and; :math:`\sqrt[3]{nmr}` exceeds `complexity_bound`.; Only returned if `compute_uv` is True.; s: :class:`numpy.ndarray`; Singular values from :math:`\Sigma` in descending order.; vt: :class:`numpy.ndarray` or :class:`BlockMatrix`; Right singular vectors :math:`V^T``, as a block matrix if :math:`n \leq m` and; :math:`\sqrt[3]{nmr}` excee",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:76539,Deployability,install,installing,76539,"own ahead, examining the relative sizes of the; trailing singular values should reveal where the spectrum switches from; non-zero to ""zero"" eigenvalues. With 64-bit floating point, zero; eigenvalues are typically about 1e-16 times the largest eigenvalue.; The corresponding singular vectors should be sliced away **before** an; action which realizes the block-matrix-side singular vectors. :meth:`svd` sets the singular values corresponding to negative; eigenvalues to exactly ``0.0``. Warning; -------; The first and third stages invoke distributed matrix multiplication with; parallelism bounded by the number of resulting blocks, whereas the; second stage is executed on the leader (master) node. For matrices of; large minimum dimension, it may be preferable to run these stages; separately. The performance of the second stage depends critically on the number of; leader (master) cores and the NumPy / SciPy configuration, viewable with; ``np.show_config()``. For Intel machines, we recommend installing the; `MKL <https://anaconda.org/anaconda/mkl>`__ package for Anaconda. Consequently, the optimal value of `complexity_bound` is highly; configuration-dependent. Parameters; ----------; compute_uv: :obj:`bool`; If False, only compute the singular values (or eigenvalues).; complexity_bound: :obj:`int`; Maximum value of :math:`\sqrt[3]{nmr}` for which; :func:`scipy.linalg.svd` is used. Returns; -------; u: :class:`numpy.ndarray` or :class:`BlockMatrix`; Left singular vectors :math:`U`, as a block matrix if :math:`n > m` and; :math:`\sqrt[3]{nmr}` exceeds `complexity_bound`.; Only returned if `compute_uv` is True.; s: :class:`numpy.ndarray`; Singular values from :math:`\Sigma` in descending order.; vt: :class:`numpy.ndarray` or :class:`BlockMatrix`; Right singular vectors :math:`V^T``, as a block matrix if :math:`n \leq m` and; :math:`\sqrt[3]{nmr}` exceeds `complexity_bound`.; Only returned if `compute_uv` is True.; """"""; n, m = self.shape. if n * m * min(n, m) <= complexity_bound*",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:76686,Deployability,configurat,configuration-dependent,76686,"-zero to ""zero"" eigenvalues. With 64-bit floating point, zero; eigenvalues are typically about 1e-16 times the largest eigenvalue.; The corresponding singular vectors should be sliced away **before** an; action which realizes the block-matrix-side singular vectors. :meth:`svd` sets the singular values corresponding to negative; eigenvalues to exactly ``0.0``. Warning; -------; The first and third stages invoke distributed matrix multiplication with; parallelism bounded by the number of resulting blocks, whereas the; second stage is executed on the leader (master) node. For matrices of; large minimum dimension, it may be preferable to run these stages; separately. The performance of the second stage depends critically on the number of; leader (master) cores and the NumPy / SciPy configuration, viewable with; ``np.show_config()``. For Intel machines, we recommend installing the; `MKL <https://anaconda.org/anaconda/mkl>`__ package for Anaconda. Consequently, the optimal value of `complexity_bound` is highly; configuration-dependent. Parameters; ----------; compute_uv: :obj:`bool`; If False, only compute the singular values (or eigenvalues).; complexity_bound: :obj:`int`; Maximum value of :math:`\sqrt[3]{nmr}` for which; :func:`scipy.linalg.svd` is used. Returns; -------; u: :class:`numpy.ndarray` or :class:`BlockMatrix`; Left singular vectors :math:`U`, as a block matrix if :math:`n > m` and; :math:`\sqrt[3]{nmr}` exceeds `complexity_bound`.; Only returned if `compute_uv` is True.; s: :class:`numpy.ndarray`; Singular values from :math:`\Sigma` in descending order.; vt: :class:`numpy.ndarray` or :class:`BlockMatrix`; Right singular vectors :math:`V^T``, as a block matrix if :math:`n \leq m` and; :math:`\sqrt[3]{nmr}` exceeds `complexity_bound`.; Only returned if `compute_uv` is True.; """"""; n, m = self.shape. if n * m * min(n, m) <= complexity_bound**3:; return _svd(self.to_numpy(), full_matrices=False, compute_uv=compute_uv, overwrite_a=True); else:; return self._svd_gr",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:83141,Deployability,update,updated,83141,"s.richUtils.RichDenseMatrixDouble.importFromDoubles(; Env.spark_backend('_breeze_fromfile').fs._jfs, uri, n_rows, n_cols, True; ). def _check_entries_size(n_rows, n_cols):; n_entries = n_rows * n_cols; if n_entries >= 1 << 31:; raise ValueError(f'number of entries must be less than 2^31, found {n_entries}'). def _breeze_from_ndarray(nd):; if any(i == 0 for i in nd.shape):; raise ValueError(f'from_numpy: ndarray dimensions must be non-zero, found shape {nd.shape}'). nd = _ndarray_as_2d(nd); nd = _ndarray_as_float64(nd); n_rows, n_cols = nd.shape. with with_local_temp_file() as path:; uri = local_path_uri(path); nd.tofile(path); return _breeze_fromfile(uri, n_rows, n_cols). def _svd(a, full_matrices=True, compute_uv=True, overwrite_a=False, check_finite=True):; """"""; SciPy supports two Lapack algorithms:; DC: https://software.intel.com/en-us/mkl-developer-reference-fortran-gesdd; GR: https://software.intel.com/en-us/mkl-developer-reference-fortran-gesvd; DC (gesdd) is faster but uses O(elements) memory; lwork may overflow int32; """"""; try:; return spla.svd(; a,; full_matrices=full_matrices,; compute_uv=compute_uv,; overwrite_a=overwrite_a,; check_finite=check_finite,; lapack_driver='gesdd',; ); except ValueError as e:; if 'Too large work array required' in str(e):; return spla.svd(; a,; full_matrices=full_matrices,; compute_uv=compute_uv,; overwrite_a=overwrite_a,; check_finite=check_finite,; lapack_driver='gesvd',; ); else:; raise. def _eigh(a):; """"""; Only the lower triangle is used. Returns eigenvalues, eigenvectors.; NumPy and SciPy apply different Lapack algorithms:; NumPy uses DC: https://software.intel.com/en-us/mkl-developer-reference-fortran-syevd; SciPy uses RRR: https://software.intel.com/en-us/mkl-developer-reference-fortran-syevr; DC (syevd) is faster but uses O(elements) memory; lwork overflows int32 for dim_a > 32766; """"""; return np.linalg.eigh(a) if a.shape[0] <= 32766 else spla.eigh(a). © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:3127,Energy Efficiency,power,power,3127,"e_level, with_local_temp_file; from hail.utils.java import Env. block_matrix_type = lazy(). [docs]class BlockMatrix(object):; """"""Hail's block-distributed matrix of :py:data:`.tfloat64` elements. .. include:: ../_templates/experimental.rst. A block matrix is a distributed analogue of a two-dimensional; `NumPy ndarray; <https://docs.scipy.org/doc/numpy/reference/arrays.ndarray.html>`__ with; shape ``(n_rows, n_cols)`` and NumPy dtype ``float64``.; Import the class with:. >>> from hail.linalg import BlockMatrix. Under the hood, block matrices are partitioned like a checkerboard into; square blocks with side length a common block size. Blocks in the final row; or column of blocks may be truncated, so block size need not evenly divide; the matrix dimensions. Block size defaults to the value given by; :meth:`default_block_size`. **Operations and broadcasting**. The core operations are consistent with NumPy: ``+``, ``-``, ``*``, and; ``/`` for element-wise addition, subtraction, multiplication, and division;; ``@`` for matrix multiplication; ``T`` for transpose; and ``**`` for; element-wise exponentiation to a scalar power. For element-wise binary operations, each operand may be a block matrix, an; ndarray, or a scalar (:obj:`int` or :obj:`float`). For matrix; multiplication, each operand may be a block matrix or an ndarray. If either; operand is a block matrix, the result is a block matrix. Binary operations; between block matrices require that both operands have the same block size. To interoperate with block matrices, ndarray operands must be one or two; dimensional with dtype convertible to ``float64``. One-dimensional ndarrays; of shape ``(n)`` are promoted to two-dimensional ndarrays of shape ``(1,; n)``, i.e. a single row. Block matrices support broadcasting of ``+``, ``-``, ``*``, and ``/``; between matrices of different shapes, consistent with the NumPy; `broadcasting rules; <https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html>`__.; There is one exceptio",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:27991,Energy Efficiency,efficient,efficient,27991,"of :obj:`int`; Indices of rows to keep. Must be non-empty and increasing. Returns; -------; :class:`.BlockMatrix`; """"""; BlockMatrix._check_indices(rows_to_keep, self.n_rows); return BlockMatrix(BlockMatrixFilter(self._bmir, [rows_to_keep, []])). [docs] @typecheck_method(cols_to_keep=sequenceof(int)); def filter_cols(self, cols_to_keep):; """"""Filters matrix columns. Parameters; ----------; cols_to_keep: :obj:`list` of :obj:`int`; Indices of columns to keep. Must be non-empty and increasing. Returns; -------; :class:`.BlockMatrix`; """"""; BlockMatrix._check_indices(cols_to_keep, self.n_cols); return BlockMatrix(BlockMatrixFilter(self._bmir, [[], cols_to_keep])). [docs] @typecheck_method(rows_to_keep=sequenceof(int), cols_to_keep=sequenceof(int)); def filter(self, rows_to_keep, cols_to_keep):; """"""Filters matrix rows and columns. Notes; -----; This method has the same effect as :meth:`BlockMatrix.filter_cols`; followed by :meth:`BlockMatrix.filter_rows` (or vice versa), but; filters the block matrix in a single pass which may be more efficient. Parameters; ----------; rows_to_keep: :obj:`list` of :obj:`int`; Indices of rows to keep. Must be non-empty and increasing.; cols_to_keep: :obj:`list` of :obj:`int`; Indices of columns to keep. Must be non-empty and increasing. Returns; -------; :class:`.BlockMatrix`; """"""; BlockMatrix._check_indices(rows_to_keep, self.n_rows); BlockMatrix._check_indices(cols_to_keep, self.n_cols); return BlockMatrix(BlockMatrixFilter(self._bmir, [rows_to_keep, cols_to_keep])). @staticmethod; def _pos_index(i, size, name, allow_size=False):; if 0 <= i < size or (i == size and allow_size):; return i; elif 0 <= i + size < size:; return i + size; else:; raise ValueError(f'invalid {name} {i} for axis of size {size}'). @staticmethod; def _range_to_keep(idx, size):; if isinstance(idx, int):; pos_idx = BlockMatrix._pos_index(idx, size, 'index'); return slice(pos_idx, pos_idx + 1, 1). assert isinstance(idx, slice); if idx.step and idx.step <= 0:; raise ValueE",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:32202,Energy Efficiency,efficient,efficient,32202," by zeroing out all blocks; which are disjoint from a diagonal band. By default,; all elements outside the band but inside blocks that overlap the; band are set to zero as well. The band is defined in terms of inclusive `lower` and `upper` indices; relative to the diagonal. For example, the indices -1, 0, and 1; correspond to the sub-diagonal, diagonal, and super-diagonal,; respectively. The diagonal band contains the elements at positions; :math:`(i, j)` such that. .. math::. \mathrm{lower} \leq j - i \leq \mathrm{upper}. `lower` must be less than or equal to `upper`, but their values may; exceed the dimensions of the matrix, the band need not include the; diagonal, and the matrix need not be square. Parameters; ----------; lower: :obj:`int`; Index of lowest band relative to the diagonal.; upper: :obj:`int`; Index of highest band relative to the diagonal.; blocks_only: :obj:`bool`; If ``False``, set all elements outside the band to zero.; If ``True``, only set all blocks outside the band to blocks; of zeros; this is more efficient. Returns; -------; :class:`.BlockMatrix`; Sparse block matrix.; """"""; if lower > upper:; raise ValueError(f'sparsify_band: lower={lower} is greater than upper={upper}'). bounds = hl.literal((lower, upper), hl.ttuple(hl.tint64, hl.tint64)); return BlockMatrix(BlockMatrixSparsify(self._bmir, bounds._ir, BandSparsifier(blocks_only))). [docs] @typecheck_method(lower=bool, blocks_only=bool); def sparsify_triangle(self, lower=False, blocks_only=False):; """"""Filter to the upper or lower triangle. Examples; --------; Consider the following block matrix:. >>> import numpy as np; >>> nd = np.array([[ 1.0, 2.0, 3.0, 4.0],; ... [ 5.0, 6.0, 7.0, 8.0],; ... [ 9.0, 10.0, 11.0, 12.0],; ... [13.0, 14.0, 15.0, 16.0]]); >>> bm = BlockMatrix.from_numpy(nd, block_size=2). Filter to the upper triangle and collect to NumPy:. >>> bm.sparsify_triangle().to_numpy() # doctest: +SKIP_OUTPUT_CHECK; array([[ 1., 2., 3., 4.],; [ 0., 6., 7., 8.],; [ 0., 0., 11., 12.],; [ ",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:34006,Energy Efficiency,efficient,efficient,34006,"e=2). Filter to the upper triangle and collect to NumPy:. >>> bm.sparsify_triangle().to_numpy() # doctest: +SKIP_OUTPUT_CHECK; array([[ 1., 2., 3., 4.],; [ 0., 6., 7., 8.],; [ 0., 0., 11., 12.],; [ 0., 0., 0., 16.]]). Set all blocks fully outside the upper triangle to zero; and collect to NumPy:. >>> bm.sparsify_triangle(blocks_only=True).to_numpy() # doctest: +SKIP_OUTPUT_CHECK; array([[ 1., 2., 3., 4.],; [ 5., 6., 7., 8.],; [ 0., 0., 11., 12.],; [ 0., 0., 15., 16.]]). Notes; -----; This method creates a block-sparse matrix by zeroing out all blocks; which are disjoint from the (non-strict) upper or lower triangle. By; default, all elements outside the triangle but inside blocks that; overlap the triangle are set to zero as well. Parameters; ----------; lower: :obj:`bool`; If ``False``, keep the upper triangle.; If ``True``, keep the lower triangle.; blocks_only: :obj:`bool`; If ``False``, set all elements outside the triangle to zero.; If ``True``, only set all blocks outside the triangle to; blocks of zeros; this is more efficient. Returns; -------; :class:`.BlockMatrix`; Sparse block matrix.; """"""; if lower:; lower_band = 1 - self.n_rows; upper_band = 0; else:; lower_band = 0; upper_band = self.n_cols - 1. return self.sparsify_band(lower_band, upper_band, blocks_only). @typecheck_method(intervals=expr_tuple([expr_array(expr_int64), expr_array(expr_int64)]), blocks_only=bool); def _sparsify_row_intervals_expr(self, intervals, blocks_only=False):; return BlockMatrix(BlockMatrixSparsify(self._bmir, intervals._ir, RowIntervalSparsifier(blocks_only))). @typecheck_method(indices=expr_array(expr_int32)); def _sparsify_blocks(self, indices):; return BlockMatrix(BlockMatrixSparsify(self._bmir, indices._ir, PerBlockSparsifier())). [docs] @typecheck_method(; starts=oneof(sequenceof(int), np.ndarray), stops=oneof(sequenceof(int), np.ndarray), blocks_only=bool; ); def sparsify_row_intervals(self, starts, stops, blocks_only=False):; """"""Creates a block-sparse matrix by filterin",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:36875,Energy Efficiency,efficient,efficient,36875,"; [ 5., 6., 0., 0.],; [ 0., 0., 11., 12.],; [ 0., 0., 15., 16.]]). Notes; -----; This method creates a block-sparse matrix by zeroing out all blocks; which are disjoint from all row intervals. By default, all elements; outside the row intervals but inside blocks that overlap the row; intervals are set to zero as well. `starts` and `stops` must both have length equal to the number of; rows. The interval for row ``i`` is ``[starts[i], stops[i])``. In; particular, ``0 <= starts[i] <= stops[i] <= n_cols`` is required; for all ``i``. This method requires the number of rows to be less than :math:`2^{31}`. Parameters; ----------; starts: :obj:`list` of :obj:`int`, or :class:`numpy.ndarray` of :obj:`int`; Start indices for each row (inclusive).; stops: :obj:`list` of :obj:`int`, or :class:`numpy.ndarray` of :obj:`int`; Stop indices for each row (exclusive).; blocks_only: :obj:`bool`; If ``False``, set all elements outside row intervals to zero.; If ``True``, only set all blocks outside row intervals to blocks; of zeros; this is more efficient.; Returns; -------; :class:`.BlockMatrix`; Sparse block matrix.; """"""; if isinstance(starts, np.ndarray):; if starts.dtype not in (np.int32, np.int64):; raise ValueError(""sparsify_row_intervals: starts ndarray must have dtype 'int32' or 'int64'""); starts = [int(s) for s in starts]; if isinstance(stops, np.ndarray):; if stops.dtype not in (np.int32, np.int64):; raise ValueError(""sparsify_row_intervals: stops ndarray must have dtype 'int32' or 'int64'""); stops = [int(s) for s in stops]. n_rows = self.n_rows; n_cols = self.n_cols; if n_rows >= (1 << 31):; raise ValueError(f'n_rows must be less than 2^31, found {n_rows}'); if len(starts) != n_rows or len(stops) != n_rows:; raise ValueError(f'starts and stops must both have length {n_rows} (the number of rows)'); if any([start < 0 for start in starts]):; raise ValueError('all start values must be non-negative'); if any([stop > self.n_cols for stop in stops]):; raise ValueError(f'all stop valu",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:55708,Energy Efficiency,reduce,reduce,55708,"index; - **entries** (:py:class:`.tarray` of :py:data:`.tfloat64`) -- Entries for the row. Examples; --------; >>> import numpy as np; >>> block_matrix = BlockMatrix.from_numpy(np.array([[1, 2], [3, 4], [5, 6]]), 2); >>> t = block_matrix.to_table_row_major(); >>> t.show(); +---------+---------------------+; | row_idx | entries |; +---------+---------------------+; | int64 | array<float64> |; +---------+---------------------+; | 0 | [1.00e+00,2.00e+00] |; | 1 | [3.00e+00,4.00e+00] |; | 2 | [5.00e+00,6.00e+00] |; +---------+---------------------+. Parameters; ----------; n_partitions : int or None; Number of partitions of the table.; maximum_cache_memory_in_bytes : int or None; The amount of memory to reserve, per partition, to cache rows of the; matrix in memory. This value must be at least large enough to hold; one row of the matrix in memory. If this value is exactly the size of; one row, then a partition makes a network request for every row of; every block. Larger values reduce the number of network requests. If; memory permits, setting this value to the size of one output; partition permits one network request per block per partition. Notes; -----; Does not support block-sparse matrices. Returns; -------; :class:`.Table`; Table where each row corresponds to a row in the block matrix.; """"""; path = new_temp_file(); if maximum_cache_memory_in_bytes and maximum_cache_memory_in_bytes > (1 << 31) - 1:; raise ValueError(; f'maximum_cache_memory_in_bytes must be less than 2^31 -1, was: {maximum_cache_memory_in_bytes}'; ). self.write(path, overwrite=True, force_row_major=True); reader = TableFromBlockMatrixNativeReader(path, n_partitions, maximum_cache_memory_in_bytes); return Table(TableRead(reader)). [docs] @typecheck_method(n_partitions=nullable(int), maximum_cache_memory_in_bytes=nullable(int)); def to_matrix_table_row_major(self, n_partitions=None, maximum_cache_memory_in_bytes=None):; """"""Returns a matrix table with row key of `row_idx` and col key `col_idx`, whose; ",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:57213,Energy Efficiency,reduce,reduce,57213,": {maximum_cache_memory_in_bytes}'; ). self.write(path, overwrite=True, force_row_major=True); reader = TableFromBlockMatrixNativeReader(path, n_partitions, maximum_cache_memory_in_bytes); return Table(TableRead(reader)). [docs] @typecheck_method(n_partitions=nullable(int), maximum_cache_memory_in_bytes=nullable(int)); def to_matrix_table_row_major(self, n_partitions=None, maximum_cache_memory_in_bytes=None):; """"""Returns a matrix table with row key of `row_idx` and col key `col_idx`, whose; entries are structs of a single field `element`. Parameters; ----------; n_partitions : int or None; Number of partitions of the matrix table.; maximum_cache_memory_in_bytes : int or None; The amount of memory to reserve, per partition, to cache rows of the; matrix in memory. This value must be at least large enough to hold; one row of the matrix in memory. If this value is exactly the size of; one row, then a partition makes a network request for every row of; every block. Larger values reduce the number of network requests. If; memory permits, setting this value to the size of one output; partition permits one network request per block per partition. Notes; -----; Does not support block-sparse matrices. Returns; -------; :class:`.MatrixTable`; Matrix table where each entry corresponds to an entry in the block matrix.; """"""; t = self.to_table_row_major(n_partitions, maximum_cache_memory_in_bytes); t = t.transmute(entries=t.entries.map(lambda i: hl.struct(element=i))); t = t.annotate_globals(cols=hl.range(self.n_cols).map(lambda i: hl.struct(col_idx=hl.int64(i)))); return t._unlocalize_entries('entries', 'cols', ['col_idx']). [docs] @staticmethod; @typecheck(; path_in=str,; path_out=str,; delimiter=str,; header=nullable(str),; add_index=bool,; parallel=nullable(ExportType.checker),; partition_size=nullable(int),; entries=enumeration('full', 'lower', 'strict_lower', 'upper', 'strict_upper'),; ); def export(; path_in,; path_out,; delimiter='\t',; header=None,; add_index=False,; paral",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:60407,Energy Efficiency,efficient,efficient,60407,"k:: text. idx A B C; 0 1.0 0.8 0.7; 1 0.8 1.0 0.3. .. code-block:: text. idx A B C; 2 0.7 0.3 1.0. Warning; -------; The block matrix must be stored in row-major format, as results; from :meth:`.BlockMatrix.write` with ``force_row_major=True`` and from; :meth:`.BlockMatrix.write_from_entry_expr`. Otherwise,; :meth:`export` will fail. Notes; -----; The five options for `entries` are illustrated below. Full:. .. code-block:: text. 1.0 0.8 0.7; 0.8 1.0 0.3; 0.7 0.3 1.0. Lower triangle:. .. code-block:: text. 1.0; 0.8 1.0; 0.7 0.3 1.0. Strict lower triangle:. .. code-block:: text. 0.8; 0.7 0.3. Upper triangle:. .. code-block:: text. 1.0 0.8 0.7; 1.0 0.3; 1.0. Strict upper triangle:. .. code-block:: text. 0.8 0.7; 0.3. The number of columns must be less than :math:`2^{31}`. The number of partitions (file shards) exported equals the ceiling; of ``n_rows / partition_size``. By default, there is one partition; per row of blocks in the block matrix. The number of partitions; should be at least the number of cores for efficient parallelism.; Setting the partition size to an exact (rather than approximate); divisor or multiple of the block size reduces superfluous shuffling; of data. If `parallel` is ``None``, these file shards are then serially; concatenated by one core into one file, a slow process. See; other options below. It is highly recommended to export large files with a ``.bgz`` extension,; which will use a block gzipped compression codec. These files can be; read natively with Python's ``gzip.open`` and R's ``read.table``. Parameters; ----------; path_in: :class:`str`; Path to input block matrix, stored row-major on disk.; path_out: :class:`str`; Path for export.; Use extension ``.gz`` for gzip or ``.bgz`` for block gzip.; delimiter: :class:`str`; Column delimiter.; header: :class:`str`, optional; If provided, `header` is prepended before the first row of data.; add_index: :obj:`bool`; If ``True``, add an initial column with the absolute row index.; parallel: :class",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:60535,Energy Efficiency,reduce,reduces,60535,"he block matrix must be stored in row-major format, as results; from :meth:`.BlockMatrix.write` with ``force_row_major=True`` and from; :meth:`.BlockMatrix.write_from_entry_expr`. Otherwise,; :meth:`export` will fail. Notes; -----; The five options for `entries` are illustrated below. Full:. .. code-block:: text. 1.0 0.8 0.7; 0.8 1.0 0.3; 0.7 0.3 1.0. Lower triangle:. .. code-block:: text. 1.0; 0.8 1.0; 0.7 0.3 1.0. Strict lower triangle:. .. code-block:: text. 0.8; 0.7 0.3. Upper triangle:. .. code-block:: text. 1.0 0.8 0.7; 1.0 0.3; 1.0. Strict upper triangle:. .. code-block:: text. 0.8 0.7; 0.3. The number of columns must be less than :math:`2^{31}`. The number of partitions (file shards) exported equals the ceiling; of ``n_rows / partition_size``. By default, there is one partition; per row of blocks in the block matrix. The number of partitions; should be at least the number of cores for efficient parallelism.; Setting the partition size to an exact (rather than approximate); divisor or multiple of the block size reduces superfluous shuffling; of data. If `parallel` is ``None``, these file shards are then serially; concatenated by one core into one file, a slow process. See; other options below. It is highly recommended to export large files with a ``.bgz`` extension,; which will use a block gzipped compression codec. These files can be; read natively with Python's ``gzip.open`` and R's ``read.table``. Parameters; ----------; path_in: :class:`str`; Path to input block matrix, stored row-major on disk.; path_out: :class:`str`; Path for export.; Use extension ``.gz`` for gzip or ``.bgz`` for block gzip.; delimiter: :class:`str`; Column delimiter.; header: :class:`str`, optional; If provided, `header` is prepended before the first row of data.; add_index: :obj:`bool`; If ``True``, add an initial column with the absolute row index.; parallel: :class:`str`, optional; If ``'header_per_shard'``, create a folder with one file per; partition, each with a header if provid",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:72554,Energy Efficiency,reduce,reduced,72554,"-------; :class:`numpy.ndarray`; """""". def parse_rects(fname):; rect_idx_and_bounds = [int(i) for i in re.findall(r'\d+', fname)]; if len(rect_idx_and_bounds) != 5:; raise ValueError(f'Invalid rectangle file name: {fname}'); return rect_idx_and_bounds. rect_files = [file['path'] for file in hl.utils.hadoop_ls(path) if not re.match(r'.*\.crc', file['path'])]; rects = [parse_rects(os.path.basename(file_path)) for file_path in rect_files]. n_rows = max(rects, key=lambda r: r[2])[2]; n_cols = max(rects, key=lambda r: r[4])[4]. nd = np.zeros(shape=(n_rows, n_cols)); with with_local_temp_file() as f:; uri = local_path_uri(f); for rect, file_path in zip(rects, rect_files):; hl.utils.hadoop_copy(file_path, uri); if binary:; rect_data = np.reshape(np.fromfile(f), (rect[2] - rect[1], rect[4] - rect[3])); else:; rect_data = np.loadtxt(f, ndmin=2); nd[rect[1] : rect[2], rect[3] : rect[4]] = rect_data; return nd. [docs] @typecheck_method(compute_uv=bool, complexity_bound=int); def svd(self, compute_uv=True, complexity_bound=8192):; r""""""Computes the reduced singular value decomposition. Examples; --------. >>> x = BlockMatrix.from_numpy(np.array([[-2.0, 0.0, 3.0],; ... [-1.0, 2.0, 4.0]])); >>> x.svd(); (array([[-0.60219551, -0.79834865],; [-0.79834865, 0.60219551]]),; array([5.61784832, 1.56197958]),; array([[ 0.35649586, -0.28421866, -0.89001711],; [ 0.6366932 , 0.77106707, 0.00879404]])). Notes; -----; This method leverages distributed matrix multiplication to compute; reduced `singular value decomposition; <https://en.wikipedia.org/wiki/Singular-value_decomposition>`__ (SVD); for matrices that would otherwise be too large to work with locally,; provided that at least one dimension is less than or equal to 46300. Let :math:`X` be an :math:`n \times m` matrix and let; :math:`r = \min(n, m)`. In particular, :math:`X` can have at most; :math:`r` non-zero singular values. The reduced SVD of :math:`X`; has the form. .. math::. X = U \Sigma V^T. where. - :math:`U` is an :math:`n \time",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:72984,Energy Efficiency,reduce,reduced,72984,"ambda r: r[2])[2]; n_cols = max(rects, key=lambda r: r[4])[4]. nd = np.zeros(shape=(n_rows, n_cols)); with with_local_temp_file() as f:; uri = local_path_uri(f); for rect, file_path in zip(rects, rect_files):; hl.utils.hadoop_copy(file_path, uri); if binary:; rect_data = np.reshape(np.fromfile(f), (rect[2] - rect[1], rect[4] - rect[3])); else:; rect_data = np.loadtxt(f, ndmin=2); nd[rect[1] : rect[2], rect[3] : rect[4]] = rect_data; return nd. [docs] @typecheck_method(compute_uv=bool, complexity_bound=int); def svd(self, compute_uv=True, complexity_bound=8192):; r""""""Computes the reduced singular value decomposition. Examples; --------. >>> x = BlockMatrix.from_numpy(np.array([[-2.0, 0.0, 3.0],; ... [-1.0, 2.0, 4.0]])); >>> x.svd(); (array([[-0.60219551, -0.79834865],; [-0.79834865, 0.60219551]]),; array([5.61784832, 1.56197958]),; array([[ 0.35649586, -0.28421866, -0.89001711],; [ 0.6366932 , 0.77106707, 0.00879404]])). Notes; -----; This method leverages distributed matrix multiplication to compute; reduced `singular value decomposition; <https://en.wikipedia.org/wiki/Singular-value_decomposition>`__ (SVD); for matrices that would otherwise be too large to work with locally,; provided that at least one dimension is less than or equal to 46300. Let :math:`X` be an :math:`n \times m` matrix and let; :math:`r = \min(n, m)`. In particular, :math:`X` can have at most; :math:`r` non-zero singular values. The reduced SVD of :math:`X`; has the form. .. math::. X = U \Sigma V^T. where. - :math:`U` is an :math:`n \times r` matrix whose columns are; (orthonormal) left singular vectors,. - :math:`\Sigma` is an :math:`r \times r` diagonal matrix of non-negative; singular values in descending order,. - :math:`V^T` is an :math:`r \times m` matrix whose rows are; (orthonormal) right singular vectors. If the singular values in :math:`\Sigma` are distinct, then the; decomposition is unique up to multiplication of corresponding left and; right singular vectors by -1. The computationa",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:73395,Energy Efficiency,reduce,reduced,73395,"nd. [docs] @typecheck_method(compute_uv=bool, complexity_bound=int); def svd(self, compute_uv=True, complexity_bound=8192):; r""""""Computes the reduced singular value decomposition. Examples; --------. >>> x = BlockMatrix.from_numpy(np.array([[-2.0, 0.0, 3.0],; ... [-1.0, 2.0, 4.0]])); >>> x.svd(); (array([[-0.60219551, -0.79834865],; [-0.79834865, 0.60219551]]),; array([5.61784832, 1.56197958]),; array([[ 0.35649586, -0.28421866, -0.89001711],; [ 0.6366932 , 0.77106707, 0.00879404]])). Notes; -----; This method leverages distributed matrix multiplication to compute; reduced `singular value decomposition; <https://en.wikipedia.org/wiki/Singular-value_decomposition>`__ (SVD); for matrices that would otherwise be too large to work with locally,; provided that at least one dimension is less than or equal to 46300. Let :math:`X` be an :math:`n \times m` matrix and let; :math:`r = \min(n, m)`. In particular, :math:`X` can have at most; :math:`r` non-zero singular values. The reduced SVD of :math:`X`; has the form. .. math::. X = U \Sigma V^T. where. - :math:`U` is an :math:`n \times r` matrix whose columns are; (orthonormal) left singular vectors,. - :math:`\Sigma` is an :math:`r \times r` diagonal matrix of non-negative; singular values in descending order,. - :math:`V^T` is an :math:`r \times m` matrix whose rows are; (orthonormal) right singular vectors. If the singular values in :math:`\Sigma` are distinct, then the; decomposition is unique up to multiplication of corresponding left and; right singular vectors by -1. The computational complexity of SVD is; roughly :math:`nmr`. We now describe the implementation in more detail.; If :math:`\sqrt[3]{nmr}` is less than or equal to `complexity_bound`,; then :math:`X` is localized to an ndarray on which; :func:`scipy.linalg.svd` is called. In this case, all components are; returned as ndarrays. If :math:`\sqrt[3]{nmr}` is greater than `complexity_bound`, then the; reduced SVD is computed via the smaller gramian matrix of :ma",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:74351,Energy Efficiency,reduce,reduced,74351,"most; :math:`r` non-zero singular values. The reduced SVD of :math:`X`; has the form. .. math::. X = U \Sigma V^T. where. - :math:`U` is an :math:`n \times r` matrix whose columns are; (orthonormal) left singular vectors,. - :math:`\Sigma` is an :math:`r \times r` diagonal matrix of non-negative; singular values in descending order,. - :math:`V^T` is an :math:`r \times m` matrix whose rows are; (orthonormal) right singular vectors. If the singular values in :math:`\Sigma` are distinct, then the; decomposition is unique up to multiplication of corresponding left and; right singular vectors by -1. The computational complexity of SVD is; roughly :math:`nmr`. We now describe the implementation in more detail.; If :math:`\sqrt[3]{nmr}` is less than or equal to `complexity_bound`,; then :math:`X` is localized to an ndarray on which; :func:`scipy.linalg.svd` is called. In this case, all components are; returned as ndarrays. If :math:`\sqrt[3]{nmr}` is greater than `complexity_bound`, then the; reduced SVD is computed via the smaller gramian matrix of :math:`X`. For; :math:`n > m`, the three stages are:. 1. Compute (and localize) the gramian matrix :math:`X^T X`,. 2. Compute the eigenvalues and right singular vectors via the; symmetric eigendecomposition :math:`X^T X = V S V^T` with; :func:`numpy.linalg.eigh` or :func:`scipy.linalg.eigh`,. 3. Compute the singular values as :math:`\Sigma = S^\frac{1}{2}` and the; the left singular vectors as the block matrix; :math:`U = X V \Sigma^{-1}`. In this case, since block matrix multiplication is lazy, it is efficient; to subsequently slice :math:`U` (e.g. based on the singular values), or; discard :math:`U` entirely. If :math:`n \leq m`, the three stages instead use the gramian; :math:`X X^T = U S U^T` and return :math:`V^T` as the; block matrix :math:`\Sigma^{-1} U^T X`. Warning; -------; Computing reduced SVD via the gramian presents an added wrinkle when; :math:`X` is not full rank, as the block-matrix-side null-basis is not; com",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:74916,Energy Efficiency,efficient,efficient,74916,"ding left and; right singular vectors by -1. The computational complexity of SVD is; roughly :math:`nmr`. We now describe the implementation in more detail.; If :math:`\sqrt[3]{nmr}` is less than or equal to `complexity_bound`,; then :math:`X` is localized to an ndarray on which; :func:`scipy.linalg.svd` is called. In this case, all components are; returned as ndarrays. If :math:`\sqrt[3]{nmr}` is greater than `complexity_bound`, then the; reduced SVD is computed via the smaller gramian matrix of :math:`X`. For; :math:`n > m`, the three stages are:. 1. Compute (and localize) the gramian matrix :math:`X^T X`,. 2. Compute the eigenvalues and right singular vectors via the; symmetric eigendecomposition :math:`X^T X = V S V^T` with; :func:`numpy.linalg.eigh` or :func:`scipy.linalg.eigh`,. 3. Compute the singular values as :math:`\Sigma = S^\frac{1}{2}` and the; the left singular vectors as the block matrix; :math:`U = X V \Sigma^{-1}`. In this case, since block matrix multiplication is lazy, it is efficient; to subsequently slice :math:`U` (e.g. based on the singular values), or; discard :math:`U` entirely. If :math:`n \leq m`, the three stages instead use the gramian; :math:`X X^T = U S U^T` and return :math:`V^T` as the; block matrix :math:`\Sigma^{-1} U^T X`. Warning; -------; Computing reduced SVD via the gramian presents an added wrinkle when; :math:`X` is not full rank, as the block-matrix-side null-basis is not; computable by the formula in the third stage. Furthermore, due to finite; precision, the zero eigenvalues of :math:`X^T X` or :math:`X X^T` will; only be approximately zero. If the rank is not known ahead, examining the relative sizes of the; trailing singular values should reveal where the spectrum switches from; non-zero to ""zero"" eigenvalues. With 64-bit floating point, zero; eigenvalues are typically about 1e-16 times the largest eigenvalue.; The corresponding singular vectors should be sliced away **before** an; action which realizes the block-matrix",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:75214,Energy Efficiency,reduce,reduced,75214,":`\sqrt[3]{nmr}` is greater than `complexity_bound`, then the; reduced SVD is computed via the smaller gramian matrix of :math:`X`. For; :math:`n > m`, the three stages are:. 1. Compute (and localize) the gramian matrix :math:`X^T X`,. 2. Compute the eigenvalues and right singular vectors via the; symmetric eigendecomposition :math:`X^T X = V S V^T` with; :func:`numpy.linalg.eigh` or :func:`scipy.linalg.eigh`,. 3. Compute the singular values as :math:`\Sigma = S^\frac{1}{2}` and the; the left singular vectors as the block matrix; :math:`U = X V \Sigma^{-1}`. In this case, since block matrix multiplication is lazy, it is efficient; to subsequently slice :math:`U` (e.g. based on the singular values), or; discard :math:`U` entirely. If :math:`n \leq m`, the three stages instead use the gramian; :math:`X X^T = U S U^T` and return :math:`V^T` as the; block matrix :math:`\Sigma^{-1} U^T X`. Warning; -------; Computing reduced SVD via the gramian presents an added wrinkle when; :math:`X` is not full rank, as the block-matrix-side null-basis is not; computable by the formula in the third stage. Furthermore, due to finite; precision, the zero eigenvalues of :math:`X^T X` or :math:`X X^T` will; only be approximately zero. If the rank is not known ahead, examining the relative sizes of the; trailing singular values should reveal where the spectrum switches from; non-zero to ""zero"" eigenvalues. With 64-bit floating point, zero; eigenvalues are typically about 1e-16 times the largest eigenvalue.; The corresponding singular vectors should be sliced away **before** an; action which realizes the block-matrix-side singular vectors. :meth:`svd` sets the singular values corresponding to negative; eigenvalues to exactly ``0.0``. Warning; -------; The first and third stages invoke distributed matrix multiplication with; parallelism bounded by the number of resulting blocks, whereas the; second stage is executed on the leader (master) node. For matrices of; large minimum dimension, it ma",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:4650,Integrability,depend,dependency,4650,". One-dimensional ndarrays; of shape ``(n)`` are promoted to two-dimensional ndarrays of shape ``(1,; n)``, i.e. a single row. Block matrices support broadcasting of ``+``, ``-``, ``*``, and ``/``; between matrices of different shapes, consistent with the NumPy; `broadcasting rules; <https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html>`__.; There is one exception: block matrices do not currently support element-wise; ""outer product"" of a single row and a single column, although the same; effect can be achieved for ``*`` by using ``@``. Warning; -------. For binary operations, if the first operand is an ndarray and the; second operand is a block matrix, the result will be a ndarray of block; matrices. To achieve the desired behavior for ``+`` and ``*``, place the; block matrix operand first; for ``-``, ``/``, and ``@``, first convert; the ndarray to a block matrix using :meth:`.from_numpy`. Warning; -------. Block matrix multiplication requires special care due to each block; of each operand being a dependency of multiple blocks in the product. The :math:`(i, j)`-block in the product ``a @ b`` is computed by summing; the products of corresponding blocks in block row :math:`i` of ``a`` and; block column :math:`j` of ``b``. So overall, in addition to this; multiplication and addition, the evaluation of ``a @ b`` realizes each; block of ``a`` as many times as the number of block columns of ``b``; and realizes each block of ``b`` as many times as the number of; block rows of ``a``. This becomes a performance and resilience issue whenever ``a`` or ``b``; is defined in terms of pending transformations (such as linear; algebra operations). For example, evaluating ``a @ (c @ d)`` will; effectively evaluate ``c @ d`` as many times as the number of block rows; in ``a``. To limit re-computation, write or cache transformed block matrix; operands before feeding them into matrix multiplication:. >>> c = BlockMatrix.read('c.bm') # doctest: +SKIP; >>> d = BlockMatrix.read(",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:8146,Integrability,depend,depend,8146,"cists often want to compute and manipulate a; banded correlation matrix capturing ""linkage disequilibrium"" between nearby; variants along the genome. In this case, working with the full correlation; matrix for tens of millions of variants would be prohibitively expensive,; and in any case, entries far from the diagonal are either not of interest or; ought to be zeroed out before downstream linear algebra. To enable such computations, block matrices do not require that all blocks; be realized explicitly. Implicit (dropped) blocks behave as blocks of; zeroes, so we refer to a block matrix in which at least one block is; implicitly zero as a **block-sparse matrix**. Otherwise, we say the matrix; is block-dense. The property :meth:`is_sparse` encodes this state. Dropped blocks are not stored in memory or on :meth:`write`. In fact,; blocks that are dropped prior to an action like :meth:`export` or; :meth:`to_numpy` are never computed in the first place, nor are any blocks; of upstream operands on which only dropped blocks depend! In addition,; linear algebra is accelerated by avoiding, for example, explicit addition of; or multiplication by blocks of zeroes. Block-sparse matrices may be created with; :meth:`sparsify_band`,; :meth:`sparsify_rectangles`,; :meth:`sparsify_row_intervals`,; and :meth:`sparsify_triangle`. The following methods naturally propagate block-sparsity:. - Addition and subtraction ""union"" realized blocks. - Element-wise multiplication ""intersects"" realized blocks. - Transpose ""transposes"" realized blocks. - :meth:`abs` and :meth:`sqrt` preserve the realized blocks. - :meth:`sum` along an axis realizes those blocks for which at least one; block summand is realized. - Matrix slicing, and more generally :meth:`filter`, :meth:`filter_rows`,; and :meth:`filter_cols`. These following methods always result in a block-dense matrix:. - :meth:`fill`. - Addition or subtraction of a scalar or broadcasted vector. - Matrix multiplication, ``@``. The following metho",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:76373,Integrability,depend,depends,76373,"finite; precision, the zero eigenvalues of :math:`X^T X` or :math:`X X^T` will; only be approximately zero. If the rank is not known ahead, examining the relative sizes of the; trailing singular values should reveal where the spectrum switches from; non-zero to ""zero"" eigenvalues. With 64-bit floating point, zero; eigenvalues are typically about 1e-16 times the largest eigenvalue.; The corresponding singular vectors should be sliced away **before** an; action which realizes the block-matrix-side singular vectors. :meth:`svd` sets the singular values corresponding to negative; eigenvalues to exactly ``0.0``. Warning; -------; The first and third stages invoke distributed matrix multiplication with; parallelism bounded by the number of resulting blocks, whereas the; second stage is executed on the leader (master) node. For matrices of; large minimum dimension, it may be preferable to run these stages; separately. The performance of the second stage depends critically on the number of; leader (master) cores and the NumPy / SciPy configuration, viewable with; ``np.show_config()``. For Intel machines, we recommend installing the; `MKL <https://anaconda.org/anaconda/mkl>`__ package for Anaconda. Consequently, the optimal value of `complexity_bound` is highly; configuration-dependent. Parameters; ----------; compute_uv: :obj:`bool`; If False, only compute the singular values (or eigenvalues).; complexity_bound: :obj:`int`; Maximum value of :math:`\sqrt[3]{nmr}` for which; :func:`scipy.linalg.svd` is used. Returns; -------; u: :class:`numpy.ndarray` or :class:`BlockMatrix`; Left singular vectors :math:`U`, as a block matrix if :math:`n > m` and; :math:`\sqrt[3]{nmr}` exceeds `complexity_bound`.; Only returned if `compute_uv` is True.; s: :class:`numpy.ndarray`; Singular values from :math:`\Sigma` in descending order.; vt: :class:`numpy.ndarray` or :class:`BlockMatrix`; Right singular vectors :math:`V^T``, as a block matrix if :math:`n \leq m` and; :math:`\sqrt[3]{nmr}` excee",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:76700,Integrability,depend,dependent,76700,"-zero to ""zero"" eigenvalues. With 64-bit floating point, zero; eigenvalues are typically about 1e-16 times the largest eigenvalue.; The corresponding singular vectors should be sliced away **before** an; action which realizes the block-matrix-side singular vectors. :meth:`svd` sets the singular values corresponding to negative; eigenvalues to exactly ``0.0``. Warning; -------; The first and third stages invoke distributed matrix multiplication with; parallelism bounded by the number of resulting blocks, whereas the; second stage is executed on the leader (master) node. For matrices of; large minimum dimension, it may be preferable to run these stages; separately. The performance of the second stage depends critically on the number of; leader (master) cores and the NumPy / SciPy configuration, viewable with; ``np.show_config()``. For Intel machines, we recommend installing the; `MKL <https://anaconda.org/anaconda/mkl>`__ package for Anaconda. Consequently, the optimal value of `complexity_bound` is highly; configuration-dependent. Parameters; ----------; compute_uv: :obj:`bool`; If False, only compute the singular values (or eigenvalues).; complexity_bound: :obj:`int`; Maximum value of :math:`\sqrt[3]{nmr}` for which; :func:`scipy.linalg.svd` is used. Returns; -------; u: :class:`numpy.ndarray` or :class:`BlockMatrix`; Left singular vectors :math:`U`, as a block matrix if :math:`n > m` and; :math:`\sqrt[3]{nmr}` exceeds `complexity_bound`.; Only returned if `compute_uv` is True.; s: :class:`numpy.ndarray`; Singular values from :math:`\Sigma` in descending order.; vt: :class:`numpy.ndarray` or :class:`BlockMatrix`; Right singular vectors :math:`V^T``, as a block matrix if :math:`n \leq m` and; :math:`\sqrt[3]{nmr}` exceeds `complexity_bound`.; Only returned if `compute_uv` is True.; """"""; n, m = self.shape. if n * m * min(n, m) <= complexity_bound**3:; return _svd(self.to_numpy(), full_matrices=False, compute_uv=compute_uv, overwrite_a=True); else:; return self._svd_gr",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:76454,Modifiability,config,configuration,76454,"finite; precision, the zero eigenvalues of :math:`X^T X` or :math:`X X^T` will; only be approximately zero. If the rank is not known ahead, examining the relative sizes of the; trailing singular values should reveal where the spectrum switches from; non-zero to ""zero"" eigenvalues. With 64-bit floating point, zero; eigenvalues are typically about 1e-16 times the largest eigenvalue.; The corresponding singular vectors should be sliced away **before** an; action which realizes the block-matrix-side singular vectors. :meth:`svd` sets the singular values corresponding to negative; eigenvalues to exactly ``0.0``. Warning; -------; The first and third stages invoke distributed matrix multiplication with; parallelism bounded by the number of resulting blocks, whereas the; second stage is executed on the leader (master) node. For matrices of; large minimum dimension, it may be preferable to run these stages; separately. The performance of the second stage depends critically on the number of; leader (master) cores and the NumPy / SciPy configuration, viewable with; ``np.show_config()``. For Intel machines, we recommend installing the; `MKL <https://anaconda.org/anaconda/mkl>`__ package for Anaconda. Consequently, the optimal value of `complexity_bound` is highly; configuration-dependent. Parameters; ----------; compute_uv: :obj:`bool`; If False, only compute the singular values (or eigenvalues).; complexity_bound: :obj:`int`; Maximum value of :math:`\sqrt[3]{nmr}` for which; :func:`scipy.linalg.svd` is used. Returns; -------; u: :class:`numpy.ndarray` or :class:`BlockMatrix`; Left singular vectors :math:`U`, as a block matrix if :math:`n > m` and; :math:`\sqrt[3]{nmr}` exceeds `complexity_bound`.; Only returned if `compute_uv` is True.; s: :class:`numpy.ndarray`; Singular values from :math:`\Sigma` in descending order.; vt: :class:`numpy.ndarray` or :class:`BlockMatrix`; Right singular vectors :math:`V^T``, as a block matrix if :math:`n \leq m` and; :math:`\sqrt[3]{nmr}` excee",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:76686,Modifiability,config,configuration-dependent,76686,"-zero to ""zero"" eigenvalues. With 64-bit floating point, zero; eigenvalues are typically about 1e-16 times the largest eigenvalue.; The corresponding singular vectors should be sliced away **before** an; action which realizes the block-matrix-side singular vectors. :meth:`svd` sets the singular values corresponding to negative; eigenvalues to exactly ``0.0``. Warning; -------; The first and third stages invoke distributed matrix multiplication with; parallelism bounded by the number of resulting blocks, whereas the; second stage is executed on the leader (master) node. For matrices of; large minimum dimension, it may be preferable to run these stages; separately. The performance of the second stage depends critically on the number of; leader (master) cores and the NumPy / SciPy configuration, viewable with; ``np.show_config()``. For Intel machines, we recommend installing the; `MKL <https://anaconda.org/anaconda/mkl>`__ package for Anaconda. Consequently, the optimal value of `complexity_bound` is highly; configuration-dependent. Parameters; ----------; compute_uv: :obj:`bool`; If False, only compute the singular values (or eigenvalues).; complexity_bound: :obj:`int`; Maximum value of :math:`\sqrt[3]{nmr}` for which; :func:`scipy.linalg.svd` is used. Returns; -------; u: :class:`numpy.ndarray` or :class:`BlockMatrix`; Left singular vectors :math:`U`, as a block matrix if :math:`n > m` and; :math:`\sqrt[3]{nmr}` exceeds `complexity_bound`.; Only returned if `compute_uv` is True.; s: :class:`numpy.ndarray`; Singular values from :math:`\Sigma` in descending order.; vt: :class:`numpy.ndarray` or :class:`BlockMatrix`; Right singular vectors :math:`V^T``, as a block matrix if :math:`n \leq m` and; :math:`\sqrt[3]{nmr}` exceeds `complexity_bound`.; Only returned if `compute_uv` is True.; """"""; n, m = self.shape. if n * m * min(n, m) <= complexity_bound**3:; return _svd(self.to_numpy(), full_matrices=False, compute_uv=compute_uv, overwrite_a=True); else:; return self._svd_gr",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:5153,Performance,perform,performance,5153,"s, if the first operand is an ndarray and the; second operand is a block matrix, the result will be a ndarray of block; matrices. To achieve the desired behavior for ``+`` and ``*``, place the; block matrix operand first; for ``-``, ``/``, and ``@``, first convert; the ndarray to a block matrix using :meth:`.from_numpy`. Warning; -------. Block matrix multiplication requires special care due to each block; of each operand being a dependency of multiple blocks in the product. The :math:`(i, j)`-block in the product ``a @ b`` is computed by summing; the products of corresponding blocks in block row :math:`i` of ``a`` and; block column :math:`j` of ``b``. So overall, in addition to this; multiplication and addition, the evaluation of ``a @ b`` realizes each; block of ``a`` as many times as the number of block columns of ``b``; and realizes each block of ``b`` as many times as the number of; block rows of ``a``. This becomes a performance and resilience issue whenever ``a`` or ``b``; is defined in terms of pending transformations (such as linear; algebra operations). For example, evaluating ``a @ (c @ d)`` will; effectively evaluate ``c @ d`` as many times as the number of block rows; in ``a``. To limit re-computation, write or cache transformed block matrix; operands before feeding them into matrix multiplication:. >>> c = BlockMatrix.read('c.bm') # doctest: +SKIP; >>> d = BlockMatrix.read('d.bm') # doctest: +SKIP; >>> (c @ d).write('cd.bm') # doctest: +SKIP; >>> a = BlockMatrix.read('a.bm') # doctest: +SKIP; >>> e = a @ BlockMatrix.read('cd.bm') # doctest: +SKIP. **Indexing and slicing**. Block matrices also support NumPy-style 2-dimensional; `indexing and slicing <https://docs.scipy.org/doc/numpy/user/basics.indexing.html>`__,; with two differences.; First, slices ``start:stop:step`` must be non-empty with positive ``step``.; Second, even if only one index is a slice, the resulting block matrix is still; 2-dimensional. For example, for a block matrix ``bm`` with 10 r",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:5460,Performance,cache,cache,5460,"darray to a block matrix using :meth:`.from_numpy`. Warning; -------. Block matrix multiplication requires special care due to each block; of each operand being a dependency of multiple blocks in the product. The :math:`(i, j)`-block in the product ``a @ b`` is computed by summing; the products of corresponding blocks in block row :math:`i` of ``a`` and; block column :math:`j` of ``b``. So overall, in addition to this; multiplication and addition, the evaluation of ``a @ b`` realizes each; block of ``a`` as many times as the number of block columns of ``b``; and realizes each block of ``b`` as many times as the number of; block rows of ``a``. This becomes a performance and resilience issue whenever ``a`` or ``b``; is defined in terms of pending transformations (such as linear; algebra operations). For example, evaluating ``a @ (c @ d)`` will; effectively evaluate ``c @ d`` as many times as the number of block rows; in ``a``. To limit re-computation, write or cache transformed block matrix; operands before feeding them into matrix multiplication:. >>> c = BlockMatrix.read('c.bm') # doctest: +SKIP; >>> d = BlockMatrix.read('d.bm') # doctest: +SKIP; >>> (c @ d).write('cd.bm') # doctest: +SKIP; >>> a = BlockMatrix.read('a.bm') # doctest: +SKIP; >>> e = a @ BlockMatrix.read('cd.bm') # doctest: +SKIP. **Indexing and slicing**. Block matrices also support NumPy-style 2-dimensional; `indexing and slicing <https://docs.scipy.org/doc/numpy/user/basics.indexing.html>`__,; with two differences.; First, slices ``start:stop:step`` must be non-empty with positive ``step``.; Second, even if only one index is a slice, the resulting block matrix is still; 2-dimensional. For example, for a block matrix ``bm`` with 10 rows and 10 columns:. - ``bm[0, 0]`` is the element in row 0 and column 0 of ``bm``. - ``bm[0:1, 0]`` is a block matrix with 1 row, 1 column,; and element ``bm[0, 0]``. - ``bm[2, :]`` is a block matrix with 1 row, 10 columns,; and elements from row 2 of ``bm``. - ``bm[:3,",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:11121,Performance,load,load,11121,"i, n_rows, n_cols, block_size=None, *, _assert_type=None):; """"""Creates a block matrix from a binary file. Examples; --------; >>> import numpy as np; >>> a = np.random.rand(10, 20); >>> a.tofile('/local/file') # doctest: +SKIP. To create a block matrix of the same dimensions:. >>> bm = BlockMatrix.fromfile('file:///local/file', 10, 20) # doctest: +SKIP. Notes; -----; This method, analogous to `numpy.fromfile; <https://docs.scipy.org/doc/numpy/reference/generated/numpy.fromfile.html>`__,; reads a binary file of float64 values in row-major order, such as that; produced by `numpy.tofile; <https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.tofile.html>`__; or :meth:`BlockMatrix.tofile`. Binary files produced and consumed by :meth:`.tofile` and; :meth:`.fromfile` are not platform independent, so should only be used; for inter-operating with NumPy, not storage. Use; :meth:`BlockMatrix.write` and :meth:`BlockMatrix.read` to save and load; block matrices, since these methods write and read blocks in parallel; and are platform independent. A NumPy ndarray must have type float64 for the output of; func:`numpy.tofile` to be a valid binary input to :meth:`.fromfile`.; This is not checked. The number of entries must be less than :math:`2^{31}`. Parameters; ----------; uri: :class:`str`, optional; URI of binary input file.; n_rows: :obj:`int`; Number of rows.; n_cols: :obj:`int`; Number of columns.; block_size: :obj:`int`, optional; Block size. Default given by :meth:`default_block_size`. See Also; --------; :meth:`.from_numpy`; """""". if not block_size:; block_size = BlockMatrix.default_block_size(). return cls(; BlockMatrixRead(BlockMatrixBinaryReader(uri, [n_rows, n_cols], block_size), _assert_type=_assert_type); ). [docs] @classmethod; @typecheck_method(ndarray=np.ndarray, block_size=nullable(int)); def from_numpy(cls, ndarray, block_size=None):; """"""Distributes a `NumPy ndarray; <https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html>`__; as a b",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:14308,Performance,perform,performance,14308,", n_rows, n_cols, block_size). [docs] @classmethod; @typecheck_method(; entry_expr=expr_float64,; mean_impute=bool,; center=bool,; normalize=bool,; axis=nullable(enumeration('rows', 'cols')),; block_size=nullable(int),; ); def from_entry_expr(; cls, entry_expr, mean_impute=False, center=False, normalize=False, axis='rows', block_size=None; ):; """"""Creates a block matrix using a matrix table entry expression. Examples; --------; >>> mt = hl.balding_nichols_model(3, 25, 50); >>> bm = BlockMatrix.from_entry_expr(mt.GT.n_alt_alleles()). Notes; -----; This convenience method writes the block matrix to a temporary file on; persistent disk and then reads the file. If you want to store the; resulting block matrix, use :meth:`write_from_entry_expr` directly to; avoid writing the result twice. See :meth:`write_from_entry_expr` for; further documentation. Warning; -------; If the rows of the matrix table have been filtered to a small fraction,; then :meth:`.MatrixTable.repartition` before this method to improve; performance. If you encounter a Hadoop write/replication error, increase the; number of persistent workers or the disk size per persistent worker,; or use :meth:`write_from_entry_expr` to write to external storage. This method opens ``n_cols / block_size`` files concurrently per task.; To not blow out memory when the number of columns is very large,; limit the Hadoop write buffer size; e.g. on GCP, set this property on; cluster startup (the default is 64MB):; ``--properties 'core:fs.gs.io.buffersize.write=1048576``. Parameters; ----------; entry_expr: :class:`.Float64Expression`; Entry expression for numeric matrix entries.; mean_impute: :obj:`bool`; If true, set missing values to the row mean before centering or; normalizing. If false, missing values will raise an error.; center: :obj:`bool`; If true, subtract the row mean.; normalize: :obj:`bool`; If true and ``center=False``, divide by the row magnitude.; If true and ``center=True``, divide the centered value by the;",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:14571,Performance,concurren,concurrently,14571,"n_impute=False, center=False, normalize=False, axis='rows', block_size=None; ):; """"""Creates a block matrix using a matrix table entry expression. Examples; --------; >>> mt = hl.balding_nichols_model(3, 25, 50); >>> bm = BlockMatrix.from_entry_expr(mt.GT.n_alt_alleles()). Notes; -----; This convenience method writes the block matrix to a temporary file on; persistent disk and then reads the file. If you want to store the; resulting block matrix, use :meth:`write_from_entry_expr` directly to; avoid writing the result twice. See :meth:`write_from_entry_expr` for; further documentation. Warning; -------; If the rows of the matrix table have been filtered to a small fraction,; then :meth:`.MatrixTable.repartition` before this method to improve; performance. If you encounter a Hadoop write/replication error, increase the; number of persistent workers or the disk size per persistent worker,; or use :meth:`write_from_entry_expr` to write to external storage. This method opens ``n_cols / block_size`` files concurrently per task.; To not blow out memory when the number of columns is very large,; limit the Hadoop write buffer size; e.g. on GCP, set this property on; cluster startup (the default is 64MB):; ``--properties 'core:fs.gs.io.buffersize.write=1048576``. Parameters; ----------; entry_expr: :class:`.Float64Expression`; Entry expression for numeric matrix entries.; mean_impute: :obj:`bool`; If true, set missing values to the row mean before centering or; normalizing. If false, missing values will raise an error.; center: :obj:`bool`; If true, subtract the row mean.; normalize: :obj:`bool`; If true and ``center=False``, divide by the row magnitude.; If true and ``center=True``, divide the centered value by the; centered row magnitude.; axis: :class:`str`; One of ""rows"" or ""cols"": axis by which to normalize or center.; block_size: :obj:`int`, optional; Block size. Default given by :meth:`.BlockMatrix.default_block_size`.; """"""; path = new_temp_file(); cls.write_from_entry_e",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:22343,Performance,load,loaded,22343,"re checkpointing.; If ``False``, checkpoint blocks in their current format.; stage_locally: :obj:`bool`; If ``True``, major output will be written to temporary local storage; before being copied to ``output``.; """"""; hl.current_backend().validate_file(path); self.write(path, overwrite, force_row_major, stage_locally); return BlockMatrix.read(path, _assert_type=self._bmir._type). [docs] @staticmethod; @typecheck(; entry_expr=expr_float64,; path=str,; overwrite=bool,; mean_impute=bool,; center=bool,; normalize=bool,; axis=nullable(enumeration('rows', 'cols')),; block_size=nullable(int),; ); def write_from_entry_expr(; entry_expr,; path,; overwrite=False,; mean_impute=False,; center=False,; normalize=False,; axis='rows',; block_size=None,; ):; """"""Writes a block matrix from a matrix table entry expression. Examples; --------; >>> mt = hl.balding_nichols_model(3, 25, 50); >>> BlockMatrix.write_from_entry_expr(mt.GT.n_alt_alleles(),; ... 'output/model.bm'). Notes; -----; The resulting file can be loaded with :meth:`BlockMatrix.read`.; Blocks are stored row-major. If a pipelined transformation significantly downsamples the rows of the; underlying matrix table, then repartitioning the matrix table ahead of; this method will greatly improve its performance. By default, this method will fail if any values are missing (to be clear,; special float values like ``nan`` are not missing values). - Set `mean_impute` to replace missing values with the row mean before; possibly centering or normalizing. If all values are missing, the row; mean is ``nan``. - Set `center` to shift each row to have mean zero before possibly; normalizing. - Set `normalize` to normalize each row to have unit length. To standardize each row, regarded as an empirical distribution, to have; mean 0 and variance 1, set `center` and `normalize` and then multiply; the result by ``sqrt(n_cols)``. Warning; -------; If the rows of the matrix table have been filtered to a small fraction,; then :meth:`.MatrixTable.repa",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:22593,Performance,perform,performance,22593,"rage; before being copied to ``output``.; """"""; hl.current_backend().validate_file(path); self.write(path, overwrite, force_row_major, stage_locally); return BlockMatrix.read(path, _assert_type=self._bmir._type). [docs] @staticmethod; @typecheck(; entry_expr=expr_float64,; path=str,; overwrite=bool,; mean_impute=bool,; center=bool,; normalize=bool,; axis=nullable(enumeration('rows', 'cols')),; block_size=nullable(int),; ); def write_from_entry_expr(; entry_expr,; path,; overwrite=False,; mean_impute=False,; center=False,; normalize=False,; axis='rows',; block_size=None,; ):; """"""Writes a block matrix from a matrix table entry expression. Examples; --------; >>> mt = hl.balding_nichols_model(3, 25, 50); >>> BlockMatrix.write_from_entry_expr(mt.GT.n_alt_alleles(),; ... 'output/model.bm'). Notes; -----; The resulting file can be loaded with :meth:`BlockMatrix.read`.; Blocks are stored row-major. If a pipelined transformation significantly downsamples the rows of the; underlying matrix table, then repartitioning the matrix table ahead of; this method will greatly improve its performance. By default, this method will fail if any values are missing (to be clear,; special float values like ``nan`` are not missing values). - Set `mean_impute` to replace missing values with the row mean before; possibly centering or normalizing. If all values are missing, the row; mean is ``nan``. - Set `center` to shift each row to have mean zero before possibly; normalizing. - Set `normalize` to normalize each row to have unit length. To standardize each row, regarded as an empirical distribution, to have; mean 0 and variance 1, set `center` and `normalize` and then multiply; the result by ``sqrt(n_cols)``. Warning; -------; If the rows of the matrix table have been filtered to a small fraction,; then :meth:`.MatrixTable.repartition` before this method to improve; performance. This method opens ``n_cols / block_size`` files concurrently per task.; To not blow out memory when the number of col",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:23378,Performance,perform,performance,23378,"BlockMatrix.read`.; Blocks are stored row-major. If a pipelined transformation significantly downsamples the rows of the; underlying matrix table, then repartitioning the matrix table ahead of; this method will greatly improve its performance. By default, this method will fail if any values are missing (to be clear,; special float values like ``nan`` are not missing values). - Set `mean_impute` to replace missing values with the row mean before; possibly centering or normalizing. If all values are missing, the row; mean is ``nan``. - Set `center` to shift each row to have mean zero before possibly; normalizing. - Set `normalize` to normalize each row to have unit length. To standardize each row, regarded as an empirical distribution, to have; mean 0 and variance 1, set `center` and `normalize` and then multiply; the result by ``sqrt(n_cols)``. Warning; -------; If the rows of the matrix table have been filtered to a small fraction,; then :meth:`.MatrixTable.repartition` before this method to improve; performance. This method opens ``n_cols / block_size`` files concurrently per task.; To not blow out memory when the number of columns is very large,; limit the Hadoop write buffer size; e.g. on GCP, set this property on; cluster startup (the default is 64MB):; ``--properties 'core:fs.gs.io.buffersize.write=1048576``. Parameters; ----------; entry_expr: :class:`.Float64Expression`; Entry expression for numeric matrix entries.; path: :class:`str`; Path for output.; overwrite : :obj:`bool`; If ``True``, overwrite an existing file at the destination.; mean_impute: :obj:`bool`; If true, set missing values to the row mean before centering or; normalizing. If false, missing values will raise an error.; center: :obj:`bool`; If true, subtract the row mean.; normalize: :obj:`bool`; If true and ``center=False``, divide by the row magnitude.; If true and ``center=True``, divide the centered value by the; centered row magnitude.; axis: :class:`str`; One of ""rows"" or ""cols"": axis by",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:23439,Performance,concurren,concurrently,23439," transformation significantly downsamples the rows of the; underlying matrix table, then repartitioning the matrix table ahead of; this method will greatly improve its performance. By default, this method will fail if any values are missing (to be clear,; special float values like ``nan`` are not missing values). - Set `mean_impute` to replace missing values with the row mean before; possibly centering or normalizing. If all values are missing, the row; mean is ``nan``. - Set `center` to shift each row to have mean zero before possibly; normalizing. - Set `normalize` to normalize each row to have unit length. To standardize each row, regarded as an empirical distribution, to have; mean 0 and variance 1, set `center` and `normalize` and then multiply; the result by ``sqrt(n_cols)``. Warning; -------; If the rows of the matrix table have been filtered to a small fraction,; then :meth:`.MatrixTable.repartition` before this method to improve; performance. This method opens ``n_cols / block_size`` files concurrently per task.; To not blow out memory when the number of columns is very large,; limit the Hadoop write buffer size; e.g. on GCP, set this property on; cluster startup (the default is 64MB):; ``--properties 'core:fs.gs.io.buffersize.write=1048576``. Parameters; ----------; entry_expr: :class:`.Float64Expression`; Entry expression for numeric matrix entries.; path: :class:`str`; Path for output.; overwrite : :obj:`bool`; If ``True``, overwrite an existing file at the destination.; mean_impute: :obj:`bool`; If true, set missing values to the row mean before centering or; normalizing. If false, missing values will raise an error.; center: :obj:`bool`; If true, subtract the row mean.; normalize: :obj:`bool`; If true and ``center=False``, divide by the row magnitude.; If true and ``center=True``, divide the centered value by the; centered row magnitude.; axis: :class:`str`; One of ""rows"" or ""cols"": axis by which to normalize or center.; block_size: :obj:`int`, optional",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:39142,Performance,load,load,39142,"ri):; """"""Collects and writes data to a binary file. Examples; --------; >>> import numpy as np; >>> bm = BlockMatrix.random(10, 20); >>> bm.tofile('file:///local/file') # doctest: +SKIP. To create a :class:`numpy.ndarray` of the same dimensions:. >>> a = np.fromfile('/local/file').reshape((10, 20)) # doctest: +SKIP. Notes; -----; This method, analogous to `numpy.tofile; <https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.tofile.html>`__,; produces a binary file of float64 values in row-major order, which can; be read by functions such as `numpy.fromfile; <https://docs.scipy.org/doc/numpy/reference/generated/numpy.fromfile.html>`__; (if a local file) and :meth:`BlockMatrix.fromfile`. Binary files produced and consumed by :meth:`.tofile` and; :meth:`.fromfile` are not platform independent, so should only be used; for inter-operating with NumPy, not storage. Use; :meth:`BlockMatrix.write` and :meth:`BlockMatrix.read` to save and load; block matrices, since these methods write and read blocks in parallel; and are platform independent. The number of entries must be less than :math:`2^{31}`. Parameters; ----------; uri: :class:`str`, optional; URI of binary output file. See Also; --------; :meth:`.to_numpy`; """"""; hl.current_backend().validate_file(uri). _check_entries_size(self.n_rows, self.n_cols). writer = BlockMatrixBinaryWriter(uri); Env.backend().execute(BlockMatrixWrite(self._bmir, writer)). [docs] @typecheck_method(_force_blocking=bool); def to_numpy(self, _force_blocking=False):; """"""Collects the block matrix into a `NumPy ndarray; <https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html>`__. Examples; --------; >>> bm = BlockMatrix.random(10, 20); >>> a = bm.to_numpy(). Notes; -----; The resulting ndarray will have the same shape as the block matrix. Returns; -------; :class:`numpy.ndarray`; """"""; from hail.backend.service_backend import ServiceBackend. if self.n_rows * self.n_cols > 1 << 31 or _force_blocking:; path = new_temp_file(",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:41819,Performance,cache,cache,41819,"DArrayExpression`; """"""; ir = BlockMatrixCollect(self._bmir); return construct_expr(ir, hl.tndarray(hl.tfloat64, 2)). @property; def is_sparse(self):; """"""Returns ``True`` if block-sparse. Notes; -----; A block matrix is block-sparse if at least of its blocks is dropped,; i.e. implicitly a block of zeros. Returns; -------; :obj:`bool`; """"""; return Env.backend()._to_java_blockmatrix_ir(self._bmir).typ().isSparse(). @property; def T(self):; """"""Matrix transpose. Returns; -------; :class:`.BlockMatrix`; """"""; if self.n_rows == 1 and self.n_cols == 1:; return self. if self.n_rows == 1:; index_expr = [0]; elif self.n_cols == 1:; index_expr = [1]; else:; index_expr = [1, 0]. return BlockMatrix(BlockMatrixBroadcast(self._bmir, index_expr, [self.n_cols, self.n_rows], self.block_size)). [docs] def densify(self):; """"""Restore all dropped blocks as explicit blocks of zeros. Returns; -------; :class:`.BlockMatrix`; """"""; return BlockMatrix(BlockMatrixDensify(self._bmir)). [docs] def cache(self):; """"""Persist this block matrix in memory. Notes; -----; This method is an alias for :meth:`persist(""MEMORY_ONLY"") <hail.linalg.BlockMatrix.persist>`. Returns; -------; :class:`.BlockMatrix`; Cached block matrix.; """"""; return self.persist('MEMORY_ONLY'). [docs] @typecheck_method(storage_level=storage_level); def persist(self, storage_level='MEMORY_AND_DISK'):; """"""Persists this block matrix in memory or on disk. Notes; -----; The :meth:`.BlockMatrix.persist` and :meth:`.BlockMatrix.cache`; methods store the current block matrix on disk or in memory temporarily; to avoid redundant computation and improve the performance of Hail; pipelines. This method is not a substitution for; :meth:`.BlockMatrix.write`, which stores a permanent file. Most users should use the ""MEMORY_AND_DISK"" storage level. See the `Spark; documentation; <http://spark.apache.org/docs/latest/programming-guide.html#rdd-persistence>`__; for a more in-depth discussion of persisting data. Parameters; ----------; storage_level : str;",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:42316,Performance,cache,cache,42316,"n self. if self.n_rows == 1:; index_expr = [0]; elif self.n_cols == 1:; index_expr = [1]; else:; index_expr = [1, 0]. return BlockMatrix(BlockMatrixBroadcast(self._bmir, index_expr, [self.n_cols, self.n_rows], self.block_size)). [docs] def densify(self):; """"""Restore all dropped blocks as explicit blocks of zeros. Returns; -------; :class:`.BlockMatrix`; """"""; return BlockMatrix(BlockMatrixDensify(self._bmir)). [docs] def cache(self):; """"""Persist this block matrix in memory. Notes; -----; This method is an alias for :meth:`persist(""MEMORY_ONLY"") <hail.linalg.BlockMatrix.persist>`. Returns; -------; :class:`.BlockMatrix`; Cached block matrix.; """"""; return self.persist('MEMORY_ONLY'). [docs] @typecheck_method(storage_level=storage_level); def persist(self, storage_level='MEMORY_AND_DISK'):; """"""Persists this block matrix in memory or on disk. Notes; -----; The :meth:`.BlockMatrix.persist` and :meth:`.BlockMatrix.cache`; methods store the current block matrix on disk or in memory temporarily; to avoid redundant computation and improve the performance of Hail; pipelines. This method is not a substitution for; :meth:`.BlockMatrix.write`, which stores a permanent file. Most users should use the ""MEMORY_AND_DISK"" storage level. See the `Spark; documentation; <http://spark.apache.org/docs/latest/programming-guide.html#rdd-persistence>`__; for a more in-depth discussion of persisting data. Parameters; ----------; storage_level : str; Storage level. One of: NONE, DISK_ONLY,; DISK_ONLY_2, MEMORY_ONLY, MEMORY_ONLY_2, MEMORY_ONLY_SER,; MEMORY_ONLY_SER_2, MEMORY_AND_DISK, MEMORY_AND_DISK_2,; MEMORY_AND_DISK_SER, MEMORY_AND_DISK_SER_2, OFF_HEAP. Returns; -------; :class:`.BlockMatrix`; Persisted block matrix.; """"""; return Env.backend().persist_blockmatrix(self). [docs] def unpersist(self):; """"""Unpersists this block matrix from memory/disk. Notes; -----; This function will have no effect on a block matrix that was not previously; persisted. Returns; -------; :class:`.BlockMatrix`; Unpe",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:42444,Performance,perform,performance,42444,"n self. if self.n_rows == 1:; index_expr = [0]; elif self.n_cols == 1:; index_expr = [1]; else:; index_expr = [1, 0]. return BlockMatrix(BlockMatrixBroadcast(self._bmir, index_expr, [self.n_cols, self.n_rows], self.block_size)). [docs] def densify(self):; """"""Restore all dropped blocks as explicit blocks of zeros. Returns; -------; :class:`.BlockMatrix`; """"""; return BlockMatrix(BlockMatrixDensify(self._bmir)). [docs] def cache(self):; """"""Persist this block matrix in memory. Notes; -----; This method is an alias for :meth:`persist(""MEMORY_ONLY"") <hail.linalg.BlockMatrix.persist>`. Returns; -------; :class:`.BlockMatrix`; Cached block matrix.; """"""; return self.persist('MEMORY_ONLY'). [docs] @typecheck_method(storage_level=storage_level); def persist(self, storage_level='MEMORY_AND_DISK'):; """"""Persists this block matrix in memory or on disk. Notes; -----; The :meth:`.BlockMatrix.persist` and :meth:`.BlockMatrix.cache`; methods store the current block matrix on disk or in memory temporarily; to avoid redundant computation and improve the performance of Hail; pipelines. This method is not a substitution for; :meth:`.BlockMatrix.write`, which stores a permanent file. Most users should use the ""MEMORY_AND_DISK"" storage level. See the `Spark; documentation; <http://spark.apache.org/docs/latest/programming-guide.html#rdd-persistence>`__; for a more in-depth discussion of persisting data. Parameters; ----------; storage_level : str; Storage level. One of: NONE, DISK_ONLY,; DISK_ONLY_2, MEMORY_ONLY, MEMORY_ONLY_2, MEMORY_ONLY_SER,; MEMORY_ONLY_SER_2, MEMORY_AND_DISK, MEMORY_AND_DISK_2,; MEMORY_AND_DISK_SER, MEMORY_AND_DISK_SER_2, OFF_HEAP. Returns; -------; :class:`.BlockMatrix`; Persisted block matrix.; """"""; return Env.backend().persist_blockmatrix(self). [docs] def unpersist(self):; """"""Unpersists this block matrix from memory/disk. Notes; -----; This function will have no effect on a block matrix that was not previously; persisted. Returns; -------; :class:`.BlockMatrix`; Unpe",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:55455,Performance,cache,cache,55455,"cache_memory_in_bytes=nullable(int)); def to_table_row_major(self, n_partitions=None, maximum_cache_memory_in_bytes=None):; """"""Returns a table where each row represents a row in the block matrix. The resulting table has the following fields:; - **row_idx** (:py:data.`tint64`, key field) -- Row index; - **entries** (:py:class:`.tarray` of :py:data:`.tfloat64`) -- Entries for the row. Examples; --------; >>> import numpy as np; >>> block_matrix = BlockMatrix.from_numpy(np.array([[1, 2], [3, 4], [5, 6]]), 2); >>> t = block_matrix.to_table_row_major(); >>> t.show(); +---------+---------------------+; | row_idx | entries |; +---------+---------------------+; | int64 | array<float64> |; +---------+---------------------+; | 0 | [1.00e+00,2.00e+00] |; | 1 | [3.00e+00,4.00e+00] |; | 2 | [5.00e+00,6.00e+00] |; +---------+---------------------+. Parameters; ----------; n_partitions : int or None; Number of partitions of the table.; maximum_cache_memory_in_bytes : int or None; The amount of memory to reserve, per partition, to cache rows of the; matrix in memory. This value must be at least large enough to hold; one row of the matrix in memory. If this value is exactly the size of; one row, then a partition makes a network request for every row of; every block. Larger values reduce the number of network requests. If; memory permits, setting this value to the size of one output; partition permits one network request per block per partition. Notes; -----; Does not support block-sparse matrices. Returns; -------; :class:`.Table`; Table where each row corresponds to a row in the block matrix.; """"""; path = new_temp_file(); if maximum_cache_memory_in_bytes and maximum_cache_memory_in_bytes > (1 << 31) - 1:; raise ValueError(; f'maximum_cache_memory_in_bytes must be less than 2^31 -1, was: {maximum_cache_memory_in_bytes}'; ). self.write(path, overwrite=True, force_row_major=True); reader = TableFromBlockMatrixNativeReader(path, n_partitions, maximum_cache_memory_in_bytes); return Tabl",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:56960,Performance,cache,cache,56960," Returns; -------; :class:`.Table`; Table where each row corresponds to a row in the block matrix.; """"""; path = new_temp_file(); if maximum_cache_memory_in_bytes and maximum_cache_memory_in_bytes > (1 << 31) - 1:; raise ValueError(; f'maximum_cache_memory_in_bytes must be less than 2^31 -1, was: {maximum_cache_memory_in_bytes}'; ). self.write(path, overwrite=True, force_row_major=True); reader = TableFromBlockMatrixNativeReader(path, n_partitions, maximum_cache_memory_in_bytes); return Table(TableRead(reader)). [docs] @typecheck_method(n_partitions=nullable(int), maximum_cache_memory_in_bytes=nullable(int)); def to_matrix_table_row_major(self, n_partitions=None, maximum_cache_memory_in_bytes=None):; """"""Returns a matrix table with row key of `row_idx` and col key `col_idx`, whose; entries are structs of a single field `element`. Parameters; ----------; n_partitions : int or None; Number of partitions of the matrix table.; maximum_cache_memory_in_bytes : int or None; The amount of memory to reserve, per partition, to cache rows of the; matrix in memory. This value must be at least large enough to hold; one row of the matrix in memory. If this value is exactly the size of; one row, then a partition makes a network request for every row of; every block. Larger values reduce the number of network requests. If; memory permits, setting this value to the size of one output; partition permits one network request per block per partition. Notes; -----; Does not support block-sparse matrices. Returns; -------; :class:`.MatrixTable`; Matrix table where each entry corresponds to an entry in the block matrix.; """"""; t = self.to_table_row_major(n_partitions, maximum_cache_memory_in_bytes); t = t.transmute(entries=t.entries.map(lambda i: hl.struct(element=i))); t = t.annotate_globals(cols=hl.range(self.n_cols).map(lambda i: hl.struct(col_idx=hl.int64(i)))); return t._unlocalize_entries('entries', 'cols', ['col_idx']). [docs] @staticmethod; @typecheck(; path_in=str,; path_out=str,; de",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:72330,Performance,load,loadtxt,72330,"ory where rectangles were written.; binary: :obj:`bool`; If true, reads the files as binary, otherwise as text delimited. Returns; -------; :class:`numpy.ndarray`; """""". def parse_rects(fname):; rect_idx_and_bounds = [int(i) for i in re.findall(r'\d+', fname)]; if len(rect_idx_and_bounds) != 5:; raise ValueError(f'Invalid rectangle file name: {fname}'); return rect_idx_and_bounds. rect_files = [file['path'] for file in hl.utils.hadoop_ls(path) if not re.match(r'.*\.crc', file['path'])]; rects = [parse_rects(os.path.basename(file_path)) for file_path in rect_files]. n_rows = max(rects, key=lambda r: r[2])[2]; n_cols = max(rects, key=lambda r: r[4])[4]. nd = np.zeros(shape=(n_rows, n_cols)); with with_local_temp_file() as f:; uri = local_path_uri(f); for rect, file_path in zip(rects, rect_files):; hl.utils.hadoop_copy(file_path, uri); if binary:; rect_data = np.reshape(np.fromfile(f), (rect[2] - rect[1], rect[4] - rect[3])); else:; rect_data = np.loadtxt(f, ndmin=2); nd[rect[1] : rect[2], rect[3] : rect[4]] = rect_data; return nd. [docs] @typecheck_method(compute_uv=bool, complexity_bound=int); def svd(self, compute_uv=True, complexity_bound=8192):; r""""""Computes the reduced singular value decomposition. Examples; --------. >>> x = BlockMatrix.from_numpy(np.array([[-2.0, 0.0, 3.0],; ... [-1.0, 2.0, 4.0]])); >>> x.svd(); (array([[-0.60219551, -0.79834865],; [-0.79834865, 0.60219551]]),; array([5.61784832, 1.56197958]),; array([[ 0.35649586, -0.28421866, -0.89001711],; [ 0.6366932 , 0.77106707, 0.00879404]])). Notes; -----; This method leverages distributed matrix multiplication to compute; reduced `singular value decomposition; <https://en.wikipedia.org/wiki/Singular-value_decomposition>`__ (SVD); for matrices that would otherwise be too large to work with locally,; provided that at least one dimension is less than or equal to 46300. Let :math:`X` be an :math:`n \times m` matrix and let; :math:`r = \min(n, m)`. In particular, :math:`X` can have at most; :math:`r` non-zero",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:76341,Performance,perform,performance,76341,"finite; precision, the zero eigenvalues of :math:`X^T X` or :math:`X X^T` will; only be approximately zero. If the rank is not known ahead, examining the relative sizes of the; trailing singular values should reveal where the spectrum switches from; non-zero to ""zero"" eigenvalues. With 64-bit floating point, zero; eigenvalues are typically about 1e-16 times the largest eigenvalue.; The corresponding singular vectors should be sliced away **before** an; action which realizes the block-matrix-side singular vectors. :meth:`svd` sets the singular values corresponding to negative; eigenvalues to exactly ``0.0``. Warning; -------; The first and third stages invoke distributed matrix multiplication with; parallelism bounded by the number of resulting blocks, whereas the; second stage is executed on the leader (master) node. For matrices of; large minimum dimension, it may be preferable to run these stages; separately. The performance of the second stage depends critically on the number of; leader (master) cores and the NumPy / SciPy configuration, viewable with; ``np.show_config()``. For Intel machines, we recommend installing the; `MKL <https://anaconda.org/anaconda/mkl>`__ package for Anaconda. Consequently, the optimal value of `complexity_bound` is highly; configuration-dependent. Parameters; ----------; compute_uv: :obj:`bool`; If False, only compute the singular values (or eigenvalues).; complexity_bound: :obj:`int`; Maximum value of :math:`\sqrt[3]{nmr}` for which; :func:`scipy.linalg.svd` is used. Returns; -------; u: :class:`numpy.ndarray` or :class:`BlockMatrix`; Left singular vectors :math:`U`, as a block matrix if :math:`n > m` and; :math:`\sqrt[3]{nmr}` exceeds `complexity_bound`.; Only returned if `compute_uv` is True.; s: :class:`numpy.ndarray`; Singular values from :math:`\Sigma` in descending order.; vt: :class:`numpy.ndarray` or :class:`BlockMatrix`; Right singular vectors :math:`V^T``, as a block matrix if :math:`n \leq m` and; :math:`\sqrt[3]{nmr}` excee",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:8201,Safety,avoid,avoiding,8201,"cists often want to compute and manipulate a; banded correlation matrix capturing ""linkage disequilibrium"" between nearby; variants along the genome. In this case, working with the full correlation; matrix for tens of millions of variants would be prohibitively expensive,; and in any case, entries far from the diagonal are either not of interest or; ought to be zeroed out before downstream linear algebra. To enable such computations, block matrices do not require that all blocks; be realized explicitly. Implicit (dropped) blocks behave as blocks of; zeroes, so we refer to a block matrix in which at least one block is; implicitly zero as a **block-sparse matrix**. Otherwise, we say the matrix; is block-dense. The property :meth:`is_sparse` encodes this state. Dropped blocks are not stored in memory or on :meth:`write`. In fact,; blocks that are dropped prior to an action like :meth:`export` or; :meth:`to_numpy` are never computed in the first place, nor are any blocks; of upstream operands on which only dropped blocks depend! In addition,; linear algebra is accelerated by avoiding, for example, explicit addition of; or multiplication by blocks of zeroes. Block-sparse matrices may be created with; :meth:`sparsify_band`,; :meth:`sparsify_rectangles`,; :meth:`sparsify_row_intervals`,; and :meth:`sparsify_triangle`. The following methods naturally propagate block-sparsity:. - Addition and subtraction ""union"" realized blocks. - Element-wise multiplication ""intersects"" realized blocks. - Transpose ""transposes"" realized blocks. - :meth:`abs` and :meth:`sqrt` preserve the realized blocks. - :meth:`sum` along an axis realizes those blocks for which at least one; block summand is realized. - Matrix slicing, and more generally :meth:`filter`, :meth:`filter_rows`,; and :meth:`filter_cols`. These following methods always result in a block-dense matrix:. - :meth:`fill`. - Addition or subtraction of a scalar or broadcasted vector. - Matrix multiplication, ``@``. The following metho",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:14054,Safety,avoid,avoid,14054," isinstance(hl.current_backend(), ServiceBackend):; path = hl.TemporaryFilename().name; hl.current_backend().fs.open(path, mode='wb').write(nd.tobytes()); uri = path; else:; path = new_local_temp_file(); nd.tofile(path); uri = local_path_uri(path); return cls.fromfile(uri, n_rows, n_cols, block_size). [docs] @classmethod; @typecheck_method(; entry_expr=expr_float64,; mean_impute=bool,; center=bool,; normalize=bool,; axis=nullable(enumeration('rows', 'cols')),; block_size=nullable(int),; ); def from_entry_expr(; cls, entry_expr, mean_impute=False, center=False, normalize=False, axis='rows', block_size=None; ):; """"""Creates a block matrix using a matrix table entry expression. Examples; --------; >>> mt = hl.balding_nichols_model(3, 25, 50); >>> bm = BlockMatrix.from_entry_expr(mt.GT.n_alt_alleles()). Notes; -----; This convenience method writes the block matrix to a temporary file on; persistent disk and then reads the file. If you want to store the; resulting block matrix, use :meth:`write_from_entry_expr` directly to; avoid writing the result twice. See :meth:`write_from_entry_expr` for; further documentation. Warning; -------; If the rows of the matrix table have been filtered to a small fraction,; then :meth:`.MatrixTable.repartition` before this method to improve; performance. If you encounter a Hadoop write/replication error, increase the; number of persistent workers or the disk size per persistent worker,; or use :meth:`write_from_entry_expr` to write to external storage. This method opens ``n_cols / block_size`` files concurrently per task.; To not blow out memory when the number of columns is very large,; limit the Hadoop write buffer size; e.g. on GCP, set this property on; cluster startup (the default is 64MB):; ``--properties 'core:fs.gs.io.buffersize.write=1048576``. Parameters; ----------; entry_expr: :class:`.Float64Expression`; Entry expression for numeric matrix entries.; mean_impute: :obj:`bool`; If true, set missing values to the row mean before cen",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:42400,Safety,avoid,avoid,42400,"n self. if self.n_rows == 1:; index_expr = [0]; elif self.n_cols == 1:; index_expr = [1]; else:; index_expr = [1, 0]. return BlockMatrix(BlockMatrixBroadcast(self._bmir, index_expr, [self.n_cols, self.n_rows], self.block_size)). [docs] def densify(self):; """"""Restore all dropped blocks as explicit blocks of zeros. Returns; -------; :class:`.BlockMatrix`; """"""; return BlockMatrix(BlockMatrixDensify(self._bmir)). [docs] def cache(self):; """"""Persist this block matrix in memory. Notes; -----; This method is an alias for :meth:`persist(""MEMORY_ONLY"") <hail.linalg.BlockMatrix.persist>`. Returns; -------; :class:`.BlockMatrix`; Cached block matrix.; """"""; return self.persist('MEMORY_ONLY'). [docs] @typecheck_method(storage_level=storage_level); def persist(self, storage_level='MEMORY_AND_DISK'):; """"""Persists this block matrix in memory or on disk. Notes; -----; The :meth:`.BlockMatrix.persist` and :meth:`.BlockMatrix.cache`; methods store the current block matrix on disk or in memory temporarily; to avoid redundant computation and improve the performance of Hail; pipelines. This method is not a substitution for; :meth:`.BlockMatrix.write`, which stores a permanent file. Most users should use the ""MEMORY_AND_DISK"" storage level. See the `Spark; documentation; <http://spark.apache.org/docs/latest/programming-guide.html#rdd-persistence>`__; for a more in-depth discussion of persisting data. Parameters; ----------; storage_level : str; Storage level. One of: NONE, DISK_ONLY,; DISK_ONLY_2, MEMORY_ONLY, MEMORY_ONLY_2, MEMORY_ONLY_SER,; MEMORY_ONLY_SER_2, MEMORY_AND_DISK, MEMORY_AND_DISK_2,; MEMORY_AND_DISK_SER, MEMORY_AND_DISK_SER_2, OFF_HEAP. Returns; -------; :class:`.BlockMatrix`; Persisted block matrix.; """"""; return Env.backend().persist_blockmatrix(self). [docs] def unpersist(self):; """"""Unpersists this block matrix from memory/disk. Notes; -----; This function will have no effect on a block matrix that was not previously; persisted. Returns; -------; :class:`.BlockMatrix`; Unpe",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:42406,Safety,redund,redundant,42406,"n self. if self.n_rows == 1:; index_expr = [0]; elif self.n_cols == 1:; index_expr = [1]; else:; index_expr = [1, 0]. return BlockMatrix(BlockMatrixBroadcast(self._bmir, index_expr, [self.n_cols, self.n_rows], self.block_size)). [docs] def densify(self):; """"""Restore all dropped blocks as explicit blocks of zeros. Returns; -------; :class:`.BlockMatrix`; """"""; return BlockMatrix(BlockMatrixDensify(self._bmir)). [docs] def cache(self):; """"""Persist this block matrix in memory. Notes; -----; This method is an alias for :meth:`persist(""MEMORY_ONLY"") <hail.linalg.BlockMatrix.persist>`. Returns; -------; :class:`.BlockMatrix`; Cached block matrix.; """"""; return self.persist('MEMORY_ONLY'). [docs] @typecheck_method(storage_level=storage_level); def persist(self, storage_level='MEMORY_AND_DISK'):; """"""Persists this block matrix in memory or on disk. Notes; -----; The :meth:`.BlockMatrix.persist` and :meth:`.BlockMatrix.cache`; methods store the current block matrix on disk or in memory temporarily; to avoid redundant computation and improve the performance of Hail; pipelines. This method is not a substitution for; :meth:`.BlockMatrix.write`, which stores a permanent file. Most users should use the ""MEMORY_AND_DISK"" storage level. See the `Spark; documentation; <http://spark.apache.org/docs/latest/programming-guide.html#rdd-persistence>`__; for a more in-depth discussion of persisting data. Parameters; ----------; storage_level : str; Storage level. One of: NONE, DISK_ONLY,; DISK_ONLY_2, MEMORY_ONLY, MEMORY_ONLY_2, MEMORY_ONLY_SER,; MEMORY_ONLY_SER_2, MEMORY_AND_DISK, MEMORY_AND_DISK_2,; MEMORY_AND_DISK_SER, MEMORY_AND_DISK_SER_2, OFF_HEAP. Returns; -------; :class:`.BlockMatrix`; Persisted block matrix.; """"""; return Env.backend().persist_blockmatrix(self). [docs] def unpersist(self):; """"""Unpersists this block matrix from memory/disk. Notes; -----; This function will have no effect on a block matrix that was not previously; persisted. Returns; -------; :class:`.BlockMatrix`; Unpe",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:9580,Testability,log,logarithm,9580," ""intersects"" realized blocks. - Transpose ""transposes"" realized blocks. - :meth:`abs` and :meth:`sqrt` preserve the realized blocks. - :meth:`sum` along an axis realizes those blocks for which at least one; block summand is realized. - Matrix slicing, and more generally :meth:`filter`, :meth:`filter_rows`,; and :meth:`filter_cols`. These following methods always result in a block-dense matrix:. - :meth:`fill`. - Addition or subtraction of a scalar or broadcasted vector. - Matrix multiplication, ``@``. The following methods fail if any operand is block-sparse, but can be forced; by first applying :meth:`densify`. - Element-wise division between two block matrices. - Multiplication by a scalar or broadcasted vector which includes an; infinite or ``nan`` value. - Division by a scalar or broadcasted vector which includes a zero, infinite; or ``nan`` value. - Division of a scalar or broadcasted vector by a block matrix. - Element-wise exponentiation by a negative exponent. - Natural logarithm, :meth:`log`.; """""". def __init__(self, bmir):; self._bmir = bmir. [docs] @classmethod; @typecheck_method(path=str, _assert_type=nullable(tblockmatrix)); def read(cls, path, *, _assert_type=None):; """"""Reads a block matrix. Parameters; ----------; path: :class:`str`; Path to input file. Returns; -------; :class:`.BlockMatrix`; """"""; return cls(BlockMatrixRead(BlockMatrixNativeReader(path), _assert_type=_assert_type)). [docs] @classmethod; @typecheck_method(uri=str, n_rows=int, n_cols=int, block_size=nullable(int), _assert_type=nullable(tblockmatrix)); def fromfile(cls, uri, n_rows, n_cols, block_size=None, *, _assert_type=None):; """"""Creates a block matrix from a binary file. Examples; --------; >>> import numpy as np; >>> a = np.random.rand(10, 20); >>> a.tofile('/local/file') # doctest: +SKIP. To create a block matrix of the same dimensions:. >>> bm = BlockMatrix.fromfile('file:///local/file', 10, 20) # doctest: +SKIP. Notes; -----; This method, analogous to `numpy.fromfile; <https:/",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:9598,Testability,log,log,9598," ""intersects"" realized blocks. - Transpose ""transposes"" realized blocks. - :meth:`abs` and :meth:`sqrt` preserve the realized blocks. - :meth:`sum` along an axis realizes those blocks for which at least one; block summand is realized. - Matrix slicing, and more generally :meth:`filter`, :meth:`filter_rows`,; and :meth:`filter_cols`. These following methods always result in a block-dense matrix:. - :meth:`fill`. - Addition or subtraction of a scalar or broadcasted vector. - Matrix multiplication, ``@``. The following methods fail if any operand is block-sparse, but can be forced; by first applying :meth:`densify`. - Element-wise division between two block matrices. - Multiplication by a scalar or broadcasted vector which includes an; infinite or ``nan`` value. - Division by a scalar or broadcasted vector which includes a zero, infinite; or ``nan`` value. - Division of a scalar or broadcasted vector by a block matrix. - Element-wise exponentiation by a negative exponent. - Natural logarithm, :meth:`log`.; """""". def __init__(self, bmir):; self._bmir = bmir. [docs] @classmethod; @typecheck_method(path=str, _assert_type=nullable(tblockmatrix)); def read(cls, path, *, _assert_type=None):; """"""Reads a block matrix. Parameters; ----------; path: :class:`str`; Path to input file. Returns; -------; :class:`.BlockMatrix`; """"""; return cls(BlockMatrixRead(BlockMatrixNativeReader(path), _assert_type=_assert_type)). [docs] @classmethod; @typecheck_method(uri=str, n_rows=int, n_cols=int, block_size=nullable(int), _assert_type=nullable(tblockmatrix)); def fromfile(cls, uri, n_rows, n_cols, block_size=None, *, _assert_type=None):; """"""Creates a block matrix from a binary file. Examples; --------; >>> import numpy as np; >>> a = np.random.rand(10, 20); >>> a.tofile('/local/file') # doctest: +SKIP. To create a block matrix of the same dimensions:. >>> bm = BlockMatrix.fromfile('file:///local/file', 10, 20) # doctest: +SKIP. Notes; -----; This method, analogous to `numpy.fromfile; <https:/",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:17878,Testability,test,test,17878,"n, [n_rows, n_cols], block_size); return BlockMatrix(rand). [docs] @classmethod; @typecheck_method(n_rows=int, n_cols=int, value=numeric, block_size=nullable(int)); def fill(cls, n_rows, n_cols, value, block_size=None):; """"""Creates a block matrix with all elements the same value. Examples; --------; Create a block matrix with 10 rows, 20 columns, and all elements equal to ``1.0``:. >>> bm = BlockMatrix.fill(10, 20, 1.0). Parameters; ----------; n_rows: :obj:`int`; Number of rows.; n_cols: :obj:`int`; Number of columns.; value: :obj:`float`; Value of all elements.; block_size: :obj:`int`, optional; Block size. Default given by :meth:`default_block_size`. Returns; -------; :class:`.BlockMatrix`; """"""; if not block_size:; block_size = BlockMatrix.default_block_size(). bmir = BlockMatrixBroadcast(_to_bmir(value, block_size), [], [n_rows, n_cols], block_size); return BlockMatrix(bmir). @classmethod; @typecheck_method(n_rows=int, n_cols=int, data=sequenceof(float), block_size=nullable(int)); def _create(cls, n_rows, n_cols, data, block_size=None):; """"""Private method for creating small test matrices."""""". if block_size is None:; block_size = BlockMatrix.default_block_size(). return BlockMatrix(ValueToBlockMatrix(hl.literal(data)._ir, [n_rows, n_cols], block_size)). [docs] @classmethod; @typecheck_method(ndarray_expression=expr_ndarray(), block_size=int); def from_ndarray(cls, ndarray_expression, block_size=4096):; """"""Create a BlockMatrix from an ndarray""""""; if ndarray_expression.dtype.element_type != hl.tfloat64:; raise ValueError(""BlockMatrix.from_ndarray expects an ndarray of type float64""). shape = hl.eval(ndarray_expression.shape). if shape is None:; raise ValueError(""Cannot make a BlockMatrix from a missing NDArray""); return BlockMatrix(ValueToBlockMatrix(ndarray_expression._ir, shape, block_size)). [docs] @staticmethod; def default_block_size():; """"""Default block side length."""""". # This should match BlockMatrix.defaultBlockSize in the Scala backend.; return 4096 # 32 * ",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:28874,Testability,assert,assert,28874,"rix.filter_rows` (or vice versa), but; filters the block matrix in a single pass which may be more efficient. Parameters; ----------; rows_to_keep: :obj:`list` of :obj:`int`; Indices of rows to keep. Must be non-empty and increasing.; cols_to_keep: :obj:`list` of :obj:`int`; Indices of columns to keep. Must be non-empty and increasing. Returns; -------; :class:`.BlockMatrix`; """"""; BlockMatrix._check_indices(rows_to_keep, self.n_rows); BlockMatrix._check_indices(cols_to_keep, self.n_cols); return BlockMatrix(BlockMatrixFilter(self._bmir, [rows_to_keep, cols_to_keep])). @staticmethod; def _pos_index(i, size, name, allow_size=False):; if 0 <= i < size or (i == size and allow_size):; return i; elif 0 <= i + size < size:; return i + size; else:; raise ValueError(f'invalid {name} {i} for axis of size {size}'). @staticmethod; def _range_to_keep(idx, size):; if isinstance(idx, int):; pos_idx = BlockMatrix._pos_index(idx, size, 'index'); return slice(pos_idx, pos_idx + 1, 1). assert isinstance(idx, slice); if idx.step and idx.step <= 0:; raise ValueError(f'slice step must be positive, found {idx.step}'). start = 0 if idx.start is None else BlockMatrix._pos_index(idx.start, size, 'start index'); stop = size if idx.stop is None else BlockMatrix._pos_index(idx.stop, size, 'stop index', allow_size=True); step = 1 if idx.step is None else idx.step. if start < stop:; return slice(start, stop, step); else:; raise ValueError(f'slice {start}:{stop}:{step} is empty'). @typecheck_method(indices=tupleof(oneof(int, sliceof(nullable(int), nullable(int), nullable(int))))); def __getitem__(self, indices):; if len(indices) != 2:; raise ValueError(f'tuple of indices or slices must have length two, found {len(indices)}'). row_idx, col_idx = indices. if isinstance(row_idx, int) and isinstance(col_idx, int):; i = BlockMatrix._pos_index(row_idx, self.n_rows, 'row index'); j = BlockMatrix._pos_index(col_idx, self.n_cols, 'col index'). return Env.backend().execute(BlockMatrixToValueApply(self._bmir,",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:51683,Testability,log,log,51683,"numeric); def __pow__(self, x):; """"""Element-wise exponentiation: a ** x. Parameters; ----------; x: :obj:`int` or :obj:`float`; Exponent. Returns; -------; :class:`.BlockMatrix`; """"""; return self._apply_map(lambda i: i**x, needs_dense=False). def _map_dense(self, func):; return self._apply_map(func, True). def _map_sparse(self, func):; return self._apply_map(func, False). [docs] def sqrt(self):; """"""Element-wise square root. Returns; -------; :class:`.BlockMatrix`; """"""; return self._apply_map(hl.sqrt, needs_dense=False). [docs] def ceil(self):; """"""Element-wise ceiling. Returns; -------; :class:`.BlockMatrix`; """"""; return self._apply_map(hl.ceil, needs_dense=False). [docs] def floor(self):; """"""Element-wise floor. Returns; -------; :class:`.BlockMatrix`; """"""; return self._apply_map(hl.floor, needs_dense=False). [docs] def abs(self):; """"""Element-wise absolute value. Returns; -------; :class:`.BlockMatrix`; """"""; return self._apply_map(hl.abs, needs_dense=False). [docs] def log(self):; """"""Element-wise natural logarithm. Returns; -------; :class:`.BlockMatrix`; """"""; return self._apply_map(lambda x: hl.log(x), needs_dense=True). [docs] def diagonal(self):; """"""Extracts diagonal elements as a row vector. Returns; -------; :class:`.BlockMatrix`; """"""; diag_bmir = BlockMatrixBroadcast(self._bmir, [0, 0], [1, min(self.n_rows, self.n_cols)], self.block_size); return BlockMatrix(diag_bmir). [docs] @typecheck_method(axis=nullable(int)); def sum(self, axis=None):; """"""Sums array elements over one or both axes. Examples; --------; >>> import numpy as np; >>> nd = np.array([[ 1.0, 2.0, 3.0],; ... [ 4.0, 5.0, 6.0]]); >>> bm = BlockMatrix.from_numpy(nd); >>> bm.sum(); 21.0. >>> bm.sum(axis=0).to_numpy(); array([[5., 7., 9.]]). >>> bm.sum(axis=1).to_numpy(); array([[ 6.],; [15.]]). Parameters; ----------; axis: :obj:`int`, optional; Axis over which to sum.; By default, sum all elements.; If ``0``, sum over rows.; If ``1``, sum over columns. Returns; -------; :obj:`float` or :class:`BlockMa",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:51719,Testability,log,logarithm,51719,"numeric); def __pow__(self, x):; """"""Element-wise exponentiation: a ** x. Parameters; ----------; x: :obj:`int` or :obj:`float`; Exponent. Returns; -------; :class:`.BlockMatrix`; """"""; return self._apply_map(lambda i: i**x, needs_dense=False). def _map_dense(self, func):; return self._apply_map(func, True). def _map_sparse(self, func):; return self._apply_map(func, False). [docs] def sqrt(self):; """"""Element-wise square root. Returns; -------; :class:`.BlockMatrix`; """"""; return self._apply_map(hl.sqrt, needs_dense=False). [docs] def ceil(self):; """"""Element-wise ceiling. Returns; -------; :class:`.BlockMatrix`; """"""; return self._apply_map(hl.ceil, needs_dense=False). [docs] def floor(self):; """"""Element-wise floor. Returns; -------; :class:`.BlockMatrix`; """"""; return self._apply_map(hl.floor, needs_dense=False). [docs] def abs(self):; """"""Element-wise absolute value. Returns; -------; :class:`.BlockMatrix`; """"""; return self._apply_map(hl.abs, needs_dense=False). [docs] def log(self):; """"""Element-wise natural logarithm. Returns; -------; :class:`.BlockMatrix`; """"""; return self._apply_map(lambda x: hl.log(x), needs_dense=True). [docs] def diagonal(self):; """"""Extracts diagonal elements as a row vector. Returns; -------; :class:`.BlockMatrix`; """"""; diag_bmir = BlockMatrixBroadcast(self._bmir, [0, 0], [1, min(self.n_rows, self.n_cols)], self.block_size); return BlockMatrix(diag_bmir). [docs] @typecheck_method(axis=nullable(int)); def sum(self, axis=None):; """"""Sums array elements over one or both axes. Examples; --------; >>> import numpy as np; >>> nd = np.array([[ 1.0, 2.0, 3.0],; ... [ 4.0, 5.0, 6.0]]); >>> bm = BlockMatrix.from_numpy(nd); >>> bm.sum(); 21.0. >>> bm.sum(axis=0).to_numpy(); array([[5., 7., 9.]]). >>> bm.sum(axis=1).to_numpy(); array([[ 6.],; [15.]]). Parameters; ----------; axis: :obj:`int`, optional; Axis over which to sum.; By default, sum all elements.; If ``0``, sum over rows.; If ``1``, sum over columns. Returns; -------; :obj:`float` or :class:`BlockMa",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:51812,Testability,log,log,51812,"`; Exponent. Returns; -------; :class:`.BlockMatrix`; """"""; return self._apply_map(lambda i: i**x, needs_dense=False). def _map_dense(self, func):; return self._apply_map(func, True). def _map_sparse(self, func):; return self._apply_map(func, False). [docs] def sqrt(self):; """"""Element-wise square root. Returns; -------; :class:`.BlockMatrix`; """"""; return self._apply_map(hl.sqrt, needs_dense=False). [docs] def ceil(self):; """"""Element-wise ceiling. Returns; -------; :class:`.BlockMatrix`; """"""; return self._apply_map(hl.ceil, needs_dense=False). [docs] def floor(self):; """"""Element-wise floor. Returns; -------; :class:`.BlockMatrix`; """"""; return self._apply_map(hl.floor, needs_dense=False). [docs] def abs(self):; """"""Element-wise absolute value. Returns; -------; :class:`.BlockMatrix`; """"""; return self._apply_map(hl.abs, needs_dense=False). [docs] def log(self):; """"""Element-wise natural logarithm. Returns; -------; :class:`.BlockMatrix`; """"""; return self._apply_map(lambda x: hl.log(x), needs_dense=True). [docs] def diagonal(self):; """"""Extracts diagonal elements as a row vector. Returns; -------; :class:`.BlockMatrix`; """"""; diag_bmir = BlockMatrixBroadcast(self._bmir, [0, 0], [1, min(self.n_rows, self.n_cols)], self.block_size); return BlockMatrix(diag_bmir). [docs] @typecheck_method(axis=nullable(int)); def sum(self, axis=None):; """"""Sums array elements over one or both axes. Examples; --------; >>> import numpy as np; >>> nd = np.array([[ 1.0, 2.0, 3.0],; ... [ 4.0, 5.0, 6.0]]); >>> bm = BlockMatrix.from_numpy(nd); >>> bm.sum(); 21.0. >>> bm.sum(axis=0).to_numpy(); array([[5., 7., 9.]]). >>> bm.sum(axis=1).to_numpy(); array([[ 6.],; [15.]]). Parameters; ----------; axis: :obj:`int`, optional; Axis over which to sum.; By default, sum all elements.; If ``0``, sum over rows.; If ``1``, sum over columns. Returns; -------; :obj:`float` or :class:`BlockMatrix`; If None, returns a float.; If ``0``, returns a block matrix with a single row.; If ``1``, returns a block matrix with ",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:22673,Usability,clear,clear,22673,"rix.read(path, _assert_type=self._bmir._type). [docs] @staticmethod; @typecheck(; entry_expr=expr_float64,; path=str,; overwrite=bool,; mean_impute=bool,; center=bool,; normalize=bool,; axis=nullable(enumeration('rows', 'cols')),; block_size=nullable(int),; ); def write_from_entry_expr(; entry_expr,; path,; overwrite=False,; mean_impute=False,; center=False,; normalize=False,; axis='rows',; block_size=None,; ):; """"""Writes a block matrix from a matrix table entry expression. Examples; --------; >>> mt = hl.balding_nichols_model(3, 25, 50); >>> BlockMatrix.write_from_entry_expr(mt.GT.n_alt_alleles(),; ... 'output/model.bm'). Notes; -----; The resulting file can be loaded with :meth:`BlockMatrix.read`.; Blocks are stored row-major. If a pipelined transformation significantly downsamples the rows of the; underlying matrix table, then repartitioning the matrix table ahead of; this method will greatly improve its performance. By default, this method will fail if any values are missing (to be clear,; special float values like ``nan`` are not missing values). - Set `mean_impute` to replace missing values with the row mean before; possibly centering or normalizing. If all values are missing, the row; mean is ``nan``. - Set `center` to shift each row to have mean zero before possibly; normalizing. - Set `normalize` to normalize each row to have unit length. To standardize each row, regarded as an empirical distribution, to have; mean 0 and variance 1, set `center` and `normalize` and then multiply; the result by ``sqrt(n_cols)``. Warning; -------; If the rows of the matrix table have been filtered to a small fraction,; then :meth:`.MatrixTable.repartition` before this method to improve; performance. This method opens ``n_cols / block_size`` files concurrently per task.; To not blow out memory when the number of columns is very large,; limit the Hadoop write buffer size; e.g. on GCP, set this property on; cluster startup (the default is 64MB):; ``--properties 'core:fs.gs.io.bu",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html:42713,Usability,guid,guide,42713," zeros. Returns; -------; :class:`.BlockMatrix`; """"""; return BlockMatrix(BlockMatrixDensify(self._bmir)). [docs] def cache(self):; """"""Persist this block matrix in memory. Notes; -----; This method is an alias for :meth:`persist(""MEMORY_ONLY"") <hail.linalg.BlockMatrix.persist>`. Returns; -------; :class:`.BlockMatrix`; Cached block matrix.; """"""; return self.persist('MEMORY_ONLY'). [docs] @typecheck_method(storage_level=storage_level); def persist(self, storage_level='MEMORY_AND_DISK'):; """"""Persists this block matrix in memory or on disk. Notes; -----; The :meth:`.BlockMatrix.persist` and :meth:`.BlockMatrix.cache`; methods store the current block matrix on disk or in memory temporarily; to avoid redundant computation and improve the performance of Hail; pipelines. This method is not a substitution for; :meth:`.BlockMatrix.write`, which stores a permanent file. Most users should use the ""MEMORY_AND_DISK"" storage level. See the `Spark; documentation; <http://spark.apache.org/docs/latest/programming-guide.html#rdd-persistence>`__; for a more in-depth discussion of persisting data. Parameters; ----------; storage_level : str; Storage level. One of: NONE, DISK_ONLY,; DISK_ONLY_2, MEMORY_ONLY, MEMORY_ONLY_2, MEMORY_ONLY_SER,; MEMORY_ONLY_SER_2, MEMORY_AND_DISK, MEMORY_AND_DISK_2,; MEMORY_AND_DISK_SER, MEMORY_AND_DISK_SER_2, OFF_HEAP. Returns; -------; :class:`.BlockMatrix`; Persisted block matrix.; """"""; return Env.backend().persist_blockmatrix(self). [docs] def unpersist(self):; """"""Unpersists this block matrix from memory/disk. Notes; -----; This function will have no effect on a block matrix that was not previously; persisted. Returns; -------; :class:`.BlockMatrix`; Unpersisted block matrix.; """"""; return Env.backend().unpersist_blockmatrix(self). def __pos__(self):; return self. def __neg__(self):; """"""Negation: -a. Returns; -------; :class:`.BlockMatrix`; """"""; return self._apply_map(lambda x: construct_expr(ApplyUnaryPrimOp('-', x._ir), hl.tfloat64), needs_dense=False). ",MatchSource.WIKI,docs/0.2/_modules/hail/linalg/blockmatrix.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/linalg/blockmatrix.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:4236,Availability,error,errors,4236,"d:int,is_female:bool,fam_id:str}>'). trios_sym = Env.get_uid(); entries_sym = Env.get_uid(); cols_sym = Env.get_uid(). mt = mt.annotate_globals(**{trios_sym: hl.literal(trios, trios_type)}); mt = mt._localize_entries(entries_sym, cols_sym); mt = mt.annotate_globals(**{; cols_sym: hl.map(; lambda i: hl.bind(; lambda t: hl.struct(; id=mt[cols_sym][t.id][k],; proband=mt[cols_sym][t.id],; father=mt[cols_sym][t.pat_id],; mother=mt[cols_sym][t.mat_id],; is_female=t.is_female,; fam_id=t.fam_id,; ),; mt[trios_sym][i],; ),; hl.range(0, n_trios),; ); }); mt = mt.annotate(**{; entries_sym: hl.map(; lambda i: hl.bind(; lambda t: hl.struct(; proband_entry=mt[entries_sym][t.id],; father_entry=mt[entries_sym][t.pat_id],; mother_entry=mt[entries_sym][t.mat_id],; ),; mt[trios_sym][i],; ),; hl.range(0, n_trios),; ); }); mt = mt.drop(trios_sym). return mt._unlocalize_entries(entries_sym, cols_sym, ['id']). [docs]@typecheck(call=expr_call, pedigree=Pedigree); def mendel_errors(call, pedigree) -> Tuple[Table, Table, Table, Table]:; r""""""Find Mendel errors; count per variant, individual and nuclear family. .. include:: ../_templates/req_tstring.rst. .. include:: ../_templates/req_tvariant.rst. .. include:: ../_templates/req_biallelic.rst. Examples; --------. Find all violations of Mendelian inheritance in each (dad, mom, kid) trio in; a pedigree and return four tables (all errors, errors by family, errors by; individual, errors by variant):. >>> ped = hl.Pedigree.read('data/trios.fam'); >>> all_errors, per_fam, per_sample, per_variant = hl.mendel_errors(dataset['GT'], ped). Export all mendel errors to a text file:. >>> all_errors.export('output/all_mendel_errors.tsv'). Annotate columns with the number of Mendel errors:. >>> annotated_samples = dataset.annotate_cols(mendel=per_sample[dataset.s]). Annotate rows with the number of Mendel errors:. >>> annotated_variants = dataset.annotate_rows(mendel=per_variant[dataset.locus, dataset.alleles]). Notes; -----. The example above returns four ta",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:4566,Availability,error,errors,4566,"t.id][k],; proband=mt[cols_sym][t.id],; father=mt[cols_sym][t.pat_id],; mother=mt[cols_sym][t.mat_id],; is_female=t.is_female,; fam_id=t.fam_id,; ),; mt[trios_sym][i],; ),; hl.range(0, n_trios),; ); }); mt = mt.annotate(**{; entries_sym: hl.map(; lambda i: hl.bind(; lambda t: hl.struct(; proband_entry=mt[entries_sym][t.id],; father_entry=mt[entries_sym][t.pat_id],; mother_entry=mt[entries_sym][t.mat_id],; ),; mt[trios_sym][i],; ),; hl.range(0, n_trios),; ); }); mt = mt.drop(trios_sym). return mt._unlocalize_entries(entries_sym, cols_sym, ['id']). [docs]@typecheck(call=expr_call, pedigree=Pedigree); def mendel_errors(call, pedigree) -> Tuple[Table, Table, Table, Table]:; r""""""Find Mendel errors; count per variant, individual and nuclear family. .. include:: ../_templates/req_tstring.rst. .. include:: ../_templates/req_tvariant.rst. .. include:: ../_templates/req_biallelic.rst. Examples; --------. Find all violations of Mendelian inheritance in each (dad, mom, kid) trio in; a pedigree and return four tables (all errors, errors by family, errors by; individual, errors by variant):. >>> ped = hl.Pedigree.read('data/trios.fam'); >>> all_errors, per_fam, per_sample, per_variant = hl.mendel_errors(dataset['GT'], ped). Export all mendel errors to a text file:. >>> all_errors.export('output/all_mendel_errors.tsv'). Annotate columns with the number of Mendel errors:. >>> annotated_samples = dataset.annotate_cols(mendel=per_sample[dataset.s]). Annotate rows with the number of Mendel errors:. >>> annotated_variants = dataset.annotate_rows(mendel=per_variant[dataset.locus, dataset.alleles]). Notes; -----. The example above returns four tables, which contain Mendelian violations; grouped in various ways. These tables are modeled after the `PLINK mendel; formats <https://www.cog-genomics.org/plink2/formats#mendel>`_, resembling; the ``.mendel``, ``.fmendel``, ``.imendel``, and ``.lmendel`` formats,; respectively. **First table:** all Mendel errors. This table contains one row per Me",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:4574,Availability,error,errors,4574,"t.id][k],; proband=mt[cols_sym][t.id],; father=mt[cols_sym][t.pat_id],; mother=mt[cols_sym][t.mat_id],; is_female=t.is_female,; fam_id=t.fam_id,; ),; mt[trios_sym][i],; ),; hl.range(0, n_trios),; ); }); mt = mt.annotate(**{; entries_sym: hl.map(; lambda i: hl.bind(; lambda t: hl.struct(; proband_entry=mt[entries_sym][t.id],; father_entry=mt[entries_sym][t.pat_id],; mother_entry=mt[entries_sym][t.mat_id],; ),; mt[trios_sym][i],; ),; hl.range(0, n_trios),; ); }); mt = mt.drop(trios_sym). return mt._unlocalize_entries(entries_sym, cols_sym, ['id']). [docs]@typecheck(call=expr_call, pedigree=Pedigree); def mendel_errors(call, pedigree) -> Tuple[Table, Table, Table, Table]:; r""""""Find Mendel errors; count per variant, individual and nuclear family. .. include:: ../_templates/req_tstring.rst. .. include:: ../_templates/req_tvariant.rst. .. include:: ../_templates/req_biallelic.rst. Examples; --------. Find all violations of Mendelian inheritance in each (dad, mom, kid) trio in; a pedigree and return four tables (all errors, errors by family, errors by; individual, errors by variant):. >>> ped = hl.Pedigree.read('data/trios.fam'); >>> all_errors, per_fam, per_sample, per_variant = hl.mendel_errors(dataset['GT'], ped). Export all mendel errors to a text file:. >>> all_errors.export('output/all_mendel_errors.tsv'). Annotate columns with the number of Mendel errors:. >>> annotated_samples = dataset.annotate_cols(mendel=per_sample[dataset.s]). Annotate rows with the number of Mendel errors:. >>> annotated_variants = dataset.annotate_rows(mendel=per_variant[dataset.locus, dataset.alleles]). Notes; -----. The example above returns four tables, which contain Mendelian violations; grouped in various ways. These tables are modeled after the `PLINK mendel; formats <https://www.cog-genomics.org/plink2/formats#mendel>`_, resembling; the ``.mendel``, ``.fmendel``, ``.imendel``, and ``.lmendel`` formats,; respectively. **First table:** all Mendel errors. This table contains one row per Me",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:4592,Availability,error,errors,4592,"t.id][k],; proband=mt[cols_sym][t.id],; father=mt[cols_sym][t.pat_id],; mother=mt[cols_sym][t.mat_id],; is_female=t.is_female,; fam_id=t.fam_id,; ),; mt[trios_sym][i],; ),; hl.range(0, n_trios),; ); }); mt = mt.annotate(**{; entries_sym: hl.map(; lambda i: hl.bind(; lambda t: hl.struct(; proband_entry=mt[entries_sym][t.id],; father_entry=mt[entries_sym][t.pat_id],; mother_entry=mt[entries_sym][t.mat_id],; ),; mt[trios_sym][i],; ),; hl.range(0, n_trios),; ); }); mt = mt.drop(trios_sym). return mt._unlocalize_entries(entries_sym, cols_sym, ['id']). [docs]@typecheck(call=expr_call, pedigree=Pedigree); def mendel_errors(call, pedigree) -> Tuple[Table, Table, Table, Table]:; r""""""Find Mendel errors; count per variant, individual and nuclear family. .. include:: ../_templates/req_tstring.rst. .. include:: ../_templates/req_tvariant.rst. .. include:: ../_templates/req_biallelic.rst. Examples; --------. Find all violations of Mendelian inheritance in each (dad, mom, kid) trio in; a pedigree and return four tables (all errors, errors by family, errors by; individual, errors by variant):. >>> ped = hl.Pedigree.read('data/trios.fam'); >>> all_errors, per_fam, per_sample, per_variant = hl.mendel_errors(dataset['GT'], ped). Export all mendel errors to a text file:. >>> all_errors.export('output/all_mendel_errors.tsv'). Annotate columns with the number of Mendel errors:. >>> annotated_samples = dataset.annotate_cols(mendel=per_sample[dataset.s]). Annotate rows with the number of Mendel errors:. >>> annotated_variants = dataset.annotate_rows(mendel=per_variant[dataset.locus, dataset.alleles]). Notes; -----. The example above returns four tables, which contain Mendelian violations; grouped in various ways. These tables are modeled after the `PLINK mendel; formats <https://www.cog-genomics.org/plink2/formats#mendel>`_, resembling; the ``.mendel``, ``.fmendel``, ``.imendel``, and ``.lmendel`` formats,; respectively. **First table:** all Mendel errors. This table contains one row per Me",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:4615,Availability,error,errors,4615,"t.id][k],; proband=mt[cols_sym][t.id],; father=mt[cols_sym][t.pat_id],; mother=mt[cols_sym][t.mat_id],; is_female=t.is_female,; fam_id=t.fam_id,; ),; mt[trios_sym][i],; ),; hl.range(0, n_trios),; ); }); mt = mt.annotate(**{; entries_sym: hl.map(; lambda i: hl.bind(; lambda t: hl.struct(; proband_entry=mt[entries_sym][t.id],; father_entry=mt[entries_sym][t.pat_id],; mother_entry=mt[entries_sym][t.mat_id],; ),; mt[trios_sym][i],; ),; hl.range(0, n_trios),; ); }); mt = mt.drop(trios_sym). return mt._unlocalize_entries(entries_sym, cols_sym, ['id']). [docs]@typecheck(call=expr_call, pedigree=Pedigree); def mendel_errors(call, pedigree) -> Tuple[Table, Table, Table, Table]:; r""""""Find Mendel errors; count per variant, individual and nuclear family. .. include:: ../_templates/req_tstring.rst. .. include:: ../_templates/req_tvariant.rst. .. include:: ../_templates/req_biallelic.rst. Examples; --------. Find all violations of Mendelian inheritance in each (dad, mom, kid) trio in; a pedigree and return four tables (all errors, errors by family, errors by; individual, errors by variant):. >>> ped = hl.Pedigree.read('data/trios.fam'); >>> all_errors, per_fam, per_sample, per_variant = hl.mendel_errors(dataset['GT'], ped). Export all mendel errors to a text file:. >>> all_errors.export('output/all_mendel_errors.tsv'). Annotate columns with the number of Mendel errors:. >>> annotated_samples = dataset.annotate_cols(mendel=per_sample[dataset.s]). Annotate rows with the number of Mendel errors:. >>> annotated_variants = dataset.annotate_rows(mendel=per_variant[dataset.locus, dataset.alleles]). Notes; -----. The example above returns four tables, which contain Mendelian violations; grouped in various ways. These tables are modeled after the `PLINK mendel; formats <https://www.cog-genomics.org/plink2/formats#mendel>`_, resembling; the ``.mendel``, ``.fmendel``, ``.imendel``, and ``.lmendel`` formats,; respectively. **First table:** all Mendel errors. This table contains one row per Me",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:4789,Availability,error,errors,4789,"bda i: hl.bind(; lambda t: hl.struct(; proband_entry=mt[entries_sym][t.id],; father_entry=mt[entries_sym][t.pat_id],; mother_entry=mt[entries_sym][t.mat_id],; ),; mt[trios_sym][i],; ),; hl.range(0, n_trios),; ); }); mt = mt.drop(trios_sym). return mt._unlocalize_entries(entries_sym, cols_sym, ['id']). [docs]@typecheck(call=expr_call, pedigree=Pedigree); def mendel_errors(call, pedigree) -> Tuple[Table, Table, Table, Table]:; r""""""Find Mendel errors; count per variant, individual and nuclear family. .. include:: ../_templates/req_tstring.rst. .. include:: ../_templates/req_tvariant.rst. .. include:: ../_templates/req_biallelic.rst. Examples; --------. Find all violations of Mendelian inheritance in each (dad, mom, kid) trio in; a pedigree and return four tables (all errors, errors by family, errors by; individual, errors by variant):. >>> ped = hl.Pedigree.read('data/trios.fam'); >>> all_errors, per_fam, per_sample, per_variant = hl.mendel_errors(dataset['GT'], ped). Export all mendel errors to a text file:. >>> all_errors.export('output/all_mendel_errors.tsv'). Annotate columns with the number of Mendel errors:. >>> annotated_samples = dataset.annotate_cols(mendel=per_sample[dataset.s]). Annotate rows with the number of Mendel errors:. >>> annotated_variants = dataset.annotate_rows(mendel=per_variant[dataset.locus, dataset.alleles]). Notes; -----. The example above returns four tables, which contain Mendelian violations; grouped in various ways. These tables are modeled after the `PLINK mendel; formats <https://www.cog-genomics.org/plink2/formats#mendel>`_, resembling; the ``.mendel``, ``.fmendel``, ``.imendel``, and ``.lmendel`` formats,; respectively. **First table:** all Mendel errors. This table contains one row per Mendel; error, keyed by the variant and proband id. - `locus` (:class:`.tlocus`) -- Variant locus, key field.; - `alleles` (:class:`.tarray` of :py:data:`.tstr`) -- Variant alleles, key field.; - (column key of `dataset`) (:py:data:`.tstr`) -- Proband",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:4911,Availability,error,errors,4911,"ym][t.pat_id],; mother_entry=mt[entries_sym][t.mat_id],; ),; mt[trios_sym][i],; ),; hl.range(0, n_trios),; ); }); mt = mt.drop(trios_sym). return mt._unlocalize_entries(entries_sym, cols_sym, ['id']). [docs]@typecheck(call=expr_call, pedigree=Pedigree); def mendel_errors(call, pedigree) -> Tuple[Table, Table, Table, Table]:; r""""""Find Mendel errors; count per variant, individual and nuclear family. .. include:: ../_templates/req_tstring.rst. .. include:: ../_templates/req_tvariant.rst. .. include:: ../_templates/req_biallelic.rst. Examples; --------. Find all violations of Mendelian inheritance in each (dad, mom, kid) trio in; a pedigree and return four tables (all errors, errors by family, errors by; individual, errors by variant):. >>> ped = hl.Pedigree.read('data/trios.fam'); >>> all_errors, per_fam, per_sample, per_variant = hl.mendel_errors(dataset['GT'], ped). Export all mendel errors to a text file:. >>> all_errors.export('output/all_mendel_errors.tsv'). Annotate columns with the number of Mendel errors:. >>> annotated_samples = dataset.annotate_cols(mendel=per_sample[dataset.s]). Annotate rows with the number of Mendel errors:. >>> annotated_variants = dataset.annotate_rows(mendel=per_variant[dataset.locus, dataset.alleles]). Notes; -----. The example above returns four tables, which contain Mendelian violations; grouped in various ways. These tables are modeled after the `PLINK mendel; formats <https://www.cog-genomics.org/plink2/formats#mendel>`_, resembling; the ``.mendel``, ``.fmendel``, ``.imendel``, and ``.lmendel`` formats,; respectively. **First table:** all Mendel errors. This table contains one row per Mendel; error, keyed by the variant and proband id. - `locus` (:class:`.tlocus`) -- Variant locus, key field.; - `alleles` (:class:`.tarray` of :py:data:`.tstr`) -- Variant alleles, key field.; - (column key of `dataset`) (:py:data:`.tstr`) -- Proband ID, key field.; - `fam_id` (:py:data:`.tstr`) -- Family ID.; - `mendel_code` (:py:data:`.tint32`) -- ",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:5037,Availability,error,errors,5037,"trios_sym). return mt._unlocalize_entries(entries_sym, cols_sym, ['id']). [docs]@typecheck(call=expr_call, pedigree=Pedigree); def mendel_errors(call, pedigree) -> Tuple[Table, Table, Table, Table]:; r""""""Find Mendel errors; count per variant, individual and nuclear family. .. include:: ../_templates/req_tstring.rst. .. include:: ../_templates/req_tvariant.rst. .. include:: ../_templates/req_biallelic.rst. Examples; --------. Find all violations of Mendelian inheritance in each (dad, mom, kid) trio in; a pedigree and return four tables (all errors, errors by family, errors by; individual, errors by variant):. >>> ped = hl.Pedigree.read('data/trios.fam'); >>> all_errors, per_fam, per_sample, per_variant = hl.mendel_errors(dataset['GT'], ped). Export all mendel errors to a text file:. >>> all_errors.export('output/all_mendel_errors.tsv'). Annotate columns with the number of Mendel errors:. >>> annotated_samples = dataset.annotate_cols(mendel=per_sample[dataset.s]). Annotate rows with the number of Mendel errors:. >>> annotated_variants = dataset.annotate_rows(mendel=per_variant[dataset.locus, dataset.alleles]). Notes; -----. The example above returns four tables, which contain Mendelian violations; grouped in various ways. These tables are modeled after the `PLINK mendel; formats <https://www.cog-genomics.org/plink2/formats#mendel>`_, resembling; the ``.mendel``, ``.fmendel``, ``.imendel``, and ``.lmendel`` formats,; respectively. **First table:** all Mendel errors. This table contains one row per Mendel; error, keyed by the variant and proband id. - `locus` (:class:`.tlocus`) -- Variant locus, key field.; - `alleles` (:class:`.tarray` of :py:data:`.tstr`) -- Variant alleles, key field.; - (column key of `dataset`) (:py:data:`.tstr`) -- Proband ID, key field.; - `fam_id` (:py:data:`.tstr`) -- Family ID.; - `mendel_code` (:py:data:`.tint32`) -- Mendel error code, see below. **Second table:** errors per nuclear family. This table contains one row; per nuclear family, keye",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:5500,Availability,error,errors,5500,"ance in each (dad, mom, kid) trio in; a pedigree and return four tables (all errors, errors by family, errors by; individual, errors by variant):. >>> ped = hl.Pedigree.read('data/trios.fam'); >>> all_errors, per_fam, per_sample, per_variant = hl.mendel_errors(dataset['GT'], ped). Export all mendel errors to a text file:. >>> all_errors.export('output/all_mendel_errors.tsv'). Annotate columns with the number of Mendel errors:. >>> annotated_samples = dataset.annotate_cols(mendel=per_sample[dataset.s]). Annotate rows with the number of Mendel errors:. >>> annotated_variants = dataset.annotate_rows(mendel=per_variant[dataset.locus, dataset.alleles]). Notes; -----. The example above returns four tables, which contain Mendelian violations; grouped in various ways. These tables are modeled after the `PLINK mendel; formats <https://www.cog-genomics.org/plink2/formats#mendel>`_, resembling; the ``.mendel``, ``.fmendel``, ``.imendel``, and ``.lmendel`` formats,; respectively. **First table:** all Mendel errors. This table contains one row per Mendel; error, keyed by the variant and proband id. - `locus` (:class:`.tlocus`) -- Variant locus, key field.; - `alleles` (:class:`.tarray` of :py:data:`.tstr`) -- Variant alleles, key field.; - (column key of `dataset`) (:py:data:`.tstr`) -- Proband ID, key field.; - `fam_id` (:py:data:`.tstr`) -- Family ID.; - `mendel_code` (:py:data:`.tint32`) -- Mendel error code, see below. **Second table:** errors per nuclear family. This table contains one row; per nuclear family, keyed by the parents. - `pat_id` (:py:data:`.tstr`) -- Paternal ID. (key field); - `mat_id` (:py:data:`.tstr`) -- Maternal ID. (key field); - `fam_id` (:py:data:`.tstr`) -- Family ID.; - `children` (:py:data:`.tint32`) -- Number of children in this nuclear family.; - `errors` (:py:data:`.tint64`) -- Number of Mendel errors in this nuclear family.; - `snp_errors` (:py:data:`.tint64`) -- Number of Mendel errors at SNPs in this; nuclear family. **Third table:** errors pe",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:5548,Availability,error,error,5548,"four tables (all errors, errors by family, errors by; individual, errors by variant):. >>> ped = hl.Pedigree.read('data/trios.fam'); >>> all_errors, per_fam, per_sample, per_variant = hl.mendel_errors(dataset['GT'], ped). Export all mendel errors to a text file:. >>> all_errors.export('output/all_mendel_errors.tsv'). Annotate columns with the number of Mendel errors:. >>> annotated_samples = dataset.annotate_cols(mendel=per_sample[dataset.s]). Annotate rows with the number of Mendel errors:. >>> annotated_variants = dataset.annotate_rows(mendel=per_variant[dataset.locus, dataset.alleles]). Notes; -----. The example above returns four tables, which contain Mendelian violations; grouped in various ways. These tables are modeled after the `PLINK mendel; formats <https://www.cog-genomics.org/plink2/formats#mendel>`_, resembling; the ``.mendel``, ``.fmendel``, ``.imendel``, and ``.lmendel`` formats,; respectively. **First table:** all Mendel errors. This table contains one row per Mendel; error, keyed by the variant and proband id. - `locus` (:class:`.tlocus`) -- Variant locus, key field.; - `alleles` (:class:`.tarray` of :py:data:`.tstr`) -- Variant alleles, key field.; - (column key of `dataset`) (:py:data:`.tstr`) -- Proband ID, key field.; - `fam_id` (:py:data:`.tstr`) -- Family ID.; - `mendel_code` (:py:data:`.tint32`) -- Mendel error code, see below. **Second table:** errors per nuclear family. This table contains one row; per nuclear family, keyed by the parents. - `pat_id` (:py:data:`.tstr`) -- Paternal ID. (key field); - `mat_id` (:py:data:`.tstr`) -- Maternal ID. (key field); - `fam_id` (:py:data:`.tstr`) -- Family ID.; - `children` (:py:data:`.tint32`) -- Number of children in this nuclear family.; - `errors` (:py:data:`.tint64`) -- Number of Mendel errors in this nuclear family.; - `snp_errors` (:py:data:`.tint64`) -- Number of Mendel errors at SNPs in this; nuclear family. **Third table:** errors per individual. This table contains one row per; individual. E",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:5900,Availability,error,error,5900,"of Mendel errors:. >>> annotated_samples = dataset.annotate_cols(mendel=per_sample[dataset.s]). Annotate rows with the number of Mendel errors:. >>> annotated_variants = dataset.annotate_rows(mendel=per_variant[dataset.locus, dataset.alleles]). Notes; -----. The example above returns four tables, which contain Mendelian violations; grouped in various ways. These tables are modeled after the `PLINK mendel; formats <https://www.cog-genomics.org/plink2/formats#mendel>`_, resembling; the ``.mendel``, ``.fmendel``, ``.imendel``, and ``.lmendel`` formats,; respectively. **First table:** all Mendel errors. This table contains one row per Mendel; error, keyed by the variant and proband id. - `locus` (:class:`.tlocus`) -- Variant locus, key field.; - `alleles` (:class:`.tarray` of :py:data:`.tstr`) -- Variant alleles, key field.; - (column key of `dataset`) (:py:data:`.tstr`) -- Proband ID, key field.; - `fam_id` (:py:data:`.tstr`) -- Family ID.; - `mendel_code` (:py:data:`.tint32`) -- Mendel error code, see below. **Second table:** errors per nuclear family. This table contains one row; per nuclear family, keyed by the parents. - `pat_id` (:py:data:`.tstr`) -- Paternal ID. (key field); - `mat_id` (:py:data:`.tstr`) -- Maternal ID. (key field); - `fam_id` (:py:data:`.tstr`) -- Family ID.; - `children` (:py:data:`.tint32`) -- Number of children in this nuclear family.; - `errors` (:py:data:`.tint64`) -- Number of Mendel errors in this nuclear family.; - `snp_errors` (:py:data:`.tint64`) -- Number of Mendel errors at SNPs in this; nuclear family. **Third table:** errors per individual. This table contains one row per; individual. Each error is counted toward the proband, father, and mother; according to the `Implicated` in the table below. - (column key of `dataset`) (:py:data:`.tstr`) -- Sample ID (key field).; - `fam_id` (:py:data:`.tstr`) -- Family ID.; - `errors` (:py:data:`.tint64`) -- Number of Mendel errors involving this; individual.; - `snp_errors` (:py:data:`.tint64`)",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:5941,Availability,error,errors,5941,"dataset.annotate_cols(mendel=per_sample[dataset.s]). Annotate rows with the number of Mendel errors:. >>> annotated_variants = dataset.annotate_rows(mendel=per_variant[dataset.locus, dataset.alleles]). Notes; -----. The example above returns four tables, which contain Mendelian violations; grouped in various ways. These tables are modeled after the `PLINK mendel; formats <https://www.cog-genomics.org/plink2/formats#mendel>`_, resembling; the ``.mendel``, ``.fmendel``, ``.imendel``, and ``.lmendel`` formats,; respectively. **First table:** all Mendel errors. This table contains one row per Mendel; error, keyed by the variant and proband id. - `locus` (:class:`.tlocus`) -- Variant locus, key field.; - `alleles` (:class:`.tarray` of :py:data:`.tstr`) -- Variant alleles, key field.; - (column key of `dataset`) (:py:data:`.tstr`) -- Proband ID, key field.; - `fam_id` (:py:data:`.tstr`) -- Family ID.; - `mendel_code` (:py:data:`.tint32`) -- Mendel error code, see below. **Second table:** errors per nuclear family. This table contains one row; per nuclear family, keyed by the parents. - `pat_id` (:py:data:`.tstr`) -- Paternal ID. (key field); - `mat_id` (:py:data:`.tstr`) -- Maternal ID. (key field); - `fam_id` (:py:data:`.tstr`) -- Family ID.; - `children` (:py:data:`.tint32`) -- Number of children in this nuclear family.; - `errors` (:py:data:`.tint64`) -- Number of Mendel errors in this nuclear family.; - `snp_errors` (:py:data:`.tint64`) -- Number of Mendel errors at SNPs in this; nuclear family. **Third table:** errors per individual. This table contains one row per; individual. Each error is counted toward the proband, father, and mother; according to the `Implicated` in the table below. - (column key of `dataset`) (:py:data:`.tstr`) -- Sample ID (key field).; - `fam_id` (:py:data:`.tstr`) -- Family ID.; - `errors` (:py:data:`.tint64`) -- Number of Mendel errors involving this; individual.; - `snp_errors` (:py:data:`.tint64`) -- Number of Mendel errors involving this;",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:6286,Availability,error,errors,6286,"e `PLINK mendel; formats <https://www.cog-genomics.org/plink2/formats#mendel>`_, resembling; the ``.mendel``, ``.fmendel``, ``.imendel``, and ``.lmendel`` formats,; respectively. **First table:** all Mendel errors. This table contains one row per Mendel; error, keyed by the variant and proband id. - `locus` (:class:`.tlocus`) -- Variant locus, key field.; - `alleles` (:class:`.tarray` of :py:data:`.tstr`) -- Variant alleles, key field.; - (column key of `dataset`) (:py:data:`.tstr`) -- Proband ID, key field.; - `fam_id` (:py:data:`.tstr`) -- Family ID.; - `mendel_code` (:py:data:`.tint32`) -- Mendel error code, see below. **Second table:** errors per nuclear family. This table contains one row; per nuclear family, keyed by the parents. - `pat_id` (:py:data:`.tstr`) -- Paternal ID. (key field); - `mat_id` (:py:data:`.tstr`) -- Maternal ID. (key field); - `fam_id` (:py:data:`.tstr`) -- Family ID.; - `children` (:py:data:`.tint32`) -- Number of children in this nuclear family.; - `errors` (:py:data:`.tint64`) -- Number of Mendel errors in this nuclear family.; - `snp_errors` (:py:data:`.tint64`) -- Number of Mendel errors at SNPs in this; nuclear family. **Third table:** errors per individual. This table contains one row per; individual. Each error is counted toward the proband, father, and mother; according to the `Implicated` in the table below. - (column key of `dataset`) (:py:data:`.tstr`) -- Sample ID (key field).; - `fam_id` (:py:data:`.tstr`) -- Family ID.; - `errors` (:py:data:`.tint64`) -- Number of Mendel errors involving this; individual.; - `snp_errors` (:py:data:`.tint64`) -- Number of Mendel errors involving this; individual at SNPs. **Fourth table:** errors per variant. - `locus` (:class:`.tlocus`) -- Variant locus, key field.; - `alleles` (:class:`.tarray` of :py:data:`.tstr`) -- Variant alleles, key field.; - `errors` (:py:data:`.tint64`) -- Number of Mendel errors in this variant. This method only considers complete trios (two parents and proband with;",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:6335,Availability,error,errors,6335,"genomics.org/plink2/formats#mendel>`_, resembling; the ``.mendel``, ``.fmendel``, ``.imendel``, and ``.lmendel`` formats,; respectively. **First table:** all Mendel errors. This table contains one row per Mendel; error, keyed by the variant and proband id. - `locus` (:class:`.tlocus`) -- Variant locus, key field.; - `alleles` (:class:`.tarray` of :py:data:`.tstr`) -- Variant alleles, key field.; - (column key of `dataset`) (:py:data:`.tstr`) -- Proband ID, key field.; - `fam_id` (:py:data:`.tstr`) -- Family ID.; - `mendel_code` (:py:data:`.tint32`) -- Mendel error code, see below. **Second table:** errors per nuclear family. This table contains one row; per nuclear family, keyed by the parents. - `pat_id` (:py:data:`.tstr`) -- Paternal ID. (key field); - `mat_id` (:py:data:`.tstr`) -- Maternal ID. (key field); - `fam_id` (:py:data:`.tstr`) -- Family ID.; - `children` (:py:data:`.tint32`) -- Number of children in this nuclear family.; - `errors` (:py:data:`.tint64`) -- Number of Mendel errors in this nuclear family.; - `snp_errors` (:py:data:`.tint64`) -- Number of Mendel errors at SNPs in this; nuclear family. **Third table:** errors per individual. This table contains one row per; individual. Each error is counted toward the proband, father, and mother; according to the `Implicated` in the table below. - (column key of `dataset`) (:py:data:`.tstr`) -- Sample ID (key field).; - `fam_id` (:py:data:`.tstr`) -- Family ID.; - `errors` (:py:data:`.tint64`) -- Number of Mendel errors involving this; individual.; - `snp_errors` (:py:data:`.tint64`) -- Number of Mendel errors involving this; individual at SNPs. **Fourth table:** errors per variant. - `locus` (:class:`.tlocus`) -- Variant locus, key field.; - `alleles` (:class:`.tarray` of :py:data:`.tstr`) -- Variant alleles, key field.; - `errors` (:py:data:`.tint64`) -- Number of Mendel errors in this variant. This method only considers complete trios (two parents and proband with; defined sex). The code of each Mendel err",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:6423,Availability,error,errors,6423,"`, and ``.lmendel`` formats,; respectively. **First table:** all Mendel errors. This table contains one row per Mendel; error, keyed by the variant and proband id. - `locus` (:class:`.tlocus`) -- Variant locus, key field.; - `alleles` (:class:`.tarray` of :py:data:`.tstr`) -- Variant alleles, key field.; - (column key of `dataset`) (:py:data:`.tstr`) -- Proband ID, key field.; - `fam_id` (:py:data:`.tstr`) -- Family ID.; - `mendel_code` (:py:data:`.tint32`) -- Mendel error code, see below. **Second table:** errors per nuclear family. This table contains one row; per nuclear family, keyed by the parents. - `pat_id` (:py:data:`.tstr`) -- Paternal ID. (key field); - `mat_id` (:py:data:`.tstr`) -- Maternal ID. (key field); - `fam_id` (:py:data:`.tstr`) -- Family ID.; - `children` (:py:data:`.tint32`) -- Number of children in this nuclear family.; - `errors` (:py:data:`.tint64`) -- Number of Mendel errors in this nuclear family.; - `snp_errors` (:py:data:`.tint64`) -- Number of Mendel errors at SNPs in this; nuclear family. **Third table:** errors per individual. This table contains one row per; individual. Each error is counted toward the proband, father, and mother; according to the `Implicated` in the table below. - (column key of `dataset`) (:py:data:`.tstr`) -- Sample ID (key field).; - `fam_id` (:py:data:`.tstr`) -- Family ID.; - `errors` (:py:data:`.tint64`) -- Number of Mendel errors involving this; individual.; - `snp_errors` (:py:data:`.tint64`) -- Number of Mendel errors involving this; individual at SNPs. **Fourth table:** errors per variant. - `locus` (:class:`.tlocus`) -- Variant locus, key field.; - `alleles` (:class:`.tarray` of :py:data:`.tstr`) -- Variant alleles, key field.; - `errors` (:py:data:`.tint64`) -- Number of Mendel errors in this variant. This method only considers complete trios (two parents and proband with; defined sex). The code of each Mendel error is determined by the table; below, extending the; `Plink classification <https://www.cog-",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:6480,Availability,error,errors,6480,"ble:** all Mendel errors. This table contains one row per Mendel; error, keyed by the variant and proband id. - `locus` (:class:`.tlocus`) -- Variant locus, key field.; - `alleles` (:class:`.tarray` of :py:data:`.tstr`) -- Variant alleles, key field.; - (column key of `dataset`) (:py:data:`.tstr`) -- Proband ID, key field.; - `fam_id` (:py:data:`.tstr`) -- Family ID.; - `mendel_code` (:py:data:`.tint32`) -- Mendel error code, see below. **Second table:** errors per nuclear family. This table contains one row; per nuclear family, keyed by the parents. - `pat_id` (:py:data:`.tstr`) -- Paternal ID. (key field); - `mat_id` (:py:data:`.tstr`) -- Maternal ID. (key field); - `fam_id` (:py:data:`.tstr`) -- Family ID.; - `children` (:py:data:`.tint32`) -- Number of children in this nuclear family.; - `errors` (:py:data:`.tint64`) -- Number of Mendel errors in this nuclear family.; - `snp_errors` (:py:data:`.tint64`) -- Number of Mendel errors at SNPs in this; nuclear family. **Third table:** errors per individual. This table contains one row per; individual. Each error is counted toward the proband, father, and mother; according to the `Implicated` in the table below. - (column key of `dataset`) (:py:data:`.tstr`) -- Sample ID (key field).; - `fam_id` (:py:data:`.tstr`) -- Family ID.; - `errors` (:py:data:`.tint64`) -- Number of Mendel errors involving this; individual.; - `snp_errors` (:py:data:`.tint64`) -- Number of Mendel errors involving this; individual at SNPs. **Fourth table:** errors per variant. - `locus` (:class:`.tlocus`) -- Variant locus, key field.; - `alleles` (:class:`.tarray` of :py:data:`.tstr`) -- Variant alleles, key field.; - `errors` (:py:data:`.tint64`) -- Number of Mendel errors in this variant. This method only considers complete trios (two parents and proband with; defined sex). The code of each Mendel error is determined by the table; below, extending the; `Plink classification <https://www.cog-genomics.org/plink2/basic_stats#mendel>`__. In the tab",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:6553,Availability,error,error,6553,":class:`.tlocus`) -- Variant locus, key field.; - `alleles` (:class:`.tarray` of :py:data:`.tstr`) -- Variant alleles, key field.; - (column key of `dataset`) (:py:data:`.tstr`) -- Proband ID, key field.; - `fam_id` (:py:data:`.tstr`) -- Family ID.; - `mendel_code` (:py:data:`.tint32`) -- Mendel error code, see below. **Second table:** errors per nuclear family. This table contains one row; per nuclear family, keyed by the parents. - `pat_id` (:py:data:`.tstr`) -- Paternal ID. (key field); - `mat_id` (:py:data:`.tstr`) -- Maternal ID. (key field); - `fam_id` (:py:data:`.tstr`) -- Family ID.; - `children` (:py:data:`.tint32`) -- Number of children in this nuclear family.; - `errors` (:py:data:`.tint64`) -- Number of Mendel errors in this nuclear family.; - `snp_errors` (:py:data:`.tint64`) -- Number of Mendel errors at SNPs in this; nuclear family. **Third table:** errors per individual. This table contains one row per; individual. Each error is counted toward the proband, father, and mother; according to the `Implicated` in the table below. - (column key of `dataset`) (:py:data:`.tstr`) -- Sample ID (key field).; - `fam_id` (:py:data:`.tstr`) -- Family ID.; - `errors` (:py:data:`.tint64`) -- Number of Mendel errors involving this; individual.; - `snp_errors` (:py:data:`.tint64`) -- Number of Mendel errors involving this; individual at SNPs. **Fourth table:** errors per variant. - `locus` (:class:`.tlocus`) -- Variant locus, key field.; - `alleles` (:class:`.tarray` of :py:data:`.tstr`) -- Variant alleles, key field.; - `errors` (:py:data:`.tint64`) -- Number of Mendel errors in this variant. This method only considers complete trios (two parents and proband with; defined sex). The code of each Mendel error is determined by the table; below, extending the; `Plink classification <https://www.cog-genomics.org/plink2/basic_stats#mendel>`__. In the table, the copy state of a locus with respect to a trio is defined; as follows, where PAR is the `pseudoautosomal region; <h",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:6782,Availability,error,errors,6782,"nd ID, key field.; - `fam_id` (:py:data:`.tstr`) -- Family ID.; - `mendel_code` (:py:data:`.tint32`) -- Mendel error code, see below. **Second table:** errors per nuclear family. This table contains one row; per nuclear family, keyed by the parents. - `pat_id` (:py:data:`.tstr`) -- Paternal ID. (key field); - `mat_id` (:py:data:`.tstr`) -- Maternal ID. (key field); - `fam_id` (:py:data:`.tstr`) -- Family ID.; - `children` (:py:data:`.tint32`) -- Number of children in this nuclear family.; - `errors` (:py:data:`.tint64`) -- Number of Mendel errors in this nuclear family.; - `snp_errors` (:py:data:`.tint64`) -- Number of Mendel errors at SNPs in this; nuclear family. **Third table:** errors per individual. This table contains one row per; individual. Each error is counted toward the proband, father, and mother; according to the `Implicated` in the table below. - (column key of `dataset`) (:py:data:`.tstr`) -- Sample ID (key field).; - `fam_id` (:py:data:`.tstr`) -- Family ID.; - `errors` (:py:data:`.tint64`) -- Number of Mendel errors involving this; individual.; - `snp_errors` (:py:data:`.tint64`) -- Number of Mendel errors involving this; individual at SNPs. **Fourth table:** errors per variant. - `locus` (:class:`.tlocus`) -- Variant locus, key field.; - `alleles` (:class:`.tarray` of :py:data:`.tstr`) -- Variant alleles, key field.; - `errors` (:py:data:`.tint64`) -- Number of Mendel errors in this variant. This method only considers complete trios (two parents and proband with; defined sex). The code of each Mendel error is determined by the table; below, extending the; `Plink classification <https://www.cog-genomics.org/plink2/basic_stats#mendel>`__. In the table, the copy state of a locus with respect to a trio is defined; as follows, where PAR is the `pseudoautosomal region; <https://en.wikipedia.org/wiki/Pseudoautosomal_region>`__ (PAR) of X and Y; defined by the reference genome and the autosome is defined by; :meth:`~.LocusExpression.in_autosome`. - Auto -- ",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:6831,Availability,error,errors,6831,"tr`) -- Family ID.; - `mendel_code` (:py:data:`.tint32`) -- Mendel error code, see below. **Second table:** errors per nuclear family. This table contains one row; per nuclear family, keyed by the parents. - `pat_id` (:py:data:`.tstr`) -- Paternal ID. (key field); - `mat_id` (:py:data:`.tstr`) -- Maternal ID. (key field); - `fam_id` (:py:data:`.tstr`) -- Family ID.; - `children` (:py:data:`.tint32`) -- Number of children in this nuclear family.; - `errors` (:py:data:`.tint64`) -- Number of Mendel errors in this nuclear family.; - `snp_errors` (:py:data:`.tint64`) -- Number of Mendel errors at SNPs in this; nuclear family. **Third table:** errors per individual. This table contains one row per; individual. Each error is counted toward the proband, father, and mother; according to the `Implicated` in the table below. - (column key of `dataset`) (:py:data:`.tstr`) -- Sample ID (key field).; - `fam_id` (:py:data:`.tstr`) -- Family ID.; - `errors` (:py:data:`.tint64`) -- Number of Mendel errors involving this; individual.; - `snp_errors` (:py:data:`.tint64`) -- Number of Mendel errors involving this; individual at SNPs. **Fourth table:** errors per variant. - `locus` (:class:`.tlocus`) -- Variant locus, key field.; - `alleles` (:class:`.tarray` of :py:data:`.tstr`) -- Variant alleles, key field.; - `errors` (:py:data:`.tint64`) -- Number of Mendel errors in this variant. This method only considers complete trios (two parents and proband with; defined sex). The code of each Mendel error is determined by the table; below, extending the; `Plink classification <https://www.cog-genomics.org/plink2/basic_stats#mendel>`__. In the table, the copy state of a locus with respect to a trio is defined; as follows, where PAR is the `pseudoautosomal region; <https://en.wikipedia.org/wiki/Pseudoautosomal_region>`__ (PAR) of X and Y; defined by the reference genome and the autosome is defined by; :meth:`~.LocusExpression.in_autosome`. - Auto -- in autosome or in PAR or female child; - Hem",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:6923,Availability,error,errors,6923,"nd table:** errors per nuclear family. This table contains one row; per nuclear family, keyed by the parents. - `pat_id` (:py:data:`.tstr`) -- Paternal ID. (key field); - `mat_id` (:py:data:`.tstr`) -- Maternal ID. (key field); - `fam_id` (:py:data:`.tstr`) -- Family ID.; - `children` (:py:data:`.tint32`) -- Number of children in this nuclear family.; - `errors` (:py:data:`.tint64`) -- Number of Mendel errors in this nuclear family.; - `snp_errors` (:py:data:`.tint64`) -- Number of Mendel errors at SNPs in this; nuclear family. **Third table:** errors per individual. This table contains one row per; individual. Each error is counted toward the proband, father, and mother; according to the `Implicated` in the table below. - (column key of `dataset`) (:py:data:`.tstr`) -- Sample ID (key field).; - `fam_id` (:py:data:`.tstr`) -- Family ID.; - `errors` (:py:data:`.tint64`) -- Number of Mendel errors involving this; individual.; - `snp_errors` (:py:data:`.tint64`) -- Number of Mendel errors involving this; individual at SNPs. **Fourth table:** errors per variant. - `locus` (:class:`.tlocus`) -- Variant locus, key field.; - `alleles` (:class:`.tarray` of :py:data:`.tstr`) -- Variant alleles, key field.; - `errors` (:py:data:`.tint64`) -- Number of Mendel errors in this variant. This method only considers complete trios (two parents and proband with; defined sex). The code of each Mendel error is determined by the table; below, extending the; `Plink classification <https://www.cog-genomics.org/plink2/basic_stats#mendel>`__. In the table, the copy state of a locus with respect to a trio is defined; as follows, where PAR is the `pseudoautosomal region; <https://en.wikipedia.org/wiki/Pseudoautosomal_region>`__ (PAR) of X and Y; defined by the reference genome and the autosome is defined by; :meth:`~.LocusExpression.in_autosome`. - Auto -- in autosome or in PAR or female child; - HemiX -- in non-PAR of X and male child; - HemiY -- in non-PAR of Y and male child. `Any` refers to",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:6984,Availability,error,errors,6984,"ins one row; per nuclear family, keyed by the parents. - `pat_id` (:py:data:`.tstr`) -- Paternal ID. (key field); - `mat_id` (:py:data:`.tstr`) -- Maternal ID. (key field); - `fam_id` (:py:data:`.tstr`) -- Family ID.; - `children` (:py:data:`.tint32`) -- Number of children in this nuclear family.; - `errors` (:py:data:`.tint64`) -- Number of Mendel errors in this nuclear family.; - `snp_errors` (:py:data:`.tint64`) -- Number of Mendel errors at SNPs in this; nuclear family. **Third table:** errors per individual. This table contains one row per; individual. Each error is counted toward the proband, father, and mother; according to the `Implicated` in the table below. - (column key of `dataset`) (:py:data:`.tstr`) -- Sample ID (key field).; - `fam_id` (:py:data:`.tstr`) -- Family ID.; - `errors` (:py:data:`.tint64`) -- Number of Mendel errors involving this; individual.; - `snp_errors` (:py:data:`.tint64`) -- Number of Mendel errors involving this; individual at SNPs. **Fourth table:** errors per variant. - `locus` (:class:`.tlocus`) -- Variant locus, key field.; - `alleles` (:class:`.tarray` of :py:data:`.tstr`) -- Variant alleles, key field.; - `errors` (:py:data:`.tint64`) -- Number of Mendel errors in this variant. This method only considers complete trios (two parents and proband with; defined sex). The code of each Mendel error is determined by the table; below, extending the; `Plink classification <https://www.cog-genomics.org/plink2/basic_stats#mendel>`__. In the table, the copy state of a locus with respect to a trio is defined; as follows, where PAR is the `pseudoautosomal region; <https://en.wikipedia.org/wiki/Pseudoautosomal_region>`__ (PAR) of X and Y; defined by the reference genome and the autosome is defined by; :meth:`~.LocusExpression.in_autosome`. - Auto -- in autosome or in PAR or female child; - HemiX -- in non-PAR of X and male child; - HemiY -- in non-PAR of Y and male child. `Any` refers to the set \{ HomRef, Het, HomVar, NoCall \} and `~`; de",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:7149,Availability,error,errors,7149," - `fam_id` (:py:data:`.tstr`) -- Family ID.; - `children` (:py:data:`.tint32`) -- Number of children in this nuclear family.; - `errors` (:py:data:`.tint64`) -- Number of Mendel errors in this nuclear family.; - `snp_errors` (:py:data:`.tint64`) -- Number of Mendel errors at SNPs in this; nuclear family. **Third table:** errors per individual. This table contains one row per; individual. Each error is counted toward the proband, father, and mother; according to the `Implicated` in the table below. - (column key of `dataset`) (:py:data:`.tstr`) -- Sample ID (key field).; - `fam_id` (:py:data:`.tstr`) -- Family ID.; - `errors` (:py:data:`.tint64`) -- Number of Mendel errors involving this; individual.; - `snp_errors` (:py:data:`.tint64`) -- Number of Mendel errors involving this; individual at SNPs. **Fourth table:** errors per variant. - `locus` (:class:`.tlocus`) -- Variant locus, key field.; - `alleles` (:class:`.tarray` of :py:data:`.tstr`) -- Variant alleles, key field.; - `errors` (:py:data:`.tint64`) -- Number of Mendel errors in this variant. This method only considers complete trios (two parents and proband with; defined sex). The code of each Mendel error is determined by the table; below, extending the; `Plink classification <https://www.cog-genomics.org/plink2/basic_stats#mendel>`__. In the table, the copy state of a locus with respect to a trio is defined; as follows, where PAR is the `pseudoautosomal region; <https://en.wikipedia.org/wiki/Pseudoautosomal_region>`__ (PAR) of X and Y; defined by the reference genome and the autosome is defined by; :meth:`~.LocusExpression.in_autosome`. - Auto -- in autosome or in PAR or female child; - HemiX -- in non-PAR of X and male child; - HemiY -- in non-PAR of Y and male child. `Any` refers to the set \{ HomRef, Het, HomVar, NoCall \} and `~`; denotes complement in this set. +------+---------+---------+--------+----------------------------+; | Code | Dad | Mom | Kid | Copy State | Implicated |; +======+=========+===",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:7198,Availability,error,errors,7198,"y ID.; - `children` (:py:data:`.tint32`) -- Number of children in this nuclear family.; - `errors` (:py:data:`.tint64`) -- Number of Mendel errors in this nuclear family.; - `snp_errors` (:py:data:`.tint64`) -- Number of Mendel errors at SNPs in this; nuclear family. **Third table:** errors per individual. This table contains one row per; individual. Each error is counted toward the proband, father, and mother; according to the `Implicated` in the table below. - (column key of `dataset`) (:py:data:`.tstr`) -- Sample ID (key field).; - `fam_id` (:py:data:`.tstr`) -- Family ID.; - `errors` (:py:data:`.tint64`) -- Number of Mendel errors involving this; individual.; - `snp_errors` (:py:data:`.tint64`) -- Number of Mendel errors involving this; individual at SNPs. **Fourth table:** errors per variant. - `locus` (:class:`.tlocus`) -- Variant locus, key field.; - `alleles` (:class:`.tarray` of :py:data:`.tstr`) -- Variant alleles, key field.; - `errors` (:py:data:`.tint64`) -- Number of Mendel errors in this variant. This method only considers complete trios (two parents and proband with; defined sex). The code of each Mendel error is determined by the table; below, extending the; `Plink classification <https://www.cog-genomics.org/plink2/basic_stats#mendel>`__. In the table, the copy state of a locus with respect to a trio is defined; as follows, where PAR is the `pseudoautosomal region; <https://en.wikipedia.org/wiki/Pseudoautosomal_region>`__ (PAR) of X and Y; defined by the reference genome and the autosome is defined by; :meth:`~.LocusExpression.in_autosome`. - Auto -- in autosome or in PAR or female child; - HemiX -- in non-PAR of X and male child; - HemiY -- in non-PAR of Y and male child. `Any` refers to the set \{ HomRef, Het, HomVar, NoCall \} and `~`; denotes complement in this set. +------+---------+---------+--------+----------------------------+; | Code | Dad | Mom | Kid | Copy State | Implicated |; +======+=========+=========+========+============+=========",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:7333,Availability,error,error,7333," - `snp_errors` (:py:data:`.tint64`) -- Number of Mendel errors at SNPs in this; nuclear family. **Third table:** errors per individual. This table contains one row per; individual. Each error is counted toward the proband, father, and mother; according to the `Implicated` in the table below. - (column key of `dataset`) (:py:data:`.tstr`) -- Sample ID (key field).; - `fam_id` (:py:data:`.tstr`) -- Family ID.; - `errors` (:py:data:`.tint64`) -- Number of Mendel errors involving this; individual.; - `snp_errors` (:py:data:`.tint64`) -- Number of Mendel errors involving this; individual at SNPs. **Fourth table:** errors per variant. - `locus` (:class:`.tlocus`) -- Variant locus, key field.; - `alleles` (:class:`.tarray` of :py:data:`.tstr`) -- Variant alleles, key field.; - `errors` (:py:data:`.tint64`) -- Number of Mendel errors in this variant. This method only considers complete trios (two parents and proband with; defined sex). The code of each Mendel error is determined by the table; below, extending the; `Plink classification <https://www.cog-genomics.org/plink2/basic_stats#mendel>`__. In the table, the copy state of a locus with respect to a trio is defined; as follows, where PAR is the `pseudoautosomal region; <https://en.wikipedia.org/wiki/Pseudoautosomal_region>`__ (PAR) of X and Y; defined by the reference genome and the autosome is defined by; :meth:`~.LocusExpression.in_autosome`. - Auto -- in autosome or in PAR or female child; - HemiX -- in non-PAR of X and male child; - HemiY -- in non-PAR of Y and male child. `Any` refers to the set \{ HomRef, Het, HomVar, NoCall \} and `~`; denotes complement in this set. +------+---------+---------+--------+----------------------------+; | Code | Dad | Mom | Kid | Copy State | Implicated |; +======+=========+=========+========+============+===============+; | 1 | HomVar | HomVar | Het | Auto | Dad, Mom, Kid |; +------+---------+---------+--------+------------+---------------+; | 2 | HomRef | HomRef | Het | Auto | Dad",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:10691,Availability,error,errors,10691,"meters; ----------; dataset : :class:`.MatrixTable`; pedigree : :class:`.Pedigree`. Returns; -------; (:class:`.Table`, :class:`.Table`, :class:`.Table`, :class:`.Table`); """"""; source = call._indices.source; if not isinstance(source, MatrixTable):; raise ValueError(; ""'mendel_errors': expected 'call' to be an expression of 'MatrixTable', found {}"".format(; ""expression of '{}'"".format(source.__class__) if source is not None else 'scalar expression'; ); ). source = source.select_entries(__GT=call); dataset = require_biallelic(source, 'mendel_errors'); tm = trio_matrix(dataset, pedigree, complete_trios=True); tm = tm.select_entries(; mendel_code=hl.mendel_error_code(; tm.locus, tm.is_female, tm.father_entry['__GT'], tm.mother_entry['__GT'], tm.proband_entry['__GT']; ); ); ck_name = next(iter(source.col_key)); tm = tm.filter_entries(hl.is_defined(tm.mendel_code)); tm = tm.rename({'id': ck_name}). entries = tm.entries(). table1 = entries.select('fam_id', 'mendel_code'). t2 = tm.annotate_cols(errors=hl.agg.count(), snp_errors=hl.agg.count_where(hl.is_snp(tm.alleles[0], tm.alleles[1]))); table2 = t2.key_cols_by().cols(); table2 = table2.select(; pat_id=table2.father[ck_name],; mat_id=table2.mother[ck_name],; fam_id=table2.fam_id,; errors=table2.errors,; snp_errors=table2.snp_errors,; ); table2 = table2.group_by('pat_id', 'mat_id').aggregate(; fam_id=hl.agg.take(table2.fam_id, 1)[0],; children=hl.int32(hl.agg.count()),; errors=hl.agg.sum(table2.errors),; snp_errors=hl.agg.sum(table2.snp_errors),; ); table2 = table2.annotate(; errors=hl.or_else(table2.errors, hl.int64(0)), snp_errors=hl.or_else(table2.snp_errors, hl.int64(0)); ). # in implicated, idx 0 is dad, idx 1 is mom, idx 2 is child; implicated = hl.literal(; [; [0, 0, 0], # dummy; [1, 1, 1],; [1, 1, 1],; [1, 0, 1],; [0, 1, 1],; [0, 0, 1],; [1, 0, 1],; [0, 1, 1],; [0, 0, 1],; [0, 1, 1],; [0, 1, 1],; [1, 0, 1],; [1, 0, 1],; ],; dtype=hl.tarray(hl.tarray(hl.tint64)),; ). table3 = (; tm.annotate_cols(; all_errors=hl.or_el",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:10933,Availability,error,errors,10933,":; raise ValueError(; ""'mendel_errors': expected 'call' to be an expression of 'MatrixTable', found {}"".format(; ""expression of '{}'"".format(source.__class__) if source is not None else 'scalar expression'; ); ). source = source.select_entries(__GT=call); dataset = require_biallelic(source, 'mendel_errors'); tm = trio_matrix(dataset, pedigree, complete_trios=True); tm = tm.select_entries(; mendel_code=hl.mendel_error_code(; tm.locus, tm.is_female, tm.father_entry['__GT'], tm.mother_entry['__GT'], tm.proband_entry['__GT']; ); ); ck_name = next(iter(source.col_key)); tm = tm.filter_entries(hl.is_defined(tm.mendel_code)); tm = tm.rename({'id': ck_name}). entries = tm.entries(). table1 = entries.select('fam_id', 'mendel_code'). t2 = tm.annotate_cols(errors=hl.agg.count(), snp_errors=hl.agg.count_where(hl.is_snp(tm.alleles[0], tm.alleles[1]))); table2 = t2.key_cols_by().cols(); table2 = table2.select(; pat_id=table2.father[ck_name],; mat_id=table2.mother[ck_name],; fam_id=table2.fam_id,; errors=table2.errors,; snp_errors=table2.snp_errors,; ); table2 = table2.group_by('pat_id', 'mat_id').aggregate(; fam_id=hl.agg.take(table2.fam_id, 1)[0],; children=hl.int32(hl.agg.count()),; errors=hl.agg.sum(table2.errors),; snp_errors=hl.agg.sum(table2.snp_errors),; ); table2 = table2.annotate(; errors=hl.or_else(table2.errors, hl.int64(0)), snp_errors=hl.or_else(table2.snp_errors, hl.int64(0)); ). # in implicated, idx 0 is dad, idx 1 is mom, idx 2 is child; implicated = hl.literal(; [; [0, 0, 0], # dummy; [1, 1, 1],; [1, 1, 1],; [1, 0, 1],; [0, 1, 1],; [0, 0, 1],; [1, 0, 1],; [0, 1, 1],; [0, 0, 1],; [0, 1, 1],; [0, 1, 1],; [1, 0, 1],; [1, 0, 1],; ],; dtype=hl.tarray(hl.tarray(hl.tint64)),; ). table3 = (; tm.annotate_cols(; all_errors=hl.or_else(hl.agg.array_sum(implicated[tm.mendel_code]), [0, 0, 0]),; snp_errors=hl.or_else(; hl.agg.filter(hl.is_snp(tm.alleles[0], tm.alleles[1]), hl.agg.array_sum(implicated[tm.mendel_code])),; [0, 0, 0],; ),; ); .key_cols_by(); .cols(); ). table3 = ta",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:10947,Availability,error,errors,10947,"endel_errors': expected 'call' to be an expression of 'MatrixTable', found {}"".format(; ""expression of '{}'"".format(source.__class__) if source is not None else 'scalar expression'; ); ). source = source.select_entries(__GT=call); dataset = require_biallelic(source, 'mendel_errors'); tm = trio_matrix(dataset, pedigree, complete_trios=True); tm = tm.select_entries(; mendel_code=hl.mendel_error_code(; tm.locus, tm.is_female, tm.father_entry['__GT'], tm.mother_entry['__GT'], tm.proband_entry['__GT']; ); ); ck_name = next(iter(source.col_key)); tm = tm.filter_entries(hl.is_defined(tm.mendel_code)); tm = tm.rename({'id': ck_name}). entries = tm.entries(). table1 = entries.select('fam_id', 'mendel_code'). t2 = tm.annotate_cols(errors=hl.agg.count(), snp_errors=hl.agg.count_where(hl.is_snp(tm.alleles[0], tm.alleles[1]))); table2 = t2.key_cols_by().cols(); table2 = table2.select(; pat_id=table2.father[ck_name],; mat_id=table2.mother[ck_name],; fam_id=table2.fam_id,; errors=table2.errors,; snp_errors=table2.snp_errors,; ); table2 = table2.group_by('pat_id', 'mat_id').aggregate(; fam_id=hl.agg.take(table2.fam_id, 1)[0],; children=hl.int32(hl.agg.count()),; errors=hl.agg.sum(table2.errors),; snp_errors=hl.agg.sum(table2.snp_errors),; ); table2 = table2.annotate(; errors=hl.or_else(table2.errors, hl.int64(0)), snp_errors=hl.or_else(table2.snp_errors, hl.int64(0)); ). # in implicated, idx 0 is dad, idx 1 is mom, idx 2 is child; implicated = hl.literal(; [; [0, 0, 0], # dummy; [1, 1, 1],; [1, 1, 1],; [1, 0, 1],; [0, 1, 1],; [0, 0, 1],; [1, 0, 1],; [0, 1, 1],; [0, 0, 1],; [0, 1, 1],; [0, 1, 1],; [1, 0, 1],; [1, 0, 1],; ],; dtype=hl.tarray(hl.tarray(hl.tint64)),; ). table3 = (; tm.annotate_cols(; all_errors=hl.or_else(hl.agg.array_sum(implicated[tm.mendel_code]), [0, 0, 0]),; snp_errors=hl.or_else(; hl.agg.filter(hl.is_snp(tm.alleles[0], tm.alleles[1]), hl.agg.array_sum(implicated[tm.mendel_code])),; [0, 0, 0],; ),; ); .key_cols_by(); .cols(); ). table3 = table3.select(; xs=[; hl.st",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:11125,Availability,error,errors,11125,"alar expression'; ); ). source = source.select_entries(__GT=call); dataset = require_biallelic(source, 'mendel_errors'); tm = trio_matrix(dataset, pedigree, complete_trios=True); tm = tm.select_entries(; mendel_code=hl.mendel_error_code(; tm.locus, tm.is_female, tm.father_entry['__GT'], tm.mother_entry['__GT'], tm.proband_entry['__GT']; ); ); ck_name = next(iter(source.col_key)); tm = tm.filter_entries(hl.is_defined(tm.mendel_code)); tm = tm.rename({'id': ck_name}). entries = tm.entries(). table1 = entries.select('fam_id', 'mendel_code'). t2 = tm.annotate_cols(errors=hl.agg.count(), snp_errors=hl.agg.count_where(hl.is_snp(tm.alleles[0], tm.alleles[1]))); table2 = t2.key_cols_by().cols(); table2 = table2.select(; pat_id=table2.father[ck_name],; mat_id=table2.mother[ck_name],; fam_id=table2.fam_id,; errors=table2.errors,; snp_errors=table2.snp_errors,; ); table2 = table2.group_by('pat_id', 'mat_id').aggregate(; fam_id=hl.agg.take(table2.fam_id, 1)[0],; children=hl.int32(hl.agg.count()),; errors=hl.agg.sum(table2.errors),; snp_errors=hl.agg.sum(table2.snp_errors),; ); table2 = table2.annotate(; errors=hl.or_else(table2.errors, hl.int64(0)), snp_errors=hl.or_else(table2.snp_errors, hl.int64(0)); ). # in implicated, idx 0 is dad, idx 1 is mom, idx 2 is child; implicated = hl.literal(; [; [0, 0, 0], # dummy; [1, 1, 1],; [1, 1, 1],; [1, 0, 1],; [0, 1, 1],; [0, 0, 1],; [1, 0, 1],; [0, 1, 1],; [0, 0, 1],; [0, 1, 1],; [0, 1, 1],; [1, 0, 1],; [1, 0, 1],; ],; dtype=hl.tarray(hl.tarray(hl.tint64)),; ). table3 = (; tm.annotate_cols(; all_errors=hl.or_else(hl.agg.array_sum(implicated[tm.mendel_code]), [0, 0, 0]),; snp_errors=hl.or_else(; hl.agg.filter(hl.is_snp(tm.alleles[0], tm.alleles[1]), hl.agg.array_sum(implicated[tm.mendel_code])),; [0, 0, 0],; ),; ); .key_cols_by(); .cols(); ). table3 = table3.select(; xs=[; hl.struct(**{; ck_name: table3.father[ck_name],; 'fam_id': table3.fam_id,; 'errors': table3.all_errors[0],; 'snp_errors': table3.snp_errors[0],; }),; hl.struct(**{; ck_n",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:11150,Availability,error,errors,11150,"e.select_entries(__GT=call); dataset = require_biallelic(source, 'mendel_errors'); tm = trio_matrix(dataset, pedigree, complete_trios=True); tm = tm.select_entries(; mendel_code=hl.mendel_error_code(; tm.locus, tm.is_female, tm.father_entry['__GT'], tm.mother_entry['__GT'], tm.proband_entry['__GT']; ); ); ck_name = next(iter(source.col_key)); tm = tm.filter_entries(hl.is_defined(tm.mendel_code)); tm = tm.rename({'id': ck_name}). entries = tm.entries(). table1 = entries.select('fam_id', 'mendel_code'). t2 = tm.annotate_cols(errors=hl.agg.count(), snp_errors=hl.agg.count_where(hl.is_snp(tm.alleles[0], tm.alleles[1]))); table2 = t2.key_cols_by().cols(); table2 = table2.select(; pat_id=table2.father[ck_name],; mat_id=table2.mother[ck_name],; fam_id=table2.fam_id,; errors=table2.errors,; snp_errors=table2.snp_errors,; ); table2 = table2.group_by('pat_id', 'mat_id').aggregate(; fam_id=hl.agg.take(table2.fam_id, 1)[0],; children=hl.int32(hl.agg.count()),; errors=hl.agg.sum(table2.errors),; snp_errors=hl.agg.sum(table2.snp_errors),; ); table2 = table2.annotate(; errors=hl.or_else(table2.errors, hl.int64(0)), snp_errors=hl.or_else(table2.snp_errors, hl.int64(0)); ). # in implicated, idx 0 is dad, idx 1 is mom, idx 2 is child; implicated = hl.literal(; [; [0, 0, 0], # dummy; [1, 1, 1],; [1, 1, 1],; [1, 0, 1],; [0, 1, 1],; [0, 0, 1],; [1, 0, 1],; [0, 1, 1],; [0, 0, 1],; [0, 1, 1],; [0, 1, 1],; [1, 0, 1],; [1, 0, 1],; ],; dtype=hl.tarray(hl.tarray(hl.tint64)),; ). table3 = (; tm.annotate_cols(; all_errors=hl.or_else(hl.agg.array_sum(implicated[tm.mendel_code]), [0, 0, 0]),; snp_errors=hl.or_else(; hl.agg.filter(hl.is_snp(tm.alleles[0], tm.alleles[1]), hl.agg.array_sum(implicated[tm.mendel_code])),; [0, 0, 0],; ),; ); .key_cols_by(); .cols(); ). table3 = table3.select(; xs=[; hl.struct(**{; ck_name: table3.father[ck_name],; 'fam_id': table3.fam_id,; 'errors': table3.all_errors[0],; 'snp_errors': table3.snp_errors[0],; }),; hl.struct(**{; ck_name: table3.mother[ck_name],; 'fam_id",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:11233,Availability,error,errors,11233,"el_errors'); tm = trio_matrix(dataset, pedigree, complete_trios=True); tm = tm.select_entries(; mendel_code=hl.mendel_error_code(; tm.locus, tm.is_female, tm.father_entry['__GT'], tm.mother_entry['__GT'], tm.proband_entry['__GT']; ); ); ck_name = next(iter(source.col_key)); tm = tm.filter_entries(hl.is_defined(tm.mendel_code)); tm = tm.rename({'id': ck_name}). entries = tm.entries(). table1 = entries.select('fam_id', 'mendel_code'). t2 = tm.annotate_cols(errors=hl.agg.count(), snp_errors=hl.agg.count_where(hl.is_snp(tm.alleles[0], tm.alleles[1]))); table2 = t2.key_cols_by().cols(); table2 = table2.select(; pat_id=table2.father[ck_name],; mat_id=table2.mother[ck_name],; fam_id=table2.fam_id,; errors=table2.errors,; snp_errors=table2.snp_errors,; ); table2 = table2.group_by('pat_id', 'mat_id').aggregate(; fam_id=hl.agg.take(table2.fam_id, 1)[0],; children=hl.int32(hl.agg.count()),; errors=hl.agg.sum(table2.errors),; snp_errors=hl.agg.sum(table2.snp_errors),; ); table2 = table2.annotate(; errors=hl.or_else(table2.errors, hl.int64(0)), snp_errors=hl.or_else(table2.snp_errors, hl.int64(0)); ). # in implicated, idx 0 is dad, idx 1 is mom, idx 2 is child; implicated = hl.literal(; [; [0, 0, 0], # dummy; [1, 1, 1],; [1, 1, 1],; [1, 0, 1],; [0, 1, 1],; [0, 0, 1],; [1, 0, 1],; [0, 1, 1],; [0, 0, 1],; [0, 1, 1],; [0, 1, 1],; [1, 0, 1],; [1, 0, 1],; ],; dtype=hl.tarray(hl.tarray(hl.tint64)),; ). table3 = (; tm.annotate_cols(; all_errors=hl.or_else(hl.agg.array_sum(implicated[tm.mendel_code]), [0, 0, 0]),; snp_errors=hl.or_else(; hl.agg.filter(hl.is_snp(tm.alleles[0], tm.alleles[1]), hl.agg.array_sum(implicated[tm.mendel_code])),; [0, 0, 0],; ),; ); .key_cols_by(); .cols(); ). table3 = table3.select(; xs=[; hl.struct(**{; ck_name: table3.father[ck_name],; 'fam_id': table3.fam_id,; 'errors': table3.all_errors[0],; 'snp_errors': table3.snp_errors[0],; }),; hl.struct(**{; ck_name: table3.mother[ck_name],; 'fam_id': table3.fam_id,; 'errors': table3.all_errors[1],; 'snp_errors': table",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:11258,Availability,error,errors,11258,"ataset, pedigree, complete_trios=True); tm = tm.select_entries(; mendel_code=hl.mendel_error_code(; tm.locus, tm.is_female, tm.father_entry['__GT'], tm.mother_entry['__GT'], tm.proband_entry['__GT']; ); ); ck_name = next(iter(source.col_key)); tm = tm.filter_entries(hl.is_defined(tm.mendel_code)); tm = tm.rename({'id': ck_name}). entries = tm.entries(). table1 = entries.select('fam_id', 'mendel_code'). t2 = tm.annotate_cols(errors=hl.agg.count(), snp_errors=hl.agg.count_where(hl.is_snp(tm.alleles[0], tm.alleles[1]))); table2 = t2.key_cols_by().cols(); table2 = table2.select(; pat_id=table2.father[ck_name],; mat_id=table2.mother[ck_name],; fam_id=table2.fam_id,; errors=table2.errors,; snp_errors=table2.snp_errors,; ); table2 = table2.group_by('pat_id', 'mat_id').aggregate(; fam_id=hl.agg.take(table2.fam_id, 1)[0],; children=hl.int32(hl.agg.count()),; errors=hl.agg.sum(table2.errors),; snp_errors=hl.agg.sum(table2.snp_errors),; ); table2 = table2.annotate(; errors=hl.or_else(table2.errors, hl.int64(0)), snp_errors=hl.or_else(table2.snp_errors, hl.int64(0)); ). # in implicated, idx 0 is dad, idx 1 is mom, idx 2 is child; implicated = hl.literal(; [; [0, 0, 0], # dummy; [1, 1, 1],; [1, 1, 1],; [1, 0, 1],; [0, 1, 1],; [0, 0, 1],; [1, 0, 1],; [0, 1, 1],; [0, 0, 1],; [0, 1, 1],; [0, 1, 1],; [1, 0, 1],; [1, 0, 1],; ],; dtype=hl.tarray(hl.tarray(hl.tint64)),; ). table3 = (; tm.annotate_cols(; all_errors=hl.or_else(hl.agg.array_sum(implicated[tm.mendel_code]), [0, 0, 0]),; snp_errors=hl.or_else(; hl.agg.filter(hl.is_snp(tm.alleles[0], tm.alleles[1]), hl.agg.array_sum(implicated[tm.mendel_code])),; [0, 0, 0],; ),; ); .key_cols_by(); .cols(); ). table3 = table3.select(; xs=[; hl.struct(**{; ck_name: table3.father[ck_name],; 'fam_id': table3.fam_id,; 'errors': table3.all_errors[0],; 'snp_errors': table3.snp_errors[0],; }),; hl.struct(**{; ck_name: table3.mother[ck_name],; 'fam_id': table3.fam_id,; 'errors': table3.all_errors[1],; 'snp_errors': table3.snp_errors[1],; }),; hl.struc",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:12032,Availability,error,errors,12032,"aggregate(; fam_id=hl.agg.take(table2.fam_id, 1)[0],; children=hl.int32(hl.agg.count()),; errors=hl.agg.sum(table2.errors),; snp_errors=hl.agg.sum(table2.snp_errors),; ); table2 = table2.annotate(; errors=hl.or_else(table2.errors, hl.int64(0)), snp_errors=hl.or_else(table2.snp_errors, hl.int64(0)); ). # in implicated, idx 0 is dad, idx 1 is mom, idx 2 is child; implicated = hl.literal(; [; [0, 0, 0], # dummy; [1, 1, 1],; [1, 1, 1],; [1, 0, 1],; [0, 1, 1],; [0, 0, 1],; [1, 0, 1],; [0, 1, 1],; [0, 0, 1],; [0, 1, 1],; [0, 1, 1],; [1, 0, 1],; [1, 0, 1],; ],; dtype=hl.tarray(hl.tarray(hl.tint64)),; ). table3 = (; tm.annotate_cols(; all_errors=hl.or_else(hl.agg.array_sum(implicated[tm.mendel_code]), [0, 0, 0]),; snp_errors=hl.or_else(; hl.agg.filter(hl.is_snp(tm.alleles[0], tm.alleles[1]), hl.agg.array_sum(implicated[tm.mendel_code])),; [0, 0, 0],; ),; ); .key_cols_by(); .cols(); ). table3 = table3.select(; xs=[; hl.struct(**{; ck_name: table3.father[ck_name],; 'fam_id': table3.fam_id,; 'errors': table3.all_errors[0],; 'snp_errors': table3.snp_errors[0],; }),; hl.struct(**{; ck_name: table3.mother[ck_name],; 'fam_id': table3.fam_id,; 'errors': table3.all_errors[1],; 'snp_errors': table3.snp_errors[1],; }),; hl.struct(**{; ck_name: table3.proband[ck_name],; 'fam_id': table3.fam_id,; 'errors': table3.all_errors[2],; 'snp_errors': table3.snp_errors[2],; }),; ]; ); table3 = table3.explode('xs'); table3 = table3.select(**table3.xs); table3 = (; table3.group_by(ck_name, 'fam_id'); .aggregate(errors=hl.agg.sum(table3.errors), snp_errors=hl.agg.sum(table3.snp_errors)); .key_by(ck_name); ). table4 = tm.select_rows(errors=hl.agg.count_where(hl.is_defined(tm.mendel_code))).rows(). return table1, table2, table3, table4. [docs]@typecheck(dataset=MatrixTable, pedigree=Pedigree); def transmission_disequilibrium_test(dataset, pedigree) -> Table:; r""""""Performs the transmission disequilibrium test on trios. .. include:: ../_templates/req_tstring.rst. .. include:: ../_templates/req_tvariant",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:12182,Availability,error,errors,12182,"le2.snp_errors),; ); table2 = table2.annotate(; errors=hl.or_else(table2.errors, hl.int64(0)), snp_errors=hl.or_else(table2.snp_errors, hl.int64(0)); ). # in implicated, idx 0 is dad, idx 1 is mom, idx 2 is child; implicated = hl.literal(; [; [0, 0, 0], # dummy; [1, 1, 1],; [1, 1, 1],; [1, 0, 1],; [0, 1, 1],; [0, 0, 1],; [1, 0, 1],; [0, 1, 1],; [0, 0, 1],; [0, 1, 1],; [0, 1, 1],; [1, 0, 1],; [1, 0, 1],; ],; dtype=hl.tarray(hl.tarray(hl.tint64)),; ). table3 = (; tm.annotate_cols(; all_errors=hl.or_else(hl.agg.array_sum(implicated[tm.mendel_code]), [0, 0, 0]),; snp_errors=hl.or_else(; hl.agg.filter(hl.is_snp(tm.alleles[0], tm.alleles[1]), hl.agg.array_sum(implicated[tm.mendel_code])),; [0, 0, 0],; ),; ); .key_cols_by(); .cols(); ). table3 = table3.select(; xs=[; hl.struct(**{; ck_name: table3.father[ck_name],; 'fam_id': table3.fam_id,; 'errors': table3.all_errors[0],; 'snp_errors': table3.snp_errors[0],; }),; hl.struct(**{; ck_name: table3.mother[ck_name],; 'fam_id': table3.fam_id,; 'errors': table3.all_errors[1],; 'snp_errors': table3.snp_errors[1],; }),; hl.struct(**{; ck_name: table3.proband[ck_name],; 'fam_id': table3.fam_id,; 'errors': table3.all_errors[2],; 'snp_errors': table3.snp_errors[2],; }),; ]; ); table3 = table3.explode('xs'); table3 = table3.select(**table3.xs); table3 = (; table3.group_by(ck_name, 'fam_id'); .aggregate(errors=hl.agg.sum(table3.errors), snp_errors=hl.agg.sum(table3.snp_errors)); .key_by(ck_name); ). table4 = tm.select_rows(errors=hl.agg.count_where(hl.is_defined(tm.mendel_code))).rows(). return table1, table2, table3, table4. [docs]@typecheck(dataset=MatrixTable, pedigree=Pedigree); def transmission_disequilibrium_test(dataset, pedigree) -> Table:; r""""""Performs the transmission disequilibrium test on trios. .. include:: ../_templates/req_tstring.rst. .. include:: ../_templates/req_tvariant.rst. .. include:: ../_templates/req_biallelic.rst. Examples; --------; Compute TDT association statistics and show the first two results:. >>> pedigr",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:12333,Availability,error,errors,12333,". # in implicated, idx 0 is dad, idx 1 is mom, idx 2 is child; implicated = hl.literal(; [; [0, 0, 0], # dummy; [1, 1, 1],; [1, 1, 1],; [1, 0, 1],; [0, 1, 1],; [0, 0, 1],; [1, 0, 1],; [0, 1, 1],; [0, 0, 1],; [0, 1, 1],; [0, 1, 1],; [1, 0, 1],; [1, 0, 1],; ],; dtype=hl.tarray(hl.tarray(hl.tint64)),; ). table3 = (; tm.annotate_cols(; all_errors=hl.or_else(hl.agg.array_sum(implicated[tm.mendel_code]), [0, 0, 0]),; snp_errors=hl.or_else(; hl.agg.filter(hl.is_snp(tm.alleles[0], tm.alleles[1]), hl.agg.array_sum(implicated[tm.mendel_code])),; [0, 0, 0],; ),; ); .key_cols_by(); .cols(); ). table3 = table3.select(; xs=[; hl.struct(**{; ck_name: table3.father[ck_name],; 'fam_id': table3.fam_id,; 'errors': table3.all_errors[0],; 'snp_errors': table3.snp_errors[0],; }),; hl.struct(**{; ck_name: table3.mother[ck_name],; 'fam_id': table3.fam_id,; 'errors': table3.all_errors[1],; 'snp_errors': table3.snp_errors[1],; }),; hl.struct(**{; ck_name: table3.proband[ck_name],; 'fam_id': table3.fam_id,; 'errors': table3.all_errors[2],; 'snp_errors': table3.snp_errors[2],; }),; ]; ); table3 = table3.explode('xs'); table3 = table3.select(**table3.xs); table3 = (; table3.group_by(ck_name, 'fam_id'); .aggregate(errors=hl.agg.sum(table3.errors), snp_errors=hl.agg.sum(table3.snp_errors)); .key_by(ck_name); ). table4 = tm.select_rows(errors=hl.agg.count_where(hl.is_defined(tm.mendel_code))).rows(). return table1, table2, table3, table4. [docs]@typecheck(dataset=MatrixTable, pedigree=Pedigree); def transmission_disequilibrium_test(dataset, pedigree) -> Table:; r""""""Performs the transmission disequilibrium test on trios. .. include:: ../_templates/req_tstring.rst. .. include:: ../_templates/req_tvariant.rst. .. include:: ../_templates/req_biallelic.rst. Examples; --------; Compute TDT association statistics and show the first two results:. >>> pedigree = hl.Pedigree.read('data/tdt_trios.fam'); >>> tdt_table = hl.transmission_disequilibrium_test(tdt_dataset, pedigree); >>> tdt_table.show(2) # doctes",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:12540,Availability,error,errors,12540,"],; [0, 1, 1],; [0, 1, 1],; [1, 0, 1],; [1, 0, 1],; ],; dtype=hl.tarray(hl.tarray(hl.tint64)),; ). table3 = (; tm.annotate_cols(; all_errors=hl.or_else(hl.agg.array_sum(implicated[tm.mendel_code]), [0, 0, 0]),; snp_errors=hl.or_else(; hl.agg.filter(hl.is_snp(tm.alleles[0], tm.alleles[1]), hl.agg.array_sum(implicated[tm.mendel_code])),; [0, 0, 0],; ),; ); .key_cols_by(); .cols(); ). table3 = table3.select(; xs=[; hl.struct(**{; ck_name: table3.father[ck_name],; 'fam_id': table3.fam_id,; 'errors': table3.all_errors[0],; 'snp_errors': table3.snp_errors[0],; }),; hl.struct(**{; ck_name: table3.mother[ck_name],; 'fam_id': table3.fam_id,; 'errors': table3.all_errors[1],; 'snp_errors': table3.snp_errors[1],; }),; hl.struct(**{; ck_name: table3.proband[ck_name],; 'fam_id': table3.fam_id,; 'errors': table3.all_errors[2],; 'snp_errors': table3.snp_errors[2],; }),; ]; ); table3 = table3.explode('xs'); table3 = table3.select(**table3.xs); table3 = (; table3.group_by(ck_name, 'fam_id'); .aggregate(errors=hl.agg.sum(table3.errors), snp_errors=hl.agg.sum(table3.snp_errors)); .key_by(ck_name); ). table4 = tm.select_rows(errors=hl.agg.count_where(hl.is_defined(tm.mendel_code))).rows(). return table1, table2, table3, table4. [docs]@typecheck(dataset=MatrixTable, pedigree=Pedigree); def transmission_disequilibrium_test(dataset, pedigree) -> Table:; r""""""Performs the transmission disequilibrium test on trios. .. include:: ../_templates/req_tstring.rst. .. include:: ../_templates/req_tvariant.rst. .. include:: ../_templates/req_biallelic.rst. Examples; --------; Compute TDT association statistics and show the first two results:. >>> pedigree = hl.Pedigree.read('data/tdt_trios.fam'); >>> tdt_table = hl.transmission_disequilibrium_test(tdt_dataset, pedigree); >>> tdt_table.show(2) # doctest: +SKIP_OUTPUT_CHECK; +---------------+------------+-------+-------+----------+----------+; | locus | alleles | t | u | chi_sq | p_value |; +---------------+------------+-------+-------+----------+------",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:12565,Availability,error,errors,12565,"],; [1, 0, 1],; ],; dtype=hl.tarray(hl.tarray(hl.tint64)),; ). table3 = (; tm.annotate_cols(; all_errors=hl.or_else(hl.agg.array_sum(implicated[tm.mendel_code]), [0, 0, 0]),; snp_errors=hl.or_else(; hl.agg.filter(hl.is_snp(tm.alleles[0], tm.alleles[1]), hl.agg.array_sum(implicated[tm.mendel_code])),; [0, 0, 0],; ),; ); .key_cols_by(); .cols(); ). table3 = table3.select(; xs=[; hl.struct(**{; ck_name: table3.father[ck_name],; 'fam_id': table3.fam_id,; 'errors': table3.all_errors[0],; 'snp_errors': table3.snp_errors[0],; }),; hl.struct(**{; ck_name: table3.mother[ck_name],; 'fam_id': table3.fam_id,; 'errors': table3.all_errors[1],; 'snp_errors': table3.snp_errors[1],; }),; hl.struct(**{; ck_name: table3.proband[ck_name],; 'fam_id': table3.fam_id,; 'errors': table3.all_errors[2],; 'snp_errors': table3.snp_errors[2],; }),; ]; ); table3 = table3.explode('xs'); table3 = table3.select(**table3.xs); table3 = (; table3.group_by(ck_name, 'fam_id'); .aggregate(errors=hl.agg.sum(table3.errors), snp_errors=hl.agg.sum(table3.snp_errors)); .key_by(ck_name); ). table4 = tm.select_rows(errors=hl.agg.count_where(hl.is_defined(tm.mendel_code))).rows(). return table1, table2, table3, table4. [docs]@typecheck(dataset=MatrixTable, pedigree=Pedigree); def transmission_disequilibrium_test(dataset, pedigree) -> Table:; r""""""Performs the transmission disequilibrium test on trios. .. include:: ../_templates/req_tstring.rst. .. include:: ../_templates/req_tvariant.rst. .. include:: ../_templates/req_biallelic.rst. Examples; --------; Compute TDT association statistics and show the first two results:. >>> pedigree = hl.Pedigree.read('data/tdt_trios.fam'); >>> tdt_table = hl.transmission_disequilibrium_test(tdt_dataset, pedigree); >>> tdt_table.show(2) # doctest: +SKIP_OUTPUT_CHECK; +---------------+------------+-------+-------+----------+----------+; | locus | alleles | t | u | chi_sq | p_value |; +---------------+------------+-------+-------+----------+----------+; | locus<GRCh37> | array<str> |",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:12662,Availability,error,errors,12662,"e_cols(; all_errors=hl.or_else(hl.agg.array_sum(implicated[tm.mendel_code]), [0, 0, 0]),; snp_errors=hl.or_else(; hl.agg.filter(hl.is_snp(tm.alleles[0], tm.alleles[1]), hl.agg.array_sum(implicated[tm.mendel_code])),; [0, 0, 0],; ),; ); .key_cols_by(); .cols(); ). table3 = table3.select(; xs=[; hl.struct(**{; ck_name: table3.father[ck_name],; 'fam_id': table3.fam_id,; 'errors': table3.all_errors[0],; 'snp_errors': table3.snp_errors[0],; }),; hl.struct(**{; ck_name: table3.mother[ck_name],; 'fam_id': table3.fam_id,; 'errors': table3.all_errors[1],; 'snp_errors': table3.snp_errors[1],; }),; hl.struct(**{; ck_name: table3.proband[ck_name],; 'fam_id': table3.fam_id,; 'errors': table3.all_errors[2],; 'snp_errors': table3.snp_errors[2],; }),; ]; ); table3 = table3.explode('xs'); table3 = table3.select(**table3.xs); table3 = (; table3.group_by(ck_name, 'fam_id'); .aggregate(errors=hl.agg.sum(table3.errors), snp_errors=hl.agg.sum(table3.snp_errors)); .key_by(ck_name); ). table4 = tm.select_rows(errors=hl.agg.count_where(hl.is_defined(tm.mendel_code))).rows(). return table1, table2, table3, table4. [docs]@typecheck(dataset=MatrixTable, pedigree=Pedigree); def transmission_disequilibrium_test(dataset, pedigree) -> Table:; r""""""Performs the transmission disequilibrium test on trios. .. include:: ../_templates/req_tstring.rst. .. include:: ../_templates/req_tvariant.rst. .. include:: ../_templates/req_biallelic.rst. Examples; --------; Compute TDT association statistics and show the first two results:. >>> pedigree = hl.Pedigree.read('data/tdt_trios.fam'); >>> tdt_table = hl.transmission_disequilibrium_test(tdt_dataset, pedigree); >>> tdt_table.show(2) # doctest: +SKIP_OUTPUT_CHECK; +---------------+------------+-------+-------+----------+----------+; | locus | alleles | t | u | chi_sq | p_value |; +---------------+------------+-------+-------+----------+----------+; | locus<GRCh37> | array<str> | int64 | int64 | float64 | float64 |; +---------------+------------+-------+-------+",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:14960,Availability,error,errors,14960,"tdt_table = tdt_table.filter(tdt_table.p_value < 0.001); >>> tdt_table.export(f""output/tdt_results.tsv""). Notes; -----; The; `transmission disequilibrium test <https://en.wikipedia.org/wiki/Transmission_disequilibrium_test#The_case_of_trios:_one_affected_child_per_family>`__; compares the number of times the alternate allele is transmitted (t) versus; not transmitted (u) from a heterozgyous parent to an affected child. The null; hypothesis holds that each case is equally likely. The TDT statistic is given by. .. math::. (t - u)^2 \over (t + u). and asymptotically follows a chi-squared distribution with one degree of; freedom under the null hypothesis. :func:`transmission_disequilibrium_test` only considers complete trios (two; parents and a proband with defined sex) and only returns results for the; autosome, as defined by :meth:`~.LocusExpression.in_autosome`, and; chromosome X. Transmissions and non-transmissions are counted only for the; configurations of genotypes and copy state in the table below, in order to; filter out Mendel errors and configurations where transmission is; guaranteed. The copy state of a locus with respect to a trio is defined as; follows:. - Auto -- in autosome or in PAR of X or female child; - HemiX -- in non-PAR of X and male child. Here PAR is the `pseudoautosomal region; <https://en.wikipedia.org/wiki/Pseudoautosomal_region>`__; of X and Y defined by :class:`.ReferenceGenome`, which many variant callers; map to chromosome X. +--------+--------+--------+------------+---+---+; | Kid | Dad | Mom | Copy State | t | u |; +========+========+========+============+===+===+; | HomRef | Het | Het | Auto | 0 | 2 |; +--------+--------+--------+------------+---+---+; | HomRef | HomRef | Het | Auto | 0 | 1 |; +--------+--------+--------+------------+---+---+; | HomRef | Het | HomRef | Auto | 0 | 1 |; +--------+--------+--------+------------+---+---+; | Het | Het | Het | Auto | 1 | 1 |; +--------+--------+--------+------------+---+---+; | Het | HomRef ",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:18631,Availability,error,error,18631,"nnotate_rows(auto_or_x_par=dataset.locus.in_autosome() | dataset.locus.in_x_par()); dataset = dataset.filter_rows(dataset.auto_or_x_par | dataset.locus.in_x_nonpar()). hom_ref = 0; het = 1; hom_var = 2. auto = 2; hemi_x = 1. # kid, dad, mom, copy, t, u; config_counts = [; (hom_ref, het, het, auto, 0, 2),; (hom_ref, hom_ref, het, auto, 0, 1),; (hom_ref, het, hom_ref, auto, 0, 1),; (het, het, het, auto, 1, 1),; (het, hom_ref, het, auto, 1, 0),; (het, het, hom_ref, auto, 1, 0),; (het, hom_var, het, auto, 0, 1),; (het, het, hom_var, auto, 0, 1),; (hom_var, het, het, auto, 2, 0),; (hom_var, het, hom_var, auto, 1, 0),; (hom_var, hom_var, het, auto, 1, 0),; (hom_ref, hom_ref, het, hemi_x, 0, 1),; (hom_ref, hom_var, het, hemi_x, 0, 1),; (hom_var, hom_ref, het, hemi_x, 1, 0),; (hom_var, hom_var, het, hemi_x, 1, 0),; ]. count_map = hl.literal({(c[0], c[1], c[2], c[3]): [c[4], c[5]] for c in config_counts}). tri = trio_matrix(dataset, pedigree, complete_trios=True). # this filter removes mendel error of het father in x_nonpar. It also avoids; # building and looking up config in common case that neither parent is het; father_is_het = tri.father_entry.GT.is_het(); parent_is_valid_het = (father_is_het & tri.auto_or_x_par) | (tri.mother_entry.GT.is_het() & ~father_is_het). copy_state = hl.if_else(tri.auto_or_x_par | tri.is_female, 2, 1). config = (; tri.proband_entry.GT.n_alt_alleles(),; tri.father_entry.GT.n_alt_alleles(),; tri.mother_entry.GT.n_alt_alleles(),; copy_state,; ). tri = tri.annotate_rows(counts=agg.filter(parent_is_valid_het, agg.array_sum(count_map.get(config)))). tab = tri.rows().select('counts'); tab = tab.transmute(t=tab.counts[0], u=tab.counts[1]); tab = tab.annotate(chi_sq=((tab.t - tab.u) ** 2) / (tab.t + tab.u)); tab = tab.annotate(p_value=hl.pchisqtail(tab.chi_sq, 1.0)). return tab.cache(). [docs]@typecheck(; mt=MatrixTable,; pedigree=Pedigree,; pop_frequency_prior=expr_float64,; min_gq=int,; min_p=numeric,; max_parent_ab=numeric,; min_child_ab=numeric,; min",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:24688,Availability,error,error,24688,"}(x_{\mathrm{mother}} = AA \mid \mathrm{mother} = AA) \\; {} \cdot {} &\mathrm{P}(x_{\mathrm{proband}} = AB \mid \mathrm{proband} = AB); \end{aligned}; \right). .. math::; \begin{aligned}; \mathrm{P}(x = (AA, AA, AB) \mid m) = &\left(; \begin{aligned}; &\mathrm{P}(x_{\mathrm{father}} = AA \mid \mathrm{father} = AB); \cdot \mathrm{P}(x_{\mathrm{mother}} = AA \mid \mathrm{mother} = AA) \\; {} + {} &\mathrm{P}(x_{\mathrm{father}} = AA \mid \mathrm{father} = AA); \cdot \mathrm{P}(x_{\mathrm{mother}} = AA \mid \mathrm{mother} = AB); \end{aligned}; \right) \\; &{} \cdot \mathrm{P}(x_{\mathrm{proband}} = AB \mid \mathrm{proband} = AB); \end{aligned}. (Technically, the second factorization assumes there is exactly (rather; than at least) one alternate allele among the parents, which may be; justified on the grounds that it is typically the most likely case by far.). While this posterior probability is a good metric for grouping putative de; novo mutations by validation likelihood, there exist error modes in; high-throughput sequencing data that are not appropriately accounted for by; the phred-scaled genotype likelihoods. To this end, a number of hard filters; are applied in order to assign validation likelihood. These filters are different for SNPs and insertions/deletions. In the below; rules, the following variables are used:. - ``DR`` refers to the ratio of the read depth in the proband to the; combined read depth in the parents.; - ``DP`` refers to the read depth (DP field) of the proband.; - ``AB`` refers to the read allele balance of the proband (number of; alternate reads divided by total reads).; - ``AC`` refers to the count of alternate alleles across all individuals; in the dataset at the site.; - ``p`` refers to :math:`\mathrm{P_{\text{de novo}}}`.; - ``min_p`` refers to the `min_p` function parameter. HIGH-quality SNV:. .. code-block:: text. (p > 0.99) AND (AB > 0.3) AND (AC == 1); OR; (p > 0.99) AND (AB > 0.3) AND (DR > 0.2); OR; (p > 0.5) AND (AB > 0.3) AND (A",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:29286,Availability,failure,failure,29286,"R),; ); else:; n_alt_alleles = hl.agg.sum(mt.GT.n_alt_alleles()); total_alleles = 2 * hl.agg.sum(hl.is_defined(mt.GT)); # subtract 1 from __alt_alleles to correct for the observed genotype; mt = mt.annotate_rows(; __prior=pop_frequency_prior,; __alt_alleles=n_alt_alleles,; __site_freq=hl.max((n_alt_alleles - 1) / total_alleles, pop_frequency_prior, MIN_POP_PRIOR),; ). mt = require_biallelic(mt, 'de_novo'). tm = trio_matrix(mt, pedigree, complete_trios=True). autosomal = tm.locus.in_autosome_or_par() | (tm.locus.in_x_nonpar() & tm.is_female); hemi_x = tm.locus.in_x_nonpar() & ~tm.is_female; hemi_y = tm.locus.in_y_nonpar() & ~tm.is_female; hemi_mt = tm.locus.in_mito() & tm.is_female. is_snp = hl.is_snp(tm.alleles[0], tm.alleles[1]); n_alt_alleles = tm.__alt_alleles; prior = tm.__site_freq; het_hom_hom = tm.proband_entry.GT.is_het() & tm.father_entry.GT.is_hom_ref() & tm.mother_entry.GT.is_hom_ref(); kid_ad_fail = tm.proband_entry.AD[1] / hl.sum(tm.proband_entry.AD) < min_child_ab. failure = hl.missing(hl.tstruct(p_de_novo=hl.tfloat64, confidence=hl.tstr)). kid = tm.proband_entry; dad = tm.father_entry; mom = tm.mother_entry. kid_linear_pl = 10 ** (-kid.PL / 10); kid_pp = hl.bind(lambda x: x / hl.sum(x), kid_linear_pl). dad_linear_pl = 10 ** (-dad.PL / 10); dad_pp = hl.bind(lambda x: x / hl.sum(x), dad_linear_pl). mom_linear_pl = 10 ** (-mom.PL / 10); mom_pp = hl.bind(lambda x: x / hl.sum(x), mom_linear_pl). kid_ad_ratio = kid.AD[1] / hl.sum(kid.AD); dp_ratio = kid.DP / (dad.DP + mom.DP). def call_auto(kid_pp, dad_pp, mom_pp, kid_ad_ratio):; p_data_given_dn = dad_pp[0] * mom_pp[0] * kid_pp[1] * DE_NOVO_PRIOR; p_het_in_parent = 1 - (1 - prior) ** 4; p_data_given_missed_het = (dad_pp[1] * mom_pp[0] + dad_pp[0] * mom_pp[1]) * kid_pp[1] * p_het_in_parent; p_de_novo = p_data_given_dn / (p_data_given_dn + p_data_given_missed_het). def solve(p_de_novo):; return (; hl.case(); .when(kid.GQ < min_gq, failure); .when((kid.DP / (dad.DP + mom.DP) < min_dp_ratio) | ~(kid_ad_ratio >=",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:30213,Availability,failure,failure,30213,"il = tm.proband_entry.AD[1] / hl.sum(tm.proband_entry.AD) < min_child_ab. failure = hl.missing(hl.tstruct(p_de_novo=hl.tfloat64, confidence=hl.tstr)). kid = tm.proband_entry; dad = tm.father_entry; mom = tm.mother_entry. kid_linear_pl = 10 ** (-kid.PL / 10); kid_pp = hl.bind(lambda x: x / hl.sum(x), kid_linear_pl). dad_linear_pl = 10 ** (-dad.PL / 10); dad_pp = hl.bind(lambda x: x / hl.sum(x), dad_linear_pl). mom_linear_pl = 10 ** (-mom.PL / 10); mom_pp = hl.bind(lambda x: x / hl.sum(x), mom_linear_pl). kid_ad_ratio = kid.AD[1] / hl.sum(kid.AD); dp_ratio = kid.DP / (dad.DP + mom.DP). def call_auto(kid_pp, dad_pp, mom_pp, kid_ad_ratio):; p_data_given_dn = dad_pp[0] * mom_pp[0] * kid_pp[1] * DE_NOVO_PRIOR; p_het_in_parent = 1 - (1 - prior) ** 4; p_data_given_missed_het = (dad_pp[1] * mom_pp[0] + dad_pp[0] * mom_pp[1]) * kid_pp[1] * p_het_in_parent; p_de_novo = p_data_given_dn / (p_data_given_dn + p_data_given_missed_het). def solve(p_de_novo):; return (; hl.case(); .when(kid.GQ < min_gq, failure); .when((kid.DP / (dad.DP + mom.DP) < min_dp_ratio) | ~(kid_ad_ratio >= min_child_ab), failure); .when((hl.sum(mom.AD) == 0) | (hl.sum(dad.AD) == 0), failure); .when(; (mom.AD[1] / hl.sum(mom.AD) > max_parent_ab) | (dad.AD[1] / hl.sum(dad.AD) > max_parent_ab), failure; ); .when(p_de_novo < min_p, failure); .when(; ~is_snp,; hl.case(); .when(; (p_de_novo > 0.99) & (kid_ad_ratio > 0.3) & (n_alt_alleles == 1),; hl.struct(p_de_novo=p_de_novo, confidence='HIGH'),; ); .when(; (p_de_novo > 0.5) & (kid_ad_ratio > 0.3) & (n_alt_alleles <= 5),; hl.struct(p_de_novo=p_de_novo, confidence='MEDIUM'),; ); .when(kid_ad_ratio > 0.2, hl.struct(p_de_novo=p_de_novo, confidence='LOW')); .or_missing(),; ); .default(; hl.case(); .when(; ((p_de_novo > 0.99) & (kid_ad_ratio > 0.3) & (dp_ratio > 0.2)); | ((p_de_novo > 0.99) & (kid_ad_ratio > 0.3) & (n_alt_alleles == 1)); | ((p_de_novo > 0.5) & (kid_ad_ratio > 0.3) & (n_alt_alleles < 10) & (kid.DP > 10)),; hl.struct(p_de_novo=p_de_novo, confidence='HIGH",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:30308,Availability,failure,failure,30308,"failure = hl.missing(hl.tstruct(p_de_novo=hl.tfloat64, confidence=hl.tstr)). kid = tm.proband_entry; dad = tm.father_entry; mom = tm.mother_entry. kid_linear_pl = 10 ** (-kid.PL / 10); kid_pp = hl.bind(lambda x: x / hl.sum(x), kid_linear_pl). dad_linear_pl = 10 ** (-dad.PL / 10); dad_pp = hl.bind(lambda x: x / hl.sum(x), dad_linear_pl). mom_linear_pl = 10 ** (-mom.PL / 10); mom_pp = hl.bind(lambda x: x / hl.sum(x), mom_linear_pl). kid_ad_ratio = kid.AD[1] / hl.sum(kid.AD); dp_ratio = kid.DP / (dad.DP + mom.DP). def call_auto(kid_pp, dad_pp, mom_pp, kid_ad_ratio):; p_data_given_dn = dad_pp[0] * mom_pp[0] * kid_pp[1] * DE_NOVO_PRIOR; p_het_in_parent = 1 - (1 - prior) ** 4; p_data_given_missed_het = (dad_pp[1] * mom_pp[0] + dad_pp[0] * mom_pp[1]) * kid_pp[1] * p_het_in_parent; p_de_novo = p_data_given_dn / (p_data_given_dn + p_data_given_missed_het). def solve(p_de_novo):; return (; hl.case(); .when(kid.GQ < min_gq, failure); .when((kid.DP / (dad.DP + mom.DP) < min_dp_ratio) | ~(kid_ad_ratio >= min_child_ab), failure); .when((hl.sum(mom.AD) == 0) | (hl.sum(dad.AD) == 0), failure); .when(; (mom.AD[1] / hl.sum(mom.AD) > max_parent_ab) | (dad.AD[1] / hl.sum(dad.AD) > max_parent_ab), failure; ); .when(p_de_novo < min_p, failure); .when(; ~is_snp,; hl.case(); .when(; (p_de_novo > 0.99) & (kid_ad_ratio > 0.3) & (n_alt_alleles == 1),; hl.struct(p_de_novo=p_de_novo, confidence='HIGH'),; ); .when(; (p_de_novo > 0.5) & (kid_ad_ratio > 0.3) & (n_alt_alleles <= 5),; hl.struct(p_de_novo=p_de_novo, confidence='MEDIUM'),; ); .when(kid_ad_ratio > 0.2, hl.struct(p_de_novo=p_de_novo, confidence='LOW')); .or_missing(),; ); .default(; hl.case(); .when(; ((p_de_novo > 0.99) & (kid_ad_ratio > 0.3) & (dp_ratio > 0.2)); | ((p_de_novo > 0.99) & (kid_ad_ratio > 0.3) & (n_alt_alleles == 1)); | ((p_de_novo > 0.5) & (kid_ad_ratio > 0.3) & (n_alt_alleles < 10) & (kid.DP > 10)),; hl.struct(p_de_novo=p_de_novo, confidence='HIGH'),; ); .when(; (p_de_novo > 0.5) & ((kid_ad_ratio > 0.3) | (n_alt_alleles",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:30371,Availability,failure,failure,30371,".proband_entry; dad = tm.father_entry; mom = tm.mother_entry. kid_linear_pl = 10 ** (-kid.PL / 10); kid_pp = hl.bind(lambda x: x / hl.sum(x), kid_linear_pl). dad_linear_pl = 10 ** (-dad.PL / 10); dad_pp = hl.bind(lambda x: x / hl.sum(x), dad_linear_pl). mom_linear_pl = 10 ** (-mom.PL / 10); mom_pp = hl.bind(lambda x: x / hl.sum(x), mom_linear_pl). kid_ad_ratio = kid.AD[1] / hl.sum(kid.AD); dp_ratio = kid.DP / (dad.DP + mom.DP). def call_auto(kid_pp, dad_pp, mom_pp, kid_ad_ratio):; p_data_given_dn = dad_pp[0] * mom_pp[0] * kid_pp[1] * DE_NOVO_PRIOR; p_het_in_parent = 1 - (1 - prior) ** 4; p_data_given_missed_het = (dad_pp[1] * mom_pp[0] + dad_pp[0] * mom_pp[1]) * kid_pp[1] * p_het_in_parent; p_de_novo = p_data_given_dn / (p_data_given_dn + p_data_given_missed_het). def solve(p_de_novo):; return (; hl.case(); .when(kid.GQ < min_gq, failure); .when((kid.DP / (dad.DP + mom.DP) < min_dp_ratio) | ~(kid_ad_ratio >= min_child_ab), failure); .when((hl.sum(mom.AD) == 0) | (hl.sum(dad.AD) == 0), failure); .when(; (mom.AD[1] / hl.sum(mom.AD) > max_parent_ab) | (dad.AD[1] / hl.sum(dad.AD) > max_parent_ab), failure; ); .when(p_de_novo < min_p, failure); .when(; ~is_snp,; hl.case(); .when(; (p_de_novo > 0.99) & (kid_ad_ratio > 0.3) & (n_alt_alleles == 1),; hl.struct(p_de_novo=p_de_novo, confidence='HIGH'),; ); .when(; (p_de_novo > 0.5) & (kid_ad_ratio > 0.3) & (n_alt_alleles <= 5),; hl.struct(p_de_novo=p_de_novo, confidence='MEDIUM'),; ); .when(kid_ad_ratio > 0.2, hl.struct(p_de_novo=p_de_novo, confidence='LOW')); .or_missing(),; ); .default(; hl.case(); .when(; ((p_de_novo > 0.99) & (kid_ad_ratio > 0.3) & (dp_ratio > 0.2)); | ((p_de_novo > 0.99) & (kid_ad_ratio > 0.3) & (n_alt_alleles == 1)); | ((p_de_novo > 0.5) & (kid_ad_ratio > 0.3) & (n_alt_alleles < 10) & (kid.DP > 10)),; hl.struct(p_de_novo=p_de_novo, confidence='HIGH'),; ); .when(; (p_de_novo > 0.5) & ((kid_ad_ratio > 0.3) | (n_alt_alleles == 1)),; hl.struct(p_de_novo=p_de_novo, confidence='MEDIUM'),; ); .when(kid_ad_ratio",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:30482,Availability,failure,failure,30482," = hl.bind(lambda x: x / hl.sum(x), kid_linear_pl). dad_linear_pl = 10 ** (-dad.PL / 10); dad_pp = hl.bind(lambda x: x / hl.sum(x), dad_linear_pl). mom_linear_pl = 10 ** (-mom.PL / 10); mom_pp = hl.bind(lambda x: x / hl.sum(x), mom_linear_pl). kid_ad_ratio = kid.AD[1] / hl.sum(kid.AD); dp_ratio = kid.DP / (dad.DP + mom.DP). def call_auto(kid_pp, dad_pp, mom_pp, kid_ad_ratio):; p_data_given_dn = dad_pp[0] * mom_pp[0] * kid_pp[1] * DE_NOVO_PRIOR; p_het_in_parent = 1 - (1 - prior) ** 4; p_data_given_missed_het = (dad_pp[1] * mom_pp[0] + dad_pp[0] * mom_pp[1]) * kid_pp[1] * p_het_in_parent; p_de_novo = p_data_given_dn / (p_data_given_dn + p_data_given_missed_het). def solve(p_de_novo):; return (; hl.case(); .when(kid.GQ < min_gq, failure); .when((kid.DP / (dad.DP + mom.DP) < min_dp_ratio) | ~(kid_ad_ratio >= min_child_ab), failure); .when((hl.sum(mom.AD) == 0) | (hl.sum(dad.AD) == 0), failure); .when(; (mom.AD[1] / hl.sum(mom.AD) > max_parent_ab) | (dad.AD[1] / hl.sum(dad.AD) > max_parent_ab), failure; ); .when(p_de_novo < min_p, failure); .when(; ~is_snp,; hl.case(); .when(; (p_de_novo > 0.99) & (kid_ad_ratio > 0.3) & (n_alt_alleles == 1),; hl.struct(p_de_novo=p_de_novo, confidence='HIGH'),; ); .when(; (p_de_novo > 0.5) & (kid_ad_ratio > 0.3) & (n_alt_alleles <= 5),; hl.struct(p_de_novo=p_de_novo, confidence='MEDIUM'),; ); .when(kid_ad_ratio > 0.2, hl.struct(p_de_novo=p_de_novo, confidence='LOW')); .or_missing(),; ); .default(; hl.case(); .when(; ((p_de_novo > 0.99) & (kid_ad_ratio > 0.3) & (dp_ratio > 0.2)); | ((p_de_novo > 0.99) & (kid_ad_ratio > 0.3) & (n_alt_alleles == 1)); | ((p_de_novo > 0.5) & (kid_ad_ratio > 0.3) & (n_alt_alleles < 10) & (kid.DP > 10)),; hl.struct(p_de_novo=p_de_novo, confidence='HIGH'),; ); .when(; (p_de_novo > 0.5) & ((kid_ad_ratio > 0.3) | (n_alt_alleles == 1)),; hl.struct(p_de_novo=p_de_novo, confidence='MEDIUM'),; ); .when(kid_ad_ratio > 0.2, hl.struct(p_de_novo=p_de_novo, confidence='LOW')); .or_missing(); ); ). return hl.bind(solve, p_de_",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:30519,Availability,failure,failure,30519," kid_linear_pl). dad_linear_pl = 10 ** (-dad.PL / 10); dad_pp = hl.bind(lambda x: x / hl.sum(x), dad_linear_pl). mom_linear_pl = 10 ** (-mom.PL / 10); mom_pp = hl.bind(lambda x: x / hl.sum(x), mom_linear_pl). kid_ad_ratio = kid.AD[1] / hl.sum(kid.AD); dp_ratio = kid.DP / (dad.DP + mom.DP). def call_auto(kid_pp, dad_pp, mom_pp, kid_ad_ratio):; p_data_given_dn = dad_pp[0] * mom_pp[0] * kid_pp[1] * DE_NOVO_PRIOR; p_het_in_parent = 1 - (1 - prior) ** 4; p_data_given_missed_het = (dad_pp[1] * mom_pp[0] + dad_pp[0] * mom_pp[1]) * kid_pp[1] * p_het_in_parent; p_de_novo = p_data_given_dn / (p_data_given_dn + p_data_given_missed_het). def solve(p_de_novo):; return (; hl.case(); .when(kid.GQ < min_gq, failure); .when((kid.DP / (dad.DP + mom.DP) < min_dp_ratio) | ~(kid_ad_ratio >= min_child_ab), failure); .when((hl.sum(mom.AD) == 0) | (hl.sum(dad.AD) == 0), failure); .when(; (mom.AD[1] / hl.sum(mom.AD) > max_parent_ab) | (dad.AD[1] / hl.sum(dad.AD) > max_parent_ab), failure; ); .when(p_de_novo < min_p, failure); .when(; ~is_snp,; hl.case(); .when(; (p_de_novo > 0.99) & (kid_ad_ratio > 0.3) & (n_alt_alleles == 1),; hl.struct(p_de_novo=p_de_novo, confidence='HIGH'),; ); .when(; (p_de_novo > 0.5) & (kid_ad_ratio > 0.3) & (n_alt_alleles <= 5),; hl.struct(p_de_novo=p_de_novo, confidence='MEDIUM'),; ); .when(kid_ad_ratio > 0.2, hl.struct(p_de_novo=p_de_novo, confidence='LOW')); .or_missing(),; ); .default(; hl.case(); .when(; ((p_de_novo > 0.99) & (kid_ad_ratio > 0.3) & (dp_ratio > 0.2)); | ((p_de_novo > 0.99) & (kid_ad_ratio > 0.3) & (n_alt_alleles == 1)); | ((p_de_novo > 0.5) & (kid_ad_ratio > 0.3) & (n_alt_alleles < 10) & (kid.DP > 10)),; hl.struct(p_de_novo=p_de_novo, confidence='HIGH'),; ); .when(; (p_de_novo > 0.5) & ((kid_ad_ratio > 0.3) | (n_alt_alleles == 1)),; hl.struct(p_de_novo=p_de_novo, confidence='MEDIUM'),; ); .when(kid_ad_ratio > 0.2, hl.struct(p_de_novo=p_de_novo, confidence='LOW')); .or_missing(); ); ). return hl.bind(solve, p_de_novo). def call_hemi(kid_pp, parent",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:31871,Availability,failure,failure,31871,"novo, confidence='LOW')); .or_missing(),; ); .default(; hl.case(); .when(; ((p_de_novo > 0.99) & (kid_ad_ratio > 0.3) & (dp_ratio > 0.2)); | ((p_de_novo > 0.99) & (kid_ad_ratio > 0.3) & (n_alt_alleles == 1)); | ((p_de_novo > 0.5) & (kid_ad_ratio > 0.3) & (n_alt_alleles < 10) & (kid.DP > 10)),; hl.struct(p_de_novo=p_de_novo, confidence='HIGH'),; ); .when(; (p_de_novo > 0.5) & ((kid_ad_ratio > 0.3) | (n_alt_alleles == 1)),; hl.struct(p_de_novo=p_de_novo, confidence='MEDIUM'),; ); .when(kid_ad_ratio > 0.2, hl.struct(p_de_novo=p_de_novo, confidence='LOW')); .or_missing(); ); ). return hl.bind(solve, p_de_novo). def call_hemi(kid_pp, parent, parent_pp, kid_ad_ratio):; p_data_given_dn = parent_pp[0] * kid_pp[1] * DE_NOVO_PRIOR; p_het_in_parent = 1 - (1 - prior) ** 4; p_data_given_missed_het = (parent_pp[1] + parent_pp[2]) * kid_pp[2] * p_het_in_parent; p_de_novo = p_data_given_dn / (p_data_given_dn + p_data_given_missed_het). def solve(p_de_novo):; return (; hl.case(); .when(kid.GQ < min_gq, failure); .when((kid.DP / (parent.DP) < min_dp_ratio) | (kid_ad_ratio < min_child_ab), failure); .when((hl.sum(parent.AD) == 0), failure); .when(parent.AD[1] / hl.sum(parent.AD) > max_parent_ab, failure); .when(p_de_novo < min_p, failure); .when(; ~is_snp,; hl.case(); .when(; (p_de_novo > 0.99) & (kid_ad_ratio > 0.3) & (n_alt_alleles == 1),; hl.struct(p_de_novo=p_de_novo, confidence='HIGH'),; ); .when(; (p_de_novo > 0.5) & (kid_ad_ratio > 0.3) & (n_alt_alleles <= 5),; hl.struct(p_de_novo=p_de_novo, confidence='MEDIUM'),; ); .when(kid_ad_ratio > 0.3, hl.struct(p_de_novo=p_de_novo, confidence='LOW')); .or_missing(),; ); .default(; hl.case(); .when(; ((p_de_novo > 0.99) & (kid_ad_ratio > 0.3) & (dp_ratio > 0.2)); | ((p_de_novo > 0.99) & (kid_ad_ratio > 0.3) & (n_alt_alleles == 1)); | ((p_de_novo > 0.5) & (kid_ad_ratio > 0.3) & (n_alt_alleles < 10) & (kid.DP > 10)),; hl.struct(p_de_novo=p_de_novo, confidence='HIGH'),; ); .when(; (p_de_novo > 0.5) & ((kid_ad_ratio > 0.3) | (n_alt_alleles =",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:31958,Availability,failure,failure,31958,".when(; ((p_de_novo > 0.99) & (kid_ad_ratio > 0.3) & (dp_ratio > 0.2)); | ((p_de_novo > 0.99) & (kid_ad_ratio > 0.3) & (n_alt_alleles == 1)); | ((p_de_novo > 0.5) & (kid_ad_ratio > 0.3) & (n_alt_alleles < 10) & (kid.DP > 10)),; hl.struct(p_de_novo=p_de_novo, confidence='HIGH'),; ); .when(; (p_de_novo > 0.5) & ((kid_ad_ratio > 0.3) | (n_alt_alleles == 1)),; hl.struct(p_de_novo=p_de_novo, confidence='MEDIUM'),; ); .when(kid_ad_ratio > 0.2, hl.struct(p_de_novo=p_de_novo, confidence='LOW')); .or_missing(); ); ). return hl.bind(solve, p_de_novo). def call_hemi(kid_pp, parent, parent_pp, kid_ad_ratio):; p_data_given_dn = parent_pp[0] * kid_pp[1] * DE_NOVO_PRIOR; p_het_in_parent = 1 - (1 - prior) ** 4; p_data_given_missed_het = (parent_pp[1] + parent_pp[2]) * kid_pp[2] * p_het_in_parent; p_de_novo = p_data_given_dn / (p_data_given_dn + p_data_given_missed_het). def solve(p_de_novo):; return (; hl.case(); .when(kid.GQ < min_gq, failure); .when((kid.DP / (parent.DP) < min_dp_ratio) | (kid_ad_ratio < min_child_ab), failure); .when((hl.sum(parent.AD) == 0), failure); .when(parent.AD[1] / hl.sum(parent.AD) > max_parent_ab, failure); .when(p_de_novo < min_p, failure); .when(; ~is_snp,; hl.case(); .when(; (p_de_novo > 0.99) & (kid_ad_ratio > 0.3) & (n_alt_alleles == 1),; hl.struct(p_de_novo=p_de_novo, confidence='HIGH'),; ); .when(; (p_de_novo > 0.5) & (kid_ad_ratio > 0.3) & (n_alt_alleles <= 5),; hl.struct(p_de_novo=p_de_novo, confidence='MEDIUM'),; ); .when(kid_ad_ratio > 0.3, hl.struct(p_de_novo=p_de_novo, confidence='LOW')); .or_missing(),; ); .default(; hl.case(); .when(; ((p_de_novo > 0.99) & (kid_ad_ratio > 0.3) & (dp_ratio > 0.2)); | ((p_de_novo > 0.99) & (kid_ad_ratio > 0.3) & (n_alt_alleles == 1)); | ((p_de_novo > 0.5) & (kid_ad_ratio > 0.3) & (n_alt_alleles < 10) & (kid.DP > 10)),; hl.struct(p_de_novo=p_de_novo, confidence='HIGH'),; ); .when(; (p_de_novo > 0.5) & ((kid_ad_ratio > 0.3) | (n_alt_alleles == 1)),; hl.struct(p_de_novo=p_de_novo, confidence='MEDIUM'),; ); .w",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:32000,Availability,failure,failure,32000,"> 0.2)); | ((p_de_novo > 0.99) & (kid_ad_ratio > 0.3) & (n_alt_alleles == 1)); | ((p_de_novo > 0.5) & (kid_ad_ratio > 0.3) & (n_alt_alleles < 10) & (kid.DP > 10)),; hl.struct(p_de_novo=p_de_novo, confidence='HIGH'),; ); .when(; (p_de_novo > 0.5) & ((kid_ad_ratio > 0.3) | (n_alt_alleles == 1)),; hl.struct(p_de_novo=p_de_novo, confidence='MEDIUM'),; ); .when(kid_ad_ratio > 0.2, hl.struct(p_de_novo=p_de_novo, confidence='LOW')); .or_missing(); ); ). return hl.bind(solve, p_de_novo). def call_hemi(kid_pp, parent, parent_pp, kid_ad_ratio):; p_data_given_dn = parent_pp[0] * kid_pp[1] * DE_NOVO_PRIOR; p_het_in_parent = 1 - (1 - prior) ** 4; p_data_given_missed_het = (parent_pp[1] + parent_pp[2]) * kid_pp[2] * p_het_in_parent; p_de_novo = p_data_given_dn / (p_data_given_dn + p_data_given_missed_het). def solve(p_de_novo):; return (; hl.case(); .when(kid.GQ < min_gq, failure); .when((kid.DP / (parent.DP) < min_dp_ratio) | (kid_ad_ratio < min_child_ab), failure); .when((hl.sum(parent.AD) == 0), failure); .when(parent.AD[1] / hl.sum(parent.AD) > max_parent_ab, failure); .when(p_de_novo < min_p, failure); .when(; ~is_snp,; hl.case(); .when(; (p_de_novo > 0.99) & (kid_ad_ratio > 0.3) & (n_alt_alleles == 1),; hl.struct(p_de_novo=p_de_novo, confidence='HIGH'),; ); .when(; (p_de_novo > 0.5) & (kid_ad_ratio > 0.3) & (n_alt_alleles <= 5),; hl.struct(p_de_novo=p_de_novo, confidence='MEDIUM'),; ); .when(kid_ad_ratio > 0.3, hl.struct(p_de_novo=p_de_novo, confidence='LOW')); .or_missing(),; ); .default(; hl.case(); .when(; ((p_de_novo > 0.99) & (kid_ad_ratio > 0.3) & (dp_ratio > 0.2)); | ((p_de_novo > 0.99) & (kid_ad_ratio > 0.3) & (n_alt_alleles == 1)); | ((p_de_novo > 0.5) & (kid_ad_ratio > 0.3) & (n_alt_alleles < 10) & (kid.DP > 10)),; hl.struct(p_de_novo=p_de_novo, confidence='HIGH'),; ); .when(; (p_de_novo > 0.5) & ((kid_ad_ratio > 0.3) | (n_alt_alleles == 1)),; hl.struct(p_de_novo=p_de_novo, confidence='MEDIUM'),; ); .when(kid_ad_ratio > 0.2, hl.struct(p_de_novo=p_de_novo, confiden",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:32066,Availability,failure,failure,32066,"t_alleles == 1)); | ((p_de_novo > 0.5) & (kid_ad_ratio > 0.3) & (n_alt_alleles < 10) & (kid.DP > 10)),; hl.struct(p_de_novo=p_de_novo, confidence='HIGH'),; ); .when(; (p_de_novo > 0.5) & ((kid_ad_ratio > 0.3) | (n_alt_alleles == 1)),; hl.struct(p_de_novo=p_de_novo, confidence='MEDIUM'),; ); .when(kid_ad_ratio > 0.2, hl.struct(p_de_novo=p_de_novo, confidence='LOW')); .or_missing(); ); ). return hl.bind(solve, p_de_novo). def call_hemi(kid_pp, parent, parent_pp, kid_ad_ratio):; p_data_given_dn = parent_pp[0] * kid_pp[1] * DE_NOVO_PRIOR; p_het_in_parent = 1 - (1 - prior) ** 4; p_data_given_missed_het = (parent_pp[1] + parent_pp[2]) * kid_pp[2] * p_het_in_parent; p_de_novo = p_data_given_dn / (p_data_given_dn + p_data_given_missed_het). def solve(p_de_novo):; return (; hl.case(); .when(kid.GQ < min_gq, failure); .when((kid.DP / (parent.DP) < min_dp_ratio) | (kid_ad_ratio < min_child_ab), failure); .when((hl.sum(parent.AD) == 0), failure); .when(parent.AD[1] / hl.sum(parent.AD) > max_parent_ab, failure); .when(p_de_novo < min_p, failure); .when(; ~is_snp,; hl.case(); .when(; (p_de_novo > 0.99) & (kid_ad_ratio > 0.3) & (n_alt_alleles == 1),; hl.struct(p_de_novo=p_de_novo, confidence='HIGH'),; ); .when(; (p_de_novo > 0.5) & (kid_ad_ratio > 0.3) & (n_alt_alleles <= 5),; hl.struct(p_de_novo=p_de_novo, confidence='MEDIUM'),; ); .when(kid_ad_ratio > 0.3, hl.struct(p_de_novo=p_de_novo, confidence='LOW')); .or_missing(),; ); .default(; hl.case(); .when(; ((p_de_novo > 0.99) & (kid_ad_ratio > 0.3) & (dp_ratio > 0.2)); | ((p_de_novo > 0.99) & (kid_ad_ratio > 0.3) & (n_alt_alleles == 1)); | ((p_de_novo > 0.5) & (kid_ad_ratio > 0.3) & (n_alt_alleles < 10) & (kid.DP > 10)),; hl.struct(p_de_novo=p_de_novo, confidence='HIGH'),; ); .when(; (p_de_novo > 0.5) & ((kid_ad_ratio > 0.3) | (n_alt_alleles == 1)),; hl.struct(p_de_novo=p_de_novo, confidence='MEDIUM'),; ); .when(kid_ad_ratio > 0.2, hl.struct(p_de_novo=p_de_novo, confidence='LOW')); .or_missing(); ); ). return hl.bind(solve, p_de_n",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:32101,Availability,failure,failure,32101," 0.5) & (kid_ad_ratio > 0.3) & (n_alt_alleles < 10) & (kid.DP > 10)),; hl.struct(p_de_novo=p_de_novo, confidence='HIGH'),; ); .when(; (p_de_novo > 0.5) & ((kid_ad_ratio > 0.3) | (n_alt_alleles == 1)),; hl.struct(p_de_novo=p_de_novo, confidence='MEDIUM'),; ); .when(kid_ad_ratio > 0.2, hl.struct(p_de_novo=p_de_novo, confidence='LOW')); .or_missing(); ); ). return hl.bind(solve, p_de_novo). def call_hemi(kid_pp, parent, parent_pp, kid_ad_ratio):; p_data_given_dn = parent_pp[0] * kid_pp[1] * DE_NOVO_PRIOR; p_het_in_parent = 1 - (1 - prior) ** 4; p_data_given_missed_het = (parent_pp[1] + parent_pp[2]) * kid_pp[2] * p_het_in_parent; p_de_novo = p_data_given_dn / (p_data_given_dn + p_data_given_missed_het). def solve(p_de_novo):; return (; hl.case(); .when(kid.GQ < min_gq, failure); .when((kid.DP / (parent.DP) < min_dp_ratio) | (kid_ad_ratio < min_child_ab), failure); .when((hl.sum(parent.AD) == 0), failure); .when(parent.AD[1] / hl.sum(parent.AD) > max_parent_ab, failure); .when(p_de_novo < min_p, failure); .when(; ~is_snp,; hl.case(); .when(; (p_de_novo > 0.99) & (kid_ad_ratio > 0.3) & (n_alt_alleles == 1),; hl.struct(p_de_novo=p_de_novo, confidence='HIGH'),; ); .when(; (p_de_novo > 0.5) & (kid_ad_ratio > 0.3) & (n_alt_alleles <= 5),; hl.struct(p_de_novo=p_de_novo, confidence='MEDIUM'),; ); .when(kid_ad_ratio > 0.3, hl.struct(p_de_novo=p_de_novo, confidence='LOW')); .or_missing(),; ); .default(; hl.case(); .when(; ((p_de_novo > 0.99) & (kid_ad_ratio > 0.3) & (dp_ratio > 0.2)); | ((p_de_novo > 0.99) & (kid_ad_ratio > 0.3) & (n_alt_alleles == 1)); | ((p_de_novo > 0.5) & (kid_ad_ratio > 0.3) & (n_alt_alleles < 10) & (kid.DP > 10)),; hl.struct(p_de_novo=p_de_novo, confidence='HIGH'),; ); .when(; (p_de_novo > 0.5) & ((kid_ad_ratio > 0.3) | (n_alt_alleles == 1)),; hl.struct(p_de_novo=p_de_novo, confidence='MEDIUM'),; ); .when(kid_ad_ratio > 0.2, hl.struct(p_de_novo=p_de_novo, confidence='LOW')); .or_missing(); ); ). return hl.bind(solve, p_de_novo). de_novo_call = (; hl.case();",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:33130,Availability,failure,failure,33130,"iven_dn + p_data_given_missed_het). def solve(p_de_novo):; return (; hl.case(); .when(kid.GQ < min_gq, failure); .when((kid.DP / (parent.DP) < min_dp_ratio) | (kid_ad_ratio < min_child_ab), failure); .when((hl.sum(parent.AD) == 0), failure); .when(parent.AD[1] / hl.sum(parent.AD) > max_parent_ab, failure); .when(p_de_novo < min_p, failure); .when(; ~is_snp,; hl.case(); .when(; (p_de_novo > 0.99) & (kid_ad_ratio > 0.3) & (n_alt_alleles == 1),; hl.struct(p_de_novo=p_de_novo, confidence='HIGH'),; ); .when(; (p_de_novo > 0.5) & (kid_ad_ratio > 0.3) & (n_alt_alleles <= 5),; hl.struct(p_de_novo=p_de_novo, confidence='MEDIUM'),; ); .when(kid_ad_ratio > 0.3, hl.struct(p_de_novo=p_de_novo, confidence='LOW')); .or_missing(),; ); .default(; hl.case(); .when(; ((p_de_novo > 0.99) & (kid_ad_ratio > 0.3) & (dp_ratio > 0.2)); | ((p_de_novo > 0.99) & (kid_ad_ratio > 0.3) & (n_alt_alleles == 1)); | ((p_de_novo > 0.5) & (kid_ad_ratio > 0.3) & (n_alt_alleles < 10) & (kid.DP > 10)),; hl.struct(p_de_novo=p_de_novo, confidence='HIGH'),; ); .when(; (p_de_novo > 0.5) & ((kid_ad_ratio > 0.3) | (n_alt_alleles == 1)),; hl.struct(p_de_novo=p_de_novo, confidence='MEDIUM'),; ); .when(kid_ad_ratio > 0.2, hl.struct(p_de_novo=p_de_novo, confidence='LOW')); .or_missing(); ); ). return hl.bind(solve, p_de_novo). de_novo_call = (; hl.case(); .when(~het_hom_hom | kid_ad_fail, failure); .when(autosomal, hl.bind(call_auto, kid_pp, dad_pp, mom_pp, kid_ad_ratio)); .when(hemi_x | hemi_mt, hl.bind(call_hemi, kid_pp, mom, mom_pp, kid_ad_ratio)); .when(hemi_y, hl.bind(call_hemi, kid_pp, dad, dad_pp, kid_ad_ratio)); .or_missing(); ). tm = tm.annotate_entries(__call=de_novo_call); tm = tm.filter_entries(hl.is_defined(tm.__call)); entries = tm.entries(); return entries.select(; '__site_freq',; 'proband',; 'father',; 'mother',; 'proband_entry',; 'father_entry',; 'mother_entry',; 'is_female',; **entries.__call,; ).rename({'__site_freq': 'prior'}). © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:14866,Deployability,configurat,configurations,14866,"tdt_table = tdt_table.filter(tdt_table.p_value < 0.001); >>> tdt_table.export(f""output/tdt_results.tsv""). Notes; -----; The; `transmission disequilibrium test <https://en.wikipedia.org/wiki/Transmission_disequilibrium_test#The_case_of_trios:_one_affected_child_per_family>`__; compares the number of times the alternate allele is transmitted (t) versus; not transmitted (u) from a heterozgyous parent to an affected child. The null; hypothesis holds that each case is equally likely. The TDT statistic is given by. .. math::. (t - u)^2 \over (t + u). and asymptotically follows a chi-squared distribution with one degree of; freedom under the null hypothesis. :func:`transmission_disequilibrium_test` only considers complete trios (two; parents and a proband with defined sex) and only returns results for the; autosome, as defined by :meth:`~.LocusExpression.in_autosome`, and; chromosome X. Transmissions and non-transmissions are counted only for the; configurations of genotypes and copy state in the table below, in order to; filter out Mendel errors and configurations where transmission is; guaranteed. The copy state of a locus with respect to a trio is defined as; follows:. - Auto -- in autosome or in PAR of X or female child; - HemiX -- in non-PAR of X and male child. Here PAR is the `pseudoautosomal region; <https://en.wikipedia.org/wiki/Pseudoautosomal_region>`__; of X and Y defined by :class:`.ReferenceGenome`, which many variant callers; map to chromosome X. +--------+--------+--------+------------+---+---+; | Kid | Dad | Mom | Copy State | t | u |; +========+========+========+============+===+===+; | HomRef | Het | Het | Auto | 0 | 2 |; +--------+--------+--------+------------+---+---+; | HomRef | HomRef | Het | Auto | 0 | 1 |; +--------+--------+--------+------------+---+---+; | HomRef | Het | HomRef | Auto | 0 | 1 |; +--------+--------+--------+------------+---+---+; | Het | Het | Het | Auto | 1 | 1 |; +--------+--------+--------+------------+---+---+; | Het | HomRef ",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:14971,Deployability,configurat,configurations,14971,"tdt_table = tdt_table.filter(tdt_table.p_value < 0.001); >>> tdt_table.export(f""output/tdt_results.tsv""). Notes; -----; The; `transmission disequilibrium test <https://en.wikipedia.org/wiki/Transmission_disequilibrium_test#The_case_of_trios:_one_affected_child_per_family>`__; compares the number of times the alternate allele is transmitted (t) versus; not transmitted (u) from a heterozgyous parent to an affected child. The null; hypothesis holds that each case is equally likely. The TDT statistic is given by. .. math::. (t - u)^2 \over (t + u). and asymptotically follows a chi-squared distribution with one degree of; freedom under the null hypothesis. :func:`transmission_disequilibrium_test` only considers complete trios (two; parents and a proband with defined sex) and only returns results for the; autosome, as defined by :meth:`~.LocusExpression.in_autosome`, and; chromosome X. Transmissions and non-transmissions are counted only for the; configurations of genotypes and copy state in the table below, in order to; filter out Mendel errors and configurations where transmission is; guaranteed. The copy state of a locus with respect to a trio is defined as; follows:. - Auto -- in autosome or in PAR of X or female child; - HemiX -- in non-PAR of X and male child. Here PAR is the `pseudoautosomal region; <https://en.wikipedia.org/wiki/Pseudoautosomal_region>`__; of X and Y defined by :class:`.ReferenceGenome`, which many variant callers; map to chromosome X. +--------+--------+--------+------------+---+---+; | Kid | Dad | Mom | Copy State | t | u |; +========+========+========+============+===+===+; | HomRef | Het | Het | Auto | 0 | 2 |; +--------+--------+--------+------------+---+---+; | HomRef | HomRef | Het | Auto | 0 | 1 |; +--------+--------+--------+------------+---+---+; | HomRef | Het | HomRef | Auto | 0 | 1 |; +--------+--------+--------+------------+---+---+; | Het | Het | Het | Auto | 1 | 1 |; +--------+--------+--------+------------+---+---+; | Het | HomRef ",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:22386,Deployability,configurat,configuration,22386,"; prior is the maximum of the `pop_frequency_prior` and ``1 / 3e7``.; - `proband` (``struct``) -- Proband column fields from `mt`.; - `father` (``struct``) -- Father column fields from `mt`.; - `mother` (``struct``) -- Mother column fields from `mt`.; - `proband_entry` (``struct``) -- Proband entry fields from `mt`.; - `father_entry` (``struct``) -- Father entry fields from `mt`.; - `proband_entry` (``struct``) -- Mother entry fields from `mt`.; - `is_female` (``bool``) -- ``True`` if proband is female.; - `p_de_novo` (``float64``) -- Unfiltered posterior probability; that the event is *de novo* rather than a missed heterozygous; event in a parent.; - `confidence` (``str``) Validation confidence. One of: ``'HIGH'``,; ``'MEDIUM'``, ``'LOW'``. The key of the table is ``['locus', 'alleles', 'id']``. The model looks for de novo events in which both parents are homozygous; reference and the proband is a heterozygous. The model makes the simplifying; assumption that when this configuration ``x = (AA, AA, AB)`` of calls; occurs, exactly one of the following is true:. - ``d``: a de novo mutation occurred in the proband and all calls are; accurate.; - ``m``: at least one parental allele is actually heterozygous and; the proband call is accurate. We can then estimate the posterior probability of a de novo mutation as:. .. math::. \mathrm{P_{\text{de novo}}} = \frac{\mathrm{P}(d \mid x)}{\mathrm{P}(d \mid x) + \mathrm{P}(m \mid x)}. Applying Bayes rule to the numerator and denominator yields. .. math::. \frac{\mathrm{P}(x \mid d)\,\mathrm{P}(d)}{\mathrm{P}(x \mid d)\,\mathrm{P}(d) +; \mathrm{P}(x \mid m)\,\mathrm{P}(m)}. The prior on de novo mutation is estimated from the rate in the literature:. .. math::. \mathrm{P}(d) = \frac{1 \, \text{mutation}}{30{,}000{,}000 \, \text{bases}}. The prior used for at least one alternate allele between the parents; depends on the alternate allele frequency:. .. math::. \mathrm{P}(m) = 1 - (1 - AF)^4. The likelihoods :math:`\mathrm{P}(x \mid ",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:33740,Deployability,update,updated,33740,"iven_dn + p_data_given_missed_het). def solve(p_de_novo):; return (; hl.case(); .when(kid.GQ < min_gq, failure); .when((kid.DP / (parent.DP) < min_dp_ratio) | (kid_ad_ratio < min_child_ab), failure); .when((hl.sum(parent.AD) == 0), failure); .when(parent.AD[1] / hl.sum(parent.AD) > max_parent_ab, failure); .when(p_de_novo < min_p, failure); .when(; ~is_snp,; hl.case(); .when(; (p_de_novo > 0.99) & (kid_ad_ratio > 0.3) & (n_alt_alleles == 1),; hl.struct(p_de_novo=p_de_novo, confidence='HIGH'),; ); .when(; (p_de_novo > 0.5) & (kid_ad_ratio > 0.3) & (n_alt_alleles <= 5),; hl.struct(p_de_novo=p_de_novo, confidence='MEDIUM'),; ); .when(kid_ad_ratio > 0.3, hl.struct(p_de_novo=p_de_novo, confidence='LOW')); .or_missing(),; ); .default(; hl.case(); .when(; ((p_de_novo > 0.99) & (kid_ad_ratio > 0.3) & (dp_ratio > 0.2)); | ((p_de_novo > 0.99) & (kid_ad_ratio > 0.3) & (n_alt_alleles == 1)); | ((p_de_novo > 0.5) & (kid_ad_ratio > 0.3) & (n_alt_alleles < 10) & (kid.DP > 10)),; hl.struct(p_de_novo=p_de_novo, confidence='HIGH'),; ); .when(; (p_de_novo > 0.5) & ((kid_ad_ratio > 0.3) | (n_alt_alleles == 1)),; hl.struct(p_de_novo=p_de_novo, confidence='MEDIUM'),; ); .when(kid_ad_ratio > 0.2, hl.struct(p_de_novo=p_de_novo, confidence='LOW')); .or_missing(); ); ). return hl.bind(solve, p_de_novo). de_novo_call = (; hl.case(); .when(~het_hom_hom | kid_ad_fail, failure); .when(autosomal, hl.bind(call_auto, kid_pp, dad_pp, mom_pp, kid_ad_ratio)); .when(hemi_x | hemi_mt, hl.bind(call_hemi, kid_pp, mom, mom_pp, kid_ad_ratio)); .when(hemi_y, hl.bind(call_hemi, kid_pp, dad, dad_pp, kid_ad_ratio)); .or_missing(); ). tm = tm.annotate_entries(__call=de_novo_call); tm = tm.filter_entries(hl.is_defined(tm.__call)); entries = tm.entries(); return entries.select(; '__site_freq',; 'proband',; 'father',; 'mother',; 'proband_entry',; 'father_entry',; 'mother_entry',; 'is_female',; **entries.__call,; ).rename({'__site_freq': 'prior'}). © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:23274,Integrability,depend,depends,23274,"rents are homozygous; reference and the proband is a heterozygous. The model makes the simplifying; assumption that when this configuration ``x = (AA, AA, AB)`` of calls; occurs, exactly one of the following is true:. - ``d``: a de novo mutation occurred in the proband and all calls are; accurate.; - ``m``: at least one parental allele is actually heterozygous and; the proband call is accurate. We can then estimate the posterior probability of a de novo mutation as:. .. math::. \mathrm{P_{\text{de novo}}} = \frac{\mathrm{P}(d \mid x)}{\mathrm{P}(d \mid x) + \mathrm{P}(m \mid x)}. Applying Bayes rule to the numerator and denominator yields. .. math::. \frac{\mathrm{P}(x \mid d)\,\mathrm{P}(d)}{\mathrm{P}(x \mid d)\,\mathrm{P}(d) +; \mathrm{P}(x \mid m)\,\mathrm{P}(m)}. The prior on de novo mutation is estimated from the rate in the literature:. .. math::. \mathrm{P}(d) = \frac{1 \, \text{mutation}}{30{,}000{,}000 \, \text{bases}}. The prior used for at least one alternate allele between the parents; depends on the alternate allele frequency:. .. math::. \mathrm{P}(m) = 1 - (1 - AF)^4. The likelihoods :math:`\mathrm{P}(x \mid d)` and :math:`\mathrm{P}(x \mid m)`; are computed from the PL (genotype likelihood) fields using these; factorizations:. .. math::; \mathrm{P}(x = (AA, AA, AB) \mid d) = \left(; \begin{aligned}; &\mathrm{P}(x_{\mathrm{father}} = AA \mid \mathrm{father} = AA) \\; {} \cdot {} &\mathrm{P}(x_{\mathrm{mother}} = AA \mid \mathrm{mother} = AA) \\; {} \cdot {} &\mathrm{P}(x_{\mathrm{proband}} = AB \mid \mathrm{proband} = AB); \end{aligned}; \right). .. math::; \begin{aligned}; \mathrm{P}(x = (AA, AA, AB) \mid m) = &\left(; \begin{aligned}; &\mathrm{P}(x_{\mathrm{father}} = AA \mid \mathrm{father} = AB); \cdot \mathrm{P}(x_{\mathrm{mother}} = AA \mid \mathrm{mother} = AA) \\; {} + {} &\mathrm{P}(x_{\mathrm{father}} = AA \mid \mathrm{father} = AA); \cdot \mathrm{P}(x_{\mathrm{mother}} = AA \mid \mathrm{mother} = AB); \end{aligned}; \right) \\; &{} \cdot \",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:4482,Modifiability,inherit,inheritance,4482,"t.id][k],; proband=mt[cols_sym][t.id],; father=mt[cols_sym][t.pat_id],; mother=mt[cols_sym][t.mat_id],; is_female=t.is_female,; fam_id=t.fam_id,; ),; mt[trios_sym][i],; ),; hl.range(0, n_trios),; ); }); mt = mt.annotate(**{; entries_sym: hl.map(; lambda i: hl.bind(; lambda t: hl.struct(; proband_entry=mt[entries_sym][t.id],; father_entry=mt[entries_sym][t.pat_id],; mother_entry=mt[entries_sym][t.mat_id],; ),; mt[trios_sym][i],; ),; hl.range(0, n_trios),; ); }); mt = mt.drop(trios_sym). return mt._unlocalize_entries(entries_sym, cols_sym, ['id']). [docs]@typecheck(call=expr_call, pedigree=Pedigree); def mendel_errors(call, pedigree) -> Tuple[Table, Table, Table, Table]:; r""""""Find Mendel errors; count per variant, individual and nuclear family. .. include:: ../_templates/req_tstring.rst. .. include:: ../_templates/req_tvariant.rst. .. include:: ../_templates/req_biallelic.rst. Examples; --------. Find all violations of Mendelian inheritance in each (dad, mom, kid) trio in; a pedigree and return four tables (all errors, errors by family, errors by; individual, errors by variant):. >>> ped = hl.Pedigree.read('data/trios.fam'); >>> all_errors, per_fam, per_sample, per_variant = hl.mendel_errors(dataset['GT'], ped). Export all mendel errors to a text file:. >>> all_errors.export('output/all_mendel_errors.tsv'). Annotate columns with the number of Mendel errors:. >>> annotated_samples = dataset.annotate_cols(mendel=per_sample[dataset.s]). Annotate rows with the number of Mendel errors:. >>> annotated_variants = dataset.annotate_rows(mendel=per_variant[dataset.locus, dataset.alleles]). Notes; -----. The example above returns four tables, which contain Mendelian violations; grouped in various ways. These tables are modeled after the `PLINK mendel; formats <https://www.cog-genomics.org/plink2/formats#mendel>`_, resembling; the ``.mendel``, ``.fmendel``, ``.imendel``, and ``.lmendel`` formats,; respectively. **First table:** all Mendel errors. This table contains one row per Me",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:7374,Modifiability,extend,extending,7374," - `snp_errors` (:py:data:`.tint64`) -- Number of Mendel errors at SNPs in this; nuclear family. **Third table:** errors per individual. This table contains one row per; individual. Each error is counted toward the proband, father, and mother; according to the `Implicated` in the table below. - (column key of `dataset`) (:py:data:`.tstr`) -- Sample ID (key field).; - `fam_id` (:py:data:`.tstr`) -- Family ID.; - `errors` (:py:data:`.tint64`) -- Number of Mendel errors involving this; individual.; - `snp_errors` (:py:data:`.tint64`) -- Number of Mendel errors involving this; individual at SNPs. **Fourth table:** errors per variant. - `locus` (:class:`.tlocus`) -- Variant locus, key field.; - `alleles` (:class:`.tarray` of :py:data:`.tstr`) -- Variant alleles, key field.; - `errors` (:py:data:`.tint64`) -- Number of Mendel errors in this variant. This method only considers complete trios (two parents and proband with; defined sex). The code of each Mendel error is determined by the table; below, extending the; `Plink classification <https://www.cog-genomics.org/plink2/basic_stats#mendel>`__. In the table, the copy state of a locus with respect to a trio is defined; as follows, where PAR is the `pseudoautosomal region; <https://en.wikipedia.org/wiki/Pseudoautosomal_region>`__ (PAR) of X and Y; defined by the reference genome and the autosome is defined by; :meth:`~.LocusExpression.in_autosome`. - Auto -- in autosome or in PAR or female child; - HemiX -- in non-PAR of X and male child; - HemiY -- in non-PAR of Y and male child. `Any` refers to the set \{ HomRef, Het, HomVar, NoCall \} and `~`; denotes complement in this set. +------+---------+---------+--------+----------------------------+; | Code | Dad | Mom | Kid | Copy State | Implicated |; +======+=========+=========+========+============+===============+; | 1 | HomVar | HomVar | Het | Auto | Dad, Mom, Kid |; +------+---------+---------+--------+------------+---------------+; | 2 | HomRef | HomRef | Het | Auto | Dad",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:14866,Modifiability,config,configurations,14866,"tdt_table = tdt_table.filter(tdt_table.p_value < 0.001); >>> tdt_table.export(f""output/tdt_results.tsv""). Notes; -----; The; `transmission disequilibrium test <https://en.wikipedia.org/wiki/Transmission_disequilibrium_test#The_case_of_trios:_one_affected_child_per_family>`__; compares the number of times the alternate allele is transmitted (t) versus; not transmitted (u) from a heterozgyous parent to an affected child. The null; hypothesis holds that each case is equally likely. The TDT statistic is given by. .. math::. (t - u)^2 \over (t + u). and asymptotically follows a chi-squared distribution with one degree of; freedom under the null hypothesis. :func:`transmission_disequilibrium_test` only considers complete trios (two; parents and a proband with defined sex) and only returns results for the; autosome, as defined by :meth:`~.LocusExpression.in_autosome`, and; chromosome X. Transmissions and non-transmissions are counted only for the; configurations of genotypes and copy state in the table below, in order to; filter out Mendel errors and configurations where transmission is; guaranteed. The copy state of a locus with respect to a trio is defined as; follows:. - Auto -- in autosome or in PAR of X or female child; - HemiX -- in non-PAR of X and male child. Here PAR is the `pseudoautosomal region; <https://en.wikipedia.org/wiki/Pseudoautosomal_region>`__; of X and Y defined by :class:`.ReferenceGenome`, which many variant callers; map to chromosome X. +--------+--------+--------+------------+---+---+; | Kid | Dad | Mom | Copy State | t | u |; +========+========+========+============+===+===+; | HomRef | Het | Het | Auto | 0 | 2 |; +--------+--------+--------+------------+---+---+; | HomRef | HomRef | Het | Auto | 0 | 1 |; +--------+--------+--------+------------+---+---+; | HomRef | Het | HomRef | Auto | 0 | 1 |; +--------+--------+--------+------------+---+---+; | Het | Het | Het | Auto | 1 | 1 |; +--------+--------+--------+------------+---+---+; | Het | HomRef ",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:14971,Modifiability,config,configurations,14971,"tdt_table = tdt_table.filter(tdt_table.p_value < 0.001); >>> tdt_table.export(f""output/tdt_results.tsv""). Notes; -----; The; `transmission disequilibrium test <https://en.wikipedia.org/wiki/Transmission_disequilibrium_test#The_case_of_trios:_one_affected_child_per_family>`__; compares the number of times the alternate allele is transmitted (t) versus; not transmitted (u) from a heterozgyous parent to an affected child. The null; hypothesis holds that each case is equally likely. The TDT statistic is given by. .. math::. (t - u)^2 \over (t + u). and asymptotically follows a chi-squared distribution with one degree of; freedom under the null hypothesis. :func:`transmission_disequilibrium_test` only considers complete trios (two; parents and a proband with defined sex) and only returns results for the; autosome, as defined by :meth:`~.LocusExpression.in_autosome`, and; chromosome X. Transmissions and non-transmissions are counted only for the; configurations of genotypes and copy state in the table below, in order to; filter out Mendel errors and configurations where transmission is; guaranteed. The copy state of a locus with respect to a trio is defined as; follows:. - Auto -- in autosome or in PAR of X or female child; - HemiX -- in non-PAR of X and male child. Here PAR is the `pseudoautosomal region; <https://en.wikipedia.org/wiki/Pseudoautosomal_region>`__; of X and Y defined by :class:`.ReferenceGenome`, which many variant callers; map to chromosome X. +--------+--------+--------+------------+---+---+; | Kid | Dad | Mom | Copy State | t | u |; +========+========+========+============+===+===+; | HomRef | Het | Het | Auto | 0 | 2 |; +--------+--------+--------+------------+---+---+; | HomRef | HomRef | Het | Auto | 0 | 1 |; +--------+--------+--------+------------+---+---+; | HomRef | Het | HomRef | Auto | 0 | 1 |; +--------+--------+--------+------------+---+---+; | Het | Het | Het | Auto | 1 | 1 |; +--------+--------+--------+------------+---+---+; | Het | HomRef ",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:18706,Modifiability,config,config,18706,"aset = dataset.filter_rows(dataset.auto_or_x_par | dataset.locus.in_x_nonpar()). hom_ref = 0; het = 1; hom_var = 2. auto = 2; hemi_x = 1. # kid, dad, mom, copy, t, u; config_counts = [; (hom_ref, het, het, auto, 0, 2),; (hom_ref, hom_ref, het, auto, 0, 1),; (hom_ref, het, hom_ref, auto, 0, 1),; (het, het, het, auto, 1, 1),; (het, hom_ref, het, auto, 1, 0),; (het, het, hom_ref, auto, 1, 0),; (het, hom_var, het, auto, 0, 1),; (het, het, hom_var, auto, 0, 1),; (hom_var, het, het, auto, 2, 0),; (hom_var, het, hom_var, auto, 1, 0),; (hom_var, hom_var, het, auto, 1, 0),; (hom_ref, hom_ref, het, hemi_x, 0, 1),; (hom_ref, hom_var, het, hemi_x, 0, 1),; (hom_var, hom_ref, het, hemi_x, 1, 0),; (hom_var, hom_var, het, hemi_x, 1, 0),; ]. count_map = hl.literal({(c[0], c[1], c[2], c[3]): [c[4], c[5]] for c in config_counts}). tri = trio_matrix(dataset, pedigree, complete_trios=True). # this filter removes mendel error of het father in x_nonpar. It also avoids; # building and looking up config in common case that neither parent is het; father_is_het = tri.father_entry.GT.is_het(); parent_is_valid_het = (father_is_het & tri.auto_or_x_par) | (tri.mother_entry.GT.is_het() & ~father_is_het). copy_state = hl.if_else(tri.auto_or_x_par | tri.is_female, 2, 1). config = (; tri.proband_entry.GT.n_alt_alleles(),; tri.father_entry.GT.n_alt_alleles(),; tri.mother_entry.GT.n_alt_alleles(),; copy_state,; ). tri = tri.annotate_rows(counts=agg.filter(parent_is_valid_het, agg.array_sum(count_map.get(config)))). tab = tri.rows().select('counts'); tab = tab.transmute(t=tab.counts[0], u=tab.counts[1]); tab = tab.annotate(chi_sq=((tab.t - tab.u) ** 2) / (tab.t + tab.u)); tab = tab.annotate(p_value=hl.pchisqtail(tab.chi_sq, 1.0)). return tab.cache(). [docs]@typecheck(; mt=MatrixTable,; pedigree=Pedigree,; pop_frequency_prior=expr_float64,; min_gq=int,; min_p=numeric,; max_parent_ab=numeric,; min_child_ab=numeric,; min_dp_ratio=numeric,; ignore_in_sample_allele_frequency=bool,; ); def de_novo(; mt: Matrix",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:18977,Modifiability,config,config,18977,"f, het, hom_ref, auto, 0, 1),; (het, het, het, auto, 1, 1),; (het, hom_ref, het, auto, 1, 0),; (het, het, hom_ref, auto, 1, 0),; (het, hom_var, het, auto, 0, 1),; (het, het, hom_var, auto, 0, 1),; (hom_var, het, het, auto, 2, 0),; (hom_var, het, hom_var, auto, 1, 0),; (hom_var, hom_var, het, auto, 1, 0),; (hom_ref, hom_ref, het, hemi_x, 0, 1),; (hom_ref, hom_var, het, hemi_x, 0, 1),; (hom_var, hom_ref, het, hemi_x, 1, 0),; (hom_var, hom_var, het, hemi_x, 1, 0),; ]. count_map = hl.literal({(c[0], c[1], c[2], c[3]): [c[4], c[5]] for c in config_counts}). tri = trio_matrix(dataset, pedigree, complete_trios=True). # this filter removes mendel error of het father in x_nonpar. It also avoids; # building and looking up config in common case that neither parent is het; father_is_het = tri.father_entry.GT.is_het(); parent_is_valid_het = (father_is_het & tri.auto_or_x_par) | (tri.mother_entry.GT.is_het() & ~father_is_het). copy_state = hl.if_else(tri.auto_or_x_par | tri.is_female, 2, 1). config = (; tri.proband_entry.GT.n_alt_alleles(),; tri.father_entry.GT.n_alt_alleles(),; tri.mother_entry.GT.n_alt_alleles(),; copy_state,; ). tri = tri.annotate_rows(counts=agg.filter(parent_is_valid_het, agg.array_sum(count_map.get(config)))). tab = tri.rows().select('counts'); tab = tab.transmute(t=tab.counts[0], u=tab.counts[1]); tab = tab.annotate(chi_sq=((tab.t - tab.u) ** 2) / (tab.t + tab.u)); tab = tab.annotate(p_value=hl.pchisqtail(tab.chi_sq, 1.0)). return tab.cache(). [docs]@typecheck(; mt=MatrixTable,; pedigree=Pedigree,; pop_frequency_prior=expr_float64,; min_gq=int,; min_p=numeric,; max_parent_ab=numeric,; min_child_ab=numeric,; min_dp_ratio=numeric,; ignore_in_sample_allele_frequency=bool,; ); def de_novo(; mt: MatrixTable,; pedigree: Pedigree,; pop_frequency_prior,; *,; min_gq: int = 20,; min_p: float = 0.05,; max_parent_ab: float = 0.05,; min_child_ab: float = 0.20,; min_dp_ratio: float = 0.10,; ignore_in_sample_allele_frequency: bool = False,; ) -> Table:; r""""""Call putative ",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:19211,Modifiability,config,config,19211," (hom_var, het, hom_var, auto, 1, 0),; (hom_var, hom_var, het, auto, 1, 0),; (hom_ref, hom_ref, het, hemi_x, 0, 1),; (hom_ref, hom_var, het, hemi_x, 0, 1),; (hom_var, hom_ref, het, hemi_x, 1, 0),; (hom_var, hom_var, het, hemi_x, 1, 0),; ]. count_map = hl.literal({(c[0], c[1], c[2], c[3]): [c[4], c[5]] for c in config_counts}). tri = trio_matrix(dataset, pedigree, complete_trios=True). # this filter removes mendel error of het father in x_nonpar. It also avoids; # building and looking up config in common case that neither parent is het; father_is_het = tri.father_entry.GT.is_het(); parent_is_valid_het = (father_is_het & tri.auto_or_x_par) | (tri.mother_entry.GT.is_het() & ~father_is_het). copy_state = hl.if_else(tri.auto_or_x_par | tri.is_female, 2, 1). config = (; tri.proband_entry.GT.n_alt_alleles(),; tri.father_entry.GT.n_alt_alleles(),; tri.mother_entry.GT.n_alt_alleles(),; copy_state,; ). tri = tri.annotate_rows(counts=agg.filter(parent_is_valid_het, agg.array_sum(count_map.get(config)))). tab = tri.rows().select('counts'); tab = tab.transmute(t=tab.counts[0], u=tab.counts[1]); tab = tab.annotate(chi_sq=((tab.t - tab.u) ** 2) / (tab.t + tab.u)); tab = tab.annotate(p_value=hl.pchisqtail(tab.chi_sq, 1.0)). return tab.cache(). [docs]@typecheck(; mt=MatrixTable,; pedigree=Pedigree,; pop_frequency_prior=expr_float64,; min_gq=int,; min_p=numeric,; max_parent_ab=numeric,; min_child_ab=numeric,; min_dp_ratio=numeric,; ignore_in_sample_allele_frequency=bool,; ); def de_novo(; mt: MatrixTable,; pedigree: Pedigree,; pop_frequency_prior,; *,; min_gq: int = 20,; min_p: float = 0.05,; max_parent_ab: float = 0.05,; min_child_ab: float = 0.20,; min_dp_ratio: float = 0.10,; ignore_in_sample_allele_frequency: bool = False,; ) -> Table:; r""""""Call putative *de novo* events from trio data. .. include:: ../_templates/req_tstring.rst. .. include:: ../_templates/req_tvariant.rst. .. include:: ../_templates/req_biallelic.rst. Examples; --------. Call de novo events:. >>> pedigree = hl.Pe",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:22386,Modifiability,config,configuration,22386,"; prior is the maximum of the `pop_frequency_prior` and ``1 / 3e7``.; - `proband` (``struct``) -- Proband column fields from `mt`.; - `father` (``struct``) -- Father column fields from `mt`.; - `mother` (``struct``) -- Mother column fields from `mt`.; - `proband_entry` (``struct``) -- Proband entry fields from `mt`.; - `father_entry` (``struct``) -- Father entry fields from `mt`.; - `proband_entry` (``struct``) -- Mother entry fields from `mt`.; - `is_female` (``bool``) -- ``True`` if proband is female.; - `p_de_novo` (``float64``) -- Unfiltered posterior probability; that the event is *de novo* rather than a missed heterozygous; event in a parent.; - `confidence` (``str``) Validation confidence. One of: ``'HIGH'``,; ``'MEDIUM'``, ``'LOW'``. The key of the table is ``['locus', 'alleles', 'id']``. The model looks for de novo events in which both parents are homozygous; reference and the proband is a heterozygous. The model makes the simplifying; assumption that when this configuration ``x = (AA, AA, AB)`` of calls; occurs, exactly one of the following is true:. - ``d``: a de novo mutation occurred in the proband and all calls are; accurate.; - ``m``: at least one parental allele is actually heterozygous and; the proband call is accurate. We can then estimate the posterior probability of a de novo mutation as:. .. math::. \mathrm{P_{\text{de novo}}} = \frac{\mathrm{P}(d \mid x)}{\mathrm{P}(d \mid x) + \mathrm{P}(m \mid x)}. Applying Bayes rule to the numerator and denominator yields. .. math::. \frac{\mathrm{P}(x \mid d)\,\mathrm{P}(d)}{\mathrm{P}(x \mid d)\,\mathrm{P}(d) +; \mathrm{P}(x \mid m)\,\mathrm{P}(m)}. The prior on de novo mutation is estimated from the rate in the literature:. .. math::. \mathrm{P}(d) = \frac{1 \, \text{mutation}}{30{,}000{,}000 \, \text{bases}}. The prior used for at least one alternate allele between the parents; depends on the alternate allele frequency:. .. math::. \mathrm{P}(m) = 1 - (1 - AF)^4. The likelihoods :math:`\mathrm{P}(x \mid ",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:25011,Modifiability,variab,variables,25011,"); \cdot \mathrm{P}(x_{\mathrm{mother}} = AA \mid \mathrm{mother} = AA) \\; {} + {} &\mathrm{P}(x_{\mathrm{father}} = AA \mid \mathrm{father} = AA); \cdot \mathrm{P}(x_{\mathrm{mother}} = AA \mid \mathrm{mother} = AB); \end{aligned}; \right) \\; &{} \cdot \mathrm{P}(x_{\mathrm{proband}} = AB \mid \mathrm{proband} = AB); \end{aligned}. (Technically, the second factorization assumes there is exactly (rather; than at least) one alternate allele among the parents, which may be; justified on the grounds that it is typically the most likely case by far.). While this posterior probability is a good metric for grouping putative de; novo mutations by validation likelihood, there exist error modes in; high-throughput sequencing data that are not appropriately accounted for by; the phred-scaled genotype likelihoods. To this end, a number of hard filters; are applied in order to assign validation likelihood. These filters are different for SNPs and insertions/deletions. In the below; rules, the following variables are used:. - ``DR`` refers to the ratio of the read depth in the proband to the; combined read depth in the parents.; - ``DP`` refers to the read depth (DP field) of the proband.; - ``AB`` refers to the read allele balance of the proband (number of; alternate reads divided by total reads).; - ``AC`` refers to the count of alternate alleles across all individuals; in the dataset at the site.; - ``p`` refers to :math:`\mathrm{P_{\text{de novo}}}`.; - ``min_p`` refers to the `min_p` function parameter. HIGH-quality SNV:. .. code-block:: text. (p > 0.99) AND (AB > 0.3) AND (AC == 1); OR; (p > 0.99) AND (AB > 0.3) AND (DR > 0.2); OR; (p > 0.5) AND (AB > 0.3) AND (AC < 10) AND (DP > 10). MEDIUM-quality SNV:. .. code-block:: text. (p > 0.5) AND (AB > 0.3); OR; (AC == 1). LOW-quality SNV:. .. code-block:: text. (AB > 0.2). HIGH-quality indel:. .. code-block:: text. (p > 0.99) AND (AB > 0.3) AND (AC == 1). MEDIUM-quality indel:. .. code-block:: text. (p > 0.5) AND (AB > 0.3) A",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:19453,Performance,cache,cache,19453,"nt_map = hl.literal({(c[0], c[1], c[2], c[3]): [c[4], c[5]] for c in config_counts}). tri = trio_matrix(dataset, pedigree, complete_trios=True). # this filter removes mendel error of het father in x_nonpar. It also avoids; # building and looking up config in common case that neither parent is het; father_is_het = tri.father_entry.GT.is_het(); parent_is_valid_het = (father_is_het & tri.auto_or_x_par) | (tri.mother_entry.GT.is_het() & ~father_is_het). copy_state = hl.if_else(tri.auto_or_x_par | tri.is_female, 2, 1). config = (; tri.proband_entry.GT.n_alt_alleles(),; tri.father_entry.GT.n_alt_alleles(),; tri.mother_entry.GT.n_alt_alleles(),; copy_state,; ). tri = tri.annotate_rows(counts=agg.filter(parent_is_valid_het, agg.array_sum(count_map.get(config)))). tab = tri.rows().select('counts'); tab = tab.transmute(t=tab.counts[0], u=tab.counts[1]); tab = tab.annotate(chi_sq=((tab.t - tab.u) ** 2) / (tab.t + tab.u)); tab = tab.annotate(p_value=hl.pchisqtail(tab.chi_sq, 1.0)). return tab.cache(). [docs]@typecheck(; mt=MatrixTable,; pedigree=Pedigree,; pop_frequency_prior=expr_float64,; min_gq=int,; min_p=numeric,; max_parent_ab=numeric,; min_child_ab=numeric,; min_dp_ratio=numeric,; ignore_in_sample_allele_frequency=bool,; ); def de_novo(; mt: MatrixTable,; pedigree: Pedigree,; pop_frequency_prior,; *,; min_gq: int = 20,; min_p: float = 0.05,; max_parent_ab: float = 0.05,; min_child_ab: float = 0.20,; min_dp_ratio: float = 0.10,; ignore_in_sample_allele_frequency: bool = False,; ) -> Table:; r""""""Call putative *de novo* events from trio data. .. include:: ../_templates/req_tstring.rst. .. include:: ../_templates/req_tvariant.rst. .. include:: ../_templates/req_biallelic.rst. Examples; --------. Call de novo events:. >>> pedigree = hl.Pedigree.read('data/trios.fam'); >>> priors = hl.import_table('data/gnomadFreq.tsv', impute=True); >>> priors = priors.transmute(**hl.parse_variant(priors.Variant)).key_by('locus', 'alleles'); >>> de_novo_results = hl.de_novo(dataset, pedigree,",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:20555,Performance,throughput,throughput,20555,",; min_p=numeric,; max_parent_ab=numeric,; min_child_ab=numeric,; min_dp_ratio=numeric,; ignore_in_sample_allele_frequency=bool,; ); def de_novo(; mt: MatrixTable,; pedigree: Pedigree,; pop_frequency_prior,; *,; min_gq: int = 20,; min_p: float = 0.05,; max_parent_ab: float = 0.05,; min_child_ab: float = 0.20,; min_dp_ratio: float = 0.10,; ignore_in_sample_allele_frequency: bool = False,; ) -> Table:; r""""""Call putative *de novo* events from trio data. .. include:: ../_templates/req_tstring.rst. .. include:: ../_templates/req_tvariant.rst. .. include:: ../_templates/req_biallelic.rst. Examples; --------. Call de novo events:. >>> pedigree = hl.Pedigree.read('data/trios.fam'); >>> priors = hl.import_table('data/gnomadFreq.tsv', impute=True); >>> priors = priors.transmute(**hl.parse_variant(priors.Variant)).key_by('locus', 'alleles'); >>> de_novo_results = hl.de_novo(dataset, pedigree, pop_frequency_prior=priors[dataset.row_key].AF). Notes; -----; This method assumes the GATK high-throughput sequencing fields exist:; `GT`, `AD`, `DP`, `GQ`, `PL`. This method replicates the functionality of `Kaitlin Samocha's de novo; caller <https://github.com/ksamocha/de_novo_scripts>`__. The version; corresponding to git commit ``bde3e40`` is implemented in Hail with her; permission and assistance. This method produces a :class:`.Table` with the following fields:. - `locus` (``locus``) -- Variant locus.; - `alleles` (``array<str>``) -- Variant alleles.; - `id` (``str``) -- Proband sample ID.; - `prior` (``float64``) -- Site frequency prior. It is the maximum of:; the computed dataset alternate allele frequency, the; `pop_frequency_prior` parameter, and the global prior; ``1 / 3e7``. If the `ignore_in_sample_allele_frequency` parameter is ``True``,; then the computed allele frequency is not included in the calculation, and the; prior is the maximum of the `pop_frequency_prior` and ``1 / 3e7``.; - `proband` (``struct``) -- Proband column fields from `mt`.; - `father` (``struct``) -- Fath",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:24709,Performance,throughput,throughput,24709,"}(x_{\mathrm{mother}} = AA \mid \mathrm{mother} = AA) \\; {} \cdot {} &\mathrm{P}(x_{\mathrm{proband}} = AB \mid \mathrm{proband} = AB); \end{aligned}; \right). .. math::; \begin{aligned}; \mathrm{P}(x = (AA, AA, AB) \mid m) = &\left(; \begin{aligned}; &\mathrm{P}(x_{\mathrm{father}} = AA \mid \mathrm{father} = AB); \cdot \mathrm{P}(x_{\mathrm{mother}} = AA \mid \mathrm{mother} = AA) \\; {} + {} &\mathrm{P}(x_{\mathrm{father}} = AA \mid \mathrm{father} = AA); \cdot \mathrm{P}(x_{\mathrm{mother}} = AA \mid \mathrm{mother} = AB); \end{aligned}; \right) \\; &{} \cdot \mathrm{P}(x_{\mathrm{proband}} = AB \mid \mathrm{proband} = AB); \end{aligned}. (Technically, the second factorization assumes there is exactly (rather; than at least) one alternate allele among the parents, which may be; justified on the grounds that it is typically the most likely case by far.). While this posterior probability is a good metric for grouping putative de; novo mutations by validation likelihood, there exist error modes in; high-throughput sequencing data that are not appropriately accounted for by; the phred-scaled genotype likelihoods. To this end, a number of hard filters; are applied in order to assign validation likelihood. These filters are different for SNPs and insertions/deletions. In the below; rules, the following variables are used:. - ``DR`` refers to the ratio of the read depth in the proband to the; combined read depth in the parents.; - ``DP`` refers to the read depth (DP field) of the proband.; - ``AB`` refers to the read allele balance of the proband (number of; alternate reads divided by total reads).; - ``AC`` refers to the count of alternate alleles across all individuals; in the dataset at the site.; - ``p`` refers to :math:`\mathrm{P_{\text{de novo}}}`.; - ``min_p`` refers to the `min_p` function parameter. HIGH-quality SNV:. .. code-block:: text. (p > 0.99) AND (AB > 0.3) AND (AC == 1); OR; (p > 0.99) AND (AB > 0.3) AND (DR > 0.2); OR; (p > 0.5) AND (AB > 0.3) AND (A",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:26566,Performance,throughput,throughput,26566," 0.99) AND (AB > 0.3) AND (AC == 1); OR; (p > 0.99) AND (AB > 0.3) AND (DR > 0.2); OR; (p > 0.5) AND (AB > 0.3) AND (AC < 10) AND (DP > 10). MEDIUM-quality SNV:. .. code-block:: text. (p > 0.5) AND (AB > 0.3); OR; (AC == 1). LOW-quality SNV:. .. code-block:: text. (AB > 0.2). HIGH-quality indel:. .. code-block:: text. (p > 0.99) AND (AB > 0.3) AND (AC == 1). MEDIUM-quality indel:. .. code-block:: text. (p > 0.5) AND (AB > 0.3) AND (AC < 10). LOW-quality indel:. .. code-block:: text. (AB > 0.2). Additionally, de novo candidates are not considered if the proband GQ is; smaller than the `min_gq` parameter, if the proband allele balance is; lower than the `min_child_ab` parameter, if the depth ratio between the; proband and parents is smaller than the `min_depth_ratio` parameter, if; the allele balance in a parent is above the `max_parent_ab` parameter, or; if the posterior probability `p` is smaller than the `min_p` parameter. Parameters; ----------; mt : :class:`.MatrixTable`; High-throughput sequencing dataset.; pedigree : :class:`.Pedigree`; Sample pedigree.; pop_frequency_prior : :class:`.Float64Expression`; Expression for population alternate allele frequency prior.; min_gq; Minimum proband GQ to be considered for *de novo* calling.; min_p; Minimum posterior probability to be considered for *de novo* calling.; max_parent_ab; Maximum parent allele balance.; min_child_ab; Minimum proband allele balance/; min_dp_ratio; Minimum ratio between proband read depth and parental read depth.; ignore_in_sample_allele_frequency; Ignore in-sample allele frequency in computing site prior. Experimental.; Returns; -------; :class:`.Table`; """"""; DE_NOVO_PRIOR = 1 / 30000000; MIN_POP_PRIOR = 100 / 30000000. required_entry_fields = {'GT', 'AD', 'DP', 'GQ', 'PL'}; missing_fields = required_entry_fields - set(mt.entry); if missing_fields:; raise ValueError(; f""'de_novo': expected 'MatrixTable' to have at least {required_entry_fields}, "" f""missing {missing_fields}""; ). pop_frequency_prio",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:18672,Safety,avoid,avoids,18672,"aset = dataset.filter_rows(dataset.auto_or_x_par | dataset.locus.in_x_nonpar()). hom_ref = 0; het = 1; hom_var = 2. auto = 2; hemi_x = 1. # kid, dad, mom, copy, t, u; config_counts = [; (hom_ref, het, het, auto, 0, 2),; (hom_ref, hom_ref, het, auto, 0, 1),; (hom_ref, het, hom_ref, auto, 0, 1),; (het, het, het, auto, 1, 1),; (het, hom_ref, het, auto, 1, 0),; (het, het, hom_ref, auto, 1, 0),; (het, hom_var, het, auto, 0, 1),; (het, het, hom_var, auto, 0, 1),; (hom_var, het, het, auto, 2, 0),; (hom_var, het, hom_var, auto, 1, 0),; (hom_var, hom_var, het, auto, 1, 0),; (hom_ref, hom_ref, het, hemi_x, 0, 1),; (hom_ref, hom_var, het, hemi_x, 0, 1),; (hom_var, hom_ref, het, hemi_x, 1, 0),; (hom_var, hom_var, het, hemi_x, 1, 0),; ]. count_map = hl.literal({(c[0], c[1], c[2], c[3]): [c[4], c[5]] for c in config_counts}). tri = trio_matrix(dataset, pedigree, complete_trios=True). # this filter removes mendel error of het father in x_nonpar. It also avoids; # building and looking up config in common case that neither parent is het; father_is_het = tri.father_entry.GT.is_het(); parent_is_valid_het = (father_is_het & tri.auto_or_x_par) | (tri.mother_entry.GT.is_het() & ~father_is_het). copy_state = hl.if_else(tri.auto_or_x_par | tri.is_female, 2, 1). config = (; tri.proband_entry.GT.n_alt_alleles(),; tri.father_entry.GT.n_alt_alleles(),; tri.mother_entry.GT.n_alt_alleles(),; copy_state,; ). tri = tri.annotate_rows(counts=agg.filter(parent_is_valid_het, agg.array_sum(count_map.get(config)))). tab = tri.rows().select('counts'); tab = tab.transmute(t=tab.counts[0], u=tab.counts[1]); tab = tab.annotate(chi_sq=((tab.t - tab.u) ** 2) / (tab.t + tab.u)); tab = tab.annotate(p_value=hl.pchisqtail(tab.chi_sq, 1.0)). return tab.cache(). [docs]@typecheck(; mt=MatrixTable,; pedigree=Pedigree,; pop_frequency_prior=expr_float64,; min_gq=int,; min_p=numeric,; max_parent_ab=numeric,; min_child_ab=numeric,; min_dp_ratio=numeric,; ignore_in_sample_allele_frequency=bool,; ); def de_novo(; mt: Matrix",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:24653,Security,validat,validation,24653,"}(x_{\mathrm{mother}} = AA \mid \mathrm{mother} = AA) \\; {} \cdot {} &\mathrm{P}(x_{\mathrm{proband}} = AB \mid \mathrm{proband} = AB); \end{aligned}; \right). .. math::; \begin{aligned}; \mathrm{P}(x = (AA, AA, AB) \mid m) = &\left(; \begin{aligned}; &\mathrm{P}(x_{\mathrm{father}} = AA \mid \mathrm{father} = AB); \cdot \mathrm{P}(x_{\mathrm{mother}} = AA \mid \mathrm{mother} = AA) \\; {} + {} &\mathrm{P}(x_{\mathrm{father}} = AA \mid \mathrm{father} = AA); \cdot \mathrm{P}(x_{\mathrm{mother}} = AA \mid \mathrm{mother} = AB); \end{aligned}; \right) \\; &{} \cdot \mathrm{P}(x_{\mathrm{proband}} = AB \mid \mathrm{proband} = AB); \end{aligned}. (Technically, the second factorization assumes there is exactly (rather; than at least) one alternate allele among the parents, which may be; justified on the grounds that it is typically the most likely case by far.). While this posterior probability is a good metric for grouping putative de; novo mutations by validation likelihood, there exist error modes in; high-throughput sequencing data that are not appropriately accounted for by; the phred-scaled genotype likelihoods. To this end, a number of hard filters; are applied in order to assign validation likelihood. These filters are different for SNPs and insertions/deletions. In the below; rules, the following variables are used:. - ``DR`` refers to the ratio of the read depth in the proband to the; combined read depth in the parents.; - ``DP`` refers to the read depth (DP field) of the proband.; - ``AB`` refers to the read allele balance of the proband (number of; alternate reads divided by total reads).; - ``AC`` refers to the count of alternate alleles across all individuals; in the dataset at the site.; - ``p`` refers to :math:`\mathrm{P_{\text{de novo}}}`.; - ``min_p`` refers to the `min_p` function parameter. HIGH-quality SNV:. .. code-block:: text. (p > 0.99) AND (AB > 0.3) AND (AC == 1); OR; (p > 0.99) AND (AB > 0.3) AND (DR > 0.2); OR; (p > 0.5) AND (AB > 0.3) AND (A",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:24890,Security,validat,validation,24890,"n{aligned}; \mathrm{P}(x = (AA, AA, AB) \mid m) = &\left(; \begin{aligned}; &\mathrm{P}(x_{\mathrm{father}} = AA \mid \mathrm{father} = AB); \cdot \mathrm{P}(x_{\mathrm{mother}} = AA \mid \mathrm{mother} = AA) \\; {} + {} &\mathrm{P}(x_{\mathrm{father}} = AA \mid \mathrm{father} = AA); \cdot \mathrm{P}(x_{\mathrm{mother}} = AA \mid \mathrm{mother} = AB); \end{aligned}; \right) \\; &{} \cdot \mathrm{P}(x_{\mathrm{proband}} = AB \mid \mathrm{proband} = AB); \end{aligned}. (Technically, the second factorization assumes there is exactly (rather; than at least) one alternate allele among the parents, which may be; justified on the grounds that it is typically the most likely case by far.). While this posterior probability is a good metric for grouping putative de; novo mutations by validation likelihood, there exist error modes in; high-throughput sequencing data that are not appropriately accounted for by; the phred-scaled genotype likelihoods. To this end, a number of hard filters; are applied in order to assign validation likelihood. These filters are different for SNPs and insertions/deletions. In the below; rules, the following variables are used:. - ``DR`` refers to the ratio of the read depth in the proband to the; combined read depth in the parents.; - ``DP`` refers to the read depth (DP field) of the proband.; - ``AB`` refers to the read allele balance of the proband (number of; alternate reads divided by total reads).; - ``AC`` refers to the count of alternate alleles across all individuals; in the dataset at the site.; - ``p`` refers to :math:`\mathrm{P_{\text{de novo}}}`.; - ``min_p`` refers to the `min_p` function parameter. HIGH-quality SNV:. .. code-block:: text. (p > 0.99) AND (AB > 0.3) AND (AC == 1); OR; (p > 0.99) AND (AB > 0.3) AND (DR > 0.2); OR; (p > 0.5) AND (AB > 0.3) AND (AC < 10) AND (DP > 10). MEDIUM-quality SNV:. .. code-block:: text. (p > 0.5) AND (AB > 0.3); OR; (AC == 1). LOW-quality SNV:. .. code-block:: text. (AB > 0.2). HIGH-quality indel",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:12937,Testability,test,test,12937,"tm.mendel_code])),; [0, 0, 0],; ),; ); .key_cols_by(); .cols(); ). table3 = table3.select(; xs=[; hl.struct(**{; ck_name: table3.father[ck_name],; 'fam_id': table3.fam_id,; 'errors': table3.all_errors[0],; 'snp_errors': table3.snp_errors[0],; }),; hl.struct(**{; ck_name: table3.mother[ck_name],; 'fam_id': table3.fam_id,; 'errors': table3.all_errors[1],; 'snp_errors': table3.snp_errors[1],; }),; hl.struct(**{; ck_name: table3.proband[ck_name],; 'fam_id': table3.fam_id,; 'errors': table3.all_errors[2],; 'snp_errors': table3.snp_errors[2],; }),; ]; ); table3 = table3.explode('xs'); table3 = table3.select(**table3.xs); table3 = (; table3.group_by(ck_name, 'fam_id'); .aggregate(errors=hl.agg.sum(table3.errors), snp_errors=hl.agg.sum(table3.snp_errors)); .key_by(ck_name); ). table4 = tm.select_rows(errors=hl.agg.count_where(hl.is_defined(tm.mendel_code))).rows(). return table1, table2, table3, table4. [docs]@typecheck(dataset=MatrixTable, pedigree=Pedigree); def transmission_disequilibrium_test(dataset, pedigree) -> Table:; r""""""Performs the transmission disequilibrium test on trios. .. include:: ../_templates/req_tstring.rst. .. include:: ../_templates/req_tvariant.rst. .. include:: ../_templates/req_biallelic.rst. Examples; --------; Compute TDT association statistics and show the first two results:. >>> pedigree = hl.Pedigree.read('data/tdt_trios.fam'); >>> tdt_table = hl.transmission_disequilibrium_test(tdt_dataset, pedigree); >>> tdt_table.show(2) # doctest: +SKIP_OUTPUT_CHECK; +---------------+------------+-------+-------+----------+----------+; | locus | alleles | t | u | chi_sq | p_value |; +---------------+------------+-------+-------+----------+----------+; | locus<GRCh37> | array<str> | int64 | int64 | float64 | float64 |; +---------------+------------+-------+-------+----------+----------+; | 1:246714629 | [""C"",""A""] | 0 | 4 | 4.00e+00 | 4.55e-02 |; | 2:167262169 | [""T"",""C""] | NA | NA | NA | NA |; +---------------+------------+-------+-------+----------+---------",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:14065,Testability,test,test,14065,"de:: ../_templates/req_biallelic.rst. Examples; --------; Compute TDT association statistics and show the first two results:. >>> pedigree = hl.Pedigree.read('data/tdt_trios.fam'); >>> tdt_table = hl.transmission_disequilibrium_test(tdt_dataset, pedigree); >>> tdt_table.show(2) # doctest: +SKIP_OUTPUT_CHECK; +---------------+------------+-------+-------+----------+----------+; | locus | alleles | t | u | chi_sq | p_value |; +---------------+------------+-------+-------+----------+----------+; | locus<GRCh37> | array<str> | int64 | int64 | float64 | float64 |; +---------------+------------+-------+-------+----------+----------+; | 1:246714629 | [""C"",""A""] | 0 | 4 | 4.00e+00 | 4.55e-02 |; | 2:167262169 | [""T"",""C""] | NA | NA | NA | NA |; +---------------+------------+-------+-------+----------+----------+. Export variants with p-values below 0.001:. >>> tdt_table = tdt_table.filter(tdt_table.p_value < 0.001); >>> tdt_table.export(f""output/tdt_results.tsv""). Notes; -----; The; `transmission disequilibrium test <https://en.wikipedia.org/wiki/Transmission_disequilibrium_test#The_case_of_trios:_one_affected_child_per_family>`__; compares the number of times the alternate allele is transmitted (t) versus; not transmitted (u) from a heterozgyous parent to an affected child. The null; hypothesis holds that each case is equally likely. The TDT statistic is given by. .. math::. (t - u)^2 \over (t + u). and asymptotically follows a chi-squared distribution with one degree of; freedom under the null hypothesis. :func:`transmission_disequilibrium_test` only considers complete trios (two; parents and a proband with defined sex) and only returns results for the; autosome, as defined by :meth:`~.LocusExpression.in_autosome`, and; chromosome X. Transmissions and non-transmissions are counted only for the; configurations of genotypes and copy state in the table below, in order to; filter out Mendel errors and configurations where transmission is; guaranteed. The copy state of a locus wi",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html:22347,Usability,simpl,simplifying,22347,"; prior is the maximum of the `pop_frequency_prior` and ``1 / 3e7``.; - `proband` (``struct``) -- Proband column fields from `mt`.; - `father` (``struct``) -- Father column fields from `mt`.; - `mother` (``struct``) -- Mother column fields from `mt`.; - `proband_entry` (``struct``) -- Proband entry fields from `mt`.; - `father_entry` (``struct``) -- Father entry fields from `mt`.; - `proband_entry` (``struct``) -- Mother entry fields from `mt`.; - `is_female` (``bool``) -- ``True`` if proband is female.; - `p_de_novo` (``float64``) -- Unfiltered posterior probability; that the event is *de novo* rather than a missed heterozygous; event in a parent.; - `confidence` (``str``) Validation confidence. One of: ``'HIGH'``,; ``'MEDIUM'``, ``'LOW'``. The key of the table is ``['locus', 'alleles', 'id']``. The model looks for de novo events in which both parents are homozygous; reference and the proband is a heterozygous. The model makes the simplifying; assumption that when this configuration ``x = (AA, AA, AB)`` of calls; occurs, exactly one of the following is true:. - ``d``: a de novo mutation occurred in the proband and all calls are; accurate.; - ``m``: at least one parental allele is actually heterozygous and; the proband call is accurate. We can then estimate the posterior probability of a de novo mutation as:. .. math::. \mathrm{P_{\text{de novo}}} = \frac{\mathrm{P}(d \mid x)}{\mathrm{P}(d \mid x) + \mathrm{P}(m \mid x)}. Applying Bayes rule to the numerator and denominator yields. .. math::. \frac{\mathrm{P}(x \mid d)\,\mathrm{P}(d)}{\mathrm{P}(x \mid d)\,\mathrm{P}(d) +; \mathrm{P}(x \mid m)\,\mathrm{P}(m)}. The prior on de novo mutation is estimated from the rate in the literature:. .. math::. \mathrm{P}(d) = \frac{1 \, \text{mutation}}{30{,}000{,}000 \, \text{bases}}. The prior used for at least one alternate allele between the parents; depends on the alternate allele frequency:. .. math::. \mathrm{P}(m) = 1 - (1 - AF)^4. The likelihoods :math:`\mathrm{P}(x \mid ",MatchSource.WIKI,docs/0.2/_modules/hail/methods/family_methods.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/family_methods.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:15392,Availability,error,errors,15392,"call}. fam_exprs = {; 'fam_id': expr_or_else(fam_id, '0'),; 'ind_id': hl.or_else(ind_id, '0'),; 'pat_id': expr_or_else(pat_id, '0'),; 'mat_id': expr_or_else(mat_id, '0'),; 'is_female': expr_or_else(is_female, '0', lambda x: hl.if_else(x, '2', '1')),; 'pheno': expr_or_else(pheno, 'NA', lambda x: hl.if_else(x, '2', '1') if x.dtype == tbool else hl.str(x)),; }. locus = dataset.locus; a = dataset.alleles. bim_exprs = {; 'varid': expr_or_else(varid, hl.delimit([locus.contig, hl.str(locus.position), a[0], a[1]], ':')),; 'cm_position': expr_or_else(cm_position, 0.0),; }. for exprs, axis in [; (fam_exprs, dataset._col_indices),; (bim_exprs, dataset._row_indices),; (entry_exprs, dataset._entry_indices),; ]:; for name, expr in exprs.items():; analyze('export_plink/{}'.format(name), expr, axis). dataset = dataset._select_all(col_exprs=fam_exprs, col_key=[], row_exprs=bim_exprs, entry_exprs=entry_exprs). # check FAM ids for white space; t_cols = dataset.cols(); errors = []; for name in ['ind_id', 'fam_id', 'pat_id', 'mat_id']:; ids = t_cols.filter(t_cols[name].matches(r""\s+""))[name].collect(). if ids:; errors.append(f""""""expr '{name}' has spaces in the following values:\n""""""); for row in ids:; errors.append(f"""""" {row}\n""""""). if errors:; raise TypeError(""\n"".join(errors)). writer = ir.MatrixPLINKWriter(output); Env.backend().execute(ir.MatrixWrite(dataset._mir, writer)). [docs]@typecheck(; dataset=oneof(MatrixTable, Table),; output=str,; append_to_header=nullable(str),; parallel=nullable(ir.ExportType.checker),; metadata=nullable(dictof(str, dictof(str, dictof(str, str)))),; tabix=bool,; ); def export_vcf(dataset, output, append_to_header=None, parallel=None, metadata=None, *, tabix=False):; """"""Export a :class:`.MatrixTable` or :class:`.Table` as a VCF file. .. include:: ../_templates/req_tvariant.rst. Examples; --------; Export to VCF as a block-compressed file:. >>> hl.export_vcf(dataset, 'output/example.vcf.bgz'). Notes; -----; :func:`.export_vcf` writes the dataset to disk in ",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:15536,Availability,error,errors,15536,"expr_or_else(pat_id, '0'),; 'mat_id': expr_or_else(mat_id, '0'),; 'is_female': expr_or_else(is_female, '0', lambda x: hl.if_else(x, '2', '1')),; 'pheno': expr_or_else(pheno, 'NA', lambda x: hl.if_else(x, '2', '1') if x.dtype == tbool else hl.str(x)),; }. locus = dataset.locus; a = dataset.alleles. bim_exprs = {; 'varid': expr_or_else(varid, hl.delimit([locus.contig, hl.str(locus.position), a[0], a[1]], ':')),; 'cm_position': expr_or_else(cm_position, 0.0),; }. for exprs, axis in [; (fam_exprs, dataset._col_indices),; (bim_exprs, dataset._row_indices),; (entry_exprs, dataset._entry_indices),; ]:; for name, expr in exprs.items():; analyze('export_plink/{}'.format(name), expr, axis). dataset = dataset._select_all(col_exprs=fam_exprs, col_key=[], row_exprs=bim_exprs, entry_exprs=entry_exprs). # check FAM ids for white space; t_cols = dataset.cols(); errors = []; for name in ['ind_id', 'fam_id', 'pat_id', 'mat_id']:; ids = t_cols.filter(t_cols[name].matches(r""\s+""))[name].collect(). if ids:; errors.append(f""""""expr '{name}' has spaces in the following values:\n""""""); for row in ids:; errors.append(f"""""" {row}\n""""""). if errors:; raise TypeError(""\n"".join(errors)). writer = ir.MatrixPLINKWriter(output); Env.backend().execute(ir.MatrixWrite(dataset._mir, writer)). [docs]@typecheck(; dataset=oneof(MatrixTable, Table),; output=str,; append_to_header=nullable(str),; parallel=nullable(ir.ExportType.checker),; metadata=nullable(dictof(str, dictof(str, dictof(str, str)))),; tabix=bool,; ); def export_vcf(dataset, output, append_to_header=None, parallel=None, metadata=None, *, tabix=False):; """"""Export a :class:`.MatrixTable` or :class:`.Table` as a VCF file. .. include:: ../_templates/req_tvariant.rst. Examples; --------; Export to VCF as a block-compressed file:. >>> hl.export_vcf(dataset, 'output/example.vcf.bgz'). Notes; -----; :func:`.export_vcf` writes the dataset to disk in VCF format as described in the; `VCF 4.2 spec <https://samtools.github.io/hts-specs/VCFv4.2.pdf>`__. Use t",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:15628,Availability,error,errors,15628,"id, '0'),; 'is_female': expr_or_else(is_female, '0', lambda x: hl.if_else(x, '2', '1')),; 'pheno': expr_or_else(pheno, 'NA', lambda x: hl.if_else(x, '2', '1') if x.dtype == tbool else hl.str(x)),; }. locus = dataset.locus; a = dataset.alleles. bim_exprs = {; 'varid': expr_or_else(varid, hl.delimit([locus.contig, hl.str(locus.position), a[0], a[1]], ':')),; 'cm_position': expr_or_else(cm_position, 0.0),; }. for exprs, axis in [; (fam_exprs, dataset._col_indices),; (bim_exprs, dataset._row_indices),; (entry_exprs, dataset._entry_indices),; ]:; for name, expr in exprs.items():; analyze('export_plink/{}'.format(name), expr, axis). dataset = dataset._select_all(col_exprs=fam_exprs, col_key=[], row_exprs=bim_exprs, entry_exprs=entry_exprs). # check FAM ids for white space; t_cols = dataset.cols(); errors = []; for name in ['ind_id', 'fam_id', 'pat_id', 'mat_id']:; ids = t_cols.filter(t_cols[name].matches(r""\s+""))[name].collect(). if ids:; errors.append(f""""""expr '{name}' has spaces in the following values:\n""""""); for row in ids:; errors.append(f"""""" {row}\n""""""). if errors:; raise TypeError(""\n"".join(errors)). writer = ir.MatrixPLINKWriter(output); Env.backend().execute(ir.MatrixWrite(dataset._mir, writer)). [docs]@typecheck(; dataset=oneof(MatrixTable, Table),; output=str,; append_to_header=nullable(str),; parallel=nullable(ir.ExportType.checker),; metadata=nullable(dictof(str, dictof(str, dictof(str, str)))),; tabix=bool,; ); def export_vcf(dataset, output, append_to_header=None, parallel=None, metadata=None, *, tabix=False):; """"""Export a :class:`.MatrixTable` or :class:`.Table` as a VCF file. .. include:: ../_templates/req_tvariant.rst. Examples; --------; Export to VCF as a block-compressed file:. >>> hl.export_vcf(dataset, 'output/example.vcf.bgz'). Notes; -----; :func:`.export_vcf` writes the dataset to disk in VCF format as described in the; `VCF 4.2 spec <https://samtools.github.io/hts-specs/VCFv4.2.pdf>`__. Use the ``.vcf.bgz`` extension rather than ``.vcf`` in the ",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:15663,Availability,error,errors,15663,",; 'pheno': expr_or_else(pheno, 'NA', lambda x: hl.if_else(x, '2', '1') if x.dtype == tbool else hl.str(x)),; }. locus = dataset.locus; a = dataset.alleles. bim_exprs = {; 'varid': expr_or_else(varid, hl.delimit([locus.contig, hl.str(locus.position), a[0], a[1]], ':')),; 'cm_position': expr_or_else(cm_position, 0.0),; }. for exprs, axis in [; (fam_exprs, dataset._col_indices),; (bim_exprs, dataset._row_indices),; (entry_exprs, dataset._entry_indices),; ]:; for name, expr in exprs.items():; analyze('export_plink/{}'.format(name), expr, axis). dataset = dataset._select_all(col_exprs=fam_exprs, col_key=[], row_exprs=bim_exprs, entry_exprs=entry_exprs). # check FAM ids for white space; t_cols = dataset.cols(); errors = []; for name in ['ind_id', 'fam_id', 'pat_id', 'mat_id']:; ids = t_cols.filter(t_cols[name].matches(r""\s+""))[name].collect(). if ids:; errors.append(f""""""expr '{name}' has spaces in the following values:\n""""""); for row in ids:; errors.append(f"""""" {row}\n""""""). if errors:; raise TypeError(""\n"".join(errors)). writer = ir.MatrixPLINKWriter(output); Env.backend().execute(ir.MatrixWrite(dataset._mir, writer)). [docs]@typecheck(; dataset=oneof(MatrixTable, Table),; output=str,; append_to_header=nullable(str),; parallel=nullable(ir.ExportType.checker),; metadata=nullable(dictof(str, dictof(str, dictof(str, str)))),; tabix=bool,; ); def export_vcf(dataset, output, append_to_header=None, parallel=None, metadata=None, *, tabix=False):; """"""Export a :class:`.MatrixTable` or :class:`.Table` as a VCF file. .. include:: ../_templates/req_tvariant.rst. Examples; --------; Export to VCF as a block-compressed file:. >>> hl.export_vcf(dataset, 'output/example.vcf.bgz'). Notes; -----; :func:`.export_vcf` writes the dataset to disk in VCF format as described in the; `VCF 4.2 spec <https://samtools.github.io/hts-specs/VCFv4.2.pdf>`__. Use the ``.vcf.bgz`` extension rather than ``.vcf`` in the output file name; for `blocked GZIP <http://www.htslib.org/doc/tabix.html>`__ compressi",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:15698,Availability,error,errors,15698,"(pheno, 'NA', lambda x: hl.if_else(x, '2', '1') if x.dtype == tbool else hl.str(x)),; }. locus = dataset.locus; a = dataset.alleles. bim_exprs = {; 'varid': expr_or_else(varid, hl.delimit([locus.contig, hl.str(locus.position), a[0], a[1]], ':')),; 'cm_position': expr_or_else(cm_position, 0.0),; }. for exprs, axis in [; (fam_exprs, dataset._col_indices),; (bim_exprs, dataset._row_indices),; (entry_exprs, dataset._entry_indices),; ]:; for name, expr in exprs.items():; analyze('export_plink/{}'.format(name), expr, axis). dataset = dataset._select_all(col_exprs=fam_exprs, col_key=[], row_exprs=bim_exprs, entry_exprs=entry_exprs). # check FAM ids for white space; t_cols = dataset.cols(); errors = []; for name in ['ind_id', 'fam_id', 'pat_id', 'mat_id']:; ids = t_cols.filter(t_cols[name].matches(r""\s+""))[name].collect(). if ids:; errors.append(f""""""expr '{name}' has spaces in the following values:\n""""""); for row in ids:; errors.append(f"""""" {row}\n""""""). if errors:; raise TypeError(""\n"".join(errors)). writer = ir.MatrixPLINKWriter(output); Env.backend().execute(ir.MatrixWrite(dataset._mir, writer)). [docs]@typecheck(; dataset=oneof(MatrixTable, Table),; output=str,; append_to_header=nullable(str),; parallel=nullable(ir.ExportType.checker),; metadata=nullable(dictof(str, dictof(str, dictof(str, str)))),; tabix=bool,; ); def export_vcf(dataset, output, append_to_header=None, parallel=None, metadata=None, *, tabix=False):; """"""Export a :class:`.MatrixTable` or :class:`.Table` as a VCF file. .. include:: ../_templates/req_tvariant.rst. Examples; --------; Export to VCF as a block-compressed file:. >>> hl.export_vcf(dataset, 'output/example.vcf.bgz'). Notes; -----; :func:`.export_vcf` writes the dataset to disk in VCF format as described in the; `VCF 4.2 spec <https://samtools.github.io/hts-specs/VCFv4.2.pdf>`__. Use the ``.vcf.bgz`` extension rather than ``.vcf`` in the output file name; for `blocked GZIP <http://www.htslib.org/doc/tabix.html>`__ compression. Note; ----; We stron",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:19366,Availability,down,downstream,19366,"om their corresponding Hail types. To output a desired; Description, Number, and/or Type value in a FORMAT or INFO field or to; specify FILTER lines, use the `metadata` parameter to supply a dictionary; with the relevant information. See; :func:`get_vcf_metadata` for how to obtain the; dictionary corresponding to the original VCF, and for info on how this; dictionary should be structured. The output VCF header will also contain CONTIG lines; with ID, length, and assembly fields derived from the reference genome of; the dataset. The output VCF header will `not` contain lines added by external tools; (such as bcftools and GATK) unless they are explicitly inserted using the; `append_to_header` parameter. Warning; -------. INFO fields stored at VCF import are `not` automatically modified to; reflect filtering of samples or genotypes, which can affect the value of; AC (allele count), AF (allele frequency), AN (allele number), etc. If a; filtered dataset is exported to VCF without updating `info`, downstream; tools which may produce erroneous results. The solution is to create new; fields in `info` or overwrite existing fields. For example, in order to; produce an accurate `AC` field, one can run :func:`.variant_qc` and copy; the `variant_qc.AC` field to `info.AC` as shown below. >>> ds = dataset.filter_entries(dataset.GQ >= 20); >>> ds = hl.variant_qc(ds); >>> ds = ds.annotate_rows(info = ds.info.annotate(AC=ds.variant_qc.AC)) # doctest: +SKIP; >>> hl.export_vcf(ds, 'output/example.vcf.bgz'). Warning; -------; Do not export to a path that is being read from in the same pipeline. Parameters; ----------; dataset : :class:`.MatrixTable`; Dataset.; output : :class:`str`; Path of .vcf or .vcf.bgz file to write.; append_to_header : :class:`str`, optional; Path of file to append to VCF header.; parallel : :class:`str`, optional; If ``'header_per_shard'``, return a set of VCF files (one per; partition) rather than serially concatenating these files. If; ``'separate_header'``, re",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:33133,Availability,error,error,33133,"alid_intervals; ),; target=t['f3'],; ). else:; raise FatalError(""too few fields for BED file: expected 3 or more, but found {}"".format(len(t.row))). if skip_invalid_intervals and reference_genome:; t = t.filter(hl.is_defined(t.interval)). return t.key_by('interval'). [docs]@typecheck(path=str, quant_pheno=bool, delimiter=str, missing=str); def import_fam(path, quant_pheno=False, delimiter=r'\\s+', missing='NA') -> Table:; """"""Import a PLINK FAM file into a :class:`.Table`. Examples; --------. Import a tab-separated; `FAM file <https://www.cog-genomics.org/plink2/formats#fam>`__; with a case-control phenotype:. >>> fam_kt = hl.import_fam('data/case_control_study.fam'). Import a FAM file with a quantitative phenotype:. >>> fam_kt = hl.import_fam('data/quantitative_study.fam', quant_pheno=True). Notes; -----. In Hail, unlike PLINK, the user must *explicitly* distinguish between; case-control and quantitative phenotypes. Importing a quantitative; phenotype with ``quant_pheno=False`` will return an error; (unless all values happen to be `0`, `1`, `2`, or `-9`):. The resulting :class:`.Table` will have fields, types, and values that are interpreted as missing. - *fam_id* (:py:data:`.tstr`) -- Family ID (missing = ""0""); - *id* (:py:data:`.tstr`) -- Sample ID (key column); - *pat_id* (:py:data:`.tstr`) -- Paternal ID (missing = ""0""); - *mat_id* (:py:data:`.tstr`) -- Maternal ID (missing = ""0""); - *is_female* (:py:data:`.tstr`) -- Sex (missing = ""NA"", ""-9"", ""0""). One of:. - *is_case* (:py:data:`.tbool`) -- Case-control phenotype (missing = ""0"", ""-9"",; non-numeric or the ``missing`` argument, if given.; - *quant_pheno* (:py:data:`.tfloat64`) -- Quantitative phenotype (missing = ""NA"" or; the ``missing`` argument, if given. Warning; -------; Hail will interpret the value ""-9"" as a valid quantitative phenotype, which; differs from default PLINK behavior. Use ``missing='-9'`` to interpret this; value as missing. Parameters; ----------; path : :class:`str`; Path to FAM file.; quant_",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:47079,Availability,toler,tolerance,47079,"e TypeError(; f""'import_bgen' requires all elements in 'variants' are a non-empty prefix of the BGEN key type: {expected_vtype!r}""; ). vir = variants._tir; if (; isinstance(vir, ir.TableRead); and isinstance(vir.reader, ir.TableNativeReader); and vir.reader.intervals is None; and variants.count() == variants.distinct().count(); ):; variants_path = vir.reader.path; else:; variants_path = new_temp_file(prefix='bgen_included_vars', extension='ht'); variants.distinct().write(variants_path); else:; variants_path = None. reader = ir.MatrixBGENReader(path, sample_file, index_file_map, n_partitions, block_size, variants_path). mt = MatrixTable(ir.MatrixRead(reader)).drop(; *[fd for fd in ['GT', 'GP', 'dosage'] if fd not in entry_set],; *[fd for fd in ['rsid', 'varid', 'offset', 'file_idx'] if fd not in row_set],; ). return mt. [docs]@typecheck(; path=oneof(str, sequenceof(str)),; sample_file=nullable(str),; tolerance=numeric,; min_partitions=nullable(int),; chromosome=nullable(str),; reference_genome=nullable(reference_genome_type),; contig_recoding=nullable(dictof(str, str)),; skip_invalid_loci=bool,; ); def import_gen(; path,; sample_file=None,; tolerance=0.2,; min_partitions=None,; chromosome=None,; reference_genome='default',; contig_recoding=None,; skip_invalid_loci=False,; ) -> MatrixTable:; """"""; Import GEN file(s) as a :class:`.MatrixTable`. Examples; --------. >>> ds = hl.import_gen('data/example.gen',; ... sample_file='data/example.sample',; ... reference_genome='GRCh37'). Notes; -----. For more information on the GEN file format, see `here; <http://www.stats.ox.ac.uk/%7Emarchini/software/gwas/file_format.html#mozTocId40300>`__. If the GEN file has only 5 columns before the start of the genotype; probability data (chromosome field is missing), you must specify the; chromosome using the `chromosome` parameter. To load multiple files at the same time, use :ref:`Hadoop Glob Patterns; <sec-hadoop-glob>`. **Column Fields**. - `s` (:py:data:`.tstr`) -- Column key. This i",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:47324,Availability,toler,tolerance,47324,"e TypeError(; f""'import_bgen' requires all elements in 'variants' are a non-empty prefix of the BGEN key type: {expected_vtype!r}""; ). vir = variants._tir; if (; isinstance(vir, ir.TableRead); and isinstance(vir.reader, ir.TableNativeReader); and vir.reader.intervals is None; and variants.count() == variants.distinct().count(); ):; variants_path = vir.reader.path; else:; variants_path = new_temp_file(prefix='bgen_included_vars', extension='ht'); variants.distinct().write(variants_path); else:; variants_path = None. reader = ir.MatrixBGENReader(path, sample_file, index_file_map, n_partitions, block_size, variants_path). mt = MatrixTable(ir.MatrixRead(reader)).drop(; *[fd for fd in ['GT', 'GP', 'dosage'] if fd not in entry_set],; *[fd for fd in ['rsid', 'varid', 'offset', 'file_idx'] if fd not in row_set],; ). return mt. [docs]@typecheck(; path=oneof(str, sequenceof(str)),; sample_file=nullable(str),; tolerance=numeric,; min_partitions=nullable(int),; chromosome=nullable(str),; reference_genome=nullable(reference_genome_type),; contig_recoding=nullable(dictof(str, str)),; skip_invalid_loci=bool,; ); def import_gen(; path,; sample_file=None,; tolerance=0.2,; min_partitions=None,; chromosome=None,; reference_genome='default',; contig_recoding=None,; skip_invalid_loci=False,; ) -> MatrixTable:; """"""; Import GEN file(s) as a :class:`.MatrixTable`. Examples; --------. >>> ds = hl.import_gen('data/example.gen',; ... sample_file='data/example.sample',; ... reference_genome='GRCh37'). Notes; -----. For more information on the GEN file format, see `here; <http://www.stats.ox.ac.uk/%7Emarchini/software/gwas/file_format.html#mozTocId40300>`__. If the GEN file has only 5 columns before the start of the genotype; probability data (chromosome field is missing), you must specify the; chromosome using the `chromosome` parameter. To load multiple files at the same time, use :ref:`Hadoop Glob Patterns; <sec-hadoop-glob>`. **Column Fields**. - `s` (:py:data:`.tstr`) -- Column key. This i",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:49605,Availability,toler,tolerance,49605,"ence_genome`. Otherwise, the type; will be a :class:`.tstruct` with two fields: `contig` with type; :py:data:`.tstr` and `position` with type :py:data:`.tint32`.; - `alleles` (:class:`.tarray` of :py:data:`.tstr`) -- Row key. An array; containing the alleles of the variant. The reference allele (4th column if; `chromosome` is not defined) is the first element of the array and the; alternate allele (5th column if `chromosome` is not defined) is the second; element.; - `varid` (:py:data:`.tstr`) -- The variant identifier. 2nd column of GEN; file if chromosome present, otherwise 1st column.; - `rsid` (:py:data:`.tstr`) -- The rsID. 3rd column of GEN file if; chromosome present, otherwise 2nd column. **Entry Fields**. - `GT` (:py:data:`.tcall`) -- The hard call corresponding to the genotype with; the highest probability.; - `GP` (:class:`.tarray` of :py:data:`.tfloat64`) -- Genotype probabilities; as defined by the GEN file spec. The array is set to missing if the; sum of the probabilities is a distance greater than the `tolerance`; parameter from 1.0. Otherwise, the probabilities are normalized to sum to; 1.0. For example, the input ``[0.98, 0.0, 0.0]`` will be normalized to; ``[1.0, 0.0, 0.0]``. Parameters; ----------; path : :class:`str` or :obj:`list` of :obj:`str`; GEN files to import.; sample_file : :class:`str`; Sample file to import.; tolerance : :obj:`float`; If the sum of the genotype probabilities for a genotype differ from 1.0; by more than the tolerance, set the genotype to missing.; min_partitions : :obj:`int`, optional; Number of partitions.; chromosome : :class:`str`, optional; Chromosome if not included in the GEN file; reference_genome : :class:`str` or :class:`.ReferenceGenome`, optional; Reference genome to use.; contig_recoding : :obj:`dict` of :class:`str` to :obj:`str`, optional; Dict of old contig name to new contig name. The new contig name must be; in the reference genome given by `reference_genome`.; skip_invalid_loci : :obj:`bool`; If ``True``",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:49933,Availability,toler,tolerance,49933,"lumn if `chromosome` is not defined) is the second; element.; - `varid` (:py:data:`.tstr`) -- The variant identifier. 2nd column of GEN; file if chromosome present, otherwise 1st column.; - `rsid` (:py:data:`.tstr`) -- The rsID. 3rd column of GEN file if; chromosome present, otherwise 2nd column. **Entry Fields**. - `GT` (:py:data:`.tcall`) -- The hard call corresponding to the genotype with; the highest probability.; - `GP` (:class:`.tarray` of :py:data:`.tfloat64`) -- Genotype probabilities; as defined by the GEN file spec. The array is set to missing if the; sum of the probabilities is a distance greater than the `tolerance`; parameter from 1.0. Otherwise, the probabilities are normalized to sum to; 1.0. For example, the input ``[0.98, 0.0, 0.0]`` will be normalized to; ``[1.0, 0.0, 0.0]``. Parameters; ----------; path : :class:`str` or :obj:`list` of :obj:`str`; GEN files to import.; sample_file : :class:`str`; Sample file to import.; tolerance : :obj:`float`; If the sum of the genotype probabilities for a genotype differ from 1.0; by more than the tolerance, set the genotype to missing.; min_partitions : :obj:`int`, optional; Number of partitions.; chromosome : :class:`str`, optional; Chromosome if not included in the GEN file; reference_genome : :class:`str` or :class:`.ReferenceGenome`, optional; Reference genome to use.; contig_recoding : :obj:`dict` of :class:`str` to :obj:`str`, optional; Dict of old contig name to new contig name. The new contig name must be; in the reference genome given by `reference_genome`.; skip_invalid_loci : :obj:`bool`; If ``True``, skip loci that are not consistent with `reference_genome`. Returns; -------; :class:`.MatrixTable`; """"""; gen_table = import_lines(path, min_partitions); sample_table = import_lines(sample_file); rg = reference_genome.name if reference_genome else None; if contig_recoding is None:; contig_recoding = hl.empty_dict(hl.tstr, hl.tstr); else:; contig_recoding = hl.dict(contig_recoding). gen_table = gen_table",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:50049,Availability,toler,tolerance,50049,"ata:`.tstr`) -- The variant identifier. 2nd column of GEN; file if chromosome present, otherwise 1st column.; - `rsid` (:py:data:`.tstr`) -- The rsID. 3rd column of GEN file if; chromosome present, otherwise 2nd column. **Entry Fields**. - `GT` (:py:data:`.tcall`) -- The hard call corresponding to the genotype with; the highest probability.; - `GP` (:class:`.tarray` of :py:data:`.tfloat64`) -- Genotype probabilities; as defined by the GEN file spec. The array is set to missing if the; sum of the probabilities is a distance greater than the `tolerance`; parameter from 1.0. Otherwise, the probabilities are normalized to sum to; 1.0. For example, the input ``[0.98, 0.0, 0.0]`` will be normalized to; ``[1.0, 0.0, 0.0]``. Parameters; ----------; path : :class:`str` or :obj:`list` of :obj:`str`; GEN files to import.; sample_file : :class:`str`; Sample file to import.; tolerance : :obj:`float`; If the sum of the genotype probabilities for a genotype differ from 1.0; by more than the tolerance, set the genotype to missing.; min_partitions : :obj:`int`, optional; Number of partitions.; chromosome : :class:`str`, optional; Chromosome if not included in the GEN file; reference_genome : :class:`str` or :class:`.ReferenceGenome`, optional; Reference genome to use.; contig_recoding : :obj:`dict` of :class:`str` to :obj:`str`, optional; Dict of old contig name to new contig name. The new contig name must be; in the reference genome given by `reference_genome`.; skip_invalid_loci : :obj:`bool`; If ``True``, skip loci that are not consistent with `reference_genome`. Returns; -------; :class:`.MatrixTable`; """"""; gen_table = import_lines(path, min_partitions); sample_table = import_lines(sample_file); rg = reference_genome.name if reference_genome else None; if contig_recoding is None:; contig_recoding = hl.empty_dict(hl.tstr, hl.tstr); else:; contig_recoding = hl.dict(contig_recoding). gen_table = gen_table.transmute(data=gen_table.text.split(' ')). if chromosome is None:; last_rowf_i",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:52729,Availability,toler,tolerance,52729,"us(contig_holder, position, rg). gen_table = gen_table.annotate(locus=locus, alleles=alleles, rsid=rsid, varid=varid); gen_table = gen_table.annotate(; entries=gen_table.data[last_rowf_idx + 1 :]; .map(lambda x: hl.float64(x)); .grouped(3); .map(lambda x: hl.struct(GP=x)); ); if skip_invalid_loci:; gen_table = gen_table.filter(hl.is_defined(gen_table.locus)). sample_table_count = sample_table.count() - 2 # Skipping first 2 unneeded rows in sample file; gen_table = gen_table.annotate_globals(cols=hl.range(sample_table_count).map(lambda x: hl.struct(col_idx=x))); mt = gen_table._unlocalize_entries('entries', 'cols', ['col_idx']). sample_table = sample_table.tail(sample_table_count).add_index(); sample_table = sample_table.annotate(s=sample_table.text.split(' ')[0]); sample_table = sample_table.key_by(sample_table.idx); mt = mt.annotate_cols(s=sample_table[hl.int64(mt.col_idx)].s). mt = mt.annotate_entries(; GP=hl.rbind(; hl.sum(mt.GP),; lambda gp_sum: hl.if_else(; hl.abs(1.0 - gp_sum) > tolerance, hl.missing(hl.tarray(hl.tfloat64)), hl.abs((1 / gp_sum) * mt.GP); ),; ); ); mt = mt.annotate_entries(; GT=hl.rbind(; hl.argmax(mt.GP),; lambda max_idx: hl.if_else(; hl.len(mt.GP.filter(lambda y: y == mt.GP[max_idx])) == 1,; hl.switch(max_idx); .when(0, hl.call(0, 0)); .when(1, hl.call(0, 1)); .when(2, hl.call(1, 1)); .or_error(""error creating gt field.""),; hl.missing(hl.tcall),; ),; ); ); mt = mt.filter_entries(hl.is_defined(mt.GP)). mt = mt.key_cols_by('s').drop('col_idx', 'file', 'data'); mt = mt.key_rows_by('locus', 'alleles').select_entries('GT', 'GP'); return mt. [docs]@typecheck(; paths=oneof(str, sequenceof(str)),; key=table_key_type,; min_partitions=nullable(int),; impute=bool,; no_header=bool,; comment=oneof(str, sequenceof(str)),; delimiter=str,; missing=oneof(str, sequenceof(str)),; types=dictof(str, hail_type),; quote=nullable(char),; skip_blank_lines=bool,; force_bgz=bool,; filter=nullable(str),; find_replace=nullable(sized_tupleof(str, str)),; force=bool,; sour",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:53070,Availability,error,error,53070,"able.locus)). sample_table_count = sample_table.count() - 2 # Skipping first 2 unneeded rows in sample file; gen_table = gen_table.annotate_globals(cols=hl.range(sample_table_count).map(lambda x: hl.struct(col_idx=x))); mt = gen_table._unlocalize_entries('entries', 'cols', ['col_idx']). sample_table = sample_table.tail(sample_table_count).add_index(); sample_table = sample_table.annotate(s=sample_table.text.split(' ')[0]); sample_table = sample_table.key_by(sample_table.idx); mt = mt.annotate_cols(s=sample_table[hl.int64(mt.col_idx)].s). mt = mt.annotate_entries(; GP=hl.rbind(; hl.sum(mt.GP),; lambda gp_sum: hl.if_else(; hl.abs(1.0 - gp_sum) > tolerance, hl.missing(hl.tarray(hl.tfloat64)), hl.abs((1 / gp_sum) * mt.GP); ),; ); ); mt = mt.annotate_entries(; GT=hl.rbind(; hl.argmax(mt.GP),; lambda max_idx: hl.if_else(; hl.len(mt.GP.filter(lambda y: y == mt.GP[max_idx])) == 1,; hl.switch(max_idx); .when(0, hl.call(0, 0)); .when(1, hl.call(0, 1)); .when(2, hl.call(1, 1)); .or_error(""error creating gt field.""),; hl.missing(hl.tcall),; ),; ); ); mt = mt.filter_entries(hl.is_defined(mt.GP)). mt = mt.key_cols_by('s').drop('col_idx', 'file', 'data'); mt = mt.key_rows_by('locus', 'alleles').select_entries('GT', 'GP'); return mt. [docs]@typecheck(; paths=oneof(str, sequenceof(str)),; key=table_key_type,; min_partitions=nullable(int),; impute=bool,; no_header=bool,; comment=oneof(str, sequenceof(str)),; delimiter=str,; missing=oneof(str, sequenceof(str)),; types=dictof(str, hail_type),; quote=nullable(char),; skip_blank_lines=bool,; force_bgz=bool,; filter=nullable(str),; find_replace=nullable(sized_tupleof(str, str)),; force=bool,; source_file_field=nullable(str),; ); def import_table(; paths,; key=None,; min_partitions=None,; impute=False,; no_header=False,; comment=(),; delimiter=""\t"",; missing=""NA"",; types={},; quote=None,; skip_blank_lines=False,; force_bgz=False,; filter=None,; find_replace=None,; force=False,; source_file_field=None,; ) -> Table:; """"""Import delimited text",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:59579,Availability,error,error,59579,"Files to import.; key : :class:`str` or :obj:`list` of :obj:`str`; Key fields(s).; min_partitions : :obj:`int` or :obj:`None`; Minimum number of partitions.; no_header : :obj:`bool`; If ``True```, assume the file has no header and name the N fields `f0`,; `f1`, ... `fN` (0-indexed).; impute : :obj:`bool`; If ``True``, Impute field types from the file.; comment : :class:`str` or :obj:`list` of :obj:`str`; Skip lines beginning with the given string if the string is a single; character. Otherwise, skip lines that match the regex specified. Multiple; comment characters or patterns should be passed as a list.; delimiter : :class:`str`; Field delimiter regex.; missing : :class:`str` or :obj:`list` [:obj:`str`]; Identifier(s) to be treated as missing.; types : :obj:`dict` mapping :class:`str` to :class:`.HailType`; Dictionary defining field types.; quote : :class:`str` or :obj:`None`; Quote character.; skip_blank_lines : :obj:`bool`; If ``True``, ignore empty lines. Otherwise, throw an error if an empty; line is found.; force_bgz : :obj:`bool`; If ``True``, load files as blocked gzip files, assuming; that they were actually compressed using the BGZ codec. This option is; useful when the file extension is not ``'.bgz'``, but the file is; blocked gzip, so that the file can be read in parallel and not on a; single node.; filter : :class:`str`, optional; Line filter regex. A partial match results in the line being removed; from the file. Applies before `find_replace`, if both are defined.; find_replace : (:class:`str`, :obj:`str`); Line substitution regex. Functions like ``re.sub``, but obeys the exact; semantics of Java's; `String.replaceAll <https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/lang/String.html#replaceAll(java.lang.String,java.lang.String)>`__.; force : :obj:`bool`; If ``True``, load gzipped files serially on one core. This should; be used only when absolutely necessary, as processing time will be; increased due to lack of parallelism.; source_fi",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:76807,Availability,error,error,76807,"ile, True)); + hl.str("" on line ""); + hl.str(row.row_id - get_file_start(row) + 1); + hl.str("" at value '""); + hl.str(row.split_array[idx]); + hl.str(""':\n""); + hl.str(msg); ). def parse_type_or_error(hail_type, row, idx, not_entries=True):; value = row.split_array[idx]; if hail_type == hl.tint32:; parsed_type = hl.parse_int32(value); elif hail_type == hl.tint64:; parsed_type = hl.parse_int64(value); elif hail_type == hl.tfloat32:; parsed_type = hl.parse_float32(value); elif hail_type == hl.tfloat64:; parsed_type = hl.parse_float64(value); else:; parsed_type = value. if not_entries:; error_clarify_msg = hl.str("" at row field '"") + hl.str(hl_row_fields[idx]) + hl.str(""'""); else:; error_clarify_msg = (; hl.str("" at column id '""); + hl.str(hl_columns[idx - num_of_row_fields]); + hl.str(""' for entry field 'x' ""); ). return hl.if_else(; hl.is_missing(value),; hl.missing(hail_type),; hl.case(); .when(~hl.is_missing(parsed_type), parsed_type); .or_error(error_msg(row, idx, f""error parsing value into {hail_type!s}"" + error_clarify_msg)),; ). num_of_row_fields = len(row_fields.keys()); add_row_id = False; if len(row_key) == 0:; add_row_id = True; row_key = ['row_id']. if sep is not None:; if delimiter is not None:; raise ValueError(f'expecting either sep or delimiter but received both: ' f'{sep}, {delimiter}'); delimiter = sep; del sep. if delimiter is None:; delimiter = '\t'; if len(delimiter) != 1:; raise FatalError('delimiter or sep must be a single character'). if add_row_id:; if 'row_id' in row_fields:; raise FatalError(; ""import_matrix_table reserves the field name 'row_id' for"" 'its own use, please use a different name'; ). for k, v in row_fields.items():; if v not in {tint32, tint64, tfloat32, tfloat64, tstr}:; raise FatalError(; f'import_matrix_table expects field types to be one of:'; f""'int32', 'int64', 'float32', 'float64', 'str': field {k!r} had type '{v}'""; ). if entry_type not in {tint32, tint64, tfloat32, tfloat64, tstr}:; raise FatalError(; """"""import_matrix_t",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:101853,Availability,down,downstream,101853,"ant.; - `rsid` (:py:data:`.tstr`) -- rsID of the variant.; - `qual` (:py:data:`.tfloat64`) -- Floating-point number in the QUAL field.; - `info` (:class:`.tstruct`) -- All INFO fields defined in the VCF header; can be found in the struct `info`. Data types match the type specified; in the VCF header, and if the declared ``Number`` is not 1, the result; will be stored as an array. **Entry Fields**. :func:`.import_vcf` generates an entry field for each FORMAT field declared; in the VCF header. The types of these fields are generated according to the; same rules as INFO fields, with one difference -- ""GT"" and other fields; specified in `call_fields` will be read as :py:data:`.tcall`. Parameters; ----------; path : :class:`str` or :obj:`list` of :obj:`str`; One or more paths to VCF files to read. Each path may or may not include glob expressions; like ``*``, ``?``, or ``[abc123]``.; force : :obj:`bool`; If ``True``, load **.vcf.gz** files serially. No downstream operations; can be parallelized, so this mode is strongly discouraged.; force_bgz : :obj:`bool`; If ``True``, load **.vcf.gz** files as blocked gzip files, assuming that they were actually; compressed using the BGZ codec.; header_file : :class:`str`, optional; Optional header override file. If not specified, the first file in; `path` is used. Glob patterns are not allowed in the `header_file`.; min_partitions : :obj:`int`, optional; Minimum partitions to load per file.; drop_samples : :obj:`bool`; If ``True``, create sites-only dataset. Don't load sample IDs or; entries.; call_fields : :obj:`list` of :class:`str`; List of FORMAT fields to load as :py:data:`.tcall`. ""GT"" is; loaded as a call automatically.; reference_genome: :class:`str` or :class:`.ReferenceGenome`, optional; Reference genome to use.; contig_recoding: :obj:`dict` of (:class:`str`, :obj:`str`), optional; Mapping from contig name in VCF to contig name in loaded dataset.; All contigs must be present in the `reference_genome`, so this is; useful for ",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:117882,Availability,error,error,117882,"aths : :class:`str` or :obj:`list` of :obj:`str`; Files to import.; key : :class:`str` or :obj:`list` of :obj:`str`; Key fields(s).; min_partitions : :obj:`int` or :obj:`None`; Minimum number of partitions.; no_header : :obj:`bool`; If ``True```, assume the file has no header and name the N fields `f0`,; `f1`, ... `fN` (0-indexed).; impute : :obj:`bool`; If ``True``, Impute field types from the file.; comment : :class:`str` or :obj:`list` of :obj:`str`; Skip lines beginning with the given string if the string is a single; character. Otherwise, skip lines that match the regex specified. Multiple; comment characters or patterns should be passed as a list.; missing : :class:`str` or :obj:`list` [:obj:`str`]; Identifier(s) to be treated as missing.; types : :obj:`dict` mapping :class:`str` to :class:`.HailType`; Dictionary defining field types.; quote : :class:`str` or :obj:`None`; Quote character.; skip_blank_lines : :obj:`bool`; If ``True``, ignore empty lines. Otherwise, throw an error if an empty; line is found.; force_bgz : :obj:`bool`; If ``True``, load files as blocked gzip files, assuming; that they were actually compressed using the BGZ codec. This option is; useful when the file extension is not ``'.bgz'``, but the file is; blocked gzip, so that the file can be read in parallel and not on a; single node.; filter : :class:`str`, optional; Line filter regex. A partial match results in the line being removed; from the file. Applies before `find_replace`, if both are defined.; find_replace : (:class:`str`, :obj:`str`); Line substitution regex. Functions like ``re.sub``, but obeys the exact; semantics of Java's; `String.replaceAll <https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/lang/String.html#replaceAll(java.lang.String,java.lang.String)>`__.; force : :obj:`bool`; If ``True``, load gzipped files serially on one core. This should; be used only when absolutely necessary, as processing time will be; increased due to lack of parallelism.; source_fi",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:19950,Deployability,pipeline,pipeline,19950,"will `not` contain lines added by external tools; (such as bcftools and GATK) unless they are explicitly inserted using the; `append_to_header` parameter. Warning; -------. INFO fields stored at VCF import are `not` automatically modified to; reflect filtering of samples or genotypes, which can affect the value of; AC (allele count), AF (allele frequency), AN (allele number), etc. If a; filtered dataset is exported to VCF without updating `info`, downstream; tools which may produce erroneous results. The solution is to create new; fields in `info` or overwrite existing fields. For example, in order to; produce an accurate `AC` field, one can run :func:`.variant_qc` and copy; the `variant_qc.AC` field to `info.AC` as shown below. >>> ds = dataset.filter_entries(dataset.GQ >= 20); >>> ds = hl.variant_qc(ds); >>> ds = ds.annotate_rows(info = ds.info.annotate(AC=ds.variant_qc.AC)) # doctest: +SKIP; >>> hl.export_vcf(ds, 'output/example.vcf.bgz'). Warning; -------; Do not export to a path that is being read from in the same pipeline. Parameters; ----------; dataset : :class:`.MatrixTable`; Dataset.; output : :class:`str`; Path of .vcf or .vcf.bgz file to write.; append_to_header : :class:`str`, optional; Path of file to append to VCF header.; parallel : :class:`str`, optional; If ``'header_per_shard'``, return a set of VCF files (one per; partition) rather than serially concatenating these files. If; ``'separate_header'``, return a separate VCF header file and a set of; VCF files (one per partition) without the header. If ``None``,; concatenate the header and all partitions into one VCF file.; metadata : :obj:`dict` [:obj:`str`, :obj:`dict` [:obj:`str`, :obj:`dict` [:obj:`str`, :obj:`str`]]], optional; Dictionary with information to fill in the VCF header. See; :func:`get_vcf_metadata` for how this; dictionary should be structured.; tabix : :obj:`bool`, optional; If true, writes a tabix index for the output VCF.; **Note**: This feature is experimental, and the interface ",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:112139,Deployability,configurat,configuration,112139,"titions:; intervals = ht._calculate_new_partitions(_n_partitions); return read_table(; path,; _intervals=intervals,; _assert_type=ht._type,; _load_refs=_load_refs,; _create_row_uids=_create_row_uids,; ); return ht. [docs]@typecheck(; t=Table,; host=str,; port=int,; index=str,; index_type=str,; block_size=int,; config=nullable(dictof(str, str)),; verbose=bool,; ); def export_elasticsearch(t, host, port, index, index_type, block_size, config=None, verbose=True):; """"""Export a :class:`.Table` to Elasticsearch. By default, this method supports Elasticsearch versions 6.8.x - 7.x.x. Older versions of elasticsearch will require; recompiling hail. .. warning::; :func:`.export_elasticsearch` is EXPERIMENTAL. .. note::; Table rows may be exported more than once. For example, if a task has to be retried after being preempted; midway through processing a partition. To avoid duplicate documents in Elasticsearch, use a `config` with the; `es.mapping.id <https://www.elastic.co/guide/en/elasticsearch/hadoop/current/configuration.html#cfg-mapping>`__; option set to a field that contains a unique value for each row.; """""". jdf = t.expand_types().to_spark(flatten=False)._jdf; Env.hail().io.ElasticsearchConnector.export(jdf, host, port, index, index_type, block_size, config, verbose). @typecheck(paths=sequenceof(str), key=nullable(sequenceof(str)), intervals=nullable(sequenceof(anytype))); def import_avro(paths, *, key=None, intervals=None):; if not paths:; raise ValueError('import_avro requires at least one path'); if (key is None) != (intervals is None):; raise ValueError('key and intervals must either be both defined or both undefined'). with hl.current_backend().fs.open(paths[0], 'rb') as avro_file:; # monkey patch DataFileReader.determine_file_length to account for bug in Google HadoopFS. def patched_determine_file_length(self) -> int:; remember_pos = self.reader.tell(); self.reader.seek(-1, 2); file_length = self.reader.tell() + 1; self.reader.seek(remember_pos); return file_length.",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:112846,Deployability,patch,patch,112846,". note::; Table rows may be exported more than once. For example, if a task has to be retried after being preempted; midway through processing a partition. To avoid duplicate documents in Elasticsearch, use a `config` with the; `es.mapping.id <https://www.elastic.co/guide/en/elasticsearch/hadoop/current/configuration.html#cfg-mapping>`__; option set to a field that contains a unique value for each row.; """""". jdf = t.expand_types().to_spark(flatten=False)._jdf; Env.hail().io.ElasticsearchConnector.export(jdf, host, port, index, index_type, block_size, config, verbose). @typecheck(paths=sequenceof(str), key=nullable(sequenceof(str)), intervals=nullable(sequenceof(anytype))); def import_avro(paths, *, key=None, intervals=None):; if not paths:; raise ValueError('import_avro requires at least one path'); if (key is None) != (intervals is None):; raise ValueError('key and intervals must either be both defined or both undefined'). with hl.current_backend().fs.open(paths[0], 'rb') as avro_file:; # monkey patch DataFileReader.determine_file_length to account for bug in Google HadoopFS. def patched_determine_file_length(self) -> int:; remember_pos = self.reader.tell(); self.reader.seek(-1, 2); file_length = self.reader.tell() + 1; self.reader.seek(remember_pos); return file_length. original_determine_file_length = DataFileReader.determine_file_length. try:; DataFileReader.determine_file_length = patched_determine_file_length. with DataFileReader(avro_file, DatumReader()) as data_file_reader:; tr = ir.AvroTableReader(avro.schema.parse(data_file_reader.schema), paths, key, intervals). finally:; DataFileReader.determine_file_length = original_determine_file_length. return Table(ir.TableRead(tr)). @typecheck(; paths=oneof(str, sequenceof(str)),; key=table_key_type,; min_partitions=nullable(int),; impute=bool,; no_header=bool,; comment=oneof(str, sequenceof(str)),; missing=oneof(str, sequenceof(str)),; types=dictof(str, hail_type),; quote=nullable(char),; skip_blank_lines=bool,; f",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:119522,Deployability,update,updated,119522," missing : :class:`str` or :obj:`list` [:obj:`str`]; Identifier(s) to be treated as missing.; types : :obj:`dict` mapping :class:`str` to :class:`.HailType`; Dictionary defining field types.; quote : :class:`str` or :obj:`None`; Quote character.; skip_blank_lines : :obj:`bool`; If ``True``, ignore empty lines. Otherwise, throw an error if an empty; line is found.; force_bgz : :obj:`bool`; If ``True``, load files as blocked gzip files, assuming; that they were actually compressed using the BGZ codec. This option is; useful when the file extension is not ``'.bgz'``, but the file is; blocked gzip, so that the file can be read in parallel and not on a; single node.; filter : :class:`str`, optional; Line filter regex. A partial match results in the line being removed; from the file. Applies before `find_replace`, if both are defined.; find_replace : (:class:`str`, :obj:`str`); Line substitution regex. Functions like ``re.sub``, but obeys the exact; semantics of Java's; `String.replaceAll <https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/lang/String.html#replaceAll(java.lang.String,java.lang.String)>`__.; force : :obj:`bool`; If ``True``, load gzipped files serially on one core. This should; be used only when absolutely necessary, as processing time will be; increased due to lack of parallelism.; source_file_field : :class:`str`, optional; If defined, the source file name for each line will be a field of the table; with this name. Can be useful when importing multiple tables using glob patterns.; Returns; -------; :class:`.Table`; """""". ht = hl.import_table(; paths,; key=key,; min_partitions=min_partitions,; impute=impute,; no_header=no_header,; comment=comment,; missing=missing,; types=types,; skip_blank_lines=skip_blank_lines,; force_bgz=force_bgz,; filter=filter,; find_replace=find_replace,; force=force,; source_file_field=source_file_field,; delimiter="","",; quote=quote,; ); return ht. © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:20905,Integrability,interface,interface,20905,"a path that is being read from in the same pipeline. Parameters; ----------; dataset : :class:`.MatrixTable`; Dataset.; output : :class:`str`; Path of .vcf or .vcf.bgz file to write.; append_to_header : :class:`str`, optional; Path of file to append to VCF header.; parallel : :class:`str`, optional; If ``'header_per_shard'``, return a set of VCF files (one per; partition) rather than serially concatenating these files. If; ``'separate_header'``, return a separate VCF header file and a set of; VCF files (one per partition) without the header. If ``None``,; concatenate the header and all partitions into one VCF file.; metadata : :obj:`dict` [:obj:`str`, :obj:`dict` [:obj:`str`, :obj:`dict` [:obj:`str`, :obj:`str`]]], optional; Dictionary with information to fill in the VCF header. See; :func:`get_vcf_metadata` for how this; dictionary should be structured.; tabix : :obj:`bool`, optional; If true, writes a tabix index for the output VCF.; **Note**: This feature is experimental, and the interface and defaults; may change in future versions.; """"""; hl.current_backend().validate_file(output). _, ext = os.path.splitext(output); if ext == '.gz':; warning(; 'VCF export with standard gzip compression requested. This is almost *never* desired and will '; 'cause issues with other tools that consume VCF files. The compression format used for VCF '; 'files is traditionally *block* gzip compression. To use block gzip compression with hail VCF '; 'export, use a path ending in `.bgz`.'; ). if isinstance(dataset, Table):; mt = MatrixTable.from_rows_table(dataset); dataset = mt.key_cols_by(sample=""""). require_col_key_str(dataset, 'export_vcf'); require_row_key_variant(dataset, 'export_vcf'). if 'filters' in dataset.row and dataset.filters.dtype != hl.tset(hl.tstr):; raise ValueError(; f""'export_vcf': expect the 'filters' field to be set<str>, found {dataset.filters.dtype}""; f""\n Either transform this field to set<str> to export as VCF FILTERS field, or drop it from the dataset.""; ). in",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:89395,Integrability,depend,dependent,89395,"-------; bed : :class:`str`; PLINK BED file. bim : :class:`str`; PLINK BIM file. fam : :class:`str`; PLINK FAM file. min_partitions : :obj:`int`, optional; Minimum number of partitions. Useful in conjunction with `block_size`. missing : :class:`str`; String used to denote missing values **only** for the phenotype field.; This is in addition to ""-9"", ""0"", and ""N/A"" for case-control; phenotypes. delimiter : :class:`str`; FAM file field delimiter regex. quant_pheno : :obj:`bool`; If ``True``, FAM phenotype is interpreted as quantitative. a2_reference : :obj:`bool`; If ``True``, A2 is treated as the reference allele. If False, A1 is treated; as the reference allele. reference_genome : :class:`str` or :class:`.ReferenceGenome`, optional; Reference genome to use. contig_recoding : :obj:`dict` of :class:`str` to :obj:`str`, optional; Dict of old contig name to new contig name. The new contig name must be; in the reference genome given by ``reference_genome``. If ``None``, the; default is dependent on the ``reference_genome``. For ""GRCh37"", the default; is ``{'23': 'X', '24': 'Y', '25': 'X', '26': 'MT'}``. For ""GRCh38"", the; default is ``{'1': 'chr1', ..., '22': 'chr22', '23': 'chrX', '24': 'chrY', '25': 'chrX', '26': 'chrM'}``. skip_invalid_loci : :obj:`bool`; If ``True``, skip loci that are not consistent with `reference_genome`. n_partitions : :obj:`int`, optional; Number of partitions. If both `n_partitions` and `block_size`; are specified, `n_partitions` will be used. block_size : :obj:`int`, optional; Block size, in MB. Default: 128MB blocks. Returns; -------; :class:`.MatrixTable`. """""". if contig_recoding is None:; if reference_genome is None:; contig_recoding = {}; elif reference_genome.name == ""GRCh37"":; contig_recoding = {'23': 'X', '24': 'Y', '25': 'X', '26': 'MT'}; elif reference_genome.name == ""GRCh38"":; contig_recoding = {; **{str(i): f'chr{i}' for i in range(1, 23)},; **{'23': 'chrX', '24': 'chrY', '25': 'chrX', '26': 'chrM'},; }; else:; contig_recoding = {}.",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:24203,Modifiability,parameteriz,parameterized,24203,"vals(; path, reference_genome='default', skip_invalid_intervals=False, contig_recoding=None, **kwargs; ) -> Table:; """"""Import a locus interval list as a :class:`.Table`. Examples; --------. Add the row field `capture_region` indicating inclusion in; at least one locus interval from `capture_intervals.txt`:. >>> intervals = hl.import_locus_intervals('data/capture_intervals.txt', reference_genome='GRCh37'); >>> result = dataset.annotate_rows(capture_region = hl.is_defined(intervals[dataset.locus])). Notes; -----. Hail expects an interval file to contain either one, three or five fields; per line in the following formats:. - ``contig:start-end``; - ``contig start end`` (tab-separated); - ``contig start end direction target`` (tab-separated). A file in either of the first two formats produces a table with one; field:. - **interval** (:class:`.tinterval`) - Row key. Genomic interval. If; `reference_genome` is defined, the point type of the interval will be; :class:`.tlocus` parameterized by the `reference_genome`. Otherwise,; the point type is a :class:`.tstruct` with two fields: `contig` with; type :obj:`.tstr` and `position` with type :py:data:`.tint32`. A file in the third format (with a ""target"" column) produces a table with two; fields:. - **interval** (:class:`.tinterval`) - Row key. Same schema as above.; - **target** (:py:data:`.tstr`). If `reference_genome` is defined **AND** the file has one field, intervals; are parsed with :func:`.parse_locus_interval`. See the documentation for; valid inputs. If `reference_genome` is **NOT** defined and the file has one field,; intervals are parsed with the regex ```""([^:]*):(\\d+)\\-(\\d+)""``; where contig, start, and end match each of the three capture groups.; ``start`` and ``end`` match positions inclusively, e.g.; ``start <= position <= end``. For files with three or five fields, ``start`` and ``end`` match positions; inclusively, e.g. ``start <= position <= end``. Parameters; ----------; path : :class:`str`; Path to fi",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:29306,Modifiability,parameteriz,parameterized,29306,"rack name=""BedTest""; 20 1 14000000; 20 17000000 18000000; ... $ cat file2.bed; track name=""BedTest""; 20 1 14000000 cnv1; 20 17000000 18000000 cnv2; ... Add the row field `cnv_region` indicating inclusion in; at least one interval of the three-column BED file:. >>> bed = hl.import_bed('data/file1.bed', reference_genome='GRCh37'); >>> result = dataset.annotate_rows(cnv_region = hl.is_defined(bed[dataset.locus])). Add a row field `cnv_id` with the value given by the; fourth column of a BED file:. >>> bed = hl.import_bed('data/file2.bed'); >>> result = dataset.annotate_rows(cnv_id = bed[dataset.locus].target). Notes; -----. The table produced by this method has one of two possible structures. If; the .bed file has only three fields (`chrom`, `chromStart`, and; `chromEnd`), then the produced table has only one column:. - **interval** (:class:`.tinterval`) - Row key. Genomic interval. If; `reference_genome` is defined, the point type of the interval will be; :class:`.tlocus` parameterized by the `reference_genome`. Otherwise,; the point type is a :class:`.tstruct` with two fields: `contig` with; type :py:data:`.tstr` and `position` with type :py:data:`.tint32`. If the .bed file has four or more columns, then Hail will store the fourth; column as a row field in the table:. - *interval* (:class:`.tinterval`) - Row key. Genomic interval. Same schema as above.; - *target* (:py:data:`.tstr`) - Fourth column of .bed file. `UCSC bed files <https://genome.ucsc.edu/FAQ/FAQformat.html#format1>`__ can; have up to 12 fields, but Hail will only ever look at the first four. Hail; ignores header lines in BED files. Warning; -------; Intervals in UCSC BED files are 0-indexed and half open.; The line ""5 100 105"" correpsonds to the interval ``[5:101-5:106)`` in Hail's; 1-indexed notation. Details; `here <http://genome.ucsc.edu/blog/the-ucsc-genome-browser-coordinate-counting-systems/>`__. Parameters; ----------; path : :class:`str`; Path to .bed file.; reference_genome : :class:`str` or :c",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:35608,Modifiability,sandbox,sandbox,35608,"na(type_and_data['data']), typ, key=['id']). [docs]@typecheck(regex=str, path=oneof(str, sequenceof(str)), max_count=int, show=bool, force=bool, force_bgz=bool); def grep(regex, path, max_count=100, *, show: bool = True, force: bool = False, force_bgz: bool = False):; r""""""Searches given paths for all lines containing regex matches. Examples; --------. Print all lines containing the string ``hello`` in *file.txt*:. >>> hl.grep('hello','data/file.txt'). Print all lines containing digits in *file1.txt* and *file2.txt*:. >>> hl.grep('\\d', ['data/file1.txt','data/file2.txt']). Notes; -----; :func:`.grep` mimics the basic functionality of Unix ``grep`` in; parallel, printing results to the screen. This command is provided as a; convenience to those in the statistical genetics community who often; search enormous text files like VCFs. Hail uses `Java regular expression; patterns; <https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/util/regex/Pattern.html>`__.; The `RegExr sandbox <http://regexr.com/>`__ may be helpful. Parameters; ----------; regex : :class:`str`; The regular expression to match.; path : :class:`str` or :obj:`list` of :obj:`str`; The files to search.; max_count : :obj:`int`; The maximum number of matches to return; show : :obj:`bool`; When `True`, show the values on stdout. When `False`, return a; dictionary mapping file names to lines.; force_bgz : :obj:`bool`; If ``True``, read files as blocked gzip files, assuming; that they were actually compressed using the BGZ codec. This option is; useful when the file extension is not ``'.bgz'``, but the file is; blocked gzip, so that the file can be read in parallel and not on a; single node.; force : :obj:`bool`; If ``True``, read gzipped files serially on one core. This should; be used only when absolutely necessary, as processing time will be; increased due to lack of parallelism. Returns; ---; :obj:`dict` of :class:`str` to :obj:`list` of :obj:`str`; """"""; from hail.backend.spark_backend import S",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:40823,Modifiability,parameteriz,parameterized,40823,"op Glob Patterns <sec-hadoop-glob>`. If n_partitions and block_size are both specified, block_size is; used. If neither are specified, the default is a 128MB block; size. **Column Fields**. - `s` (:py:data:`.tstr`) -- Column key. This is the sample ID imported; from the first column of the sample file if given. Otherwise, the sample; ID is taken from the sample identifying block in the first BGEN file if it; exists; else IDs are assigned from `_0`, `_1`, to `_N`. **Row Fields**. Between two and four row fields are created. The `locus` and `alleles` are; always included. `_row_fields` determines if `varid` and `rsid` are also; included. For best performance, only include fields necessary for your; analysis. NOTE: the `_row_fields` parameter is considered an experimental; feature and may be removed without warning. - `locus` (:class:`.tlocus` or :class:`.tstruct`) -- Row key. The chromosome; and position. If `reference_genome` is defined, the type will be; :class:`.tlocus` parameterized by `reference_genome`. Otherwise, the type; will be a :class:`.tstruct` with two fields: `contig` with type; :py:data:`.tstr` and `position` with type :py:data:`.tint32`.; - `alleles` (:class:`.tarray` of :py:data:`.tstr`) -- Row key. An; array containing the alleles of the variant. The reference; allele is the first element in the array.; - `varid` (:py:data:`.tstr`) -- The variant identifier. The third field in; each variant identifying block.; - `rsid` (:py:data:`.tstr`) -- The rsID for the variant. The fifth field in; each variant identifying block. **Entry Fields**. Up to three entry fields are created, as determined by; `entry_fields`. For best performance, include precisely those; fields required for your analysis. It is also possible to pass an; empty tuple or list for `entry_fields`, which can greatly; accelerate processing speed if your workflow does not use the; genotype data. - `GT` (:py:data:`.tcall`) -- The hard call corresponding to the genotype with; the greatest probab",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:48549,Modifiability,parameteriz,parameterized,48549,"port_gen('data/example.gen',; ... sample_file='data/example.sample',; ... reference_genome='GRCh37'). Notes; -----. For more information on the GEN file format, see `here; <http://www.stats.ox.ac.uk/%7Emarchini/software/gwas/file_format.html#mozTocId40300>`__. If the GEN file has only 5 columns before the start of the genotype; probability data (chromosome field is missing), you must specify the; chromosome using the `chromosome` parameter. To load multiple files at the same time, use :ref:`Hadoop Glob Patterns; <sec-hadoop-glob>`. **Column Fields**. - `s` (:py:data:`.tstr`) -- Column key. This is the sample ID imported; from the first column of the sample file. **Row Fields**. - `locus` (:class:`.tlocus` or :class:`.tstruct`) -- Row key. The genomic; location consisting of the chromosome (1st column if present, otherwise; given by `chromosome`) and position (4th column if `chromosome` is not; defined). If `reference_genome` is defined, the type will be; :class:`.tlocus` parameterized by `reference_genome`. Otherwise, the type; will be a :class:`.tstruct` with two fields: `contig` with type; :py:data:`.tstr` and `position` with type :py:data:`.tint32`.; - `alleles` (:class:`.tarray` of :py:data:`.tstr`) -- Row key. An array; containing the alleles of the variant. The reference allele (4th column if; `chromosome` is not defined) is the first element of the array and the; alternate allele (5th column if `chromosome` is not defined) is the second; element.; - `varid` (:py:data:`.tstr`) -- The variant identifier. 2nd column of GEN; file if chromosome present, otherwise 1st column.; - `rsid` (:py:data:`.tstr`) -- The rsID. 3rd column of GEN file if; chromosome present, otherwise 2nd column. **Entry Fields**. - `GT` (:py:data:`.tcall`) -- The hard call corresponding to the genotype with; the highest probability.; - `GP` (:class:`.tarray` of :py:data:`.tfloat64`) -- Genotype probabilities; as defined by the GEN file spec. The array is set to missing if the; sum of the prob",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:86597,Modifiability,parameteriz,parameterized,86597,"miter='\\\\s+',; missing='NA',; quant_pheno=False,; a2_reference=True,; reference_genome='default',; contig_recoding=None,; skip_invalid_loci=False,; n_partitions=None,; block_size=None,; ) -> MatrixTable:; """"""Import a PLINK dataset (BED, BIM, FAM) as a :class:`.MatrixTable`. Examples; --------. >>> ds = hl.import_plink(bed='data/test.bed',; ... bim='data/test.bim',; ... fam='data/test.fam',; ... reference_genome='GRCh37'). Notes; -----. Only binary SNP-major mode files can be read into Hail. To convert your; file from individual-major mode to SNP-major mode, use PLINK to read in; your fileset and use the ``--make-bed`` option. Hail uses the individual ID (column 2 in FAM file) as the sample id (`s`).; The individual IDs must be unique. The resulting :class:`.MatrixTable` has the following fields:. * Row fields:. * `locus` (:class:`.tlocus` or :class:`.tstruct`) -- Row key. The; chromosome and position. If `reference_genome` is defined, the type; will be :class:`.tlocus` parameterized by `reference_genome`.; Otherwise, the type will be a :class:`.tstruct` with two fields:; `contig` with type :py:data:`.tstr` and `position` with type; :py:data:`.tint32`.; * `alleles` (:class:`.tarray` of :py:data:`.tstr`) -- Row key. An; array containing the alleles of the variant. The reference allele (A2; if `a2_reference` is ``True``) is the first element in the array.; * `rsid` (:py:data:`.tstr`) -- Column 2 in the BIM file.; * `cm_position` (:py:data:`.tfloat64`) -- Column 3 in the BIM file,; the position in centimorgans. * Column fields:. * `s` (:py:data:`.tstr`) -- Column 2 in the Fam file (key field).; * `fam_id` (:py:data:`.tstr`) -- Column 1 in the FAM file. Set to; missing if ID equals ""0"".; * `pat_id` (:py:data:`.tstr`) -- Column 3 in the FAM file. Set to; missing if ID equals ""0"".; * `mat_id` (:py:data:`.tstr`) -- Column 4 in the FAM file. Set to; missing if ID equals ""0"".; * `is_female` (:py:data:`.tstr`) -- Column 5 in the FAM file. Set to; missing if value equals ""-9""",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:100358,Modifiability,parameteriz,parameterized,100358," the same chrom, pos, ref, alt, all these; records will be imported as-is (in multiple rows) and will not be collapsed; into a single variant. .. note::. Using the **FILTER** field:. The information in the FILTER field of a VCF is contained in the; ``filters`` row field. This annotation is a ``set<str>`` and can be; queried for filter membership with expressions like; ``ds.filters.contains(""VQSRTranche99.5..."")``. Variants that are flagged; as ""PASS"" will have no filters applied; for these variants,; ``hl.len(ds.filters)`` is ``0``. Thus, filtering to PASS variants; can be done with :meth:`.MatrixTable.filter_rows` as follows:. >>> pass_ds = dataset.filter_rows(hl.len(dataset.filters) == 0). **Column Fields**. - `s` (:py:data:`.tstr`) -- Column key. This is the sample ID. **Row Fields**. - `locus` (:class:`.tlocus` or :class:`.tstruct`) -- Row key. The; chromosome (CHROM field) and position (POS field). If `reference_genome`; is defined, the type will be :class:`.tlocus` parameterized by; `reference_genome`. Otherwise, the type will be a :class:`.tstruct` with; two fields: `contig` with type :py:data:`.tstr` and `position` with type; :py:data:`.tint32`.; - `alleles` (:class:`.tarray` of :py:data:`.tstr`) -- Row key. An array; containing the alleles of the variant. The reference allele (REF field) is; the first element in the array and the alternate alleles (ALT field) are; the subsequent elements.; - `filters` (:class:`.tset` of :py:data:`.tstr`) -- Set containing all filters applied to a; variant.; - `rsid` (:py:data:`.tstr`) -- rsID of the variant.; - `qual` (:py:data:`.tfloat64`) -- Floating-point number in the QUAL field.; - `info` (:class:`.tstruct`) -- All INFO fields defined in the VCF header; can be found in the struct `info`. Data types match the type specified; in the VCF header, and if the declared ``Number`` is not 1, the result; will be stored as an array. **Entry Fields**. :func:`.import_vcf` generates an entry field for each FORMAT field declared; in t",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:111437,Modifiability,config,config,111437,"ue,; _create_row_uids=False,; ) -> Table:; """"""Read in a :class:`.Table` written with :meth:`.Table.write`. Parameters; ----------; path : :class:`str`; File to read. Returns; -------; :class:`.Table`; """"""; if _load_refs:; for rg_config in Env.backend().load_references_from_dataset(path):; hl.ReferenceGenome._from_config(rg_config). if _intervals is not None and _n_partitions is not None:; raise ValueError(""'read_table' does not support both _intervals and _n_partitions""); tr = ir.TableNativeReader(path, _intervals, _filter_intervals); ht = Table(ir.TableRead(tr, False, drop_row_uids=not _create_row_uids, _assert_type=_assert_type)). if _n_partitions:; intervals = ht._calculate_new_partitions(_n_partitions); return read_table(; path,; _intervals=intervals,; _assert_type=ht._type,; _load_refs=_load_refs,; _create_row_uids=_create_row_uids,; ); return ht. [docs]@typecheck(; t=Table,; host=str,; port=int,; index=str,; index_type=str,; block_size=int,; config=nullable(dictof(str, str)),; verbose=bool,; ); def export_elasticsearch(t, host, port, index, index_type, block_size, config=None, verbose=True):; """"""Export a :class:`.Table` to Elasticsearch. By default, this method supports Elasticsearch versions 6.8.x - 7.x.x. Older versions of elasticsearch will require; recompiling hail. .. warning::; :func:`.export_elasticsearch` is EXPERIMENTAL. .. note::; Table rows may be exported more than once. For example, if a task has to be retried after being preempted; midway through processing a partition. To avoid duplicate documents in Elasticsearch, use a `config` with the; `es.mapping.id <https://www.elastic.co/guide/en/elasticsearch/hadoop/current/configuration.html#cfg-mapping>`__; option set to a field that contains a unique value for each row.; """""". jdf = t.expand_types().to_spark(flatten=False)._jdf; Env.hail().io.ElasticsearchConnector.export(jdf, host, port, index, index_type, block_size, config, verbose). @typecheck(paths=sequenceof(str), key=nullable(sequenceof(str)), in",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:111562,Modifiability,config,config,111562,"ue,; _create_row_uids=False,; ) -> Table:; """"""Read in a :class:`.Table` written with :meth:`.Table.write`. Parameters; ----------; path : :class:`str`; File to read. Returns; -------; :class:`.Table`; """"""; if _load_refs:; for rg_config in Env.backend().load_references_from_dataset(path):; hl.ReferenceGenome._from_config(rg_config). if _intervals is not None and _n_partitions is not None:; raise ValueError(""'read_table' does not support both _intervals and _n_partitions""); tr = ir.TableNativeReader(path, _intervals, _filter_intervals); ht = Table(ir.TableRead(tr, False, drop_row_uids=not _create_row_uids, _assert_type=_assert_type)). if _n_partitions:; intervals = ht._calculate_new_partitions(_n_partitions); return read_table(; path,; _intervals=intervals,; _assert_type=ht._type,; _load_refs=_load_refs,; _create_row_uids=_create_row_uids,; ); return ht. [docs]@typecheck(; t=Table,; host=str,; port=int,; index=str,; index_type=str,; block_size=int,; config=nullable(dictof(str, str)),; verbose=bool,; ); def export_elasticsearch(t, host, port, index, index_type, block_size, config=None, verbose=True):; """"""Export a :class:`.Table` to Elasticsearch. By default, this method supports Elasticsearch versions 6.8.x - 7.x.x. Older versions of elasticsearch will require; recompiling hail. .. warning::; :func:`.export_elasticsearch` is EXPERIMENTAL. .. note::; Table rows may be exported more than once. For example, if a task has to be retried after being preempted; midway through processing a partition. To avoid duplicate documents in Elasticsearch, use a `config` with the; `es.mapping.id <https://www.elastic.co/guide/en/elasticsearch/hadoop/current/configuration.html#cfg-mapping>`__; option set to a field that contains a unique value for each row.; """""". jdf = t.expand_types().to_spark(flatten=False)._jdf; Env.hail().io.ElasticsearchConnector.export(jdf, host, port, index, index_type, block_size, config, verbose). @typecheck(paths=sequenceof(str), key=nullable(sequenceof(str)), in",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:112044,Modifiability,config,config,112044,"ir.TableRead(tr, False, drop_row_uids=not _create_row_uids, _assert_type=_assert_type)). if _n_partitions:; intervals = ht._calculate_new_partitions(_n_partitions); return read_table(; path,; _intervals=intervals,; _assert_type=ht._type,; _load_refs=_load_refs,; _create_row_uids=_create_row_uids,; ); return ht. [docs]@typecheck(; t=Table,; host=str,; port=int,; index=str,; index_type=str,; block_size=int,; config=nullable(dictof(str, str)),; verbose=bool,; ); def export_elasticsearch(t, host, port, index, index_type, block_size, config=None, verbose=True):; """"""Export a :class:`.Table` to Elasticsearch. By default, this method supports Elasticsearch versions 6.8.x - 7.x.x. Older versions of elasticsearch will require; recompiling hail. .. warning::; :func:`.export_elasticsearch` is EXPERIMENTAL. .. note::; Table rows may be exported more than once. For example, if a task has to be retried after being preempted; midway through processing a partition. To avoid duplicate documents in Elasticsearch, use a `config` with the; `es.mapping.id <https://www.elastic.co/guide/en/elasticsearch/hadoop/current/configuration.html#cfg-mapping>`__; option set to a field that contains a unique value for each row.; """""". jdf = t.expand_types().to_spark(flatten=False)._jdf; Env.hail().io.ElasticsearchConnector.export(jdf, host, port, index, index_type, block_size, config, verbose). @typecheck(paths=sequenceof(str), key=nullable(sequenceof(str)), intervals=nullable(sequenceof(anytype))); def import_avro(paths, *, key=None, intervals=None):; if not paths:; raise ValueError('import_avro requires at least one path'); if (key is None) != (intervals is None):; raise ValueError('key and intervals must either be both defined or both undefined'). with hl.current_backend().fs.open(paths[0], 'rb') as avro_file:; # monkey patch DataFileReader.determine_file_length to account for bug in Google HadoopFS. def patched_determine_file_length(self) -> int:; remember_pos = self.reader.tell(); self.reader.seek",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:112139,Modifiability,config,configuration,112139,"titions:; intervals = ht._calculate_new_partitions(_n_partitions); return read_table(; path,; _intervals=intervals,; _assert_type=ht._type,; _load_refs=_load_refs,; _create_row_uids=_create_row_uids,; ); return ht. [docs]@typecheck(; t=Table,; host=str,; port=int,; index=str,; index_type=str,; block_size=int,; config=nullable(dictof(str, str)),; verbose=bool,; ); def export_elasticsearch(t, host, port, index, index_type, block_size, config=None, verbose=True):; """"""Export a :class:`.Table` to Elasticsearch. By default, this method supports Elasticsearch versions 6.8.x - 7.x.x. Older versions of elasticsearch will require; recompiling hail. .. warning::; :func:`.export_elasticsearch` is EXPERIMENTAL. .. note::; Table rows may be exported more than once. For example, if a task has to be retried after being preempted; midway through processing a partition. To avoid duplicate documents in Elasticsearch, use a `config` with the; `es.mapping.id <https://www.elastic.co/guide/en/elasticsearch/hadoop/current/configuration.html#cfg-mapping>`__; option set to a field that contains a unique value for each row.; """""". jdf = t.expand_types().to_spark(flatten=False)._jdf; Env.hail().io.ElasticsearchConnector.export(jdf, host, port, index, index_type, block_size, config, verbose). @typecheck(paths=sequenceof(str), key=nullable(sequenceof(str)), intervals=nullable(sequenceof(anytype))); def import_avro(paths, *, key=None, intervals=None):; if not paths:; raise ValueError('import_avro requires at least one path'); if (key is None) != (intervals is None):; raise ValueError('key and intervals must either be both defined or both undefined'). with hl.current_backend().fs.open(paths[0], 'rb') as avro_file:; # monkey patch DataFileReader.determine_file_length to account for bug in Google HadoopFS. def patched_determine_file_length(self) -> int:; remember_pos = self.reader.tell(); self.reader.seek(-1, 2); file_length = self.reader.tell() + 1; self.reader.seek(remember_pos); return file_length.",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:112391,Modifiability,config,config,112391,"t=str,; port=int,; index=str,; index_type=str,; block_size=int,; config=nullable(dictof(str, str)),; verbose=bool,; ); def export_elasticsearch(t, host, port, index, index_type, block_size, config=None, verbose=True):; """"""Export a :class:`.Table` to Elasticsearch. By default, this method supports Elasticsearch versions 6.8.x - 7.x.x. Older versions of elasticsearch will require; recompiling hail. .. warning::; :func:`.export_elasticsearch` is EXPERIMENTAL. .. note::; Table rows may be exported more than once. For example, if a task has to be retried after being preempted; midway through processing a partition. To avoid duplicate documents in Elasticsearch, use a `config` with the; `es.mapping.id <https://www.elastic.co/guide/en/elasticsearch/hadoop/current/configuration.html#cfg-mapping>`__; option set to a field that contains a unique value for each row.; """""". jdf = t.expand_types().to_spark(flatten=False)._jdf; Env.hail().io.ElasticsearchConnector.export(jdf, host, port, index, index_type, block_size, config, verbose). @typecheck(paths=sequenceof(str), key=nullable(sequenceof(str)), intervals=nullable(sequenceof(anytype))); def import_avro(paths, *, key=None, intervals=None):; if not paths:; raise ValueError('import_avro requires at least one path'); if (key is None) != (intervals is None):; raise ValueError('key and intervals must either be both defined or both undefined'). with hl.current_backend().fs.open(paths[0], 'rb') as avro_file:; # monkey patch DataFileReader.determine_file_length to account for bug in Google HadoopFS. def patched_determine_file_length(self) -> int:; remember_pos = self.reader.tell(); self.reader.seek(-1, 2); file_length = self.reader.tell() + 1; self.reader.seek(remember_pos); return file_length. original_determine_file_length = DataFileReader.determine_file_length. try:; DataFileReader.determine_file_length = patched_determine_file_length. with DataFileReader(avro_file, DatumReader()) as data_file_reader:; tr = ir.AvroTableReader(avro.s",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:25602,Performance,load,loaded,25602,"arget** (:py:data:`.tstr`). If `reference_genome` is defined **AND** the file has one field, intervals; are parsed with :func:`.parse_locus_interval`. See the documentation for; valid inputs. If `reference_genome` is **NOT** defined and the file has one field,; intervals are parsed with the regex ```""([^:]*):(\\d+)\\-(\\d+)""``; where contig, start, and end match each of the three capture groups.; ``start`` and ``end`` match positions inclusively, e.g.; ``start <= position <= end``. For files with three or five fields, ``start`` and ``end`` match positions; inclusively, e.g. ``start <= position <= end``. Parameters; ----------; path : :class:`str`; Path to file.; reference_genome : :class:`str` or :class:`.ReferenceGenome`, optional; Reference genome to use.; skip_invalid_intervals : :obj:`bool`; If ``True`` and `reference_genome` is not ``None``, skip lines with; intervals that are not consistent with the reference genome.; contig_recoding: :obj:`dict` of (:class:`str`, :obj:`str`); Mapping from contig name in file to contig name in loaded dataset.; All contigs must be present in the `reference_genome`, so this is; useful for mapping differently-formatted data onto known references.; **kwargs; Additional optional arguments to :func:`import_table` are valid; arguments here except: `no_header`, `comment`, `impute`, and; `types`, as these are used by :func:`import_locus_intervals`. Returns; -------; :class:`.Table`; Interval-keyed table.; """""". if contig_recoding is not None:; contig_recoding = hl.literal(contig_recoding). def recode_contig(x):; if contig_recoding is None:; return x; return contig_recoding.get(x, x). t = import_table(; path,; comment=""@"",; impute=False,; no_header=True,; types={'f0': tstr, 'f1': tint32, 'f2': tint32, 'f3': tstr, 'f4': tstr},; **kwargs,; ). if t.row.dtype == tstruct(f0=tstr):; if reference_genome:; t = t.select(interval=hl.parse_locus_interval(t['f0'], reference_genome)); else:; interval_regex = r""([^:]*):(\d+)\-(\d+)"". def checked_match",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:30662,Performance,load,loaded,30662,"nterval* (:class:`.tinterval`) - Row key. Genomic interval. Same schema as above.; - *target* (:py:data:`.tstr`) - Fourth column of .bed file. `UCSC bed files <https://genome.ucsc.edu/FAQ/FAQformat.html#format1>`__ can; have up to 12 fields, but Hail will only ever look at the first four. Hail; ignores header lines in BED files. Warning; -------; Intervals in UCSC BED files are 0-indexed and half open.; The line ""5 100 105"" correpsonds to the interval ``[5:101-5:106)`` in Hail's; 1-indexed notation. Details; `here <http://genome.ucsc.edu/blog/the-ucsc-genome-browser-coordinate-counting-systems/>`__. Parameters; ----------; path : :class:`str`; Path to .bed file.; reference_genome : :class:`str` or :class:`.ReferenceGenome`, optional; Reference genome to use.; skip_invalid_intervals : :obj:`bool`; If ``True`` and `reference_genome` is not ``None``, skip lines with; intervals that are not consistent with the reference genome.; contig_recoding: :obj:`dict` of (:class:`str`, :obj:`str`); Mapping from contig name in BED to contig name in loaded dataset.; All contigs must be present in the `reference_genome`, so this is; useful for mapping differently-formatted data onto known references.; **kwargs; Additional optional arguments to :func:`import_table` are valid arguments here except:; `no_header`, `delimiter`, `impute`, `skip_blank_lines`, `types`, and `comment` as these; are used by import_bed. Returns; -------; :class:`.Table`; Interval-keyed table.; """""". # UCSC BED spec defined here: https://genome.ucsc.edu/FAQ/FAQformat.html#format1. t = import_table(; path,; no_header=True,; delimiter=r""\s+"",; impute=False,; skip_blank_lines=True,; types={'f0': tstr, 'f1': tint32, 'f2': tint32, 'f3': tstr, 'f4': tstr},; comment=[""""""^browser.*"""""", """"""^track.*"""""", r""""""^\w+=(""[\w\d ]+""|\d+).*""""""],; **kwargs,; ). if contig_recoding is not None:; contig_recoding = hl.literal(contig_recoding). def recode_contig(x):; if contig_recoding is None:; return x; return contig_recoding.get(x, x). i",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:39784,Performance,load,load,39784,"y('v'); >>> ds_result = hl.import_bgen(""data/example.8bits.bgen"",; ... entry_fields=['dosage'],; ... sample_file=""data/example.8bits.sample"",; ... variants=variants.v). Load a set of variants specified by a table keyed by 'locus' and 'alleles' from a BGEN file:. >>> ds_result = hl.import_bgen(""data/example.8bits.bgen"",; ... entry_fields=['dosage'],; ... sample_file=""data/example.8bits.sample"",; ... variants=variants_table). Notes; -----. Hail supports importing data from v1.2 of the `BGEN file format; <http://www.well.ox.ac.uk/~gav/bgen_format/bgen_format.html>`__.; Genotypes must be **unphased** and **diploid**, genotype; probabilities must be stored with 8 bits, and genotype probability; blocks must be compressed with zlib or uncompressed. All variants; must be bi-allelic. Each BGEN file must have a corresponding index file, which can be generated; with :func:`.index_bgen`. All files must have been indexed with the same; reference genome. To load multiple files at the same time,; use :ref:`Hadoop Glob Patterns <sec-hadoop-glob>`. If n_partitions and block_size are both specified, block_size is; used. If neither are specified, the default is a 128MB block; size. **Column Fields**. - `s` (:py:data:`.tstr`) -- Column key. This is the sample ID imported; from the first column of the sample file if given. Otherwise, the sample; ID is taken from the sample identifying block in the first BGEN file if it; exists; else IDs are assigned from `_0`, `_1`, to `_N`. **Row Fields**. Between two and four row fields are created. The `locus` and `alleles` are; always included. `_row_fields` determines if `varid` and `rsid` are also; included. For best performance, only include fields necessary for your; analysis. NOTE: the `_row_fields` parameter is considered an experimental; feature and may be removed without warning. - `locus` (:class:`.tlocus` or :class:`.tstruct`) -- Row key. The chromosome; and position. If `reference_genome` is defined, the type will be; :class:`.tlocus` para",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:40490,Performance,perform,performance,40490,"ability; blocks must be compressed with zlib or uncompressed. All variants; must be bi-allelic. Each BGEN file must have a corresponding index file, which can be generated; with :func:`.index_bgen`. All files must have been indexed with the same; reference genome. To load multiple files at the same time,; use :ref:`Hadoop Glob Patterns <sec-hadoop-glob>`. If n_partitions and block_size are both specified, block_size is; used. If neither are specified, the default is a 128MB block; size. **Column Fields**. - `s` (:py:data:`.tstr`) -- Column key. This is the sample ID imported; from the first column of the sample file if given. Otherwise, the sample; ID is taken from the sample identifying block in the first BGEN file if it; exists; else IDs are assigned from `_0`, `_1`, to `_N`. **Row Fields**. Between two and four row fields are created. The `locus` and `alleles` are; always included. `_row_fields` determines if `varid` and `rsid` are also; included. For best performance, only include fields necessary for your; analysis. NOTE: the `_row_fields` parameter is considered an experimental; feature and may be removed without warning. - `locus` (:class:`.tlocus` or :class:`.tstruct`) -- Row key. The chromosome; and position. If `reference_genome` is defined, the type will be; :class:`.tlocus` parameterized by `reference_genome`. Otherwise, the type; will be a :class:`.tstruct` with two fields: `contig` with type; :py:data:`.tstr` and `position` with type :py:data:`.tint32`.; - `alleles` (:class:`.tarray` of :py:data:`.tstr`) -- Row key. An; array containing the alleles of the variant. The reference; allele is the first element in the array.; - `varid` (:py:data:`.tstr`) -- The variant identifier. The third field in; each variant identifying block.; - `rsid` (:py:data:`.tstr`) -- The rsID for the variant. The fifth field in; each variant identifying block. **Entry Fields**. Up to three entry fields are created, as determined by; `entry_fields`. For best performance, include",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:41496,Performance,perform,performance,41496,"ssary for your; analysis. NOTE: the `_row_fields` parameter is considered an experimental; feature and may be removed without warning. - `locus` (:class:`.tlocus` or :class:`.tstruct`) -- Row key. The chromosome; and position. If `reference_genome` is defined, the type will be; :class:`.tlocus` parameterized by `reference_genome`. Otherwise, the type; will be a :class:`.tstruct` with two fields: `contig` with type; :py:data:`.tstr` and `position` with type :py:data:`.tint32`.; - `alleles` (:class:`.tarray` of :py:data:`.tstr`) -- Row key. An; array containing the alleles of the variant. The reference; allele is the first element in the array.; - `varid` (:py:data:`.tstr`) -- The variant identifier. The third field in; each variant identifying block.; - `rsid` (:py:data:`.tstr`) -- The rsID for the variant. The fifth field in; each variant identifying block. **Entry Fields**. Up to three entry fields are created, as determined by; `entry_fields`. For best performance, include precisely those; fields required for your analysis. It is also possible to pass an; empty tuple or list for `entry_fields`, which can greatly; accelerate processing speed if your workflow does not use the; genotype data. - `GT` (:py:data:`.tcall`) -- The hard call corresponding to the genotype with; the greatest probability. If there is not a unique maximum probability, the; hard call is set to missing.; - `GP` (:class:`.tarray` of :py:data:`.tfloat64`) -- Genotype probabilities; as defined by the BGEN file spec. For bi-allelic variants, the array has; three elements giving the probabilities of homozygous reference,; heterozygous, and homozygous alternate genotype, in that order.; - `dosage` (:py:data:`.tfloat64`) -- The expected value of the number of; alternate alleles, given by the probability of heterozygous genotype plus; twice the probability of homozygous alternate genotype. All variants must; be bi-allelic. See Also; --------; :func:`.index_bgen`. Parameters; ----------; path : :class:`s",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:48011,Performance,load,load,48011,"mple_file=nullable(str),; tolerance=numeric,; min_partitions=nullable(int),; chromosome=nullable(str),; reference_genome=nullable(reference_genome_type),; contig_recoding=nullable(dictof(str, str)),; skip_invalid_loci=bool,; ); def import_gen(; path,; sample_file=None,; tolerance=0.2,; min_partitions=None,; chromosome=None,; reference_genome='default',; contig_recoding=None,; skip_invalid_loci=False,; ) -> MatrixTable:; """"""; Import GEN file(s) as a :class:`.MatrixTable`. Examples; --------. >>> ds = hl.import_gen('data/example.gen',; ... sample_file='data/example.sample',; ... reference_genome='GRCh37'). Notes; -----. For more information on the GEN file format, see `here; <http://www.stats.ox.ac.uk/%7Emarchini/software/gwas/file_format.html#mozTocId40300>`__. If the GEN file has only 5 columns before the start of the genotype; probability data (chromosome field is missing), you must specify the; chromosome using the `chromosome` parameter. To load multiple files at the same time, use :ref:`Hadoop Glob Patterns; <sec-hadoop-glob>`. **Column Fields**. - `s` (:py:data:`.tstr`) -- Column key. This is the sample ID imported; from the first column of the sample file. **Row Fields**. - `locus` (:class:`.tlocus` or :class:`.tstruct`) -- Row key. The genomic; location consisting of the chromosome (1st column if present, otherwise; given by `chromosome`) and position (4th column if `chromosome` is not; defined). If `reference_genome` is defined, the type will be; :class:`.tlocus` parameterized by `reference_genome`. Otherwise, the type; will be a :class:`.tstruct` with two fields: `contig` with type; :py:data:`.tstr` and `position` with type :py:data:`.tint32`.; - `alleles` (:class:`.tarray` of :py:data:`.tstr`) -- Row key. An array; containing the alleles of the variant. The reference allele (4th column if; `chromosome` is not defined) is the first element of the array and the; alternate allele (5th column if `chromosome` is not defined) is the second; element.; - `varid` (:",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:59652,Performance,load,load,59652,"s : :obj:`int` or :obj:`None`; Minimum number of partitions.; no_header : :obj:`bool`; If ``True```, assume the file has no header and name the N fields `f0`,; `f1`, ... `fN` (0-indexed).; impute : :obj:`bool`; If ``True``, Impute field types from the file.; comment : :class:`str` or :obj:`list` of :obj:`str`; Skip lines beginning with the given string if the string is a single; character. Otherwise, skip lines that match the regex specified. Multiple; comment characters or patterns should be passed as a list.; delimiter : :class:`str`; Field delimiter regex.; missing : :class:`str` or :obj:`list` [:obj:`str`]; Identifier(s) to be treated as missing.; types : :obj:`dict` mapping :class:`str` to :class:`.HailType`; Dictionary defining field types.; quote : :class:`str` or :obj:`None`; Quote character.; skip_blank_lines : :obj:`bool`; If ``True``, ignore empty lines. Otherwise, throw an error if an empty; line is found.; force_bgz : :obj:`bool`; If ``True``, load files as blocked gzip files, assuming; that they were actually compressed using the BGZ codec. This option is; useful when the file extension is not ``'.bgz'``, but the file is; blocked gzip, so that the file can be read in parallel and not on a; single node.; filter : :class:`str`, optional; Line filter regex. A partial match results in the line being removed; from the file. Applies before `find_replace`, if both are defined.; find_replace : (:class:`str`, :obj:`str`); Line substitution regex. Functions like ``re.sub``, but obeys the exact; semantics of Java's; `String.replaceAll <https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/lang/String.html#replaceAll(java.lang.String,java.lang.String)>`__.; force : :obj:`bool`; If ``True``, load gzipped files serially on one core. This should; be used only when absolutely necessary, as processing time will be; increased due to lack of parallelism.; source_file_field : :class:`str`, optional; If defined, the source file name for each line will be a field",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:60415,Performance,load,load,60415,"efining field types.; quote : :class:`str` or :obj:`None`; Quote character.; skip_blank_lines : :obj:`bool`; If ``True``, ignore empty lines. Otherwise, throw an error if an empty; line is found.; force_bgz : :obj:`bool`; If ``True``, load files as blocked gzip files, assuming; that they were actually compressed using the BGZ codec. This option is; useful when the file extension is not ``'.bgz'``, but the file is; blocked gzip, so that the file can be read in parallel and not on a; single node.; filter : :class:`str`, optional; Line filter regex. A partial match results in the line being removed; from the file. Applies before `find_replace`, if both are defined.; find_replace : (:class:`str`, :obj:`str`); Line substitution regex. Functions like ``re.sub``, but obeys the exact; semantics of Java's; `String.replaceAll <https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/lang/String.html#replaceAll(java.lang.String,java.lang.String)>`__.; force : :obj:`bool`; If ``True``, load gzipped files serially on one core. This should; be used only when absolutely necessary, as processing time will be; increased due to lack of parallelism.; source_file_field : :class:`str`, optional; If defined, the source file name for each line will be a field of the table; with this name. Can be useful when importing multiple tables using glob patterns.; Returns; -------; :class:`.Table`; """"""; if len(delimiter) < 1:; raise ValueError('import_table: empty delimiter is not supported'). paths = wrap_to_list(paths); comment = wrap_to_list(comment); missing = wrap_to_list(missing). ht = hl.import_lines(paths, min_partitions, force_bgz, force). should_remove_line_expr = should_remove_line(; ht.text, filter=filter, comment=comment, skip_blank_lines=skip_blank_lines; ); if should_remove_line_expr is not None:; ht = ht.filter(should_remove_line_expr, keep=False). try:; if len(paths) <= 1:; # With zero or one files and no filters, the first row, if it exists must be in the first; # partiti",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:65858,Performance,load,load,65858,"info('\n'.join(strs2)). if key:; key = wrap_to_list(key); ht = ht.key_by(*key); return ht. [docs]@typecheck(; paths=oneof(str, sequenceof(str)), min_partitions=nullable(int), force_bgz=bool, force=bool, file_per_partition=bool; ); def import_lines(paths, min_partitions=None, force_bgz=False, force=False, file_per_partition=False) -> Table:; """"""Import lines of file(s) as a :class:`.Table` of strings. Examples; --------. To import a file as a table of strings:. >>> ht = hl.import_lines('data/matrix2.tsv'); >>> ht.describe(); ----------------------------------------; Global fields:; None; ----------------------------------------; Row fields:; 'file': str; 'text': str; ----------------------------------------; Key: []; ----------------------------------------. Parameters; ----------; paths: :class:`str` or :obj:`list` of :obj:`str`; Files to import.; min_partitions: :obj:`int` or :obj:`None`; Minimum number of partitions.; force_bgz : :obj:`bool`; If ``True``, load files as blocked gzip files, assuming; that they were actually compressed using the BGZ codec. This option is; useful when the file extension is not ``'.bgz'``, but the file is; blocked gzip, so that the file can be read in parallel and not on a; single node.; force : :obj:`bool`; If ``True``, load gzipped files serially on one core. This should; be used only when absolutely necessary, as processing time will be; increased due to lack of parallelism.; file_per_partition : :obj:`bool`; If ``True``, each file will be in a seperate partition. Not recommended; for most uses. Error thrown if ``True`` and `min_partitions` is less than; the number of files. Returns; -------; :class:`.Table`; Table constructed from imported data.; """""". paths = wrap_to_list(paths). if file_per_partition and min_partitions is not None:; if min_partitions > len(paths):; raise FatalError(; f'file_per_partition is True while min partitions is {min_partitions} ,which is greater'; f' than the number of files, {len(paths)}'; ). st_reader = ir",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:66158,Performance,load,load,66158,"e, force_bgz=False, force=False, file_per_partition=False) -> Table:; """"""Import lines of file(s) as a :class:`.Table` of strings. Examples; --------. To import a file as a table of strings:. >>> ht = hl.import_lines('data/matrix2.tsv'); >>> ht.describe(); ----------------------------------------; Global fields:; None; ----------------------------------------; Row fields:; 'file': str; 'text': str; ----------------------------------------; Key: []; ----------------------------------------. Parameters; ----------; paths: :class:`str` or :obj:`list` of :obj:`str`; Files to import.; min_partitions: :obj:`int` or :obj:`None`; Minimum number of partitions.; force_bgz : :obj:`bool`; If ``True``, load files as blocked gzip files, assuming; that they were actually compressed using the BGZ codec. This option is; useful when the file extension is not ``'.bgz'``, but the file is; blocked gzip, so that the file can be read in parallel and not on a; single node.; force : :obj:`bool`; If ``True``, load gzipped files serially on one core. This should; be used only when absolutely necessary, as processing time will be; increased due to lack of parallelism.; file_per_partition : :obj:`bool`; If ``True``, each file will be in a seperate partition. Not recommended; for most uses. Error thrown if ``True`` and `min_partitions` is less than; the number of files. Returns; -------; :class:`.Table`; Table constructed from imported data.; """""". paths = wrap_to_list(paths). if file_per_partition and min_partitions is not None:; if min_partitions > len(paths):; raise FatalError(; f'file_per_partition is True while min partitions is {min_partitions} ,which is greater'; f' than the number of files, {len(paths)}'; ). st_reader = ir.StringTableReader(paths, min_partitions, force_bgz, force, file_per_partition); table_type = hl.ttable(global_type=hl.tstruct(), row_type=hl.tstruct(file=hl.tstr, text=hl.tstr), row_key=[]); string_table = Table(ir.TableRead(st_reader, _assert_type=table_type)); return s",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:72287,Performance,load,load,72287," will never be missing, even if the `missing` string appears; in the column IDs. Parameters; ----------; paths: :class:`str` or :obj:`list` of :obj:`str`; Files to import.; row_fields: :obj:`dict` of :class:`str` to :class:`.HailType`; Columns to take as row fields in the MatrixTable. They must be located; before all entry columns.; row_key: :class:`str` or :obj:`list` of :obj:`str`; Key fields(s). If empty, creates an index `row_id` to use as key.; entry_type: :class:`.HailType`; Type of entries in matrix table. Must be one of: :py:data:`.tint32`,; :py:data:`.tint64`, :py:data:`.tfloat32`, :py:data:`.tfloat64`, or; :py:data:`.tstr`. Default: :py:data:`.tint32`.; missing: :class:`str`; Identifier to be treated as missing. Default: NA; min_partitions: :obj:`int` or :obj:`None`; Minimum number of partitions.; no_header: :obj:`bool`; If ``True``, assume the file has no header and name the row fields `f0`,; `f1`, ... `fK` (0-indexed) and the column keys 0, 1, ... N.; force_bgz : :obj:`bool`; If ``True``, load **.gz** files as blocked gzip files, assuming; that they were actually compressed using the BGZ codec.; sep : :class:`str`; This parameter is a deprecated name for `delimiter`, please use that; instead.; delimiter : :class:`str`; A single character string which separates values in the file.; comment : :class:`str` or :obj:`list` of :obj:`str`; Skip lines beginning with the given string if the string is a single; character. Otherwise, skip lines that match the regex specified. Multiple; comment characters or patterns should be passed as a list. Returns; -------; :class:`.MatrixTable`; MatrixTable constructed from imported data.; """"""; row_key = wrap_to_list(row_key); comment = wrap_to_list(comment); paths = [hl.current_backend().fs.canonicalize_path(p) for p in wrap_to_list(paths)]; missing_list = wrap_to_list(missing). def comment_filter(table):; return (; hl.rbind(; hl.array(comment),; lambda hl_comment: hl_comment.any(; lambda com: hl.if_else(hl.len(com) == 1, tab",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:98365,Performance,load,load,98365,"+------------+------+---------+----------+--------------+; <BLANKLINE>; +------------------+----------------+----------------+--------------+; | info.B | info.C | info.D | 'SAMPLE1'.GT |; +------------------+----------------+----------------+--------------+; | array<float64> | array<float64> | array<float64> | call |; +------------------+----------------+----------------+--------------+; | [NA,2.00e+00,NA] | NA | NA | 0/0 |; +------------------+----------------+----------------+--------------+; <BLANKLINE>; +--------------+--------------+--------------+; | 'SAMPLE1'.X | 'SAMPLE1'.Y | 'SAMPLE1'.Z |; +--------------+--------------+--------------+; | array<int32> | array<int32> | array<int32> |; +--------------+--------------+--------------+; | [1,NA,1] | NA | NA |; +--------------+--------------+--------------+. Notes; -----. Hail is designed to be maximally compatible with files in the `VCF v4.2; spec <https://samtools.github.io/hts-specs/VCFv4.2.pdf>`__. :func:`.import_vcf` takes a list of VCF files to load. All files must have; the same header and the same set of samples in the same order (e.g., a; dataset split by chromosome). Files can be specified as :ref:`Hadoop glob; patterns <sec-hadoop-glob>`. Ensure that the VCF file is correctly prepared for import: VCFs should; either be uncompressed (**.vcf**) or block compressed (**.vcf.bgz**). If you; have a large compressed VCF that ends in **.vcf.gz**, it is likely that the; file is actually block-compressed, and you should rename the file to; **.vcf.bgz** accordingly. If you are unable to rename this file, please use; `force_bgz=True` to ignore the extension and treat this file as; block-gzipped. If you have a **non-block** (aka standard) gzipped file, you may use; `force=True`; however, we strongly discourage this because each file will be; processed by a single core. Import will take significantly longer for any; non-trivial dataset. :func:`.import_vcf` does not perform deduplication - if the provided VCF(s); cont",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:99295,Performance,perform,perform,99295,"e same header and the same set of samples in the same order (e.g., a; dataset split by chromosome). Files can be specified as :ref:`Hadoop glob; patterns <sec-hadoop-glob>`. Ensure that the VCF file is correctly prepared for import: VCFs should; either be uncompressed (**.vcf**) or block compressed (**.vcf.bgz**). If you; have a large compressed VCF that ends in **.vcf.gz**, it is likely that the; file is actually block-compressed, and you should rename the file to; **.vcf.bgz** accordingly. If you are unable to rename this file, please use; `force_bgz=True` to ignore the extension and treat this file as; block-gzipped. If you have a **non-block** (aka standard) gzipped file, you may use; `force=True`; however, we strongly discourage this because each file will be; processed by a single core. Import will take significantly longer for any; non-trivial dataset. :func:`.import_vcf` does not perform deduplication - if the provided VCF(s); contain multiple records with the same chrom, pos, ref, alt, all these; records will be imported as-is (in multiple rows) and will not be collapsed; into a single variant. .. note::. Using the **FILTER** field:. The information in the FILTER field of a VCF is contained in the; ``filters`` row field. This annotation is a ``set<str>`` and can be; queried for filter membership with expressions like; ``ds.filters.contains(""VQSRTranche99.5..."")``. Variants that are flagged; as ""PASS"" will have no filters applied; for these variants,; ``hl.len(ds.filters)`` is ``0``. Thus, filtering to PASS variants; can be done with :meth:`.MatrixTable.filter_rows` as follows:. >>> pass_ds = dataset.filter_rows(hl.len(dataset.filters) == 0). **Column Fields**. - `s` (:py:data:`.tstr`) -- Column key. This is the sample ID. **Row Fields**. - `locus` (:class:`.tlocus` or :class:`.tstruct`) -- Row key. The; chromosome (CHROM field) and position (POS field). If `reference_genome`; is defined, the type will be :class:`.tlocus` parameterized by; `reference_genome`",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:101817,Performance,load,load,101817,"s` (:class:`.tset` of :py:data:`.tstr`) -- Set containing all filters applied to a; variant.; - `rsid` (:py:data:`.tstr`) -- rsID of the variant.; - `qual` (:py:data:`.tfloat64`) -- Floating-point number in the QUAL field.; - `info` (:class:`.tstruct`) -- All INFO fields defined in the VCF header; can be found in the struct `info`. Data types match the type specified; in the VCF header, and if the declared ``Number`` is not 1, the result; will be stored as an array. **Entry Fields**. :func:`.import_vcf` generates an entry field for each FORMAT field declared; in the VCF header. The types of these fields are generated according to the; same rules as INFO fields, with one difference -- ""GT"" and other fields; specified in `call_fields` will be read as :py:data:`.tcall`. Parameters; ----------; path : :class:`str` or :obj:`list` of :obj:`str`; One or more paths to VCF files to read. Each path may or may not include glob expressions; like ``*``, ``?``, or ``[abc123]``.; force : :obj:`bool`; If ``True``, load **.vcf.gz** files serially. No downstream operations; can be parallelized, so this mode is strongly discouraged.; force_bgz : :obj:`bool`; If ``True``, load **.vcf.gz** files as blocked gzip files, assuming that they were actually; compressed using the BGZ codec.; header_file : :class:`str`, optional; Optional header override file. If not specified, the first file in; `path` is used. Glob patterns are not allowed in the `header_file`.; min_partitions : :obj:`int`, optional; Minimum partitions to load per file.; drop_samples : :obj:`bool`; If ``True``, create sites-only dataset. Don't load sample IDs or; entries.; call_fields : :obj:`list` of :class:`str`; List of FORMAT fields to load as :py:data:`.tcall`. ""GT"" is; loaded as a call automatically.; reference_genome: :class:`str` or :class:`.ReferenceGenome`, optional; Reference genome to use.; contig_recoding: :obj:`dict` of (:class:`str`, :obj:`str`), optional; Mapping from contig name in VCF to contig name in loaded",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:101974,Performance,load,load,101974," (:py:data:`.tfloat64`) -- Floating-point number in the QUAL field.; - `info` (:class:`.tstruct`) -- All INFO fields defined in the VCF header; can be found in the struct `info`. Data types match the type specified; in the VCF header, and if the declared ``Number`` is not 1, the result; will be stored as an array. **Entry Fields**. :func:`.import_vcf` generates an entry field for each FORMAT field declared; in the VCF header. The types of these fields are generated according to the; same rules as INFO fields, with one difference -- ""GT"" and other fields; specified in `call_fields` will be read as :py:data:`.tcall`. Parameters; ----------; path : :class:`str` or :obj:`list` of :obj:`str`; One or more paths to VCF files to read. Each path may or may not include glob expressions; like ``*``, ``?``, or ``[abc123]``.; force : :obj:`bool`; If ``True``, load **.vcf.gz** files serially. No downstream operations; can be parallelized, so this mode is strongly discouraged.; force_bgz : :obj:`bool`; If ``True``, load **.vcf.gz** files as blocked gzip files, assuming that they were actually; compressed using the BGZ codec.; header_file : :class:`str`, optional; Optional header override file. If not specified, the first file in; `path` is used. Glob patterns are not allowed in the `header_file`.; min_partitions : :obj:`int`, optional; Minimum partitions to load per file.; drop_samples : :obj:`bool`; If ``True``, create sites-only dataset. Don't load sample IDs or; entries.; call_fields : :obj:`list` of :class:`str`; List of FORMAT fields to load as :py:data:`.tcall`. ""GT"" is; loaded as a call automatically.; reference_genome: :class:`str` or :class:`.ReferenceGenome`, optional; Reference genome to use.; contig_recoding: :obj:`dict` of (:class:`str`, :obj:`str`), optional; Mapping from contig name in VCF to contig name in loaded dataset.; All contigs must be present in the `reference_genome`, so this is; useful for mapping differently-formatted data onto known references.; array_e",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:102323,Performance,load,load,102323,"`.import_vcf` generates an entry field for each FORMAT field declared; in the VCF header. The types of these fields are generated according to the; same rules as INFO fields, with one difference -- ""GT"" and other fields; specified in `call_fields` will be read as :py:data:`.tcall`. Parameters; ----------; path : :class:`str` or :obj:`list` of :obj:`str`; One or more paths to VCF files to read. Each path may or may not include glob expressions; like ``*``, ``?``, or ``[abc123]``.; force : :obj:`bool`; If ``True``, load **.vcf.gz** files serially. No downstream operations; can be parallelized, so this mode is strongly discouraged.; force_bgz : :obj:`bool`; If ``True``, load **.vcf.gz** files as blocked gzip files, assuming that they were actually; compressed using the BGZ codec.; header_file : :class:`str`, optional; Optional header override file. If not specified, the first file in; `path` is used. Glob patterns are not allowed in the `header_file`.; min_partitions : :obj:`int`, optional; Minimum partitions to load per file.; drop_samples : :obj:`bool`; If ``True``, create sites-only dataset. Don't load sample IDs or; entries.; call_fields : :obj:`list` of :class:`str`; List of FORMAT fields to load as :py:data:`.tcall`. ""GT"" is; loaded as a call automatically.; reference_genome: :class:`str` or :class:`.ReferenceGenome`, optional; Reference genome to use.; contig_recoding: :obj:`dict` of (:class:`str`, :obj:`str`), optional; Mapping from contig name in VCF to contig name in loaded dataset.; All contigs must be present in the `reference_genome`, so this is; useful for mapping differently-formatted data onto known references.; array_elements_required : :obj:`bool`; If ``True``, all elements in an array field must be present. Set this; parameter to ``False`` for Hail to allow array fields with missing; values such as ``1,.,5``. In this case, the second element will be; missing. However, in the case of a single missing element ``.``, the; entire field will be missing and",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:102413,Performance,load,load,102413,"ated according to the; same rules as INFO fields, with one difference -- ""GT"" and other fields; specified in `call_fields` will be read as :py:data:`.tcall`. Parameters; ----------; path : :class:`str` or :obj:`list` of :obj:`str`; One or more paths to VCF files to read. Each path may or may not include glob expressions; like ``*``, ``?``, or ``[abc123]``.; force : :obj:`bool`; If ``True``, load **.vcf.gz** files serially. No downstream operations; can be parallelized, so this mode is strongly discouraged.; force_bgz : :obj:`bool`; If ``True``, load **.vcf.gz** files as blocked gzip files, assuming that they were actually; compressed using the BGZ codec.; header_file : :class:`str`, optional; Optional header override file. If not specified, the first file in; `path` is used. Glob patterns are not allowed in the `header_file`.; min_partitions : :obj:`int`, optional; Minimum partitions to load per file.; drop_samples : :obj:`bool`; If ``True``, create sites-only dataset. Don't load sample IDs or; entries.; call_fields : :obj:`list` of :class:`str`; List of FORMAT fields to load as :py:data:`.tcall`. ""GT"" is; loaded as a call automatically.; reference_genome: :class:`str` or :class:`.ReferenceGenome`, optional; Reference genome to use.; contig_recoding: :obj:`dict` of (:class:`str`, :obj:`str`), optional; Mapping from contig name in VCF to contig name in loaded dataset.; All contigs must be present in the `reference_genome`, so this is; useful for mapping differently-formatted data onto known references.; array_elements_required : :obj:`bool`; If ``True``, all elements in an array field must be present. Set this; parameter to ``False`` for Hail to allow array fields with missing; values such as ``1,.,5``. In this case, the second element will be; missing. However, in the case of a single missing element ``.``, the; entire field will be missing and **not** an array with one missing; element.; skip_invalid_loci : :obj:`bool`; If ``True``, skip loci that are not consistent",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:102511,Performance,load,load,102511,"ference -- ""GT"" and other fields; specified in `call_fields` will be read as :py:data:`.tcall`. Parameters; ----------; path : :class:`str` or :obj:`list` of :obj:`str`; One or more paths to VCF files to read. Each path may or may not include glob expressions; like ``*``, ``?``, or ``[abc123]``.; force : :obj:`bool`; If ``True``, load **.vcf.gz** files serially. No downstream operations; can be parallelized, so this mode is strongly discouraged.; force_bgz : :obj:`bool`; If ``True``, load **.vcf.gz** files as blocked gzip files, assuming that they were actually; compressed using the BGZ codec.; header_file : :class:`str`, optional; Optional header override file. If not specified, the first file in; `path` is used. Glob patterns are not allowed in the `header_file`.; min_partitions : :obj:`int`, optional; Minimum partitions to load per file.; drop_samples : :obj:`bool`; If ``True``, create sites-only dataset. Don't load sample IDs or; entries.; call_fields : :obj:`list` of :class:`str`; List of FORMAT fields to load as :py:data:`.tcall`. ""GT"" is; loaded as a call automatically.; reference_genome: :class:`str` or :class:`.ReferenceGenome`, optional; Reference genome to use.; contig_recoding: :obj:`dict` of (:class:`str`, :obj:`str`), optional; Mapping from contig name in VCF to contig name in loaded dataset.; All contigs must be present in the `reference_genome`, so this is; useful for mapping differently-formatted data onto known references.; array_elements_required : :obj:`bool`; If ``True``, all elements in an array field must be present. Set this; parameter to ``False`` for Hail to allow array fields with missing; values such as ``1,.,5``. In this case, the second element will be; missing. However, in the case of a single missing element ``.``, the; entire field will be missing and **not** an array with one missing; element.; skip_invalid_loci : :obj:`bool`; If ``True``, skip loci that are not consistent with `reference_genome`.; entry_float_type: :class:`.HailType",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:102547,Performance,load,loaded,102547,"d as :py:data:`.tcall`. Parameters; ----------; path : :class:`str` or :obj:`list` of :obj:`str`; One or more paths to VCF files to read. Each path may or may not include glob expressions; like ``*``, ``?``, or ``[abc123]``.; force : :obj:`bool`; If ``True``, load **.vcf.gz** files serially. No downstream operations; can be parallelized, so this mode is strongly discouraged.; force_bgz : :obj:`bool`; If ``True``, load **.vcf.gz** files as blocked gzip files, assuming that they were actually; compressed using the BGZ codec.; header_file : :class:`str`, optional; Optional header override file. If not specified, the first file in; `path` is used. Glob patterns are not allowed in the `header_file`.; min_partitions : :obj:`int`, optional; Minimum partitions to load per file.; drop_samples : :obj:`bool`; If ``True``, create sites-only dataset. Don't load sample IDs or; entries.; call_fields : :obj:`list` of :class:`str`; List of FORMAT fields to load as :py:data:`.tcall`. ""GT"" is; loaded as a call automatically.; reference_genome: :class:`str` or :class:`.ReferenceGenome`, optional; Reference genome to use.; contig_recoding: :obj:`dict` of (:class:`str`, :obj:`str`), optional; Mapping from contig name in VCF to contig name in loaded dataset.; All contigs must be present in the `reference_genome`, so this is; useful for mapping differently-formatted data onto known references.; array_elements_required : :obj:`bool`; If ``True``, all elements in an array field must be present. Set this; parameter to ``False`` for Hail to allow array fields with missing; values such as ``1,.,5``. In this case, the second element will be; missing. However, in the case of a single missing element ``.``, the; entire field will be missing and **not** an array with one missing; element.; skip_invalid_loci : :obj:`bool`; If ``True``, skip loci that are not consistent with `reference_genome`.; entry_float_type: :class:`.HailType`; Type of floating point entries in matrix table. Must be one of:; :py:",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:102797,Performance,load,loaded,102797,"s; like ``*``, ``?``, or ``[abc123]``.; force : :obj:`bool`; If ``True``, load **.vcf.gz** files serially. No downstream operations; can be parallelized, so this mode is strongly discouraged.; force_bgz : :obj:`bool`; If ``True``, load **.vcf.gz** files as blocked gzip files, assuming that they were actually; compressed using the BGZ codec.; header_file : :class:`str`, optional; Optional header override file. If not specified, the first file in; `path` is used. Glob patterns are not allowed in the `header_file`.; min_partitions : :obj:`int`, optional; Minimum partitions to load per file.; drop_samples : :obj:`bool`; If ``True``, create sites-only dataset. Don't load sample IDs or; entries.; call_fields : :obj:`list` of :class:`str`; List of FORMAT fields to load as :py:data:`.tcall`. ""GT"" is; loaded as a call automatically.; reference_genome: :class:`str` or :class:`.ReferenceGenome`, optional; Reference genome to use.; contig_recoding: :obj:`dict` of (:class:`str`, :obj:`str`), optional; Mapping from contig name in VCF to contig name in loaded dataset.; All contigs must be present in the `reference_genome`, so this is; useful for mapping differently-formatted data onto known references.; array_elements_required : :obj:`bool`; If ``True``, all elements in an array field must be present. Set this; parameter to ``False`` for Hail to allow array fields with missing; values such as ``1,.,5``. In this case, the second element will be; missing. However, in the case of a single missing element ``.``, the; entire field will be missing and **not** an array with one missing; element.; skip_invalid_loci : :obj:`bool`; If ``True``, skip loci that are not consistent with `reference_genome`.; entry_float_type: :class:`.HailType`; Type of floating point entries in matrix table. Must be one of:; :py:data:`.tfloat32` or :py:data:`.tfloat64`. Default:; :py:data:`.tfloat64`.; filter : :class:`str`, optional; Line filter regex. A partial match results in the line being removed; from the",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:117955,Performance,load,load,117955,"list` of :obj:`str`; Key fields(s).; min_partitions : :obj:`int` or :obj:`None`; Minimum number of partitions.; no_header : :obj:`bool`; If ``True```, assume the file has no header and name the N fields `f0`,; `f1`, ... `fN` (0-indexed).; impute : :obj:`bool`; If ``True``, Impute field types from the file.; comment : :class:`str` or :obj:`list` of :obj:`str`; Skip lines beginning with the given string if the string is a single; character. Otherwise, skip lines that match the regex specified. Multiple; comment characters or patterns should be passed as a list.; missing : :class:`str` or :obj:`list` [:obj:`str`]; Identifier(s) to be treated as missing.; types : :obj:`dict` mapping :class:`str` to :class:`.HailType`; Dictionary defining field types.; quote : :class:`str` or :obj:`None`; Quote character.; skip_blank_lines : :obj:`bool`; If ``True``, ignore empty lines. Otherwise, throw an error if an empty; line is found.; force_bgz : :obj:`bool`; If ``True``, load files as blocked gzip files, assuming; that they were actually compressed using the BGZ codec. This option is; useful when the file extension is not ``'.bgz'``, but the file is; blocked gzip, so that the file can be read in parallel and not on a; single node.; filter : :class:`str`, optional; Line filter regex. A partial match results in the line being removed; from the file. Applies before `find_replace`, if both are defined.; find_replace : (:class:`str`, :obj:`str`); Line substitution regex. Functions like ``re.sub``, but obeys the exact; semantics of Java's; `String.replaceAll <https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/lang/String.html#replaceAll(java.lang.String,java.lang.String)>`__.; force : :obj:`bool`; If ``True``, load gzipped files serially on one core. This should; be used only when absolutely necessary, as processing time will be; increased due to lack of parallelism.; source_file_field : :class:`str`, optional; If defined, the source file name for each line will be a field",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:118718,Performance,load,load,118718," missing : :class:`str` or :obj:`list` [:obj:`str`]; Identifier(s) to be treated as missing.; types : :obj:`dict` mapping :class:`str` to :class:`.HailType`; Dictionary defining field types.; quote : :class:`str` or :obj:`None`; Quote character.; skip_blank_lines : :obj:`bool`; If ``True``, ignore empty lines. Otherwise, throw an error if an empty; line is found.; force_bgz : :obj:`bool`; If ``True``, load files as blocked gzip files, assuming; that they were actually compressed using the BGZ codec. This option is; useful when the file extension is not ``'.bgz'``, but the file is; blocked gzip, so that the file can be read in parallel and not on a; single node.; filter : :class:`str`, optional; Line filter regex. A partial match results in the line being removed; from the file. Applies before `find_replace`, if both are defined.; find_replace : (:class:`str`, :obj:`str`); Line substitution regex. Functions like ``re.sub``, but obeys the exact; semantics of Java's; `String.replaceAll <https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/lang/String.html#replaceAll(java.lang.String,java.lang.String)>`__.; force : :obj:`bool`; If ``True``, load gzipped files serially on one core. This should; be used only when absolutely necessary, as processing time will be; increased due to lack of parallelism.; source_file_field : :class:`str`, optional; If defined, the source file name for each line will be a field of the table; with this name. Can be useful when importing multiple tables using glob patterns.; Returns; -------; :class:`.Table`; """""". ht = hl.import_table(; paths,; key=key,; min_partitions=min_partitions,; impute=impute,; no_header=no_header,; comment=comment,; missing=missing,; types=types,; skip_blank_lines=skip_blank_lines,; force_bgz=force_bgz,; filter=filter,; find_replace=find_replace,; force=force,; source_file_field=source_file_field,; delimiter="","",; quote=quote,; ); return ht. © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:62544,Safety,avoid,avoid,62544,"first_row_ht = ht.head(1). if find_replace is not None:; ht = ht.annotate(text=ht['text'].replace(*find_replace)). first_rows = first_row_ht.annotate(; header=first_row_ht.text._split_line(; delimiter, missing=hl.empty_array(hl.tstr), quote=quote, regex=len(delimiter) > 1; ); ).collect(); except FatalError as err:; if '_filter_partitions: no partition with index 0' in err.args[0]:; first_rows = []; else:; raise. if len(first_rows) == 0:; raise ValueError(f""Invalid file: no lines remaining after filters\n Files provided: {', '.join(paths)}""); first_row = first_rows[0]. if no_header:; fields = [f'f{index}' for index in range(0, len(first_row.header))]; else:; maybe_duplicated_fields = first_row.header; renamings, fields = deduplicate(maybe_duplicated_fields); ht = ht.filter(; ht.text == first_row.text, keep=False; ) # FIXME: seems wrong. Could easily fix with partition index and row_within_partition_index.; if renamings:; hl.utils.warning(; f'import_table: renamed the following {plural(""field"", len(renamings))} to avoid name conflicts:'; + ''.join(f'\n {k!r} -> {v!r}' for k, v in renamings); ). ht = ht.annotate(; split_text=(; hl.case(); .when(hl.len(ht.text) > 0, split_lines(ht, fields, delimiter=delimiter, missing=missing, quote=quote)); .or_error(hl.str(""Blank line found in file "") + ht.file); ); ); ht = ht.drop('text'). fields_to_value = {}; strs = []; if impute:; fields_to_impute_idx = []; fields_to_guess = []; for idx, field in enumerate(fields):; if types.get(field) is None:; fields_to_impute_idx.append(idx); fields_to_guess.append(field). hl.utils.info('Reading table to impute column types'); guessed = ht.aggregate(; hl.agg.array_agg(lambda x: hl.agg._impute_type(x), [ht.split_text[i] for i in fields_to_impute_idx]); ). reasons = {f: 'user-supplied type' for f in types}; imputed_types = dict(); for field, s in zip(fields_to_guess, guessed):; if not s['anyNonMissing']:; imputed_types[field] = hl.tstr; reasons[field] = 'no non-missing observations'; else:; if s[",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:111993,Safety,avoid,avoid,111993,"ir.TableRead(tr, False, drop_row_uids=not _create_row_uids, _assert_type=_assert_type)). if _n_partitions:; intervals = ht._calculate_new_partitions(_n_partitions); return read_table(; path,; _intervals=intervals,; _assert_type=ht._type,; _load_refs=_load_refs,; _create_row_uids=_create_row_uids,; ); return ht. [docs]@typecheck(; t=Table,; host=str,; port=int,; index=str,; index_type=str,; block_size=int,; config=nullable(dictof(str, str)),; verbose=bool,; ); def export_elasticsearch(t, host, port, index, index_type, block_size, config=None, verbose=True):; """"""Export a :class:`.Table` to Elasticsearch. By default, this method supports Elasticsearch versions 6.8.x - 7.x.x. Older versions of elasticsearch will require; recompiling hail. .. warning::; :func:`.export_elasticsearch` is EXPERIMENTAL. .. note::; Table rows may be exported more than once. For example, if a task has to be retried after being preempted; midway through processing a partition. To avoid duplicate documents in Elasticsearch, use a `config` with the; `es.mapping.id <https://www.elastic.co/guide/en/elasticsearch/hadoop/current/configuration.html#cfg-mapping>`__; option set to a field that contains a unique value for each row.; """""". jdf = t.expand_types().to_spark(flatten=False)._jdf; Env.hail().io.ElasticsearchConnector.export(jdf, host, port, index, index_type, block_size, config, verbose). @typecheck(paths=sequenceof(str), key=nullable(sequenceof(str)), intervals=nullable(sequenceof(anytype))); def import_avro(paths, *, key=None, intervals=None):; if not paths:; raise ValueError('import_avro requires at least one path'); if (key is None) != (intervals is None):; raise ValueError('key and intervals must either be both defined or both undefined'). with hl.current_backend().fs.open(paths[0], 'rb') as avro_file:; # monkey patch DataFileReader.determine_file_length to account for bug in Google HadoopFS. def patched_determine_file_length(self) -> int:; remember_pos = self.reader.tell(); self.reader.seek",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:35608,Testability,sandbox,sandbox,35608,"na(type_and_data['data']), typ, key=['id']). [docs]@typecheck(regex=str, path=oneof(str, sequenceof(str)), max_count=int, show=bool, force=bool, force_bgz=bool); def grep(regex, path, max_count=100, *, show: bool = True, force: bool = False, force_bgz: bool = False):; r""""""Searches given paths for all lines containing regex matches. Examples; --------. Print all lines containing the string ``hello`` in *file.txt*:. >>> hl.grep('hello','data/file.txt'). Print all lines containing digits in *file1.txt* and *file2.txt*:. >>> hl.grep('\\d', ['data/file1.txt','data/file2.txt']). Notes; -----; :func:`.grep` mimics the basic functionality of Unix ``grep`` in; parallel, printing results to the screen. This command is provided as a; convenience to those in the statistical genetics community who often; search enormous text files like VCFs. Hail uses `Java regular expression; patterns; <https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/util/regex/Pattern.html>`__.; The `RegExr sandbox <http://regexr.com/>`__ may be helpful. Parameters; ----------; regex : :class:`str`; The regular expression to match.; path : :class:`str` or :obj:`list` of :obj:`str`; The files to search.; max_count : :obj:`int`; The maximum number of matches to return; show : :obj:`bool`; When `True`, show the values on stdout. When `False`, return a; dictionary mapping file names to lines.; force_bgz : :obj:`bool`; If ``True``, read files as blocked gzip files, assuming; that they were actually compressed using the BGZ codec. This option is; useful when the file extension is not ``'.bgz'``, but the file is; blocked gzip, so that the file can be read in parallel and not on a; single node.; force : :obj:`bool`; If ``True``, read gzipped files serially on one core. This should; be used only when absolutely necessary, as processing time will be; increased due to lack of parallelism. Returns; ---; :obj:`dict` of :class:`str` to :obj:`list` of :obj:`str`; """"""; from hail.backend.spark_backend import S",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:45543,Testability,assert,assert,45543,"iants = hl.struct(locus=variants). if len(variants.dtype) == 0 or not variants.dtype._is_prefix_of(expected_vtype):; raise TypeError(; ""'import_bgen' requires the expression type for 'variants' is a non-empty prefix of the BGEN key type: \n""; + f""\tFound: {variants.dtype!r}\n""; + f""\tExpected: {expected_vtype!r}\n""; ). uid = Env.get_uid(); fnames = list(variants.dtype); name, variants = variants._to_table(; uid; ) # This will add back the other key fields of the source, which we don't want; variants = variants.key_by(**{fname: variants[name][fname] for fname in fnames}); variants = variants.select(); elif isinstance(variants, Table):; if len(variants.key) == 0 or not variants.key.dtype._is_prefix_of(expected_vtype):; raise TypeError(; ""'import_bgen' requires the row key type for 'variants' is a non-empty prefix of the BGEN key type: \n""; + f""\tFound: {variants.key.dtype!r}\n""; + f""\tExpected: {expected_vtype!r}\n""; ); variants = variants.select(); else:; assert isinstance(variants, list); try:; if len(variants) == 0:; variants = hl.Table.parallelize(variants, schema=expected_vtype, key=['locus', 'alleles']); else:; first_v = variants[0]; if isinstance(first_v, hl.Locus):; variants = hl.Table.parallelize(; [hl.Struct(locus=v) for v in variants], schema=hl.tstruct(locus=lt), key='locus'; ); else:; assert isinstance(first_v, hl.utils.Struct); if len(first_v) == 1:; variants = hl.Table.parallelize(variants, schema=hl.tstruct(locus=lt), key='locus'); else:; variants = hl.Table.parallelize(variants, schema=expected_vtype, key=['locus', 'alleles']); except Exception:; raise TypeError(; f""'import_bgen' requires all elements in 'variants' are a non-empty prefix of the BGEN key type: {expected_vtype!r}""; ). vir = variants._tir; if (; isinstance(vir, ir.TableRead); and isinstance(vir.reader, ir.TableNativeReader); and vir.reader.intervals is None; and variants.count() == variants.distinct().count(); ):; variants_path = vir.reader.path; else:; variants_path = new_temp_file(pref",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:45891,Testability,assert,assert,45891,"r}\n""; ). uid = Env.get_uid(); fnames = list(variants.dtype); name, variants = variants._to_table(; uid; ) # This will add back the other key fields of the source, which we don't want; variants = variants.key_by(**{fname: variants[name][fname] for fname in fnames}); variants = variants.select(); elif isinstance(variants, Table):; if len(variants.key) == 0 or not variants.key.dtype._is_prefix_of(expected_vtype):; raise TypeError(; ""'import_bgen' requires the row key type for 'variants' is a non-empty prefix of the BGEN key type: \n""; + f""\tFound: {variants.key.dtype!r}\n""; + f""\tExpected: {expected_vtype!r}\n""; ); variants = variants.select(); else:; assert isinstance(variants, list); try:; if len(variants) == 0:; variants = hl.Table.parallelize(variants, schema=expected_vtype, key=['locus', 'alleles']); else:; first_v = variants[0]; if isinstance(first_v, hl.Locus):; variants = hl.Table.parallelize(; [hl.Struct(locus=v) for v in variants], schema=hl.tstruct(locus=lt), key='locus'; ); else:; assert isinstance(first_v, hl.utils.Struct); if len(first_v) == 1:; variants = hl.Table.parallelize(variants, schema=hl.tstruct(locus=lt), key='locus'); else:; variants = hl.Table.parallelize(variants, schema=expected_vtype, key=['locus', 'alleles']); except Exception:; raise TypeError(; f""'import_bgen' requires all elements in 'variants' are a non-empty prefix of the BGEN key type: {expected_vtype!r}""; ). vir = variants._tir; if (; isinstance(vir, ir.TableRead); and isinstance(vir.reader, ir.TableNativeReader); and vir.reader.intervals is None; and variants.count() == variants.distinct().count(); ):; variants_path = vir.reader.path; else:; variants_path = new_temp_file(prefix='bgen_included_vars', extension='ht'); variants.distinct().write(variants_path); else:; variants_path = None. reader = ir.MatrixBGENReader(path, sample_file, index_file_map, n_partitions, block_size, variants_path). mt = MatrixTable(ir.MatrixRead(reader)).drop(; *[fd for fd in ['GT', 'GP', 'dosage'] if fd n",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:85943,Testability,test,test,85943,"ht = ht.annotate_globals(; cols=hl.range(0, len(header_dict['column_ids'])).map(lambda col_idx: hl.struct(col_id=hl_columns[col_idx])); ). if not add_row_id:; ht = ht.drop('row_id'). mt = ht._unlocalize_entries('entries', 'cols', ['col_id']); mt = mt.key_rows_by(*row_key); return mt. [docs]@typecheck(; bed=str,; bim=str,; fam=str,; min_partitions=nullable(int),; delimiter=str,; missing=str,; quant_pheno=bool,; a2_reference=bool,; reference_genome=nullable(reference_genome_type),; contig_recoding=nullable(dictof(str, str)),; skip_invalid_loci=bool,; n_partitions=nullable(int),; block_size=nullable(int),; ); def import_plink(; bed,; bim,; fam,; min_partitions=None,; delimiter='\\\\s+',; missing='NA',; quant_pheno=False,; a2_reference=True,; reference_genome='default',; contig_recoding=None,; skip_invalid_loci=False,; n_partitions=None,; block_size=None,; ) -> MatrixTable:; """"""Import a PLINK dataset (BED, BIM, FAM) as a :class:`.MatrixTable`. Examples; --------. >>> ds = hl.import_plink(bed='data/test.bed',; ... bim='data/test.bim',; ... fam='data/test.fam',; ... reference_genome='GRCh37'). Notes; -----. Only binary SNP-major mode files can be read into Hail. To convert your; file from individual-major mode to SNP-major mode, use PLINK to read in; your fileset and use the ``--make-bed`` option. Hail uses the individual ID (column 2 in FAM file) as the sample id (`s`).; The individual IDs must be unique. The resulting :class:`.MatrixTable` has the following fields:. * Row fields:. * `locus` (:class:`.tlocus` or :class:`.tstruct`) -- Row key. The; chromosome and position. If `reference_genome` is defined, the type; will be :class:`.tlocus` parameterized by `reference_genome`.; Otherwise, the type will be a :class:`.tstruct` with two fields:; `contig` with type :py:data:`.tstr` and `position` with type; :py:data:`.tint32`.; * `alleles` (:class:`.tarray` of :py:data:`.tstr`) -- Row key. An; array containing the alleles of the variant. The reference allele (A2; if `a2_refer",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:85969,Testability,test,test,85969,"hl.range(0, len(header_dict['column_ids'])).map(lambda col_idx: hl.struct(col_id=hl_columns[col_idx])); ). if not add_row_id:; ht = ht.drop('row_id'). mt = ht._unlocalize_entries('entries', 'cols', ['col_id']); mt = mt.key_rows_by(*row_key); return mt. [docs]@typecheck(; bed=str,; bim=str,; fam=str,; min_partitions=nullable(int),; delimiter=str,; missing=str,; quant_pheno=bool,; a2_reference=bool,; reference_genome=nullable(reference_genome_type),; contig_recoding=nullable(dictof(str, str)),; skip_invalid_loci=bool,; n_partitions=nullable(int),; block_size=nullable(int),; ); def import_plink(; bed,; bim,; fam,; min_partitions=None,; delimiter='\\\\s+',; missing='NA',; quant_pheno=False,; a2_reference=True,; reference_genome='default',; contig_recoding=None,; skip_invalid_loci=False,; n_partitions=None,; block_size=None,; ) -> MatrixTable:; """"""Import a PLINK dataset (BED, BIM, FAM) as a :class:`.MatrixTable`. Examples; --------. >>> ds = hl.import_plink(bed='data/test.bed',; ... bim='data/test.bim',; ... fam='data/test.fam',; ... reference_genome='GRCh37'). Notes; -----. Only binary SNP-major mode files can be read into Hail. To convert your; file from individual-major mode to SNP-major mode, use PLINK to read in; your fileset and use the ``--make-bed`` option. Hail uses the individual ID (column 2 in FAM file) as the sample id (`s`).; The individual IDs must be unique. The resulting :class:`.MatrixTable` has the following fields:. * Row fields:. * `locus` (:class:`.tlocus` or :class:`.tstruct`) -- Row key. The; chromosome and position. If `reference_genome` is defined, the type; will be :class:`.tlocus` parameterized by `reference_genome`.; Otherwise, the type will be a :class:`.tstruct` with two fields:; `contig` with type :py:data:`.tstr` and `position` with type; :py:data:`.tint32`.; * `alleles` (:class:`.tarray` of :py:data:`.tstr`) -- Row key. An; array containing the alleles of the variant. The reference allele (A2; if `a2_reference` is ``True``) is the first ",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:85995,Testability,test,test,85995,"t['column_ids'])).map(lambda col_idx: hl.struct(col_id=hl_columns[col_idx])); ). if not add_row_id:; ht = ht.drop('row_id'). mt = ht._unlocalize_entries('entries', 'cols', ['col_id']); mt = mt.key_rows_by(*row_key); return mt. [docs]@typecheck(; bed=str,; bim=str,; fam=str,; min_partitions=nullable(int),; delimiter=str,; missing=str,; quant_pheno=bool,; a2_reference=bool,; reference_genome=nullable(reference_genome_type),; contig_recoding=nullable(dictof(str, str)),; skip_invalid_loci=bool,; n_partitions=nullable(int),; block_size=nullable(int),; ); def import_plink(; bed,; bim,; fam,; min_partitions=None,; delimiter='\\\\s+',; missing='NA',; quant_pheno=False,; a2_reference=True,; reference_genome='default',; contig_recoding=None,; skip_invalid_loci=False,; n_partitions=None,; block_size=None,; ) -> MatrixTable:; """"""Import a PLINK dataset (BED, BIM, FAM) as a :class:`.MatrixTable`. Examples; --------. >>> ds = hl.import_plink(bed='data/test.bed',; ... bim='data/test.bim',; ... fam='data/test.fam',; ... reference_genome='GRCh37'). Notes; -----. Only binary SNP-major mode files can be read into Hail. To convert your; file from individual-major mode to SNP-major mode, use PLINK to read in; your fileset and use the ``--make-bed`` option. Hail uses the individual ID (column 2 in FAM file) as the sample id (`s`).; The individual IDs must be unique. The resulting :class:`.MatrixTable` has the following fields:. * Row fields:. * `locus` (:class:`.tlocus` or :class:`.tstruct`) -- Row key. The; chromosome and position. If `reference_genome` is defined, the type; will be :class:`.tlocus` parameterized by `reference_genome`.; Otherwise, the type will be a :class:`.tstruct` with two fields:; `contig` with type :py:data:`.tstr` and `position` with type; :py:data:`.tint32`.; * `alleles` (:class:`.tarray` of :py:data:`.tstr`) -- Row key. An; array containing the alleles of the variant. The reference allele (A2; if `a2_reference` is ``True``) is the first element in the array.; * `",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/impex.html:112101,Usability,guid,guide,112101,"titions:; intervals = ht._calculate_new_partitions(_n_partitions); return read_table(; path,; _intervals=intervals,; _assert_type=ht._type,; _load_refs=_load_refs,; _create_row_uids=_create_row_uids,; ); return ht. [docs]@typecheck(; t=Table,; host=str,; port=int,; index=str,; index_type=str,; block_size=int,; config=nullable(dictof(str, str)),; verbose=bool,; ); def export_elasticsearch(t, host, port, index, index_type, block_size, config=None, verbose=True):; """"""Export a :class:`.Table` to Elasticsearch. By default, this method supports Elasticsearch versions 6.8.x - 7.x.x. Older versions of elasticsearch will require; recompiling hail. .. warning::; :func:`.export_elasticsearch` is EXPERIMENTAL. .. note::; Table rows may be exported more than once. For example, if a task has to be retried after being preempted; midway through processing a partition. To avoid duplicate documents in Elasticsearch, use a `config` with the; `es.mapping.id <https://www.elastic.co/guide/en/elasticsearch/hadoop/current/configuration.html#cfg-mapping>`__; option set to a field that contains a unique value for each row.; """""". jdf = t.expand_types().to_spark(flatten=False)._jdf; Env.hail().io.ElasticsearchConnector.export(jdf, host, port, index, index_type, block_size, config, verbose). @typecheck(paths=sequenceof(str), key=nullable(sequenceof(str)), intervals=nullable(sequenceof(anytype))); def import_avro(paths, *, key=None, intervals=None):; if not paths:; raise ValueError('import_avro requires at least one path'); if (key is None) != (intervals is None):; raise ValueError('key and intervals must either be both defined or both undefined'). with hl.current_backend().fs.open(paths[0], 'rb') as avro_file:; # monkey patch DataFileReader.determine_file_length to account for bug in Google HadoopFS. def patched_determine_file_length(self) -> int:; remember_pos = self.reader.tell(); self.reader.seek(-1, 2); file_length = self.reader.tell() + 1; self.reader.seek(remember_pos); return file_length.",MatchSource.WIKI,docs/0.2/_modules/hail/methods/impex.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/impex.html
https://hail.is/docs/0.2/_modules/hail/methods/misc.html:6424,Availability,checkpoint,checkpoint,6424,"rce; if not isinstance(source, Table):; raise ValueError(; ""'maximal_independent_set' expects an expression of 'Table'. Found {}"".format(; ""expression of '{}'"".format(source.__class__) if source is not None else 'scalar expression'; ); ). if i._indices.source != j._indices.source:; raise ValueError(; ""'maximal_independent_set' expects arguments `i` and `j` to be expressions of the same Table. ""; ""Found\n{}\n{}"".format(i, j); ). node_t = i.dtype. if tie_breaker:; wrapped_node_t = ttuple(node_t); left_id = Env.get_uid(); right_id = Env.get_uid(); left = construct_variable(left_id, wrapped_node_t); right = construct_variable(right_id, wrapped_node_t); tie_breaker_expr = hl.float64(tie_breaker(left[0], right[0])); tie_breaker_ir = tie_breaker_expr._ir; t, _ = source._process_joins(i, j, tie_breaker_expr); else:; left_id, right_id, tie_breaker_ir = None, None, None; t, _ = source._process_joins(i, j). edges = t.select(__i=i, __j=j).key_by().select('__i', '__j'); edges = edges.checkpoint(new_temp_file()). mis_nodes = hl.set(; construct_expr(; ir.ArrayMaximalIndependentSet(edges.collect(_localize=False)._ir, left_id, right_id, tie_breaker_ir),; hl.tarray(node_t),; ); ). nodes = edges.select(node=[edges.__i, edges.__j]); nodes = nodes.explode(nodes.node); nodes = nodes.annotate_globals(mis_nodes=mis_nodes); nodes = nodes.filter(nodes.mis_nodes.contains(nodes.node), keep); nodes = nodes.select_globals(); if keyed:; return nodes.key_by('node').distinct(); return nodes. def require_col_key_str(dataset: MatrixTable, method: str):; if not len(dataset.col_key) == 1 or dataset[next(iter(dataset.col_key))].dtype != hl.tstr:; raise ValueError(; f""Method '{method}' requires column key to be one field of type 'str', found ""; f""{list(str(x.dtype) for x in dataset.col_key.values())}""; ). def require_table_key_variant(ht, method):; if (; list(ht.key) != ['locus', 'alleles']; or not isinstance(ht['locus'].dtype, tlocus); or not ht['alleles'].dtype == tarray(tstr); ):; raise ValueError(; """,MatchSource.WIKI,docs/0.2/_modules/hail/methods/misc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/misc.html
https://hail.is/docs/0.2/_modules/hail/methods/misc.html:16992,Deployability,update,updated,16992,"pects a table with interval keys""); point_type = ht.key[0].dtype.point_type; if isinstance(points, Table):; if len(points.key) != 1 or points.key[0].dtype != point_type:; raise ValueError(; ""'segment_intervals' expects points to be a table with a single""; "" key of the same type as the intervals in 'ht', or an array of those points:""; f""\n expect {point_type}, found {list(points.key.dtype.values())}""; ); points = hl.array(hl.set(points.collect(_localize=False))); if points.dtype.element_type != point_type:; raise ValueError(; f""'segment_intervals' expects points to be a table with a single""; f"" key of the same type as the intervals in 'ht', or an array of those points:""; f""\n expect {point_type}, found {points.dtype.element_type}""; ). points = hl._sort_by(points, lambda l, r: hl._compare(l, r) < 0). ht = ht.annotate_globals(__points=points). interval = ht.key[0]; points = ht.__points; lower = hl.expr.functions._lower_bound(points, interval.start); higher = hl.expr.functions._lower_bound(points, interval.end); n_points = hl.len(points); lower = hl.if_else((lower < n_points) & (points[lower] == interval.start), lower + 1, lower); higher = hl.if_else((higher < n_points) & (points[higher] == interval.end), higher - 1, higher); interval_results = hl.rbind(; lower,; higher,; lambda lower, higher: hl.if_else(; lower >= higher,; [interval],; hl.flatten([; [; hl.interval(; interval.start, points[lower], includes_start=interval.includes_start, includes_end=False; ); ],; hl.range(lower, higher - 1).map(; lambda x: hl.interval(points[x], points[x + 1], includes_start=True, includes_end=False); ),; [; hl.interval(; points[higher - 1], interval.end, includes_start=True, includes_end=interval.includes_end; ); ],; ]),; ),; ); ht = ht.annotate(__new_intervals=interval_results, lower=lower, higher=higher).explode('__new_intervals'); return ht.key_by(**{next(iter(ht.key)): ht.__new_intervals}).drop('__new_intervals'). © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,docs/0.2/_modules/hail/methods/misc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/misc.html
https://hail.is/docs/0.2/_modules/hail/methods/misc.html:11040,Modifiability,parameteriz,parameterized,11040,"(dataset, method); return dataset._select_rows(; method,; hl.case(); .when(dataset.alleles.length() == 2, dataset._rvrow); .or_error(; f""'{method}' expects biallelic variants ('alleles' field of length 2), found ""; + hl.str(dataset.locus); + "", ""; + hl.str(dataset.alleles); ),; ). [docs]@typecheck(dataset=MatrixTable, name=str); def rename_duplicates(dataset, name='unique_id') -> MatrixTable:; """"""Rename duplicate column keys. .. include:: ../_templates/req_tstring.rst. Examples; --------. >>> renamed = hl.rename_duplicates(dataset).cols(); >>> duplicate_samples = (renamed.filter(renamed.s != renamed.unique_id); ... .select(); ... .collect()). Notes; -----. This method produces a new column field from the string column key by; appending a unique suffix ``_N`` as necessary. For example, if the column; key ""NA12878"" appears three times in the dataset, the first will produce; ""NA12878"", the second will produce ""NA12878_1"", and the third will produce; ""NA12878_2"". The name of this new field is parameterized by `name`. Parameters; ----------; dataset : :class:`.MatrixTable`; Dataset.; name : :class:`str`; Name of new field. Returns; -------; :class:`.MatrixTable`; """""". require_col_key_str(dataset, 'rename_duplicates'); ids = dataset.col_key[0].collect(). mapping, new_ids = deduplicate(ids). if mapping:; info(; f'Renamed {len(mapping)} duplicate {plural(""sample ID"", len(mapping))}. Mangled IDs as follows:'; + ''.join(f'\n ""{pre}"" => ""{post}""' for pre, post in mapping); ); else:; info('No duplicate sample IDs found.'); return dataset.annotate_cols(**{name: hl.literal(new_ids)[hl.int(hl.scan.count())]}). [docs]@typecheck(ds=oneof(Table, MatrixTable), intervals=expr_array(expr_interval(expr_any)), keep=bool); def filter_intervals(ds, intervals, keep=True) -> Union[Table, MatrixTable]:; """"""Filter rows with a list of intervals. Examples; --------. Filter to loci falling within one interval:. >>> ds_result = hl.filter_intervals(dataset, [hl.parse_locus_interval('17:38449840-38530",MatchSource.WIKI,docs/0.2/_modules/hail/methods/misc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/misc.html
https://hail.is/docs/0.2/_modules/hail/methods/misc.html:12495,Performance,load,loaded,12495," + ''.join(f'\n ""{pre}"" => ""{post}""' for pre, post in mapping); ); else:; info('No duplicate sample IDs found.'); return dataset.annotate_cols(**{name: hl.literal(new_ids)[hl.int(hl.scan.count())]}). [docs]@typecheck(ds=oneof(Table, MatrixTable), intervals=expr_array(expr_interval(expr_any)), keep=bool); def filter_intervals(ds, intervals, keep=True) -> Union[Table, MatrixTable]:; """"""Filter rows with a list of intervals. Examples; --------. Filter to loci falling within one interval:. >>> ds_result = hl.filter_intervals(dataset, [hl.parse_locus_interval('17:38449840-38530994')]). Remove all loci within list of intervals:. >>> intervals = [hl.parse_locus_interval(x) for x in ['1:50M-75M', '2:START-400000', '3-22']]; >>> ds_result = hl.filter_intervals(dataset, intervals, keep=False). Notes; -----; Based on the `keep` argument, this method will either restrict to points; in the supplied interval ranges, or remove all rows in those ranges. When ``keep=True``, partitions that don't overlap any supplied interval; will not be loaded at all. This enables :func:`.filter_intervals` to be; used for reasonably low-latency queries of small ranges of the dataset, even; on large datasets. Parameters; ----------; ds : :class:`.MatrixTable` or :class:`.Table`; Dataset to filter.; intervals : :class:`.ArrayExpression` of type :class:`.tinterval`; Intervals to filter on. The point type of the interval must; be a prefix of the key or equal to the first field of the key.; keep : :obj:`bool`; If ``True``, keep only rows that fall within any interval in `intervals`.; If ``False``, keep only rows that fall outside all intervals in; `intervals`. Returns; -------; :class:`.MatrixTable` or :class:`.Table`. """""". if isinstance(ds, MatrixTable):; k_type = ds.row_key.dtype; else:; assert isinstance(ds, Table); k_type = ds.key.dtype. point_type = intervals.dtype.element_type.point_type. def is_struct_prefix(partial, full):; if list(partial) != list(full)[: len(partial)]:; return False; for k, v i",MatchSource.WIKI,docs/0.2/_modules/hail/methods/misc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/misc.html
https://hail.is/docs/0.2/_modules/hail/methods/misc.html:12580,Performance,latency,latency,12580,"otate_cols(**{name: hl.literal(new_ids)[hl.int(hl.scan.count())]}). [docs]@typecheck(ds=oneof(Table, MatrixTable), intervals=expr_array(expr_interval(expr_any)), keep=bool); def filter_intervals(ds, intervals, keep=True) -> Union[Table, MatrixTable]:; """"""Filter rows with a list of intervals. Examples; --------. Filter to loci falling within one interval:. >>> ds_result = hl.filter_intervals(dataset, [hl.parse_locus_interval('17:38449840-38530994')]). Remove all loci within list of intervals:. >>> intervals = [hl.parse_locus_interval(x) for x in ['1:50M-75M', '2:START-400000', '3-22']]; >>> ds_result = hl.filter_intervals(dataset, intervals, keep=False). Notes; -----; Based on the `keep` argument, this method will either restrict to points; in the supplied interval ranges, or remove all rows in those ranges. When ``keep=True``, partitions that don't overlap any supplied interval; will not be loaded at all. This enables :func:`.filter_intervals` to be; used for reasonably low-latency queries of small ranges of the dataset, even; on large datasets. Parameters; ----------; ds : :class:`.MatrixTable` or :class:`.Table`; Dataset to filter.; intervals : :class:`.ArrayExpression` of type :class:`.tinterval`; Intervals to filter on. The point type of the interval must; be a prefix of the key or equal to the first field of the key.; keep : :obj:`bool`; If ``True``, keep only rows that fall within any interval in `intervals`.; If ``False``, keep only rows that fall outside all intervals in; `intervals`. Returns; -------; :class:`.MatrixTable` or :class:`.Table`. """""". if isinstance(ds, MatrixTable):; k_type = ds.row_key.dtype; else:; assert isinstance(ds, Table); k_type = ds.key.dtype. point_type = intervals.dtype.element_type.point_type. def is_struct_prefix(partial, full):; if list(partial) != list(full)[: len(partial)]:; return False; for k, v in partial.items():; if full[k] != v:; return False; return True. if point_type == k_type[0]:; needs_wrapper = True; k_name = k_type.f",MatchSource.WIKI,docs/0.2/_modules/hail/methods/misc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/misc.html
https://hail.is/docs/0.2/_modules/hail/methods/misc.html:7754,Testability,assert,assert,7754,"lter(nodes.mis_nodes.contains(nodes.node), keep); nodes = nodes.select_globals(); if keyed:; return nodes.key_by('node').distinct(); return nodes. def require_col_key_str(dataset: MatrixTable, method: str):; if not len(dataset.col_key) == 1 or dataset[next(iter(dataset.col_key))].dtype != hl.tstr:; raise ValueError(; f""Method '{method}' requires column key to be one field of type 'str', found ""; f""{list(str(x.dtype) for x in dataset.col_key.values())}""; ). def require_table_key_variant(ht, method):; if (; list(ht.key) != ['locus', 'alleles']; or not isinstance(ht['locus'].dtype, tlocus); or not ht['alleles'].dtype == tarray(tstr); ):; raise ValueError(; ""Method '{}' requires key to be two fields 'locus' (type 'locus<any>') and ""; ""'alleles' (type 'array<str>')\n""; "" Found:{}"".format(method, ''.join(""\n '{}': {}"".format(k, str(ht[k].dtype)) for k in ht.key)); ). def require_row_key_variant(dataset, method):; if isinstance(dataset, Table):; key = dataset.key; else:; assert isinstance(dataset, MatrixTable); key = dataset.row_key; if (; list(key) != ['locus', 'alleles']; or not isinstance(dataset['locus'].dtype, tlocus); or not dataset['alleles'].dtype == tarray(tstr); ):; raise ValueError(; ""Method '{}' requires row key to be two fields 'locus' (type 'locus<any>') and ""; ""'alleles' (type 'array<str>')\n""; "" Found:{}"".format(method, ''.join(""\n '{}': {}"".format(k, str(dataset[k].dtype)) for k in key)); ). def require_alleles_field(dataset, method):; if 'alleles' not in dataset.row:; raise ValueError(f""Method '{method}' requires a field 'alleles' (type 'array<str>')\n""); if dataset.alleles.dtype != tarray(tstr):; raise ValueError(; f""Method '{method}' requires a field 'alleles' (type 'array<str>')\n""; f"" Found:\n""; f"" 'alleles': {dataset.alleles.dtype}""; ). def require_row_key_variant_w_struct_locus(dataset, method):; if (; list(dataset.row_key) != ['locus', 'alleles']; or not dataset['alleles'].dtype == tarray(tstr); or (; not isinstance(dataset['locus'].dtype, tlocus); ",MatchSource.WIKI,docs/0.2/_modules/hail/methods/misc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/misc.html
https://hail.is/docs/0.2/_modules/hail/methods/misc.html:9275,Testability,assert,assert,9275,"f""Method '{method}' requires a field 'alleles' (type 'array<str>')\n""); if dataset.alleles.dtype != tarray(tstr):; raise ValueError(; f""Method '{method}' requires a field 'alleles' (type 'array<str>')\n""; f"" Found:\n""; f"" 'alleles': {dataset.alleles.dtype}""; ). def require_row_key_variant_w_struct_locus(dataset, method):; if (; list(dataset.row_key) != ['locus', 'alleles']; or not dataset['alleles'].dtype == tarray(tstr); or (; not isinstance(dataset['locus'].dtype, tlocus); and dataset['locus'].dtype != hl.dtype('struct{contig: str, position: int32}'); ); ):; raise ValueError(; ""Method '{}' requires row key to be two fields 'locus'""; "" (type 'locus<any>' or 'struct{{contig: str, position: int32}}') and ""; ""'alleles' (type 'array<str>')\n""; "" Found:{}"".format(; method, ''.join(""\n '{}': {}"".format(k, str(dataset[k].dtype)) for k in dataset.row_key); ); ). def require_first_key_field_locus(dataset, method):; if isinstance(dataset, Table):; key = dataset.key; else:; assert isinstance(dataset, MatrixTable); key = dataset.row_key; if len(key) == 0 or not isinstance(key[0].dtype, tlocus):; raise ValueError(; ""Method '{}' requires first key field of type 'locus<any>'.\n"" "" Found:{}"".format(; method, ''.join(""\n '{}': {}"".format(k, str(dataset[k].dtype)) for k in key); ); ). @typecheck(table=Table, method=str); def require_key(table, method):; if len(table.key) == 0:; raise ValueError(""Method '{}' requires a non-empty key"".format(method)). @typecheck(dataset=MatrixTable, method=str, tolerate_generic_locus=bool); def require_biallelic(dataset, method, tolerate_generic_locus: bool = False) -> MatrixTable:; if tolerate_generic_locus:; require_row_key_variant_w_struct_locus(dataset, method); else:; require_row_key_variant(dataset, method); return dataset._select_rows(; method,; hl.case(); .when(dataset.alleles.length() == 2, dataset._rvrow); .or_error(; f""'{method}' expects biallelic variants ('alleles' field of length 2), found ""; + hl.str(dataset.locus); + "", ""; + hl.str(data",MatchSource.WIKI,docs/0.2/_modules/hail/methods/misc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/misc.html
https://hail.is/docs/0.2/_modules/hail/methods/misc.html:13241,Testability,assert,assert,13241,"tes; -----; Based on the `keep` argument, this method will either restrict to points; in the supplied interval ranges, or remove all rows in those ranges. When ``keep=True``, partitions that don't overlap any supplied interval; will not be loaded at all. This enables :func:`.filter_intervals` to be; used for reasonably low-latency queries of small ranges of the dataset, even; on large datasets. Parameters; ----------; ds : :class:`.MatrixTable` or :class:`.Table`; Dataset to filter.; intervals : :class:`.ArrayExpression` of type :class:`.tinterval`; Intervals to filter on. The point type of the interval must; be a prefix of the key or equal to the first field of the key.; keep : :obj:`bool`; If ``True``, keep only rows that fall within any interval in `intervals`.; If ``False``, keep only rows that fall outside all intervals in; `intervals`. Returns; -------; :class:`.MatrixTable` or :class:`.Table`. """""". if isinstance(ds, MatrixTable):; k_type = ds.row_key.dtype; else:; assert isinstance(ds, Table); k_type = ds.key.dtype. point_type = intervals.dtype.element_type.point_type. def is_struct_prefix(partial, full):; if list(partial) != list(full)[: len(partial)]:; return False; for k, v in partial.items():; if full[k] != v:; return False; return True. if point_type == k_type[0]:; needs_wrapper = True; k_name = k_type.fields[0]; point_type = hl.tstruct(**{k_name: k_type[k_name]}); elif isinstance(point_type, tstruct) and is_struct_prefix(point_type, k_type):; needs_wrapper = False; else:; raise TypeError(; ""The point type is incompatible with key type of the dataset ('{}', '{}')"".format(; repr(point_type), repr(k_type); ); ). def wrap_input(interval):; if interval is None:; raise TypeError(""'filter_intervals' does not allow missing values in 'intervals'.""); elif needs_wrapper:; return Interval(; Struct(**{k_name: interval.start}),; Struct(**{k_name: interval.end}),; interval.includes_start,; interval.includes_end,; ); else:; return interval. intervals = hl.eval(interval",MatchSource.WIKI,docs/0.2/_modules/hail/methods/misc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/misc.html
https://hail.is/docs/0.2/_modules/hail/methods/pca.html:5195,Availability,error,error,5195,"om hail.backend.service_backend import ServiceBackend. if isinstance(hl.current_backend(), ServiceBackend):; return _hwe_normalized_blanczos(call_expr, k, compute_loadings). return pca(hwe_normalize(call_expr), k, compute_loadings). [docs]@typecheck(entry_expr=expr_float64, k=int, compute_loadings=bool); def pca(entry_expr, k=10, compute_loadings=False) -> Tuple[List[float], Table, Table]:; r""""""Run principal component analysis (PCA) on numeric columns derived from a; matrix table. Examples; --------. For a matrix table with variant rows, sample columns, and genotype entries,; compute the top 2 PC sample scores and eigenvalues of the matrix of 0s and; 1s encoding missingness of genotype calls. >>> eigenvalues, scores, _ = hl.pca(hl.int(hl.is_defined(dataset.GT)),; ... k=2). Warning; -------; This method does **not** automatically mean-center or normalize each column.; If desired, such transformations should be incorporated in `entry_expr`. Hail will return an error if `entry_expr` evaluates to missing, nan, or; infinity on any entry. Notes; -----. PCA is run on the columns of the numeric matrix obtained by evaluating; `entry_expr` on each entry of the matrix table, or equivalently on the rows; of the **transposed** numeric matrix :math:`M` referenced below. PCA computes the SVD. .. math::. M = USV^T. where columns of :math:`U` are left singular vectors (orthonormal in; :math:`\mathbb{R}^n`), columns of :math:`V` are right singular vectors; (orthonormal in :math:`\mathbb{R}^m`), and :math:`S=\mathrm{diag}(s_1, s_2,; \ldots)` with ordered singular values :math:`s_1 \ge s_2 \ge \cdots \ge 0`.; Typically one computes only the first :math:`k` singular vectors and values,; yielding the best rank :math:`k` approximation :math:`U_k S_k V_k^T` of; :math:`M`; the truncations :math:`U_k`, :math:`S_k` and :math:`V_k` are; :math:`n \times k`, :math:`k \times k` and :math:`m \times k`; respectively. From the perspective of the rows of :math:`M` as samples (data points),; :math:`V_",MatchSource.WIKI,docs/0.2/_modules/hail/methods/pca.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/pca.html
https://hail.is/docs/0.2/_modules/hail/methods/pca.html:13881,Availability,checkpoint,checkpoint,13881,":`\mathrm{span}(U) = \mathcal{K}_p(AA^T, AV_0)`; * :math:`V[:, :b] = V_0`; * :math:`R\in\mathbb{R}^{b\times b}` is upper triangular; where :math:`\mathcal{K}_p(X, Y)` is the block Krylov subspace; :math:`\mathrm{span}(Y, XY, \dots, X^pY)`. Parameters; ----------; A_expr; V0; p; compute_U. Returns; -------. """"""; t = A.block_table; A_expr = A.block_expr. g_list = [V0]; G_i = V0; k = hl.eval(V0.shape[1]). for j in range(0, p):; info(f""krylov_factorization: Beginning iteration {j+1}/{p}""); G_i = t.aggregate(hl.agg.ndarray_sum(A_expr.T @ (A_expr @ G_i)), _localize=False); G_i = hl.nd.qr(G_i)[0]._persist(); g_list.append(G_i). info(""krylov_factorization: Iterations complete. Computing local QR""); V0 = hl.nd.hstack(g_list). if compute_V:; V = hl.nd.qr(V0)[0]._persist(); t = t.annotate(AV=A_expr @ V); else:; V = hl.nd.qr(V0)[0]; t = t.annotate(AV=A_expr @ V); V = None. if compute_U:; temp_file_name = hl.utils.new_temp_file(""_krylov_factorization_intermediate"", ""ht""); t = t.checkpoint(temp_file_name); AV_local = t.aggregate(hl.nd.vstack(hl.agg.collect(t.AV)), _localize=False); U, R = hl.nd.qr(AV_local)._persist(); else:; Rs = t.aggregate(hl.nd.vstack(hl.agg.collect(hl.nd.qr(t.AV)[1])), _localize=False); R = hl.nd.qr(Rs)[1]._persist(); U = None. return KrylovFactorization(U, R, V, k). def _reduced_svd(A: TallSkinnyMatrix, k=10, compute_U=False, iterations=2, iteration_size=None):; # Set Parameters; q = iterations; if iteration_size is None:; L = k + 2; else:; L = iteration_size; assert (q + 1) * L >= k; n = A.ncols. # Generate random matrix G; G = hl.rand_norm(0, 1, size=(n, L)); G = hl.nd.qr(G)[0]._persist(). fact = _krylov_factorization(A, G, q, compute_U); info(""_reduced_svd: Computing local SVD""); return fact.reduced_svd(k). @typecheck(; A=oneof(expr_float64, TallSkinnyMatrix), num_moments=int, p=nullable(int), moment_samples=int, block_size=int; ); def _spectral_moments(A, num_moments, p=None, moment_samples=500, block_size=128):; if not isinstance(A, TallSkinnyMatrix):; ",MatchSource.WIKI,docs/0.2/_modules/hail/methods/pca.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/pca.html
https://hail.is/docs/0.2/_modules/hail/methods/pca.html:18894,Availability,error,error,18894,"adings=bool,; q_iterations=int,; oversampling_param=nullable(int),; block_size=int,; compute_scores=bool,; transpose=bool,; ); def _blanczos_pca(; A,; k=10,; compute_loadings=False,; q_iterations=10,; oversampling_param=None,; block_size=128,; compute_scores=True,; transpose=False,; ):; r""""""Run randomized principal component analysis approximation (PCA); on numeric columns derived from a matrix table. Implements the Blanczos algorithm found by Rokhlin, Szlam, and Tygert. Examples; --------. For a matrix table with variant rows, sample columns, and genotype entries,; compute the top 2 PC sample scores and eigenvalues of the matrix of 0s and; 1s encoding missingness of genotype calls. >>> eigenvalues, scores, _ = hl._blanczos_pca(hl.int(hl.is_defined(dataset.GT)),; ... k=2). Warning; -------; This method does **not** automatically mean-center or normalize each column.; If desired, such transformations should be incorporated in `entry_expr`. Hail will return an error if `entry_expr` evaluates to missing, nan, or; infinity on any entry. Notes; -----. PCA is run on the columns of the numeric matrix obtained by evaluating; `entry_expr` on each entry of the matrix table, or equivalently on the rows; of the **transposed** numeric matrix :math:`M` referenced below. PCA computes the SVD. .. math::. M = USV^T. where columns of :math:`U` are left singular vectors (orthonormal in; :math:`\mathbb{R}^n`), columns of :math:`V` are right singular vectors; (orthonormal in :math:`\mathbb{R}^m`), and :math:`S=\mathrm{diag}(s_1, s_2,; \ldots)` with ordered singular values :math:`s_1 \ge s_2 \ge \cdots \ge 0`.; Typically one computes only the first :math:`k` singular vectors and values,; yielding the best rank :math:`k` approximation :math:`U_k S_k V_k^T` of; :math:`M`; the truncations :math:`U_k`, :math:`S_k` and :math:`V_k` are; :math:`n \times k`, :math:`k \times k` and :math:`m \times k`; respectively. From the perspective of the rows of :math:`M` as samples (data points),; :math:`V_",MatchSource.WIKI,docs/0.2/_modules/hail/methods/pca.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/pca.html
https://hail.is/docs/0.2/_modules/hail/methods/pca.html:24481,Deployability,update,updated,24481,"; lt = None; eigens = hl.eval(S * S); if transpose:; if compute_loadings:; lt = numpy_to_cols_table(V, 'loadings'); if compute_scores:; st = numpy_to_rows_table(U * S, 'scores'); else:; if compute_scores:; st = numpy_to_cols_table(V * S, 'scores'); if compute_loadings:; lt = numpy_to_rows_table(U, 'loadings'). return eigens, st, lt. @typecheck(; call_expr=expr_call,; k=int,; compute_loadings=bool,; q_iterations=int,; oversampling_param=nullable(int),; block_size=int,; ); def _hwe_normalized_blanczos(; call_expr, k=10, compute_loadings=False, q_iterations=10, oversampling_param=None, block_size=128; ):; r""""""Run randomized principal component analysis approximation (PCA) on the; Hardy-Weinberg-normalized genotype call matrix. Implements the Blanczos algorithm found by Rokhlin, Szlam, and Tygert. Examples; --------. >>> eigenvalues, scores, loadings = hl._hwe_normalized_blanczos(dataset.GT, k=5). Notes; -----; This method specializes :func:`._blanczos_pca` for the common use case; of PCA in statistical genetics, that of projecting samples to a small; number of ancestry coordinates. Variants that are all homozygous reference; or all homozygous alternate are unnormalizable and removed before; evaluation. See :func:`._blanczos_pca` for more details. Parameters; ----------; call_expr : :class:`.CallExpression`; Entry-indexed call expression.; k : :obj:`int`; Number of principal components.; compute_loadings : :obj:`bool`; If ``True``, compute row loadings. Returns; -------; (:obj:`list` of :obj:`float`, :class:`.Table`, :class:`.Table`); List of eigenvalues, table with column scores, table with row loadings.; """"""; raise_unless_entry_indexed('_blanczos_pca/entry_expr', call_expr); A = _make_tsm_from_call(call_expr, block_size, hwe_normalize=True). return _blanczos_pca(; A,; k,; compute_loadings=compute_loadings,; q_iterations=q_iterations,; oversampling_param=oversampling_param,; block_size=block_size,; ). © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,docs/0.2/_modules/hail/methods/pca.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/pca.html
https://hail.is/docs/0.2/_modules/hail/methods/pca.html:21176,Energy Efficiency,power,power,21176,"The eigenvalues of the Gramian; :math:`MM^T` are the squares of the singular values :math:`s_1^2, s_2^2,; \ldots`, which represent the variances carried by the respective PCs. By; default, Hail only computes the loadings if the ``loadings`` parameter is; specified. Scores are stored in a :class:`.Table` with the column key of the matrix; table as key and a field `scores` of type ``array<float64>`` containing; the principal component scores. Loadings are stored in a :class:`.Table` with the row key of the matrix; table as key and a field `loadings` of type ``array<float64>`` containing; the principal component loadings. The eigenvalues are returned in descending order, with scores and loadings; given the corresponding array order. Parameters; ----------; entry_expr : :class:`.Expression`; Numeric expression for matrix entries.; k : :obj:`int`; Number of principal components.; compute_loadings : :obj:`bool`; If ``True``, compute row loadings.; q_iterations : :obj:`int`; Number of rounds of power iteration to amplify singular values.; oversampling_param : :obj:`int`; Amount of oversampling to use when approximating the singular values.; Usually a value between `0 <= oversampling_param <= k`. Returns; -------; (:obj:`list` of :obj:`float`, :class:`.Table`, :class:`.Table`); List of eigenvalues, table with column scores, table with row loadings.; """"""; if not isinstance(A, TallSkinnyMatrix):; raise_unless_entry_indexed('_blanczos_pca/entry_expr', A); A = _make_tsm(A, block_size). if oversampling_param is None:; oversampling_param = k. compute_U = (not transpose and compute_loadings) or (transpose and compute_scores); U, S, V = _reduced_svd(A, k, compute_U, q_iterations, k + oversampling_param); info(""blanczos_pca: SVD Complete. Computing conversion to PCs.""). def numpy_to_rows_table(X, field_name):; t = A.source_table.select(); t = t.annotate_globals(X=X); idx_name = '_tmp_pca_loading_index'; t = t.add_index(idx_name); t = t.annotate(**{field_name: hl.array(t.X[t[idx_name",MatchSource.WIKI,docs/0.2/_modules/hail/methods/pca.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/pca.html
https://hail.is/docs/0.2/_modules/hail/methods/pca.html:2110,Performance,load,loadings,2110,"annotate_rows(__AC=agg.sum(mt.__gt), __n_called=agg.count_where(hl.is_defined(mt.__gt))); mt = mt.filter_rows((mt.__AC > 0) & (mt.__AC < 2 * mt.__n_called)). n_variants = mt.count_rows(); if n_variants == 0:; raise FatalError(""hwe_normalize: found 0 variants after filtering out monomorphic sites.""); info(f""hwe_normalize: found {n_variants} variants after filtering out monomorphic sites.""). mt = mt.annotate_rows(__mean_gt=mt.__AC / mt.__n_called); mt = mt.annotate_rows(__hwe_scaled_std_dev=hl.sqrt(mt.__mean_gt * (2 - mt.__mean_gt) * n_variants / 2)); mt = mt.unfilter_entries(). normalized_gt = hl.or_else((mt.__gt - mt.__mean_gt) / mt.__hwe_scaled_std_dev, 0.0); return normalized_gt. [docs]@typecheck(call_expr=expr_call, k=int, compute_loadings=bool); def hwe_normalized_pca(call_expr, k=10, compute_loadings=False) -> Tuple[List[float], Table, Table]:; r""""""Run principal component analysis (PCA) on the Hardy-Weinberg-normalized; genotype call matrix. Examples; --------. >>> eigenvalues, scores, loadings = hl.hwe_normalized_pca(dataset.GT, k=5). Notes; -----; This method specializes :func:`.pca` for the common use case; of PCA in statistical genetics, that of projecting samples to a small; number of ancestry coordinates. Variants that are all homozygous reference; or all homozygous alternate are unnormalizable and removed before; evaluation. See :func:`.pca` for more details. Users of PLINK/GCTA should be aware that Hail computes the GRM slightly; differently with regard to missing data. In Hail, the; :math:`ij` entry of the GRM :math:`MM^T` is simply the dot product of rows; :math:`i` and :math:`j` of :math:`M`; in terms of :math:`C` it is. .. math::. \frac{1}{m}\sum_{l\in\mathcal{C}_i\cap\mathcal{C}_j}\frac{(C_{il}-2p_l)(C_{jl} - 2p_l)}{2p_l(1-p_l)}. where :math:`\mathcal{C}_i = \{l \mid C_{il} \text{ is non-missing}\}`. In; PLINK/GCTA the denominator :math:`m` is replaced with the number of terms in; the sum :math:`\lvert\mathcal{C}_i\cap\mathcal{C}_j\rvert`, i.e. the",MatchSource.WIKI,docs/0.2/_modules/hail/methods/pca.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/pca.html
https://hail.is/docs/0.2/_modules/hail/methods/pca.html:3331,Performance,load,loadings,3331,"f projecting samples to a small; number of ancestry coordinates. Variants that are all homozygous reference; or all homozygous alternate are unnormalizable and removed before; evaluation. See :func:`.pca` for more details. Users of PLINK/GCTA should be aware that Hail computes the GRM slightly; differently with regard to missing data. In Hail, the; :math:`ij` entry of the GRM :math:`MM^T` is simply the dot product of rows; :math:`i` and :math:`j` of :math:`M`; in terms of :math:`C` it is. .. math::. \frac{1}{m}\sum_{l\in\mathcal{C}_i\cap\mathcal{C}_j}\frac{(C_{il}-2p_l)(C_{jl} - 2p_l)}{2p_l(1-p_l)}. where :math:`\mathcal{C}_i = \{l \mid C_{il} \text{ is non-missing}\}`. In; PLINK/GCTA the denominator :math:`m` is replaced with the number of terms in; the sum :math:`\lvert\mathcal{C}_i\cap\mathcal{C}_j\rvert`, i.e. the; number of variants where both samples have non-missing genotypes. While this; is arguably a better estimator of the true GRM (trading shrinkage for; noise), it has the drawback that one loses the clean interpretation of the; loadings and scores as features and projections. Separately, for the PCs PLINK/GCTA output the eigenvectors of the GRM, i.e.; the left singular vectors :math:`U_k` instead of the component scores; :math:`U_k S_k`. The scores have the advantage of representing true; projections of the data onto features with the variance of a score; reflecting the variance explained by the corresponding feature. In PC; bi-plots this amounts to a change in aspect ratio; for use of PCs as; covariates in regression it is immaterial. Parameters; ----------; call_expr : :class:`.CallExpression`; Entry-indexed call expression.; k : :obj:`int`; Number of principal components.; compute_loadings : :obj:`bool`; If ``True``, compute row loadings. Returns; -------; (:obj:`list` of :obj:`float`, :class:`.Table`, :class:`.Table`); List of eigenvalues, table with column scores, table with row loadings.; """"""; from hail.backend.service_backend import ServiceBackend",MatchSource.WIKI,docs/0.2/_modules/hail/methods/pca.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/pca.html
https://hail.is/docs/0.2/_modules/hail/methods/pca.html:4049,Performance,load,loadings,4049,"f terms in; the sum :math:`\lvert\mathcal{C}_i\cap\mathcal{C}_j\rvert`, i.e. the; number of variants where both samples have non-missing genotypes. While this; is arguably a better estimator of the true GRM (trading shrinkage for; noise), it has the drawback that one loses the clean interpretation of the; loadings and scores as features and projections. Separately, for the PCs PLINK/GCTA output the eigenvectors of the GRM, i.e.; the left singular vectors :math:`U_k` instead of the component scores; :math:`U_k S_k`. The scores have the advantage of representing true; projections of the data onto features with the variance of a score; reflecting the variance explained by the corresponding feature. In PC; bi-plots this amounts to a change in aspect ratio; for use of PCs as; covariates in regression it is immaterial. Parameters; ----------; call_expr : :class:`.CallExpression`; Entry-indexed call expression.; k : :obj:`int`; Number of principal components.; compute_loadings : :obj:`bool`; If ``True``, compute row loadings. Returns; -------; (:obj:`list` of :obj:`float`, :class:`.Table`, :class:`.Table`); List of eigenvalues, table with column scores, table with row loadings.; """"""; from hail.backend.service_backend import ServiceBackend. if isinstance(hl.current_backend(), ServiceBackend):; return _hwe_normalized_blanczos(call_expr, k, compute_loadings). return pca(hwe_normalize(call_expr), k, compute_loadings). [docs]@typecheck(entry_expr=expr_float64, k=int, compute_loadings=bool); def pca(entry_expr, k=10, compute_loadings=False) -> Tuple[List[float], Table, Table]:; r""""""Run principal component analysis (PCA) on numeric columns derived from a; matrix table. Examples; --------. For a matrix table with variant rows, sample columns, and genotype entries,; compute the top 2 PC sample scores and eigenvalues of the matrix of 0s and; 1s encoding missingness of genotype calls. >>> eigenvalues, scores, _ = hl.pca(hl.int(hl.is_defined(dataset.GT)),; ... k=2). Warning; -------; ",MatchSource.WIKI,docs/0.2/_modules/hail/methods/pca.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/pca.html
https://hail.is/docs/0.2/_modules/hail/methods/pca.html:4204,Performance,load,loadings,4204,"hile this; is arguably a better estimator of the true GRM (trading shrinkage for; noise), it has the drawback that one loses the clean interpretation of the; loadings and scores as features and projections. Separately, for the PCs PLINK/GCTA output the eigenvectors of the GRM, i.e.; the left singular vectors :math:`U_k` instead of the component scores; :math:`U_k S_k`. The scores have the advantage of representing true; projections of the data onto features with the variance of a score; reflecting the variance explained by the corresponding feature. In PC; bi-plots this amounts to a change in aspect ratio; for use of PCs as; covariates in regression it is immaterial. Parameters; ----------; call_expr : :class:`.CallExpression`; Entry-indexed call expression.; k : :obj:`int`; Number of principal components.; compute_loadings : :obj:`bool`; If ``True``, compute row loadings. Returns; -------; (:obj:`list` of :obj:`float`, :class:`.Table`, :class:`.Table`); List of eigenvalues, table with column scores, table with row loadings.; """"""; from hail.backend.service_backend import ServiceBackend. if isinstance(hl.current_backend(), ServiceBackend):; return _hwe_normalized_blanczos(call_expr, k, compute_loadings). return pca(hwe_normalize(call_expr), k, compute_loadings). [docs]@typecheck(entry_expr=expr_float64, k=int, compute_loadings=bool); def pca(entry_expr, k=10, compute_loadings=False) -> Tuple[List[float], Table, Table]:; r""""""Run principal component analysis (PCA) on numeric columns derived from a; matrix table. Examples; --------. For a matrix table with variant rows, sample columns, and genotype entries,; compute the top 2 PC sample scores and eigenvalues of the matrix of 0s and; 1s encoding missingness of genotype calls. >>> eigenvalues, scores, _ = hl.pca(hl.int(hl.is_defined(dataset.GT)),; ... k=2). Warning; -------; This method does **not** automatically mean-center or normalize each column.; If desired, such transformations should be incorporated in `entry_expr`",MatchSource.WIKI,docs/0.2/_modules/hail/methods/pca.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/pca.html
https://hail.is/docs/0.2/_modules/hail/methods/pca.html:6238,Performance,load,loadings,6238,"nfinity on any entry. Notes; -----. PCA is run on the columns of the numeric matrix obtained by evaluating; `entry_expr` on each entry of the matrix table, or equivalently on the rows; of the **transposed** numeric matrix :math:`M` referenced below. PCA computes the SVD. .. math::. M = USV^T. where columns of :math:`U` are left singular vectors (orthonormal in; :math:`\mathbb{R}^n`), columns of :math:`V` are right singular vectors; (orthonormal in :math:`\mathbb{R}^m`), and :math:`S=\mathrm{diag}(s_1, s_2,; \ldots)` with ordered singular values :math:`s_1 \ge s_2 \ge \cdots \ge 0`.; Typically one computes only the first :math:`k` singular vectors and values,; yielding the best rank :math:`k` approximation :math:`U_k S_k V_k^T` of; :math:`M`; the truncations :math:`U_k`, :math:`S_k` and :math:`V_k` are; :math:`n \times k`, :math:`k \times k` and :math:`m \times k`; respectively. From the perspective of the rows of :math:`M` as samples (data points),; :math:`V_k` contains the loadings for the first :math:`k` PCs while; :math:`MV_k = U_k S_k` contains the first :math:`k` PC scores of each; sample. The loadings represent a new basis of features while the scores; represent the projected data on those features. The eigenvalues of the Gramian; :math:`MM^T` are the squares of the singular values :math:`s_1^2, s_2^2,; \ldots`, which represent the variances carried by the respective PCs. By; default, Hail only computes the loadings if the ``loadings`` parameter is; specified. Scores are stored in a :class:`.Table` with the column key of the matrix; table as key and a field `scores` of type ``array<float64>`` containing; the principal component scores. Loadings are stored in a :class:`.Table` with the row key of the matrix; table as key and a field `loadings` of type ``array<float64>`` containing; the principal component loadings. The eigenvalues are returned in descending order, with scores and loadings; given the corresponding array order. Parameters; ----------; entry_expr :",MatchSource.WIKI,docs/0.2/_modules/hail/methods/pca.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/pca.html
https://hail.is/docs/0.2/_modules/hail/methods/pca.html:6365,Performance,load,loadings,6365,"ntly on the rows; of the **transposed** numeric matrix :math:`M` referenced below. PCA computes the SVD. .. math::. M = USV^T. where columns of :math:`U` are left singular vectors (orthonormal in; :math:`\mathbb{R}^n`), columns of :math:`V` are right singular vectors; (orthonormal in :math:`\mathbb{R}^m`), and :math:`S=\mathrm{diag}(s_1, s_2,; \ldots)` with ordered singular values :math:`s_1 \ge s_2 \ge \cdots \ge 0`.; Typically one computes only the first :math:`k` singular vectors and values,; yielding the best rank :math:`k` approximation :math:`U_k S_k V_k^T` of; :math:`M`; the truncations :math:`U_k`, :math:`S_k` and :math:`V_k` are; :math:`n \times k`, :math:`k \times k` and :math:`m \times k`; respectively. From the perspective of the rows of :math:`M` as samples (data points),; :math:`V_k` contains the loadings for the first :math:`k` PCs while; :math:`MV_k = U_k S_k` contains the first :math:`k` PC scores of each; sample. The loadings represent a new basis of features while the scores; represent the projected data on those features. The eigenvalues of the Gramian; :math:`MM^T` are the squares of the singular values :math:`s_1^2, s_2^2,; \ldots`, which represent the variances carried by the respective PCs. By; default, Hail only computes the loadings if the ``loadings`` parameter is; specified. Scores are stored in a :class:`.Table` with the column key of the matrix; table as key and a field `scores` of type ``array<float64>`` containing; the principal component scores. Loadings are stored in a :class:`.Table` with the row key of the matrix; table as key and a field `loadings` of type ``array<float64>`` containing; the principal component loadings. The eigenvalues are returned in descending order, with scores and loadings; given the corresponding array order. Parameters; ----------; entry_expr : :class:`.Expression`; Numeric expression for matrix entries.; k : :obj:`int`; Number of principal components.; compute_loadings : :obj:`bool`; If ``True``, compute ro",MatchSource.WIKI,docs/0.2/_modules/hail/methods/pca.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/pca.html
https://hail.is/docs/0.2/_modules/hail/methods/pca.html:6686,Performance,load,loadings,6686,"mal in :math:`\mathbb{R}^m`), and :math:`S=\mathrm{diag}(s_1, s_2,; \ldots)` with ordered singular values :math:`s_1 \ge s_2 \ge \cdots \ge 0`.; Typically one computes only the first :math:`k` singular vectors and values,; yielding the best rank :math:`k` approximation :math:`U_k S_k V_k^T` of; :math:`M`; the truncations :math:`U_k`, :math:`S_k` and :math:`V_k` are; :math:`n \times k`, :math:`k \times k` and :math:`m \times k`; respectively. From the perspective of the rows of :math:`M` as samples (data points),; :math:`V_k` contains the loadings for the first :math:`k` PCs while; :math:`MV_k = U_k S_k` contains the first :math:`k` PC scores of each; sample. The loadings represent a new basis of features while the scores; represent the projected data on those features. The eigenvalues of the Gramian; :math:`MM^T` are the squares of the singular values :math:`s_1^2, s_2^2,; \ldots`, which represent the variances carried by the respective PCs. By; default, Hail only computes the loadings if the ``loadings`` parameter is; specified. Scores are stored in a :class:`.Table` with the column key of the matrix; table as key and a field `scores` of type ``array<float64>`` containing; the principal component scores. Loadings are stored in a :class:`.Table` with the row key of the matrix; table as key and a field `loadings` of type ``array<float64>`` containing; the principal component loadings. The eigenvalues are returned in descending order, with scores and loadings; given the corresponding array order. Parameters; ----------; entry_expr : :class:`.Expression`; Numeric expression for matrix entries.; k : :obj:`int`; Number of principal components.; compute_loadings : :obj:`bool`; If ``True``, compute row loadings. Returns; -------; (:obj:`list` of :obj:`float`, :class:`.Table`, :class:`.Table`); List of eigenvalues, table with column scores, table with row loadings.; """"""; from hail.backend.service_backend import ServiceBackend. if isinstance(hl.current_backend(), ServiceBack",MatchSource.WIKI,docs/0.2/_modules/hail/methods/pca.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/pca.html
https://hail.is/docs/0.2/_modules/hail/methods/pca.html:6704,Performance,load,loadings,6704,"mal in :math:`\mathbb{R}^m`), and :math:`S=\mathrm{diag}(s_1, s_2,; \ldots)` with ordered singular values :math:`s_1 \ge s_2 \ge \cdots \ge 0`.; Typically one computes only the first :math:`k` singular vectors and values,; yielding the best rank :math:`k` approximation :math:`U_k S_k V_k^T` of; :math:`M`; the truncations :math:`U_k`, :math:`S_k` and :math:`V_k` are; :math:`n \times k`, :math:`k \times k` and :math:`m \times k`; respectively. From the perspective of the rows of :math:`M` as samples (data points),; :math:`V_k` contains the loadings for the first :math:`k` PCs while; :math:`MV_k = U_k S_k` contains the first :math:`k` PC scores of each; sample. The loadings represent a new basis of features while the scores; represent the projected data on those features. The eigenvalues of the Gramian; :math:`MM^T` are the squares of the singular values :math:`s_1^2, s_2^2,; \ldots`, which represent the variances carried by the respective PCs. By; default, Hail only computes the loadings if the ``loadings`` parameter is; specified. Scores are stored in a :class:`.Table` with the column key of the matrix; table as key and a field `scores` of type ``array<float64>`` containing; the principal component scores. Loadings are stored in a :class:`.Table` with the row key of the matrix; table as key and a field `loadings` of type ``array<float64>`` containing; the principal component loadings. The eigenvalues are returned in descending order, with scores and loadings; given the corresponding array order. Parameters; ----------; entry_expr : :class:`.Expression`; Numeric expression for matrix entries.; k : :obj:`int`; Number of principal components.; compute_loadings : :obj:`bool`; If ``True``, compute row loadings. Returns; -------; (:obj:`list` of :obj:`float`, :class:`.Table`, :class:`.Table`); List of eigenvalues, table with column scores, table with row loadings.; """"""; from hail.backend.service_backend import ServiceBackend. if isinstance(hl.current_backend(), ServiceBack",MatchSource.WIKI,docs/0.2/_modules/hail/methods/pca.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/pca.html
https://hail.is/docs/0.2/_modules/hail/methods/pca.html:7018,Performance,load,loadings,7018,"k`, :math:`S_k` and :math:`V_k` are; :math:`n \times k`, :math:`k \times k` and :math:`m \times k`; respectively. From the perspective of the rows of :math:`M` as samples (data points),; :math:`V_k` contains the loadings for the first :math:`k` PCs while; :math:`MV_k = U_k S_k` contains the first :math:`k` PC scores of each; sample. The loadings represent a new basis of features while the scores; represent the projected data on those features. The eigenvalues of the Gramian; :math:`MM^T` are the squares of the singular values :math:`s_1^2, s_2^2,; \ldots`, which represent the variances carried by the respective PCs. By; default, Hail only computes the loadings if the ``loadings`` parameter is; specified. Scores are stored in a :class:`.Table` with the column key of the matrix; table as key and a field `scores` of type ``array<float64>`` containing; the principal component scores. Loadings are stored in a :class:`.Table` with the row key of the matrix; table as key and a field `loadings` of type ``array<float64>`` containing; the principal component loadings. The eigenvalues are returned in descending order, with scores and loadings; given the corresponding array order. Parameters; ----------; entry_expr : :class:`.Expression`; Numeric expression for matrix entries.; k : :obj:`int`; Number of principal components.; compute_loadings : :obj:`bool`; If ``True``, compute row loadings. Returns; -------; (:obj:`list` of :obj:`float`, :class:`.Table`, :class:`.Table`); List of eigenvalues, table with column scores, table with row loadings.; """"""; from hail.backend.service_backend import ServiceBackend. if isinstance(hl.current_backend(), ServiceBackend):; return _blanczos_pca(entry_expr, k, compute_loadings). raise_unless_entry_indexed('pca/entry_expr', entry_expr). mt = matrix_table_source('pca/entry_expr', entry_expr). # FIXME: remove once select_entries on a field is free; if entry_expr in mt._fields_inverse:; field = mt._fields_inverse[entry_expr]; else:; field = Env.get_",MatchSource.WIKI,docs/0.2/_modules/hail/methods/pca.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/pca.html
https://hail.is/docs/0.2/_modules/hail/methods/pca.html:7091,Performance,load,loadings,7091,"k`, :math:`S_k` and :math:`V_k` are; :math:`n \times k`, :math:`k \times k` and :math:`m \times k`; respectively. From the perspective of the rows of :math:`M` as samples (data points),; :math:`V_k` contains the loadings for the first :math:`k` PCs while; :math:`MV_k = U_k S_k` contains the first :math:`k` PC scores of each; sample. The loadings represent a new basis of features while the scores; represent the projected data on those features. The eigenvalues of the Gramian; :math:`MM^T` are the squares of the singular values :math:`s_1^2, s_2^2,; \ldots`, which represent the variances carried by the respective PCs. By; default, Hail only computes the loadings if the ``loadings`` parameter is; specified. Scores are stored in a :class:`.Table` with the column key of the matrix; table as key and a field `scores` of type ``array<float64>`` containing; the principal component scores. Loadings are stored in a :class:`.Table` with the row key of the matrix; table as key and a field `loadings` of type ``array<float64>`` containing; the principal component loadings. The eigenvalues are returned in descending order, with scores and loadings; given the corresponding array order. Parameters; ----------; entry_expr : :class:`.Expression`; Numeric expression for matrix entries.; k : :obj:`int`; Number of principal components.; compute_loadings : :obj:`bool`; If ``True``, compute row loadings. Returns; -------; (:obj:`list` of :obj:`float`, :class:`.Table`, :class:`.Table`); List of eigenvalues, table with column scores, table with row loadings.; """"""; from hail.backend.service_backend import ServiceBackend. if isinstance(hl.current_backend(), ServiceBackend):; return _blanczos_pca(entry_expr, k, compute_loadings). raise_unless_entry_indexed('pca/entry_expr', entry_expr). mt = matrix_table_source('pca/entry_expr', entry_expr). # FIXME: remove once select_entries on a field is free; if entry_expr in mt._fields_inverse:; field = mt._fields_inverse[entry_expr]; else:; field = Env.get_",MatchSource.WIKI,docs/0.2/_modules/hail/methods/pca.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/pca.html
https://hail.is/docs/0.2/_modules/hail/methods/pca.html:7167,Performance,load,loadings,7167,"tive of the rows of :math:`M` as samples (data points),; :math:`V_k` contains the loadings for the first :math:`k` PCs while; :math:`MV_k = U_k S_k` contains the first :math:`k` PC scores of each; sample. The loadings represent a new basis of features while the scores; represent the projected data on those features. The eigenvalues of the Gramian; :math:`MM^T` are the squares of the singular values :math:`s_1^2, s_2^2,; \ldots`, which represent the variances carried by the respective PCs. By; default, Hail only computes the loadings if the ``loadings`` parameter is; specified. Scores are stored in a :class:`.Table` with the column key of the matrix; table as key and a field `scores` of type ``array<float64>`` containing; the principal component scores. Loadings are stored in a :class:`.Table` with the row key of the matrix; table as key and a field `loadings` of type ``array<float64>`` containing; the principal component loadings. The eigenvalues are returned in descending order, with scores and loadings; given the corresponding array order. Parameters; ----------; entry_expr : :class:`.Expression`; Numeric expression for matrix entries.; k : :obj:`int`; Number of principal components.; compute_loadings : :obj:`bool`; If ``True``, compute row loadings. Returns; -------; (:obj:`list` of :obj:`float`, :class:`.Table`, :class:`.Table`); List of eigenvalues, table with column scores, table with row loadings.; """"""; from hail.backend.service_backend import ServiceBackend. if isinstance(hl.current_backend(), ServiceBackend):; return _blanczos_pca(entry_expr, k, compute_loadings). raise_unless_entry_indexed('pca/entry_expr', entry_expr). mt = matrix_table_source('pca/entry_expr', entry_expr). # FIXME: remove once select_entries on a field is free; if entry_expr in mt._fields_inverse:; field = mt._fields_inverse[entry_expr]; else:; field = Env.get_uid(); mt = mt.select_entries(**{field: entry_expr}); mt = mt.select_cols().select_rows().select_globals(). t = Table(; ir.MatrixT",MatchSource.WIKI,docs/0.2/_modules/hail/methods/pca.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/pca.html
https://hail.is/docs/0.2/_modules/hail/methods/pca.html:7419,Performance,load,loadings,7419,"s of features while the scores; represent the projected data on those features. The eigenvalues of the Gramian; :math:`MM^T` are the squares of the singular values :math:`s_1^2, s_2^2,; \ldots`, which represent the variances carried by the respective PCs. By; default, Hail only computes the loadings if the ``loadings`` parameter is; specified. Scores are stored in a :class:`.Table` with the column key of the matrix; table as key and a field `scores` of type ``array<float64>`` containing; the principal component scores. Loadings are stored in a :class:`.Table` with the row key of the matrix; table as key and a field `loadings` of type ``array<float64>`` containing; the principal component loadings. The eigenvalues are returned in descending order, with scores and loadings; given the corresponding array order. Parameters; ----------; entry_expr : :class:`.Expression`; Numeric expression for matrix entries.; k : :obj:`int`; Number of principal components.; compute_loadings : :obj:`bool`; If ``True``, compute row loadings. Returns; -------; (:obj:`list` of :obj:`float`, :class:`.Table`, :class:`.Table`); List of eigenvalues, table with column scores, table with row loadings.; """"""; from hail.backend.service_backend import ServiceBackend. if isinstance(hl.current_backend(), ServiceBackend):; return _blanczos_pca(entry_expr, k, compute_loadings). raise_unless_entry_indexed('pca/entry_expr', entry_expr). mt = matrix_table_source('pca/entry_expr', entry_expr). # FIXME: remove once select_entries on a field is free; if entry_expr in mt._fields_inverse:; field = mt._fields_inverse[entry_expr]; else:; field = Env.get_uid(); mt = mt.select_entries(**{field: entry_expr}); mt = mt.select_cols().select_rows().select_globals(). t = Table(; ir.MatrixToTableApply(; mt._mir, {'name': 'PCA', 'entryField': field, 'k': k, 'computeLoadings': compute_loadings}; ); ).persist(). g = t.index_globals(); scores = hl.Table.parallelize(g.scores, key=list(mt.col_key)); if not compute_loadings:; t =",MatchSource.WIKI,docs/0.2/_modules/hail/methods/pca.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/pca.html
https://hail.is/docs/0.2/_modules/hail/methods/pca.html:7574,Performance,load,loadings,7574,"ingular values :math:`s_1^2, s_2^2,; \ldots`, which represent the variances carried by the respective PCs. By; default, Hail only computes the loadings if the ``loadings`` parameter is; specified. Scores are stored in a :class:`.Table` with the column key of the matrix; table as key and a field `scores` of type ``array<float64>`` containing; the principal component scores. Loadings are stored in a :class:`.Table` with the row key of the matrix; table as key and a field `loadings` of type ``array<float64>`` containing; the principal component loadings. The eigenvalues are returned in descending order, with scores and loadings; given the corresponding array order. Parameters; ----------; entry_expr : :class:`.Expression`; Numeric expression for matrix entries.; k : :obj:`int`; Number of principal components.; compute_loadings : :obj:`bool`; If ``True``, compute row loadings. Returns; -------; (:obj:`list` of :obj:`float`, :class:`.Table`, :class:`.Table`); List of eigenvalues, table with column scores, table with row loadings.; """"""; from hail.backend.service_backend import ServiceBackend. if isinstance(hl.current_backend(), ServiceBackend):; return _blanczos_pca(entry_expr, k, compute_loadings). raise_unless_entry_indexed('pca/entry_expr', entry_expr). mt = matrix_table_source('pca/entry_expr', entry_expr). # FIXME: remove once select_entries on a field is free; if entry_expr in mt._fields_inverse:; field = mt._fields_inverse[entry_expr]; else:; field = Env.get_uid(); mt = mt.select_entries(**{field: entry_expr}); mt = mt.select_cols().select_rows().select_globals(). t = Table(; ir.MatrixToTableApply(; mt._mir, {'name': 'PCA', 'entryField': field, 'k': k, 'computeLoadings': compute_loadings}; ); ).persist(). g = t.index_globals(); scores = hl.Table.parallelize(g.scores, key=list(mt.col_key)); if not compute_loadings:; t = None; return hl.eval(g.eigenvalues), scores, None if t is None else t.drop('eigenvalues', 'scores'). class TallSkinnyMatrix:; def __init__(self, blo",MatchSource.WIKI,docs/0.2/_modules/hail/methods/pca.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/pca.html
https://hail.is/docs/0.2/_modules/hail/methods/pca.html:17702,Performance,load,loadings,17702,".T @ G2); Q1, R1 = hl.nd.qr(G2)._persist(); fact2 = _krylov_factorization(A, Q1, p, compute_U=False); moments_and_stdevs = fact2.spectral_moments(num_moments, R1); # Add back exact moments; moments = moments_and_stdevs.moments + hl.nd.array([; fact.S.map(lambda x: x ** (2 * i)).sum() for i in range(1, num_moments + 1); ]); moments_and_stdevs = hl.eval(hl.struct(moments=moments, stdevs=moments_and_stdevs.stdevs)); moments = moments_and_stdevs.moments; stdevs = moments_and_stdevs.stdevs. scores = V * S; eigens = hl.eval(S * S); info(""blanczos_pca: SVD Complete. Computing conversion to PCs.""). hail_array_scores = scores._data_array(); cols_and_scores = hl.zip(A.source_table.index_globals().cols, hail_array_scores).map(; lambda tup: tup[0].annotate(scores=tup[1]); ); st = hl.Table.parallelize(cols_and_scores, key=A.col_key). if compute_loadings:; lt = A.source_table.select(); lt = lt.annotate_globals(U=U); idx_name = '_tmp_pca_loading_index'; lt = lt.add_index(idx_name); lt = lt.annotate(loadings=hl.array(lt.U[lt[idx_name], :])).select_globals(); lt = lt.drop(lt[idx_name]); else:; lt = None. return eigens, st, lt, moments, stdevs. @typecheck(; A=oneof(expr_float64, TallSkinnyMatrix),; k=int,; compute_loadings=bool,; q_iterations=int,; oversampling_param=nullable(int),; block_size=int,; compute_scores=bool,; transpose=bool,; ); def _blanczos_pca(; A,; k=10,; compute_loadings=False,; q_iterations=10,; oversampling_param=None,; block_size=128,; compute_scores=True,; transpose=False,; ):; r""""""Run randomized principal component analysis approximation (PCA); on numeric columns derived from a matrix table. Implements the Blanczos algorithm found by Rokhlin, Szlam, and Tygert. Examples; --------. For a matrix table with variant rows, sample columns, and genotype entries,; compute the top 2 PC sample scores and eigenvalues of the matrix of 0s and; 1s encoding missingness of genotype calls. >>> eigenvalues, scores, _ = hl._blanczos_pca(hl.int(hl.is_defined(dataset.GT)),; ... k=2).",MatchSource.WIKI,docs/0.2/_modules/hail/methods/pca.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/pca.html
https://hail.is/docs/0.2/_modules/hail/methods/pca.html:19937,Performance,load,loadings,19937,"nfinity on any entry. Notes; -----. PCA is run on the columns of the numeric matrix obtained by evaluating; `entry_expr` on each entry of the matrix table, or equivalently on the rows; of the **transposed** numeric matrix :math:`M` referenced below. PCA computes the SVD. .. math::. M = USV^T. where columns of :math:`U` are left singular vectors (orthonormal in; :math:`\mathbb{R}^n`), columns of :math:`V` are right singular vectors; (orthonormal in :math:`\mathbb{R}^m`), and :math:`S=\mathrm{diag}(s_1, s_2,; \ldots)` with ordered singular values :math:`s_1 \ge s_2 \ge \cdots \ge 0`.; Typically one computes only the first :math:`k` singular vectors and values,; yielding the best rank :math:`k` approximation :math:`U_k S_k V_k^T` of; :math:`M`; the truncations :math:`U_k`, :math:`S_k` and :math:`V_k` are; :math:`n \times k`, :math:`k \times k` and :math:`m \times k`; respectively. From the perspective of the rows of :math:`M` as samples (data points),; :math:`V_k` contains the loadings for the first :math:`k` PCs while; :math:`MV_k = U_k S_k` contains the first :math:`k` PC scores of each; sample. The loadings represent a new basis of features while the scores; represent the projected data on those features. The eigenvalues of the Gramian; :math:`MM^T` are the squares of the singular values :math:`s_1^2, s_2^2,; \ldots`, which represent the variances carried by the respective PCs. By; default, Hail only computes the loadings if the ``loadings`` parameter is; specified. Scores are stored in a :class:`.Table` with the column key of the matrix; table as key and a field `scores` of type ``array<float64>`` containing; the principal component scores. Loadings are stored in a :class:`.Table` with the row key of the matrix; table as key and a field `loadings` of type ``array<float64>`` containing; the principal component loadings. The eigenvalues are returned in descending order, with scores and loadings; given the corresponding array order. Parameters; ----------; entry_expr :",MatchSource.WIKI,docs/0.2/_modules/hail/methods/pca.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/pca.html
https://hail.is/docs/0.2/_modules/hail/methods/pca.html:20064,Performance,load,loadings,20064,"ntly on the rows; of the **transposed** numeric matrix :math:`M` referenced below. PCA computes the SVD. .. math::. M = USV^T. where columns of :math:`U` are left singular vectors (orthonormal in; :math:`\mathbb{R}^n`), columns of :math:`V` are right singular vectors; (orthonormal in :math:`\mathbb{R}^m`), and :math:`S=\mathrm{diag}(s_1, s_2,; \ldots)` with ordered singular values :math:`s_1 \ge s_2 \ge \cdots \ge 0`.; Typically one computes only the first :math:`k` singular vectors and values,; yielding the best rank :math:`k` approximation :math:`U_k S_k V_k^T` of; :math:`M`; the truncations :math:`U_k`, :math:`S_k` and :math:`V_k` are; :math:`n \times k`, :math:`k \times k` and :math:`m \times k`; respectively. From the perspective of the rows of :math:`M` as samples (data points),; :math:`V_k` contains the loadings for the first :math:`k` PCs while; :math:`MV_k = U_k S_k` contains the first :math:`k` PC scores of each; sample. The loadings represent a new basis of features while the scores; represent the projected data on those features. The eigenvalues of the Gramian; :math:`MM^T` are the squares of the singular values :math:`s_1^2, s_2^2,; \ldots`, which represent the variances carried by the respective PCs. By; default, Hail only computes the loadings if the ``loadings`` parameter is; specified. Scores are stored in a :class:`.Table` with the column key of the matrix; table as key and a field `scores` of type ``array<float64>`` containing; the principal component scores. Loadings are stored in a :class:`.Table` with the row key of the matrix; table as key and a field `loadings` of type ``array<float64>`` containing; the principal component loadings. The eigenvalues are returned in descending order, with scores and loadings; given the corresponding array order. Parameters; ----------; entry_expr : :class:`.Expression`; Numeric expression for matrix entries.; k : :obj:`int`; Number of principal components.; compute_loadings : :obj:`bool`; If ``True``, compute ro",MatchSource.WIKI,docs/0.2/_modules/hail/methods/pca.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/pca.html
https://hail.is/docs/0.2/_modules/hail/methods/pca.html:20385,Performance,load,loadings,20385,"mal in :math:`\mathbb{R}^m`), and :math:`S=\mathrm{diag}(s_1, s_2,; \ldots)` with ordered singular values :math:`s_1 \ge s_2 \ge \cdots \ge 0`.; Typically one computes only the first :math:`k` singular vectors and values,; yielding the best rank :math:`k` approximation :math:`U_k S_k V_k^T` of; :math:`M`; the truncations :math:`U_k`, :math:`S_k` and :math:`V_k` are; :math:`n \times k`, :math:`k \times k` and :math:`m \times k`; respectively. From the perspective of the rows of :math:`M` as samples (data points),; :math:`V_k` contains the loadings for the first :math:`k` PCs while; :math:`MV_k = U_k S_k` contains the first :math:`k` PC scores of each; sample. The loadings represent a new basis of features while the scores; represent the projected data on those features. The eigenvalues of the Gramian; :math:`MM^T` are the squares of the singular values :math:`s_1^2, s_2^2,; \ldots`, which represent the variances carried by the respective PCs. By; default, Hail only computes the loadings if the ``loadings`` parameter is; specified. Scores are stored in a :class:`.Table` with the column key of the matrix; table as key and a field `scores` of type ``array<float64>`` containing; the principal component scores. Loadings are stored in a :class:`.Table` with the row key of the matrix; table as key and a field `loadings` of type ``array<float64>`` containing; the principal component loadings. The eigenvalues are returned in descending order, with scores and loadings; given the corresponding array order. Parameters; ----------; entry_expr : :class:`.Expression`; Numeric expression for matrix entries.; k : :obj:`int`; Number of principal components.; compute_loadings : :obj:`bool`; If ``True``, compute row loadings.; q_iterations : :obj:`int`; Number of rounds of power iteration to amplify singular values.; oversampling_param : :obj:`int`; Amount of oversampling to use when approximating the singular values.; Usually a value between `0 <= oversampling_param <= k`. Returns; ---",MatchSource.WIKI,docs/0.2/_modules/hail/methods/pca.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/pca.html
https://hail.is/docs/0.2/_modules/hail/methods/pca.html:20403,Performance,load,loadings,20403,"mal in :math:`\mathbb{R}^m`), and :math:`S=\mathrm{diag}(s_1, s_2,; \ldots)` with ordered singular values :math:`s_1 \ge s_2 \ge \cdots \ge 0`.; Typically one computes only the first :math:`k` singular vectors and values,; yielding the best rank :math:`k` approximation :math:`U_k S_k V_k^T` of; :math:`M`; the truncations :math:`U_k`, :math:`S_k` and :math:`V_k` are; :math:`n \times k`, :math:`k \times k` and :math:`m \times k`; respectively. From the perspective of the rows of :math:`M` as samples (data points),; :math:`V_k` contains the loadings for the first :math:`k` PCs while; :math:`MV_k = U_k S_k` contains the first :math:`k` PC scores of each; sample. The loadings represent a new basis of features while the scores; represent the projected data on those features. The eigenvalues of the Gramian; :math:`MM^T` are the squares of the singular values :math:`s_1^2, s_2^2,; \ldots`, which represent the variances carried by the respective PCs. By; default, Hail only computes the loadings if the ``loadings`` parameter is; specified. Scores are stored in a :class:`.Table` with the column key of the matrix; table as key and a field `scores` of type ``array<float64>`` containing; the principal component scores. Loadings are stored in a :class:`.Table` with the row key of the matrix; table as key and a field `loadings` of type ``array<float64>`` containing; the principal component loadings. The eigenvalues are returned in descending order, with scores and loadings; given the corresponding array order. Parameters; ----------; entry_expr : :class:`.Expression`; Numeric expression for matrix entries.; k : :obj:`int`; Number of principal components.; compute_loadings : :obj:`bool`; If ``True``, compute row loadings.; q_iterations : :obj:`int`; Number of rounds of power iteration to amplify singular values.; oversampling_param : :obj:`int`; Amount of oversampling to use when approximating the singular values.; Usually a value between `0 <= oversampling_param <= k`. Returns; ---",MatchSource.WIKI,docs/0.2/_modules/hail/methods/pca.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/pca.html
https://hail.is/docs/0.2/_modules/hail/methods/pca.html:20717,Performance,load,loadings,20717,"k`, :math:`S_k` and :math:`V_k` are; :math:`n \times k`, :math:`k \times k` and :math:`m \times k`; respectively. From the perspective of the rows of :math:`M` as samples (data points),; :math:`V_k` contains the loadings for the first :math:`k` PCs while; :math:`MV_k = U_k S_k` contains the first :math:`k` PC scores of each; sample. The loadings represent a new basis of features while the scores; represent the projected data on those features. The eigenvalues of the Gramian; :math:`MM^T` are the squares of the singular values :math:`s_1^2, s_2^2,; \ldots`, which represent the variances carried by the respective PCs. By; default, Hail only computes the loadings if the ``loadings`` parameter is; specified. Scores are stored in a :class:`.Table` with the column key of the matrix; table as key and a field `scores` of type ``array<float64>`` containing; the principal component scores. Loadings are stored in a :class:`.Table` with the row key of the matrix; table as key and a field `loadings` of type ``array<float64>`` containing; the principal component loadings. The eigenvalues are returned in descending order, with scores and loadings; given the corresponding array order. Parameters; ----------; entry_expr : :class:`.Expression`; Numeric expression for matrix entries.; k : :obj:`int`; Number of principal components.; compute_loadings : :obj:`bool`; If ``True``, compute row loadings.; q_iterations : :obj:`int`; Number of rounds of power iteration to amplify singular values.; oversampling_param : :obj:`int`; Amount of oversampling to use when approximating the singular values.; Usually a value between `0 <= oversampling_param <= k`. Returns; -------; (:obj:`list` of :obj:`float`, :class:`.Table`, :class:`.Table`); List of eigenvalues, table with column scores, table with row loadings.; """"""; if not isinstance(A, TallSkinnyMatrix):; raise_unless_entry_indexed('_blanczos_pca/entry_expr', A); A = _make_tsm(A, block_size). if oversampling_param is None:; oversampling_param = k",MatchSource.WIKI,docs/0.2/_modules/hail/methods/pca.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/pca.html
https://hail.is/docs/0.2/_modules/hail/methods/pca.html:20790,Performance,load,loadings,20790,"k`, :math:`S_k` and :math:`V_k` are; :math:`n \times k`, :math:`k \times k` and :math:`m \times k`; respectively. From the perspective of the rows of :math:`M` as samples (data points),; :math:`V_k` contains the loadings for the first :math:`k` PCs while; :math:`MV_k = U_k S_k` contains the first :math:`k` PC scores of each; sample. The loadings represent a new basis of features while the scores; represent the projected data on those features. The eigenvalues of the Gramian; :math:`MM^T` are the squares of the singular values :math:`s_1^2, s_2^2,; \ldots`, which represent the variances carried by the respective PCs. By; default, Hail only computes the loadings if the ``loadings`` parameter is; specified. Scores are stored in a :class:`.Table` with the column key of the matrix; table as key and a field `scores` of type ``array<float64>`` containing; the principal component scores. Loadings are stored in a :class:`.Table` with the row key of the matrix; table as key and a field `loadings` of type ``array<float64>`` containing; the principal component loadings. The eigenvalues are returned in descending order, with scores and loadings; given the corresponding array order. Parameters; ----------; entry_expr : :class:`.Expression`; Numeric expression for matrix entries.; k : :obj:`int`; Number of principal components.; compute_loadings : :obj:`bool`; If ``True``, compute row loadings.; q_iterations : :obj:`int`; Number of rounds of power iteration to amplify singular values.; oversampling_param : :obj:`int`; Amount of oversampling to use when approximating the singular values.; Usually a value between `0 <= oversampling_param <= k`. Returns; -------; (:obj:`list` of :obj:`float`, :class:`.Table`, :class:`.Table`); List of eigenvalues, table with column scores, table with row loadings.; """"""; if not isinstance(A, TallSkinnyMatrix):; raise_unless_entry_indexed('_blanczos_pca/entry_expr', A); A = _make_tsm(A, block_size). if oversampling_param is None:; oversampling_param = k",MatchSource.WIKI,docs/0.2/_modules/hail/methods/pca.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/pca.html
https://hail.is/docs/0.2/_modules/hail/methods/pca.html:20866,Performance,load,loadings,20866,"tive of the rows of :math:`M` as samples (data points),; :math:`V_k` contains the loadings for the first :math:`k` PCs while; :math:`MV_k = U_k S_k` contains the first :math:`k` PC scores of each; sample. The loadings represent a new basis of features while the scores; represent the projected data on those features. The eigenvalues of the Gramian; :math:`MM^T` are the squares of the singular values :math:`s_1^2, s_2^2,; \ldots`, which represent the variances carried by the respective PCs. By; default, Hail only computes the loadings if the ``loadings`` parameter is; specified. Scores are stored in a :class:`.Table` with the column key of the matrix; table as key and a field `scores` of type ``array<float64>`` containing; the principal component scores. Loadings are stored in a :class:`.Table` with the row key of the matrix; table as key and a field `loadings` of type ``array<float64>`` containing; the principal component loadings. The eigenvalues are returned in descending order, with scores and loadings; given the corresponding array order. Parameters; ----------; entry_expr : :class:`.Expression`; Numeric expression for matrix entries.; k : :obj:`int`; Number of principal components.; compute_loadings : :obj:`bool`; If ``True``, compute row loadings.; q_iterations : :obj:`int`; Number of rounds of power iteration to amplify singular values.; oversampling_param : :obj:`int`; Amount of oversampling to use when approximating the singular values.; Usually a value between `0 <= oversampling_param <= k`. Returns; -------; (:obj:`list` of :obj:`float`, :class:`.Table`, :class:`.Table`); List of eigenvalues, table with column scores, table with row loadings.; """"""; if not isinstance(A, TallSkinnyMatrix):; raise_unless_entry_indexed('_blanczos_pca/entry_expr', A); A = _make_tsm(A, block_size). if oversampling_param is None:; oversampling_param = k. compute_U = (not transpose and compute_loadings) or (transpose and compute_scores); U, S, V = _reduced_svd(A, k, compute_U, q_it",MatchSource.WIKI,docs/0.2/_modules/hail/methods/pca.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/pca.html
https://hail.is/docs/0.2/_modules/hail/methods/pca.html:21118,Performance,load,loadings,21118,"s of features while the scores; represent the projected data on those features. The eigenvalues of the Gramian; :math:`MM^T` are the squares of the singular values :math:`s_1^2, s_2^2,; \ldots`, which represent the variances carried by the respective PCs. By; default, Hail only computes the loadings if the ``loadings`` parameter is; specified. Scores are stored in a :class:`.Table` with the column key of the matrix; table as key and a field `scores` of type ``array<float64>`` containing; the principal component scores. Loadings are stored in a :class:`.Table` with the row key of the matrix; table as key and a field `loadings` of type ``array<float64>`` containing; the principal component loadings. The eigenvalues are returned in descending order, with scores and loadings; given the corresponding array order. Parameters; ----------; entry_expr : :class:`.Expression`; Numeric expression for matrix entries.; k : :obj:`int`; Number of principal components.; compute_loadings : :obj:`bool`; If ``True``, compute row loadings.; q_iterations : :obj:`int`; Number of rounds of power iteration to amplify singular values.; oversampling_param : :obj:`int`; Amount of oversampling to use when approximating the singular values.; Usually a value between `0 <= oversampling_param <= k`. Returns; -------; (:obj:`list` of :obj:`float`, :class:`.Table`, :class:`.Table`); List of eigenvalues, table with column scores, table with row loadings.; """"""; if not isinstance(A, TallSkinnyMatrix):; raise_unless_entry_indexed('_blanczos_pca/entry_expr', A); A = _make_tsm(A, block_size). if oversampling_param is None:; oversampling_param = k. compute_U = (not transpose and compute_loadings) or (transpose and compute_scores); U, S, V = _reduced_svd(A, k, compute_U, q_iterations, k + oversampling_param); info(""blanczos_pca: SVD Complete. Computing conversion to PCs.""). def numpy_to_rows_table(X, field_name):; t = A.source_table.select(); t = t.annotate_globals(X=X); idx_name = '_tmp_pca_loading_index'; ",MatchSource.WIKI,docs/0.2/_modules/hail/methods/pca.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/pca.html
https://hail.is/docs/0.2/_modules/hail/methods/pca.html:21526,Performance,load,loadings,21526,"ey of the matrix; table as key and a field `scores` of type ``array<float64>`` containing; the principal component scores. Loadings are stored in a :class:`.Table` with the row key of the matrix; table as key and a field `loadings` of type ``array<float64>`` containing; the principal component loadings. The eigenvalues are returned in descending order, with scores and loadings; given the corresponding array order. Parameters; ----------; entry_expr : :class:`.Expression`; Numeric expression for matrix entries.; k : :obj:`int`; Number of principal components.; compute_loadings : :obj:`bool`; If ``True``, compute row loadings.; q_iterations : :obj:`int`; Number of rounds of power iteration to amplify singular values.; oversampling_param : :obj:`int`; Amount of oversampling to use when approximating the singular values.; Usually a value between `0 <= oversampling_param <= k`. Returns; -------; (:obj:`list` of :obj:`float`, :class:`.Table`, :class:`.Table`); List of eigenvalues, table with column scores, table with row loadings.; """"""; if not isinstance(A, TallSkinnyMatrix):; raise_unless_entry_indexed('_blanczos_pca/entry_expr', A); A = _make_tsm(A, block_size). if oversampling_param is None:; oversampling_param = k. compute_U = (not transpose and compute_loadings) or (transpose and compute_scores); U, S, V = _reduced_svd(A, k, compute_U, q_iterations, k + oversampling_param); info(""blanczos_pca: SVD Complete. Computing conversion to PCs.""). def numpy_to_rows_table(X, field_name):; t = A.source_table.select(); t = t.annotate_globals(X=X); idx_name = '_tmp_pca_loading_index'; t = t.add_index(idx_name); t = t.annotate(**{field_name: hl.array(t.X[t[idx_name], :])}).select_globals(); t = t.drop(t[idx_name]); return t. def numpy_to_cols_table(X, field_name):; hail_array = X._data_array(); cols_and_X = hl.zip(A.source_table.index_globals().cols, hail_array).map(; lambda tup: tup[0].annotate(**{field_name: tup[1]}); ); t = hl.Table.parallelize(cols_and_X, key=A.col_key); retur",MatchSource.WIKI,docs/0.2/_modules/hail/methods/pca.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/pca.html
https://hail.is/docs/0.2/_modules/hail/methods/pca.html:22613,Performance,load,loadings,22613,"ersampling_param is None:; oversampling_param = k. compute_U = (not transpose and compute_loadings) or (transpose and compute_scores); U, S, V = _reduced_svd(A, k, compute_U, q_iterations, k + oversampling_param); info(""blanczos_pca: SVD Complete. Computing conversion to PCs.""). def numpy_to_rows_table(X, field_name):; t = A.source_table.select(); t = t.annotate_globals(X=X); idx_name = '_tmp_pca_loading_index'; t = t.add_index(idx_name); t = t.annotate(**{field_name: hl.array(t.X[t[idx_name], :])}).select_globals(); t = t.drop(t[idx_name]); return t. def numpy_to_cols_table(X, field_name):; hail_array = X._data_array(); cols_and_X = hl.zip(A.source_table.index_globals().cols, hail_array).map(; lambda tup: tup[0].annotate(**{field_name: tup[1]}); ); t = hl.Table.parallelize(cols_and_X, key=A.col_key); return t. st = None; lt = None; eigens = hl.eval(S * S); if transpose:; if compute_loadings:; lt = numpy_to_cols_table(V, 'loadings'); if compute_scores:; st = numpy_to_rows_table(U * S, 'scores'); else:; if compute_scores:; st = numpy_to_cols_table(V * S, 'scores'); if compute_loadings:; lt = numpy_to_rows_table(U, 'loadings'). return eigens, st, lt. @typecheck(; call_expr=expr_call,; k=int,; compute_loadings=bool,; q_iterations=int,; oversampling_param=nullable(int),; block_size=int,; ); def _hwe_normalized_blanczos(; call_expr, k=10, compute_loadings=False, q_iterations=10, oversampling_param=None, block_size=128; ):; r""""""Run randomized principal component analysis approximation (PCA) on the; Hardy-Weinberg-normalized genotype call matrix. Implements the Blanczos algorithm found by Rokhlin, Szlam, and Tygert. Examples; --------. >>> eigenvalues, scores, loadings = hl._hwe_normalized_blanczos(dataset.GT, k=5). Notes; -----; This method specializes :func:`._blanczos_pca` for the common use case; of PCA in statistical genetics, that of projecting samples to a small; number of ancestry coordinates. Variants that are all homozygous reference; or all homozygous alternate ",MatchSource.WIKI,docs/0.2/_modules/hail/methods/pca.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/pca.html
https://hail.is/docs/0.2/_modules/hail/methods/pca.html:22809,Performance,load,loadings,22809,"ersampling_param is None:; oversampling_param = k. compute_U = (not transpose and compute_loadings) or (transpose and compute_scores); U, S, V = _reduced_svd(A, k, compute_U, q_iterations, k + oversampling_param); info(""blanczos_pca: SVD Complete. Computing conversion to PCs.""). def numpy_to_rows_table(X, field_name):; t = A.source_table.select(); t = t.annotate_globals(X=X); idx_name = '_tmp_pca_loading_index'; t = t.add_index(idx_name); t = t.annotate(**{field_name: hl.array(t.X[t[idx_name], :])}).select_globals(); t = t.drop(t[idx_name]); return t. def numpy_to_cols_table(X, field_name):; hail_array = X._data_array(); cols_and_X = hl.zip(A.source_table.index_globals().cols, hail_array).map(; lambda tup: tup[0].annotate(**{field_name: tup[1]}); ); t = hl.Table.parallelize(cols_and_X, key=A.col_key); return t. st = None; lt = None; eigens = hl.eval(S * S); if transpose:; if compute_loadings:; lt = numpy_to_cols_table(V, 'loadings'); if compute_scores:; st = numpy_to_rows_table(U * S, 'scores'); else:; if compute_scores:; st = numpy_to_cols_table(V * S, 'scores'); if compute_loadings:; lt = numpy_to_rows_table(U, 'loadings'). return eigens, st, lt. @typecheck(; call_expr=expr_call,; k=int,; compute_loadings=bool,; q_iterations=int,; oversampling_param=nullable(int),; block_size=int,; ); def _hwe_normalized_blanczos(; call_expr, k=10, compute_loadings=False, q_iterations=10, oversampling_param=None, block_size=128; ):; r""""""Run randomized principal component analysis approximation (PCA) on the; Hardy-Weinberg-normalized genotype call matrix. Implements the Blanczos algorithm found by Rokhlin, Szlam, and Tygert. Examples; --------. >>> eigenvalues, scores, loadings = hl._hwe_normalized_blanczos(dataset.GT, k=5). Notes; -----; This method specializes :func:`._blanczos_pca` for the common use case; of PCA in statistical genetics, that of projecting samples to a small; number of ancestry coordinates. Variants that are all homozygous reference; or all homozygous alternate ",MatchSource.WIKI,docs/0.2/_modules/hail/methods/pca.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/pca.html
https://hail.is/docs/0.2/_modules/hail/methods/pca.html:23359,Performance,load,loadings,23359,"s().cols, hail_array).map(; lambda tup: tup[0].annotate(**{field_name: tup[1]}); ); t = hl.Table.parallelize(cols_and_X, key=A.col_key); return t. st = None; lt = None; eigens = hl.eval(S * S); if transpose:; if compute_loadings:; lt = numpy_to_cols_table(V, 'loadings'); if compute_scores:; st = numpy_to_rows_table(U * S, 'scores'); else:; if compute_scores:; st = numpy_to_cols_table(V * S, 'scores'); if compute_loadings:; lt = numpy_to_rows_table(U, 'loadings'). return eigens, st, lt. @typecheck(; call_expr=expr_call,; k=int,; compute_loadings=bool,; q_iterations=int,; oversampling_param=nullable(int),; block_size=int,; ); def _hwe_normalized_blanczos(; call_expr, k=10, compute_loadings=False, q_iterations=10, oversampling_param=None, block_size=128; ):; r""""""Run randomized principal component analysis approximation (PCA) on the; Hardy-Weinberg-normalized genotype call matrix. Implements the Blanczos algorithm found by Rokhlin, Szlam, and Tygert. Examples; --------. >>> eigenvalues, scores, loadings = hl._hwe_normalized_blanczos(dataset.GT, k=5). Notes; -----; This method specializes :func:`._blanczos_pca` for the common use case; of PCA in statistical genetics, that of projecting samples to a small; number of ancestry coordinates. Variants that are all homozygous reference; or all homozygous alternate are unnormalizable and removed before; evaluation. See :func:`._blanczos_pca` for more details. Parameters; ----------; call_expr : :class:`.CallExpression`; Entry-indexed call expression.; k : :obj:`int`; Number of principal components.; compute_loadings : :obj:`bool`; If ``True``, compute row loadings. Returns; -------; (:obj:`list` of :obj:`float`, :class:`.Table`, :class:`.Table`); List of eigenvalues, table with column scores, table with row loadings.; """"""; raise_unless_entry_indexed('_blanczos_pca/entry_expr', call_expr); A = _make_tsm_from_call(call_expr, block_size, hwe_normalize=True). return _blanczos_pca(; A,; k,; compute_loadings=compute_loadings,; q_itera",MatchSource.WIKI,docs/0.2/_modules/hail/methods/pca.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/pca.html
https://hail.is/docs/0.2/_modules/hail/methods/pca.html:23973,Performance,load,loadings,23973,"; lt = None; eigens = hl.eval(S * S); if transpose:; if compute_loadings:; lt = numpy_to_cols_table(V, 'loadings'); if compute_scores:; st = numpy_to_rows_table(U * S, 'scores'); else:; if compute_scores:; st = numpy_to_cols_table(V * S, 'scores'); if compute_loadings:; lt = numpy_to_rows_table(U, 'loadings'). return eigens, st, lt. @typecheck(; call_expr=expr_call,; k=int,; compute_loadings=bool,; q_iterations=int,; oversampling_param=nullable(int),; block_size=int,; ); def _hwe_normalized_blanczos(; call_expr, k=10, compute_loadings=False, q_iterations=10, oversampling_param=None, block_size=128; ):; r""""""Run randomized principal component analysis approximation (PCA) on the; Hardy-Weinberg-normalized genotype call matrix. Implements the Blanczos algorithm found by Rokhlin, Szlam, and Tygert. Examples; --------. >>> eigenvalues, scores, loadings = hl._hwe_normalized_blanczos(dataset.GT, k=5). Notes; -----; This method specializes :func:`._blanczos_pca` for the common use case; of PCA in statistical genetics, that of projecting samples to a small; number of ancestry coordinates. Variants that are all homozygous reference; or all homozygous alternate are unnormalizable and removed before; evaluation. See :func:`._blanczos_pca` for more details. Parameters; ----------; call_expr : :class:`.CallExpression`; Entry-indexed call expression.; k : :obj:`int`; Number of principal components.; compute_loadings : :obj:`bool`; If ``True``, compute row loadings. Returns; -------; (:obj:`list` of :obj:`float`, :class:`.Table`, :class:`.Table`); List of eigenvalues, table with column scores, table with row loadings.; """"""; raise_unless_entry_indexed('_blanczos_pca/entry_expr', call_expr); A = _make_tsm_from_call(call_expr, block_size, hwe_normalize=True). return _blanczos_pca(; A,; k,; compute_loadings=compute_loadings,; q_iterations=q_iterations,; oversampling_param=oversampling_param,; block_size=block_size,; ). © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,docs/0.2/_modules/hail/methods/pca.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/pca.html
https://hail.is/docs/0.2/_modules/hail/methods/pca.html:24128,Performance,load,loadings,24128,"; lt = None; eigens = hl.eval(S * S); if transpose:; if compute_loadings:; lt = numpy_to_cols_table(V, 'loadings'); if compute_scores:; st = numpy_to_rows_table(U * S, 'scores'); else:; if compute_scores:; st = numpy_to_cols_table(V * S, 'scores'); if compute_loadings:; lt = numpy_to_rows_table(U, 'loadings'). return eigens, st, lt. @typecheck(; call_expr=expr_call,; k=int,; compute_loadings=bool,; q_iterations=int,; oversampling_param=nullable(int),; block_size=int,; ); def _hwe_normalized_blanczos(; call_expr, k=10, compute_loadings=False, q_iterations=10, oversampling_param=None, block_size=128; ):; r""""""Run randomized principal component analysis approximation (PCA) on the; Hardy-Weinberg-normalized genotype call matrix. Implements the Blanczos algorithm found by Rokhlin, Szlam, and Tygert. Examples; --------. >>> eigenvalues, scores, loadings = hl._hwe_normalized_blanczos(dataset.GT, k=5). Notes; -----; This method specializes :func:`._blanczos_pca` for the common use case; of PCA in statistical genetics, that of projecting samples to a small; number of ancestry coordinates. Variants that are all homozygous reference; or all homozygous alternate are unnormalizable and removed before; evaluation. See :func:`._blanczos_pca` for more details. Parameters; ----------; call_expr : :class:`.CallExpression`; Entry-indexed call expression.; k : :obj:`int`; Number of principal components.; compute_loadings : :obj:`bool`; If ``True``, compute row loadings. Returns; -------; (:obj:`list` of :obj:`float`, :class:`.Table`, :class:`.Table`); List of eigenvalues, table with column scores, table with row loadings.; """"""; raise_unless_entry_indexed('_blanczos_pca/entry_expr', call_expr); A = _make_tsm_from_call(call_expr, block_size, hwe_normalize=True). return _blanczos_pca(; A,; k,; compute_loadings=compute_loadings,; q_iterations=q_iterations,; oversampling_param=oversampling_param,; block_size=block_size,; ). © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,docs/0.2/_modules/hail/methods/pca.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/pca.html
https://hail.is/docs/0.2/_modules/hail/methods/pca.html:14395,Testability,assert,assert,14395,"j in range(0, p):; info(f""krylov_factorization: Beginning iteration {j+1}/{p}""); G_i = t.aggregate(hl.agg.ndarray_sum(A_expr.T @ (A_expr @ G_i)), _localize=False); G_i = hl.nd.qr(G_i)[0]._persist(); g_list.append(G_i). info(""krylov_factorization: Iterations complete. Computing local QR""); V0 = hl.nd.hstack(g_list). if compute_V:; V = hl.nd.qr(V0)[0]._persist(); t = t.annotate(AV=A_expr @ V); else:; V = hl.nd.qr(V0)[0]; t = t.annotate(AV=A_expr @ V); V = None. if compute_U:; temp_file_name = hl.utils.new_temp_file(""_krylov_factorization_intermediate"", ""ht""); t = t.checkpoint(temp_file_name); AV_local = t.aggregate(hl.nd.vstack(hl.agg.collect(t.AV)), _localize=False); U, R = hl.nd.qr(AV_local)._persist(); else:; Rs = t.aggregate(hl.nd.vstack(hl.agg.collect(hl.nd.qr(t.AV)[1])), _localize=False); R = hl.nd.qr(Rs)[1]._persist(); U = None. return KrylovFactorization(U, R, V, k). def _reduced_svd(A: TallSkinnyMatrix, k=10, compute_U=False, iterations=2, iteration_size=None):; # Set Parameters; q = iterations; if iteration_size is None:; L = k + 2; else:; L = iteration_size; assert (q + 1) * L >= k; n = A.ncols. # Generate random matrix G; G = hl.rand_norm(0, 1, size=(n, L)); G = hl.nd.qr(G)[0]._persist(). fact = _krylov_factorization(A, G, q, compute_U); info(""_reduced_svd: Computing local SVD""); return fact.reduced_svd(k). @typecheck(; A=oneof(expr_float64, TallSkinnyMatrix), num_moments=int, p=nullable(int), moment_samples=int, block_size=int; ); def _spectral_moments(A, num_moments, p=None, moment_samples=500, block_size=128):; if not isinstance(A, TallSkinnyMatrix):; raise_unless_entry_indexed('_spectral_moments/entry_expr', A); A = _make_tsm(A, block_size). n = A.ncols. if p is None:; p = min(num_moments // 2, 10). # TODO: When moment_samples > n, we should just do a TSQR on A, and compute; # the spectrum of R.; assert moment_samples < n, '_spectral_moments: moment_samples must be smaller than num cols of A'; G = hl.rand_unif(-1, 1, size=(n, moment_samples)).map(lambd",MatchSource.WIKI,docs/0.2/_modules/hail/methods/pca.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/pca.html
https://hail.is/docs/0.2/_modules/hail/methods/pca.html:15153,Testability,assert,assert,15153,"uced_svd(A: TallSkinnyMatrix, k=10, compute_U=False, iterations=2, iteration_size=None):; # Set Parameters; q = iterations; if iteration_size is None:; L = k + 2; else:; L = iteration_size; assert (q + 1) * L >= k; n = A.ncols. # Generate random matrix G; G = hl.rand_norm(0, 1, size=(n, L)); G = hl.nd.qr(G)[0]._persist(). fact = _krylov_factorization(A, G, q, compute_U); info(""_reduced_svd: Computing local SVD""); return fact.reduced_svd(k). @typecheck(; A=oneof(expr_float64, TallSkinnyMatrix), num_moments=int, p=nullable(int), moment_samples=int, block_size=int; ); def _spectral_moments(A, num_moments, p=None, moment_samples=500, block_size=128):; if not isinstance(A, TallSkinnyMatrix):; raise_unless_entry_indexed('_spectral_moments/entry_expr', A); A = _make_tsm(A, block_size). n = A.ncols. if p is None:; p = min(num_moments // 2, 10). # TODO: When moment_samples > n, we should just do a TSQR on A, and compute; # the spectrum of R.; assert moment_samples < n, '_spectral_moments: moment_samples must be smaller than num cols of A'; G = hl.rand_unif(-1, 1, size=(n, moment_samples)).map(lambda x: hl.sign(x)); Q1, R1 = hl.nd.qr(G)._persist(); fact = _krylov_factorization(A, Q1, p, compute_U=False); moments_and_stdevs = hl.eval(fact.spectral_moments(num_moments, R1)); moments = moments_and_stdevs.moments; stdevs = moments_and_stdevs.stdevs; return moments, stdevs. @typecheck(; A=oneof(expr_float64, TallSkinnyMatrix),; k=int,; num_moments=int,; compute_loadings=bool,; q_iterations=int,; oversampling_param=nullable(int),; block_size=int,; moment_samples=int,; ); def _pca_and_moments(; A,; k=10,; num_moments=5,; compute_loadings=False,; q_iterations=10,; oversampling_param=None,; block_size=128,; moment_samples=100,; ):; if not isinstance(A, TallSkinnyMatrix):; raise_unless_entry_indexed('_spectral_moments/entry_expr', A); A = _make_tsm(A, block_size). if oversampling_param is None:; oversampling_param = k. # Set Parameters; q = q_iterations; L = k + oversampling_param; n =",MatchSource.WIKI,docs/0.2/_modules/hail/methods/pca.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/pca.html
https://hail.is/docs/0.2/_modules/hail/methods/pca.html:2670,Usability,simpl,simply,2670,"ormalized_gt = hl.or_else((mt.__gt - mt.__mean_gt) / mt.__hwe_scaled_std_dev, 0.0); return normalized_gt. [docs]@typecheck(call_expr=expr_call, k=int, compute_loadings=bool); def hwe_normalized_pca(call_expr, k=10, compute_loadings=False) -> Tuple[List[float], Table, Table]:; r""""""Run principal component analysis (PCA) on the Hardy-Weinberg-normalized; genotype call matrix. Examples; --------. >>> eigenvalues, scores, loadings = hl.hwe_normalized_pca(dataset.GT, k=5). Notes; -----; This method specializes :func:`.pca` for the common use case; of PCA in statistical genetics, that of projecting samples to a small; number of ancestry coordinates. Variants that are all homozygous reference; or all homozygous alternate are unnormalizable and removed before; evaluation. See :func:`.pca` for more details. Users of PLINK/GCTA should be aware that Hail computes the GRM slightly; differently with regard to missing data. In Hail, the; :math:`ij` entry of the GRM :math:`MM^T` is simply the dot product of rows; :math:`i` and :math:`j` of :math:`M`; in terms of :math:`C` it is. .. math::. \frac{1}{m}\sum_{l\in\mathcal{C}_i\cap\mathcal{C}_j}\frac{(C_{il}-2p_l)(C_{jl} - 2p_l)}{2p_l(1-p_l)}. where :math:`\mathcal{C}_i = \{l \mid C_{il} \text{ is non-missing}\}`. In; PLINK/GCTA the denominator :math:`m` is replaced with the number of terms in; the sum :math:`\lvert\mathcal{C}_i\cap\mathcal{C}_j\rvert`, i.e. the; number of variants where both samples have non-missing genotypes. While this; is arguably a better estimator of the true GRM (trading shrinkage for; noise), it has the drawback that one loses the clean interpretation of the; loadings and scores as features and projections. Separately, for the PCs PLINK/GCTA output the eigenvectors of the GRM, i.e.; the left singular vectors :math:`U_k` instead of the component scores; :math:`U_k S_k`. The scores have the advantage of representing true; projections of the data onto features with the variance of a score; reflecting the variance e",MatchSource.WIKI,docs/0.2/_modules/hail/methods/pca.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/pca.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:3409,Availability,error,error,3409,"-------. Compute sample QC metrics and remove low-quality samples:. >>> dataset = hl.sample_qc(dataset, name='sample_qc'); >>> filtered_dataset = dataset.filter_cols((dataset.sample_qc.dp_stats.mean > 20) & (dataset.sample_qc.r_ti_tv > 1.5)). Notes; -----. This method computes summary statistics per sample from a genetic matrix and stores; the results as a new column-indexed struct field in the matrix, named based on the; `name` parameter. If `mt` contains an entry field `DP` of type :py:data:`.tint32`, then the; field `dp_stats` is computed. If `mt` contains an entry field `GQ` of type; :py:data:`.tint32`, then the field `gq_stats` is computed. Both `dp_stats`; and `gq_stats` are structs with with four fields:. - `mean` (``float64``) -- Mean value.; - `stdev` (``float64``) -- Standard deviation (zero degrees of freedom).; - `min` (``int32``) -- Minimum value.; - `max` (``int32``) -- Maximum value. If the dataset does not contain an entry field `GT` of type; :py:data:`.tcall`, then an error is raised. The following fields are always; computed from `GT`:. - `call_rate` (``float64``) -- Fraction of calls not missing or filtered.; Equivalent to `n_called` divided by :meth:`.count_rows`.; - `n_called` (``int64``) -- Number of non-missing calls.; - `n_not_called` (``int64``) -- Number of missing calls.; - `n_filtered` (``int64``) -- Number of filtered entries.; - `n_hom_ref` (``int64``) -- Number of homozygous reference calls.; - `n_het` (``int64``) -- Number of heterozygous calls.; - `n_hom_var` (``int64``) -- Number of homozygous alternate calls.; - `n_non_ref` (``int64``) -- Sum of `n_het` and `n_hom_var`.; - `n_snp` (``int64``) -- Number of SNP alternate alleles.; - `n_insertion` (``int64``) -- Number of insertion alternate alleles.; - `n_deletion` (``int64``) -- Number of deletion alternate alleles.; - `n_singleton` (``int64``) -- Number of private alleles. Reference alleles are never counted as singletons, even if; every other allele at a site is non-reference.; - ",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:9097,Availability,error,error,9097,"atrixTable, name=str); def variant_qc(mt, name='variant_qc') -> MatrixTable:; """"""Compute common variant statistics (quality control metrics). .. include:: ../_templates/req_tvariant.rst. Examples; --------. >>> dataset_result = hl.variant_qc(dataset). Notes; -----; This method computes variant statistics from the genotype data, returning; a new struct field `name` with the following metrics based on the fields; present in the entry schema. If `mt` contains an entry field `DP` of type :py:data:`.tint32`, then the; field `dp_stats` is computed. If `mt` contains an entry field `GQ` of type; :py:data:`.tint32`, then the field `gq_stats` is computed. Both `dp_stats`; and `gq_stats` are structs with with four fields:. - `mean` (``float64``) -- Mean value.; - `stdev` (``float64``) -- Standard deviation (zero degrees of freedom).; - `min` (``int32``) -- Minimum value.; - `max` (``int32``) -- Maximum value. If the dataset does not contain an entry field `GT` of type; :py:data:`.tcall`, then an error is raised. The following fields are always; computed from `GT`:. - `AF` (``array<float64>``) -- Calculated allele frequency, one element; per allele, including the reference. Sums to one. Equivalent to; `AC` / `AN`.; - `AC` (``array<int32>``) -- Calculated allele count, one element per; allele, including the reference. Sums to `AN`.; - `AN` (``int32``) -- Total number of called alleles.; - `homozygote_count` (``array<int32>``) -- Number of homozygotes per; allele. One element per allele, including the reference.; - `call_rate` (``float64``) -- Fraction of calls neither missing nor filtered.; Equivalent to `n_called` / :meth:`.count_cols`.; - `n_called` (``int64``) -- Number of samples with a defined `GT`.; - `n_not_called` (``int64``) -- Number of samples with a missing `GT`.; - `n_filtered` (``int64``) -- Number of filtered entries.; - `n_het` (``int64``) -- Number of heterozygous samples.; - `n_non_ref` (``int64``) -- Number of samples with at least one called; non-reference al",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:26247,Availability,avail,available,26247,"ancestor.fa.gz,filter_position:0.05,min_intron_size:15,conservation_file:{self.data_mount}/loftee_data/phylocsf_gerp.sql,gerp_file:{self.data_mount}/loftee_data/GERP_scores.final.sorted.txt.gz \; -o STDOUT; '''. The following environment variables are added to the job's environment:. - `VEP_BLOCK_SIZE` - The maximum number of variants provided as input to each invocation of VEP.; - `VEP_PART_ID` - Partition ID.; - `VEP_DATA_MOUNT` - Location where the vep data is mounted (same as `data_mount` in the config).; - `VEP_CONSEQUENCE` - Integer equal to 0 or 1 on whether `csq` is False or True.; - `VEP_TOLERATE_PARSE_ERROR` - Integer equal to 0 or 1 on whether `tolerate_parse_error` is False or True.; - `VEP_OUTPUT_FILE` - String specifying the local path where the output TSV file with the VEP result should be located.; - `VEP_INPUT_FILE` - String specifying the local path where the input VCF shard is located for all jobs. The `VEP_INPUT_FILE` environment variable is not available for the single job that computes the consequence header when; ``csq=True``; """""". json_typ: hl.expr.HailType; data_bucket: str; data_mount: str; regions: List[str]; image: str; env: Dict[str, str]; data_bucket_is_requester_pays: bool; cloud: str; batch_run_command: List[str]; batch_run_csq_header_command: List[str]. @abc.abstractmethod; def command(; self, consequence: bool, tolerate_parse_error: bool, part_id: int, input_file: Optional[str], output_file: str; ) -> List[str]:; raise NotImplementedError. [docs]class VEPConfigGRCh37Version85(VEPConfig):; """"""; The Hail-maintained VEP configuration for GRCh37 for VEP version 85. This class takes the following constructor arguments:. - `data_bucket` (:obj:`.str`) -- The location where the VEP data is stored.; - `data_mount` (:obj:`.str`) -- The location in the container where the data should be mounted.; - `image` (:obj:`.str`) -- The docker image to run VEP.; - `cloud` (:obj:`.str`) -- The cloud where the Batch Service is located.; - `data_bucket_is_",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:44262,Availability,checkpoint,checkpoint,44262,"tes with the VCF CSQ field as a :py:data:`.tstr`.; If ``False``, annotates as the `vep_json_schema`.; tolerate_parse_error : :obj:`bool`; If ``True``, ignore invalid JSON produced by VEP and return a missing annotation. Returns; -------; :class:`.MatrixTable` or :class:`.Table`; Dataset with new row-indexed field `name` containing VEP annotations. """""". if isinstance(dataset, MatrixTable):; require_row_key_variant(dataset, 'vep'); ht = dataset.select_rows().rows(); else:; require_table_key_variant(dataset, 'vep'); ht = dataset.select(). ht = ht.distinct(). backend = hl.current_backend(); if isinstance(backend, ServiceBackend):; with hl.TemporaryDirectory(prefix='qob/vep/inputs/') as vep_input_path:; with hl.TemporaryDirectory(prefix='qob/vep/outputs/') as vep_output_path:; annotations = _service_vep(; backend, ht, config, block_size, csq, tolerate_parse_error, vep_input_path, vep_output_path; ); annotations = annotations.checkpoint(new_temp_file()); else:; if config is None:; maybe_cloud_spark_provider = guess_cloud_spark_provider(); maybe_config = os.getenv(""VEP_CONFIG_URI""); if maybe_config is not None:; config = maybe_config; elif maybe_cloud_spark_provider == 'hdinsight':; warning(; 'Assuming you are in a hailctl hdinsight cluster. If not, specify the config parameter to `hl.vep`.'; ); config = 'file:/vep_data/vep-azure.json'; else:; raise ValueError(""No config set and VEP_CONFIG_URI was not set.""). annotations = Table(; TableToTableApply(; ht._tir,; {; 'name': 'VEP',; 'config': config,; 'csq': csq,; 'blockSize': block_size,; 'tolerateParseError': tolerate_parse_error,; },; ); ).persist(). if csq:; dataset = dataset.annotate_globals(**{name + '_csq_header': annotations.index_globals()['vep_csq_header']}). if isinstance(dataset, MatrixTable):; vep = annotations[dataset.row_key]; return dataset.annotate_rows(**{name: vep.vep, name + '_proc_id': vep.vep_proc_id}); else:; vep = annotations[dataset.key]; return dataset.annotate(**{name: vep.vep, name + '_proc_id': vep.",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:44884,Availability,toler,tolerateParseError,44884,". ht = ht.distinct(). backend = hl.current_backend(); if isinstance(backend, ServiceBackend):; with hl.TemporaryDirectory(prefix='qob/vep/inputs/') as vep_input_path:; with hl.TemporaryDirectory(prefix='qob/vep/outputs/') as vep_output_path:; annotations = _service_vep(; backend, ht, config, block_size, csq, tolerate_parse_error, vep_input_path, vep_output_path; ); annotations = annotations.checkpoint(new_temp_file()); else:; if config is None:; maybe_cloud_spark_provider = guess_cloud_spark_provider(); maybe_config = os.getenv(""VEP_CONFIG_URI""); if maybe_config is not None:; config = maybe_config; elif maybe_cloud_spark_provider == 'hdinsight':; warning(; 'Assuming you are in a hailctl hdinsight cluster. If not, specify the config parameter to `hl.vep`.'; ); config = 'file:/vep_data/vep-azure.json'; else:; raise ValueError(""No config set and VEP_CONFIG_URI was not set.""). annotations = Table(; TableToTableApply(; ht._tir,; {; 'name': 'VEP',; 'config': config,; 'csq': csq,; 'blockSize': block_size,; 'tolerateParseError': tolerate_parse_error,; },; ); ).persist(). if csq:; dataset = dataset.annotate_globals(**{name + '_csq_header': annotations.index_globals()['vep_csq_header']}). if isinstance(dataset, MatrixTable):; vep = annotations[dataset.row_key]; return dataset.annotate_rows(**{name: vep.vep, name + '_proc_id': vep.vep_proc_id}); else:; vep = annotations[dataset.key]; return dataset.annotate(**{name: vep.vep, name + '_proc_id': vep.vep_proc_id}). [docs]@typecheck(dataset=oneof(Table, MatrixTable), config=str, block_size=int, name=str); def nirvana(dataset: Union[MatrixTable, Table], config, block_size=500000, name='nirvana'):; """"""Annotate variants using `Nirvana <https://github.com/Illumina/Nirvana>`_. .. include:: ../_templates/experimental.rst. .. include:: ../_templates/req_tvariant.rst. :func:`.nirvana` runs `Nirvana; <https://github.com/Illumina/Nirvana>`_ on the current dataset and adds a; new row field in the location specified by `name`. Examples; -----",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:58194,Availability,down,down,58194,"leles per variant; -------------------; 2 alleles: 346 variants; ==============================; Variants per contig; -------------------; 20: 346 variants; ==============================; Allele type distribution; ------------------------; SNP: 301 alleles; Deletion: 27 alleles; Insertion: 18 alleles; ==============================. Parameters; ----------; mt : :class:`.MatrixTable` or :class:`.Table`; Matrix table with a variant (locus / alleles) row key.; show : :obj:`bool`; If ``True``, print results instead of returning them.; handler. Notes; -----; The result returned if `show` is ``False`` is a :class:`.Struct` with; five fields:. - `n_variants` (:obj:`int`): Number of variants present in the matrix table.; - `allele_types` (:obj:`dict` [:obj:`str`, :obj:`int`]): Number of alternate alleles in; each allele allele category.; - `contigs` (:obj:`dict` [:obj:`str`, :obj:`int`]): Number of variants on each contig.; - `allele_counts` (:obj:`dict` [:obj:`int`, :obj:`int`]): Number of variants broken down; by number of alleles (biallelic is 2, for example).; - `r_ti_tv` (:obj:`float`): Ratio of transition alternate alleles to; transversion alternate alleles. Returns; -------; :obj:`None` or :class:`.Struct`; Returns ``None`` if `show` is ``True``, or returns results as a struct.; """"""; require_row_key_variant(mt, 'summarize_variants'); if isinstance(mt, MatrixTable):; ht = mt.rows(); else:; ht = mt; allele_pairs = hl.range(1, hl.len(ht.alleles)).map(lambda i: (ht.alleles[0], ht.alleles[i])). def explode_result(alleles):; ref, alt = alleles; return (; hl.agg.counter(hl.allele_type(ref, alt)),; hl.agg.count_where(hl.is_transition(ref, alt)),; hl.agg.count_where(hl.is_transversion(ref, alt)),; ). (allele_types, nti, ntv), contigs, allele_counts, n_variants = ht.aggregate((; hl.agg.explode(explode_result, allele_pairs),; hl.agg.counter(ht.locus.contig),; hl.agg.counter(hl.len(ht.alleles)),; hl.agg.count(),; )); rg = ht.locus.dtype.reference_genome; if show:; summary = _Var",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:23077,Deployability,configurat,configuration,23077,"=tint32,; transcript_consequences=tarray(; tstruct(; allele_num=tint32,; amino_acids=tstr,; biotype=tstr,; canonical=tint32,; ccds=tstr,; cdna_start=tint32,; cdna_end=tint32,; cds_end=tint32,; cds_start=tint32,; codons=tstr,; consequence_terms=tarray(tstr),; distance=tint32,; domains=tarray(tstruct(db=tstr, name=tstr)),; exon=tstr,; gene_id=tstr,; gene_pheno=tint32,; gene_symbol=tstr,; gene_symbol_source=tstr,; hgnc_id=tstr,; hgvsc=tstr,; hgvsp=tstr,; hgvs_offset=tint32,; impact=tstr,; intron=tstr,; lof=tstr,; lof_flags=tstr,; lof_filter=tstr,; lof_info=tstr,; minimised=tint32,; polyphen_prediction=tstr,; polyphen_score=tfloat,; protein_end=tint32,; protein_start=tint32,; protein_id=tstr,; sift_prediction=tstr,; sift_score=tfloat,; strand=tint32,; swissprot=tstr,; transcript_id=tstr,; trembl=tstr,; uniparc=tstr,; variant_allele=tstr,; ); ),; variant_class=tstr,; ). [docs]class VEPConfig(abc.ABC):; """"""Base class for configuring VEP. To define a custom VEP configuration to for Query on Batch, construct a new class that inherits from :class:`.VEPConfig`; and has the following parameters defined:. - `json_type` (:class:`.HailType`): The type of the VEP JSON schema (as produced by VEP when invoked with the `--json` option).; - `data_bucket` (:obj:`.str`) -- The location where the VEP data is stored.; - `data_mount` (:obj:`.str`) -- The location in the container where the data should be mounted.; - `batch_run_command` (:obj:`.list` of :obj:`.str`) -- The command line to run for a VEP job for a partition.; - `batch_run_csq_header_command` (:obj:`.list` of :obj:`.str`) -- The command line to run when generating the consequence header.; - `env` (dict of :obj:`.str` to :obj:`.str`) -- A map of environment variables to values to add to the environment when invoking the command.; - `cloud` (:obj:`.str`) -- The cloud where the Batch Service is located.; - `image` (:obj:`.str`) -- The docker image to run VEP.; - `data_bucket_is_requester_pays` (:obj:`.bool`) -- True if the data bu",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:26844,Deployability,configurat,configuration,26844,"1 on whether `csq` is False or True.; - `VEP_TOLERATE_PARSE_ERROR` - Integer equal to 0 or 1 on whether `tolerate_parse_error` is False or True.; - `VEP_OUTPUT_FILE` - String specifying the local path where the output TSV file with the VEP result should be located.; - `VEP_INPUT_FILE` - String specifying the local path where the input VCF shard is located for all jobs. The `VEP_INPUT_FILE` environment variable is not available for the single job that computes the consequence header when; ``csq=True``; """""". json_typ: hl.expr.HailType; data_bucket: str; data_mount: str; regions: List[str]; image: str; env: Dict[str, str]; data_bucket_is_requester_pays: bool; cloud: str; batch_run_command: List[str]; batch_run_csq_header_command: List[str]. @abc.abstractmethod; def command(; self, consequence: bool, tolerate_parse_error: bool, part_id: int, input_file: Optional[str], output_file: str; ) -> List[str]:; raise NotImplementedError. [docs]class VEPConfigGRCh37Version85(VEPConfig):; """"""; The Hail-maintained VEP configuration for GRCh37 for VEP version 85. This class takes the following constructor arguments:. - `data_bucket` (:obj:`.str`) -- The location where the VEP data is stored.; - `data_mount` (:obj:`.str`) -- The location in the container where the data should be mounted.; - `image` (:obj:`.str`) -- The docker image to run VEP.; - `cloud` (:obj:`.str`) -- The cloud where the Batch Service is located.; - `data_bucket_is_requester_pays` (:obj:`.bool`) -- True if the data bucket is requester pays.; - `regions` (:obj:`.list` of :obj:`.str`) -- A list of regions the VEP jobs can run in. """""". def __init__(; self,; *,; data_bucket: str,; data_mount: str,; image: str,; regions: List[str],; cloud: str,; data_bucket_is_requester_pays: bool,; ):; self.data_bucket = data_bucket; self.data_mount = data_mount; self.image = image; self.regions = regions; self.env = {}; self.data_bucket_is_requester_pays = data_bucket_is_requester_pays; self.cloud = cloud; self.batch_run_command = ['",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:28802,Deployability,configurat,configuration,28802,"cloud = cloud; self.batch_run_command = ['python3', '/hail-vep/vep.py', 'vep']; self.batch_run_csq_header_command = ['python3', '/hail-vep/vep.py', 'csq_header']; self.json_typ = vep_json_typ. def command(; self,; *,; consequence: bool,; tolerate_parse_error: bool,; part_id: int,; input_file: Optional[str],; output_file: str,; ) -> str:; vcf_or_json = '--vcf' if consequence else '--json'; input_file = f'--input_file {input_file}' if input_file else ''; return f""""""/vep/vep {input_file} \; --format vcf \; {vcf_or_json} \; --everything \; --allele_number \; --no_stats \; --cache \; --offline \; --minimal \; --assembly GRCh37 \; --dir={self.data_mount} \; --plugin LoF,human_ancestor_fa:{self.data_mount}/loftee_data/human_ancestor.fa.gz,filter_position:0.05,min_intron_size:15,conservation_file:{self.data_mount}/loftee_data/phylocsf_gerp.sql,gerp_file:{self.data_mount}/loftee_data/GERP_scores.final.sorted.txt.gz \; -o STDOUT; """""". [docs]class VEPConfigGRCh38Version95(VEPConfig):; """"""; The Hail-maintained VEP configuration for GRCh38 for VEP version 95. This class takes the following constructor arguments:. - `data_bucket` (:obj:`.str`) -- The location where the VEP data is stored.; - `data_mount` (:obj:`.str`) -- The location in the container where the data should be mounted.; - `image` (:obj:`.str`) -- The docker image to run VEP.; - `cloud` (:obj:`.str`) -- The cloud where the Batch Service is located.; - `data_bucket_is_requester_pays` (:obj:`.bool`) -- True if the data bucket is set to requester pays.; - `regions` (:obj:`.list` of :obj:`.str`) -- A list of regions the VEP jobs can run in. """""". def __init__(; self,; *,; data_bucket: str,; data_mount: str,; image: str,; regions: List[str],; cloud: str,; data_bucket_is_requester_pays: bool,; ):; self.data_bucket = data_bucket; self.data_mount = data_mount; self.image = image; self.regions = regions; self.env = {}; self.data_bucket_is_requester_pays = data_bucket_is_requester_pays; self.cloud = cloud; self.batch_run_comma",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:31890,Deployability,configurat,configuration,31890,"e {self.data_mount} \; -o STDOUT; """""". supported_vep_configs = {; ('GRCh37', 'gcp', 'us-central1', 'hail.is'): VEPConfigGRCh37Version85(; data_bucket='hail-qob-vep-grch37-us-central1',; data_mount='/vep_data/',; image=HAIL_GENETICS_VEP_GRCH37_85_IMAGE,; regions=['us-central1'],; cloud='gcp',; data_bucket_is_requester_pays=True,; ),; ('GRCh38', 'gcp', 'us-central1', 'hail.is'): VEPConfigGRCh38Version95(; data_bucket='hail-qob-vep-grch38-us-central1',; data_mount='/vep_data/',; image=HAIL_GENETICS_VEP_GRCH38_95_IMAGE,; regions=['us-central1'],; cloud='gcp',; data_bucket_is_requester_pays=True,; ),; }. def _supported_vep_config(cloud: str, reference_genome: str, *, regions: List[str]) -> VEPConfig:; domain = get_deploy_config()._domain. for region in regions:; config_params = (reference_genome, cloud, region, domain); if config_params in supported_vep_configs:; return supported_vep_configs[config_params]. raise ValueError(; f'could not find a supported vep configuration for reference genome {reference_genome}, '; f'cloud {cloud}, regions {regions}, and domain {domain}'; ). def _service_vep(; backend: ServiceBackend,; ht: Table,; config: Optional[VEPConfig],; block_size: int,; csq: bool,; tolerate_parse_error: bool,; temp_input_directory: str,; temp_output_directory: str,; ) -> Table:; reference_genome = ht.locus.dtype.reference_genome.name; cloud = async_to_blocking(backend._batch_client.cloud()); regions = backend.regions. if config is not None:; vep_config = config; else:; vep_config = _supported_vep_config(cloud, reference_genome, regions=regions). requester_pays_project = backend.flags.get('gcs_requester_pays_project'); if requester_pays_project is None and vep_config.data_bucket_is_requester_pays and vep_config.cloud == 'gcp':; raise ValueError(; ""No requester pays project has been set. ""; ""Use hl.init(gcs_requester_pays_configuration='MY_PROJECT') ""; ""to set the requester pays project to use.""; ). if csq:; vep_typ = hl.tarray(hl.tstr); else:; vep_typ = vep_config.",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:33515,Deployability,update,update,33515,"ckend.flags.get('gcs_requester_pays_project'); if requester_pays_project is None and vep_config.data_bucket_is_requester_pays and vep_config.cloud == 'gcp':; raise ValueError(; ""No requester pays project has been set. ""; ""Use hl.init(gcs_requester_pays_configuration='MY_PROJECT') ""; ""to set the requester pays project to use.""; ). if csq:; vep_typ = hl.tarray(hl.tstr); else:; vep_typ = vep_config.json_typ. def build_vep_batch(b: bc.aioclient.Batch, vep_input_path: str, vep_output_path: str):; if csq:; local_output_file = '/io/output'; vep_command = vep_config.command(; consequence=csq,; part_id=-1,; input_file=None,; output_file=local_output_file,; tolerate_parse_error=tolerate_parse_error,; ); env = {; 'VEP_BLOCK_SIZE': str(block_size),; 'VEP_DATA_MOUNT': shq(vep_config.data_mount),; 'VEP_CONSEQUENCE': str(int(csq)),; 'VEP_TOLERATE_PARSE_ERROR': str(int(tolerate_parse_error)),; 'VEP_PART_ID': str(-1),; 'VEP_OUTPUT_FILE': local_output_file,; 'VEP_COMMAND': vep_command,; }; env.update(vep_config.env); b.create_job(; vep_config.image,; vep_config.batch_run_csq_header_command,; attributes={'name': 'csq-header'},; resources={'cpu': '1', 'memory': 'standard'},; cloudfuse=[(vep_config.data_bucket, vep_config.data_mount, True)],; output_files=[(local_output_file, f'{vep_output_path}/csq-header')],; regions=vep_config.regions,; requester_pays_project=requester_pays_project,; env=env,; ). for f in hl.hadoop_ls(vep_input_path):; path = f['path']; part_name = os.path.basename(path); if not part_name.startswith('part-'):; continue; part_id = int(part_name.split('-')[1]). local_input_file = '/io/input'; local_output_file = '/io/output.gz'. vep_command = vep_config.command(; consequence=csq,; part_id=part_id,; input_file=local_input_file,; output_file=local_output_file,; tolerate_parse_error=tolerate_parse_error,; ). env = {; 'VEP_BLOCK_SIZE': str(block_size),; 'VEP_DATA_MOUNT': shq(vep_config.data_mount),; 'VEP_CONSEQUENCE': str(int(csq)),; 'VEP_TOLERATE_PARSE_ERROR': str(int(tol",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:34683,Deployability,update,update,34683,"d'},; cloudfuse=[(vep_config.data_bucket, vep_config.data_mount, True)],; output_files=[(local_output_file, f'{vep_output_path}/csq-header')],; regions=vep_config.regions,; requester_pays_project=requester_pays_project,; env=env,; ). for f in hl.hadoop_ls(vep_input_path):; path = f['path']; part_name = os.path.basename(path); if not part_name.startswith('part-'):; continue; part_id = int(part_name.split('-')[1]). local_input_file = '/io/input'; local_output_file = '/io/output.gz'. vep_command = vep_config.command(; consequence=csq,; part_id=part_id,; input_file=local_input_file,; output_file=local_output_file,; tolerate_parse_error=tolerate_parse_error,; ). env = {; 'VEP_BLOCK_SIZE': str(block_size),; 'VEP_DATA_MOUNT': shq(vep_config.data_mount),; 'VEP_CONSEQUENCE': str(int(csq)),; 'VEP_TOLERATE_PARSE_ERROR': str(int(tolerate_parse_error)),; 'VEP_PART_ID': str(-1),; 'VEP_INPUT_FILE': local_input_file,; 'VEP_OUTPUT_FILE': local_output_file,; 'VEP_COMMAND': vep_command,; }; env.update(vep_config.env). b.create_job(; vep_config.image,; vep_config.batch_run_command,; attributes={'name': f'vep-{part_id}'},; resources={'cpu': '1', 'memory': 'standard'},; input_files=[(path, local_input_file)],; output_files=[(local_output_file, f'{vep_output_path}/annotations/{part_name}.tsv.gz')],; cloudfuse=[(vep_config.data_bucket, vep_config.data_mount, True)],; regions=vep_config.regions,; requester_pays_project=requester_pays_project,; env=env,; ). hl.export_vcf(ht, temp_input_directory, parallel='header_per_shard'). starting_job_id = async_to_blocking(backend._batch.status())['n_jobs'] + 1. b = bc.client.Batch(backend._batch); build_vep_batch(b, temp_input_directory, temp_output_directory). b.submit(disable_progress_bar=True). try:; status = b.wait(; description='vep(...)',; disable_progress_bar=backend.disable_progress_bar,; progress=None,; starting_job=starting_job_id,; ); except BaseException as e:; if isinstance(e, KeyboardInterrupt):; print(""Received a keyboard interrupt, canc",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:37453,Deployability,configurat,configuration,37453,"tions.variant, reference_genome=reference_genome)); annotations = annotations.drop('variant'). if csq:; with hl.hadoop_open(f'{temp_output_directory}/csq-header') as f:; vep_csq_header = f.read().rstrip(); annotations = annotations.annotate_globals(vep_csq_header=vep_csq_header). return annotations. [docs]@typecheck(; dataset=oneof(Table, MatrixTable),; config=nullable(oneof(str, VEPConfig)),; block_size=int,; name=str,; csq=bool,; tolerate_parse_error=bool,; ); def vep(; dataset: Union[Table, MatrixTable],; config: Optional[Union[str, VEPConfig]] = None,; block_size: int = 1000,; name: str = 'vep',; csq: bool = False,; tolerate_parse_error: bool = False,; ):; """"""Annotate variants with VEP. .. include:: ../_templates/req_tvariant.rst. :func:`.vep` runs `Variant Effect Predictor; <http://www.ensembl.org/info/docs/tools/vep/index.html>`__ on the; current dataset and adds the result as a row field. Examples; --------. Add VEP annotations to the dataset:. >>> result = hl.vep(dataset, ""data/vep-configuration.json"") # doctest: +SKIP. Notes; -----. **Installation**. This VEP command only works if you have already installed VEP on your; computing environment. If you use `hailctl dataproc` to start Hail clusters,; installing VEP is achieved by specifying the `--vep` flag. For more detailed instructions,; see :ref:`vep_dataproc`. If you use `hailctl hdinsight`, see :ref:`vep_hdinsight`. **Spark Configuration**. :func:`.vep` needs a configuration file to tell it how to run VEP. This is the ``config`` argument; to the VEP function. If you are using `hailctl dataproc` as mentioned above, you can just use the; default argument for ``config`` and everything will work. If you need to run VEP with Hail in other environments,; there are detailed instructions below. The format of the configuration file is JSON, and :func:`.vep`; expects a JSON object with three fields:. - `command` (array of string) -- The VEP command line to run. The string literal `__OUTPUT_FORMAT_FLAG__` is replaced",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:37572,Deployability,install,installed,37572,"n(f'{temp_output_directory}/csq-header') as f:; vep_csq_header = f.read().rstrip(); annotations = annotations.annotate_globals(vep_csq_header=vep_csq_header). return annotations. [docs]@typecheck(; dataset=oneof(Table, MatrixTable),; config=nullable(oneof(str, VEPConfig)),; block_size=int,; name=str,; csq=bool,; tolerate_parse_error=bool,; ); def vep(; dataset: Union[Table, MatrixTable],; config: Optional[Union[str, VEPConfig]] = None,; block_size: int = 1000,; name: str = 'vep',; csq: bool = False,; tolerate_parse_error: bool = False,; ):; """"""Annotate variants with VEP. .. include:: ../_templates/req_tvariant.rst. :func:`.vep` runs `Variant Effect Predictor; <http://www.ensembl.org/info/docs/tools/vep/index.html>`__ on the; current dataset and adds the result as a row field. Examples; --------. Add VEP annotations to the dataset:. >>> result = hl.vep(dataset, ""data/vep-configuration.json"") # doctest: +SKIP. Notes; -----. **Installation**. This VEP command only works if you have already installed VEP on your; computing environment. If you use `hailctl dataproc` to start Hail clusters,; installing VEP is achieved by specifying the `--vep` flag. For more detailed instructions,; see :ref:`vep_dataproc`. If you use `hailctl hdinsight`, see :ref:`vep_hdinsight`. **Spark Configuration**. :func:`.vep` needs a configuration file to tell it how to run VEP. This is the ``config`` argument; to the VEP function. If you are using `hailctl dataproc` as mentioned above, you can just use the; default argument for ``config`` and everything will work. If you need to run VEP with Hail in other environments,; there are detailed instructions below. The format of the configuration file is JSON, and :func:`.vep`; expects a JSON object with three fields:. - `command` (array of string) -- The VEP command line to run. The string literal `__OUTPUT_FORMAT_FLAG__` is replaced with `--json` or `--vcf` depending on `csq`.; - `env` (object) -- A map of environment variables to values to add to the",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:37673,Deployability,install,installing,37673,"tions.annotate_globals(vep_csq_header=vep_csq_header). return annotations. [docs]@typecheck(; dataset=oneof(Table, MatrixTable),; config=nullable(oneof(str, VEPConfig)),; block_size=int,; name=str,; csq=bool,; tolerate_parse_error=bool,; ); def vep(; dataset: Union[Table, MatrixTable],; config: Optional[Union[str, VEPConfig]] = None,; block_size: int = 1000,; name: str = 'vep',; csq: bool = False,; tolerate_parse_error: bool = False,; ):; """"""Annotate variants with VEP. .. include:: ../_templates/req_tvariant.rst. :func:`.vep` runs `Variant Effect Predictor; <http://www.ensembl.org/info/docs/tools/vep/index.html>`__ on the; current dataset and adds the result as a row field. Examples; --------. Add VEP annotations to the dataset:. >>> result = hl.vep(dataset, ""data/vep-configuration.json"") # doctest: +SKIP. Notes; -----. **Installation**. This VEP command only works if you have already installed VEP on your; computing environment. If you use `hailctl dataproc` to start Hail clusters,; installing VEP is achieved by specifying the `--vep` flag. For more detailed instructions,; see :ref:`vep_dataproc`. If you use `hailctl hdinsight`, see :ref:`vep_hdinsight`. **Spark Configuration**. :func:`.vep` needs a configuration file to tell it how to run VEP. This is the ``config`` argument; to the VEP function. If you are using `hailctl dataproc` as mentioned above, you can just use the; default argument for ``config`` and everything will work. If you need to run VEP with Hail in other environments,; there are detailed instructions below. The format of the configuration file is JSON, and :func:`.vep`; expects a JSON object with three fields:. - `command` (array of string) -- The VEP command line to run. The string literal `__OUTPUT_FORMAT_FLAG__` is replaced with `--json` or `--vcf` depending on `csq`.; - `env` (object) -- A map of environment variables to values to add to the environment when invoking the command. The value of each object member must be a string.; - `vep_json_s",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:37894,Deployability,configurat,configuration,37894,"; ); def vep(; dataset: Union[Table, MatrixTable],; config: Optional[Union[str, VEPConfig]] = None,; block_size: int = 1000,; name: str = 'vep',; csq: bool = False,; tolerate_parse_error: bool = False,; ):; """"""Annotate variants with VEP. .. include:: ../_templates/req_tvariant.rst. :func:`.vep` runs `Variant Effect Predictor; <http://www.ensembl.org/info/docs/tools/vep/index.html>`__ on the; current dataset and adds the result as a row field. Examples; --------. Add VEP annotations to the dataset:. >>> result = hl.vep(dataset, ""data/vep-configuration.json"") # doctest: +SKIP. Notes; -----. **Installation**. This VEP command only works if you have already installed VEP on your; computing environment. If you use `hailctl dataproc` to start Hail clusters,; installing VEP is achieved by specifying the `--vep` flag. For more detailed instructions,; see :ref:`vep_dataproc`. If you use `hailctl hdinsight`, see :ref:`vep_hdinsight`. **Spark Configuration**. :func:`.vep` needs a configuration file to tell it how to run VEP. This is the ``config`` argument; to the VEP function. If you are using `hailctl dataproc` as mentioned above, you can just use the; default argument for ``config`` and everything will work. If you need to run VEP with Hail in other environments,; there are detailed instructions below. The format of the configuration file is JSON, and :func:`.vep`; expects a JSON object with three fields:. - `command` (array of string) -- The VEP command line to run. The string literal `__OUTPUT_FORMAT_FLAG__` is replaced with `--json` or `--vcf` depending on `csq`.; - `env` (object) -- A map of environment variables to values to add to the environment when invoking the command. The value of each object member must be a string.; - `vep_json_schema` (string): The type of the VEP JSON schema (as produced by the VEP when invoked with the `--json` option). Note: This is the old-style 'parseable' Hail type syntax. This will change. Here is an example configuration file for invok",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:38244,Deployability,configurat,configuration,38244,"mbl.org/info/docs/tools/vep/index.html>`__ on the; current dataset and adds the result as a row field. Examples; --------. Add VEP annotations to the dataset:. >>> result = hl.vep(dataset, ""data/vep-configuration.json"") # doctest: +SKIP. Notes; -----. **Installation**. This VEP command only works if you have already installed VEP on your; computing environment. If you use `hailctl dataproc` to start Hail clusters,; installing VEP is achieved by specifying the `--vep` flag. For more detailed instructions,; see :ref:`vep_dataproc`. If you use `hailctl hdinsight`, see :ref:`vep_hdinsight`. **Spark Configuration**. :func:`.vep` needs a configuration file to tell it how to run VEP. This is the ``config`` argument; to the VEP function. If you are using `hailctl dataproc` as mentioned above, you can just use the; default argument for ``config`` and everything will work. If you need to run VEP with Hail in other environments,; there are detailed instructions below. The format of the configuration file is JSON, and :func:`.vep`; expects a JSON object with three fields:. - `command` (array of string) -- The VEP command line to run. The string literal `__OUTPUT_FORMAT_FLAG__` is replaced with `--json` or `--vcf` depending on `csq`.; - `env` (object) -- A map of environment variables to values to add to the environment when invoking the command. The value of each object member must be a string.; - `vep_json_schema` (string): The type of the VEP JSON schema (as produced by the VEP when invoked with the `--json` option). Note: This is the old-style 'parseable' Hail type syntax. This will change. Here is an example configuration file for invoking VEP release 85; installed in `/vep` with the Loftee plugin:. .. code-block:: text. {; ""command"": [; ""/vep"",; ""--format"", ""vcf"",; ""__OUTPUT_FORMAT_FLAG__"",; ""--everything"",; ""--allele_number"",; ""--no_stats"",; ""--cache"", ""--offline"",; ""--minimal"",; ""--assembly"", ""GRCh37"",; ""--plugin"", ""LoF,human_ancestor_fa:/root/.vep/loftee_data/human_ances",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:38882,Deployability,configurat,configuration,38882,"ll it how to run VEP. This is the ``config`` argument; to the VEP function. If you are using `hailctl dataproc` as mentioned above, you can just use the; default argument for ``config`` and everything will work. If you need to run VEP with Hail in other environments,; there are detailed instructions below. The format of the configuration file is JSON, and :func:`.vep`; expects a JSON object with three fields:. - `command` (array of string) -- The VEP command line to run. The string literal `__OUTPUT_FORMAT_FLAG__` is replaced with `--json` or `--vcf` depending on `csq`.; - `env` (object) -- A map of environment variables to values to add to the environment when invoking the command. The value of each object member must be a string.; - `vep_json_schema` (string): The type of the VEP JSON schema (as produced by the VEP when invoked with the `--json` option). Note: This is the old-style 'parseable' Hail type syntax. This will change. Here is an example configuration file for invoking VEP release 85; installed in `/vep` with the Loftee plugin:. .. code-block:: text. {; ""command"": [; ""/vep"",; ""--format"", ""vcf"",; ""__OUTPUT_FORMAT_FLAG__"",; ""--everything"",; ""--allele_number"",; ""--no_stats"",; ""--cache"", ""--offline"",; ""--minimal"",; ""--assembly"", ""GRCh37"",; ""--plugin"", ""LoF,human_ancestor_fa:/root/.vep/loftee_data/human_ancestor.fa.gz,filter_position:0.05,min_intron_size:15,conservation_file:/root/.vep/loftee_data/phylocsf_gerp.sql,gerp_file:/root/.vep/loftee_data/GERP_scores.final.sorted.txt.gz"",; ""-o"", ""STDOUT""; ],; ""env"": {; ""PERL5LIB"": ""/vep_data/loftee""; },; ""vep_json_schema"": ""Struct{assembly_name:String,allele_string:String,ancestral:String,colocated_variants:Array[Struct{aa_allele:String,aa_maf:Float64,afr_allele:String,afr_maf:Float64,allele_string:String,amr_allele:String,amr_maf:Float64,clin_sig:Array[String],end:Int32,eas_allele:String,eas_maf:Float64,ea_allele:String,ea_maf:Float64,eur_allele:String,eur_maf:Float64,exac_adj_allele:String,exac_adj_maf:Float64,exac",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:38918,Deployability,release,release,38918,"ll it how to run VEP. This is the ``config`` argument; to the VEP function. If you are using `hailctl dataproc` as mentioned above, you can just use the; default argument for ``config`` and everything will work. If you need to run VEP with Hail in other environments,; there are detailed instructions below. The format of the configuration file is JSON, and :func:`.vep`; expects a JSON object with three fields:. - `command` (array of string) -- The VEP command line to run. The string literal `__OUTPUT_FORMAT_FLAG__` is replaced with `--json` or `--vcf` depending on `csq`.; - `env` (object) -- A map of environment variables to values to add to the environment when invoking the command. The value of each object member must be a string.; - `vep_json_schema` (string): The type of the VEP JSON schema (as produced by the VEP when invoked with the `--json` option). Note: This is the old-style 'parseable' Hail type syntax. This will change. Here is an example configuration file for invoking VEP release 85; installed in `/vep` with the Loftee plugin:. .. code-block:: text. {; ""command"": [; ""/vep"",; ""--format"", ""vcf"",; ""__OUTPUT_FORMAT_FLAG__"",; ""--everything"",; ""--allele_number"",; ""--no_stats"",; ""--cache"", ""--offline"",; ""--minimal"",; ""--assembly"", ""GRCh37"",; ""--plugin"", ""LoF,human_ancestor_fa:/root/.vep/loftee_data/human_ancestor.fa.gz,filter_position:0.05,min_intron_size:15,conservation_file:/root/.vep/loftee_data/phylocsf_gerp.sql,gerp_file:/root/.vep/loftee_data/GERP_scores.final.sorted.txt.gz"",; ""-o"", ""STDOUT""; ],; ""env"": {; ""PERL5LIB"": ""/vep_data/loftee""; },; ""vep_json_schema"": ""Struct{assembly_name:String,allele_string:String,ancestral:String,colocated_variants:Array[Struct{aa_allele:String,aa_maf:Float64,afr_allele:String,afr_maf:Float64,allele_string:String,amr_allele:String,amr_maf:Float64,clin_sig:Array[String],end:Int32,eas_allele:String,eas_maf:Float64,ea_allele:String,ea_maf:Float64,eur_allele:String,eur_maf:Float64,exac_adj_allele:String,exac_adj_maf:Float64,exac",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:38930,Deployability,install,installed,38930,"ll it how to run VEP. This is the ``config`` argument; to the VEP function. If you are using `hailctl dataproc` as mentioned above, you can just use the; default argument for ``config`` and everything will work. If you need to run VEP with Hail in other environments,; there are detailed instructions below. The format of the configuration file is JSON, and :func:`.vep`; expects a JSON object with three fields:. - `command` (array of string) -- The VEP command line to run. The string literal `__OUTPUT_FORMAT_FLAG__` is replaced with `--json` or `--vcf` depending on `csq`.; - `env` (object) -- A map of environment variables to values to add to the environment when invoking the command. The value of each object member must be a string.; - `vep_json_schema` (string): The type of the VEP JSON schema (as produced by the VEP when invoked with the `--json` option). Note: This is the old-style 'parseable' Hail type syntax. This will change. Here is an example configuration file for invoking VEP release 85; installed in `/vep` with the Loftee plugin:. .. code-block:: text. {; ""command"": [; ""/vep"",; ""--format"", ""vcf"",; ""__OUTPUT_FORMAT_FLAG__"",; ""--everything"",; ""--allele_number"",; ""--no_stats"",; ""--cache"", ""--offline"",; ""--minimal"",; ""--assembly"", ""GRCh37"",; ""--plugin"", ""LoF,human_ancestor_fa:/root/.vep/loftee_data/human_ancestor.fa.gz,filter_position:0.05,min_intron_size:15,conservation_file:/root/.vep/loftee_data/phylocsf_gerp.sql,gerp_file:/root/.vep/loftee_data/GERP_scores.final.sorted.txt.gz"",; ""-o"", ""STDOUT""; ],; ""env"": {; ""PERL5LIB"": ""/vep_data/loftee""; },; ""vep_json_schema"": ""Struct{assembly_name:String,allele_string:String,ancestral:String,colocated_variants:Array[Struct{aa_allele:String,aa_maf:Float64,afr_allele:String,afr_maf:Float64,allele_string:String,amr_allele:String,amr_maf:Float64,clin_sig:Array[String],end:Int32,eas_allele:String,eas_maf:Float64,ea_allele:String,ea_maf:Float64,eur_allele:String,eur_maf:Float64,exac_adj_allele:String,exac_adj_maf:Float64,exac",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:41977,Deployability,configurat,configuration,41977,"ring],impact:String,minimised:Int32,regulatory_feature_id:String,variant_allele:String}],seq_region_name:String,start:Int32,strand:Int32,transcript_consequences:Array[Struct{allele_num:Int32,amino_acids:String,biotype:String,canonical:Int32,ccds:String,cdna_start:Int32,cdna_end:Int32,cds_end:Int32,cds_start:Int32,codons:String,consequence_terms:Array[String],distance:Int32,domains:Array[Struct{db:String,name:String}],exon:String,gene_id:String,gene_pheno:Int32,gene_symbol:String,gene_symbol_source:String,hgnc_id:String,hgvsc:String,hgvsp:String,hgvs_offset:Int32,impact:String,intron:String,lof:String,lof_flags:String,lof_filter:String,lof_info:String,minimised:Int32,polyphen_prediction:String,polyphen_score:Float64,protein_end:Int32,protein_start:Int32,protein_id:String,sift_prediction:String,sift_score:Float64,strand:Int32,swissprot:String,transcript_id:String,trembl:String,uniparc:String,variant_allele:String}],variant_class:String}""; }. The configuration files used by``hailctl dataproc`` can be found at the following locations:. - ``GRCh37``: ``gs://hail-us-central1-vep/vep85-loftee-gcloud.json``; - ``GRCh38``: ``gs://hail-us-central1-vep/vep95-GRCh38-loftee-gcloud.json``. If no config file is specified, this function will check to see if environment variable `VEP_CONFIG_URI` is set with a path to a config file. **Batch Service Configuration**. If no config is specified, Hail will use the user's Service configuration parameters to find a supported VEP configuration.; However, if you wish to use your own implementation of VEP, then see the documentation for :class:`.VEPConfig`. **Annotations**. A new row field is added in the location specified by `name` with type given; by the type given by the `json_vep_schema` (if `csq` is ``False``) or; :class:`.tarray` of :py:data:`.tstr` (if `csq` is ``True``). If csq is ``True``, then the CSQ header string is also added as a global; field with name ``name + '_csq_header'``. Parameters; ----------; dataset : :class:`.MatrixT",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:42449,Deployability,configurat,configuration,42449,"g,gene_id:String,gene_pheno:Int32,gene_symbol:String,gene_symbol_source:String,hgnc_id:String,hgvsc:String,hgvsp:String,hgvs_offset:Int32,impact:String,intron:String,lof:String,lof_flags:String,lof_filter:String,lof_info:String,minimised:Int32,polyphen_prediction:String,polyphen_score:Float64,protein_end:Int32,protein_start:Int32,protein_id:String,sift_prediction:String,sift_score:Float64,strand:Int32,swissprot:String,transcript_id:String,trembl:String,uniparc:String,variant_allele:String}],variant_class:String}""; }. The configuration files used by``hailctl dataproc`` can be found at the following locations:. - ``GRCh37``: ``gs://hail-us-central1-vep/vep85-loftee-gcloud.json``; - ``GRCh38``: ``gs://hail-us-central1-vep/vep95-GRCh38-loftee-gcloud.json``. If no config file is specified, this function will check to see if environment variable `VEP_CONFIG_URI` is set with a path to a config file. **Batch Service Configuration**. If no config is specified, Hail will use the user's Service configuration parameters to find a supported VEP configuration.; However, if you wish to use your own implementation of VEP, then see the documentation for :class:`.VEPConfig`. **Annotations**. A new row field is added in the location specified by `name` with type given; by the type given by the `json_vep_schema` (if `csq` is ``False``) or; :class:`.tarray` of :py:data:`.tstr` (if `csq` is ``True``). If csq is ``True``, then the CSQ header string is also added as a global; field with name ``name + '_csq_header'``. Parameters; ----------; dataset : :class:`.MatrixTable` or :class:`.Table`; Dataset.; config : :class:`str` or :class:`.VEPConfig`, optional; Path to VEP configuration file or a VEPConfig object.; block_size : :obj:`int`; Number of rows to process per VEP invocation.; name : :class:`str`; Name for resulting row field.; csq : :obj:`bool`; If ``True``, annotates with the VCF CSQ field as a :py:data:`.tstr`.; If ``False``, annotates as the `vep_json_schema`.; tolerate_parse_error",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:42498,Deployability,configurat,configuration,42498,"g,gene_id:String,gene_pheno:Int32,gene_symbol:String,gene_symbol_source:String,hgnc_id:String,hgvsc:String,hgvsp:String,hgvs_offset:Int32,impact:String,intron:String,lof:String,lof_flags:String,lof_filter:String,lof_info:String,minimised:Int32,polyphen_prediction:String,polyphen_score:Float64,protein_end:Int32,protein_start:Int32,protein_id:String,sift_prediction:String,sift_score:Float64,strand:Int32,swissprot:String,transcript_id:String,trembl:String,uniparc:String,variant_allele:String}],variant_class:String}""; }. The configuration files used by``hailctl dataproc`` can be found at the following locations:. - ``GRCh37``: ``gs://hail-us-central1-vep/vep85-loftee-gcloud.json``; - ``GRCh38``: ``gs://hail-us-central1-vep/vep95-GRCh38-loftee-gcloud.json``. If no config file is specified, this function will check to see if environment variable `VEP_CONFIG_URI` is set with a path to a config file. **Batch Service Configuration**. If no config is specified, Hail will use the user's Service configuration parameters to find a supported VEP configuration.; However, if you wish to use your own implementation of VEP, then see the documentation for :class:`.VEPConfig`. **Annotations**. A new row field is added in the location specified by `name` with type given; by the type given by the `json_vep_schema` (if `csq` is ``False``) or; :class:`.tarray` of :py:data:`.tstr` (if `csq` is ``True``). If csq is ``True``, then the CSQ header string is also added as a global; field with name ``name + '_csq_header'``. Parameters; ----------; dataset : :class:`.MatrixTable` or :class:`.Table`; Dataset.; config : :class:`str` or :class:`.VEPConfig`, optional; Path to VEP configuration file or a VEPConfig object.; block_size : :obj:`int`; Number of rows to process per VEP invocation.; name : :class:`str`; Name for resulting row field.; csq : :obj:`bool`; If ``True``, annotates with the VCF CSQ field as a :py:data:`.tstr`.; If ``False``, annotates as the `vep_json_schema`.; tolerate_parse_error",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:43123,Deployability,configurat,configuration,43123,"ud.json``; - ``GRCh38``: ``gs://hail-us-central1-vep/vep95-GRCh38-loftee-gcloud.json``. If no config file is specified, this function will check to see if environment variable `VEP_CONFIG_URI` is set with a path to a config file. **Batch Service Configuration**. If no config is specified, Hail will use the user's Service configuration parameters to find a supported VEP configuration.; However, if you wish to use your own implementation of VEP, then see the documentation for :class:`.VEPConfig`. **Annotations**. A new row field is added in the location specified by `name` with type given; by the type given by the `json_vep_schema` (if `csq` is ``False``) or; :class:`.tarray` of :py:data:`.tstr` (if `csq` is ``True``). If csq is ``True``, then the CSQ header string is also added as a global; field with name ``name + '_csq_header'``. Parameters; ----------; dataset : :class:`.MatrixTable` or :class:`.Table`; Dataset.; config : :class:`str` or :class:`.VEPConfig`, optional; Path to VEP configuration file or a VEPConfig object.; block_size : :obj:`int`; Number of rows to process per VEP invocation.; name : :class:`str`; Name for resulting row field.; csq : :obj:`bool`; If ``True``, annotates with the VCF CSQ field as a :py:data:`.tstr`.; If ``False``, annotates as the `vep_json_schema`.; tolerate_parse_error : :obj:`bool`; If ``True``, ignore invalid JSON produced by VEP and return a missing annotation. Returns; -------; :class:`.MatrixTable` or :class:`.Table`; Dataset with new row-indexed field `name` containing VEP annotations. """""". if isinstance(dataset, MatrixTable):; require_row_key_variant(dataset, 'vep'); ht = dataset.select_rows().rows(); else:; require_table_key_variant(dataset, 'vep'); ht = dataset.select(). ht = ht.distinct(). backend = hl.current_backend(); if isinstance(backend, ServiceBackend):; with hl.TemporaryDirectory(prefix='qob/vep/inputs/') as vep_input_path:; with hl.TemporaryDirectory(prefix='qob/vep/outputs/') as vep_output_path:; annotations = _s",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:46039,Deployability,configurat,configuration,46039,"bals()['vep_csq_header']}). if isinstance(dataset, MatrixTable):; vep = annotations[dataset.row_key]; return dataset.annotate_rows(**{name: vep.vep, name + '_proc_id': vep.vep_proc_id}); else:; vep = annotations[dataset.key]; return dataset.annotate(**{name: vep.vep, name + '_proc_id': vep.vep_proc_id}). [docs]@typecheck(dataset=oneof(Table, MatrixTable), config=str, block_size=int, name=str); def nirvana(dataset: Union[MatrixTable, Table], config, block_size=500000, name='nirvana'):; """"""Annotate variants using `Nirvana <https://github.com/Illumina/Nirvana>`_. .. include:: ../_templates/experimental.rst. .. include:: ../_templates/req_tvariant.rst. :func:`.nirvana` runs `Nirvana; <https://github.com/Illumina/Nirvana>`_ on the current dataset and adds a; new row field in the location specified by `name`. Examples; --------. Add Nirvana annotations to the dataset:. >>> result = hl.nirvana(dataset, ""data/nirvana.properties"") # doctest: +SKIP. **Configuration**. :func:`.nirvana` requires a configuration file. The format is a; `.properties file <https://en.wikipedia.org/wiki/.properties>`__, where each; line defines a property as a key-value pair of the form ``key = value``.; :func:`.nirvana` supports the following properties:. - **hail.nirvana.dotnet** -- Location of dotnet. Optional, default: dotnet.; - **hail.nirvana.path** -- Value of the PATH environment variable when; invoking Nirvana. Optional, by default PATH is not set.; - **hail.nirvana.location** -- Location of Nirvana.dll. Required.; - **hail.nirvana.reference** -- Location of reference genome. Required.; - **hail.nirvana.cache** -- Location of cache. Required.; - **hail.nirvana.supplementaryAnnotationDirectory** -- Location of; Supplementary Database. Optional, no supplementary database by default. Here is an example ``nirvana.properties`` configuration file:. .. code-block:: text. hail.nirvana.location = /path/to/dotnet/netcoreapp2.0/Nirvana.dll; hail.nirvana.reference = /path/to/nirvana/References/Homo_sapi",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:46867,Deployability,configurat,configuration,46867,"-. Add Nirvana annotations to the dataset:. >>> result = hl.nirvana(dataset, ""data/nirvana.properties"") # doctest: +SKIP. **Configuration**. :func:`.nirvana` requires a configuration file. The format is a; `.properties file <https://en.wikipedia.org/wiki/.properties>`__, where each; line defines a property as a key-value pair of the form ``key = value``.; :func:`.nirvana` supports the following properties:. - **hail.nirvana.dotnet** -- Location of dotnet. Optional, default: dotnet.; - **hail.nirvana.path** -- Value of the PATH environment variable when; invoking Nirvana. Optional, by default PATH is not set.; - **hail.nirvana.location** -- Location of Nirvana.dll. Required.; - **hail.nirvana.reference** -- Location of reference genome. Required.; - **hail.nirvana.cache** -- Location of cache. Required.; - **hail.nirvana.supplementaryAnnotationDirectory** -- Location of; Supplementary Database. Optional, no supplementary database by default. Here is an example ``nirvana.properties`` configuration file:. .. code-block:: text. hail.nirvana.location = /path/to/dotnet/netcoreapp2.0/Nirvana.dll; hail.nirvana.reference = /path/to/nirvana/References/Homo_sapiens.GRCh37.Nirvana.dat; hail.nirvana.cache = /path/to/nirvana/Cache/GRCh37/Ensembl; hail.nirvana.supplementaryAnnotationDirectory = /path/to/nirvana/SupplementaryDatabase/GRCh37. **Annotations**. A new row field is added in the location specified by `name` with the; following schema:. .. code-block:: text. struct {; chromosome: str,; refAllele: str,; position: int32,; altAlleles: array<str>,; cytogeneticBand: str,; quality: float64,; filters: array<str>,; jointSomaticNormalQuality: int32,; copyNumber: int32,; strandBias: float64,; recalibratedQuality: float64,; variants: array<struct {; altAllele: str,; refAllele: str,; chromosome: str,; begin: int32,; end: int32,; phylopScore: float64,; isReferenceMinor: bool,; variantType: str,; vid: str,; hgvsg: str,; isRecomposedVariant: bool,; isDecomposedVariant: bool,; regulatoryR",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:51732,Deployability,configurat,configuration,51732,"sp: str,; isCanonical: bool,; polyPhenScore: float64,; polyPhenPrediction: str,; proteinId: str,; proteinPos: str,; siftScore: float64,; siftPrediction: str; }>,; ensembl: array<struct {; transcript: str,; bioType: str,; aminoAcids: str,; cdnaPos: str,; codons: str,; cdsPos: str,; exons: str,; introns: str,; geneId: str,; hgnc: str,; consequence: array<str>,; hgvsc: str,; hgvsp: str,; isCanonical: bool,; polyPhenScore: float64,; polyPhenPrediction: str,; proteinId: str,; proteinPos: str,; siftScore: float64,; siftPrediction: str; }>; },; overlappingGenes: array<str>; }>; genes: array<struct {; name: str,; omim: array<struct {; mimNumber: int32,; hgnc: str,; description: str,; phenotypes: array<struct {; mimNumber: int32,; phenotype: str,; mapping: str,; inheritance: array<str>,; comments: str; }>; }>; exac: struct {; pLi: float64,; pRec: float64,; pNull: float64; }; }>; }. Parameters; ----------; dataset : :class:`.MatrixTable` or :class:`.Table`; Dataset.; config : :class:`str`; Path to Nirvana configuration file.; block_size : :obj:`int`; Number of rows to process per Nirvana invocation.; name : :class:`str`; Name for resulting row field. Returns; -------; :class:`.MatrixTable` or :class:`.Table`; Dataset with new row-indexed field `name` containing Nirvana annotations.; """"""; if isinstance(dataset, MatrixTable):; require_row_key_variant(dataset, 'nirvana'); ht = dataset.select_rows().rows(); else:; require_table_key_variant(dataset, 'nirvana'); ht = dataset.select(). annotations = Table(; TableToTableApply(ht._tir, {'name': 'Nirvana', 'config': config, 'blockSize': block_size}); ).persist(). if isinstance(dataset, MatrixTable):; return dataset.annotate_rows(**{name: annotations[dataset.row_key].nirvana}); else:; return dataset.annotate(**{name: annotations[dataset.key].nirvana}). class _VariantSummary(object):; def __init__(self, rg, n_variants, alleles_per_variant, variants_per_contig, allele_types, nti, ntv):; self.rg = rg; self.n_variants = n_variants; self.all",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:63354,Deployability,update,updated,63354," ['LA', 'LAD', 'LGT', 'GQ']):; ad_field = 'LAD'; gt_field = 'LGT'; elif all(x in mt.entry for x in ['AD', 'GT', 'GQ']):; ad_field = 'AD'; gt_field = 'GT'; else:; raise ValueError(; f""'compute_charr': require a VDS or MatrixTable with fields LAD/LAD/LGT/GQ/DP or AD/GT/GQ/DP,""; f"" found entry fields {list(mt.entry)}""; ); # Annotate reference allele frequency when it is not defined in the original data, and name it 'ref_AF'.; ref_af_field = '__ref_af'; if ref_AF is None:; n_samples = mt.count_cols(); if n_samples < 10000:; raise ValueError(; ""'compute_charr': with fewer than 10,000 samples, require a reference AF in 'reference_data_source'.""; ). n_alleles = 2 * n_samples; mt = mt.annotate_rows(**{ref_af_field: 1 - hl.agg.sum(mt[gt_field].n_alt_alleles()) / n_alleles}); else:; mt = mt.annotate_rows(**{ref_af_field: ref_AF}). # Filter to autosomal biallelic SNVs with reference allele frequency within the range (min_af, max_af); rg = mt.locus.dtype.reference_genome.name; if rg == 'GRCh37':; mt = hl.filter_intervals(mt, [hl.parse_locus_interval('1-22', reference_genome=rg)]); elif rg == 'GRCh38':; mt = hl.filter_intervals(mt, [hl.parse_locus_interval('chr1-chr22', reference_genome=rg)]); else:; mt = mt.filter_rows(mt.locus.in_autosome()). mt = mt.filter_rows(; (hl.len(mt.alleles) == 2); & hl.is_snp(mt.alleles[0], mt.alleles[1]); & (mt[ref_af_field] > min_af); & (mt[ref_af_field] < max_af); ). # Filter to variant calls with GQ above min_gq and DP within the range (min_dp, max_dp); ad_dp = mt['DP'] if 'DP' in mt.entry else hl.sum(mt[ad_field]); mt = mt.filter_entries(mt[gt_field].is_hom_var() & (mt.GQ >= min_gq) & (ad_dp >= min_dp) & (ad_dp <= max_dp)). # Compute CHARR; mt = mt.select_cols(charr=hl.agg.mean((mt[ad_field][0] / (mt[ad_field][0] + mt[ad_field][1])) / mt[ref_af_field])). mt = mt.select_globals(; af_min=min_af,; af_max=max_af,; dp_min=min_dp,; dp_max=max_dp,; gq_min=min_gq,; ). return mt.cols(). © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:35898,Integrability,message,message,35898,"=[(local_output_file, f'{vep_output_path}/annotations/{part_name}.tsv.gz')],; cloudfuse=[(vep_config.data_bucket, vep_config.data_mount, True)],; regions=vep_config.regions,; requester_pays_project=requester_pays_project,; env=env,; ). hl.export_vcf(ht, temp_input_directory, parallel='header_per_shard'). starting_job_id = async_to_blocking(backend._batch.status())['n_jobs'] + 1. b = bc.client.Batch(backend._batch); build_vep_batch(b, temp_input_directory, temp_output_directory). b.submit(disable_progress_bar=True). try:; status = b.wait(; description='vep(...)',; disable_progress_bar=backend.disable_progress_bar,; progress=None,; starting_job=starting_job_id,; ); except BaseException as e:; if isinstance(e, KeyboardInterrupt):; print(""Received a keyboard interrupt, cancelling the batch...""); b.cancel(); backend._batch = None; raise. if status['n_succeeded'] != status['n_jobs']:; failing_job = next(iter(b.jobs('!success'))); failing_job = b.get_job(failing_job['job_id']); message = {'batch_status': status, 'job_status': failing_job.status(), 'log': failing_job.log()}; raise FatalError(yamlx.dump(message)). annotations = hl.import_table(; f'{temp_output_directory}/annotations/*',; types={'variant': hl.tstr, 'vep': vep_typ, 'part_id': hl.tint, 'block_id': hl.tint},; force=True,; ). annotations = annotations.annotate(; vep_proc_id=hl.struct(part_id=annotations.part_id, block_id=annotations.block_id); ); annotations = annotations.drop('part_id', 'block_id'); annotations = annotations.key_by(**hl.parse_variant(annotations.variant, reference_genome=reference_genome)); annotations = annotations.drop('variant'). if csq:; with hl.hadoop_open(f'{temp_output_directory}/csq-header') as f:; vep_csq_header = f.read().rstrip(); annotations = annotations.annotate_globals(vep_csq_header=vep_csq_header). return annotations. [docs]@typecheck(; dataset=oneof(Table, MatrixTable),; config=nullable(oneof(str, VEPConfig)),; block_size=int,; name=str,; csq=bool,; tolerate_parse_error=bool,; )",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:36024,Integrability,message,message,36024,"vep_config.data_mount, True)],; regions=vep_config.regions,; requester_pays_project=requester_pays_project,; env=env,; ). hl.export_vcf(ht, temp_input_directory, parallel='header_per_shard'). starting_job_id = async_to_blocking(backend._batch.status())['n_jobs'] + 1. b = bc.client.Batch(backend._batch); build_vep_batch(b, temp_input_directory, temp_output_directory). b.submit(disable_progress_bar=True). try:; status = b.wait(; description='vep(...)',; disable_progress_bar=backend.disable_progress_bar,; progress=None,; starting_job=starting_job_id,; ); except BaseException as e:; if isinstance(e, KeyboardInterrupt):; print(""Received a keyboard interrupt, cancelling the batch...""); b.cancel(); backend._batch = None; raise. if status['n_succeeded'] != status['n_jobs']:; failing_job = next(iter(b.jobs('!success'))); failing_job = b.get_job(failing_job['job_id']); message = {'batch_status': status, 'job_status': failing_job.status(), 'log': failing_job.log()}; raise FatalError(yamlx.dump(message)). annotations = hl.import_table(; f'{temp_output_directory}/annotations/*',; types={'variant': hl.tstr, 'vep': vep_typ, 'part_id': hl.tint, 'block_id': hl.tint},; force=True,; ). annotations = annotations.annotate(; vep_proc_id=hl.struct(part_id=annotations.part_id, block_id=annotations.block_id); ); annotations = annotations.drop('part_id', 'block_id'); annotations = annotations.key_by(**hl.parse_variant(annotations.variant, reference_genome=reference_genome)); annotations = annotations.drop('variant'). if csq:; with hl.hadoop_open(f'{temp_output_directory}/csq-header') as f:; vep_csq_header = f.read().rstrip(); annotations = annotations.annotate_globals(vep_csq_header=vep_csq_header). return annotations. [docs]@typecheck(; dataset=oneof(Table, MatrixTable),; config=nullable(oneof(str, VEPConfig)),; block_size=int,; name=str,; csq=bool,; tolerate_parse_error=bool,; ); def vep(; dataset: Union[Table, MatrixTable],; config: Optional[Union[str, VEPConfig]] = None,; block_size: int ",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:38475,Integrability,depend,depending,38475,"""data/vep-configuration.json"") # doctest: +SKIP. Notes; -----. **Installation**. This VEP command only works if you have already installed VEP on your; computing environment. If you use `hailctl dataproc` to start Hail clusters,; installing VEP is achieved by specifying the `--vep` flag. For more detailed instructions,; see :ref:`vep_dataproc`. If you use `hailctl hdinsight`, see :ref:`vep_hdinsight`. **Spark Configuration**. :func:`.vep` needs a configuration file to tell it how to run VEP. This is the ``config`` argument; to the VEP function. If you are using `hailctl dataproc` as mentioned above, you can just use the; default argument for ``config`` and everything will work. If you need to run VEP with Hail in other environments,; there are detailed instructions below. The format of the configuration file is JSON, and :func:`.vep`; expects a JSON object with three fields:. - `command` (array of string) -- The VEP command line to run. The string literal `__OUTPUT_FORMAT_FLAG__` is replaced with `--json` or `--vcf` depending on `csq`.; - `env` (object) -- A map of environment variables to values to add to the environment when invoking the command. The value of each object member must be a string.; - `vep_json_schema` (string): The type of the VEP JSON schema (as produced by the VEP when invoked with the `--json` option). Note: This is the old-style 'parseable' Hail type syntax. This will change. Here is an example configuration file for invoking VEP release 85; installed in `/vep` with the Loftee plugin:. .. code-block:: text. {; ""command"": [; ""/vep"",; ""--format"", ""vcf"",; ""__OUTPUT_FORMAT_FLAG__"",; ""--everything"",; ""--allele_number"",; ""--no_stats"",; ""--cache"", ""--offline"",; ""--minimal"",; ""--assembly"", ""GRCh37"",; ""--plugin"", ""LoF,human_ancestor_fa:/root/.vep/loftee_data/human_ancestor.fa.gz,filter_position:0.05,min_intron_size:15,conservation_file:/root/.vep/loftee_data/phylocsf_gerp.sql,gerp_file:/root/.vep/loftee_data/GERP_scores.final.sorted.txt.gz"",; ""-o"", ""STDOU",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:1428,Modifiability,config,config,1428,"e for hail.methods.qc; import abc; import logging; import os; from collections import Counter; from shlex import quote as shq; from typing import Dict, List, Optional, Tuple, Union. import hail as hl; import hailtop.batch_client as bc; from hail.backend.service_backend import ServiceBackend; from hail.expr import Float64Expression; from hail.expr.expressions.expression_typecheck import expr_float64; from hail.expr.functions import numeric_allele_type; from hail.expr.types import tarray, tfloat, tint32, tstr, tstruct; from hail.genetics.allele_type import AlleleType; from hail.ir import TableToTableApply; from hail.matrixtable import MatrixTable; from hail.table import Table; from hail.typecheck import anytype, nullable, numeric, oneof, typecheck; from hail.utils import FatalError; from hail.utils.java import Env, info, warning; from hail.utils.misc import divide_null, guess_cloud_spark_provider, new_temp_file; from hailtop import pip_version, yamlx; from hailtop.config import get_deploy_config; from hailtop.utils import async_to_blocking. from .misc import (; require_alleles_field,; require_biallelic,; require_col_key_str,; require_row_key_variant,; require_table_key_variant,; ). log = logging.getLogger('methods.qc'). HAIL_GENETICS_VEP_GRCH37_85_IMAGE = os.environ.get(; 'HAIL_GENETICS_VEP_GRCH37_85_IMAGE', f'hailgenetics/vep-grch37-85:{pip_version()}'; ); HAIL_GENETICS_VEP_GRCH38_95_IMAGE = os.environ.get(; 'HAIL_GENETICS_VEP_GRCH38_95_IMAGE', f'hailgenetics/vep-grch38-95:{pip_version()}'; ). def _qc_allele_type(ref, alt):; return hl.bind(; lambda at: hl.if_else(; at == AlleleType.SNP,; hl.if_else(hl.is_transition(ref, alt), AlleleType.TRANSITION, AlleleType.TRANSVERSION),; at,; ),; numeric_allele_type(ref, alt),; ). [docs]@typecheck(mt=MatrixTable, name=str); def sample_qc(mt, name='sample_qc') -> MatrixTable:; """"""Compute per-sample metrics useful for quality control. .. include:: ../_templates/req_tvariant.rst. Examples; --------. Compute sample QC metrics and rem",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:23037,Modifiability,config,configuring,23037,",; variant_allele=tstr,; ); ),; seq_region_name=tstr,; start=tint32,; strand=tint32,; transcript_consequences=tarray(; tstruct(; allele_num=tint32,; amino_acids=tstr,; biotype=tstr,; canonical=tint32,; ccds=tstr,; cdna_start=tint32,; cdna_end=tint32,; cds_end=tint32,; cds_start=tint32,; codons=tstr,; consequence_terms=tarray(tstr),; distance=tint32,; domains=tarray(tstruct(db=tstr, name=tstr)),; exon=tstr,; gene_id=tstr,; gene_pheno=tint32,; gene_symbol=tstr,; gene_symbol_source=tstr,; hgnc_id=tstr,; hgvsc=tstr,; hgvsp=tstr,; hgvs_offset=tint32,; impact=tstr,; intron=tstr,; lof=tstr,; lof_flags=tstr,; lof_filter=tstr,; lof_info=tstr,; minimised=tint32,; polyphen_prediction=tstr,; polyphen_score=tfloat,; protein_end=tint32,; protein_start=tint32,; protein_id=tstr,; sift_prediction=tstr,; sift_score=tfloat,; strand=tint32,; swissprot=tstr,; transcript_id=tstr,; trembl=tstr,; uniparc=tstr,; variant_allele=tstr,; ); ),; variant_class=tstr,; ). [docs]class VEPConfig(abc.ABC):; """"""Base class for configuring VEP. To define a custom VEP configuration to for Query on Batch, construct a new class that inherits from :class:`.VEPConfig`; and has the following parameters defined:. - `json_type` (:class:`.HailType`): The type of the VEP JSON schema (as produced by VEP when invoked with the `--json` option).; - `data_bucket` (:obj:`.str`) -- The location where the VEP data is stored.; - `data_mount` (:obj:`.str`) -- The location in the container where the data should be mounted.; - `batch_run_command` (:obj:`.list` of :obj:`.str`) -- The command line to run for a VEP job for a partition.; - `batch_run_csq_header_command` (:obj:`.list` of :obj:`.str`) -- The command line to run when generating the consequence header.; - `env` (dict of :obj:`.str` to :obj:`.str`) -- A map of environment variables to values to add to the environment when invoking the command.; - `cloud` (:obj:`.str`) -- The cloud where the Batch Service is located.; - `image` (:obj:`.str`) -- The docker image to run V",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:23077,Modifiability,config,configuration,23077,"=tint32,; transcript_consequences=tarray(; tstruct(; allele_num=tint32,; amino_acids=tstr,; biotype=tstr,; canonical=tint32,; ccds=tstr,; cdna_start=tint32,; cdna_end=tint32,; cds_end=tint32,; cds_start=tint32,; codons=tstr,; consequence_terms=tarray(tstr),; distance=tint32,; domains=tarray(tstruct(db=tstr, name=tstr)),; exon=tstr,; gene_id=tstr,; gene_pheno=tint32,; gene_symbol=tstr,; gene_symbol_source=tstr,; hgnc_id=tstr,; hgvsc=tstr,; hgvsp=tstr,; hgvs_offset=tint32,; impact=tstr,; intron=tstr,; lof=tstr,; lof_flags=tstr,; lof_filter=tstr,; lof_info=tstr,; minimised=tint32,; polyphen_prediction=tstr,; polyphen_score=tfloat,; protein_end=tint32,; protein_start=tint32,; protein_id=tstr,; sift_prediction=tstr,; sift_score=tfloat,; strand=tint32,; swissprot=tstr,; transcript_id=tstr,; trembl=tstr,; uniparc=tstr,; variant_allele=tstr,; ); ),; variant_class=tstr,; ). [docs]class VEPConfig(abc.ABC):; """"""Base class for configuring VEP. To define a custom VEP configuration to for Query on Batch, construct a new class that inherits from :class:`.VEPConfig`; and has the following parameters defined:. - `json_type` (:class:`.HailType`): The type of the VEP JSON schema (as produced by VEP when invoked with the `--json` option).; - `data_bucket` (:obj:`.str`) -- The location where the VEP data is stored.; - `data_mount` (:obj:`.str`) -- The location in the container where the data should be mounted.; - `batch_run_command` (:obj:`.list` of :obj:`.str`) -- The command line to run for a VEP job for a partition.; - `batch_run_csq_header_command` (:obj:`.list` of :obj:`.str`) -- The command line to run when generating the consequence header.; - `env` (dict of :obj:`.str` to :obj:`.str`) -- A map of environment variables to values to add to the environment when invoking the command.; - `cloud` (:obj:`.str`) -- The cloud where the Batch Service is located.; - `image` (:obj:`.str`) -- The docker image to run VEP.; - `data_bucket_is_requester_pays` (:obj:`.bool`) -- True if the data bu",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:23141,Modifiability,inherit,inherits,23141,"=tint32,; transcript_consequences=tarray(; tstruct(; allele_num=tint32,; amino_acids=tstr,; biotype=tstr,; canonical=tint32,; ccds=tstr,; cdna_start=tint32,; cdna_end=tint32,; cds_end=tint32,; cds_start=tint32,; codons=tstr,; consequence_terms=tarray(tstr),; distance=tint32,; domains=tarray(tstruct(db=tstr, name=tstr)),; exon=tstr,; gene_id=tstr,; gene_pheno=tint32,; gene_symbol=tstr,; gene_symbol_source=tstr,; hgnc_id=tstr,; hgvsc=tstr,; hgvsp=tstr,; hgvs_offset=tint32,; impact=tstr,; intron=tstr,; lof=tstr,; lof_flags=tstr,; lof_filter=tstr,; lof_info=tstr,; minimised=tint32,; polyphen_prediction=tstr,; polyphen_score=tfloat,; protein_end=tint32,; protein_start=tint32,; protein_id=tstr,; sift_prediction=tstr,; sift_score=tfloat,; strand=tint32,; swissprot=tstr,; transcript_id=tstr,; trembl=tstr,; uniparc=tstr,; variant_allele=tstr,; ); ),; variant_class=tstr,; ). [docs]class VEPConfig(abc.ABC):; """"""Base class for configuring VEP. To define a custom VEP configuration to for Query on Batch, construct a new class that inherits from :class:`.VEPConfig`; and has the following parameters defined:. - `json_type` (:class:`.HailType`): The type of the VEP JSON schema (as produced by VEP when invoked with the `--json` option).; - `data_bucket` (:obj:`.str`) -- The location where the VEP data is stored.; - `data_mount` (:obj:`.str`) -- The location in the container where the data should be mounted.; - `batch_run_command` (:obj:`.list` of :obj:`.str`) -- The command line to run for a VEP job for a partition.; - `batch_run_csq_header_command` (:obj:`.list` of :obj:`.str`) -- The command line to run when generating the consequence header.; - `env` (dict of :obj:`.str` to :obj:`.str`) -- A map of environment variables to values to add to the environment when invoking the command.; - `cloud` (:obj:`.str`) -- The cloud where the Batch Service is located.; - `image` (:obj:`.str`) -- The docker image to run VEP.; - `data_bucket_is_requester_pays` (:obj:`.bool`) -- True if the data bu",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:23833,Modifiability,variab,variables,23833,"nd=tint32,; swissprot=tstr,; transcript_id=tstr,; trembl=tstr,; uniparc=tstr,; variant_allele=tstr,; ); ),; variant_class=tstr,; ). [docs]class VEPConfig(abc.ABC):; """"""Base class for configuring VEP. To define a custom VEP configuration to for Query on Batch, construct a new class that inherits from :class:`.VEPConfig`; and has the following parameters defined:. - `json_type` (:class:`.HailType`): The type of the VEP JSON schema (as produced by VEP when invoked with the `--json` option).; - `data_bucket` (:obj:`.str`) -- The location where the VEP data is stored.; - `data_mount` (:obj:`.str`) -- The location in the container where the data should be mounted.; - `batch_run_command` (:obj:`.list` of :obj:`.str`) -- The command line to run for a VEP job for a partition.; - `batch_run_csq_header_command` (:obj:`.list` of :obj:`.str`) -- The command line to run when generating the consequence header.; - `env` (dict of :obj:`.str` to :obj:`.str`) -- A map of environment variables to values to add to the environment when invoking the command.; - `cloud` (:obj:`.str`) -- The cloud where the Batch Service is located.; - `image` (:obj:`.str`) -- The docker image to run VEP.; - `data_bucket_is_requester_pays` (:obj:`.bool`) -- True if the data bucket is requester pays.; - `regions` (:obj:`.list` of :obj:`.str`) -- A list of regions the VEP jobs can run in. In addition, the method `command` must be defined with the following signature. The output is the exact command to run the; VEP executable. The inputs are `consequence` and `tolerate_parse_error` which are user-defined parameters to :func:`.vep`,; `part_id` which is the partition ID, `input_file` which is the path to the input file where the input data can be found, and; `output_file` is the path to the output file where the VEP annotations are written to. An example is shown below:. .. code-block:: python3. def command(self,; consequence: bool,; tolerate_parse_error: bool,; part_id: int,; input_file: Optional[str],; output_",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:25202,Modifiability,plugin,plugin,25202,"an run in. In addition, the method `command` must be defined with the following signature. The output is the exact command to run the; VEP executable. The inputs are `consequence` and `tolerate_parse_error` which are user-defined parameters to :func:`.vep`,; `part_id` which is the partition ID, `input_file` which is the path to the input file where the input data can be found, and; `output_file` is the path to the output file where the VEP annotations are written to. An example is shown below:. .. code-block:: python3. def command(self,; consequence: bool,; tolerate_parse_error: bool,; part_id: int,; input_file: Optional[str],; output_file: str) -> List[str]:; vcf_or_json = '--vcf' if consequence else '--json'; input_file = f'--input_file {input_file}' if input_file else ''; return f'''/vep/vep {input_file} \; --format vcf \; {vcf_or_json} \; --everything \; --allele_number \; --no_stats \; --cache \; --offline \; --minimal \; --assembly GRCh37 \; --dir={self.data_mount} \; --plugin LoF,human_ancestor_fa:{self.data_mount}/loftee_data/human_ancestor.fa.gz,filter_position:0.05,min_intron_size:15,conservation_file:{self.data_mount}/loftee_data/phylocsf_gerp.sql,gerp_file:{self.data_mount}/loftee_data/GERP_scores.final.sorted.txt.gz \; -o STDOUT; '''. The following environment variables are added to the job's environment:. - `VEP_BLOCK_SIZE` - The maximum number of variants provided as input to each invocation of VEP.; - `VEP_PART_ID` - Partition ID.; - `VEP_DATA_MOUNT` - Location where the vep data is mounted (same as `data_mount` in the config).; - `VEP_CONSEQUENCE` - Integer equal to 0 or 1 on whether `csq` is False or True.; - `VEP_TOLERATE_PARSE_ERROR` - Integer equal to 0 or 1 on whether `tolerate_parse_error` is False or True.; - `VEP_OUTPUT_FILE` - String specifying the local path where the output TSV file with the VEP result should be located.; - `VEP_INPUT_FILE` - String specifying the local path where the input VCF shard is located for all jobs. The `VEP_INPU",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:25505,Modifiability,variab,variables,25505,"file` which is the path to the input file where the input data can be found, and; `output_file` is the path to the output file where the VEP annotations are written to. An example is shown below:. .. code-block:: python3. def command(self,; consequence: bool,; tolerate_parse_error: bool,; part_id: int,; input_file: Optional[str],; output_file: str) -> List[str]:; vcf_or_json = '--vcf' if consequence else '--json'; input_file = f'--input_file {input_file}' if input_file else ''; return f'''/vep/vep {input_file} \; --format vcf \; {vcf_or_json} \; --everything \; --allele_number \; --no_stats \; --cache \; --offline \; --minimal \; --assembly GRCh37 \; --dir={self.data_mount} \; --plugin LoF,human_ancestor_fa:{self.data_mount}/loftee_data/human_ancestor.fa.gz,filter_position:0.05,min_intron_size:15,conservation_file:{self.data_mount}/loftee_data/phylocsf_gerp.sql,gerp_file:{self.data_mount}/loftee_data/GERP_scores.final.sorted.txt.gz \; -o STDOUT; '''. The following environment variables are added to the job's environment:. - `VEP_BLOCK_SIZE` - The maximum number of variants provided as input to each invocation of VEP.; - `VEP_PART_ID` - Partition ID.; - `VEP_DATA_MOUNT` - Location where the vep data is mounted (same as `data_mount` in the config).; - `VEP_CONSEQUENCE` - Integer equal to 0 or 1 on whether `csq` is False or True.; - `VEP_TOLERATE_PARSE_ERROR` - Integer equal to 0 or 1 on whether `tolerate_parse_error` is False or True.; - `VEP_OUTPUT_FILE` - String specifying the local path where the output TSV file with the VEP result should be located.; - `VEP_INPUT_FILE` - String specifying the local path where the input VCF shard is located for all jobs. The `VEP_INPUT_FILE` environment variable is not available for the single job that computes the consequence header when; ``csq=True``; """""". json_typ: hl.expr.HailType; data_bucket: str; data_mount: str; regions: List[str]; image: str; env: Dict[str, str]; data_bucket_is_requester_pays: bool; cloud: str; batch_run_co",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:25772,Modifiability,config,config,25772,"hon3. def command(self,; consequence: bool,; tolerate_parse_error: bool,; part_id: int,; input_file: Optional[str],; output_file: str) -> List[str]:; vcf_or_json = '--vcf' if consequence else '--json'; input_file = f'--input_file {input_file}' if input_file else ''; return f'''/vep/vep {input_file} \; --format vcf \; {vcf_or_json} \; --everything \; --allele_number \; --no_stats \; --cache \; --offline \; --minimal \; --assembly GRCh37 \; --dir={self.data_mount} \; --plugin LoF,human_ancestor_fa:{self.data_mount}/loftee_data/human_ancestor.fa.gz,filter_position:0.05,min_intron_size:15,conservation_file:{self.data_mount}/loftee_data/phylocsf_gerp.sql,gerp_file:{self.data_mount}/loftee_data/GERP_scores.final.sorted.txt.gz \; -o STDOUT; '''. The following environment variables are added to the job's environment:. - `VEP_BLOCK_SIZE` - The maximum number of variants provided as input to each invocation of VEP.; - `VEP_PART_ID` - Partition ID.; - `VEP_DATA_MOUNT` - Location where the vep data is mounted (same as `data_mount` in the config).; - `VEP_CONSEQUENCE` - Integer equal to 0 or 1 on whether `csq` is False or True.; - `VEP_TOLERATE_PARSE_ERROR` - Integer equal to 0 or 1 on whether `tolerate_parse_error` is False or True.; - `VEP_OUTPUT_FILE` - String specifying the local path where the output TSV file with the VEP result should be located.; - `VEP_INPUT_FILE` - String specifying the local path where the input VCF shard is located for all jobs. The `VEP_INPUT_FILE` environment variable is not available for the single job that computes the consequence header when; ``csq=True``; """""". json_typ: hl.expr.HailType; data_bucket: str; data_mount: str; regions: List[str]; image: str; env: Dict[str, str]; data_bucket_is_requester_pays: bool; cloud: str; batch_run_command: List[str]; batch_run_csq_header_command: List[str]. @abc.abstractmethod; def command(; self, consequence: bool, tolerate_parse_error: bool, part_id: int, input_file: Optional[str], output_file: str; ) -> List[",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:26231,Modifiability,variab,variable,26231,"ancestor.fa.gz,filter_position:0.05,min_intron_size:15,conservation_file:{self.data_mount}/loftee_data/phylocsf_gerp.sql,gerp_file:{self.data_mount}/loftee_data/GERP_scores.final.sorted.txt.gz \; -o STDOUT; '''. The following environment variables are added to the job's environment:. - `VEP_BLOCK_SIZE` - The maximum number of variants provided as input to each invocation of VEP.; - `VEP_PART_ID` - Partition ID.; - `VEP_DATA_MOUNT` - Location where the vep data is mounted (same as `data_mount` in the config).; - `VEP_CONSEQUENCE` - Integer equal to 0 or 1 on whether `csq` is False or True.; - `VEP_TOLERATE_PARSE_ERROR` - Integer equal to 0 or 1 on whether `tolerate_parse_error` is False or True.; - `VEP_OUTPUT_FILE` - String specifying the local path where the output TSV file with the VEP result should be located.; - `VEP_INPUT_FILE` - String specifying the local path where the input VCF shard is located for all jobs. The `VEP_INPUT_FILE` environment variable is not available for the single job that computes the consequence header when; ``csq=True``; """""". json_typ: hl.expr.HailType; data_bucket: str; data_mount: str; regions: List[str]; image: str; env: Dict[str, str]; data_bucket_is_requester_pays: bool; cloud: str; batch_run_command: List[str]; batch_run_csq_header_command: List[str]. @abc.abstractmethod; def command(; self, consequence: bool, tolerate_parse_error: bool, part_id: int, input_file: Optional[str], output_file: str; ) -> List[str]:; raise NotImplementedError. [docs]class VEPConfigGRCh37Version85(VEPConfig):; """"""; The Hail-maintained VEP configuration for GRCh37 for VEP version 85. This class takes the following constructor arguments:. - `data_bucket` (:obj:`.str`) -- The location where the VEP data is stored.; - `data_mount` (:obj:`.str`) -- The location in the container where the data should be mounted.; - `image` (:obj:`.str`) -- The docker image to run VEP.; - `cloud` (:obj:`.str`) -- The cloud where the Batch Service is located.; - `data_bucket_is_",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:26844,Modifiability,config,configuration,26844,"1 on whether `csq` is False or True.; - `VEP_TOLERATE_PARSE_ERROR` - Integer equal to 0 or 1 on whether `tolerate_parse_error` is False or True.; - `VEP_OUTPUT_FILE` - String specifying the local path where the output TSV file with the VEP result should be located.; - `VEP_INPUT_FILE` - String specifying the local path where the input VCF shard is located for all jobs. The `VEP_INPUT_FILE` environment variable is not available for the single job that computes the consequence header when; ``csq=True``; """""". json_typ: hl.expr.HailType; data_bucket: str; data_mount: str; regions: List[str]; image: str; env: Dict[str, str]; data_bucket_is_requester_pays: bool; cloud: str; batch_run_command: List[str]; batch_run_csq_header_command: List[str]. @abc.abstractmethod; def command(; self, consequence: bool, tolerate_parse_error: bool, part_id: int, input_file: Optional[str], output_file: str; ) -> List[str]:; raise NotImplementedError. [docs]class VEPConfigGRCh37Version85(VEPConfig):; """"""; The Hail-maintained VEP configuration for GRCh37 for VEP version 85. This class takes the following constructor arguments:. - `data_bucket` (:obj:`.str`) -- The location where the VEP data is stored.; - `data_mount` (:obj:`.str`) -- The location in the container where the data should be mounted.; - `image` (:obj:`.str`) -- The docker image to run VEP.; - `cloud` (:obj:`.str`) -- The cloud where the Batch Service is located.; - `data_bucket_is_requester_pays` (:obj:`.bool`) -- True if the data bucket is requester pays.; - `regions` (:obj:`.list` of :obj:`.str`) -- A list of regions the VEP jobs can run in. """""". def __init__(; self,; *,; data_bucket: str,; data_mount: str,; image: str,; regions: List[str],; cloud: str,; data_bucket_is_requester_pays: bool,; ):; self.data_bucket = data_bucket; self.data_mount = data_mount; self.image = image; self.regions = regions; self.env = {}; self.data_bucket_is_requester_pays = data_bucket_is_requester_pays; self.cloud = cloud; self.batch_run_command = ['",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:28446,Modifiability,plugin,plugin,28446,"lf,; *,; data_bucket: str,; data_mount: str,; image: str,; regions: List[str],; cloud: str,; data_bucket_is_requester_pays: bool,; ):; self.data_bucket = data_bucket; self.data_mount = data_mount; self.image = image; self.regions = regions; self.env = {}; self.data_bucket_is_requester_pays = data_bucket_is_requester_pays; self.cloud = cloud; self.batch_run_command = ['python3', '/hail-vep/vep.py', 'vep']; self.batch_run_csq_header_command = ['python3', '/hail-vep/vep.py', 'csq_header']; self.json_typ = vep_json_typ. def command(; self,; *,; consequence: bool,; tolerate_parse_error: bool,; part_id: int,; input_file: Optional[str],; output_file: str,; ) -> str:; vcf_or_json = '--vcf' if consequence else '--json'; input_file = f'--input_file {input_file}' if input_file else ''; return f""""""/vep/vep {input_file} \; --format vcf \; {vcf_or_json} \; --everything \; --allele_number \; --no_stats \; --cache \; --offline \; --minimal \; --assembly GRCh37 \; --dir={self.data_mount} \; --plugin LoF,human_ancestor_fa:{self.data_mount}/loftee_data/human_ancestor.fa.gz,filter_position:0.05,min_intron_size:15,conservation_file:{self.data_mount}/loftee_data/phylocsf_gerp.sql,gerp_file:{self.data_mount}/loftee_data/GERP_scores.final.sorted.txt.gz \; -o STDOUT; """""". [docs]class VEPConfigGRCh38Version95(VEPConfig):; """"""; The Hail-maintained VEP configuration for GRCh38 for VEP version 95. This class takes the following constructor arguments:. - `data_bucket` (:obj:`.str`) -- The location where the VEP data is stored.; - `data_mount` (:obj:`.str`) -- The location in the container where the data should be mounted.; - `image` (:obj:`.str`) -- The docker image to run VEP.; - `cloud` (:obj:`.str`) -- The cloud where the Batch Service is located.; - `data_bucket_is_requester_pays` (:obj:`.bool`) -- True if the data bucket is set to requester pays.; - `regions` (:obj:`.list` of :obj:`.str`) -- A list of regions the VEP jobs can run in. """""". def __init__(; self,; *,; data_bucket: str,; data_mo",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:28802,Modifiability,config,configuration,28802,"cloud = cloud; self.batch_run_command = ['python3', '/hail-vep/vep.py', 'vep']; self.batch_run_csq_header_command = ['python3', '/hail-vep/vep.py', 'csq_header']; self.json_typ = vep_json_typ. def command(; self,; *,; consequence: bool,; tolerate_parse_error: bool,; part_id: int,; input_file: Optional[str],; output_file: str,; ) -> str:; vcf_or_json = '--vcf' if consequence else '--json'; input_file = f'--input_file {input_file}' if input_file else ''; return f""""""/vep/vep {input_file} \; --format vcf \; {vcf_or_json} \; --everything \; --allele_number \; --no_stats \; --cache \; --offline \; --minimal \; --assembly GRCh37 \; --dir={self.data_mount} \; --plugin LoF,human_ancestor_fa:{self.data_mount}/loftee_data/human_ancestor.fa.gz,filter_position:0.05,min_intron_size:15,conservation_file:{self.data_mount}/loftee_data/phylocsf_gerp.sql,gerp_file:{self.data_mount}/loftee_data/GERP_scores.final.sorted.txt.gz \; -o STDOUT; """""". [docs]class VEPConfigGRCh38Version95(VEPConfig):; """"""; The Hail-maintained VEP configuration for GRCh38 for VEP version 95. This class takes the following constructor arguments:. - `data_bucket` (:obj:`.str`) -- The location where the VEP data is stored.; - `data_mount` (:obj:`.str`) -- The location in the container where the data should be mounted.; - `image` (:obj:`.str`) -- The docker image to run VEP.; - `cloud` (:obj:`.str`) -- The cloud where the Batch Service is located.; - `data_bucket_is_requester_pays` (:obj:`.bool`) -- True if the data bucket is set to requester pays.; - `regions` (:obj:`.list` of :obj:`.str`) -- A list of regions the VEP jobs can run in. """""". def __init__(; self,; *,; data_bucket: str,; data_mount: str,; image: str,; regions: List[str],; cloud: str,; data_bucket_is_requester_pays: bool,; ):; self.data_bucket = data_bucket; self.data_mount = data_mount; self.image = image; self.regions = regions; self.env = {}; self.data_bucket_is_requester_pays = data_bucket_is_requester_pays; self.cloud = cloud; self.batch_run_comma",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:30633,Modifiability,plugin,plugin,30633,"lf.env = {}; self.data_bucket_is_requester_pays = data_bucket_is_requester_pays; self.cloud = cloud; self.batch_run_command = ['python3', '/hail-vep/vep.py', 'vep']; self.batch_run_csq_header_command = ['python3', '/hail-vep/vep.py', 'csq_header']; self.json_typ = vep_json_typ._insert_field(; 'transcript_consequences',; tarray(; vep_json_typ['transcript_consequences'].element_type._insert_fields(; appris=tstr,; tsl=tint32,; ); ),; ). def command(; self,; *,; consequence: bool,; tolerate_parse_error: bool,; part_id: int,; input_file: Optional[str],; output_file: str,; ) -> str:; vcf_or_json = '--vcf' if consequence else '--json'; input_file = f'--input_file {input_file}' if input_file else ''; return f""""""/vep/vep {input_file} \; --format vcf \; {vcf_or_json} \; --everything \; --allele_number \; --no_stats \; --cache \; --offline \; --minimal \; --assembly GRCh38 \; --fasta {self.data_mount}homo_sapiens/95_GRCh38/Homo_sapiens.GRCh38.dna.toplevel.fa.gz \; --plugin ""LoF,loftee_path:/vep/ensembl-vep/Plugins/,gerp_bigwig:{self.data_mount}/gerp_conservation_scores.homo_sapiens.GRCh38.bw,human_ancestor_fa:{self.data_mount}/human_ancestor.fa.gz,conservation_file:{self.data_mount}/loftee.sql"" \; --dir_plugins /vep/ensembl-vep/Plugins/ \; --dir_cache {self.data_mount} \; -o STDOUT; """""". supported_vep_configs = {; ('GRCh37', 'gcp', 'us-central1', 'hail.is'): VEPConfigGRCh37Version85(; data_bucket='hail-qob-vep-grch37-us-central1',; data_mount='/vep_data/',; image=HAIL_GENETICS_VEP_GRCH37_85_IMAGE,; regions=['us-central1'],; cloud='gcp',; data_bucket_is_requester_pays=True,; ),; ('GRCh38', 'gcp', 'us-central1', 'hail.is'): VEPConfigGRCh38Version95(; data_bucket='hail-qob-vep-grch38-us-central1',; data_mount='/vep_data/',; image=HAIL_GENETICS_VEP_GRCH38_95_IMAGE,; regions=['us-central1'],; cloud='gcp',; data_bucket_is_requester_pays=True,; ),; }. def _supported_vep_config(cloud: str, reference_genome: str, *, regions: List[str]) -> VEPConfig:; domain = get_deploy_config()._domai",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:31890,Modifiability,config,configuration,31890,"e {self.data_mount} \; -o STDOUT; """""". supported_vep_configs = {; ('GRCh37', 'gcp', 'us-central1', 'hail.is'): VEPConfigGRCh37Version85(; data_bucket='hail-qob-vep-grch37-us-central1',; data_mount='/vep_data/',; image=HAIL_GENETICS_VEP_GRCH37_85_IMAGE,; regions=['us-central1'],; cloud='gcp',; data_bucket_is_requester_pays=True,; ),; ('GRCh38', 'gcp', 'us-central1', 'hail.is'): VEPConfigGRCh38Version95(; data_bucket='hail-qob-vep-grch38-us-central1',; data_mount='/vep_data/',; image=HAIL_GENETICS_VEP_GRCH38_95_IMAGE,; regions=['us-central1'],; cloud='gcp',; data_bucket_is_requester_pays=True,; ),; }. def _supported_vep_config(cloud: str, reference_genome: str, *, regions: List[str]) -> VEPConfig:; domain = get_deploy_config()._domain. for region in regions:; config_params = (reference_genome, cloud, region, domain); if config_params in supported_vep_configs:; return supported_vep_configs[config_params]. raise ValueError(; f'could not find a supported vep configuration for reference genome {reference_genome}, '; f'cloud {cloud}, regions {regions}, and domain {domain}'; ). def _service_vep(; backend: ServiceBackend,; ht: Table,; config: Optional[VEPConfig],; block_size: int,; csq: bool,; tolerate_parse_error: bool,; temp_input_directory: str,; temp_output_directory: str,; ) -> Table:; reference_genome = ht.locus.dtype.reference_genome.name; cloud = async_to_blocking(backend._batch_client.cloud()); regions = backend.regions. if config is not None:; vep_config = config; else:; vep_config = _supported_vep_config(cloud, reference_genome, regions=regions). requester_pays_project = backend.flags.get('gcs_requester_pays_project'); if requester_pays_project is None and vep_config.data_bucket_is_requester_pays and vep_config.cloud == 'gcp':; raise ValueError(; ""No requester pays project has been set. ""; ""Use hl.init(gcs_requester_pays_configuration='MY_PROJECT') ""; ""to set the requester pays project to use.""; ). if csq:; vep_typ = hl.tarray(hl.tstr); else:; vep_typ = vep_config.",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:32066,Modifiability,config,config,32066,"ta/',; image=HAIL_GENETICS_VEP_GRCH37_85_IMAGE,; regions=['us-central1'],; cloud='gcp',; data_bucket_is_requester_pays=True,; ),; ('GRCh38', 'gcp', 'us-central1', 'hail.is'): VEPConfigGRCh38Version95(; data_bucket='hail-qob-vep-grch38-us-central1',; data_mount='/vep_data/',; image=HAIL_GENETICS_VEP_GRCH38_95_IMAGE,; regions=['us-central1'],; cloud='gcp',; data_bucket_is_requester_pays=True,; ),; }. def _supported_vep_config(cloud: str, reference_genome: str, *, regions: List[str]) -> VEPConfig:; domain = get_deploy_config()._domain. for region in regions:; config_params = (reference_genome, cloud, region, domain); if config_params in supported_vep_configs:; return supported_vep_configs[config_params]. raise ValueError(; f'could not find a supported vep configuration for reference genome {reference_genome}, '; f'cloud {cloud}, regions {regions}, and domain {domain}'; ). def _service_vep(; backend: ServiceBackend,; ht: Table,; config: Optional[VEPConfig],; block_size: int,; csq: bool,; tolerate_parse_error: bool,; temp_input_directory: str,; temp_output_directory: str,; ) -> Table:; reference_genome = ht.locus.dtype.reference_genome.name; cloud = async_to_blocking(backend._batch_client.cloud()); regions = backend.regions. if config is not None:; vep_config = config; else:; vep_config = _supported_vep_config(cloud, reference_genome, regions=regions). requester_pays_project = backend.flags.get('gcs_requester_pays_project'); if requester_pays_project is None and vep_config.data_bucket_is_requester_pays and vep_config.cloud == 'gcp':; raise ValueError(; ""No requester pays project has been set. ""; ""Use hl.init(gcs_requester_pays_configuration='MY_PROJECT') ""; ""to set the requester pays project to use.""; ). if csq:; vep_typ = hl.tarray(hl.tstr); else:; vep_typ = vep_config.json_typ. def build_vep_batch(b: bc.aioclient.Batch, vep_input_path: str, vep_output_path: str):; if csq:; local_output_file = '/io/output'; vep_command = vep_config.command(; consequence=csq,; part_id=-1,",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:32370,Modifiability,config,config,32370,"38_95_IMAGE,; regions=['us-central1'],; cloud='gcp',; data_bucket_is_requester_pays=True,; ),; }. def _supported_vep_config(cloud: str, reference_genome: str, *, regions: List[str]) -> VEPConfig:; domain = get_deploy_config()._domain. for region in regions:; config_params = (reference_genome, cloud, region, domain); if config_params in supported_vep_configs:; return supported_vep_configs[config_params]. raise ValueError(; f'could not find a supported vep configuration for reference genome {reference_genome}, '; f'cloud {cloud}, regions {regions}, and domain {domain}'; ). def _service_vep(; backend: ServiceBackend,; ht: Table,; config: Optional[VEPConfig],; block_size: int,; csq: bool,; tolerate_parse_error: bool,; temp_input_directory: str,; temp_output_directory: str,; ) -> Table:; reference_genome = ht.locus.dtype.reference_genome.name; cloud = async_to_blocking(backend._batch_client.cloud()); regions = backend.regions. if config is not None:; vep_config = config; else:; vep_config = _supported_vep_config(cloud, reference_genome, regions=regions). requester_pays_project = backend.flags.get('gcs_requester_pays_project'); if requester_pays_project is None and vep_config.data_bucket_is_requester_pays and vep_config.cloud == 'gcp':; raise ValueError(; ""No requester pays project has been set. ""; ""Use hl.init(gcs_requester_pays_configuration='MY_PROJECT') ""; ""to set the requester pays project to use.""; ). if csq:; vep_typ = hl.tarray(hl.tstr); else:; vep_typ = vep_config.json_typ. def build_vep_batch(b: bc.aioclient.Batch, vep_input_path: str, vep_output_path: str):; if csq:; local_output_file = '/io/output'; vep_command = vep_config.command(; consequence=csq,; part_id=-1,; input_file=None,; output_file=local_output_file,; tolerate_parse_error=tolerate_parse_error,; ); env = {; 'VEP_BLOCK_SIZE': str(block_size),; 'VEP_DATA_MOUNT': shq(vep_config.data_mount),; 'VEP_CONSEQUENCE': str(int(csq)),; 'VEP_TOLERATE_PARSE_ERROR': str(int(tolerate_parse_error)),; 'VEP_PART_ID': s",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:32404,Modifiability,config,config,32404,"38_95_IMAGE,; regions=['us-central1'],; cloud='gcp',; data_bucket_is_requester_pays=True,; ),; }. def _supported_vep_config(cloud: str, reference_genome: str, *, regions: List[str]) -> VEPConfig:; domain = get_deploy_config()._domain. for region in regions:; config_params = (reference_genome, cloud, region, domain); if config_params in supported_vep_configs:; return supported_vep_configs[config_params]. raise ValueError(; f'could not find a supported vep configuration for reference genome {reference_genome}, '; f'cloud {cloud}, regions {regions}, and domain {domain}'; ). def _service_vep(; backend: ServiceBackend,; ht: Table,; config: Optional[VEPConfig],; block_size: int,; csq: bool,; tolerate_parse_error: bool,; temp_input_directory: str,; temp_output_directory: str,; ) -> Table:; reference_genome = ht.locus.dtype.reference_genome.name; cloud = async_to_blocking(backend._batch_client.cloud()); regions = backend.regions. if config is not None:; vep_config = config; else:; vep_config = _supported_vep_config(cloud, reference_genome, regions=regions). requester_pays_project = backend.flags.get('gcs_requester_pays_project'); if requester_pays_project is None and vep_config.data_bucket_is_requester_pays and vep_config.cloud == 'gcp':; raise ValueError(; ""No requester pays project has been set. ""; ""Use hl.init(gcs_requester_pays_configuration='MY_PROJECT') ""; ""to set the requester pays project to use.""; ). if csq:; vep_typ = hl.tarray(hl.tstr); else:; vep_typ = vep_config.json_typ. def build_vep_batch(b: bc.aioclient.Batch, vep_input_path: str, vep_output_path: str):; if csq:; local_output_file = '/io/output'; vep_command = vep_config.command(; consequence=csq,; part_id=-1,; input_file=None,; output_file=local_output_file,; tolerate_parse_error=tolerate_parse_error,; ); env = {; 'VEP_BLOCK_SIZE': str(block_size),; 'VEP_DATA_MOUNT': shq(vep_config.data_mount),; 'VEP_CONSEQUENCE': str(int(csq)),; 'VEP_TOLERATE_PARSE_ERROR': str(int(tolerate_parse_error)),; 'VEP_PART_ID': s",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:36804,Modifiability,config,config,36804,"failing_job.status(), 'log': failing_job.log()}; raise FatalError(yamlx.dump(message)). annotations = hl.import_table(; f'{temp_output_directory}/annotations/*',; types={'variant': hl.tstr, 'vep': vep_typ, 'part_id': hl.tint, 'block_id': hl.tint},; force=True,; ). annotations = annotations.annotate(; vep_proc_id=hl.struct(part_id=annotations.part_id, block_id=annotations.block_id); ); annotations = annotations.drop('part_id', 'block_id'); annotations = annotations.key_by(**hl.parse_variant(annotations.variant, reference_genome=reference_genome)); annotations = annotations.drop('variant'). if csq:; with hl.hadoop_open(f'{temp_output_directory}/csq-header') as f:; vep_csq_header = f.read().rstrip(); annotations = annotations.annotate_globals(vep_csq_header=vep_csq_header). return annotations. [docs]@typecheck(; dataset=oneof(Table, MatrixTable),; config=nullable(oneof(str, VEPConfig)),; block_size=int,; name=str,; csq=bool,; tolerate_parse_error=bool,; ); def vep(; dataset: Union[Table, MatrixTable],; config: Optional[Union[str, VEPConfig]] = None,; block_size: int = 1000,; name: str = 'vep',; csq: bool = False,; tolerate_parse_error: bool = False,; ):; """"""Annotate variants with VEP. .. include:: ../_templates/req_tvariant.rst. :func:`.vep` runs `Variant Effect Predictor; <http://www.ensembl.org/info/docs/tools/vep/index.html>`__ on the; current dataset and adds the result as a row field. Examples; --------. Add VEP annotations to the dataset:. >>> result = hl.vep(dataset, ""data/vep-configuration.json"") # doctest: +SKIP. Notes; -----. **Installation**. This VEP command only works if you have already installed VEP on your; computing environment. If you use `hailctl dataproc` to start Hail clusters,; installing VEP is achieved by specifying the `--vep` flag. For more detailed instructions,; see :ref:`vep_dataproc`. If you use `hailctl hdinsight`, see :ref:`vep_hdinsight`. **Spark Configuration**. :func:`.vep` needs a configuration file to tell it how to run VEP. This is ",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:36962,Modifiability,config,config,36962,"failing_job.status(), 'log': failing_job.log()}; raise FatalError(yamlx.dump(message)). annotations = hl.import_table(; f'{temp_output_directory}/annotations/*',; types={'variant': hl.tstr, 'vep': vep_typ, 'part_id': hl.tint, 'block_id': hl.tint},; force=True,; ). annotations = annotations.annotate(; vep_proc_id=hl.struct(part_id=annotations.part_id, block_id=annotations.block_id); ); annotations = annotations.drop('part_id', 'block_id'); annotations = annotations.key_by(**hl.parse_variant(annotations.variant, reference_genome=reference_genome)); annotations = annotations.drop('variant'). if csq:; with hl.hadoop_open(f'{temp_output_directory}/csq-header') as f:; vep_csq_header = f.read().rstrip(); annotations = annotations.annotate_globals(vep_csq_header=vep_csq_header). return annotations. [docs]@typecheck(; dataset=oneof(Table, MatrixTable),; config=nullable(oneof(str, VEPConfig)),; block_size=int,; name=str,; csq=bool,; tolerate_parse_error=bool,; ); def vep(; dataset: Union[Table, MatrixTable],; config: Optional[Union[str, VEPConfig]] = None,; block_size: int = 1000,; name: str = 'vep',; csq: bool = False,; tolerate_parse_error: bool = False,; ):; """"""Annotate variants with VEP. .. include:: ../_templates/req_tvariant.rst. :func:`.vep` runs `Variant Effect Predictor; <http://www.ensembl.org/info/docs/tools/vep/index.html>`__ on the; current dataset and adds the result as a row field. Examples; --------. Add VEP annotations to the dataset:. >>> result = hl.vep(dataset, ""data/vep-configuration.json"") # doctest: +SKIP. Notes; -----. **Installation**. This VEP command only works if you have already installed VEP on your; computing environment. If you use `hailctl dataproc` to start Hail clusters,; installing VEP is achieved by specifying the `--vep` flag. For more detailed instructions,; see :ref:`vep_dataproc`. If you use `hailctl hdinsight`, see :ref:`vep_hdinsight`. **Spark Configuration**. :func:`.vep` needs a configuration file to tell it how to run VEP. This is ",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:37453,Modifiability,config,configuration,37453,"tions.variant, reference_genome=reference_genome)); annotations = annotations.drop('variant'). if csq:; with hl.hadoop_open(f'{temp_output_directory}/csq-header') as f:; vep_csq_header = f.read().rstrip(); annotations = annotations.annotate_globals(vep_csq_header=vep_csq_header). return annotations. [docs]@typecheck(; dataset=oneof(Table, MatrixTable),; config=nullable(oneof(str, VEPConfig)),; block_size=int,; name=str,; csq=bool,; tolerate_parse_error=bool,; ); def vep(; dataset: Union[Table, MatrixTable],; config: Optional[Union[str, VEPConfig]] = None,; block_size: int = 1000,; name: str = 'vep',; csq: bool = False,; tolerate_parse_error: bool = False,; ):; """"""Annotate variants with VEP. .. include:: ../_templates/req_tvariant.rst. :func:`.vep` runs `Variant Effect Predictor; <http://www.ensembl.org/info/docs/tools/vep/index.html>`__ on the; current dataset and adds the result as a row field. Examples; --------. Add VEP annotations to the dataset:. >>> result = hl.vep(dataset, ""data/vep-configuration.json"") # doctest: +SKIP. Notes; -----. **Installation**. This VEP command only works if you have already installed VEP on your; computing environment. If you use `hailctl dataproc` to start Hail clusters,; installing VEP is achieved by specifying the `--vep` flag. For more detailed instructions,; see :ref:`vep_dataproc`. If you use `hailctl hdinsight`, see :ref:`vep_hdinsight`. **Spark Configuration**. :func:`.vep` needs a configuration file to tell it how to run VEP. This is the ``config`` argument; to the VEP function. If you are using `hailctl dataproc` as mentioned above, you can just use the; default argument for ``config`` and everything will work. If you need to run VEP with Hail in other environments,; there are detailed instructions below. The format of the configuration file is JSON, and :func:`.vep`; expects a JSON object with three fields:. - `command` (array of string) -- The VEP command line to run. The string literal `__OUTPUT_FORMAT_FLAG__` is replaced",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:37894,Modifiability,config,configuration,37894,"; ); def vep(; dataset: Union[Table, MatrixTable],; config: Optional[Union[str, VEPConfig]] = None,; block_size: int = 1000,; name: str = 'vep',; csq: bool = False,; tolerate_parse_error: bool = False,; ):; """"""Annotate variants with VEP. .. include:: ../_templates/req_tvariant.rst. :func:`.vep` runs `Variant Effect Predictor; <http://www.ensembl.org/info/docs/tools/vep/index.html>`__ on the; current dataset and adds the result as a row field. Examples; --------. Add VEP annotations to the dataset:. >>> result = hl.vep(dataset, ""data/vep-configuration.json"") # doctest: +SKIP. Notes; -----. **Installation**. This VEP command only works if you have already installed VEP on your; computing environment. If you use `hailctl dataproc` to start Hail clusters,; installing VEP is achieved by specifying the `--vep` flag. For more detailed instructions,; see :ref:`vep_dataproc`. If you use `hailctl hdinsight`, see :ref:`vep_hdinsight`. **Spark Configuration**. :func:`.vep` needs a configuration file to tell it how to run VEP. This is the ``config`` argument; to the VEP function. If you are using `hailctl dataproc` as mentioned above, you can just use the; default argument for ``config`` and everything will work. If you need to run VEP with Hail in other environments,; there are detailed instructions below. The format of the configuration file is JSON, and :func:`.vep`; expects a JSON object with three fields:. - `command` (array of string) -- The VEP command line to run. The string literal `__OUTPUT_FORMAT_FLAG__` is replaced with `--json` or `--vcf` depending on `csq`.; - `env` (object) -- A map of environment variables to values to add to the environment when invoking the command. The value of each object member must be a string.; - `vep_json_schema` (string): The type of the VEP JSON schema (as produced by the VEP when invoked with the `--json` option). Note: This is the old-style 'parseable' Hail type syntax. This will change. Here is an example configuration file for invok",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:37954,Modifiability,config,config,37954,"ig: Optional[Union[str, VEPConfig]] = None,; block_size: int = 1000,; name: str = 'vep',; csq: bool = False,; tolerate_parse_error: bool = False,; ):; """"""Annotate variants with VEP. .. include:: ../_templates/req_tvariant.rst. :func:`.vep` runs `Variant Effect Predictor; <http://www.ensembl.org/info/docs/tools/vep/index.html>`__ on the; current dataset and adds the result as a row field. Examples; --------. Add VEP annotations to the dataset:. >>> result = hl.vep(dataset, ""data/vep-configuration.json"") # doctest: +SKIP. Notes; -----. **Installation**. This VEP command only works if you have already installed VEP on your; computing environment. If you use `hailctl dataproc` to start Hail clusters,; installing VEP is achieved by specifying the `--vep` flag. For more detailed instructions,; see :ref:`vep_dataproc`. If you use `hailctl hdinsight`, see :ref:`vep_hdinsight`. **Spark Configuration**. :func:`.vep` needs a configuration file to tell it how to run VEP. This is the ``config`` argument; to the VEP function. If you are using `hailctl dataproc` as mentioned above, you can just use the; default argument for ``config`` and everything will work. If you need to run VEP with Hail in other environments,; there are detailed instructions below. The format of the configuration file is JSON, and :func:`.vep`; expects a JSON object with three fields:. - `command` (array of string) -- The VEP command line to run. The string literal `__OUTPUT_FORMAT_FLAG__` is replaced with `--json` or `--vcf` depending on `csq`.; - `env` (object) -- A map of environment variables to values to add to the environment when invoking the command. The value of each object member must be a string.; - `vep_json_schema` (string): The type of the VEP JSON schema (as produced by the VEP when invoked with the `--json` option). Note: This is the old-style 'parseable' Hail type syntax. This will change. Here is an example configuration file for invoking VEP release 85; installed in `/vep` with the Loftee ",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:38095,Modifiability,config,config,38095,"bool = False,; tolerate_parse_error: bool = False,; ):; """"""Annotate variants with VEP. .. include:: ../_templates/req_tvariant.rst. :func:`.vep` runs `Variant Effect Predictor; <http://www.ensembl.org/info/docs/tools/vep/index.html>`__ on the; current dataset and adds the result as a row field. Examples; --------. Add VEP annotations to the dataset:. >>> result = hl.vep(dataset, ""data/vep-configuration.json"") # doctest: +SKIP. Notes; -----. **Installation**. This VEP command only works if you have already installed VEP on your; computing environment. If you use `hailctl dataproc` to start Hail clusters,; installing VEP is achieved by specifying the `--vep` flag. For more detailed instructions,; see :ref:`vep_dataproc`. If you use `hailctl hdinsight`, see :ref:`vep_hdinsight`. **Spark Configuration**. :func:`.vep` needs a configuration file to tell it how to run VEP. This is the ``config`` argument; to the VEP function. If you are using `hailctl dataproc` as mentioned above, you can just use the; default argument for ``config`` and everything will work. If you need to run VEP with Hail in other environments,; there are detailed instructions below. The format of the configuration file is JSON, and :func:`.vep`; expects a JSON object with three fields:. - `command` (array of string) -- The VEP command line to run. The string literal `__OUTPUT_FORMAT_FLAG__` is replaced with `--json` or `--vcf` depending on `csq`.; - `env` (object) -- A map of environment variables to values to add to the environment when invoking the command. The value of each object member must be a string.; - `vep_json_schema` (string): The type of the VEP JSON schema (as produced by the VEP when invoked with the `--json` option). Note: This is the old-style 'parseable' Hail type syntax. This will change. Here is an example configuration file for invoking VEP release 85; installed in `/vep` with the Loftee plugin:. .. code-block:: text. {; ""command"": [; ""/vep"",; ""--format"", ""vcf"",; ""__OUTPUT_FORMAT_F",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:38244,Modifiability,config,configuration,38244,"mbl.org/info/docs/tools/vep/index.html>`__ on the; current dataset and adds the result as a row field. Examples; --------. Add VEP annotations to the dataset:. >>> result = hl.vep(dataset, ""data/vep-configuration.json"") # doctest: +SKIP. Notes; -----. **Installation**. This VEP command only works if you have already installed VEP on your; computing environment. If you use `hailctl dataproc` to start Hail clusters,; installing VEP is achieved by specifying the `--vep` flag. For more detailed instructions,; see :ref:`vep_dataproc`. If you use `hailctl hdinsight`, see :ref:`vep_hdinsight`. **Spark Configuration**. :func:`.vep` needs a configuration file to tell it how to run VEP. This is the ``config`` argument; to the VEP function. If you are using `hailctl dataproc` as mentioned above, you can just use the; default argument for ``config`` and everything will work. If you need to run VEP with Hail in other environments,; there are detailed instructions below. The format of the configuration file is JSON, and :func:`.vep`; expects a JSON object with three fields:. - `command` (array of string) -- The VEP command line to run. The string literal `__OUTPUT_FORMAT_FLAG__` is replaced with `--json` or `--vcf` depending on `csq`.; - `env` (object) -- A map of environment variables to values to add to the environment when invoking the command. The value of each object member must be a string.; - `vep_json_schema` (string): The type of the VEP JSON schema (as produced by the VEP when invoked with the `--json` option). Note: This is the old-style 'parseable' Hail type syntax. This will change. Here is an example configuration file for invoking VEP release 85; installed in `/vep` with the Loftee plugin:. .. code-block:: text. {; ""command"": [; ""/vep"",; ""--format"", ""vcf"",; ""__OUTPUT_FORMAT_FLAG__"",; ""--everything"",; ""--allele_number"",; ""--no_stats"",; ""--cache"", ""--offline"",; ""--minimal"",; ""--assembly"", ""GRCh37"",; ""--plugin"", ""LoF,human_ancestor_fa:/root/.vep/loftee_data/human_ances",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:38537,Modifiability,variab,variables,38537," if you have already installed VEP on your; computing environment. If you use `hailctl dataproc` to start Hail clusters,; installing VEP is achieved by specifying the `--vep` flag. For more detailed instructions,; see :ref:`vep_dataproc`. If you use `hailctl hdinsight`, see :ref:`vep_hdinsight`. **Spark Configuration**. :func:`.vep` needs a configuration file to tell it how to run VEP. This is the ``config`` argument; to the VEP function. If you are using `hailctl dataproc` as mentioned above, you can just use the; default argument for ``config`` and everything will work. If you need to run VEP with Hail in other environments,; there are detailed instructions below. The format of the configuration file is JSON, and :func:`.vep`; expects a JSON object with three fields:. - `command` (array of string) -- The VEP command line to run. The string literal `__OUTPUT_FORMAT_FLAG__` is replaced with `--json` or `--vcf` depending on `csq`.; - `env` (object) -- A map of environment variables to values to add to the environment when invoking the command. The value of each object member must be a string.; - `vep_json_schema` (string): The type of the VEP JSON schema (as produced by the VEP when invoked with the `--json` option). Note: This is the old-style 'parseable' Hail type syntax. This will change. Here is an example configuration file for invoking VEP release 85; installed in `/vep` with the Loftee plugin:. .. code-block:: text. {; ""command"": [; ""/vep"",; ""--format"", ""vcf"",; ""__OUTPUT_FORMAT_FLAG__"",; ""--everything"",; ""--allele_number"",; ""--no_stats"",; ""--cache"", ""--offline"",; ""--minimal"",; ""--assembly"", ""GRCh37"",; ""--plugin"", ""LoF,human_ancestor_fa:/root/.vep/loftee_data/human_ancestor.fa.gz,filter_position:0.05,min_intron_size:15,conservation_file:/root/.vep/loftee_data/phylocsf_gerp.sql,gerp_file:/root/.vep/loftee_data/GERP_scores.final.sorted.txt.gz"",; ""-o"", ""STDOUT""; ],; ""env"": {; ""PERL5LIB"": ""/vep_data/loftee""; },; ""vep_json_schema"": ""Struct{assembly_name:String,allele",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:38882,Modifiability,config,configuration,38882,"ll it how to run VEP. This is the ``config`` argument; to the VEP function. If you are using `hailctl dataproc` as mentioned above, you can just use the; default argument for ``config`` and everything will work. If you need to run VEP with Hail in other environments,; there are detailed instructions below. The format of the configuration file is JSON, and :func:`.vep`; expects a JSON object with three fields:. - `command` (array of string) -- The VEP command line to run. The string literal `__OUTPUT_FORMAT_FLAG__` is replaced with `--json` or `--vcf` depending on `csq`.; - `env` (object) -- A map of environment variables to values to add to the environment when invoking the command. The value of each object member must be a string.; - `vep_json_schema` (string): The type of the VEP JSON schema (as produced by the VEP when invoked with the `--json` option). Note: This is the old-style 'parseable' Hail type syntax. This will change. Here is an example configuration file for invoking VEP release 85; installed in `/vep` with the Loftee plugin:. .. code-block:: text. {; ""command"": [; ""/vep"",; ""--format"", ""vcf"",; ""__OUTPUT_FORMAT_FLAG__"",; ""--everything"",; ""--allele_number"",; ""--no_stats"",; ""--cache"", ""--offline"",; ""--minimal"",; ""--assembly"", ""GRCh37"",; ""--plugin"", ""LoF,human_ancestor_fa:/root/.vep/loftee_data/human_ancestor.fa.gz,filter_position:0.05,min_intron_size:15,conservation_file:/root/.vep/loftee_data/phylocsf_gerp.sql,gerp_file:/root/.vep/loftee_data/GERP_scores.final.sorted.txt.gz"",; ""-o"", ""STDOUT""; ],; ""env"": {; ""PERL5LIB"": ""/vep_data/loftee""; },; ""vep_json_schema"": ""Struct{assembly_name:String,allele_string:String,ancestral:String,colocated_variants:Array[Struct{aa_allele:String,aa_maf:Float64,afr_allele:String,afr_maf:Float64,allele_string:String,amr_allele:String,amr_maf:Float64,clin_sig:Array[String],end:Int32,eas_allele:String,eas_maf:Float64,ea_allele:String,ea_maf:Float64,eur_allele:String,eur_maf:Float64,exac_adj_allele:String,exac_adj_maf:Float64,exac",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:38966,Modifiability,plugin,plugin,38966,"ll it how to run VEP. This is the ``config`` argument; to the VEP function. If you are using `hailctl dataproc` as mentioned above, you can just use the; default argument for ``config`` and everything will work. If you need to run VEP with Hail in other environments,; there are detailed instructions below. The format of the configuration file is JSON, and :func:`.vep`; expects a JSON object with three fields:. - `command` (array of string) -- The VEP command line to run. The string literal `__OUTPUT_FORMAT_FLAG__` is replaced with `--json` or `--vcf` depending on `csq`.; - `env` (object) -- A map of environment variables to values to add to the environment when invoking the command. The value of each object member must be a string.; - `vep_json_schema` (string): The type of the VEP JSON schema (as produced by the VEP when invoked with the `--json` option). Note: This is the old-style 'parseable' Hail type syntax. This will change. Here is an example configuration file for invoking VEP release 85; installed in `/vep` with the Loftee plugin:. .. code-block:: text. {; ""command"": [; ""/vep"",; ""--format"", ""vcf"",; ""__OUTPUT_FORMAT_FLAG__"",; ""--everything"",; ""--allele_number"",; ""--no_stats"",; ""--cache"", ""--offline"",; ""--minimal"",; ""--assembly"", ""GRCh37"",; ""--plugin"", ""LoF,human_ancestor_fa:/root/.vep/loftee_data/human_ancestor.fa.gz,filter_position:0.05,min_intron_size:15,conservation_file:/root/.vep/loftee_data/phylocsf_gerp.sql,gerp_file:/root/.vep/loftee_data/GERP_scores.final.sorted.txt.gz"",; ""-o"", ""STDOUT""; ],; ""env"": {; ""PERL5LIB"": ""/vep_data/loftee""; },; ""vep_json_schema"": ""Struct{assembly_name:String,allele_string:String,ancestral:String,colocated_variants:Array[Struct{aa_allele:String,aa_maf:Float64,afr_allele:String,afr_maf:Float64,allele_string:String,amr_allele:String,amr_maf:Float64,clin_sig:Array[String],end:Int32,eas_allele:String,eas_maf:Float64,ea_allele:String,ea_maf:Float64,eur_allele:String,eur_maf:Float64,exac_adj_allele:String,exac_adj_maf:Float64,exac",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:39189,Modifiability,plugin,plugin,39189,"ything will work. If you need to run VEP with Hail in other environments,; there are detailed instructions below. The format of the configuration file is JSON, and :func:`.vep`; expects a JSON object with three fields:. - `command` (array of string) -- The VEP command line to run. The string literal `__OUTPUT_FORMAT_FLAG__` is replaced with `--json` or `--vcf` depending on `csq`.; - `env` (object) -- A map of environment variables to values to add to the environment when invoking the command. The value of each object member must be a string.; - `vep_json_schema` (string): The type of the VEP JSON schema (as produced by the VEP when invoked with the `--json` option). Note: This is the old-style 'parseable' Hail type syntax. This will change. Here is an example configuration file for invoking VEP release 85; installed in `/vep` with the Loftee plugin:. .. code-block:: text. {; ""command"": [; ""/vep"",; ""--format"", ""vcf"",; ""__OUTPUT_FORMAT_FLAG__"",; ""--everything"",; ""--allele_number"",; ""--no_stats"",; ""--cache"", ""--offline"",; ""--minimal"",; ""--assembly"", ""GRCh37"",; ""--plugin"", ""LoF,human_ancestor_fa:/root/.vep/loftee_data/human_ancestor.fa.gz,filter_position:0.05,min_intron_size:15,conservation_file:/root/.vep/loftee_data/phylocsf_gerp.sql,gerp_file:/root/.vep/loftee_data/GERP_scores.final.sorted.txt.gz"",; ""-o"", ""STDOUT""; ],; ""env"": {; ""PERL5LIB"": ""/vep_data/loftee""; },; ""vep_json_schema"": ""Struct{assembly_name:String,allele_string:String,ancestral:String,colocated_variants:Array[Struct{aa_allele:String,aa_maf:Float64,afr_allele:String,afr_maf:Float64,allele_string:String,amr_allele:String,amr_maf:Float64,clin_sig:Array[String],end:Int32,eas_allele:String,eas_maf:Float64,ea_allele:String,ea_maf:Float64,eur_allele:String,eur_maf:Float64,exac_adj_allele:String,exac_adj_maf:Float64,exac_allele:String,exac_afr_allele:String,exac_afr_maf:Float64,exac_amr_allele:String,exac_amr_maf:Float64,exac_eas_allele:String,exac_eas_maf:Float64,exac_fin_allele:String,exac_fin_maf:Float64,exa",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:41977,Modifiability,config,configuration,41977,"ring],impact:String,minimised:Int32,regulatory_feature_id:String,variant_allele:String}],seq_region_name:String,start:Int32,strand:Int32,transcript_consequences:Array[Struct{allele_num:Int32,amino_acids:String,biotype:String,canonical:Int32,ccds:String,cdna_start:Int32,cdna_end:Int32,cds_end:Int32,cds_start:Int32,codons:String,consequence_terms:Array[String],distance:Int32,domains:Array[Struct{db:String,name:String}],exon:String,gene_id:String,gene_pheno:Int32,gene_symbol:String,gene_symbol_source:String,hgnc_id:String,hgvsc:String,hgvsp:String,hgvs_offset:Int32,impact:String,intron:String,lof:String,lof_flags:String,lof_filter:String,lof_info:String,minimised:Int32,polyphen_prediction:String,polyphen_score:Float64,protein_end:Int32,protein_start:Int32,protein_id:String,sift_prediction:String,sift_score:Float64,strand:Int32,swissprot:String,transcript_id:String,trembl:String,uniparc:String,variant_allele:String}],variant_class:String}""; }. The configuration files used by``hailctl dataproc`` can be found at the following locations:. - ``GRCh37``: ``gs://hail-us-central1-vep/vep85-loftee-gcloud.json``; - ``GRCh38``: ``gs://hail-us-central1-vep/vep95-GRCh38-loftee-gcloud.json``. If no config file is specified, this function will check to see if environment variable `VEP_CONFIG_URI` is set with a path to a config file. **Batch Service Configuration**. If no config is specified, Hail will use the user's Service configuration parameters to find a supported VEP configuration.; However, if you wish to use your own implementation of VEP, then see the documentation for :class:`.VEPConfig`. **Annotations**. A new row field is added in the location specified by `name` with type given; by the type given by the `json_vep_schema` (if `csq` is ``False``) or; :class:`.tarray` of :py:data:`.tstr` (if `csq` is ``True``). If csq is ``True``, then the CSQ header string is also added as a global; field with name ``name + '_csq_header'``. Parameters; ----------; dataset : :class:`.MatrixT",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:42220,Modifiability,config,config,42220,"nt32,cdna_end:Int32,cds_end:Int32,cds_start:Int32,codons:String,consequence_terms:Array[String],distance:Int32,domains:Array[Struct{db:String,name:String}],exon:String,gene_id:String,gene_pheno:Int32,gene_symbol:String,gene_symbol_source:String,hgnc_id:String,hgvsc:String,hgvsp:String,hgvs_offset:Int32,impact:String,intron:String,lof:String,lof_flags:String,lof_filter:String,lof_info:String,minimised:Int32,polyphen_prediction:String,polyphen_score:Float64,protein_end:Int32,protein_start:Int32,protein_id:String,sift_prediction:String,sift_score:Float64,strand:Int32,swissprot:String,transcript_id:String,trembl:String,uniparc:String,variant_allele:String}],variant_class:String}""; }. The configuration files used by``hailctl dataproc`` can be found at the following locations:. - ``GRCh37``: ``gs://hail-us-central1-vep/vep85-loftee-gcloud.json``; - ``GRCh38``: ``gs://hail-us-central1-vep/vep95-GRCh38-loftee-gcloud.json``. If no config file is specified, this function will check to see if environment variable `VEP_CONFIG_URI` is set with a path to a config file. **Batch Service Configuration**. If no config is specified, Hail will use the user's Service configuration parameters to find a supported VEP configuration.; However, if you wish to use your own implementation of VEP, then see the documentation for :class:`.VEPConfig`. **Annotations**. A new row field is added in the location specified by `name` with type given; by the type given by the `json_vep_schema` (if `csq` is ``False``) or; :class:`.tarray` of :py:data:`.tstr` (if `csq` is ``True``). If csq is ``True``, then the CSQ header string is also added as a global; field with name ``name + '_csq_header'``. Parameters; ----------; dataset : :class:`.MatrixTable` or :class:`.Table`; Dataset.; config : :class:`str` or :class:`.VEPConfig`, optional; Path to VEP configuration file or a VEPConfig object.; block_size : :obj:`int`; Number of rows to process per VEP invocation.; name : :class:`str`; Name for resulting row fi",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:42293,Modifiability,variab,variable,42293,"nt32,cdna_end:Int32,cds_end:Int32,cds_start:Int32,codons:String,consequence_terms:Array[String],distance:Int32,domains:Array[Struct{db:String,name:String}],exon:String,gene_id:String,gene_pheno:Int32,gene_symbol:String,gene_symbol_source:String,hgnc_id:String,hgvsc:String,hgvsp:String,hgvs_offset:Int32,impact:String,intron:String,lof:String,lof_flags:String,lof_filter:String,lof_info:String,minimised:Int32,polyphen_prediction:String,polyphen_score:Float64,protein_end:Int32,protein_start:Int32,protein_id:String,sift_prediction:String,sift_score:Float64,strand:Int32,swissprot:String,transcript_id:String,trembl:String,uniparc:String,variant_allele:String}],variant_class:String}""; }. The configuration files used by``hailctl dataproc`` can be found at the following locations:. - ``GRCh37``: ``gs://hail-us-central1-vep/vep85-loftee-gcloud.json``; - ``GRCh38``: ``gs://hail-us-central1-vep/vep95-GRCh38-loftee-gcloud.json``. If no config file is specified, this function will check to see if environment variable `VEP_CONFIG_URI` is set with a path to a config file. **Batch Service Configuration**. If no config is specified, Hail will use the user's Service configuration parameters to find a supported VEP configuration.; However, if you wish to use your own implementation of VEP, then see the documentation for :class:`.VEPConfig`. **Annotations**. A new row field is added in the location specified by `name` with type given; by the type given by the `json_vep_schema` (if `csq` is ``False``) or; :class:`.tarray` of :py:data:`.tstr` (if `csq` is ``True``). If csq is ``True``, then the CSQ header string is also added as a global; field with name ``name + '_csq_header'``. Parameters; ----------; dataset : :class:`.MatrixTable` or :class:`.Table`; Dataset.; config : :class:`str` or :class:`.VEPConfig`, optional; Path to VEP configuration file or a VEPConfig object.; block_size : :obj:`int`; Number of rows to process per VEP invocation.; name : :class:`str`; Name for resulting row fi",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:42343,Modifiability,config,config,42343,"nt32,cdna_end:Int32,cds_end:Int32,cds_start:Int32,codons:String,consequence_terms:Array[String],distance:Int32,domains:Array[Struct{db:String,name:String}],exon:String,gene_id:String,gene_pheno:Int32,gene_symbol:String,gene_symbol_source:String,hgnc_id:String,hgvsc:String,hgvsp:String,hgvs_offset:Int32,impact:String,intron:String,lof:String,lof_flags:String,lof_filter:String,lof_info:String,minimised:Int32,polyphen_prediction:String,polyphen_score:Float64,protein_end:Int32,protein_start:Int32,protein_id:String,sift_prediction:String,sift_score:Float64,strand:Int32,swissprot:String,transcript_id:String,trembl:String,uniparc:String,variant_allele:String}],variant_class:String}""; }. The configuration files used by``hailctl dataproc`` can be found at the following locations:. - ``GRCh37``: ``gs://hail-us-central1-vep/vep85-loftee-gcloud.json``; - ``GRCh38``: ``gs://hail-us-central1-vep/vep95-GRCh38-loftee-gcloud.json``. If no config file is specified, this function will check to see if environment variable `VEP_CONFIG_URI` is set with a path to a config file. **Batch Service Configuration**. If no config is specified, Hail will use the user's Service configuration parameters to find a supported VEP configuration.; However, if you wish to use your own implementation of VEP, then see the documentation for :class:`.VEPConfig`. **Annotations**. A new row field is added in the location specified by `name` with type given; by the type given by the `json_vep_schema` (if `csq` is ``False``) or; :class:`.tarray` of :py:data:`.tstr` (if `csq` is ``True``). If csq is ``True``, then the CSQ header string is also added as a global; field with name ``name + '_csq_header'``. Parameters; ----------; dataset : :class:`.MatrixTable` or :class:`.Table`; Dataset.; config : :class:`str` or :class:`.VEPConfig`, optional; Path to VEP configuration file or a VEPConfig object.; block_size : :obj:`int`; Number of rows to process per VEP invocation.; name : :class:`str`; Name for resulting row fi",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:42395,Modifiability,config,config,42395,"g,gene_id:String,gene_pheno:Int32,gene_symbol:String,gene_symbol_source:String,hgnc_id:String,hgvsc:String,hgvsp:String,hgvs_offset:Int32,impact:String,intron:String,lof:String,lof_flags:String,lof_filter:String,lof_info:String,minimised:Int32,polyphen_prediction:String,polyphen_score:Float64,protein_end:Int32,protein_start:Int32,protein_id:String,sift_prediction:String,sift_score:Float64,strand:Int32,swissprot:String,transcript_id:String,trembl:String,uniparc:String,variant_allele:String}],variant_class:String}""; }. The configuration files used by``hailctl dataproc`` can be found at the following locations:. - ``GRCh37``: ``gs://hail-us-central1-vep/vep85-loftee-gcloud.json``; - ``GRCh38``: ``gs://hail-us-central1-vep/vep95-GRCh38-loftee-gcloud.json``. If no config file is specified, this function will check to see if environment variable `VEP_CONFIG_URI` is set with a path to a config file. **Batch Service Configuration**. If no config is specified, Hail will use the user's Service configuration parameters to find a supported VEP configuration.; However, if you wish to use your own implementation of VEP, then see the documentation for :class:`.VEPConfig`. **Annotations**. A new row field is added in the location specified by `name` with type given; by the type given by the `json_vep_schema` (if `csq` is ``False``) or; :class:`.tarray` of :py:data:`.tstr` (if `csq` is ``True``). If csq is ``True``, then the CSQ header string is also added as a global; field with name ``name + '_csq_header'``. Parameters; ----------; dataset : :class:`.MatrixTable` or :class:`.Table`; Dataset.; config : :class:`str` or :class:`.VEPConfig`, optional; Path to VEP configuration file or a VEPConfig object.; block_size : :obj:`int`; Number of rows to process per VEP invocation.; name : :class:`str`; Name for resulting row field.; csq : :obj:`bool`; If ``True``, annotates with the VCF CSQ field as a :py:data:`.tstr`.; If ``False``, annotates as the `vep_json_schema`.; tolerate_parse_error",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:42449,Modifiability,config,configuration,42449,"g,gene_id:String,gene_pheno:Int32,gene_symbol:String,gene_symbol_source:String,hgnc_id:String,hgvsc:String,hgvsp:String,hgvs_offset:Int32,impact:String,intron:String,lof:String,lof_flags:String,lof_filter:String,lof_info:String,minimised:Int32,polyphen_prediction:String,polyphen_score:Float64,protein_end:Int32,protein_start:Int32,protein_id:String,sift_prediction:String,sift_score:Float64,strand:Int32,swissprot:String,transcript_id:String,trembl:String,uniparc:String,variant_allele:String}],variant_class:String}""; }. The configuration files used by``hailctl dataproc`` can be found at the following locations:. - ``GRCh37``: ``gs://hail-us-central1-vep/vep85-loftee-gcloud.json``; - ``GRCh38``: ``gs://hail-us-central1-vep/vep95-GRCh38-loftee-gcloud.json``. If no config file is specified, this function will check to see if environment variable `VEP_CONFIG_URI` is set with a path to a config file. **Batch Service Configuration**. If no config is specified, Hail will use the user's Service configuration parameters to find a supported VEP configuration.; However, if you wish to use your own implementation of VEP, then see the documentation for :class:`.VEPConfig`. **Annotations**. A new row field is added in the location specified by `name` with type given; by the type given by the `json_vep_schema` (if `csq` is ``False``) or; :class:`.tarray` of :py:data:`.tstr` (if `csq` is ``True``). If csq is ``True``, then the CSQ header string is also added as a global; field with name ``name + '_csq_header'``. Parameters; ----------; dataset : :class:`.MatrixTable` or :class:`.Table`; Dataset.; config : :class:`str` or :class:`.VEPConfig`, optional; Path to VEP configuration file or a VEPConfig object.; block_size : :obj:`int`; Number of rows to process per VEP invocation.; name : :class:`str`; Name for resulting row field.; csq : :obj:`bool`; If ``True``, annotates with the VCF CSQ field as a :py:data:`.tstr`.; If ``False``, annotates as the `vep_json_schema`.; tolerate_parse_error",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:42498,Modifiability,config,configuration,42498,"g,gene_id:String,gene_pheno:Int32,gene_symbol:String,gene_symbol_source:String,hgnc_id:String,hgvsc:String,hgvsp:String,hgvs_offset:Int32,impact:String,intron:String,lof:String,lof_flags:String,lof_filter:String,lof_info:String,minimised:Int32,polyphen_prediction:String,polyphen_score:Float64,protein_end:Int32,protein_start:Int32,protein_id:String,sift_prediction:String,sift_score:Float64,strand:Int32,swissprot:String,transcript_id:String,trembl:String,uniparc:String,variant_allele:String}],variant_class:String}""; }. The configuration files used by``hailctl dataproc`` can be found at the following locations:. - ``GRCh37``: ``gs://hail-us-central1-vep/vep85-loftee-gcloud.json``; - ``GRCh38``: ``gs://hail-us-central1-vep/vep95-GRCh38-loftee-gcloud.json``. If no config file is specified, this function will check to see if environment variable `VEP_CONFIG_URI` is set with a path to a config file. **Batch Service Configuration**. If no config is specified, Hail will use the user's Service configuration parameters to find a supported VEP configuration.; However, if you wish to use your own implementation of VEP, then see the documentation for :class:`.VEPConfig`. **Annotations**. A new row field is added in the location specified by `name` with type given; by the type given by the `json_vep_schema` (if `csq` is ``False``) or; :class:`.tarray` of :py:data:`.tstr` (if `csq` is ``True``). If csq is ``True``, then the CSQ header string is also added as a global; field with name ``name + '_csq_header'``. Parameters; ----------; dataset : :class:`.MatrixTable` or :class:`.Table`; Dataset.; config : :class:`str` or :class:`.VEPConfig`, optional; Path to VEP configuration file or a VEPConfig object.; block_size : :obj:`int`; Number of rows to process per VEP invocation.; name : :class:`str`; Name for resulting row field.; csq : :obj:`bool`; If ``True``, annotates with the VCF CSQ field as a :py:data:`.tstr`.; If ``False``, annotates as the `vep_json_schema`.; tolerate_parse_error",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:43055,Modifiability,config,config,43055,"GRCh37``: ``gs://hail-us-central1-vep/vep85-loftee-gcloud.json``; - ``GRCh38``: ``gs://hail-us-central1-vep/vep95-GRCh38-loftee-gcloud.json``. If no config file is specified, this function will check to see if environment variable `VEP_CONFIG_URI` is set with a path to a config file. **Batch Service Configuration**. If no config is specified, Hail will use the user's Service configuration parameters to find a supported VEP configuration.; However, if you wish to use your own implementation of VEP, then see the documentation for :class:`.VEPConfig`. **Annotations**. A new row field is added in the location specified by `name` with type given; by the type given by the `json_vep_schema` (if `csq` is ``False``) or; :class:`.tarray` of :py:data:`.tstr` (if `csq` is ``True``). If csq is ``True``, then the CSQ header string is also added as a global; field with name ``name + '_csq_header'``. Parameters; ----------; dataset : :class:`.MatrixTable` or :class:`.Table`; Dataset.; config : :class:`str` or :class:`.VEPConfig`, optional; Path to VEP configuration file or a VEPConfig object.; block_size : :obj:`int`; Number of rows to process per VEP invocation.; name : :class:`str`; Name for resulting row field.; csq : :obj:`bool`; If ``True``, annotates with the VCF CSQ field as a :py:data:`.tstr`.; If ``False``, annotates as the `vep_json_schema`.; tolerate_parse_error : :obj:`bool`; If ``True``, ignore invalid JSON produced by VEP and return a missing annotation. Returns; -------; :class:`.MatrixTable` or :class:`.Table`; Dataset with new row-indexed field `name` containing VEP annotations. """""". if isinstance(dataset, MatrixTable):; require_row_key_variant(dataset, 'vep'); ht = dataset.select_rows().rows(); else:; require_table_key_variant(dataset, 'vep'); ht = dataset.select(). ht = ht.distinct(). backend = hl.current_backend(); if isinstance(backend, ServiceBackend):; with hl.TemporaryDirectory(prefix='qob/vep/inputs/') as vep_input_path:; with hl.TemporaryDirectory(prefix='",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:43123,Modifiability,config,configuration,43123,"ud.json``; - ``GRCh38``: ``gs://hail-us-central1-vep/vep95-GRCh38-loftee-gcloud.json``. If no config file is specified, this function will check to see if environment variable `VEP_CONFIG_URI` is set with a path to a config file. **Batch Service Configuration**. If no config is specified, Hail will use the user's Service configuration parameters to find a supported VEP configuration.; However, if you wish to use your own implementation of VEP, then see the documentation for :class:`.VEPConfig`. **Annotations**. A new row field is added in the location specified by `name` with type given; by the type given by the `json_vep_schema` (if `csq` is ``False``) or; :class:`.tarray` of :py:data:`.tstr` (if `csq` is ``True``). If csq is ``True``, then the CSQ header string is also added as a global; field with name ``name + '_csq_header'``. Parameters; ----------; dataset : :class:`.MatrixTable` or :class:`.Table`; Dataset.; config : :class:`str` or :class:`.VEPConfig`, optional; Path to VEP configuration file or a VEPConfig object.; block_size : :obj:`int`; Number of rows to process per VEP invocation.; name : :class:`str`; Name for resulting row field.; csq : :obj:`bool`; If ``True``, annotates with the VCF CSQ field as a :py:data:`.tstr`.; If ``False``, annotates as the `vep_json_schema`.; tolerate_parse_error : :obj:`bool`; If ``True``, ignore invalid JSON produced by VEP and return a missing annotation. Returns; -------; :class:`.MatrixTable` or :class:`.Table`; Dataset with new row-indexed field `name` containing VEP annotations. """""". if isinstance(dataset, MatrixTable):; require_row_key_variant(dataset, 'vep'); ht = dataset.select_rows().rows(); else:; require_table_key_variant(dataset, 'vep'); ht = dataset.select(). ht = ht.distinct(). backend = hl.current_backend(); if isinstance(backend, ServiceBackend):; with hl.TemporaryDirectory(prefix='qob/vep/inputs/') as vep_input_path:; with hl.TemporaryDirectory(prefix='qob/vep/outputs/') as vep_output_path:; annotations = _s",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:44153,Modifiability,config,config,44153,"fig object.; block_size : :obj:`int`; Number of rows to process per VEP invocation.; name : :class:`str`; Name for resulting row field.; csq : :obj:`bool`; If ``True``, annotates with the VCF CSQ field as a :py:data:`.tstr`.; If ``False``, annotates as the `vep_json_schema`.; tolerate_parse_error : :obj:`bool`; If ``True``, ignore invalid JSON produced by VEP and return a missing annotation. Returns; -------; :class:`.MatrixTable` or :class:`.Table`; Dataset with new row-indexed field `name` containing VEP annotations. """""". if isinstance(dataset, MatrixTable):; require_row_key_variant(dataset, 'vep'); ht = dataset.select_rows().rows(); else:; require_table_key_variant(dataset, 'vep'); ht = dataset.select(). ht = ht.distinct(). backend = hl.current_backend(); if isinstance(backend, ServiceBackend):; with hl.TemporaryDirectory(prefix='qob/vep/inputs/') as vep_input_path:; with hl.TemporaryDirectory(prefix='qob/vep/outputs/') as vep_output_path:; annotations = _service_vep(; backend, ht, config, block_size, csq, tolerate_parse_error, vep_input_path, vep_output_path; ); annotations = annotations.checkpoint(new_temp_file()); else:; if config is None:; maybe_cloud_spark_provider = guess_cloud_spark_provider(); maybe_config = os.getenv(""VEP_CONFIG_URI""); if maybe_config is not None:; config = maybe_config; elif maybe_cloud_spark_provider == 'hdinsight':; warning(; 'Assuming you are in a hailctl hdinsight cluster. If not, specify the config parameter to `hl.vep`.'; ); config = 'file:/vep_data/vep-azure.json'; else:; raise ValueError(""No config set and VEP_CONFIG_URI was not set.""). annotations = Table(; TableToTableApply(; ht._tir,; {; 'name': 'VEP',; 'config': config,; 'csq': csq,; 'blockSize': block_size,; 'tolerateParseError': tolerate_parse_error,; },; ); ).persist(). if csq:; dataset = dataset.annotate_globals(**{name + '_csq_header': annotations.index_globals()['vep_csq_header']}). if isinstance(dataset, MatrixTable):; vep = annotations[dataset.row_key]; return datase",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:44301,Modifiability,config,config,44301,"tes with the VCF CSQ field as a :py:data:`.tstr`.; If ``False``, annotates as the `vep_json_schema`.; tolerate_parse_error : :obj:`bool`; If ``True``, ignore invalid JSON produced by VEP and return a missing annotation. Returns; -------; :class:`.MatrixTable` or :class:`.Table`; Dataset with new row-indexed field `name` containing VEP annotations. """""". if isinstance(dataset, MatrixTable):; require_row_key_variant(dataset, 'vep'); ht = dataset.select_rows().rows(); else:; require_table_key_variant(dataset, 'vep'); ht = dataset.select(). ht = ht.distinct(). backend = hl.current_backend(); if isinstance(backend, ServiceBackend):; with hl.TemporaryDirectory(prefix='qob/vep/inputs/') as vep_input_path:; with hl.TemporaryDirectory(prefix='qob/vep/outputs/') as vep_output_path:; annotations = _service_vep(; backend, ht, config, block_size, csq, tolerate_parse_error, vep_input_path, vep_output_path; ); annotations = annotations.checkpoint(new_temp_file()); else:; if config is None:; maybe_cloud_spark_provider = guess_cloud_spark_provider(); maybe_config = os.getenv(""VEP_CONFIG_URI""); if maybe_config is not None:; config = maybe_config; elif maybe_cloud_spark_provider == 'hdinsight':; warning(; 'Assuming you are in a hailctl hdinsight cluster. If not, specify the config parameter to `hl.vep`.'; ); config = 'file:/vep_data/vep-azure.json'; else:; raise ValueError(""No config set and VEP_CONFIG_URI was not set.""). annotations = Table(; TableToTableApply(; ht._tir,; {; 'name': 'VEP',; 'config': config,; 'csq': csq,; 'blockSize': block_size,; 'tolerateParseError': tolerate_parse_error,; },; ); ).persist(). if csq:; dataset = dataset.annotate_globals(**{name + '_csq_header': annotations.index_globals()['vep_csq_header']}). if isinstance(dataset, MatrixTable):; vep = annotations[dataset.row_key]; return dataset.annotate_rows(**{name: vep.vep, name + '_proc_id': vep.vep_proc_id}); else:; vep = annotations[dataset.key]; return dataset.annotate(**{name: vep.vep, name + '_proc_id': vep.",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:44451,Modifiability,config,config,44451,"valid JSON produced by VEP and return a missing annotation. Returns; -------; :class:`.MatrixTable` or :class:`.Table`; Dataset with new row-indexed field `name` containing VEP annotations. """""". if isinstance(dataset, MatrixTable):; require_row_key_variant(dataset, 'vep'); ht = dataset.select_rows().rows(); else:; require_table_key_variant(dataset, 'vep'); ht = dataset.select(). ht = ht.distinct(). backend = hl.current_backend(); if isinstance(backend, ServiceBackend):; with hl.TemporaryDirectory(prefix='qob/vep/inputs/') as vep_input_path:; with hl.TemporaryDirectory(prefix='qob/vep/outputs/') as vep_output_path:; annotations = _service_vep(; backend, ht, config, block_size, csq, tolerate_parse_error, vep_input_path, vep_output_path; ); annotations = annotations.checkpoint(new_temp_file()); else:; if config is None:; maybe_cloud_spark_provider = guess_cloud_spark_provider(); maybe_config = os.getenv(""VEP_CONFIG_URI""); if maybe_config is not None:; config = maybe_config; elif maybe_cloud_spark_provider == 'hdinsight':; warning(; 'Assuming you are in a hailctl hdinsight cluster. If not, specify the config parameter to `hl.vep`.'; ); config = 'file:/vep_data/vep-azure.json'; else:; raise ValueError(""No config set and VEP_CONFIG_URI was not set.""). annotations = Table(; TableToTableApply(; ht._tir,; {; 'name': 'VEP',; 'config': config,; 'csq': csq,; 'blockSize': block_size,; 'tolerateParseError': tolerate_parse_error,; },; ); ).persist(). if csq:; dataset = dataset.annotate_globals(**{name + '_csq_header': annotations.index_globals()['vep_csq_header']}). if isinstance(dataset, MatrixTable):; vep = annotations[dataset.row_key]; return dataset.annotate_rows(**{name: vep.vep, name + '_proc_id': vep.vep_proc_id}); else:; vep = annotations[dataset.key]; return dataset.annotate(**{name: vep.vep, name + '_proc_id': vep.vep_proc_id}). [docs]@typecheck(dataset=oneof(Table, MatrixTable), config=str, block_size=int, name=str); def nirvana(dataset: Union[MatrixTable, Table], config",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:44603,Modifiability,config,config,44603,"e`; Dataset with new row-indexed field `name` containing VEP annotations. """""". if isinstance(dataset, MatrixTable):; require_row_key_variant(dataset, 'vep'); ht = dataset.select_rows().rows(); else:; require_table_key_variant(dataset, 'vep'); ht = dataset.select(). ht = ht.distinct(). backend = hl.current_backend(); if isinstance(backend, ServiceBackend):; with hl.TemporaryDirectory(prefix='qob/vep/inputs/') as vep_input_path:; with hl.TemporaryDirectory(prefix='qob/vep/outputs/') as vep_output_path:; annotations = _service_vep(; backend, ht, config, block_size, csq, tolerate_parse_error, vep_input_path, vep_output_path; ); annotations = annotations.checkpoint(new_temp_file()); else:; if config is None:; maybe_cloud_spark_provider = guess_cloud_spark_provider(); maybe_config = os.getenv(""VEP_CONFIG_URI""); if maybe_config is not None:; config = maybe_config; elif maybe_cloud_spark_provider == 'hdinsight':; warning(; 'Assuming you are in a hailctl hdinsight cluster. If not, specify the config parameter to `hl.vep`.'; ); config = 'file:/vep_data/vep-azure.json'; else:; raise ValueError(""No config set and VEP_CONFIG_URI was not set.""). annotations = Table(; TableToTableApply(; ht._tir,; {; 'name': 'VEP',; 'config': config,; 'csq': csq,; 'blockSize': block_size,; 'tolerateParseError': tolerate_parse_error,; },; ); ).persist(). if csq:; dataset = dataset.annotate_globals(**{name + '_csq_header': annotations.index_globals()['vep_csq_header']}). if isinstance(dataset, MatrixTable):; vep = annotations[dataset.row_key]; return dataset.annotate_rows(**{name: vep.vep, name + '_proc_id': vep.vep_proc_id}); else:; vep = annotations[dataset.key]; return dataset.annotate(**{name: vep.vep, name + '_proc_id': vep.vep_proc_id}). [docs]@typecheck(dataset=oneof(Table, MatrixTable), config=str, block_size=int, name=str); def nirvana(dataset: Union[MatrixTable, Table], config, block_size=500000, name='nirvana'):; """"""Annotate variants using `Nirvana <https://github.com/Illumina/Nirvana>`_. ",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:44638,Modifiability,config,config,44638,"ntaining VEP annotations. """""". if isinstance(dataset, MatrixTable):; require_row_key_variant(dataset, 'vep'); ht = dataset.select_rows().rows(); else:; require_table_key_variant(dataset, 'vep'); ht = dataset.select(). ht = ht.distinct(). backend = hl.current_backend(); if isinstance(backend, ServiceBackend):; with hl.TemporaryDirectory(prefix='qob/vep/inputs/') as vep_input_path:; with hl.TemporaryDirectory(prefix='qob/vep/outputs/') as vep_output_path:; annotations = _service_vep(; backend, ht, config, block_size, csq, tolerate_parse_error, vep_input_path, vep_output_path; ); annotations = annotations.checkpoint(new_temp_file()); else:; if config is None:; maybe_cloud_spark_provider = guess_cloud_spark_provider(); maybe_config = os.getenv(""VEP_CONFIG_URI""); if maybe_config is not None:; config = maybe_config; elif maybe_cloud_spark_provider == 'hdinsight':; warning(; 'Assuming you are in a hailctl hdinsight cluster. If not, specify the config parameter to `hl.vep`.'; ); config = 'file:/vep_data/vep-azure.json'; else:; raise ValueError(""No config set and VEP_CONFIG_URI was not set.""). annotations = Table(; TableToTableApply(; ht._tir,; {; 'name': 'VEP',; 'config': config,; 'csq': csq,; 'blockSize': block_size,; 'tolerateParseError': tolerate_parse_error,; },; ); ).persist(). if csq:; dataset = dataset.annotate_globals(**{name + '_csq_header': annotations.index_globals()['vep_csq_header']}). if isinstance(dataset, MatrixTable):; vep = annotations[dataset.row_key]; return dataset.annotate_rows(**{name: vep.vep, name + '_proc_id': vep.vep_proc_id}); else:; vep = annotations[dataset.key]; return dataset.annotate(**{name: vep.vep, name + '_proc_id': vep.vep_proc_id}). [docs]@typecheck(dataset=oneof(Table, MatrixTable), config=str, block_size=int, name=str); def nirvana(dataset: Union[MatrixTable, Table], config, block_size=500000, name='nirvana'):; """"""Annotate variants using `Nirvana <https://github.com/Illumina/Nirvana>`_. .. include:: ../_templates/experimental.rst. .. ",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:44708,Modifiability,config,config,44708,"xTable):; require_row_key_variant(dataset, 'vep'); ht = dataset.select_rows().rows(); else:; require_table_key_variant(dataset, 'vep'); ht = dataset.select(). ht = ht.distinct(). backend = hl.current_backend(); if isinstance(backend, ServiceBackend):; with hl.TemporaryDirectory(prefix='qob/vep/inputs/') as vep_input_path:; with hl.TemporaryDirectory(prefix='qob/vep/outputs/') as vep_output_path:; annotations = _service_vep(; backend, ht, config, block_size, csq, tolerate_parse_error, vep_input_path, vep_output_path; ); annotations = annotations.checkpoint(new_temp_file()); else:; if config is None:; maybe_cloud_spark_provider = guess_cloud_spark_provider(); maybe_config = os.getenv(""VEP_CONFIG_URI""); if maybe_config is not None:; config = maybe_config; elif maybe_cloud_spark_provider == 'hdinsight':; warning(; 'Assuming you are in a hailctl hdinsight cluster. If not, specify the config parameter to `hl.vep`.'; ); config = 'file:/vep_data/vep-azure.json'; else:; raise ValueError(""No config set and VEP_CONFIG_URI was not set.""). annotations = Table(; TableToTableApply(; ht._tir,; {; 'name': 'VEP',; 'config': config,; 'csq': csq,; 'blockSize': block_size,; 'tolerateParseError': tolerate_parse_error,; },; ); ).persist(). if csq:; dataset = dataset.annotate_globals(**{name + '_csq_header': annotations.index_globals()['vep_csq_header']}). if isinstance(dataset, MatrixTable):; vep = annotations[dataset.row_key]; return dataset.annotate_rows(**{name: vep.vep, name + '_proc_id': vep.vep_proc_id}); else:; vep = annotations[dataset.key]; return dataset.annotate(**{name: vep.vep, name + '_proc_id': vep.vep_proc_id}). [docs]@typecheck(dataset=oneof(Table, MatrixTable), config=str, block_size=int, name=str); def nirvana(dataset: Union[MatrixTable, Table], config, block_size=500000, name='nirvana'):; """"""Annotate variants using `Nirvana <https://github.com/Illumina/Nirvana>`_. .. include:: ../_templates/experimental.rst. .. include:: ../_templates/req_tvariant.rst. :func:`.nirvana` ",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:44826,Modifiability,config,config,44826,". ht = ht.distinct(). backend = hl.current_backend(); if isinstance(backend, ServiceBackend):; with hl.TemporaryDirectory(prefix='qob/vep/inputs/') as vep_input_path:; with hl.TemporaryDirectory(prefix='qob/vep/outputs/') as vep_output_path:; annotations = _service_vep(; backend, ht, config, block_size, csq, tolerate_parse_error, vep_input_path, vep_output_path; ); annotations = annotations.checkpoint(new_temp_file()); else:; if config is None:; maybe_cloud_spark_provider = guess_cloud_spark_provider(); maybe_config = os.getenv(""VEP_CONFIG_URI""); if maybe_config is not None:; config = maybe_config; elif maybe_cloud_spark_provider == 'hdinsight':; warning(; 'Assuming you are in a hailctl hdinsight cluster. If not, specify the config parameter to `hl.vep`.'; ); config = 'file:/vep_data/vep-azure.json'; else:; raise ValueError(""No config set and VEP_CONFIG_URI was not set.""). annotations = Table(; TableToTableApply(; ht._tir,; {; 'name': 'VEP',; 'config': config,; 'csq': csq,; 'blockSize': block_size,; 'tolerateParseError': tolerate_parse_error,; },; ); ).persist(). if csq:; dataset = dataset.annotate_globals(**{name + '_csq_header': annotations.index_globals()['vep_csq_header']}). if isinstance(dataset, MatrixTable):; vep = annotations[dataset.row_key]; return dataset.annotate_rows(**{name: vep.vep, name + '_proc_id': vep.vep_proc_id}); else:; vep = annotations[dataset.key]; return dataset.annotate(**{name: vep.vep, name + '_proc_id': vep.vep_proc_id}). [docs]@typecheck(dataset=oneof(Table, MatrixTable), config=str, block_size=int, name=str); def nirvana(dataset: Union[MatrixTable, Table], config, block_size=500000, name='nirvana'):; """"""Annotate variants using `Nirvana <https://github.com/Illumina/Nirvana>`_. .. include:: ../_templates/experimental.rst. .. include:: ../_templates/req_tvariant.rst. :func:`.nirvana` runs `Nirvana; <https://github.com/Illumina/Nirvana>`_ on the current dataset and adds a; new row field in the location specified by `name`. Examples; -----",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:44835,Modifiability,config,config,44835,". ht = ht.distinct(). backend = hl.current_backend(); if isinstance(backend, ServiceBackend):; with hl.TemporaryDirectory(prefix='qob/vep/inputs/') as vep_input_path:; with hl.TemporaryDirectory(prefix='qob/vep/outputs/') as vep_output_path:; annotations = _service_vep(; backend, ht, config, block_size, csq, tolerate_parse_error, vep_input_path, vep_output_path; ); annotations = annotations.checkpoint(new_temp_file()); else:; if config is None:; maybe_cloud_spark_provider = guess_cloud_spark_provider(); maybe_config = os.getenv(""VEP_CONFIG_URI""); if maybe_config is not None:; config = maybe_config; elif maybe_cloud_spark_provider == 'hdinsight':; warning(; 'Assuming you are in a hailctl hdinsight cluster. If not, specify the config parameter to `hl.vep`.'; ); config = 'file:/vep_data/vep-azure.json'; else:; raise ValueError(""No config set and VEP_CONFIG_URI was not set.""). annotations = Table(; TableToTableApply(; ht._tir,; {; 'name': 'VEP',; 'config': config,; 'csq': csq,; 'blockSize': block_size,; 'tolerateParseError': tolerate_parse_error,; },; ); ).persist(). if csq:; dataset = dataset.annotate_globals(**{name + '_csq_header': annotations.index_globals()['vep_csq_header']}). if isinstance(dataset, MatrixTable):; vep = annotations[dataset.row_key]; return dataset.annotate_rows(**{name: vep.vep, name + '_proc_id': vep.vep_proc_id}); else:; vep = annotations[dataset.key]; return dataset.annotate(**{name: vep.vep, name + '_proc_id': vep.vep_proc_id}). [docs]@typecheck(dataset=oneof(Table, MatrixTable), config=str, block_size=int, name=str); def nirvana(dataset: Union[MatrixTable, Table], config, block_size=500000, name='nirvana'):; """"""Annotate variants using `Nirvana <https://github.com/Illumina/Nirvana>`_. .. include:: ../_templates/experimental.rst. .. include:: ../_templates/req_tvariant.rst. :func:`.nirvana` runs `Nirvana; <https://github.com/Illumina/Nirvana>`_ on the current dataset and adds a; new row field in the location specified by `name`. Examples; -----",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:45396,Modifiability,config,config,45396,"aybe_config; elif maybe_cloud_spark_provider == 'hdinsight':; warning(; 'Assuming you are in a hailctl hdinsight cluster. If not, specify the config parameter to `hl.vep`.'; ); config = 'file:/vep_data/vep-azure.json'; else:; raise ValueError(""No config set and VEP_CONFIG_URI was not set.""). annotations = Table(; TableToTableApply(; ht._tir,; {; 'name': 'VEP',; 'config': config,; 'csq': csq,; 'blockSize': block_size,; 'tolerateParseError': tolerate_parse_error,; },; ); ).persist(). if csq:; dataset = dataset.annotate_globals(**{name + '_csq_header': annotations.index_globals()['vep_csq_header']}). if isinstance(dataset, MatrixTable):; vep = annotations[dataset.row_key]; return dataset.annotate_rows(**{name: vep.vep, name + '_proc_id': vep.vep_proc_id}); else:; vep = annotations[dataset.key]; return dataset.annotate(**{name: vep.vep, name + '_proc_id': vep.vep_proc_id}). [docs]@typecheck(dataset=oneof(Table, MatrixTable), config=str, block_size=int, name=str); def nirvana(dataset: Union[MatrixTable, Table], config, block_size=500000, name='nirvana'):; """"""Annotate variants using `Nirvana <https://github.com/Illumina/Nirvana>`_. .. include:: ../_templates/experimental.rst. .. include:: ../_templates/req_tvariant.rst. :func:`.nirvana` runs `Nirvana; <https://github.com/Illumina/Nirvana>`_ on the current dataset and adds a; new row field in the location specified by `name`. Examples; --------. Add Nirvana annotations to the dataset:. >>> result = hl.nirvana(dataset, ""data/nirvana.properties"") # doctest: +SKIP. **Configuration**. :func:`.nirvana` requires a configuration file. The format is a; `.properties file <https://en.wikipedia.org/wiki/.properties>`__, where each; line defines a property as a key-value pair of the form ``key = value``.; :func:`.nirvana` supports the following properties:. - **hail.nirvana.dotnet** -- Location of dotnet. Optional, default: dotnet.; - **hail.nirvana.path** -- Value of the PATH environment variable when; invoking Nirvana. Optional, by d",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:45483,Modifiability,config,config,45483,"aybe_config; elif maybe_cloud_spark_provider == 'hdinsight':; warning(; 'Assuming you are in a hailctl hdinsight cluster. If not, specify the config parameter to `hl.vep`.'; ); config = 'file:/vep_data/vep-azure.json'; else:; raise ValueError(""No config set and VEP_CONFIG_URI was not set.""). annotations = Table(; TableToTableApply(; ht._tir,; {; 'name': 'VEP',; 'config': config,; 'csq': csq,; 'blockSize': block_size,; 'tolerateParseError': tolerate_parse_error,; },; ); ).persist(). if csq:; dataset = dataset.annotate_globals(**{name + '_csq_header': annotations.index_globals()['vep_csq_header']}). if isinstance(dataset, MatrixTable):; vep = annotations[dataset.row_key]; return dataset.annotate_rows(**{name: vep.vep, name + '_proc_id': vep.vep_proc_id}); else:; vep = annotations[dataset.key]; return dataset.annotate(**{name: vep.vep, name + '_proc_id': vep.vep_proc_id}). [docs]@typecheck(dataset=oneof(Table, MatrixTable), config=str, block_size=int, name=str); def nirvana(dataset: Union[MatrixTable, Table], config, block_size=500000, name='nirvana'):; """"""Annotate variants using `Nirvana <https://github.com/Illumina/Nirvana>`_. .. include:: ../_templates/experimental.rst. .. include:: ../_templates/req_tvariant.rst. :func:`.nirvana` runs `Nirvana; <https://github.com/Illumina/Nirvana>`_ on the current dataset and adds a; new row field in the location specified by `name`. Examples; --------. Add Nirvana annotations to the dataset:. >>> result = hl.nirvana(dataset, ""data/nirvana.properties"") # doctest: +SKIP. **Configuration**. :func:`.nirvana` requires a configuration file. The format is a; `.properties file <https://en.wikipedia.org/wiki/.properties>`__, where each; line defines a property as a key-value pair of the form ``key = value``.; :func:`.nirvana` supports the following properties:. - **hail.nirvana.dotnet** -- Location of dotnet. Optional, default: dotnet.; - **hail.nirvana.path** -- Value of the PATH environment variable when; invoking Nirvana. Optional, by d",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:46039,Modifiability,config,configuration,46039,"bals()['vep_csq_header']}). if isinstance(dataset, MatrixTable):; vep = annotations[dataset.row_key]; return dataset.annotate_rows(**{name: vep.vep, name + '_proc_id': vep.vep_proc_id}); else:; vep = annotations[dataset.key]; return dataset.annotate(**{name: vep.vep, name + '_proc_id': vep.vep_proc_id}). [docs]@typecheck(dataset=oneof(Table, MatrixTable), config=str, block_size=int, name=str); def nirvana(dataset: Union[MatrixTable, Table], config, block_size=500000, name='nirvana'):; """"""Annotate variants using `Nirvana <https://github.com/Illumina/Nirvana>`_. .. include:: ../_templates/experimental.rst. .. include:: ../_templates/req_tvariant.rst. :func:`.nirvana` runs `Nirvana; <https://github.com/Illumina/Nirvana>`_ on the current dataset and adds a; new row field in the location specified by `name`. Examples; --------. Add Nirvana annotations to the dataset:. >>> result = hl.nirvana(dataset, ""data/nirvana.properties"") # doctest: +SKIP. **Configuration**. :func:`.nirvana` requires a configuration file. The format is a; `.properties file <https://en.wikipedia.org/wiki/.properties>`__, where each; line defines a property as a key-value pair of the form ``key = value``.; :func:`.nirvana` supports the following properties:. - **hail.nirvana.dotnet** -- Location of dotnet. Optional, default: dotnet.; - **hail.nirvana.path** -- Value of the PATH environment variable when; invoking Nirvana. Optional, by default PATH is not set.; - **hail.nirvana.location** -- Location of Nirvana.dll. Required.; - **hail.nirvana.reference** -- Location of reference genome. Required.; - **hail.nirvana.cache** -- Location of cache. Required.; - **hail.nirvana.supplementaryAnnotationDirectory** -- Location of; Supplementary Database. Optional, no supplementary database by default. Here is an example ``nirvana.properties`` configuration file:. .. code-block:: text. hail.nirvana.location = /path/to/dotnet/netcoreapp2.0/Nirvana.dll; hail.nirvana.reference = /path/to/nirvana/References/Homo_sapi",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:46415,Modifiability,variab,variable,46415,"ck_size=int, name=str); def nirvana(dataset: Union[MatrixTable, Table], config, block_size=500000, name='nirvana'):; """"""Annotate variants using `Nirvana <https://github.com/Illumina/Nirvana>`_. .. include:: ../_templates/experimental.rst. .. include:: ../_templates/req_tvariant.rst. :func:`.nirvana` runs `Nirvana; <https://github.com/Illumina/Nirvana>`_ on the current dataset and adds a; new row field in the location specified by `name`. Examples; --------. Add Nirvana annotations to the dataset:. >>> result = hl.nirvana(dataset, ""data/nirvana.properties"") # doctest: +SKIP. **Configuration**. :func:`.nirvana` requires a configuration file. The format is a; `.properties file <https://en.wikipedia.org/wiki/.properties>`__, where each; line defines a property as a key-value pair of the form ``key = value``.; :func:`.nirvana` supports the following properties:. - **hail.nirvana.dotnet** -- Location of dotnet. Optional, default: dotnet.; - **hail.nirvana.path** -- Value of the PATH environment variable when; invoking Nirvana. Optional, by default PATH is not set.; - **hail.nirvana.location** -- Location of Nirvana.dll. Required.; - **hail.nirvana.reference** -- Location of reference genome. Required.; - **hail.nirvana.cache** -- Location of cache. Required.; - **hail.nirvana.supplementaryAnnotationDirectory** -- Location of; Supplementary Database. Optional, no supplementary database by default. Here is an example ``nirvana.properties`` configuration file:. .. code-block:: text. hail.nirvana.location = /path/to/dotnet/netcoreapp2.0/Nirvana.dll; hail.nirvana.reference = /path/to/nirvana/References/Homo_sapiens.GRCh37.Nirvana.dat; hail.nirvana.cache = /path/to/nirvana/Cache/GRCh37/Ensembl; hail.nirvana.supplementaryAnnotationDirectory = /path/to/nirvana/SupplementaryDatabase/GRCh37. **Annotations**. A new row field is added in the location specified by `name` with the; following schema:. .. code-block:: text. struct {; chromosome: str,; refAllele: str,; position: int32,; a",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:46867,Modifiability,config,configuration,46867,"-. Add Nirvana annotations to the dataset:. >>> result = hl.nirvana(dataset, ""data/nirvana.properties"") # doctest: +SKIP. **Configuration**. :func:`.nirvana` requires a configuration file. The format is a; `.properties file <https://en.wikipedia.org/wiki/.properties>`__, where each; line defines a property as a key-value pair of the form ``key = value``.; :func:`.nirvana` supports the following properties:. - **hail.nirvana.dotnet** -- Location of dotnet. Optional, default: dotnet.; - **hail.nirvana.path** -- Value of the PATH environment variable when; invoking Nirvana. Optional, by default PATH is not set.; - **hail.nirvana.location** -- Location of Nirvana.dll. Required.; - **hail.nirvana.reference** -- Location of reference genome. Required.; - **hail.nirvana.cache** -- Location of cache. Required.; - **hail.nirvana.supplementaryAnnotationDirectory** -- Location of; Supplementary Database. Optional, no supplementary database by default. Here is an example ``nirvana.properties`` configuration file:. .. code-block:: text. hail.nirvana.location = /path/to/dotnet/netcoreapp2.0/Nirvana.dll; hail.nirvana.reference = /path/to/nirvana/References/Homo_sapiens.GRCh37.Nirvana.dat; hail.nirvana.cache = /path/to/nirvana/Cache/GRCh37/Ensembl; hail.nirvana.supplementaryAnnotationDirectory = /path/to/nirvana/SupplementaryDatabase/GRCh37. **Annotations**. A new row field is added in the location specified by `name` with the; following schema:. .. code-block:: text. struct {; chromosome: str,; refAllele: str,; position: int32,; altAlleles: array<str>,; cytogeneticBand: str,; quality: float64,; filters: array<str>,; jointSomaticNormalQuality: int32,; copyNumber: int32,; strandBias: float64,; recalibratedQuality: float64,; variants: array<struct {; altAllele: str,; refAllele: str,; chromosome: str,; begin: int32,; end: int32,; phylopScore: float64,; isReferenceMinor: bool,; variantType: str,; vid: str,; hgvsg: str,; isRecomposedVariant: bool,; isDecomposedVariant: bool,; regulatoryR",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:51485,Modifiability,inherit,inheritance,51485,"Hc: int32,; asjAf: float64,; asjAc: int32,; asjAn: int32,; asjHc: int32,; sasAf: float64,; sasAc: int32,; sasAn: int32,; sasHc: int32,; failedFilter: bool; },; topmed: struct {; failedFilter: bool,; allAc: int32,; allAn: int32,; allAf: float64,; allHc: int32; },; oneKg: struct {; ancestralAllele: str,; allAf: float64,; allAc: int32,; allAn: int32,; afrAf: float64,; afrAc: int32,; afrAn: int32,; amrAf: float64,; amrAc: int32,; amrAn: int32,; easAf: float64,; easAc: int32,; easAn: int32,; eurAf: float64,; eurAc: int32,; eurAn: int32,; sasAf: float64,; sasAc: int32,; sasAn: int32; },; mitomap: array<struct {; refAllele: str,; altAllele: str,; diseases : array<str>,; hasHomoplasmy: bool,; hasHeteroplasmy: bool,; status: str,; clinicalSignificance: str,; scorePercentile: float64,; isAlleleSpecific: bool,; chromosome: str,; begin: int32,; end: int32,; variantType: str; }; transcripts: struct {; refSeq: array<struct {; transcript: str,; bioType: str,; aminoAcids: str,; cdnaPos: str,; codons: str,; cdsPos: str,; exons: str,; introns: str,; geneId: str,; hgnc: str,; consequence: array<str>,; hgvsc: str,; hgvsp: str,; isCanonical: bool,; polyPhenScore: float64,; polyPhenPrediction: str,; proteinId: str,; proteinPos: str,; siftScore: float64,; siftPrediction: str; }>,; ensembl: array<struct {; transcript: str,; bioType: str,; aminoAcids: str,; cdnaPos: str,; codons: str,; cdsPos: str,; exons: str,; introns: str,; geneId: str,; hgnc: str,; consequence: array<str>,; hgvsc: str,; hgvsp: str,; isCanonical: bool,; polyPhenScore: float64,; polyPhenPrediction: str,; proteinId: str,; proteinPos: str,; siftScore: float64,; siftPrediction: str; }>; },; overlappingGenes: array<str>; }>; genes: array<struct {; name: str,; omim: array<struct {; mimNumber: int32,; hgnc: str,; description: str,; phenotypes: array<struct {; mimNumber: int32,; phenotype: str,; mapping: str,; inheritance: array<str>,; comments: str; }>; }>; exac: struct {; pLi: float64,; pRec: float64,; pNull: float64; }; }>; }.",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:51693,Modifiability,config,config,51693,"sp: str,; isCanonical: bool,; polyPhenScore: float64,; polyPhenPrediction: str,; proteinId: str,; proteinPos: str,; siftScore: float64,; siftPrediction: str; }>,; ensembl: array<struct {; transcript: str,; bioType: str,; aminoAcids: str,; cdnaPos: str,; codons: str,; cdsPos: str,; exons: str,; introns: str,; geneId: str,; hgnc: str,; consequence: array<str>,; hgvsc: str,; hgvsp: str,; isCanonical: bool,; polyPhenScore: float64,; polyPhenPrediction: str,; proteinId: str,; proteinPos: str,; siftScore: float64,; siftPrediction: str; }>; },; overlappingGenes: array<str>; }>; genes: array<struct {; name: str,; omim: array<struct {; mimNumber: int32,; hgnc: str,; description: str,; phenotypes: array<struct {; mimNumber: int32,; phenotype: str,; mapping: str,; inheritance: array<str>,; comments: str; }>; }>; exac: struct {; pLi: float64,; pRec: float64,; pNull: float64; }; }>; }. Parameters; ----------; dataset : :class:`.MatrixTable` or :class:`.Table`; Dataset.; config : :class:`str`; Path to Nirvana configuration file.; block_size : :obj:`int`; Number of rows to process per Nirvana invocation.; name : :class:`str`; Name for resulting row field. Returns; -------; :class:`.MatrixTable` or :class:`.Table`; Dataset with new row-indexed field `name` containing Nirvana annotations.; """"""; if isinstance(dataset, MatrixTable):; require_row_key_variant(dataset, 'nirvana'); ht = dataset.select_rows().rows(); else:; require_table_key_variant(dataset, 'nirvana'); ht = dataset.select(). annotations = Table(; TableToTableApply(ht._tir, {'name': 'Nirvana', 'config': config, 'blockSize': block_size}); ).persist(). if isinstance(dataset, MatrixTable):; return dataset.annotate_rows(**{name: annotations[dataset.row_key].nirvana}); else:; return dataset.annotate(**{name: annotations[dataset.key].nirvana}). class _VariantSummary(object):; def __init__(self, rg, n_variants, alleles_per_variant, variants_per_contig, allele_types, nti, ntv):; self.rg = rg; self.n_variants = n_variants; self.all",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:51732,Modifiability,config,configuration,51732,"sp: str,; isCanonical: bool,; polyPhenScore: float64,; polyPhenPrediction: str,; proteinId: str,; proteinPos: str,; siftScore: float64,; siftPrediction: str; }>,; ensembl: array<struct {; transcript: str,; bioType: str,; aminoAcids: str,; cdnaPos: str,; codons: str,; cdsPos: str,; exons: str,; introns: str,; geneId: str,; hgnc: str,; consequence: array<str>,; hgvsc: str,; hgvsp: str,; isCanonical: bool,; polyPhenScore: float64,; polyPhenPrediction: str,; proteinId: str,; proteinPos: str,; siftScore: float64,; siftPrediction: str; }>; },; overlappingGenes: array<str>; }>; genes: array<struct {; name: str,; omim: array<struct {; mimNumber: int32,; hgnc: str,; description: str,; phenotypes: array<struct {; mimNumber: int32,; phenotype: str,; mapping: str,; inheritance: array<str>,; comments: str; }>; }>; exac: struct {; pLi: float64,; pRec: float64,; pNull: float64; }; }>; }. Parameters; ----------; dataset : :class:`.MatrixTable` or :class:`.Table`; Dataset.; config : :class:`str`; Path to Nirvana configuration file.; block_size : :obj:`int`; Number of rows to process per Nirvana invocation.; name : :class:`str`; Name for resulting row field. Returns; -------; :class:`.MatrixTable` or :class:`.Table`; Dataset with new row-indexed field `name` containing Nirvana annotations.; """"""; if isinstance(dataset, MatrixTable):; require_row_key_variant(dataset, 'nirvana'); ht = dataset.select_rows().rows(); else:; require_table_key_variant(dataset, 'nirvana'); ht = dataset.select(). annotations = Table(; TableToTableApply(ht._tir, {'name': 'Nirvana', 'config': config, 'blockSize': block_size}); ).persist(). if isinstance(dataset, MatrixTable):; return dataset.annotate_rows(**{name: annotations[dataset.row_key].nirvana}); else:; return dataset.annotate(**{name: annotations[dataset.key].nirvana}). class _VariantSummary(object):; def __init__(self, rg, n_variants, alleles_per_variant, variants_per_contig, allele_types, nti, ntv):; self.rg = rg; self.n_variants = n_variants; self.all",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:52285,Modifiability,config,config,52285," }>; genes: array<struct {; name: str,; omim: array<struct {; mimNumber: int32,; hgnc: str,; description: str,; phenotypes: array<struct {; mimNumber: int32,; phenotype: str,; mapping: str,; inheritance: array<str>,; comments: str; }>; }>; exac: struct {; pLi: float64,; pRec: float64,; pNull: float64; }; }>; }. Parameters; ----------; dataset : :class:`.MatrixTable` or :class:`.Table`; Dataset.; config : :class:`str`; Path to Nirvana configuration file.; block_size : :obj:`int`; Number of rows to process per Nirvana invocation.; name : :class:`str`; Name for resulting row field. Returns; -------; :class:`.MatrixTable` or :class:`.Table`; Dataset with new row-indexed field `name` containing Nirvana annotations.; """"""; if isinstance(dataset, MatrixTable):; require_row_key_variant(dataset, 'nirvana'); ht = dataset.select_rows().rows(); else:; require_table_key_variant(dataset, 'nirvana'); ht = dataset.select(). annotations = Table(; TableToTableApply(ht._tir, {'name': 'Nirvana', 'config': config, 'blockSize': block_size}); ).persist(). if isinstance(dataset, MatrixTable):; return dataset.annotate_rows(**{name: annotations[dataset.row_key].nirvana}); else:; return dataset.annotate(**{name: annotations[dataset.key].nirvana}). class _VariantSummary(object):; def __init__(self, rg, n_variants, alleles_per_variant, variants_per_contig, allele_types, nti, ntv):; self.rg = rg; self.n_variants = n_variants; self.alleles_per_variant = alleles_per_variant; self.variants_per_contig = variants_per_contig; self.allele_types = allele_types; self.nti = nti; self.ntv = ntv. def __repr__(self):; return self.__str__(). def _repr_html_(self):; return self._html_string(). def __str__(self):; contig_idx = {contig: i for i, contig in enumerate(self.rg.contigs)}; max_contig_len = max(len(contig) for contig in self.variants_per_contig); contig_formatter = f'%{max_contig_len}s'. max_allele_count_len = max(len(str(x)) for x in self.alleles_per_variant); allele_count_formatter = f'%{max_allele_cou",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:52294,Modifiability,config,config,52294," }>; genes: array<struct {; name: str,; omim: array<struct {; mimNumber: int32,; hgnc: str,; description: str,; phenotypes: array<struct {; mimNumber: int32,; phenotype: str,; mapping: str,; inheritance: array<str>,; comments: str; }>; }>; exac: struct {; pLi: float64,; pRec: float64,; pNull: float64; }; }>; }. Parameters; ----------; dataset : :class:`.MatrixTable` or :class:`.Table`; Dataset.; config : :class:`str`; Path to Nirvana configuration file.; block_size : :obj:`int`; Number of rows to process per Nirvana invocation.; name : :class:`str`; Name for resulting row field. Returns; -------; :class:`.MatrixTable` or :class:`.Table`; Dataset with new row-indexed field `name` containing Nirvana annotations.; """"""; if isinstance(dataset, MatrixTable):; require_row_key_variant(dataset, 'nirvana'); ht = dataset.select_rows().rows(); else:; require_table_key_variant(dataset, 'nirvana'); ht = dataset.select(). annotations = Table(; TableToTableApply(ht._tir, {'name': 'Nirvana', 'config': config, 'blockSize': block_size}); ).persist(). if isinstance(dataset, MatrixTable):; return dataset.annotate_rows(**{name: annotations[dataset.row_key].nirvana}); else:; return dataset.annotate(**{name: annotations[dataset.key].nirvana}). class _VariantSummary(object):; def __init__(self, rg, n_variants, alleles_per_variant, variants_per_contig, allele_types, nti, ntv):; self.rg = rg; self.n_variants = n_variants; self.alleles_per_variant = alleles_per_variant; self.variants_per_contig = variants_per_contig; self.allele_types = allele_types; self.nti = nti; self.ntv = ntv. def __repr__(self):; return self.__str__(). def _repr_html_(self):; return self._html_string(). def __str__(self):; contig_idx = {contig: i for i, contig in enumerate(self.rg.contigs)}; max_contig_len = max(len(contig) for contig in self.variants_per_contig); contig_formatter = f'%{max_contig_len}s'. max_allele_count_len = max(len(str(x)) for x in self.alleles_per_variant); allele_count_formatter = f'%{max_allele_cou",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:14032,Performance,perform,performs,14032,"0].p_value,; 'p_value_excess_het': hwe[1].p_value,; }),; ),; ). return mt.annotate_rows(**{name: result}). [docs]@typecheck(left=MatrixTable, right=MatrixTable, _localize_global_statistics=bool); def concordance(left, right, *, _localize_global_statistics=True) -> Tuple[List[List[int]], Table, Table]:; """"""Calculate call concordance with another dataset. .. include:: ../_templates/req_tstring.rst. .. include:: ../_templates/req_tvariant.rst. .. include:: ../_templates/req_biallelic.rst. .. include:: ../_templates/req_unphased_diploid_gt.rst. Examples; --------. Compute concordance between two datasets and output the global concordance; statistics and two tables with concordance computed per column key and per; row key:. >>> global_conc, cols_conc, rows_conc = hl.concordance(dataset, dataset2). Notes; -----. This method computes the genotype call concordance (from the entry; field **GT**) between two biallelic variant datasets. It requires; unique sample IDs and performs an inner join on samples (only; samples in both datasets will be considered). In addition, all genotype; calls must be **diploid** and **unphased**. It performs an ordered zip join of the variants. That means the; variants of each dataset are sorted, with duplicate variants; appearing in some random relative order, and then zipped together.; When a variant appears a different number of times between the two; datasets, the dataset with the fewer number of instances is padded; with ""no data"". For example, if a variant is only in one dataset,; then each genotype is treated as ""no data"" in the other. This method returns a tuple of three objects: a nested list of; list of int with global concordance summary statistics, a table; with concordance statistics per column key, and a table with; concordance statistics per row key. **Using the global summary result**. The global summary is a list of list of int (conceptually a 5 by 5 matrix),; where the indices have special meaning:. 0. No Data (missing variant or",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:14193,Performance,perform,performs,14193,"ble, _localize_global_statistics=bool); def concordance(left, right, *, _localize_global_statistics=True) -> Tuple[List[List[int]], Table, Table]:; """"""Calculate call concordance with another dataset. .. include:: ../_templates/req_tstring.rst. .. include:: ../_templates/req_tvariant.rst. .. include:: ../_templates/req_biallelic.rst. .. include:: ../_templates/req_unphased_diploid_gt.rst. Examples; --------. Compute concordance between two datasets and output the global concordance; statistics and two tables with concordance computed per column key and per; row key:. >>> global_conc, cols_conc, rows_conc = hl.concordance(dataset, dataset2). Notes; -----. This method computes the genotype call concordance (from the entry; field **GT**) between two biallelic variant datasets. It requires; unique sample IDs and performs an inner join on samples (only; samples in both datasets will be considered). In addition, all genotype; calls must be **diploid** and **unphased**. It performs an ordered zip join of the variants. That means the; variants of each dataset are sorted, with duplicate variants; appearing in some random relative order, and then zipped together.; When a variant appears a different number of times between the two; datasets, the dataset with the fewer number of instances is padded; with ""no data"". For example, if a variant is only in one dataset,; then each genotype is treated as ""no data"" in the other. This method returns a tuple of three objects: a nested list of; list of int with global concordance summary statistics, a table; with concordance statistics per column key, and a table with; concordance statistics per row key. **Using the global summary result**. The global summary is a list of list of int (conceptually a 5 by 5 matrix),; where the indices have special meaning:. 0. No Data (missing variant or filtered entry); 1. No Call (missing genotype call); 2. Hom Ref; 3. Heterozygous; 4. Hom Var. The first index is the state in the left dataset and the secon",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:25117,Performance,cache,cache,25117,"Service is located.; - `image` (:obj:`.str`) -- The docker image to run VEP.; - `data_bucket_is_requester_pays` (:obj:`.bool`) -- True if the data bucket is requester pays.; - `regions` (:obj:`.list` of :obj:`.str`) -- A list of regions the VEP jobs can run in. In addition, the method `command` must be defined with the following signature. The output is the exact command to run the; VEP executable. The inputs are `consequence` and `tolerate_parse_error` which are user-defined parameters to :func:`.vep`,; `part_id` which is the partition ID, `input_file` which is the path to the input file where the input data can be found, and; `output_file` is the path to the output file where the VEP annotations are written to. An example is shown below:. .. code-block:: python3. def command(self,; consequence: bool,; tolerate_parse_error: bool,; part_id: int,; input_file: Optional[str],; output_file: str) -> List[str]:; vcf_or_json = '--vcf' if consequence else '--json'; input_file = f'--input_file {input_file}' if input_file else ''; return f'''/vep/vep {input_file} \; --format vcf \; {vcf_or_json} \; --everything \; --allele_number \; --no_stats \; --cache \; --offline \; --minimal \; --assembly GRCh37 \; --dir={self.data_mount} \; --plugin LoF,human_ancestor_fa:{self.data_mount}/loftee_data/human_ancestor.fa.gz,filter_position:0.05,min_intron_size:15,conservation_file:{self.data_mount}/loftee_data/phylocsf_gerp.sql,gerp_file:{self.data_mount}/loftee_data/GERP_scores.final.sorted.txt.gz \; -o STDOUT; '''. The following environment variables are added to the job's environment:. - `VEP_BLOCK_SIZE` - The maximum number of variants provided as input to each invocation of VEP.; - `VEP_PART_ID` - Partition ID.; - `VEP_DATA_MOUNT` - Location where the vep data is mounted (same as `data_mount` in the config).; - `VEP_CONSEQUENCE` - Integer equal to 0 or 1 on whether `csq` is False or True.; - `VEP_TOLERATE_PARSE_ERROR` - Integer equal to 0 or 1 on whether `tolerate_parse_error` is Fals",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:28361,Performance,cache,cache,28361,"The cloud where the Batch Service is located.; - `data_bucket_is_requester_pays` (:obj:`.bool`) -- True if the data bucket is requester pays.; - `regions` (:obj:`.list` of :obj:`.str`) -- A list of regions the VEP jobs can run in. """""". def __init__(; self,; *,; data_bucket: str,; data_mount: str,; image: str,; regions: List[str],; cloud: str,; data_bucket_is_requester_pays: bool,; ):; self.data_bucket = data_bucket; self.data_mount = data_mount; self.image = image; self.regions = regions; self.env = {}; self.data_bucket_is_requester_pays = data_bucket_is_requester_pays; self.cloud = cloud; self.batch_run_command = ['python3', '/hail-vep/vep.py', 'vep']; self.batch_run_csq_header_command = ['python3', '/hail-vep/vep.py', 'csq_header']; self.json_typ = vep_json_typ. def command(; self,; *,; consequence: bool,; tolerate_parse_error: bool,; part_id: int,; input_file: Optional[str],; output_file: str,; ) -> str:; vcf_or_json = '--vcf' if consequence else '--json'; input_file = f'--input_file {input_file}' if input_file else ''; return f""""""/vep/vep {input_file} \; --format vcf \; {vcf_or_json} \; --everything \; --allele_number \; --no_stats \; --cache \; --offline \; --minimal \; --assembly GRCh37 \; --dir={self.data_mount} \; --plugin LoF,human_ancestor_fa:{self.data_mount}/loftee_data/human_ancestor.fa.gz,filter_position:0.05,min_intron_size:15,conservation_file:{self.data_mount}/loftee_data/phylocsf_gerp.sql,gerp_file:{self.data_mount}/loftee_data/GERP_scores.final.sorted.txt.gz \; -o STDOUT; """""". [docs]class VEPConfigGRCh38Version95(VEPConfig):; """"""; The Hail-maintained VEP configuration for GRCh38 for VEP version 95. This class takes the following constructor arguments:. - `data_bucket` (:obj:`.str`) -- The location where the VEP data is stored.; - `data_mount` (:obj:`.str`) -- The location in the container where the data should be mounted.; - `image` (:obj:`.str`) -- The docker image to run VEP.; - `cloud` (:obj:`.str`) -- The cloud where the Batch Service is locate",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:30485,Performance,cache,cache,30485,":`.list` of :obj:`.str`) -- A list of regions the VEP jobs can run in. """""". def __init__(; self,; *,; data_bucket: str,; data_mount: str,; image: str,; regions: List[str],; cloud: str,; data_bucket_is_requester_pays: bool,; ):; self.data_bucket = data_bucket; self.data_mount = data_mount; self.image = image; self.regions = regions; self.env = {}; self.data_bucket_is_requester_pays = data_bucket_is_requester_pays; self.cloud = cloud; self.batch_run_command = ['python3', '/hail-vep/vep.py', 'vep']; self.batch_run_csq_header_command = ['python3', '/hail-vep/vep.py', 'csq_header']; self.json_typ = vep_json_typ._insert_field(; 'transcript_consequences',; tarray(; vep_json_typ['transcript_consequences'].element_type._insert_fields(; appris=tstr,; tsl=tint32,; ); ),; ). def command(; self,; *,; consequence: bool,; tolerate_parse_error: bool,; part_id: int,; input_file: Optional[str],; output_file: str,; ) -> str:; vcf_or_json = '--vcf' if consequence else '--json'; input_file = f'--input_file {input_file}' if input_file else ''; return f""""""/vep/vep {input_file} \; --format vcf \; {vcf_or_json} \; --everything \; --allele_number \; --no_stats \; --cache \; --offline \; --minimal \; --assembly GRCh38 \; --fasta {self.data_mount}homo_sapiens/95_GRCh38/Homo_sapiens.GRCh38.dna.toplevel.fa.gz \; --plugin ""LoF,loftee_path:/vep/ensembl-vep/Plugins/,gerp_bigwig:{self.data_mount}/gerp_conservation_scores.homo_sapiens.GRCh38.bw,human_ancestor_fa:{self.data_mount}/human_ancestor.fa.gz,conservation_file:{self.data_mount}/loftee.sql"" \; --dir_plugins /vep/ensembl-vep/Plugins/ \; --dir_cache {self.data_mount} \; -o STDOUT; """""". supported_vep_configs = {; ('GRCh37', 'gcp', 'us-central1', 'hail.is'): VEPConfigGRCh37Version85(; data_bucket='hail-qob-vep-grch37-us-central1',; data_mount='/vep_data/',; image=HAIL_GENETICS_VEP_GRCH37_85_IMAGE,; regions=['us-central1'],; cloud='gcp',; data_bucket_is_requester_pays=True,; ),; ('GRCh38', 'gcp', 'us-central1', 'hail.is'): VEPConfigGRCh38Version95(;",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:39125,Performance,cache,cache,39125,"ything will work. If you need to run VEP with Hail in other environments,; there are detailed instructions below. The format of the configuration file is JSON, and :func:`.vep`; expects a JSON object with three fields:. - `command` (array of string) -- The VEP command line to run. The string literal `__OUTPUT_FORMAT_FLAG__` is replaced with `--json` or `--vcf` depending on `csq`.; - `env` (object) -- A map of environment variables to values to add to the environment when invoking the command. The value of each object member must be a string.; - `vep_json_schema` (string): The type of the VEP JSON schema (as produced by the VEP when invoked with the `--json` option). Note: This is the old-style 'parseable' Hail type syntax. This will change. Here is an example configuration file for invoking VEP release 85; installed in `/vep` with the Loftee plugin:. .. code-block:: text. {; ""command"": [; ""/vep"",; ""--format"", ""vcf"",; ""__OUTPUT_FORMAT_FLAG__"",; ""--everything"",; ""--allele_number"",; ""--no_stats"",; ""--cache"", ""--offline"",; ""--minimal"",; ""--assembly"", ""GRCh37"",; ""--plugin"", ""LoF,human_ancestor_fa:/root/.vep/loftee_data/human_ancestor.fa.gz,filter_position:0.05,min_intron_size:15,conservation_file:/root/.vep/loftee_data/phylocsf_gerp.sql,gerp_file:/root/.vep/loftee_data/GERP_scores.final.sorted.txt.gz"",; ""-o"", ""STDOUT""; ],; ""env"": {; ""PERL5LIB"": ""/vep_data/loftee""; },; ""vep_json_schema"": ""Struct{assembly_name:String,allele_string:String,ancestral:String,colocated_variants:Array[Struct{aa_allele:String,aa_maf:Float64,afr_allele:String,afr_maf:Float64,allele_string:String,amr_allele:String,amr_maf:Float64,clin_sig:Array[String],end:Int32,eas_allele:String,eas_maf:Float64,ea_allele:String,ea_maf:Float64,eur_allele:String,eur_maf:Float64,exac_adj_allele:String,exac_adj_maf:Float64,exac_allele:String,exac_afr_allele:String,exac_afr_maf:Float64,exac_amr_allele:String,exac_amr_maf:Float64,exac_eas_allele:String,exac_eas_maf:Float64,exac_fin_allele:String,exac_fin_maf:Float64,exa",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:46644,Performance,cache,cache,46644,"de:: ../_templates/req_tvariant.rst. :func:`.nirvana` runs `Nirvana; <https://github.com/Illumina/Nirvana>`_ on the current dataset and adds a; new row field in the location specified by `name`. Examples; --------. Add Nirvana annotations to the dataset:. >>> result = hl.nirvana(dataset, ""data/nirvana.properties"") # doctest: +SKIP. **Configuration**. :func:`.nirvana` requires a configuration file. The format is a; `.properties file <https://en.wikipedia.org/wiki/.properties>`__, where each; line defines a property as a key-value pair of the form ``key = value``.; :func:`.nirvana` supports the following properties:. - **hail.nirvana.dotnet** -- Location of dotnet. Optional, default: dotnet.; - **hail.nirvana.path** -- Value of the PATH environment variable when; invoking Nirvana. Optional, by default PATH is not set.; - **hail.nirvana.location** -- Location of Nirvana.dll. Required.; - **hail.nirvana.reference** -- Location of reference genome. Required.; - **hail.nirvana.cache** -- Location of cache. Required.; - **hail.nirvana.supplementaryAnnotationDirectory** -- Location of; Supplementary Database. Optional, no supplementary database by default. Here is an example ``nirvana.properties`` configuration file:. .. code-block:: text. hail.nirvana.location = /path/to/dotnet/netcoreapp2.0/Nirvana.dll; hail.nirvana.reference = /path/to/nirvana/References/Homo_sapiens.GRCh37.Nirvana.dat; hail.nirvana.cache = /path/to/nirvana/Cache/GRCh37/Ensembl; hail.nirvana.supplementaryAnnotationDirectory = /path/to/nirvana/SupplementaryDatabase/GRCh37. **Annotations**. A new row field is added in the location specified by `name` with the; following schema:. .. code-block:: text. struct {; chromosome: str,; refAllele: str,; position: int32,; altAlleles: array<str>,; cytogeneticBand: str,; quality: float64,; filters: array<str>,; jointSomaticNormalQuality: int32,; copyNumber: int32,; strandBias: float64,; recalibratedQuality: float64,; variants: array<struct {; altAllele: str,; refAllele",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:46667,Performance,cache,cache,46667,"de:: ../_templates/req_tvariant.rst. :func:`.nirvana` runs `Nirvana; <https://github.com/Illumina/Nirvana>`_ on the current dataset and adds a; new row field in the location specified by `name`. Examples; --------. Add Nirvana annotations to the dataset:. >>> result = hl.nirvana(dataset, ""data/nirvana.properties"") # doctest: +SKIP. **Configuration**. :func:`.nirvana` requires a configuration file. The format is a; `.properties file <https://en.wikipedia.org/wiki/.properties>`__, where each; line defines a property as a key-value pair of the form ``key = value``.; :func:`.nirvana` supports the following properties:. - **hail.nirvana.dotnet** -- Location of dotnet. Optional, default: dotnet.; - **hail.nirvana.path** -- Value of the PATH environment variable when; invoking Nirvana. Optional, by default PATH is not set.; - **hail.nirvana.location** -- Location of Nirvana.dll. Required.; - **hail.nirvana.reference** -- Location of reference genome. Required.; - **hail.nirvana.cache** -- Location of cache. Required.; - **hail.nirvana.supplementaryAnnotationDirectory** -- Location of; Supplementary Database. Optional, no supplementary database by default. Here is an example ``nirvana.properties`` configuration file:. .. code-block:: text. hail.nirvana.location = /path/to/dotnet/netcoreapp2.0/Nirvana.dll; hail.nirvana.reference = /path/to/nirvana/References/Homo_sapiens.GRCh37.Nirvana.dat; hail.nirvana.cache = /path/to/nirvana/Cache/GRCh37/Ensembl; hail.nirvana.supplementaryAnnotationDirectory = /path/to/nirvana/SupplementaryDatabase/GRCh37. **Annotations**. A new row field is added in the location specified by `name` with the; following schema:. .. code-block:: text. struct {; chromosome: str,; refAllele: str,; position: int32,; altAlleles: array<str>,; cytogeneticBand: str,; quality: float64,; filters: array<str>,; jointSomaticNormalQuality: int32,; copyNumber: int32,; strandBias: float64,; recalibratedQuality: float64,; variants: array<struct {; altAllele: str,; refAllele",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:47076,Performance,cache,cache,47076,"/en.wikipedia.org/wiki/.properties>`__, where each; line defines a property as a key-value pair of the form ``key = value``.; :func:`.nirvana` supports the following properties:. - **hail.nirvana.dotnet** -- Location of dotnet. Optional, default: dotnet.; - **hail.nirvana.path** -- Value of the PATH environment variable when; invoking Nirvana. Optional, by default PATH is not set.; - **hail.nirvana.location** -- Location of Nirvana.dll. Required.; - **hail.nirvana.reference** -- Location of reference genome. Required.; - **hail.nirvana.cache** -- Location of cache. Required.; - **hail.nirvana.supplementaryAnnotationDirectory** -- Location of; Supplementary Database. Optional, no supplementary database by default. Here is an example ``nirvana.properties`` configuration file:. .. code-block:: text. hail.nirvana.location = /path/to/dotnet/netcoreapp2.0/Nirvana.dll; hail.nirvana.reference = /path/to/nirvana/References/Homo_sapiens.GRCh37.Nirvana.dat; hail.nirvana.cache = /path/to/nirvana/Cache/GRCh37/Ensembl; hail.nirvana.supplementaryAnnotationDirectory = /path/to/nirvana/SupplementaryDatabase/GRCh37. **Annotations**. A new row field is added in the location specified by `name` with the; following schema:. .. code-block:: text. struct {; chromosome: str,; refAllele: str,; position: int32,; altAlleles: array<str>,; cytogeneticBand: str,; quality: float64,; filters: array<str>,; jointSomaticNormalQuality: int32,; copyNumber: int32,; strandBias: float64,; recalibratedQuality: float64,; variants: array<struct {; altAllele: str,; refAllele: str,; chromosome: str,; begin: int32,; end: int32,; phylopScore: float64,; isReferenceMinor: bool,; variantType: str,; vid: str,; hgvsg: str,; isRecomposedVariant: bool,; isDecomposedVariant: bool,; regulatoryRegions: array<struct {; id: str,; type: str,; consequence: set<str>; }>,; clinvar: array<struct {; id: str,; reviewStatus: str,; isAlleleSpecific: bool,; alleleOrigins: array<str>,; refAllele: str,; altAllele: str,; phenotypes: arr",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:60443,Performance,load,loaded,60443,"heck(; ds=oneof(MatrixTable, lambda: hl.vds.VariantDataset),; min_af=numeric,; max_af=numeric,; min_dp=int,; max_dp=int,; min_gq=int,; ref_AF=nullable(expr_float64),; ); def compute_charr(; ds: Union[MatrixTable, 'hl.vds.VariantDataset'],; min_af: float = 0.05,; max_af: float = 0.95,; min_dp: int = 10,; max_dp: int = 100,; min_gq: int = 20,; ref_AF: Optional[Float64Expression] = None,; ):; """"""Compute CHARR, the DNA sample contamination estimator. .. include:: ../_templates/experimental.rst. Notes; -----. The returned table has the sample ID field, plus the field:. - `charr` (float64): CHARR contamination estimation. Note; -----; It is possible to use gnomAD reference allele frequencies with the following:. >>> gnomad_sites = hl.experimental.load_dataset('gnomad_genome_sites', version='3.1.2') # doctest: +SKIP; >>> charr_result = hl.compute_charr(mt, ref_af=(1 - gnomad_sites[mt.row_key].freq[0].AF)) # doctest: +SKIP. If the dataset is loaded from a gvcf and has NON_REF alleles, drop the last allele with the following or load it with the hail vcf combiner:. >>> mt = mt.key_rows_by(locus=mt.locus, alleles=mt.alleles[:-1]). Parameters; ----------; ds : :class:`.MatrixTable` or :class:`.VariantDataset`; Dataset.; min_af; Minimum reference allele frequency to filter variants.; max_af; Maximum reference allele frequency to filter variants.; min_dp; Minimum sequencing depth to filter variants.; max_dp; Maximum sequencing depth to filter variants.; min_gq; Minimum genotype quality to filter variants; ref_AF; Reference AF expression. Necessary when the sample size is below 10,000. Returns; -------; :class:`.Table`; """""". # Determine whether the input data is in the VDS format; if not, convert matrixtable to VDS and extract only the variant call information; if isinstance(ds, hl.vds.VariantDataset):; mt = ds.variant_data; else:; mt = ds. if all(x in mt.entry for x in ['LA', 'LAD', 'LGT', 'GQ']):; ad_field = 'LAD'; gt_field = 'LGT'; elif all(x in mt.entry for x in ['AD', 'GT', '",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:60530,Performance,load,load,60530,"heck(; ds=oneof(MatrixTable, lambda: hl.vds.VariantDataset),; min_af=numeric,; max_af=numeric,; min_dp=int,; max_dp=int,; min_gq=int,; ref_AF=nullable(expr_float64),; ); def compute_charr(; ds: Union[MatrixTable, 'hl.vds.VariantDataset'],; min_af: float = 0.05,; max_af: float = 0.95,; min_dp: int = 10,; max_dp: int = 100,; min_gq: int = 20,; ref_AF: Optional[Float64Expression] = None,; ):; """"""Compute CHARR, the DNA sample contamination estimator. .. include:: ../_templates/experimental.rst. Notes; -----. The returned table has the sample ID field, plus the field:. - `charr` (float64): CHARR contamination estimation. Note; -----; It is possible to use gnomAD reference allele frequencies with the following:. >>> gnomad_sites = hl.experimental.load_dataset('gnomad_genome_sites', version='3.1.2') # doctest: +SKIP; >>> charr_result = hl.compute_charr(mt, ref_af=(1 - gnomad_sites[mt.row_key].freq[0].AF)) # doctest: +SKIP. If the dataset is loaded from a gvcf and has NON_REF alleles, drop the last allele with the following or load it with the hail vcf combiner:. >>> mt = mt.key_rows_by(locus=mt.locus, alleles=mt.alleles[:-1]). Parameters; ----------; ds : :class:`.MatrixTable` or :class:`.VariantDataset`; Dataset.; min_af; Minimum reference allele frequency to filter variants.; max_af; Maximum reference allele frequency to filter variants.; min_dp; Minimum sequencing depth to filter variants.; max_dp; Maximum sequencing depth to filter variants.; min_gq; Minimum genotype quality to filter variants; ref_AF; Reference AF expression. Necessary when the sample size is below 10,000. Returns; -------; :class:`.Table`; """""". # Determine whether the input data is in the VDS format; if not, convert matrixtable to VDS and extract only the variant call information; if isinstance(ds, hl.vds.VariantDataset):; mt = ds.variant_data; else:; mt = ds. if all(x in mt.entry for x in ['LA', 'LAD', 'LGT', 'GQ']):; ad_field = 'LAD'; gt_field = 'LGT'; elif all(x in mt.entry for x in ['AD', 'GT', '",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:493,Testability,log,logging,493,"﻿. Hail | ; hail.methods.qc. 	Fill out the Community Feedback Survey!; . Query Docs. Batch Docs. Forum. Science. Blog. Hail Docs; ; ; ; (0.2); ; ; . ; . Installation; Hail on the Cloud; Tutorials; Reference (Python API); Configuration Reference; Overview; How-To Guides; Cheatsheets; Datasets; Annotation Database; Libraries; For Software Developers; Other Resources; Change Log And Version Policy. menu; Hail. Module code; hail.methods.qc. Source code for hail.methods.qc; import abc; import logging; import os; from collections import Counter; from shlex import quote as shq; from typing import Dict, List, Optional, Tuple, Union. import hail as hl; import hailtop.batch_client as bc; from hail.backend.service_backend import ServiceBackend; from hail.expr import Float64Expression; from hail.expr.expressions.expression_typecheck import expr_float64; from hail.expr.functions import numeric_allele_type; from hail.expr.types import tarray, tfloat, tint32, tstr, tstruct; from hail.genetics.allele_type import AlleleType; from hail.ir import TableToTableApply; from hail.matrixtable import MatrixTable; from hail.table import Table; from hail.typecheck import anytype, nullable, numeric, oneof, typecheck; from hail.utils import FatalError; from hail.utils.java import Env, info, warning; from hail.utils.misc import divide_null, guess_cloud_spark_provider, new_temp_file; from hailtop import pip_version, yamlx; from hailtop.config import get_deploy_config; from hailtop.utils import async_to_blocking. from .misc import (; require_alleles_field,; require_biallelic,; require_col_key_str,; require_row_key_variant,; require_table_key_variant,; ). log = logging.getLogger('methods.qc'). HAIL_GENETICS_VEP_GRCH37_85_IMAGE = os.environ.get(; 'HAIL_GENETICS_VEP_GRCH37_85_IMAGE', f'hailgenetics/vep-grch37-85:{pip_version()}'; ); HAIL_GENETICS_VEP_GRCH38_95_IMAGE = os.environ.get(; 'HAIL_GENETICS_VEP_GRCH38_95_IMAGE', f'hailgenetics/vep-grch38-95:{pip_version()}'; ). def _qc_allele_type(ref, alt):; ",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:1650,Testability,log,log,1650,"rt hailtop.batch_client as bc; from hail.backend.service_backend import ServiceBackend; from hail.expr import Float64Expression; from hail.expr.expressions.expression_typecheck import expr_float64; from hail.expr.functions import numeric_allele_type; from hail.expr.types import tarray, tfloat, tint32, tstr, tstruct; from hail.genetics.allele_type import AlleleType; from hail.ir import TableToTableApply; from hail.matrixtable import MatrixTable; from hail.table import Table; from hail.typecheck import anytype, nullable, numeric, oneof, typecheck; from hail.utils import FatalError; from hail.utils.java import Env, info, warning; from hail.utils.misc import divide_null, guess_cloud_spark_provider, new_temp_file; from hailtop import pip_version, yamlx; from hailtop.config import get_deploy_config; from hailtop.utils import async_to_blocking. from .misc import (; require_alleles_field,; require_biallelic,; require_col_key_str,; require_row_key_variant,; require_table_key_variant,; ). log = logging.getLogger('methods.qc'). HAIL_GENETICS_VEP_GRCH37_85_IMAGE = os.environ.get(; 'HAIL_GENETICS_VEP_GRCH37_85_IMAGE', f'hailgenetics/vep-grch37-85:{pip_version()}'; ); HAIL_GENETICS_VEP_GRCH38_95_IMAGE = os.environ.get(; 'HAIL_GENETICS_VEP_GRCH38_95_IMAGE', f'hailgenetics/vep-grch38-95:{pip_version()}'; ). def _qc_allele_type(ref, alt):; return hl.bind(; lambda at: hl.if_else(; at == AlleleType.SNP,; hl.if_else(hl.is_transition(ref, alt), AlleleType.TRANSITION, AlleleType.TRANSVERSION),; at,; ),; numeric_allele_type(ref, alt),; ). [docs]@typecheck(mt=MatrixTable, name=str); def sample_qc(mt, name='sample_qc') -> MatrixTable:; """"""Compute per-sample metrics useful for quality control. .. include:: ../_templates/req_tvariant.rst. Examples; --------. Compute sample QC metrics and remove low-quality samples:. >>> dataset = hl.sample_qc(dataset, name='sample_qc'); >>> filtered_dataset = dataset.filter_cols((dataset.sample_qc.dp_stats.mean > 20) & (dataset.sample_qc.r_ti_tv > 1.5)). Notes",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:1656,Testability,log,logging,1656,"rt hailtop.batch_client as bc; from hail.backend.service_backend import ServiceBackend; from hail.expr import Float64Expression; from hail.expr.expressions.expression_typecheck import expr_float64; from hail.expr.functions import numeric_allele_type; from hail.expr.types import tarray, tfloat, tint32, tstr, tstruct; from hail.genetics.allele_type import AlleleType; from hail.ir import TableToTableApply; from hail.matrixtable import MatrixTable; from hail.table import Table; from hail.typecheck import anytype, nullable, numeric, oneof, typecheck; from hail.utils import FatalError; from hail.utils.java import Env, info, warning; from hail.utils.misc import divide_null, guess_cloud_spark_provider, new_temp_file; from hailtop import pip_version, yamlx; from hailtop.config import get_deploy_config; from hailtop.utils import async_to_blocking. from .misc import (; require_alleles_field,; require_biallelic,; require_col_key_str,; require_row_key_variant,; require_table_key_variant,; ). log = logging.getLogger('methods.qc'). HAIL_GENETICS_VEP_GRCH37_85_IMAGE = os.environ.get(; 'HAIL_GENETICS_VEP_GRCH37_85_IMAGE', f'hailgenetics/vep-grch37-85:{pip_version()}'; ); HAIL_GENETICS_VEP_GRCH38_95_IMAGE = os.environ.get(; 'HAIL_GENETICS_VEP_GRCH38_95_IMAGE', f'hailgenetics/vep-grch38-95:{pip_version()}'; ). def _qc_allele_type(ref, alt):; return hl.bind(; lambda at: hl.if_else(; at == AlleleType.SNP,; hl.if_else(hl.is_transition(ref, alt), AlleleType.TRANSITION, AlleleType.TRANSVERSION),; at,; ),; numeric_allele_type(ref, alt),; ). [docs]@typecheck(mt=MatrixTable, name=str); def sample_qc(mt, name='sample_qc') -> MatrixTable:; """"""Compute per-sample metrics useful for quality control. .. include:: ../_templates/req_tvariant.rst. Examples; --------. Compute sample QC metrics and remove low-quality samples:. >>> dataset = hl.sample_qc(dataset, name='sample_qc'); >>> filtered_dataset = dataset.filter_cols((dataset.sample_qc.dp_stats.mean > 20) & (dataset.sample_qc.r_ti_tv > 1.5)). Notes",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:10330,Testability,test,test,10330," - `AC` (``array<int32>``) -- Calculated allele count, one element per; allele, including the reference. Sums to `AN`.; - `AN` (``int32``) -- Total number of called alleles.; - `homozygote_count` (``array<int32>``) -- Number of homozygotes per; allele. One element per allele, including the reference.; - `call_rate` (``float64``) -- Fraction of calls neither missing nor filtered.; Equivalent to `n_called` / :meth:`.count_cols`.; - `n_called` (``int64``) -- Number of samples with a defined `GT`.; - `n_not_called` (``int64``) -- Number of samples with a missing `GT`.; - `n_filtered` (``int64``) -- Number of filtered entries.; - `n_het` (``int64``) -- Number of heterozygous samples.; - `n_non_ref` (``int64``) -- Number of samples with at least one called; non-reference allele.; - `het_freq_hwe` (``float64``) -- Expected frequency of heterozygous; samples under Hardy-Weinberg equilibrium. See; :func:`.functions.hardy_weinberg_test` for details.; - `p_value_hwe` (``float64``) -- p-value from two-sided test of Hardy-Weinberg; equilibrium. See :func:`.functions.hardy_weinberg_test` for details.; - `p_value_excess_het` (``float64``) -- p-value from one-sided test of; Hardy-Weinberg equilibrium for excess heterozygosity.; See :func:`.functions.hardy_weinberg_test` for details. Warning; -------; `het_freq_hwe` and `p_value_hwe` are calculated as in; :func:`.functions.hardy_weinberg_test`, with non-diploid calls; (``ploidy != 2``) ignored in the counts. As this test is only; statistically rigorous in the biallelic setting, :func:`.variant_qc`; sets both fields to missing for multiallelic variants. Consider using; :func:`~hail.methods.split_multi` to split multi-allelic variants beforehand. Parameters; ----------; mt : :class:`.MatrixTable`; Dataset.; name : :class:`str`; Name for resulting field. Returns; -------; :class:`.MatrixTable`; """"""; require_alleles_field(mt, 'variant_qc'). bound_exprs = {}; gq_dp_exprs = {}. def has_field_of_type(name, dtype):; return name in mt.entry ",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:10487,Testability,test,test,10487,"lleles.; - `homozygote_count` (``array<int32>``) -- Number of homozygotes per; allele. One element per allele, including the reference.; - `call_rate` (``float64``) -- Fraction of calls neither missing nor filtered.; Equivalent to `n_called` / :meth:`.count_cols`.; - `n_called` (``int64``) -- Number of samples with a defined `GT`.; - `n_not_called` (``int64``) -- Number of samples with a missing `GT`.; - `n_filtered` (``int64``) -- Number of filtered entries.; - `n_het` (``int64``) -- Number of heterozygous samples.; - `n_non_ref` (``int64``) -- Number of samples with at least one called; non-reference allele.; - `het_freq_hwe` (``float64``) -- Expected frequency of heterozygous; samples under Hardy-Weinberg equilibrium. See; :func:`.functions.hardy_weinberg_test` for details.; - `p_value_hwe` (``float64``) -- p-value from two-sided test of Hardy-Weinberg; equilibrium. See :func:`.functions.hardy_weinberg_test` for details.; - `p_value_excess_het` (``float64``) -- p-value from one-sided test of; Hardy-Weinberg equilibrium for excess heterozygosity.; See :func:`.functions.hardy_weinberg_test` for details. Warning; -------; `het_freq_hwe` and `p_value_hwe` are calculated as in; :func:`.functions.hardy_weinberg_test`, with non-diploid calls; (``ploidy != 2``) ignored in the counts. As this test is only; statistically rigorous in the biallelic setting, :func:`.variant_qc`; sets both fields to missing for multiallelic variants. Consider using; :func:`~hail.methods.split_multi` to split multi-allelic variants beforehand. Parameters; ----------; mt : :class:`.MatrixTable`; Dataset.; name : :class:`str`; Name for resulting field. Returns; -------; :class:`.MatrixTable`; """"""; require_alleles_field(mt, 'variant_qc'). bound_exprs = {}; gq_dp_exprs = {}. def has_field_of_type(name, dtype):; return name in mt.entry and mt[name].dtype == dtype. if has_field_of_type('DP', hl.tint32):; gq_dp_exprs['dp_stats'] = hl.agg.stats(mt.DP).select('mean', 'stdev', 'min', 'max'). if has_field_",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:10793,Testability,test,test,10793,"not_called` (``int64``) -- Number of samples with a missing `GT`.; - `n_filtered` (``int64``) -- Number of filtered entries.; - `n_het` (``int64``) -- Number of heterozygous samples.; - `n_non_ref` (``int64``) -- Number of samples with at least one called; non-reference allele.; - `het_freq_hwe` (``float64``) -- Expected frequency of heterozygous; samples under Hardy-Weinberg equilibrium. See; :func:`.functions.hardy_weinberg_test` for details.; - `p_value_hwe` (``float64``) -- p-value from two-sided test of Hardy-Weinberg; equilibrium. See :func:`.functions.hardy_weinberg_test` for details.; - `p_value_excess_het` (``float64``) -- p-value from one-sided test of; Hardy-Weinberg equilibrium for excess heterozygosity.; See :func:`.functions.hardy_weinberg_test` for details. Warning; -------; `het_freq_hwe` and `p_value_hwe` are calculated as in; :func:`.functions.hardy_weinberg_test`, with non-diploid calls; (``ploidy != 2``) ignored in the counts. As this test is only; statistically rigorous in the biallelic setting, :func:`.variant_qc`; sets both fields to missing for multiallelic variants. Consider using; :func:`~hail.methods.split_multi` to split multi-allelic variants beforehand. Parameters; ----------; mt : :class:`.MatrixTable`; Dataset.; name : :class:`str`; Name for resulting field. Returns; -------; :class:`.MatrixTable`; """"""; require_alleles_field(mt, 'variant_qc'). bound_exprs = {}; gq_dp_exprs = {}. def has_field_of_type(name, dtype):; return name in mt.entry and mt[name].dtype == dtype. if has_field_of_type('DP', hl.tint32):; gq_dp_exprs['dp_stats'] = hl.agg.stats(mt.DP).select('mean', 'stdev', 'min', 'max'). if has_field_of_type('GQ', hl.tint32):; gq_dp_exprs['gq_stats'] = hl.agg.stats(mt.GQ).select('mean', 'stdev', 'min', 'max'). if not has_field_of_type('GT', hl.tcall):; raise ValueError(""'variant_qc': expect an entry field 'GT' of type 'call'""). bound_exprs['n_called'] = hl.agg.count_where(hl.is_defined(mt['GT'])); bound_exprs['n_not_called'] = hl.ag",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:35970,Testability,log,log,35970,"ame}.tsv.gz')],; cloudfuse=[(vep_config.data_bucket, vep_config.data_mount, True)],; regions=vep_config.regions,; requester_pays_project=requester_pays_project,; env=env,; ). hl.export_vcf(ht, temp_input_directory, parallel='header_per_shard'). starting_job_id = async_to_blocking(backend._batch.status())['n_jobs'] + 1. b = bc.client.Batch(backend._batch); build_vep_batch(b, temp_input_directory, temp_output_directory). b.submit(disable_progress_bar=True). try:; status = b.wait(; description='vep(...)',; disable_progress_bar=backend.disable_progress_bar,; progress=None,; starting_job=starting_job_id,; ); except BaseException as e:; if isinstance(e, KeyboardInterrupt):; print(""Received a keyboard interrupt, cancelling the batch...""); b.cancel(); backend._batch = None; raise. if status['n_succeeded'] != status['n_jobs']:; failing_job = next(iter(b.jobs('!success'))); failing_job = b.get_job(failing_job['job_id']); message = {'batch_status': status, 'job_status': failing_job.status(), 'log': failing_job.log()}; raise FatalError(yamlx.dump(message)). annotations = hl.import_table(; f'{temp_output_directory}/annotations/*',; types={'variant': hl.tstr, 'vep': vep_typ, 'part_id': hl.tint, 'block_id': hl.tint},; force=True,; ). annotations = annotations.annotate(; vep_proc_id=hl.struct(part_id=annotations.part_id, block_id=annotations.block_id); ); annotations = annotations.drop('part_id', 'block_id'); annotations = annotations.key_by(**hl.parse_variant(annotations.variant, reference_genome=reference_genome)); annotations = annotations.drop('variant'). if csq:; with hl.hadoop_open(f'{temp_output_directory}/csq-header') as f:; vep_csq_header = f.read().rstrip(); annotations = annotations.annotate_globals(vep_csq_header=vep_csq_header). return annotations. [docs]@typecheck(; dataset=oneof(Table, MatrixTable),; config=nullable(oneof(str, VEPConfig)),; block_size=int,; name=str,; csq=bool,; tolerate_parse_error=bool,; ); def vep(; dataset: Union[Table, MatrixTable],; config: Opti",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/qc.html:35988,Testability,log,log,35988,"ep_config.data_bucket, vep_config.data_mount, True)],; regions=vep_config.regions,; requester_pays_project=requester_pays_project,; env=env,; ). hl.export_vcf(ht, temp_input_directory, parallel='header_per_shard'). starting_job_id = async_to_blocking(backend._batch.status())['n_jobs'] + 1. b = bc.client.Batch(backend._batch); build_vep_batch(b, temp_input_directory, temp_output_directory). b.submit(disable_progress_bar=True). try:; status = b.wait(; description='vep(...)',; disable_progress_bar=backend.disable_progress_bar,; progress=None,; starting_job=starting_job_id,; ); except BaseException as e:; if isinstance(e, KeyboardInterrupt):; print(""Received a keyboard interrupt, cancelling the batch...""); b.cancel(); backend._batch = None; raise. if status['n_succeeded'] != status['n_jobs']:; failing_job = next(iter(b.jobs('!success'))); failing_job = b.get_job(failing_job['job_id']); message = {'batch_status': status, 'job_status': failing_job.status(), 'log': failing_job.log()}; raise FatalError(yamlx.dump(message)). annotations = hl.import_table(; f'{temp_output_directory}/annotations/*',; types={'variant': hl.tstr, 'vep': vep_typ, 'part_id': hl.tint, 'block_id': hl.tint},; force=True,; ). annotations = annotations.annotate(; vep_proc_id=hl.struct(part_id=annotations.part_id, block_id=annotations.block_id); ); annotations = annotations.drop('part_id', 'block_id'); annotations = annotations.key_by(**hl.parse_variant(annotations.variant, reference_genome=reference_genome)); annotations = annotations.drop('variant'). if csq:; with hl.hadoop_open(f'{temp_output_directory}/csq-header') as f:; vep_csq_header = f.read().rstrip(); annotations = annotations.annotate_globals(vep_csq_header=vep_csq_header). return annotations. [docs]@typecheck(; dataset=oneof(Table, MatrixTable),; config=nullable(oneof(str, VEPConfig)),; block_size=int,; name=str,; csq=bool,; tolerate_parse_error=bool,; ); def vep(; dataset: Union[Table, MatrixTable],; config: Optional[Union[str, VEPConfig]] = ",MatchSource.WIKI,docs/0.2/_modules/hail/methods/qc.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/qc.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:9740,Availability,error,error,9740,"s a single value or a list, :func:`.linear_regression_rows`; considers the same set of columns (i.e., samples, points) for every response; variable and row, namely those columns for which **all** response variables; and covariates are defined. If `y` is a list of lists, then each inner list is treated as an; independent group, subsetting columns for missingness separately. Notes; -----; With the default root and `y` a single expression, the following row-indexed; fields are added. - **<row key fields>** (Any) -- Row key fields.; - **<pass_through fields>** (Any) -- Row fields in `pass_through`.; - **n** (:py:data:`.tint32`) -- Number of columns used.; - **sum_x** (:py:data:`.tfloat64`) -- Sum of input values `x`.; - **y_transpose_x** (:py:data:`.tfloat64`) -- Dot product of response; vector `y` with the input vector `x`.; - **beta** (:py:data:`.tfloat64`) --; Fit effect coefficient of `x`, :math:`\hat\beta_1` below.; - **standard_error** (:py:data:`.tfloat64`) --; Estimated standard error, :math:`\widehat{\mathrm{se}}_1`.; - **t_stat** (:py:data:`.tfloat64`) -- :math:`t`-statistic, equal to; :math:`\hat\beta_1 / \widehat{\mathrm{se}}_1`.; - **p_value** (:py:data:`.tfloat64`) -- :math:`p`-value. If `y` is a list of expressions, then the last five fields instead have type; :class:`.tarray` of :py:data:`.tfloat64`, with corresponding indexing of; the list and each array. If `y` is a list of lists of expressions, then `n` and `sum_x` are of type; ``array<float64>``, and the last five fields are of type; ``array<array<float64>>``. Index into these arrays with; ``a[index_in_outer_list, index_in_inner_list]``. For example, if; ``y=[[a], [b, c]]`` then the p-value for ``b`` is ``p_value[1][0]``. In the statistical genetics example above, the input variable `x` encodes; genotype as the number of alternate alleles (0, 1, or 2). For each variant; (row), genotype is tested for association with height controlling for age; and sex, by fitting the linear regression model:. .. math:",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:25796,Availability,checkpoint,checkpoint,25796,"ta', 'standard_error', 't_stat', 'p_value']; computed_row_fields = {; field_name: per_y_list.map(lambda one_y: one_y[field_name][row_idx]); for field_name in computed_row_field_names; }; pass_through_rows = {field_name: block[field_name][row_idx] for field_name in row_field_names}. if not is_chained:; computed_row_fields = {key: value[0] for key, value in computed_row_fields.items()}. return hl.struct(**{**idxth_keys, **computed_row_fields, **pass_through_rows}). new_rows = hl.range(rows_in_block).map(build_row). return new_rows. def process_partition(part):; grouped = part.grouped(block_size); return grouped.flatmap(lambda block: process_block(block)._to_stream()). res = ht._map_partitions(process_partition). if not y_is_list:; fields = ['y_transpose_x', 'beta', 'standard_error', 't_stat', 'p_value']; res = res.annotate(**{f: res[f][0] for f in fields}). res = res.select_globals(). temp_file_name = hl.utils.new_temp_file(""_linear_regression_rows_nd"", ""result""); res = res.checkpoint(temp_file_name). return res. [docs]@typecheck(; test=enumeration('wald', 'lrt', 'score', 'firth'),; y=oneof(expr_float64, sequenceof(expr_float64)),; x=expr_float64,; covariates=sequenceof(expr_float64),; pass_through=sequenceof(oneof(str, Expression)),; max_iterations=nullable(int),; tolerance=nullable(float),; ); def logistic_regression_rows(; test, y, x, covariates, pass_through=(), *, max_iterations: Optional[int] = None, tolerance: Optional[float] = None; ) -> Table:; r""""""For each row, test an input variable for association with a; binary response variable using logistic regression. Examples; --------; Run the logistic regression Wald test per variant using a Boolean; phenotype, intercept and two covariates stored in column-indexed; fields:. >>> result_ht = hl.logistic_regression_rows(; ... test='wald',; ... y=dataset.pheno.is_case,; ... x=dataset.GT.n_alt_alleles(),; ... covariates=[1, dataset.pheno.age, dataset.pheno.is_female]). Run the logistic regression Wald test per variant us",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:26093,Availability,toler,tolerance,26093,"ed_row_fields = {key: value[0] for key, value in computed_row_fields.items()}. return hl.struct(**{**idxth_keys, **computed_row_fields, **pass_through_rows}). new_rows = hl.range(rows_in_block).map(build_row). return new_rows. def process_partition(part):; grouped = part.grouped(block_size); return grouped.flatmap(lambda block: process_block(block)._to_stream()). res = ht._map_partitions(process_partition). if not y_is_list:; fields = ['y_transpose_x', 'beta', 'standard_error', 't_stat', 'p_value']; res = res.annotate(**{f: res[f][0] for f in fields}). res = res.select_globals(). temp_file_name = hl.utils.new_temp_file(""_linear_regression_rows_nd"", ""result""); res = res.checkpoint(temp_file_name). return res. [docs]@typecheck(; test=enumeration('wald', 'lrt', 'score', 'firth'),; y=oneof(expr_float64, sequenceof(expr_float64)),; x=expr_float64,; covariates=sequenceof(expr_float64),; pass_through=sequenceof(oneof(str, Expression)),; max_iterations=nullable(int),; tolerance=nullable(float),; ); def logistic_regression_rows(; test, y, x, covariates, pass_through=(), *, max_iterations: Optional[int] = None, tolerance: Optional[float] = None; ) -> Table:; r""""""For each row, test an input variable for association with a; binary response variable using logistic regression. Examples; --------; Run the logistic regression Wald test per variant using a Boolean; phenotype, intercept and two covariates stored in column-indexed; fields:. >>> result_ht = hl.logistic_regression_rows(; ... test='wald',; ... y=dataset.pheno.is_case,; ... x=dataset.GT.n_alt_alleles(),; ... covariates=[1, dataset.pheno.age, dataset.pheno.is_female]). Run the logistic regression Wald test per variant using a list of binary (0/1); phenotypes, intercept and two covariates stored in column-indexed; fields:. >>> result_ht = hl.logistic_regression_rows(; ... test='wald',; ... y=[dataset.pheno.is_case, dataset.pheno.is_case], # where pheno values are 0, 1, or missing; ... x=dataset.GT.n_alt_alleles(),; ... cova",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:26237,Availability,toler,tolerance,26237,"ed_row_fields = {key: value[0] for key, value in computed_row_fields.items()}. return hl.struct(**{**idxth_keys, **computed_row_fields, **pass_through_rows}). new_rows = hl.range(rows_in_block).map(build_row). return new_rows. def process_partition(part):; grouped = part.grouped(block_size); return grouped.flatmap(lambda block: process_block(block)._to_stream()). res = ht._map_partitions(process_partition). if not y_is_list:; fields = ['y_transpose_x', 'beta', 'standard_error', 't_stat', 'p_value']; res = res.annotate(**{f: res[f][0] for f in fields}). res = res.select_globals(). temp_file_name = hl.utils.new_temp_file(""_linear_regression_rows_nd"", ""result""); res = res.checkpoint(temp_file_name). return res. [docs]@typecheck(; test=enumeration('wald', 'lrt', 'score', 'firth'),; y=oneof(expr_float64, sequenceof(expr_float64)),; x=expr_float64,; covariates=sequenceof(expr_float64),; pass_through=sequenceof(oneof(str, Expression)),; max_iterations=nullable(int),; tolerance=nullable(float),; ); def logistic_regression_rows(; test, y, x, covariates, pass_through=(), *, max_iterations: Optional[int] = None, tolerance: Optional[float] = None; ) -> Table:; r""""""For each row, test an input variable for association with a; binary response variable using logistic regression. Examples; --------; Run the logistic regression Wald test per variant using a Boolean; phenotype, intercept and two covariates stored in column-indexed; fields:. >>> result_ht = hl.logistic_regression_rows(; ... test='wald',; ... y=dataset.pheno.is_case,; ... x=dataset.GT.n_alt_alleles(),; ... covariates=[1, dataset.pheno.age, dataset.pheno.is_female]). Run the logistic regression Wald test per variant using a list of binary (0/1); phenotypes, intercept and two covariates stored in column-indexed; fields:. >>> result_ht = hl.logistic_regression_rows(; ... test='wald',; ... y=[dataset.pheno.is_case, dataset.pheno.is_case], # where pheno values are 0, 1, or missing; ... x=dataset.GT.n_alt_alleles(),; ... cova",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:27251,Availability,toler,tolerance,27251,"l[int] = None, tolerance: Optional[float] = None; ) -> Table:; r""""""For each row, test an input variable for association with a; binary response variable using logistic regression. Examples; --------; Run the logistic regression Wald test per variant using a Boolean; phenotype, intercept and two covariates stored in column-indexed; fields:. >>> result_ht = hl.logistic_regression_rows(; ... test='wald',; ... y=dataset.pheno.is_case,; ... x=dataset.GT.n_alt_alleles(),; ... covariates=[1, dataset.pheno.age, dataset.pheno.is_female]). Run the logistic regression Wald test per variant using a list of binary (0/1); phenotypes, intercept and two covariates stored in column-indexed; fields:. >>> result_ht = hl.logistic_regression_rows(; ... test='wald',; ... y=[dataset.pheno.is_case, dataset.pheno.is_case], # where pheno values are 0, 1, or missing; ... x=dataset.GT.n_alt_alleles(),; ... covariates=[1, dataset.pheno.age, dataset.pheno.is_female]). As above but with at most 100 Newton iterations and a stricter-than-default tolerance of 1e-8:. >>> result_ht = hl.logistic_regression_rows(; ... test='wald',; ... y=[dataset.pheno.is_case, dataset.pheno.is_case], # where pheno values are 0, 1, or missing; ... x=dataset.GT.n_alt_alleles(),; ... covariates=[1, dataset.pheno.age, dataset.pheno.is_female],; ... max_iterations=100,; ... tolerance=1e-8). Warning; -------; :func:`.logistic_regression_rows` considers the same set of; columns (i.e., samples, points) for every row, namely those columns for; which **all** response variables and covariates are defined. For each row, missing values of; `x` are mean-imputed over these columns. As in the example, the; intercept covariate ``1`` must be included **explicitly** if desired. Notes; -----; This method performs, for each row, a significance test of the input; variable in predicting a binary (case-control) response variable based; on the logistic regression model. The response variable type must either; be numeric (with all present valu",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:27561,Availability,toler,tolerance,27561,"result_ht = hl.logistic_regression_rows(; ... test='wald',; ... y=dataset.pheno.is_case,; ... x=dataset.GT.n_alt_alleles(),; ... covariates=[1, dataset.pheno.age, dataset.pheno.is_female]). Run the logistic regression Wald test per variant using a list of binary (0/1); phenotypes, intercept and two covariates stored in column-indexed; fields:. >>> result_ht = hl.logistic_regression_rows(; ... test='wald',; ... y=[dataset.pheno.is_case, dataset.pheno.is_case], # where pheno values are 0, 1, or missing; ... x=dataset.GT.n_alt_alleles(),; ... covariates=[1, dataset.pheno.age, dataset.pheno.is_female]). As above but with at most 100 Newton iterations and a stricter-than-default tolerance of 1e-8:. >>> result_ht = hl.logistic_regression_rows(; ... test='wald',; ... y=[dataset.pheno.is_case, dataset.pheno.is_case], # where pheno values are 0, 1, or missing; ... x=dataset.GT.n_alt_alleles(),; ... covariates=[1, dataset.pheno.age, dataset.pheno.is_female],; ... max_iterations=100,; ... tolerance=1e-8). Warning; -------; :func:`.logistic_regression_rows` considers the same set of; columns (i.e., samples, points) for every row, namely those columns for; which **all** response variables and covariates are defined. For each row, missing values of; `x` are mean-imputed over these columns. As in the example, the; intercept covariate ``1`` must be included **explicitly** if desired. Notes; -----; This method performs, for each row, a significance test of the input; variable in predicting a binary (case-control) response variable based; on the logistic regression model. The response variable type must either; be numeric (with all present values 0 or 1) or Boolean, in which case; true and false are coded as 1 and 0, respectively. Hail supports the Wald test ('wald'), likelihood ratio test ('lrt'),; Rao score test ('score'), and Firth test ('firth'). Hail only includes; columns for which the response variable and all covariates are defined.; For each row, Hail imputes missing input va",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:29671,Availability,error,error,29671," + \varepsilon),; \quad; \varepsilon \sim \mathrm{N}(0, \sigma^2). where :math:`\mathrm{sigmoid}` is the `sigmoid function`_, the genotype; :math:`\mathrm{gt}` is coded as 0 for HomRef, 1 for Het, and 2 for; HomVar, and the Boolean covariate :math:`\mathrm{is\_female}` is coded as; for ``True`` (female) and 0 for ``False`` (male). The null model sets; :math:`\beta_1 = 0`. .. _sigmoid function: https://en.wikipedia.org/wiki/Sigmoid_function. The structure of the emitted row field depends on the test statistic as; shown in the tables below. ========== ================== ======= ============================================; Test Field Type Value; ========== ================== ======= ============================================; Wald `beta` float64 fit effect coefficient,; :math:`\hat\beta_1`; Wald `standard_error` float64 estimated standard error,; :math:`\widehat{\mathrm{se}}`; Wald `z_stat` float64 Wald :math:`z`-statistic, equal to; :math:`\hat\beta_1 / \widehat{\mathrm{se}}`; Wald `p_value` float64 Wald p-value testing :math:`\beta_1 = 0`; LRT, Firth `beta` float64 fit effect coefficient,; :math:`\hat\beta_1`; LRT, Firth `chi_sq_stat` float64 deviance statistic; LRT, Firth `p_value` float64 LRT / Firth p-value testing; :math:`\beta_1 = 0`; Score `chi_sq_stat` float64 score statistic; Score `p_value` float64 score p-value testing :math:`\beta_1 = 0`; ========== ================== ======= ============================================. For the Wald and likelihood ratio tests, Hail fits the logistic model for; each row using Newton iteration and only emits the above fields; when the maximum likelihood estimate of the coefficients converges. The; Firth test uses a modified form of Newton iteration. To help diagnose; convergence issues, Hail also emits three fields which summarize the; iterative fitting process:. ================ =================== ======= ===============================; Test Field Type Value; ================ =================== ======= ===============",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:32435,Availability,error,errors,32435,"g we find 4 or 5; iterations nearly always suffice. Convergence may also fail due to; explosion, which refers to low-level numerical linear algebra exceptions; caused by manipulating ill-conditioned matrices. Explosion may result from; (nearly) linearly dependent covariates or complete separation_. .. _separation: https://en.wikipedia.org/wiki/Separation_(statistics). A more common situation in genetics is quasi-complete seperation, e.g.; variants that are observed only in cases (or controls). Such variants; inevitably arise when testing millions of variants with very low minor; allele count. The maximum likelihood estimate of :math:`\beta` under; logistic regression is then undefined but convergence may still occur; after a large number of iterations due to a very flat likelihood; surface. In testing, we find that such variants produce a secondary bump; from 10 to 15 iterations in the histogram of number of iterations per; variant. We also find that this faux convergence produces large standard; errors and large (insignificant) p-values. To not miss such variants,; consider using Firth logistic regression, linear regression, or; group-based tests. Here's a concrete illustration of quasi-complete seperation in R. Suppose; we have 2010 samples distributed as follows for a particular variant:. ======= ====== === ======; Status HomRef Het HomVar; ======= ====== === ======; Case 1000 10 0; Control 1000 0 0; ======= ====== === ======. The following R code fits the (standard) logistic, Firth logistic,; and linear regression models to this data, where ``x`` is genotype,; ``y`` is phenotype, and ``logistf`` is from the logistf package:. .. code-block:: R. x <- c(rep(0,1000), rep(1,1000), rep(1,10); y <- c(rep(0,1000), rep(0,1000), rep(1,10)); logfit <- glm(y ~ x, family=binomial()); firthfit <- logistf(y ~ x); linfit <- lm(y ~ x). The resulting p-values for the genotype coefficient are 0.991, 0.00085,; and 0.0016, respectively. The erroneous value 0.991 is due to; quasi-com",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:36690,Availability,toler,tolerance,36690,"l row fields from; matrix table underlying ``x``. For example, to include an ""rsid"" field, set; ``pass_through=['rsid']`` or ``pass_through=[mt.rsid]``. Parameters; ----------; test : {'wald', 'lrt', 'score', 'firth'}; Statistical test.; y : :class:`.Float64Expression` or :obj:`list` of :class:`.Float64Expression`; One or more column-indexed response expressions.; All non-missing values must evaluate to 0 or 1.; Note that a :class:`.BooleanExpression` will be implicitly converted to; a :class:`.Float64Expression` with this property.; x : :class:`.Float64Expression`; Entry-indexed expression for input variable.; covariates : :obj:`list` of :class:`.Float64Expression`; Non-empty list of column-indexed covariate expressions.; pass_through : :obj:`list` of :class:`str` or :class:`.Expression`; Additional row fields to include in the resulting table.; max_iterations : :obj:`int`; The maximum number of iterations.; tolerance : :obj:`float`, optional; The iterative fit of this model is considered ""converged"" if the change in the estimated; beta is smaller than tolerance. By default the tolerance is 1e-6. Returns; -------; :class:`.Table`. """"""; if max_iterations is None:; max_iterations = 25 if test != 'firth' else 100. if hl.current_backend().requires_lowering:; return _logistic_regression_rows_nd(; test, y, x, covariates, pass_through, max_iterations=max_iterations, tolerance=tolerance; ). if tolerance is None:; tolerance = 1e-6; assert tolerance > 0.0. if len(covariates) == 0:; raise ValueError('logistic regression requires at least one covariate expression'). mt = matrix_table_source('logistic_regresion_rows/x', x); raise_unless_entry_indexed('logistic_regresion_rows/x', x). y_is_list = isinstance(y, list); if y_is_list and len(y) == 0:; raise ValueError(""'logistic_regression_rows': found no values for 'y'""); y = [raise_unless_column_indexed('logistic_regression_rows/y', y) or y for y in wrap_to_list(y)]. for e in covariates:; analyze('logistic_regression_rows/covariates",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:36837,Availability,toler,tolerance,36837,"l row fields from; matrix table underlying ``x``. For example, to include an ""rsid"" field, set; ``pass_through=['rsid']`` or ``pass_through=[mt.rsid]``. Parameters; ----------; test : {'wald', 'lrt', 'score', 'firth'}; Statistical test.; y : :class:`.Float64Expression` or :obj:`list` of :class:`.Float64Expression`; One or more column-indexed response expressions.; All non-missing values must evaluate to 0 or 1.; Note that a :class:`.BooleanExpression` will be implicitly converted to; a :class:`.Float64Expression` with this property.; x : :class:`.Float64Expression`; Entry-indexed expression for input variable.; covariates : :obj:`list` of :class:`.Float64Expression`; Non-empty list of column-indexed covariate expressions.; pass_through : :obj:`list` of :class:`str` or :class:`.Expression`; Additional row fields to include in the resulting table.; max_iterations : :obj:`int`; The maximum number of iterations.; tolerance : :obj:`float`, optional; The iterative fit of this model is considered ""converged"" if the change in the estimated; beta is smaller than tolerance. By default the tolerance is 1e-6. Returns; -------; :class:`.Table`. """"""; if max_iterations is None:; max_iterations = 25 if test != 'firth' else 100. if hl.current_backend().requires_lowering:; return _logistic_regression_rows_nd(; test, y, x, covariates, pass_through, max_iterations=max_iterations, tolerance=tolerance; ). if tolerance is None:; tolerance = 1e-6; assert tolerance > 0.0. if len(covariates) == 0:; raise ValueError('logistic regression requires at least one covariate expression'). mt = matrix_table_source('logistic_regresion_rows/x', x); raise_unless_entry_indexed('logistic_regresion_rows/x', x). y_is_list = isinstance(y, list); if y_is_list and len(y) == 0:; raise ValueError(""'logistic_regression_rows': found no values for 'y'""); y = [raise_unless_column_indexed('logistic_regression_rows/y', y) or y for y in wrap_to_list(y)]. for e in covariates:; analyze('logistic_regression_rows/covariates",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:36863,Availability,toler,tolerance,36863,"`pass_through=['rsid']`` or ``pass_through=[mt.rsid]``. Parameters; ----------; test : {'wald', 'lrt', 'score', 'firth'}; Statistical test.; y : :class:`.Float64Expression` or :obj:`list` of :class:`.Float64Expression`; One or more column-indexed response expressions.; All non-missing values must evaluate to 0 or 1.; Note that a :class:`.BooleanExpression` will be implicitly converted to; a :class:`.Float64Expression` with this property.; x : :class:`.Float64Expression`; Entry-indexed expression for input variable.; covariates : :obj:`list` of :class:`.Float64Expression`; Non-empty list of column-indexed covariate expressions.; pass_through : :obj:`list` of :class:`str` or :class:`.Expression`; Additional row fields to include in the resulting table.; max_iterations : :obj:`int`; The maximum number of iterations.; tolerance : :obj:`float`, optional; The iterative fit of this model is considered ""converged"" if the change in the estimated; beta is smaller than tolerance. By default the tolerance is 1e-6. Returns; -------; :class:`.Table`. """"""; if max_iterations is None:; max_iterations = 25 if test != 'firth' else 100. if hl.current_backend().requires_lowering:; return _logistic_regression_rows_nd(; test, y, x, covariates, pass_through, max_iterations=max_iterations, tolerance=tolerance; ). if tolerance is None:; tolerance = 1e-6; assert tolerance > 0.0. if len(covariates) == 0:; raise ValueError('logistic regression requires at least one covariate expression'). mt = matrix_table_source('logistic_regresion_rows/x', x); raise_unless_entry_indexed('logistic_regresion_rows/x', x). y_is_list = isinstance(y, list); if y_is_list and len(y) == 0:; raise ValueError(""'logistic_regression_rows': found no values for 'y'""); y = [raise_unless_column_indexed('logistic_regression_rows/y', y) or y for y in wrap_to_list(y)]. for e in covariates:; analyze('logistic_regression_rows/covariates', e, mt._col_indices). _warn_if_no_intercept('logistic_regression_rows', covariates). x_field_n",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:37150,Availability,toler,tolerance,37150,"lumn-indexed response expressions.; All non-missing values must evaluate to 0 or 1.; Note that a :class:`.BooleanExpression` will be implicitly converted to; a :class:`.Float64Expression` with this property.; x : :class:`.Float64Expression`; Entry-indexed expression for input variable.; covariates : :obj:`list` of :class:`.Float64Expression`; Non-empty list of column-indexed covariate expressions.; pass_through : :obj:`list` of :class:`str` or :class:`.Expression`; Additional row fields to include in the resulting table.; max_iterations : :obj:`int`; The maximum number of iterations.; tolerance : :obj:`float`, optional; The iterative fit of this model is considered ""converged"" if the change in the estimated; beta is smaller than tolerance. By default the tolerance is 1e-6. Returns; -------; :class:`.Table`. """"""; if max_iterations is None:; max_iterations = 25 if test != 'firth' else 100. if hl.current_backend().requires_lowering:; return _logistic_regression_rows_nd(; test, y, x, covariates, pass_through, max_iterations=max_iterations, tolerance=tolerance; ). if tolerance is None:; tolerance = 1e-6; assert tolerance > 0.0. if len(covariates) == 0:; raise ValueError('logistic regression requires at least one covariate expression'). mt = matrix_table_source('logistic_regresion_rows/x', x); raise_unless_entry_indexed('logistic_regresion_rows/x', x). y_is_list = isinstance(y, list); if y_is_list and len(y) == 0:; raise ValueError(""'logistic_regression_rows': found no values for 'y'""); y = [raise_unless_column_indexed('logistic_regression_rows/y', y) or y for y in wrap_to_list(y)]. for e in covariates:; analyze('logistic_regression_rows/covariates', e, mt._col_indices). _warn_if_no_intercept('logistic_regression_rows', covariates). x_field_name = Env.get_uid(); y_field = [f'__y_{i}' for i in range(len(y))]. y_dict = dict(zip(y_field, y)). cov_field_names = [f'__cov{i}' for i in range(len(covariates))]; row_fields = _get_regression_row_fields(mt, pass_through, 'logistic_r",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:37160,Availability,toler,tolerance,37160,"lumn-indexed response expressions.; All non-missing values must evaluate to 0 or 1.; Note that a :class:`.BooleanExpression` will be implicitly converted to; a :class:`.Float64Expression` with this property.; x : :class:`.Float64Expression`; Entry-indexed expression for input variable.; covariates : :obj:`list` of :class:`.Float64Expression`; Non-empty list of column-indexed covariate expressions.; pass_through : :obj:`list` of :class:`str` or :class:`.Expression`; Additional row fields to include in the resulting table.; max_iterations : :obj:`int`; The maximum number of iterations.; tolerance : :obj:`float`, optional; The iterative fit of this model is considered ""converged"" if the change in the estimated; beta is smaller than tolerance. By default the tolerance is 1e-6. Returns; -------; :class:`.Table`. """"""; if max_iterations is None:; max_iterations = 25 if test != 'firth' else 100. if hl.current_backend().requires_lowering:; return _logistic_regression_rows_nd(; test, y, x, covariates, pass_through, max_iterations=max_iterations, tolerance=tolerance; ). if tolerance is None:; tolerance = 1e-6; assert tolerance > 0.0. if len(covariates) == 0:; raise ValueError('logistic regression requires at least one covariate expression'). mt = matrix_table_source('logistic_regresion_rows/x', x); raise_unless_entry_indexed('logistic_regresion_rows/x', x). y_is_list = isinstance(y, list); if y_is_list and len(y) == 0:; raise ValueError(""'logistic_regression_rows': found no values for 'y'""); y = [raise_unless_column_indexed('logistic_regression_rows/y', y) or y for y in wrap_to_list(y)]. for e in covariates:; analyze('logistic_regression_rows/covariates', e, mt._col_indices). _warn_if_no_intercept('logistic_regression_rows', covariates). x_field_name = Env.get_uid(); y_field = [f'__y_{i}' for i in range(len(y))]. y_dict = dict(zip(y_field, y)). cov_field_names = [f'__cov{i}' for i in range(len(covariates))]; row_fields = _get_regression_row_fields(mt, pass_through, 'logistic_r",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:37177,Availability,toler,tolerance,37177,"BooleanExpression` will be implicitly converted to; a :class:`.Float64Expression` with this property.; x : :class:`.Float64Expression`; Entry-indexed expression for input variable.; covariates : :obj:`list` of :class:`.Float64Expression`; Non-empty list of column-indexed covariate expressions.; pass_through : :obj:`list` of :class:`str` or :class:`.Expression`; Additional row fields to include in the resulting table.; max_iterations : :obj:`int`; The maximum number of iterations.; tolerance : :obj:`float`, optional; The iterative fit of this model is considered ""converged"" if the change in the estimated; beta is smaller than tolerance. By default the tolerance is 1e-6. Returns; -------; :class:`.Table`. """"""; if max_iterations is None:; max_iterations = 25 if test != 'firth' else 100. if hl.current_backend().requires_lowering:; return _logistic_regression_rows_nd(; test, y, x, covariates, pass_through, max_iterations=max_iterations, tolerance=tolerance; ). if tolerance is None:; tolerance = 1e-6; assert tolerance > 0.0. if len(covariates) == 0:; raise ValueError('logistic regression requires at least one covariate expression'). mt = matrix_table_source('logistic_regresion_rows/x', x); raise_unless_entry_indexed('logistic_regresion_rows/x', x). y_is_list = isinstance(y, list); if y_is_list and len(y) == 0:; raise ValueError(""'logistic_regression_rows': found no values for 'y'""); y = [raise_unless_column_indexed('logistic_regression_rows/y', y) or y for y in wrap_to_list(y)]. for e in covariates:; analyze('logistic_regression_rows/covariates', e, mt._col_indices). _warn_if_no_intercept('logistic_regression_rows', covariates). x_field_name = Env.get_uid(); y_field = [f'__y_{i}' for i in range(len(y))]. y_dict = dict(zip(y_field, y)). cov_field_names = [f'__cov{i}' for i in range(len(covariates))]; row_fields = _get_regression_row_fields(mt, pass_through, 'logistic_regression_rows'). # FIXME: selecting an existing entry field should be emitted as a SelectFields; mt = mt._",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:37197,Availability,toler,tolerance,37197,"BooleanExpression` will be implicitly converted to; a :class:`.Float64Expression` with this property.; x : :class:`.Float64Expression`; Entry-indexed expression for input variable.; covariates : :obj:`list` of :class:`.Float64Expression`; Non-empty list of column-indexed covariate expressions.; pass_through : :obj:`list` of :class:`str` or :class:`.Expression`; Additional row fields to include in the resulting table.; max_iterations : :obj:`int`; The maximum number of iterations.; tolerance : :obj:`float`, optional; The iterative fit of this model is considered ""converged"" if the change in the estimated; beta is smaller than tolerance. By default the tolerance is 1e-6. Returns; -------; :class:`.Table`. """"""; if max_iterations is None:; max_iterations = 25 if test != 'firth' else 100. if hl.current_backend().requires_lowering:; return _logistic_regression_rows_nd(; test, y, x, covariates, pass_through, max_iterations=max_iterations, tolerance=tolerance; ). if tolerance is None:; tolerance = 1e-6; assert tolerance > 0.0. if len(covariates) == 0:; raise ValueError('logistic regression requires at least one covariate expression'). mt = matrix_table_source('logistic_regresion_rows/x', x); raise_unless_entry_indexed('logistic_regresion_rows/x', x). y_is_list = isinstance(y, list); if y_is_list and len(y) == 0:; raise ValueError(""'logistic_regression_rows': found no values for 'y'""); y = [raise_unless_column_indexed('logistic_regression_rows/y', y) or y for y in wrap_to_list(y)]. for e in covariates:; analyze('logistic_regression_rows/covariates', e, mt._col_indices). _warn_if_no_intercept('logistic_regression_rows', covariates). x_field_name = Env.get_uid(); y_field = [f'__y_{i}' for i in range(len(y))]. y_dict = dict(zip(y_field, y)). cov_field_names = [f'__cov{i}' for i in range(len(covariates))]; row_fields = _get_regression_row_fields(mt, pass_through, 'logistic_regression_rows'). # FIXME: selecting an existing entry field should be emitted as a SelectFields; mt = mt._",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:37222,Availability,toler,tolerance,37222,"BooleanExpression` will be implicitly converted to; a :class:`.Float64Expression` with this property.; x : :class:`.Float64Expression`; Entry-indexed expression for input variable.; covariates : :obj:`list` of :class:`.Float64Expression`; Non-empty list of column-indexed covariate expressions.; pass_through : :obj:`list` of :class:`str` or :class:`.Expression`; Additional row fields to include in the resulting table.; max_iterations : :obj:`int`; The maximum number of iterations.; tolerance : :obj:`float`, optional; The iterative fit of this model is considered ""converged"" if the change in the estimated; beta is smaller than tolerance. By default the tolerance is 1e-6. Returns; -------; :class:`.Table`. """"""; if max_iterations is None:; max_iterations = 25 if test != 'firth' else 100. if hl.current_backend().requires_lowering:; return _logistic_regression_rows_nd(; test, y, x, covariates, pass_through, max_iterations=max_iterations, tolerance=tolerance; ). if tolerance is None:; tolerance = 1e-6; assert tolerance > 0.0. if len(covariates) == 0:; raise ValueError('logistic regression requires at least one covariate expression'). mt = matrix_table_source('logistic_regresion_rows/x', x); raise_unless_entry_indexed('logistic_regresion_rows/x', x). y_is_list = isinstance(y, list); if y_is_list and len(y) == 0:; raise ValueError(""'logistic_regression_rows': found no values for 'y'""); y = [raise_unless_column_indexed('logistic_regression_rows/y', y) or y for y in wrap_to_list(y)]. for e in covariates:; analyze('logistic_regression_rows/covariates', e, mt._col_indices). _warn_if_no_intercept('logistic_regression_rows', covariates). x_field_name = Env.get_uid(); y_field = [f'__y_{i}' for i in range(len(y))]. y_dict = dict(zip(y_field, y)). cov_field_names = [f'__cov{i}' for i in range(len(covariates))]; row_fields = _get_regression_row_fields(mt, pass_through, 'logistic_regression_rows'). # FIXME: selecting an existing entry field should be emitted as a SelectFields; mt = mt._",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:38592,Availability,toler,tolerance,38592," no values for 'y'""); y = [raise_unless_column_indexed('logistic_regression_rows/y', y) or y for y in wrap_to_list(y)]. for e in covariates:; analyze('logistic_regression_rows/covariates', e, mt._col_indices). _warn_if_no_intercept('logistic_regression_rows', covariates). x_field_name = Env.get_uid(); y_field = [f'__y_{i}' for i in range(len(y))]. y_dict = dict(zip(y_field, y)). cov_field_names = [f'__cov{i}' for i in range(len(covariates))]; row_fields = _get_regression_row_fields(mt, pass_through, 'logistic_regression_rows'). # FIXME: selecting an existing entry field should be emitted as a SelectFields; mt = mt._select_all(; col_exprs=dict(**y_dict, **dict(zip(cov_field_names, covariates))),; row_exprs=row_fields,; col_key=[],; entry_exprs={x_field_name: x},; ). config = {; 'name': 'LogisticRegression',; 'test': test,; 'yFields': y_field,; 'xField': x_field_name,; 'covFields': cov_field_names,; 'passThrough': [x for x in row_fields if x not in mt.row_key],; 'maxIterations': max_iterations,; 'tolerance': tolerance,; }. result = Table(ir.MatrixToTableApply(mt._mir, config)). if not y_is_list:; result = result.transmute(**result.logistic_regression[0]). return result.persist(). # Helpers for logreg:; def mean_impute(hl_array):; non_missing_mean = hl.mean(hl_array, filter_missing=True); return hl_array.map(lambda entry: hl.coalesce(entry, non_missing_mean)). sigmoid = expit. def nd_max(hl_nd):; return hl.max(hl.array(hl_nd.reshape(-1))). def logreg_fit(; X: NDArrayNumericExpression, # (K,); y: NDArrayNumericExpression, # (N, K); null_fit: Optional[StructExpression],; max_iterations: int,; tolerance: float,; ) -> StructExpression:; """"""Iteratively reweighted least squares to fit the model y ~ Bernoulli(logit(X \beta)). When fitting the null model, K=n_covariates, otherwise K=n_covariates + 1.; """"""; assert max_iterations >= 0; assert X.ndim == 2; assert y.ndim == 1; # X is samples by covs.; # y is length num samples, for one cov.; n = X.shape[0]; m = X.shape[1]. if null",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:38604,Availability,toler,tolerance,38604," no values for 'y'""); y = [raise_unless_column_indexed('logistic_regression_rows/y', y) or y for y in wrap_to_list(y)]. for e in covariates:; analyze('logistic_regression_rows/covariates', e, mt._col_indices). _warn_if_no_intercept('logistic_regression_rows', covariates). x_field_name = Env.get_uid(); y_field = [f'__y_{i}' for i in range(len(y))]. y_dict = dict(zip(y_field, y)). cov_field_names = [f'__cov{i}' for i in range(len(covariates))]; row_fields = _get_regression_row_fields(mt, pass_through, 'logistic_regression_rows'). # FIXME: selecting an existing entry field should be emitted as a SelectFields; mt = mt._select_all(; col_exprs=dict(**y_dict, **dict(zip(cov_field_names, covariates))),; row_exprs=row_fields,; col_key=[],; entry_exprs={x_field_name: x},; ). config = {; 'name': 'LogisticRegression',; 'test': test,; 'yFields': y_field,; 'xField': x_field_name,; 'covFields': cov_field_names,; 'passThrough': [x for x in row_fields if x not in mt.row_key],; 'maxIterations': max_iterations,; 'tolerance': tolerance,; }. result = Table(ir.MatrixToTableApply(mt._mir, config)). if not y_is_list:; result = result.transmute(**result.logistic_regression[0]). return result.persist(). # Helpers for logreg:; def mean_impute(hl_array):; non_missing_mean = hl.mean(hl_array, filter_missing=True); return hl_array.map(lambda entry: hl.coalesce(entry, non_missing_mean)). sigmoid = expit. def nd_max(hl_nd):; return hl.max(hl.array(hl_nd.reshape(-1))). def logreg_fit(; X: NDArrayNumericExpression, # (K,); y: NDArrayNumericExpression, # (N, K); null_fit: Optional[StructExpression],; max_iterations: int,; tolerance: float,; ) -> StructExpression:; """"""Iteratively reweighted least squares to fit the model y ~ Bernoulli(logit(X \beta)). When fitting the null model, K=n_covariates, otherwise K=n_covariates + 1.; """"""; assert max_iterations >= 0; assert X.ndim == 2; assert y.ndim == 1; # X is samples by covs.; # y is length num samples, for one cov.; n = X.shape[0]; m = X.shape[1]. if null",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:39197,Availability,toler,tolerance,39197,"lectFields; mt = mt._select_all(; col_exprs=dict(**y_dict, **dict(zip(cov_field_names, covariates))),; row_exprs=row_fields,; col_key=[],; entry_exprs={x_field_name: x},; ). config = {; 'name': 'LogisticRegression',; 'test': test,; 'yFields': y_field,; 'xField': x_field_name,; 'covFields': cov_field_names,; 'passThrough': [x for x in row_fields if x not in mt.row_key],; 'maxIterations': max_iterations,; 'tolerance': tolerance,; }. result = Table(ir.MatrixToTableApply(mt._mir, config)). if not y_is_list:; result = result.transmute(**result.logistic_regression[0]). return result.persist(). # Helpers for logreg:; def mean_impute(hl_array):; non_missing_mean = hl.mean(hl_array, filter_missing=True); return hl_array.map(lambda entry: hl.coalesce(entry, non_missing_mean)). sigmoid = expit. def nd_max(hl_nd):; return hl.max(hl.array(hl_nd.reshape(-1))). def logreg_fit(; X: NDArrayNumericExpression, # (K,); y: NDArrayNumericExpression, # (N, K); null_fit: Optional[StructExpression],; max_iterations: int,; tolerance: float,; ) -> StructExpression:; """"""Iteratively reweighted least squares to fit the model y ~ Bernoulli(logit(X \beta)). When fitting the null model, K=n_covariates, otherwise K=n_covariates + 1.; """"""; assert max_iterations >= 0; assert X.ndim == 2; assert y.ndim == 1; # X is samples by covs.; # y is length num samples, for one cov.; n = X.shape[0]; m = X.shape[1]. if null_fit is None:; avg = y.sum() / n; logit_avg = hl.log(avg / (1 - avg)); b = hl.nd.hstack([hl.nd.array([logit_avg]), hl.nd.zeros((hl.int32(m - 1)))]); mu = sigmoid(X @ b); score = X.T @ (y - mu); # Reshape so we do a rowwise multiply; fisher = X.T @ (X * (mu * (1 - mu)).reshape(-1, 1)); else:; # num covs used to fit null model.; m0 = null_fit.b.shape[0]; m_diff = m - m0. X0 = X[:, 0:m0]; X1 = X[:, m0:]. b = hl.nd.hstack([null_fit.b, hl.nd.zeros((m_diff,))]); mu = sigmoid(X @ b); score = hl.nd.hstack([null_fit.score, X1.T @ (y - mu)]). fisher00 = null_fit.fisher; fisher01 = X0.T @ (X1 * (mu * (1 - m",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:40988,Availability,toler,tolerance,40988,". b = hl.nd.hstack([null_fit.b, hl.nd.zeros((m_diff,))]); mu = sigmoid(X @ b); score = hl.nd.hstack([null_fit.score, X1.T @ (y - mu)]). fisher00 = null_fit.fisher; fisher01 = X0.T @ (X1 * (mu * (1 - mu)).reshape(-1, 1)); fisher10 = fisher01.T; fisher11 = X1.T @ (X1 * (mu * (1 - mu)).reshape(-1, 1)). fisher = hl.nd.vstack([hl.nd.hstack([fisher00, fisher01]), hl.nd.hstack([fisher10, fisher11])]). dtype = numerical_regression_fit_dtype; blank_struct = hl.struct(**{k: hl.missing(dtype[k]) for k in dtype}). def search(recur, iteration, b, mu, score, fisher):; def cont(exploded, delta_b, max_delta_b):; log_lkhd = hl.log((y * mu) + (1 - y) * (1 - mu)).sum(). next_b = b + delta_b; next_mu = sigmoid(X @ next_b); next_score = X.T @ (y - next_mu); next_fisher = X.T @ (X * (next_mu * (1 - next_mu)).reshape(-1, 1)). return (; hl.case(); .when(; exploded | hl.is_nan(delta_b[0]),; blank_struct.annotate(n_iterations=iteration, log_lkhd=log_lkhd, converged=False, exploded=True),; ); .when(; max_delta_b < tolerance,; hl.struct(; b=b,; score=score,; fisher=fisher,; mu=mu,; n_iterations=iteration,; log_lkhd=log_lkhd,; converged=True,; exploded=False,; ),; ); .when(; iteration == max_iterations,; blank_struct.annotate(n_iterations=iteration, log_lkhd=log_lkhd, converged=False, exploded=False),; ); .default(recur(iteration + 1, next_b, next_mu, next_score, next_fisher)); ). delta_b_struct = hl.nd.solve(fisher, score, no_crash=True); exploded = delta_b_struct.failed; delta_b = delta_b_struct.solution; max_delta_b = nd_max(hl.abs(delta_b)); return hl.bind(cont, exploded, delta_b, max_delta_b). if max_iterations == 0:; return blank_struct.annotate(n_iterations=0, log_lkhd=0, converged=False, exploded=False); return hl.experimental.loop(search, numerical_regression_fit_dtype, 1, b, mu, score, fisher). def wald_test(X, fit):; se = hl.sqrt(hl.nd.diagonal(hl.nd.inv(fit.fisher))); z = fit.b / se; p = z.map(lambda e: 2 * hl.pnorm(-hl.abs(e))); return hl.struct(; beta=fit.b[X.shape[1] - 1],; stand",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:43413,Availability,toler,tolerance,43413,"it.select('n_iterations', 'converged', 'exploded'),; ). def logistic_score_test(X, y, null_fit):; m = X.shape[1]; m0 = null_fit.b.shape[0]; b = hl.nd.hstack([null_fit.b, hl.nd.zeros((hl.int32(m - m0)))]). X0 = X[:, 0:m0]; X1 = X[:, m0:]. mu = hl.expit(X @ b). score_0 = null_fit.score; score_1 = X1.T @ (y - mu); score = hl.nd.hstack([score_0, score_1]). fisher00 = null_fit.fisher; fisher01 = X0.T @ (X1 * (mu * (1 - mu)).reshape(-1, 1)); fisher10 = fisher01.T; fisher11 = X1.T @ (X1 * (mu * (1 - mu)).reshape(-1, 1)). fisher = hl.nd.vstack([hl.nd.hstack([fisher00, fisher01]), hl.nd.hstack([fisher10, fisher11])]). solve_attempt = hl.nd.solve(fisher, score, no_crash=True). chi_sq = hl.or_missing(~solve_attempt.failed, (score * solve_attempt.solution).sum()). p = hl.pchisqtail(chi_sq, m - m0). return hl.struct(chi_sq_stat=chi_sq, p_value=p). def _firth_fit(; b: NDArrayNumericExpression, # (K,); X: NDArrayNumericExpression, # (N, K); y: NDArrayNumericExpression, # (N,); max_iterations: int,; tolerance: float,; ) -> StructExpression:; """"""Iteratively reweighted least squares using Firth's regression to fit the model y ~ Bernoulli(logit(X \beta)). When fitting the null model, K=n_covariates, otherwise K=n_covariates + 1.; """"""; assert max_iterations >= 0; assert X.ndim == 2; assert y.ndim == 1; assert b.ndim == 1. dtype = numerical_regression_fit_dtype._drop_fields(['score', 'fisher']); blank_struct = hl.struct(**{k: hl.missing(dtype[k]) for k in dtype}); X_bslice = X[:, : b.shape[0]]. def fit(recur, iteration, b):; def cont(exploded, delta_b, max_delta_b):; log_lkhd_left = hl.log(y * mu + (hl.literal(1.0) - y) * (1 - mu)).sum(); log_lkhd_right = hl.log(hl.abs(hl.nd.diagonal(r))).sum(); log_lkhd = log_lkhd_left + log_lkhd_right. next_b = b + delta_b. return (; hl.case(); .when(; exploded | hl.is_nan(delta_b[0]),; blank_struct.annotate(n_iterations=iteration, log_lkhd=log_lkhd, converged=False, exploded=True),; ); .when(; max_delta_b < tolerance,; hl.struct(b=b, mu=mu, n_iterati",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:44371,Availability,toler,tolerance,44371,"ricExpression, # (N,); max_iterations: int,; tolerance: float,; ) -> StructExpression:; """"""Iteratively reweighted least squares using Firth's regression to fit the model y ~ Bernoulli(logit(X \beta)). When fitting the null model, K=n_covariates, otherwise K=n_covariates + 1.; """"""; assert max_iterations >= 0; assert X.ndim == 2; assert y.ndim == 1; assert b.ndim == 1. dtype = numerical_regression_fit_dtype._drop_fields(['score', 'fisher']); blank_struct = hl.struct(**{k: hl.missing(dtype[k]) for k in dtype}); X_bslice = X[:, : b.shape[0]]. def fit(recur, iteration, b):; def cont(exploded, delta_b, max_delta_b):; log_lkhd_left = hl.log(y * mu + (hl.literal(1.0) - y) * (1 - mu)).sum(); log_lkhd_right = hl.log(hl.abs(hl.nd.diagonal(r))).sum(); log_lkhd = log_lkhd_left + log_lkhd_right. next_b = b + delta_b. return (; hl.case(); .when(; exploded | hl.is_nan(delta_b[0]),; blank_struct.annotate(n_iterations=iteration, log_lkhd=log_lkhd, converged=False, exploded=True),; ); .when(; max_delta_b < tolerance,; hl.struct(b=b, mu=mu, n_iterations=iteration, log_lkhd=log_lkhd, converged=True, exploded=False),; ); .when(; iteration == max_iterations,; blank_struct.annotate(n_iterations=iteration, log_lkhd=log_lkhd, converged=False, exploded=False),; ); .default(recur(iteration + 1, next_b)); ). m = b.shape[0] # n_covariates or n_covariates + 1, depending on improved null fit vs full fit; mu = sigmoid(X_bslice @ b); sqrtW = hl.sqrt(mu * (1 - mu)); q, r = hl.nd.qr(X * sqrtW.T.reshape(-1, 1)); h = (q * q).sum(1); coef = r[:m, :m]; residual = y - mu; dep = q[:, :m].T @ ((residual + (h * (0.5 - mu))) / sqrtW); delta_b_struct = hl.nd.solve_triangular(coef, dep.reshape(-1, 1), no_crash=True); exploded = delta_b_struct.failed; delta_b = delta_b_struct.solution.reshape(-1). max_delta_b = nd_max(hl.abs(delta_b)). return hl.bind(cont, exploded, delta_b, max_delta_b). if max_iterations == 0:; return blank_struct.annotate(n_iterations=0, log_lkhd=0, converged=False, exploded=False); return hl.",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:45453,Availability,toler,tolerance,45453,"oded=False),; ); .when(; iteration == max_iterations,; blank_struct.annotate(n_iterations=iteration, log_lkhd=log_lkhd, converged=False, exploded=False),; ); .default(recur(iteration + 1, next_b)); ). m = b.shape[0] # n_covariates or n_covariates + 1, depending on improved null fit vs full fit; mu = sigmoid(X_bslice @ b); sqrtW = hl.sqrt(mu * (1 - mu)); q, r = hl.nd.qr(X * sqrtW.T.reshape(-1, 1)); h = (q * q).sum(1); coef = r[:m, :m]; residual = y - mu; dep = q[:, :m].T @ ((residual + (h * (0.5 - mu))) / sqrtW); delta_b_struct = hl.nd.solve_triangular(coef, dep.reshape(-1, 1), no_crash=True); exploded = delta_b_struct.failed; delta_b = delta_b_struct.solution.reshape(-1). max_delta_b = nd_max(hl.abs(delta_b)). return hl.bind(cont, exploded, delta_b, max_delta_b). if max_iterations == 0:; return blank_struct.annotate(n_iterations=0, log_lkhd=0, converged=False, exploded=False); return hl.experimental.loop(fit, dtype, 1, b). def _firth_test(null_fit, X, y, max_iterations, tolerance) -> StructExpression:; firth_improved_null_fit = _firth_fit(null_fit.b, X, y, max_iterations=max_iterations, tolerance=tolerance); dof = 1 # 1 variant. def cont(firth_improved_null_fit):; initial_b_full_model = hl.nd.hstack([firth_improved_null_fit.b, hl.nd.array([0.0])]); firth_fit = _firth_fit(initial_b_full_model, X, y, max_iterations=max_iterations, tolerance=tolerance). def cont2(firth_fit):; firth_chi_sq = 2 * (firth_fit.log_lkhd - firth_improved_null_fit.log_lkhd); firth_p = hl.pchisqtail(firth_chi_sq, dof). blank_struct = hl.struct(; beta=hl.missing(hl.tfloat64),; chi_sq_stat=hl.missing(hl.tfloat64),; p_value=hl.missing(hl.tfloat64),; firth_null_fit=hl.missing(firth_improved_null_fit.dtype),; fit=hl.missing(firth_fit.dtype),; ); return (; hl.case(); .when(; firth_improved_null_fit.converged,; hl.case(); .when(; firth_fit.converged,; hl.struct(; beta=firth_fit.b[firth_fit.b.shape[0] - 1],; chi_sq_stat=firth_chi_sq,; p_value=firth_p,; firth_null_fit=firth_improved_null_fit,; fit=firth",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:45572,Availability,toler,tolerance,45572,"lkhd=log_lkhd, converged=False, exploded=False),; ); .default(recur(iteration + 1, next_b)); ). m = b.shape[0] # n_covariates or n_covariates + 1, depending on improved null fit vs full fit; mu = sigmoid(X_bslice @ b); sqrtW = hl.sqrt(mu * (1 - mu)); q, r = hl.nd.qr(X * sqrtW.T.reshape(-1, 1)); h = (q * q).sum(1); coef = r[:m, :m]; residual = y - mu; dep = q[:, :m].T @ ((residual + (h * (0.5 - mu))) / sqrtW); delta_b_struct = hl.nd.solve_triangular(coef, dep.reshape(-1, 1), no_crash=True); exploded = delta_b_struct.failed; delta_b = delta_b_struct.solution.reshape(-1). max_delta_b = nd_max(hl.abs(delta_b)). return hl.bind(cont, exploded, delta_b, max_delta_b). if max_iterations == 0:; return blank_struct.annotate(n_iterations=0, log_lkhd=0, converged=False, exploded=False); return hl.experimental.loop(fit, dtype, 1, b). def _firth_test(null_fit, X, y, max_iterations, tolerance) -> StructExpression:; firth_improved_null_fit = _firth_fit(null_fit.b, X, y, max_iterations=max_iterations, tolerance=tolerance); dof = 1 # 1 variant. def cont(firth_improved_null_fit):; initial_b_full_model = hl.nd.hstack([firth_improved_null_fit.b, hl.nd.array([0.0])]); firth_fit = _firth_fit(initial_b_full_model, X, y, max_iterations=max_iterations, tolerance=tolerance). def cont2(firth_fit):; firth_chi_sq = 2 * (firth_fit.log_lkhd - firth_improved_null_fit.log_lkhd); firth_p = hl.pchisqtail(firth_chi_sq, dof). blank_struct = hl.struct(; beta=hl.missing(hl.tfloat64),; chi_sq_stat=hl.missing(hl.tfloat64),; p_value=hl.missing(hl.tfloat64),; firth_null_fit=hl.missing(firth_improved_null_fit.dtype),; fit=hl.missing(firth_fit.dtype),; ); return (; hl.case(); .when(; firth_improved_null_fit.converged,; hl.case(); .when(; firth_fit.converged,; hl.struct(; beta=firth_fit.b[firth_fit.b.shape[0] - 1],; chi_sq_stat=firth_chi_sq,; p_value=firth_p,; firth_null_fit=firth_improved_null_fit,; fit=firth_fit,; ),; ); .default(blank_struct.annotate(firth_null_fit=firth_improved_null_fit, fit=firth_fit)),; );",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:45582,Availability,toler,tolerance,45582,"lkhd=log_lkhd, converged=False, exploded=False),; ); .default(recur(iteration + 1, next_b)); ). m = b.shape[0] # n_covariates or n_covariates + 1, depending on improved null fit vs full fit; mu = sigmoid(X_bslice @ b); sqrtW = hl.sqrt(mu * (1 - mu)); q, r = hl.nd.qr(X * sqrtW.T.reshape(-1, 1)); h = (q * q).sum(1); coef = r[:m, :m]; residual = y - mu; dep = q[:, :m].T @ ((residual + (h * (0.5 - mu))) / sqrtW); delta_b_struct = hl.nd.solve_triangular(coef, dep.reshape(-1, 1), no_crash=True); exploded = delta_b_struct.failed; delta_b = delta_b_struct.solution.reshape(-1). max_delta_b = nd_max(hl.abs(delta_b)). return hl.bind(cont, exploded, delta_b, max_delta_b). if max_iterations == 0:; return blank_struct.annotate(n_iterations=0, log_lkhd=0, converged=False, exploded=False); return hl.experimental.loop(fit, dtype, 1, b). def _firth_test(null_fit, X, y, max_iterations, tolerance) -> StructExpression:; firth_improved_null_fit = _firth_fit(null_fit.b, X, y, max_iterations=max_iterations, tolerance=tolerance); dof = 1 # 1 variant. def cont(firth_improved_null_fit):; initial_b_full_model = hl.nd.hstack([firth_improved_null_fit.b, hl.nd.array([0.0])]); firth_fit = _firth_fit(initial_b_full_model, X, y, max_iterations=max_iterations, tolerance=tolerance). def cont2(firth_fit):; firth_chi_sq = 2 * (firth_fit.log_lkhd - firth_improved_null_fit.log_lkhd); firth_p = hl.pchisqtail(firth_chi_sq, dof). blank_struct = hl.struct(; beta=hl.missing(hl.tfloat64),; chi_sq_stat=hl.missing(hl.tfloat64),; p_value=hl.missing(hl.tfloat64),; firth_null_fit=hl.missing(firth_improved_null_fit.dtype),; fit=hl.missing(firth_fit.dtype),; ); return (; hl.case(); .when(; firth_improved_null_fit.converged,; hl.case(); .when(; firth_fit.converged,; hl.struct(; beta=firth_fit.b[firth_fit.b.shape[0] - 1],; chi_sq_stat=firth_chi_sq,; p_value=firth_p,; firth_null_fit=firth_improved_null_fit,; fit=firth_fit,; ),; ); .default(blank_struct.annotate(firth_null_fit=firth_improved_null_fit, fit=firth_fit)),; );",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:45819,Availability,toler,tolerance,45819," @ b); sqrtW = hl.sqrt(mu * (1 - mu)); q, r = hl.nd.qr(X * sqrtW.T.reshape(-1, 1)); h = (q * q).sum(1); coef = r[:m, :m]; residual = y - mu; dep = q[:, :m].T @ ((residual + (h * (0.5 - mu))) / sqrtW); delta_b_struct = hl.nd.solve_triangular(coef, dep.reshape(-1, 1), no_crash=True); exploded = delta_b_struct.failed; delta_b = delta_b_struct.solution.reshape(-1). max_delta_b = nd_max(hl.abs(delta_b)). return hl.bind(cont, exploded, delta_b, max_delta_b). if max_iterations == 0:; return blank_struct.annotate(n_iterations=0, log_lkhd=0, converged=False, exploded=False); return hl.experimental.loop(fit, dtype, 1, b). def _firth_test(null_fit, X, y, max_iterations, tolerance) -> StructExpression:; firth_improved_null_fit = _firth_fit(null_fit.b, X, y, max_iterations=max_iterations, tolerance=tolerance); dof = 1 # 1 variant. def cont(firth_improved_null_fit):; initial_b_full_model = hl.nd.hstack([firth_improved_null_fit.b, hl.nd.array([0.0])]); firth_fit = _firth_fit(initial_b_full_model, X, y, max_iterations=max_iterations, tolerance=tolerance). def cont2(firth_fit):; firth_chi_sq = 2 * (firth_fit.log_lkhd - firth_improved_null_fit.log_lkhd); firth_p = hl.pchisqtail(firth_chi_sq, dof). blank_struct = hl.struct(; beta=hl.missing(hl.tfloat64),; chi_sq_stat=hl.missing(hl.tfloat64),; p_value=hl.missing(hl.tfloat64),; firth_null_fit=hl.missing(firth_improved_null_fit.dtype),; fit=hl.missing(firth_fit.dtype),; ); return (; hl.case(); .when(; firth_improved_null_fit.converged,; hl.case(); .when(; firth_fit.converged,; hl.struct(; beta=firth_fit.b[firth_fit.b.shape[0] - 1],; chi_sq_stat=firth_chi_sq,; p_value=firth_p,; firth_null_fit=firth_improved_null_fit,; fit=firth_fit,; ),; ); .default(blank_struct.annotate(firth_null_fit=firth_improved_null_fit, fit=firth_fit)),; ); .default(blank_struct.annotate(firth_null_fit=firth_improved_null_fit)); ). return hl.bind(cont2, firth_fit). return hl.bind(cont, firth_improved_null_fit). @typecheck(; test=enumeration('wald', 'lrt', 'score', ",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:45829,Availability,toler,tolerance,45829," @ b); sqrtW = hl.sqrt(mu * (1 - mu)); q, r = hl.nd.qr(X * sqrtW.T.reshape(-1, 1)); h = (q * q).sum(1); coef = r[:m, :m]; residual = y - mu; dep = q[:, :m].T @ ((residual + (h * (0.5 - mu))) / sqrtW); delta_b_struct = hl.nd.solve_triangular(coef, dep.reshape(-1, 1), no_crash=True); exploded = delta_b_struct.failed; delta_b = delta_b_struct.solution.reshape(-1). max_delta_b = nd_max(hl.abs(delta_b)). return hl.bind(cont, exploded, delta_b, max_delta_b). if max_iterations == 0:; return blank_struct.annotate(n_iterations=0, log_lkhd=0, converged=False, exploded=False); return hl.experimental.loop(fit, dtype, 1, b). def _firth_test(null_fit, X, y, max_iterations, tolerance) -> StructExpression:; firth_improved_null_fit = _firth_fit(null_fit.b, X, y, max_iterations=max_iterations, tolerance=tolerance); dof = 1 # 1 variant. def cont(firth_improved_null_fit):; initial_b_full_model = hl.nd.hstack([firth_improved_null_fit.b, hl.nd.array([0.0])]); firth_fit = _firth_fit(initial_b_full_model, X, y, max_iterations=max_iterations, tolerance=tolerance). def cont2(firth_fit):; firth_chi_sq = 2 * (firth_fit.log_lkhd - firth_improved_null_fit.log_lkhd); firth_p = hl.pchisqtail(firth_chi_sq, dof). blank_struct = hl.struct(; beta=hl.missing(hl.tfloat64),; chi_sq_stat=hl.missing(hl.tfloat64),; p_value=hl.missing(hl.tfloat64),; firth_null_fit=hl.missing(firth_improved_null_fit.dtype),; fit=hl.missing(firth_fit.dtype),; ); return (; hl.case(); .when(; firth_improved_null_fit.converged,; hl.case(); .when(; firth_fit.converged,; hl.struct(; beta=firth_fit.b[firth_fit.b.shape[0] - 1],; chi_sq_stat=firth_chi_sq,; p_value=firth_p,; firth_null_fit=firth_improved_null_fit,; fit=firth_fit,; ),; ); .default(blank_struct.annotate(firth_null_fit=firth_improved_null_fit, fit=firth_fit)),; ); .default(blank_struct.annotate(firth_null_fit=firth_improved_null_fit)); ). return hl.bind(cont2, firth_fit). return hl.bind(cont, firth_improved_null_fit). @typecheck(; test=enumeration('wald', 'lrt', 'score', ",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:46982,Availability,toler,tolerance,46982,"eta=hl.missing(hl.tfloat64),; chi_sq_stat=hl.missing(hl.tfloat64),; p_value=hl.missing(hl.tfloat64),; firth_null_fit=hl.missing(firth_improved_null_fit.dtype),; fit=hl.missing(firth_fit.dtype),; ); return (; hl.case(); .when(; firth_improved_null_fit.converged,; hl.case(); .when(; firth_fit.converged,; hl.struct(; beta=firth_fit.b[firth_fit.b.shape[0] - 1],; chi_sq_stat=firth_chi_sq,; p_value=firth_p,; firth_null_fit=firth_improved_null_fit,; fit=firth_fit,; ),; ); .default(blank_struct.annotate(firth_null_fit=firth_improved_null_fit, fit=firth_fit)),; ); .default(blank_struct.annotate(firth_null_fit=firth_improved_null_fit)); ). return hl.bind(cont2, firth_fit). return hl.bind(cont, firth_improved_null_fit). @typecheck(; test=enumeration('wald', 'lrt', 'score', 'firth'),; y=oneof(expr_float64, sequenceof(expr_float64)),; x=expr_float64,; covariates=sequenceof(expr_float64),; pass_through=sequenceof(oneof(str, Expression)),; max_iterations=nullable(int),; tolerance=nullable(float),; ); def _logistic_regression_rows_nd(; test, y, x, covariates, pass_through=(), *, max_iterations: Optional[int] = None, tolerance: Optional[float] = None; ) -> Table:; r""""""For each row, test an input variable for association with a; binary response variable using logistic regression. Examples; --------; Run the logistic regression Wald test per variant using a Boolean; phenotype, intercept and two covariates stored in column-indexed; fields:. >>> result_ht = hl.logistic_regression_rows(; ... test='wald',; ... y=dataset.pheno.is_case,; ... x=dataset.GT.n_alt_alleles(),; ... covariates=[1, dataset.pheno.age, dataset.pheno.is_female]). Run the logistic regression Wald test per variant using a list of binary (0/1); phenotypes, intercept and two covariates stored in column-indexed; fields:. >>> result_ht = hl.logistic_regression_rows(; ... test='wald',; ... y=[dataset.pheno.is_case, dataset.pheno.is_case], # where pheno values are 0, 1, or missing; ... x=dataset.GT.n_alt_alleles(),; ... covar",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:47130,Availability,toler,tolerance,47130,"eta=hl.missing(hl.tfloat64),; chi_sq_stat=hl.missing(hl.tfloat64),; p_value=hl.missing(hl.tfloat64),; firth_null_fit=hl.missing(firth_improved_null_fit.dtype),; fit=hl.missing(firth_fit.dtype),; ); return (; hl.case(); .when(; firth_improved_null_fit.converged,; hl.case(); .when(; firth_fit.converged,; hl.struct(; beta=firth_fit.b[firth_fit.b.shape[0] - 1],; chi_sq_stat=firth_chi_sq,; p_value=firth_p,; firth_null_fit=firth_improved_null_fit,; fit=firth_fit,; ),; ); .default(blank_struct.annotate(firth_null_fit=firth_improved_null_fit, fit=firth_fit)),; ); .default(blank_struct.annotate(firth_null_fit=firth_improved_null_fit)); ). return hl.bind(cont2, firth_fit). return hl.bind(cont, firth_improved_null_fit). @typecheck(; test=enumeration('wald', 'lrt', 'score', 'firth'),; y=oneof(expr_float64, sequenceof(expr_float64)),; x=expr_float64,; covariates=sequenceof(expr_float64),; pass_through=sequenceof(oneof(str, Expression)),; max_iterations=nullable(int),; tolerance=nullable(float),; ); def _logistic_regression_rows_nd(; test, y, x, covariates, pass_through=(), *, max_iterations: Optional[int] = None, tolerance: Optional[float] = None; ) -> Table:; r""""""For each row, test an input variable for association with a; binary response variable using logistic regression. Examples; --------; Run the logistic regression Wald test per variant using a Boolean; phenotype, intercept and two covariates stored in column-indexed; fields:. >>> result_ht = hl.logistic_regression_rows(; ... test='wald',; ... y=dataset.pheno.is_case,; ... x=dataset.GT.n_alt_alleles(),; ... covariates=[1, dataset.pheno.age, dataset.pheno.is_female]). Run the logistic regression Wald test per variant using a list of binary (0/1); phenotypes, intercept and two covariates stored in column-indexed; fields:. >>> result_ht = hl.logistic_regression_rows(; ... test='wald',; ... y=[dataset.pheno.is_case, dataset.pheno.is_case], # where pheno values are 0, 1, or missing; ... x=dataset.GT.n_alt_alleles(),; ... covar",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:50161,Availability,error,error,50161," + \varepsilon),; \quad; \varepsilon \sim \mathrm{N}(0, \sigma^2). where :math:`\mathrm{sigmoid}` is the `sigmoid function`_, the genotype; :math:`\mathrm{gt}` is coded as 0 for HomRef, 1 for Het, and 2 for; HomVar, and the Boolean covariate :math:`\mathrm{is\_female}` is coded as; for ``True`` (female) and 0 for ``False`` (male). The null model sets; :math:`\beta_1 = 0`. .. _sigmoid function: https://en.wikipedia.org/wiki/Sigmoid_function. The structure of the emitted row field depends on the test statistic as; shown in the tables below. ========== ================== ======= ============================================; Test Field Type Value; ========== ================== ======= ============================================; Wald `beta` float64 fit effect coefficient,; :math:`\hat\beta_1`; Wald `standard_error` float64 estimated standard error,; :math:`\widehat{\mathrm{se}}`; Wald `z_stat` float64 Wald :math:`z`-statistic, equal to; :math:`\hat\beta_1 / \widehat{\mathrm{se}}`; Wald `p_value` float64 Wald p-value testing :math:`\beta_1 = 0`; LRT, Firth `beta` float64 fit effect coefficient,; :math:`\hat\beta_1`; LRT, Firth `chi_sq_stat` float64 deviance statistic; LRT, Firth `p_value` float64 LRT / Firth p-value testing; :math:`\beta_1 = 0`; Score `chi_sq_stat` float64 score statistic; Score `p_value` float64 score p-value testing :math:`\beta_1 = 0`; ========== ================== ======= ============================================. For the Wald and likelihood ratio tests, Hail fits the logistic model for; each row using Newton iteration and only emits the above fields; when the maximum likelihood estimate of the coefficients converges. The; Firth test uses a modified form of Newton iteration. To help diagnose; convergence issues, Hail also emits three fields which summarize the; iterative fitting process:. ================ =================== ======= ===============================; Test Field Type Value; ================ =================== ======= ===============",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:52891,Availability,error,errors,52891,"g we find 4 or 5 iterations; nearly always suffice. Convergence may also fail due to explosion,; which refers to low-level numerical linear algebra exceptions caused by; manipulating ill-conditioned matrices. Explosion may result from (nearly); linearly dependent covariates or complete separation_. .. _separation: https://en.wikipedia.org/wiki/Separation_(statistics). A more common situation in genetics is quasi-complete seperation, e.g.; variants that are observed only in cases (or controls). Such variants; inevitably arise when testing millions of variants with very low minor; allele count. The maximum likelihood estimate of :math:`\beta` under; logistic regression is then undefined but convergence may still occur; after a large number of iterations due to a very flat likelihood; surface. In testing, we find that such variants produce a secondary bump; from 10 to 15 iterations in the histogram of number of iterations per; variant. We also find that this faux convergence produces large standard; errors and large (insignificant) p-values. To not miss such variants,; consider using Firth logistic regression, linear regression, or; group-based tests. Here's a concrete illustration of quasi-complete seperation in R. Suppose; we have 2010 samples distributed as follows for a particular variant:. ======= ====== === ======; Status HomRef Het HomVar; ======= ====== === ======; Case 1000 10 0; Control 1000 0 0; ======= ====== === ======. The following R code fits the (standard) logistic, Firth logistic,; and linear regression models to this data, where ``x`` is genotype,; ``y`` is phenotype, and ``logistf`` is from the logistf package:. .. code-block:: R. x <- c(rep(0,1000), rep(1,1000), rep(1,10); y <- c(rep(0,1000), rep(0,1000), rep(1,10)); logfit <- glm(y ~ x, family=binomial()); firthfit <- logistf(y ~ x); linfit <- lm(y ~ x). The resulting p-values for the genotype coefficient are 0.991, 0.00085,; and 0.0016, respectively. The erroneous value 0.991 is due to; quasi-com",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:57190,Availability,toler,tolerance,57190," fields from; matrix table underlying ``x``. For example, to include an ""rsid"" field, set; ``pass_through=['rsid']`` or ``pass_through=[mt.rsid]``. Parameters; ----------; test : {'wald', 'lrt', 'score', 'firth'}; Statistical test.; y : :class:`.Float64Expression` or :obj:`list` of :class:`.Float64Expression`; One or more column-indexed response expressions.; All non-missing values must evaluate to 0 or 1.; Note that a :class:`.BooleanExpression` will be implicitly converted to; a :class:`.Float64Expression` with this property.; x : :class:`.Float64Expression`; Entry-indexed expression for input variable.; covariates : :obj:`list` of :class:`.Float64Expression`; Non-empty list of column-indexed covariate expressions.; pass_through : :obj:`list` of :class:`str` or :class:`.Expression`; Additional row fields to include in the resulting table. Returns; -------; :class:`.Table`; """"""; if max_iterations is None:; max_iterations = 25 if test != 'firth' else 100. if tolerance is None:; tolerance = 1e-8; assert tolerance > 0.0. if len(covariates) == 0:; raise ValueError('logistic regression requires at least one covariate expression'). mt = matrix_table_source('logistic_regresion_rows/x', x); raise_unless_entry_indexed('logistic_regresion_rows/x', x). y_is_list = isinstance(y, list); if y_is_list and len(y) == 0:; raise ValueError(""'logistic_regression_rows': found no values for 'y'""). y = [raise_unless_column_indexed('logistic_regression_rows/y', y) or y for y in wrap_to_list(y)]. for e in covariates:; analyze('logistic_regression_rows/covariates', e, mt._col_indices). # _warn_if_no_intercept('logistic_regression_rows', covariates). x_field_name = Env.get_uid(); y_field_names = [f'__y_{i}' for i in range(len(y))]. y_dict = dict(zip(y_field_names, y)). cov_field_names = [f'__cov{i}' for i in range(len(covariates))]; row_fields = _get_regression_row_fields(mt, pass_through, 'logistic_regression_rows'). # Handle filtering columns with missing values:; mt = mt.filter_cols(hl.arr",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:57210,Availability,toler,tolerance,57210," fields from; matrix table underlying ``x``. For example, to include an ""rsid"" field, set; ``pass_through=['rsid']`` or ``pass_through=[mt.rsid]``. Parameters; ----------; test : {'wald', 'lrt', 'score', 'firth'}; Statistical test.; y : :class:`.Float64Expression` or :obj:`list` of :class:`.Float64Expression`; One or more column-indexed response expressions.; All non-missing values must evaluate to 0 or 1.; Note that a :class:`.BooleanExpression` will be implicitly converted to; a :class:`.Float64Expression` with this property.; x : :class:`.Float64Expression`; Entry-indexed expression for input variable.; covariates : :obj:`list` of :class:`.Float64Expression`; Non-empty list of column-indexed covariate expressions.; pass_through : :obj:`list` of :class:`str` or :class:`.Expression`; Additional row fields to include in the resulting table. Returns; -------; :class:`.Table`; """"""; if max_iterations is None:; max_iterations = 25 if test != 'firth' else 100. if tolerance is None:; tolerance = 1e-8; assert tolerance > 0.0. if len(covariates) == 0:; raise ValueError('logistic regression requires at least one covariate expression'). mt = matrix_table_source('logistic_regresion_rows/x', x); raise_unless_entry_indexed('logistic_regresion_rows/x', x). y_is_list = isinstance(y, list); if y_is_list and len(y) == 0:; raise ValueError(""'logistic_regression_rows': found no values for 'y'""). y = [raise_unless_column_indexed('logistic_regression_rows/y', y) or y for y in wrap_to_list(y)]. for e in covariates:; analyze('logistic_regression_rows/covariates', e, mt._col_indices). # _warn_if_no_intercept('logistic_regression_rows', covariates). x_field_name = Env.get_uid(); y_field_names = [f'__y_{i}' for i in range(len(y))]. y_dict = dict(zip(y_field_names, y)). cov_field_names = [f'__cov{i}' for i in range(len(covariates))]; row_fields = _get_regression_row_fields(mt, pass_through, 'logistic_regression_rows'). # Handle filtering columns with missing values:; mt = mt.filter_cols(hl.arr",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:57235,Availability,toler,tolerance,57235," fields from; matrix table underlying ``x``. For example, to include an ""rsid"" field, set; ``pass_through=['rsid']`` or ``pass_through=[mt.rsid]``. Parameters; ----------; test : {'wald', 'lrt', 'score', 'firth'}; Statistical test.; y : :class:`.Float64Expression` or :obj:`list` of :class:`.Float64Expression`; One or more column-indexed response expressions.; All non-missing values must evaluate to 0 or 1.; Note that a :class:`.BooleanExpression` will be implicitly converted to; a :class:`.Float64Expression` with this property.; x : :class:`.Float64Expression`; Entry-indexed expression for input variable.; covariates : :obj:`list` of :class:`.Float64Expression`; Non-empty list of column-indexed covariate expressions.; pass_through : :obj:`list` of :class:`str` or :class:`.Expression`; Additional row fields to include in the resulting table. Returns; -------; :class:`.Table`; """"""; if max_iterations is None:; max_iterations = 25 if test != 'firth' else 100. if tolerance is None:; tolerance = 1e-8; assert tolerance > 0.0. if len(covariates) == 0:; raise ValueError('logistic regression requires at least one covariate expression'). mt = matrix_table_source('logistic_regresion_rows/x', x); raise_unless_entry_indexed('logistic_regresion_rows/x', x). y_is_list = isinstance(y, list); if y_is_list and len(y) == 0:; raise ValueError(""'logistic_regression_rows': found no values for 'y'""). y = [raise_unless_column_indexed('logistic_regression_rows/y', y) or y for y in wrap_to_list(y)]. for e in covariates:; analyze('logistic_regression_rows/covariates', e, mt._col_indices). # _warn_if_no_intercept('logistic_regression_rows', covariates). x_field_name = Env.get_uid(); y_field_names = [f'__y_{i}' for i in range(len(y))]. y_dict = dict(zip(y_field_names, y)). cov_field_names = [f'__cov{i}' for i in range(len(covariates))]; row_fields = _get_regression_row_fields(mt, pass_through, 'logistic_regression_rows'). # Handle filtering columns with missing values:; mt = mt.filter_cols(hl.arr",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:59569,Availability,toler,tolerance,59569,"ows are samples, columns are the different covariates; ht = ht.annotate_globals(; covmat=hl.nd.array(ht.samples.map(lambda s: [s[cov_name] for cov_name in cov_field_names])); ). # yvecs is a list of sample-length vectors, one for each dependent variable.; ht = ht.annotate_globals(yvecs=[hl.nd.array(ht.samples[y_name]) for y_name in y_field_names]). # Fit null models, which means doing a logreg fit with just the covariates for each phenotype.; def fit_null(yvec):; def error_if_not_converged(null_fit):; return (; hl.case(); .when(; ~null_fit.exploded,; (; hl.case(); .when(null_fit.converged, null_fit); .or_error(; ""Failed to fit logistic regression null model (standard MLE with covariates only): ""; ""Newton iteration failed to converge""; ); ),; ); .or_error(; hl.format(; ""Failed to fit logistic regression null model (standard MLE with covariates only): ""; ""exploded at Newton iteration %d"",; null_fit.n_iterations,; ); ); ). null_fit = logreg_fit(ht.covmat, yvec, None, max_iterations=max_iterations, tolerance=tolerance); return hl.bind(error_if_not_converged, null_fit). ht = ht.annotate_globals(null_fits=ht.yvecs.map(fit_null)). ht = ht.transmute(x=hl.nd.array(mean_impute(ht.entries[x_field_name]))); ht = ht.annotate(covs_and_x=hl.nd.hstack([ht.covmat, ht.x.reshape((-1, 1))])). def run_test(yvec, null_fit):; if test == 'score':; return logistic_score_test(ht.covs_and_x, yvec, null_fit); if test == 'firth':; return _firth_test(null_fit, ht.covs_and_x, yvec, max_iterations=max_iterations, tolerance=tolerance). test_fit = logreg_fit(ht.covs_and_x, yvec, null_fit, max_iterations=max_iterations, tolerance=tolerance); if test == 'wald':; return wald_test(ht.covs_and_x, test_fit); assert test == 'lrt', test; return lrt_test(ht.covs_and_x, null_fit, test_fit). ht = ht.select(; logistic_regression=hl.starmap(run_test, hl.zip(ht.yvecs, ht.null_fits)), **{f: ht[f] for f in row_fields}; ); assert 'null_fits' not in row_fields; assert 'logistic_regression' not in row_fields. if not y_",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:59579,Availability,toler,tolerance,59579,"ows are samples, columns are the different covariates; ht = ht.annotate_globals(; covmat=hl.nd.array(ht.samples.map(lambda s: [s[cov_name] for cov_name in cov_field_names])); ). # yvecs is a list of sample-length vectors, one for each dependent variable.; ht = ht.annotate_globals(yvecs=[hl.nd.array(ht.samples[y_name]) for y_name in y_field_names]). # Fit null models, which means doing a logreg fit with just the covariates for each phenotype.; def fit_null(yvec):; def error_if_not_converged(null_fit):; return (; hl.case(); .when(; ~null_fit.exploded,; (; hl.case(); .when(null_fit.converged, null_fit); .or_error(; ""Failed to fit logistic regression null model (standard MLE with covariates only): ""; ""Newton iteration failed to converge""; ); ),; ); .or_error(; hl.format(; ""Failed to fit logistic regression null model (standard MLE with covariates only): ""; ""exploded at Newton iteration %d"",; null_fit.n_iterations,; ); ); ). null_fit = logreg_fit(ht.covmat, yvec, None, max_iterations=max_iterations, tolerance=tolerance); return hl.bind(error_if_not_converged, null_fit). ht = ht.annotate_globals(null_fits=ht.yvecs.map(fit_null)). ht = ht.transmute(x=hl.nd.array(mean_impute(ht.entries[x_field_name]))); ht = ht.annotate(covs_and_x=hl.nd.hstack([ht.covmat, ht.x.reshape((-1, 1))])). def run_test(yvec, null_fit):; if test == 'score':; return logistic_score_test(ht.covs_and_x, yvec, null_fit); if test == 'firth':; return _firth_test(null_fit, ht.covs_and_x, yvec, max_iterations=max_iterations, tolerance=tolerance). test_fit = logreg_fit(ht.covs_and_x, yvec, null_fit, max_iterations=max_iterations, tolerance=tolerance); if test == 'wald':; return wald_test(ht.covs_and_x, test_fit); assert test == 'lrt', test; return lrt_test(ht.covs_and_x, null_fit, test_fit). ht = ht.select(; logistic_regression=hl.starmap(run_test, hl.zip(ht.yvecs, ht.null_fits)), **{f: ht[f] for f in row_fields}; ); assert 'null_fits' not in row_fields; assert 'logistic_regression' not in row_fields. if not y_",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:60066,Availability,toler,tolerance,60066,"d(null_fit):; return (; hl.case(); .when(; ~null_fit.exploded,; (; hl.case(); .when(null_fit.converged, null_fit); .or_error(; ""Failed to fit logistic regression null model (standard MLE with covariates only): ""; ""Newton iteration failed to converge""; ); ),; ); .or_error(; hl.format(; ""Failed to fit logistic regression null model (standard MLE with covariates only): ""; ""exploded at Newton iteration %d"",; null_fit.n_iterations,; ); ); ). null_fit = logreg_fit(ht.covmat, yvec, None, max_iterations=max_iterations, tolerance=tolerance); return hl.bind(error_if_not_converged, null_fit). ht = ht.annotate_globals(null_fits=ht.yvecs.map(fit_null)). ht = ht.transmute(x=hl.nd.array(mean_impute(ht.entries[x_field_name]))); ht = ht.annotate(covs_and_x=hl.nd.hstack([ht.covmat, ht.x.reshape((-1, 1))])). def run_test(yvec, null_fit):; if test == 'score':; return logistic_score_test(ht.covs_and_x, yvec, null_fit); if test == 'firth':; return _firth_test(null_fit, ht.covs_and_x, yvec, max_iterations=max_iterations, tolerance=tolerance). test_fit = logreg_fit(ht.covs_and_x, yvec, null_fit, max_iterations=max_iterations, tolerance=tolerance); if test == 'wald':; return wald_test(ht.covs_and_x, test_fit); assert test == 'lrt', test; return lrt_test(ht.covs_and_x, null_fit, test_fit). ht = ht.select(; logistic_regression=hl.starmap(run_test, hl.zip(ht.yvecs, ht.null_fits)), **{f: ht[f] for f in row_fields}; ); assert 'null_fits' not in row_fields; assert 'logistic_regression' not in row_fields. if not y_is_list:; assert all(f not in row_fields for f in ht.null_fits[0]); assert all(f not in row_fields for f in ht.logistic_regression[0]); ht = ht.select_globals(**ht.null_fits[0]); return ht.transmute(**ht.logistic_regression[0]); ht = ht.select_globals('null_fits'); return ht. [docs]@typecheck(; test=enumeration('wald', 'lrt', 'score'),; y=expr_float64,; x=expr_float64,; covariates=sequenceof(expr_float64),; pass_through=sequenceof(oneof(str, Expression)),; max_iterations=int,; tolerance=",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:60076,Availability,toler,tolerance,60076,"d(null_fit):; return (; hl.case(); .when(; ~null_fit.exploded,; (; hl.case(); .when(null_fit.converged, null_fit); .or_error(; ""Failed to fit logistic regression null model (standard MLE with covariates only): ""; ""Newton iteration failed to converge""; ); ),; ); .or_error(; hl.format(; ""Failed to fit logistic regression null model (standard MLE with covariates only): ""; ""exploded at Newton iteration %d"",; null_fit.n_iterations,; ); ); ). null_fit = logreg_fit(ht.covmat, yvec, None, max_iterations=max_iterations, tolerance=tolerance); return hl.bind(error_if_not_converged, null_fit). ht = ht.annotate_globals(null_fits=ht.yvecs.map(fit_null)). ht = ht.transmute(x=hl.nd.array(mean_impute(ht.entries[x_field_name]))); ht = ht.annotate(covs_and_x=hl.nd.hstack([ht.covmat, ht.x.reshape((-1, 1))])). def run_test(yvec, null_fit):; if test == 'score':; return logistic_score_test(ht.covs_and_x, yvec, null_fit); if test == 'firth':; return _firth_test(null_fit, ht.covs_and_x, yvec, max_iterations=max_iterations, tolerance=tolerance). test_fit = logreg_fit(ht.covs_and_x, yvec, null_fit, max_iterations=max_iterations, tolerance=tolerance); if test == 'wald':; return wald_test(ht.covs_and_x, test_fit); assert test == 'lrt', test; return lrt_test(ht.covs_and_x, null_fit, test_fit). ht = ht.select(; logistic_regression=hl.starmap(run_test, hl.zip(ht.yvecs, ht.null_fits)), **{f: ht[f] for f in row_fields}; ); assert 'null_fits' not in row_fields; assert 'logistic_regression' not in row_fields. if not y_is_list:; assert all(f not in row_fields for f in ht.null_fits[0]); assert all(f not in row_fields for f in ht.logistic_regression[0]); ht = ht.select_globals(**ht.null_fits[0]); return ht.transmute(**ht.logistic_regression[0]); ht = ht.select_globals('null_fits'); return ht. [docs]@typecheck(; test=enumeration('wald', 'lrt', 'score'),; y=expr_float64,; x=expr_float64,; covariates=sequenceof(expr_float64),; pass_through=sequenceof(oneof(str, Expression)),; max_iterations=int,; tolerance=",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:60172,Availability,toler,tolerance,60172,"ror(; ""Failed to fit logistic regression null model (standard MLE with covariates only): ""; ""Newton iteration failed to converge""; ); ),; ); .or_error(; hl.format(; ""Failed to fit logistic regression null model (standard MLE with covariates only): ""; ""exploded at Newton iteration %d"",; null_fit.n_iterations,; ); ); ). null_fit = logreg_fit(ht.covmat, yvec, None, max_iterations=max_iterations, tolerance=tolerance); return hl.bind(error_if_not_converged, null_fit). ht = ht.annotate_globals(null_fits=ht.yvecs.map(fit_null)). ht = ht.transmute(x=hl.nd.array(mean_impute(ht.entries[x_field_name]))); ht = ht.annotate(covs_and_x=hl.nd.hstack([ht.covmat, ht.x.reshape((-1, 1))])). def run_test(yvec, null_fit):; if test == 'score':; return logistic_score_test(ht.covs_and_x, yvec, null_fit); if test == 'firth':; return _firth_test(null_fit, ht.covs_and_x, yvec, max_iterations=max_iterations, tolerance=tolerance). test_fit = logreg_fit(ht.covs_and_x, yvec, null_fit, max_iterations=max_iterations, tolerance=tolerance); if test == 'wald':; return wald_test(ht.covs_and_x, test_fit); assert test == 'lrt', test; return lrt_test(ht.covs_and_x, null_fit, test_fit). ht = ht.select(; logistic_regression=hl.starmap(run_test, hl.zip(ht.yvecs, ht.null_fits)), **{f: ht[f] for f in row_fields}; ); assert 'null_fits' not in row_fields; assert 'logistic_regression' not in row_fields. if not y_is_list:; assert all(f not in row_fields for f in ht.null_fits[0]); assert all(f not in row_fields for f in ht.logistic_regression[0]); ht = ht.select_globals(**ht.null_fits[0]); return ht.transmute(**ht.logistic_regression[0]); ht = ht.select_globals('null_fits'); return ht. [docs]@typecheck(; test=enumeration('wald', 'lrt', 'score'),; y=expr_float64,; x=expr_float64,; covariates=sequenceof(expr_float64),; pass_through=sequenceof(oneof(str, Expression)),; max_iterations=int,; tolerance=nullable(float),; ); def poisson_regression_rows(; test, y, x, covariates, pass_through=(), *, max_iterations: int = 25, t",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:60182,Availability,toler,tolerance,60182,"ror(; ""Failed to fit logistic regression null model (standard MLE with covariates only): ""; ""Newton iteration failed to converge""; ); ),; ); .or_error(; hl.format(; ""Failed to fit logistic regression null model (standard MLE with covariates only): ""; ""exploded at Newton iteration %d"",; null_fit.n_iterations,; ); ); ). null_fit = logreg_fit(ht.covmat, yvec, None, max_iterations=max_iterations, tolerance=tolerance); return hl.bind(error_if_not_converged, null_fit). ht = ht.annotate_globals(null_fits=ht.yvecs.map(fit_null)). ht = ht.transmute(x=hl.nd.array(mean_impute(ht.entries[x_field_name]))); ht = ht.annotate(covs_and_x=hl.nd.hstack([ht.covmat, ht.x.reshape((-1, 1))])). def run_test(yvec, null_fit):; if test == 'score':; return logistic_score_test(ht.covs_and_x, yvec, null_fit); if test == 'firth':; return _firth_test(null_fit, ht.covs_and_x, yvec, max_iterations=max_iterations, tolerance=tolerance). test_fit = logreg_fit(ht.covs_and_x, yvec, null_fit, max_iterations=max_iterations, tolerance=tolerance); if test == 'wald':; return wald_test(ht.covs_and_x, test_fit); assert test == 'lrt', test; return lrt_test(ht.covs_and_x, null_fit, test_fit). ht = ht.select(; logistic_regression=hl.starmap(run_test, hl.zip(ht.yvecs, ht.null_fits)), **{f: ht[f] for f in row_fields}; ); assert 'null_fits' not in row_fields; assert 'logistic_regression' not in row_fields. if not y_is_list:; assert all(f not in row_fields for f in ht.null_fits[0]); assert all(f not in row_fields for f in ht.logistic_regression[0]); ht = ht.select_globals(**ht.null_fits[0]); return ht.transmute(**ht.logistic_regression[0]); ht = ht.select_globals('null_fits'); return ht. [docs]@typecheck(; test=enumeration('wald', 'lrt', 'score'),; y=expr_float64,; x=expr_float64,; covariates=sequenceof(expr_float64),; pass_through=sequenceof(oneof(str, Expression)),; max_iterations=int,; tolerance=nullable(float),; ); def poisson_regression_rows(; test, y, x, covariates, pass_through=(), *, max_iterations: int = 25, t",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:61042,Availability,toler,tolerance,61042,"_fit = logreg_fit(ht.covs_and_x, yvec, null_fit, max_iterations=max_iterations, tolerance=tolerance); if test == 'wald':; return wald_test(ht.covs_and_x, test_fit); assert test == 'lrt', test; return lrt_test(ht.covs_and_x, null_fit, test_fit). ht = ht.select(; logistic_regression=hl.starmap(run_test, hl.zip(ht.yvecs, ht.null_fits)), **{f: ht[f] for f in row_fields}; ); assert 'null_fits' not in row_fields; assert 'logistic_regression' not in row_fields. if not y_is_list:; assert all(f not in row_fields for f in ht.null_fits[0]); assert all(f not in row_fields for f in ht.logistic_regression[0]); ht = ht.select_globals(**ht.null_fits[0]); return ht.transmute(**ht.logistic_regression[0]); ht = ht.select_globals('null_fits'); return ht. [docs]@typecheck(; test=enumeration('wald', 'lrt', 'score'),; y=expr_float64,; x=expr_float64,; covariates=sequenceof(expr_float64),; pass_through=sequenceof(oneof(str, Expression)),; max_iterations=int,; tolerance=nullable(float),; ); def poisson_regression_rows(; test, y, x, covariates, pass_through=(), *, max_iterations: int = 25, tolerance: Optional[float] = None; ) -> Table:; r""""""For each row, test an input variable for association with a; count response variable using `Poisson regression <https://en.wikipedia.org/wiki/Poisson_regression>`__. Notes; -----; See :func:`.logistic_regression_rows` for more info on statistical tests; of general linear models. Note; ----; Use the `pass_through` parameter to include additional row fields from; matrix table underlying ``x``. For example, to include an ""rsid"" field, set; ``pass_through=['rsid']`` or ``pass_through=[mt.rsid]``. Parameters; ----------; y : :class:`.Float64Expression`; Column-indexed response expression.; All non-missing values must evaluate to a non-negative integer.; x : :class:`.Float64Expression`; Entry-indexed expression for input variable.; covariates : :obj:`list` of :class:`.Float64Expression`; Non-empty list of column-indexed covariate expressions.; pass_through : :o",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:61173,Availability,toler,tolerance,61173,"_fit = logreg_fit(ht.covs_and_x, yvec, null_fit, max_iterations=max_iterations, tolerance=tolerance); if test == 'wald':; return wald_test(ht.covs_and_x, test_fit); assert test == 'lrt', test; return lrt_test(ht.covs_and_x, null_fit, test_fit). ht = ht.select(; logistic_regression=hl.starmap(run_test, hl.zip(ht.yvecs, ht.null_fits)), **{f: ht[f] for f in row_fields}; ); assert 'null_fits' not in row_fields; assert 'logistic_regression' not in row_fields. if not y_is_list:; assert all(f not in row_fields for f in ht.null_fits[0]); assert all(f not in row_fields for f in ht.logistic_regression[0]); ht = ht.select_globals(**ht.null_fits[0]); return ht.transmute(**ht.logistic_regression[0]); ht = ht.select_globals('null_fits'); return ht. [docs]@typecheck(; test=enumeration('wald', 'lrt', 'score'),; y=expr_float64,; x=expr_float64,; covariates=sequenceof(expr_float64),; pass_through=sequenceof(oneof(str, Expression)),; max_iterations=int,; tolerance=nullable(float),; ); def poisson_regression_rows(; test, y, x, covariates, pass_through=(), *, max_iterations: int = 25, tolerance: Optional[float] = None; ) -> Table:; r""""""For each row, test an input variable for association with a; count response variable using `Poisson regression <https://en.wikipedia.org/wiki/Poisson_regression>`__. Notes; -----; See :func:`.logistic_regression_rows` for more info on statistical tests; of general linear models. Note; ----; Use the `pass_through` parameter to include additional row fields from; matrix table underlying ``x``. For example, to include an ""rsid"" field, set; ``pass_through=['rsid']`` or ``pass_through=[mt.rsid]``. Parameters; ----------; y : :class:`.Float64Expression`; Column-indexed response expression.; All non-missing values must evaluate to a non-negative integer.; x : :class:`.Float64Expression`; Entry-indexed expression for input variable.; covariates : :obj:`list` of :class:`.Float64Expression`; Non-empty list of column-indexed covariate expressions.; pass_through : :o",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:62201,Availability,toler,tolerance,62201,"with a; count response variable using `Poisson regression <https://en.wikipedia.org/wiki/Poisson_regression>`__. Notes; -----; See :func:`.logistic_regression_rows` for more info on statistical tests; of general linear models. Note; ----; Use the `pass_through` parameter to include additional row fields from; matrix table underlying ``x``. For example, to include an ""rsid"" field, set; ``pass_through=['rsid']`` or ``pass_through=[mt.rsid]``. Parameters; ----------; y : :class:`.Float64Expression`; Column-indexed response expression.; All non-missing values must evaluate to a non-negative integer.; x : :class:`.Float64Expression`; Entry-indexed expression for input variable.; covariates : :obj:`list` of :class:`.Float64Expression`; Non-empty list of column-indexed covariate expressions.; pass_through : :obj:`list` of :class:`str` or :class:`.Expression`; Additional row fields to include in the resulting table.; tolerance : :obj:`float`, optional; The iterative fit of this model is considered ""converged"" if the change in the estimated; beta is smaller than tolerance. By default the tolerance is 1e-6. Returns; -------; :class:`.Table`. """"""; if hl.current_backend().requires_lowering:; return _lowered_poisson_regression_rows(; test, y, x, covariates, pass_through, max_iterations=max_iterations, tolerance=tolerance; ). if tolerance is None:; tolerance = 1e-6; assert tolerance > 0.0. if len(covariates) == 0:; raise ValueError('Poisson regression requires at least one covariate expression'). mt = matrix_table_source('poisson_regression_rows/x', x); raise_unless_entry_indexed('poisson_regression_rows/x', x). analyze('poisson_regression_rows/y', y, mt._col_indices). all_exprs = [y]; for e in covariates:; all_exprs.append(e); analyze('poisson_regression_rows/covariates', e, mt._col_indices). _warn_if_no_intercept('poisson_regression_rows', covariates). x_field_name = Env.get_uid(); y_field_name = '__y'; cov_field_names = list(f'__cov{i}' for i in range(len(covariates))); row_fie",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:62348,Availability,toler,tolerance,62348,"with a; count response variable using `Poisson regression <https://en.wikipedia.org/wiki/Poisson_regression>`__. Notes; -----; See :func:`.logistic_regression_rows` for more info on statistical tests; of general linear models. Note; ----; Use the `pass_through` parameter to include additional row fields from; matrix table underlying ``x``. For example, to include an ""rsid"" field, set; ``pass_through=['rsid']`` or ``pass_through=[mt.rsid]``. Parameters; ----------; y : :class:`.Float64Expression`; Column-indexed response expression.; All non-missing values must evaluate to a non-negative integer.; x : :class:`.Float64Expression`; Entry-indexed expression for input variable.; covariates : :obj:`list` of :class:`.Float64Expression`; Non-empty list of column-indexed covariate expressions.; pass_through : :obj:`list` of :class:`str` or :class:`.Expression`; Additional row fields to include in the resulting table.; tolerance : :obj:`float`, optional; The iterative fit of this model is considered ""converged"" if the change in the estimated; beta is smaller than tolerance. By default the tolerance is 1e-6. Returns; -------; :class:`.Table`. """"""; if hl.current_backend().requires_lowering:; return _lowered_poisson_regression_rows(; test, y, x, covariates, pass_through, max_iterations=max_iterations, tolerance=tolerance; ). if tolerance is None:; tolerance = 1e-6; assert tolerance > 0.0. if len(covariates) == 0:; raise ValueError('Poisson regression requires at least one covariate expression'). mt = matrix_table_source('poisson_regression_rows/x', x); raise_unless_entry_indexed('poisson_regression_rows/x', x). analyze('poisson_regression_rows/y', y, mt._col_indices). all_exprs = [y]; for e in covariates:; all_exprs.append(e); analyze('poisson_regression_rows/covariates', e, mt._col_indices). _warn_if_no_intercept('poisson_regression_rows', covariates). x_field_name = Env.get_uid(); y_field_name = '__y'; cov_field_names = list(f'__cov{i}' for i in range(len(covariates))); row_fie",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:62374,Availability,toler,tolerance,62374,"regression>`__. Notes; -----; See :func:`.logistic_regression_rows` for more info on statistical tests; of general linear models. Note; ----; Use the `pass_through` parameter to include additional row fields from; matrix table underlying ``x``. For example, to include an ""rsid"" field, set; ``pass_through=['rsid']`` or ``pass_through=[mt.rsid]``. Parameters; ----------; y : :class:`.Float64Expression`; Column-indexed response expression.; All non-missing values must evaluate to a non-negative integer.; x : :class:`.Float64Expression`; Entry-indexed expression for input variable.; covariates : :obj:`list` of :class:`.Float64Expression`; Non-empty list of column-indexed covariate expressions.; pass_through : :obj:`list` of :class:`str` or :class:`.Expression`; Additional row fields to include in the resulting table.; tolerance : :obj:`float`, optional; The iterative fit of this model is considered ""converged"" if the change in the estimated; beta is smaller than tolerance. By default the tolerance is 1e-6. Returns; -------; :class:`.Table`. """"""; if hl.current_backend().requires_lowering:; return _lowered_poisson_regression_rows(; test, y, x, covariates, pass_through, max_iterations=max_iterations, tolerance=tolerance; ). if tolerance is None:; tolerance = 1e-6; assert tolerance > 0.0. if len(covariates) == 0:; raise ValueError('Poisson regression requires at least one covariate expression'). mt = matrix_table_source('poisson_regression_rows/x', x); raise_unless_entry_indexed('poisson_regression_rows/x', x). analyze('poisson_regression_rows/y', y, mt._col_indices). all_exprs = [y]; for e in covariates:; all_exprs.append(e); analyze('poisson_regression_rows/covariates', e, mt._col_indices). _warn_if_no_intercept('poisson_regression_rows', covariates). x_field_name = Env.get_uid(); y_field_name = '__y'; cov_field_names = list(f'__cov{i}' for i in range(len(covariates))); row_fields = _get_regression_row_fields(mt, pass_through, 'poisson_regression_rows'). # FIXME: selectin",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:62588,Availability,toler,tolerance,62588,"ough` parameter to include additional row fields from; matrix table underlying ``x``. For example, to include an ""rsid"" field, set; ``pass_through=['rsid']`` or ``pass_through=[mt.rsid]``. Parameters; ----------; y : :class:`.Float64Expression`; Column-indexed response expression.; All non-missing values must evaluate to a non-negative integer.; x : :class:`.Float64Expression`; Entry-indexed expression for input variable.; covariates : :obj:`list` of :class:`.Float64Expression`; Non-empty list of column-indexed covariate expressions.; pass_through : :obj:`list` of :class:`str` or :class:`.Expression`; Additional row fields to include in the resulting table.; tolerance : :obj:`float`, optional; The iterative fit of this model is considered ""converged"" if the change in the estimated; beta is smaller than tolerance. By default the tolerance is 1e-6. Returns; -------; :class:`.Table`. """"""; if hl.current_backend().requires_lowering:; return _lowered_poisson_regression_rows(; test, y, x, covariates, pass_through, max_iterations=max_iterations, tolerance=tolerance; ). if tolerance is None:; tolerance = 1e-6; assert tolerance > 0.0. if len(covariates) == 0:; raise ValueError('Poisson regression requires at least one covariate expression'). mt = matrix_table_source('poisson_regression_rows/x', x); raise_unless_entry_indexed('poisson_regression_rows/x', x). analyze('poisson_regression_rows/y', y, mt._col_indices). all_exprs = [y]; for e in covariates:; all_exprs.append(e); analyze('poisson_regression_rows/covariates', e, mt._col_indices). _warn_if_no_intercept('poisson_regression_rows', covariates). x_field_name = Env.get_uid(); y_field_name = '__y'; cov_field_names = list(f'__cov{i}' for i in range(len(covariates))); row_fields = _get_regression_row_fields(mt, pass_through, 'poisson_regression_rows'). # FIXME: selecting an existing entry field should be emitted as a SelectFields; mt = mt._select_all(; col_exprs=dict(**{y_field_name: y}, **dict(zip(cov_field_names, covariates",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:62598,Availability,toler,tolerance,62598,"ough` parameter to include additional row fields from; matrix table underlying ``x``. For example, to include an ""rsid"" field, set; ``pass_through=['rsid']`` or ``pass_through=[mt.rsid]``. Parameters; ----------; y : :class:`.Float64Expression`; Column-indexed response expression.; All non-missing values must evaluate to a non-negative integer.; x : :class:`.Float64Expression`; Entry-indexed expression for input variable.; covariates : :obj:`list` of :class:`.Float64Expression`; Non-empty list of column-indexed covariate expressions.; pass_through : :obj:`list` of :class:`str` or :class:`.Expression`; Additional row fields to include in the resulting table.; tolerance : :obj:`float`, optional; The iterative fit of this model is considered ""converged"" if the change in the estimated; beta is smaller than tolerance. By default the tolerance is 1e-6. Returns; -------; :class:`.Table`. """"""; if hl.current_backend().requires_lowering:; return _lowered_poisson_regression_rows(; test, y, x, covariates, pass_through, max_iterations=max_iterations, tolerance=tolerance; ). if tolerance is None:; tolerance = 1e-6; assert tolerance > 0.0. if len(covariates) == 0:; raise ValueError('Poisson regression requires at least one covariate expression'). mt = matrix_table_source('poisson_regression_rows/x', x); raise_unless_entry_indexed('poisson_regression_rows/x', x). analyze('poisson_regression_rows/y', y, mt._col_indices). all_exprs = [y]; for e in covariates:; all_exprs.append(e); analyze('poisson_regression_rows/covariates', e, mt._col_indices). _warn_if_no_intercept('poisson_regression_rows', covariates). x_field_name = Env.get_uid(); y_field_name = '__y'; cov_field_names = list(f'__cov{i}' for i in range(len(covariates))); row_fields = _get_regression_row_fields(mt, pass_through, 'poisson_regression_rows'). # FIXME: selecting an existing entry field should be emitted as a SelectFields; mt = mt._select_all(; col_exprs=dict(**{y_field_name: y}, **dict(zip(cov_field_names, covariates",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:62615,Availability,toler,tolerance,62615,"e an ""rsid"" field, set; ``pass_through=['rsid']`` or ``pass_through=[mt.rsid]``. Parameters; ----------; y : :class:`.Float64Expression`; Column-indexed response expression.; All non-missing values must evaluate to a non-negative integer.; x : :class:`.Float64Expression`; Entry-indexed expression for input variable.; covariates : :obj:`list` of :class:`.Float64Expression`; Non-empty list of column-indexed covariate expressions.; pass_through : :obj:`list` of :class:`str` or :class:`.Expression`; Additional row fields to include in the resulting table.; tolerance : :obj:`float`, optional; The iterative fit of this model is considered ""converged"" if the change in the estimated; beta is smaller than tolerance. By default the tolerance is 1e-6. Returns; -------; :class:`.Table`. """"""; if hl.current_backend().requires_lowering:; return _lowered_poisson_regression_rows(; test, y, x, covariates, pass_through, max_iterations=max_iterations, tolerance=tolerance; ). if tolerance is None:; tolerance = 1e-6; assert tolerance > 0.0. if len(covariates) == 0:; raise ValueError('Poisson regression requires at least one covariate expression'). mt = matrix_table_source('poisson_regression_rows/x', x); raise_unless_entry_indexed('poisson_regression_rows/x', x). analyze('poisson_regression_rows/y', y, mt._col_indices). all_exprs = [y]; for e in covariates:; all_exprs.append(e); analyze('poisson_regression_rows/covariates', e, mt._col_indices). _warn_if_no_intercept('poisson_regression_rows', covariates). x_field_name = Env.get_uid(); y_field_name = '__y'; cov_field_names = list(f'__cov{i}' for i in range(len(covariates))); row_fields = _get_regression_row_fields(mt, pass_through, 'poisson_regression_rows'). # FIXME: selecting an existing entry field should be emitted as a SelectFields; mt = mt._select_all(; col_exprs=dict(**{y_field_name: y}, **dict(zip(cov_field_names, covariates))),; row_exprs=row_fields,; col_key=[],; entry_exprs={x_field_name: x},; ). config = {; 'name': 'PoissonRegr",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:62635,Availability,toler,tolerance,62635,"e an ""rsid"" field, set; ``pass_through=['rsid']`` or ``pass_through=[mt.rsid]``. Parameters; ----------; y : :class:`.Float64Expression`; Column-indexed response expression.; All non-missing values must evaluate to a non-negative integer.; x : :class:`.Float64Expression`; Entry-indexed expression for input variable.; covariates : :obj:`list` of :class:`.Float64Expression`; Non-empty list of column-indexed covariate expressions.; pass_through : :obj:`list` of :class:`str` or :class:`.Expression`; Additional row fields to include in the resulting table.; tolerance : :obj:`float`, optional; The iterative fit of this model is considered ""converged"" if the change in the estimated; beta is smaller than tolerance. By default the tolerance is 1e-6. Returns; -------; :class:`.Table`. """"""; if hl.current_backend().requires_lowering:; return _lowered_poisson_regression_rows(; test, y, x, covariates, pass_through, max_iterations=max_iterations, tolerance=tolerance; ). if tolerance is None:; tolerance = 1e-6; assert tolerance > 0.0. if len(covariates) == 0:; raise ValueError('Poisson regression requires at least one covariate expression'). mt = matrix_table_source('poisson_regression_rows/x', x); raise_unless_entry_indexed('poisson_regression_rows/x', x). analyze('poisson_regression_rows/y', y, mt._col_indices). all_exprs = [y]; for e in covariates:; all_exprs.append(e); analyze('poisson_regression_rows/covariates', e, mt._col_indices). _warn_if_no_intercept('poisson_regression_rows', covariates). x_field_name = Env.get_uid(); y_field_name = '__y'; cov_field_names = list(f'__cov{i}' for i in range(len(covariates))); row_fields = _get_regression_row_fields(mt, pass_through, 'poisson_regression_rows'). # FIXME: selecting an existing entry field should be emitted as a SelectFields; mt = mt._select_all(; col_exprs=dict(**{y_field_name: y}, **dict(zip(cov_field_names, covariates))),; row_exprs=row_fields,; col_key=[],; entry_exprs={x_field_name: x},; ). config = {; 'name': 'PoissonRegr",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:62660,Availability,toler,tolerance,62660,"e an ""rsid"" field, set; ``pass_through=['rsid']`` or ``pass_through=[mt.rsid]``. Parameters; ----------; y : :class:`.Float64Expression`; Column-indexed response expression.; All non-missing values must evaluate to a non-negative integer.; x : :class:`.Float64Expression`; Entry-indexed expression for input variable.; covariates : :obj:`list` of :class:`.Float64Expression`; Non-empty list of column-indexed covariate expressions.; pass_through : :obj:`list` of :class:`str` or :class:`.Expression`; Additional row fields to include in the resulting table.; tolerance : :obj:`float`, optional; The iterative fit of this model is considered ""converged"" if the change in the estimated; beta is smaller than tolerance. By default the tolerance is 1e-6. Returns; -------; :class:`.Table`. """"""; if hl.current_backend().requires_lowering:; return _lowered_poisson_regression_rows(; test, y, x, covariates, pass_through, max_iterations=max_iterations, tolerance=tolerance; ). if tolerance is None:; tolerance = 1e-6; assert tolerance > 0.0. if len(covariates) == 0:; raise ValueError('Poisson regression requires at least one covariate expression'). mt = matrix_table_source('poisson_regression_rows/x', x); raise_unless_entry_indexed('poisson_regression_rows/x', x). analyze('poisson_regression_rows/y', y, mt._col_indices). all_exprs = [y]; for e in covariates:; all_exprs.append(e); analyze('poisson_regression_rows/covariates', e, mt._col_indices). _warn_if_no_intercept('poisson_regression_rows', covariates). x_field_name = Env.get_uid(); y_field_name = '__y'; cov_field_names = list(f'__cov{i}' for i in range(len(covariates))); row_fields = _get_regression_row_fields(mt, pass_through, 'poisson_regression_rows'). # FIXME: selecting an existing entry field should be emitted as a SelectFields; mt = mt._select_all(; col_exprs=dict(**{y_field_name: y}, **dict(zip(cov_field_names, covariates))),; row_exprs=row_fields,; col_key=[],; entry_exprs={x_field_name: x},; ). config = {; 'name': 'PoissonRegr",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:63848,Availability,toler,tolerance,63848,", x); raise_unless_entry_indexed('poisson_regression_rows/x', x). analyze('poisson_regression_rows/y', y, mt._col_indices). all_exprs = [y]; for e in covariates:; all_exprs.append(e); analyze('poisson_regression_rows/covariates', e, mt._col_indices). _warn_if_no_intercept('poisson_regression_rows', covariates). x_field_name = Env.get_uid(); y_field_name = '__y'; cov_field_names = list(f'__cov{i}' for i in range(len(covariates))); row_fields = _get_regression_row_fields(mt, pass_through, 'poisson_regression_rows'). # FIXME: selecting an existing entry field should be emitted as a SelectFields; mt = mt._select_all(; col_exprs=dict(**{y_field_name: y}, **dict(zip(cov_field_names, covariates))),; row_exprs=row_fields,; col_key=[],; entry_exprs={x_field_name: x},; ). config = {; 'name': 'PoissonRegression',; 'test': test,; 'yField': y_field_name,; 'xField': x_field_name,; 'covFields': cov_field_names,; 'passThrough': [x for x in row_fields if x not in mt.row_key],; 'maxIterations': max_iterations,; 'tolerance': tolerance,; }. return Table(ir.MatrixToTableApply(mt._mir, config)).persist(). @typecheck(; test=enumeration('wald', 'lrt', 'score'),; y=expr_float64,; x=expr_float64,; covariates=sequenceof(expr_float64),; pass_through=sequenceof(oneof(str, Expression)),; max_iterations=int,; tolerance=nullable(float),; ); def _lowered_poisson_regression_rows(; test, y, x, covariates, pass_through=(), *, max_iterations: int = 25, tolerance: Optional[float] = None; ):; assert max_iterations > 0. if tolerance is None:; tolerance = 1e-8; assert tolerance > 0.0. k = len(covariates); if k == 0:; raise ValueError('_lowered_poisson_regression_rows: at least one covariate is required.'); _warn_if_no_intercept('_lowered_poisson_regression_rows', covariates). mt = matrix_table_source('_lowered_poisson_regression_rows/x', x); raise_unless_entry_indexed('_lowered_poisson_regression_rows/x', x). row_exprs = _get_regression_row_fields(mt, pass_through, '_lowered_poisson_regression_rows'); mt =",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:63860,Availability,toler,tolerance,63860,", x); raise_unless_entry_indexed('poisson_regression_rows/x', x). analyze('poisson_regression_rows/y', y, mt._col_indices). all_exprs = [y]; for e in covariates:; all_exprs.append(e); analyze('poisson_regression_rows/covariates', e, mt._col_indices). _warn_if_no_intercept('poisson_regression_rows', covariates). x_field_name = Env.get_uid(); y_field_name = '__y'; cov_field_names = list(f'__cov{i}' for i in range(len(covariates))); row_fields = _get_regression_row_fields(mt, pass_through, 'poisson_regression_rows'). # FIXME: selecting an existing entry field should be emitted as a SelectFields; mt = mt._select_all(; col_exprs=dict(**{y_field_name: y}, **dict(zip(cov_field_names, covariates))),; row_exprs=row_fields,; col_key=[],; entry_exprs={x_field_name: x},; ). config = {; 'name': 'PoissonRegression',; 'test': test,; 'yField': y_field_name,; 'xField': x_field_name,; 'covFields': cov_field_names,; 'passThrough': [x for x in row_fields if x not in mt.row_key],; 'maxIterations': max_iterations,; 'tolerance': tolerance,; }. return Table(ir.MatrixToTableApply(mt._mir, config)).persist(). @typecheck(; test=enumeration('wald', 'lrt', 'score'),; y=expr_float64,; x=expr_float64,; covariates=sequenceof(expr_float64),; pass_through=sequenceof(oneof(str, Expression)),; max_iterations=int,; tolerance=nullable(float),; ); def _lowered_poisson_regression_rows(; test, y, x, covariates, pass_through=(), *, max_iterations: int = 25, tolerance: Optional[float] = None; ):; assert max_iterations > 0. if tolerance is None:; tolerance = 1e-8; assert tolerance > 0.0. k = len(covariates); if k == 0:; raise ValueError('_lowered_poisson_regression_rows: at least one covariate is required.'); _warn_if_no_intercept('_lowered_poisson_regression_rows', covariates). mt = matrix_table_source('_lowered_poisson_regression_rows/x', x); raise_unless_entry_indexed('_lowered_poisson_regression_rows/x', x). row_exprs = _get_regression_row_fields(mt, pass_through, '_lowered_poisson_regression_rows'); mt =",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:64138,Availability,toler,tolerance,64138,"variates). x_field_name = Env.get_uid(); y_field_name = '__y'; cov_field_names = list(f'__cov{i}' for i in range(len(covariates))); row_fields = _get_regression_row_fields(mt, pass_through, 'poisson_regression_rows'). # FIXME: selecting an existing entry field should be emitted as a SelectFields; mt = mt._select_all(; col_exprs=dict(**{y_field_name: y}, **dict(zip(cov_field_names, covariates))),; row_exprs=row_fields,; col_key=[],; entry_exprs={x_field_name: x},; ). config = {; 'name': 'PoissonRegression',; 'test': test,; 'yField': y_field_name,; 'xField': x_field_name,; 'covFields': cov_field_names,; 'passThrough': [x for x in row_fields if x not in mt.row_key],; 'maxIterations': max_iterations,; 'tolerance': tolerance,; }. return Table(ir.MatrixToTableApply(mt._mir, config)).persist(). @typecheck(; test=enumeration('wald', 'lrt', 'score'),; y=expr_float64,; x=expr_float64,; covariates=sequenceof(expr_float64),; pass_through=sequenceof(oneof(str, Expression)),; max_iterations=int,; tolerance=nullable(float),; ); def _lowered_poisson_regression_rows(; test, y, x, covariates, pass_through=(), *, max_iterations: int = 25, tolerance: Optional[float] = None; ):; assert max_iterations > 0. if tolerance is None:; tolerance = 1e-8; assert tolerance > 0.0. k = len(covariates); if k == 0:; raise ValueError('_lowered_poisson_regression_rows: at least one covariate is required.'); _warn_if_no_intercept('_lowered_poisson_regression_rows', covariates). mt = matrix_table_source('_lowered_poisson_regression_rows/x', x); raise_unless_entry_indexed('_lowered_poisson_regression_rows/x', x). row_exprs = _get_regression_row_fields(mt, pass_through, '_lowered_poisson_regression_rows'); mt = mt._select_all(; row_exprs=dict(pass_through=hl.struct(**row_exprs)),; col_exprs=dict(y=y, covariates=covariates),; entry_exprs=dict(x=x),; ); # FIXME: the order of the columns is irrelevant to regression; mt = mt.key_cols_by(). mt = mt.filter_cols(hl.all(hl.is_defined(mt.y), *[hl.is_defined(mt.covari",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:64278,Availability,toler,tolerance,64278,"variates). x_field_name = Env.get_uid(); y_field_name = '__y'; cov_field_names = list(f'__cov{i}' for i in range(len(covariates))); row_fields = _get_regression_row_fields(mt, pass_through, 'poisson_regression_rows'). # FIXME: selecting an existing entry field should be emitted as a SelectFields; mt = mt._select_all(; col_exprs=dict(**{y_field_name: y}, **dict(zip(cov_field_names, covariates))),; row_exprs=row_fields,; col_key=[],; entry_exprs={x_field_name: x},; ). config = {; 'name': 'PoissonRegression',; 'test': test,; 'yField': y_field_name,; 'xField': x_field_name,; 'covFields': cov_field_names,; 'passThrough': [x for x in row_fields if x not in mt.row_key],; 'maxIterations': max_iterations,; 'tolerance': tolerance,; }. return Table(ir.MatrixToTableApply(mt._mir, config)).persist(). @typecheck(; test=enumeration('wald', 'lrt', 'score'),; y=expr_float64,; x=expr_float64,; covariates=sequenceof(expr_float64),; pass_through=sequenceof(oneof(str, Expression)),; max_iterations=int,; tolerance=nullable(float),; ); def _lowered_poisson_regression_rows(; test, y, x, covariates, pass_through=(), *, max_iterations: int = 25, tolerance: Optional[float] = None; ):; assert max_iterations > 0. if tolerance is None:; tolerance = 1e-8; assert tolerance > 0.0. k = len(covariates); if k == 0:; raise ValueError('_lowered_poisson_regression_rows: at least one covariate is required.'); _warn_if_no_intercept('_lowered_poisson_regression_rows', covariates). mt = matrix_table_source('_lowered_poisson_regression_rows/x', x); raise_unless_entry_indexed('_lowered_poisson_regression_rows/x', x). row_exprs = _get_regression_row_fields(mt, pass_through, '_lowered_poisson_regression_rows'); mt = mt._select_all(; row_exprs=dict(pass_through=hl.struct(**row_exprs)),; col_exprs=dict(y=y, covariates=covariates),; entry_exprs=dict(x=x),; ); # FIXME: the order of the columns is irrelevant to regression; mt = mt.key_cols_by(). mt = mt.filter_cols(hl.all(hl.is_defined(mt.y), *[hl.is_defined(mt.covari",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:64347,Availability,toler,tolerance,64347,"ng an existing entry field should be emitted as a SelectFields; mt = mt._select_all(; col_exprs=dict(**{y_field_name: y}, **dict(zip(cov_field_names, covariates))),; row_exprs=row_fields,; col_key=[],; entry_exprs={x_field_name: x},; ). config = {; 'name': 'PoissonRegression',; 'test': test,; 'yField': y_field_name,; 'xField': x_field_name,; 'covFields': cov_field_names,; 'passThrough': [x for x in row_fields if x not in mt.row_key],; 'maxIterations': max_iterations,; 'tolerance': tolerance,; }. return Table(ir.MatrixToTableApply(mt._mir, config)).persist(). @typecheck(; test=enumeration('wald', 'lrt', 'score'),; y=expr_float64,; x=expr_float64,; covariates=sequenceof(expr_float64),; pass_through=sequenceof(oneof(str, Expression)),; max_iterations=int,; tolerance=nullable(float),; ); def _lowered_poisson_regression_rows(; test, y, x, covariates, pass_through=(), *, max_iterations: int = 25, tolerance: Optional[float] = None; ):; assert max_iterations > 0. if tolerance is None:; tolerance = 1e-8; assert tolerance > 0.0. k = len(covariates); if k == 0:; raise ValueError('_lowered_poisson_regression_rows: at least one covariate is required.'); _warn_if_no_intercept('_lowered_poisson_regression_rows', covariates). mt = matrix_table_source('_lowered_poisson_regression_rows/x', x); raise_unless_entry_indexed('_lowered_poisson_regression_rows/x', x). row_exprs = _get_regression_row_fields(mt, pass_through, '_lowered_poisson_regression_rows'); mt = mt._select_all(; row_exprs=dict(pass_through=hl.struct(**row_exprs)),; col_exprs=dict(y=y, covariates=covariates),; entry_exprs=dict(x=x),; ); # FIXME: the order of the columns is irrelevant to regression; mt = mt.key_cols_by(). mt = mt.filter_cols(hl.all(hl.is_defined(mt.y), *[hl.is_defined(mt.covariates[i]) for i in range(k)])). mt = mt.annotate_globals(; **mt.aggregate_cols(; hl.struct(; yvec=hl.agg.collect(hl.float(mt.y)),; covmat=hl.agg.collect(mt.covariates.map(hl.float)),; n=hl.agg.count(),; ),; _localize=False,; ); ); mt =",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:64367,Availability,toler,tolerance,64367,"ng an existing entry field should be emitted as a SelectFields; mt = mt._select_all(; col_exprs=dict(**{y_field_name: y}, **dict(zip(cov_field_names, covariates))),; row_exprs=row_fields,; col_key=[],; entry_exprs={x_field_name: x},; ). config = {; 'name': 'PoissonRegression',; 'test': test,; 'yField': y_field_name,; 'xField': x_field_name,; 'covFields': cov_field_names,; 'passThrough': [x for x in row_fields if x not in mt.row_key],; 'maxIterations': max_iterations,; 'tolerance': tolerance,; }. return Table(ir.MatrixToTableApply(mt._mir, config)).persist(). @typecheck(; test=enumeration('wald', 'lrt', 'score'),; y=expr_float64,; x=expr_float64,; covariates=sequenceof(expr_float64),; pass_through=sequenceof(oneof(str, Expression)),; max_iterations=int,; tolerance=nullable(float),; ); def _lowered_poisson_regression_rows(; test, y, x, covariates, pass_through=(), *, max_iterations: int = 25, tolerance: Optional[float] = None; ):; assert max_iterations > 0. if tolerance is None:; tolerance = 1e-8; assert tolerance > 0.0. k = len(covariates); if k == 0:; raise ValueError('_lowered_poisson_regression_rows: at least one covariate is required.'); _warn_if_no_intercept('_lowered_poisson_regression_rows', covariates). mt = matrix_table_source('_lowered_poisson_regression_rows/x', x); raise_unless_entry_indexed('_lowered_poisson_regression_rows/x', x). row_exprs = _get_regression_row_fields(mt, pass_through, '_lowered_poisson_regression_rows'); mt = mt._select_all(; row_exprs=dict(pass_through=hl.struct(**row_exprs)),; col_exprs=dict(y=y, covariates=covariates),; entry_exprs=dict(x=x),; ); # FIXME: the order of the columns is irrelevant to regression; mt = mt.key_cols_by(). mt = mt.filter_cols(hl.all(hl.is_defined(mt.y), *[hl.is_defined(mt.covariates[i]) for i in range(k)])). mt = mt.annotate_globals(; **mt.aggregate_cols(; hl.struct(; yvec=hl.agg.collect(hl.float(mt.y)),; covmat=hl.agg.collect(mt.covariates.map(hl.float)),; n=hl.agg.count(),; ),; _localize=False,; ); ); mt =",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:64392,Availability,toler,tolerance,64392,"ng an existing entry field should be emitted as a SelectFields; mt = mt._select_all(; col_exprs=dict(**{y_field_name: y}, **dict(zip(cov_field_names, covariates))),; row_exprs=row_fields,; col_key=[],; entry_exprs={x_field_name: x},; ). config = {; 'name': 'PoissonRegression',; 'test': test,; 'yField': y_field_name,; 'xField': x_field_name,; 'covFields': cov_field_names,; 'passThrough': [x for x in row_fields if x not in mt.row_key],; 'maxIterations': max_iterations,; 'tolerance': tolerance,; }. return Table(ir.MatrixToTableApply(mt._mir, config)).persist(). @typecheck(; test=enumeration('wald', 'lrt', 'score'),; y=expr_float64,; x=expr_float64,; covariates=sequenceof(expr_float64),; pass_through=sequenceof(oneof(str, Expression)),; max_iterations=int,; tolerance=nullable(float),; ); def _lowered_poisson_regression_rows(; test, y, x, covariates, pass_through=(), *, max_iterations: int = 25, tolerance: Optional[float] = None; ):; assert max_iterations > 0. if tolerance is None:; tolerance = 1e-8; assert tolerance > 0.0. k = len(covariates); if k == 0:; raise ValueError('_lowered_poisson_regression_rows: at least one covariate is required.'); _warn_if_no_intercept('_lowered_poisson_regression_rows', covariates). mt = matrix_table_source('_lowered_poisson_regression_rows/x', x); raise_unless_entry_indexed('_lowered_poisson_regression_rows/x', x). row_exprs = _get_regression_row_fields(mt, pass_through, '_lowered_poisson_regression_rows'); mt = mt._select_all(; row_exprs=dict(pass_through=hl.struct(**row_exprs)),; col_exprs=dict(y=y, covariates=covariates),; entry_exprs=dict(x=x),; ); # FIXME: the order of the columns is irrelevant to regression; mt = mt.key_cols_by(). mt = mt.filter_cols(hl.all(hl.is_defined(mt.y), *[hl.is_defined(mt.covariates[i]) for i in range(k)])). mt = mt.annotate_globals(; **mt.aggregate_cols(; hl.struct(; yvec=hl.agg.collect(hl.float(mt.y)),; covmat=hl.agg.collect(mt.covariates.map(hl.float)),; n=hl.agg.count(),; ),; _localize=False,; ); ); mt =",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:66009,Availability,toler,tolerance,66009,"x),; ); # FIXME: the order of the columns is irrelevant to regression; mt = mt.key_cols_by(). mt = mt.filter_cols(hl.all(hl.is_defined(mt.y), *[hl.is_defined(mt.covariates[i]) for i in range(k)])). mt = mt.annotate_globals(; **mt.aggregate_cols(; hl.struct(; yvec=hl.agg.collect(hl.float(mt.y)),; covmat=hl.agg.collect(mt.covariates.map(hl.float)),; n=hl.agg.count(),; ),; _localize=False,; ); ); mt = mt.annotate_globals(; yvec=(; hl.case(); .when(mt.n - k - 1 >= 1, hl.nd.array(mt.yvec)); .or_error(; hl.format(""_lowered_poisson_regression_rows: insufficient degrees of freedom: n=%s, k=%s"", mt.n, k); ); ),; covmat=hl.nd.array(mt.covmat),; n_complete_samples=mt.n,; ); covmat = mt.covmat; yvec = mt.yvec; n = mt.n_complete_samples. logmean = hl.log(yvec.sum() / n); b = hl.nd.array([logmean, *[0 for _ in range(k - 1)]]); mu = hl.exp(covmat @ b); residual = yvec - mu; score = covmat.T @ residual; fisher = (mu * covmat.T) @ covmat; mt = mt.annotate_globals(null_fit=_poisson_fit(covmat, yvec, b, mu, score, fisher, max_iterations, tolerance)); mt = mt.annotate_globals(; null_fit=hl.case(); .when(mt.null_fit.converged, mt.null_fit); .or_error(; hl.format(; '_lowered_poisson_regression_rows: null model did not converge: %s',; mt.null_fit.select('n_iterations', 'log_lkhd', 'converged', 'exploded'),; ); ); ); mt = mt.annotate_rows(mean_x=hl.agg.mean(mt.x)); mt = mt.annotate_rows(xvec=hl.nd.array(hl.agg.collect(hl.coalesce(mt.x, mt.mean_x)))); ht = mt.rows(). covmat = ht.covmat; null_fit = ht.null_fit; # FIXME: we should test a whole block of variants at a time not one-by-one; xvec = ht.xvec; yvec = ht.yvec. if test == 'score':; chi_sq, p = _poisson_score_test(null_fit, covmat, yvec, xvec); return ht.select(chi_sq_stat=chi_sq, p_value=p, **ht.pass_through).select_globals('null_fit'). X = hl.nd.hstack([covmat, xvec.T.reshape(-1, 1)]); b = hl.nd.hstack([null_fit.b, hl.nd.array([0.0])]); mu = sigmoid(X @ b); residual = yvec - mu; score = hl.nd.hstack([null_fit.score, hl.nd.array([xvec ",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:67313,Availability,toler,tolerance,67313,"annotate_rows(mean_x=hl.agg.mean(mt.x)); mt = mt.annotate_rows(xvec=hl.nd.array(hl.agg.collect(hl.coalesce(mt.x, mt.mean_x)))); ht = mt.rows(). covmat = ht.covmat; null_fit = ht.null_fit; # FIXME: we should test a whole block of variants at a time not one-by-one; xvec = ht.xvec; yvec = ht.yvec. if test == 'score':; chi_sq, p = _poisson_score_test(null_fit, covmat, yvec, xvec); return ht.select(chi_sq_stat=chi_sq, p_value=p, **ht.pass_through).select_globals('null_fit'). X = hl.nd.hstack([covmat, xvec.T.reshape(-1, 1)]); b = hl.nd.hstack([null_fit.b, hl.nd.array([0.0])]); mu = sigmoid(X @ b); residual = yvec - mu; score = hl.nd.hstack([null_fit.score, hl.nd.array([xvec @ residual])]). fisher00 = null_fit.fisher; fisher01 = ((covmat.T * mu) @ xvec).reshape((-1, 1)); fisher10 = fisher01.T; fisher11 = hl.nd.array([[(mu * xvec.T) @ xvec]]); fisher = hl.nd.vstack([hl.nd.hstack([fisher00, fisher01]), hl.nd.hstack([fisher10, fisher11])]). test_fit = _poisson_fit(X, yvec, b, mu, score, fisher, max_iterations, tolerance); if test == 'lrt':; return ht.select(test_fit=test_fit, **lrt_test(X, null_fit, test_fit), **ht.pass_through).select_globals(; 'null_fit'; ); assert test == 'wald'; return ht.select(test_fit=test_fit, **wald_test(X, test_fit), **ht.pass_through).select_globals('null_fit'). def _poisson_fit(; X: NDArrayNumericExpression, # (N, K); y: NDArrayNumericExpression, # (N,); b: NDArrayNumericExpression, # (K,); mu: NDArrayNumericExpression, # (N,); score: NDArrayNumericExpression, # (K,); fisher: NDArrayNumericExpression, # (K, K); max_iterations: int,; tolerance: float,; ) -> StructExpression:; """"""Iteratively reweighted least squares to fit the model y ~ Poisson(exp(X \beta)). When fitting the null model, K=n_covariates, otherwise K=n_covariates + 1.; """"""; assert max_iterations >= 0; assert X.ndim == 2; assert y.ndim == 1; assert b.ndim == 1; assert mu.ndim == 1; assert score.ndim == 1; assert fisher.ndim == 2. dtype = numerical_regression_fit_dtype; blank_struct = hl",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:67875,Availability,toler,tolerance,67875,"vec.T.reshape(-1, 1)]); b = hl.nd.hstack([null_fit.b, hl.nd.array([0.0])]); mu = sigmoid(X @ b); residual = yvec - mu; score = hl.nd.hstack([null_fit.score, hl.nd.array([xvec @ residual])]). fisher00 = null_fit.fisher; fisher01 = ((covmat.T * mu) @ xvec).reshape((-1, 1)); fisher10 = fisher01.T; fisher11 = hl.nd.array([[(mu * xvec.T) @ xvec]]); fisher = hl.nd.vstack([hl.nd.hstack([fisher00, fisher01]), hl.nd.hstack([fisher10, fisher11])]). test_fit = _poisson_fit(X, yvec, b, mu, score, fisher, max_iterations, tolerance); if test == 'lrt':; return ht.select(test_fit=test_fit, **lrt_test(X, null_fit, test_fit), **ht.pass_through).select_globals(; 'null_fit'; ); assert test == 'wald'; return ht.select(test_fit=test_fit, **wald_test(X, test_fit), **ht.pass_through).select_globals('null_fit'). def _poisson_fit(; X: NDArrayNumericExpression, # (N, K); y: NDArrayNumericExpression, # (N,); b: NDArrayNumericExpression, # (K,); mu: NDArrayNumericExpression, # (N,); score: NDArrayNumericExpression, # (K,); fisher: NDArrayNumericExpression, # (K, K); max_iterations: int,; tolerance: float,; ) -> StructExpression:; """"""Iteratively reweighted least squares to fit the model y ~ Poisson(exp(X \beta)). When fitting the null model, K=n_covariates, otherwise K=n_covariates + 1.; """"""; assert max_iterations >= 0; assert X.ndim == 2; assert y.ndim == 1; assert b.ndim == 1; assert mu.ndim == 1; assert score.ndim == 1; assert fisher.ndim == 2. dtype = numerical_regression_fit_dtype; blank_struct = hl.struct(**{k: hl.missing(dtype[k]) for k in dtype}). def fit(recur, iteration, b, mu, score, fisher):; def cont(exploded, delta_b, max_delta_b):; log_lkhd = y @ hl.log(mu) - mu.sum(). next_b = b + delta_b; next_mu = hl.exp(X @ next_b); next_score = X.T @ (y - next_mu); next_fisher = (next_mu * X.T) @ X. return (; hl.case(); .when(; exploded | hl.is_nan(delta_b[0]),; blank_struct.annotate(n_iterations=iteration, log_lkhd=log_lkhd, converged=False, exploded=True),; ); .when(; max_delta_b < toleranc",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:68791,Availability,toler,tolerance,68791,"cExpression, # (K,); fisher: NDArrayNumericExpression, # (K, K); max_iterations: int,; tolerance: float,; ) -> StructExpression:; """"""Iteratively reweighted least squares to fit the model y ~ Poisson(exp(X \beta)). When fitting the null model, K=n_covariates, otherwise K=n_covariates + 1.; """"""; assert max_iterations >= 0; assert X.ndim == 2; assert y.ndim == 1; assert b.ndim == 1; assert mu.ndim == 1; assert score.ndim == 1; assert fisher.ndim == 2. dtype = numerical_regression_fit_dtype; blank_struct = hl.struct(**{k: hl.missing(dtype[k]) for k in dtype}). def fit(recur, iteration, b, mu, score, fisher):; def cont(exploded, delta_b, max_delta_b):; log_lkhd = y @ hl.log(mu) - mu.sum(). next_b = b + delta_b; next_mu = hl.exp(X @ next_b); next_score = X.T @ (y - next_mu); next_fisher = (next_mu * X.T) @ X. return (; hl.case(); .when(; exploded | hl.is_nan(delta_b[0]),; blank_struct.annotate(n_iterations=iteration, log_lkhd=log_lkhd, converged=False, exploded=True),; ); .when(; max_delta_b < tolerance,; hl.struct(; b=b,; score=score,; fisher=fisher,; mu=mu,; n_iterations=iteration,; log_lkhd=log_lkhd,; converged=True,; exploded=False,; ),; ); .when(; iteration == max_iterations,; blank_struct.annotate(n_iterations=iteration, log_lkhd=log_lkhd, converged=False, exploded=False),; ); .default(recur(iteration + 1, next_b, next_mu, next_score, next_fisher)); ). delta_b_struct = hl.nd.solve(fisher, score, no_crash=True). exploded = delta_b_struct.failed; delta_b = delta_b_struct.solution; max_delta_b = nd_max(delta_b.map(lambda e: hl.abs(e))); return hl.bind(cont, exploded, delta_b, max_delta_b). if max_iterations == 0:; return blank_struct.select(n_iterations=0, log_lkhd=0, converged=False, exploded=False); return hl.experimental.loop(fit, dtype, 1, b, mu, score, fisher). def _poisson_score_test(null_fit, covmat, y, xvec):; dof = 1. X = hl.nd.hstack([covmat, xvec.T.reshape(-1, 1)]); b = hl.nd.hstack([null_fit.b, hl.nd.array([0.0])]); mu = hl.exp(X @ b); score = hl.nd.hstack(",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:74770,Availability,avail,available,74770,"widehat{\sigma} G W G^T \widehat{\sigma} h \\; A &= \widehat{\sigma} G W^{1/2} \\; B &= A A^T \\; \\; Q &= h^T B h \\; \end{align*}. This expression is a `""quadratic form"" <https://en.wikipedia.org/wiki/Quadratic_form>`__ of the; vector :math:`h`. Because :math:`B` is a real symmetric matrix, we can eigendecompose it into an; orthogonal matrix and a diagonal matrix of eigenvalues:. .. math::. \begin{align*}; U \Lambda U^T &= B \quad\quad \Lambda \textrm{ diagonal } U \textrm{ orthogonal} \\; Q &= h^T U \Lambda U^T h; \end{align*}. An orthogonal matrix transforms a vector of i.i.d. standard normal variables into a new vector; of different i.i.d standard normal variables, so we can interpret :math:`Q` as a weighted sum of; i.i.d. standard normal variables:. .. math::. \begin{align*}; \tilde{h} &= U^T h \\; Q &= \sum_s \Lambda_{ss} \tilde{h}_s^2; \end{align*}. The distribution of such sums (indeed, any quadratic form of i.i.d. standard normal variables); is governed by the generalized chi-squared distribution (the CDF is available in Hail as; :func:`.pgenchisq`):. .. math::. \begin{align*}; \lambda_i &= \Lambda_{ii} \\; Q &\sim \mathrm{GeneralizedChiSquared}(\lambda, \vec{1}, \vec{0}, 0, 0); \end{align*}. Therefore, we can test the null hypothesis by calculating the probability of receiving values; larger than :math:`Q`. If that probability is very small, then the residual phenotypes are; likely not i.i.d. normal variables with variance :math:`\widehat{\sigma}^2`. The SKAT method was originally described in:. Wu MC, Lee S, Cai T, Li Y, Boehnke M, Lin X. *Rare-variant association testing for; sequencing data with the sequence kernel association test.* Am J Hum Genet. 2011 Jul; 15;89(1):82-93. doi: 10.1016/j.ajhg.2011.05.029. Epub 2011 Jul 7. PMID: 21737059; PMCID:; PMC3135811. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3135811/. Examples; --------. Generate a dataset with a phenotype noisily computed from the genotypes:. >>> hl.reset_global_randomness(); >>> mt = hl.ba",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:76290,Availability,fault,fault,76290,"association testing for; sequencing data with the sequence kernel association test.* Am J Hum Genet. 2011 Jul; 15;89(1):82-93. doi: 10.1016/j.ajhg.2011.05.029. Epub 2011 Jul 7. PMID: 21737059; PMCID:; PMC3135811. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3135811/. Examples; --------. Generate a dataset with a phenotype noisily computed from the genotypes:. >>> hl.reset_global_randomness(); >>> mt = hl.balding_nichols_model(1, n_samples=100, n_variants=20); >>> mt = mt.annotate_rows(gene = mt.locus.position // 12); >>> mt = mt.annotate_rows(weight = 1); >>> mt = mt.annotate_cols(phenotype = hl.agg.sum(mt.GT.n_alt_alleles()) - 20 + hl.rand_norm(0, 1)). Test if the phenotype is significantly associated with the genotype:. >>> skat = hl._linear_skat(; ... mt.gene,; ... mt.weight,; ... mt.phenotype,; ... mt.GT.n_alt_alleles(),; ... covariates=[1.0]); >>> skat.show(); +-------+-------+----------+----------+-------+; | group | size | q_stat | p_value | fault |; +-------+-------+----------+----------+-------+; | int32 | int64 | float64 | float64 | int32 |; +-------+-------+----------+----------+-------+; | 0 | 11 | 8.76e+02 | 1.23e-05 | 0 |; | 1 | 9 | 8.13e+02 | 3.95e-05 | 0 |; +-------+-------+----------+----------+-------+. The same test, but using the original paper's suggested weights which are derived from the; allele frequency. >>> mt = hl.variant_qc(mt); >>> skat = hl._linear_skat(; ... mt.gene,; ... hl.dbeta(mt.variant_qc.AF[0], 1, 25),; ... mt.phenotype,; ... mt.GT.n_alt_alleles(),; ... covariates=[1.0]); >>> skat.show(); +-------+-------+----------+----------+-------+; | group | size | q_stat | p_value | fault |; +-------+-------+----------+----------+-------+; | int32 | int64 | float64 | float64 | int32 |; +-------+-------+----------+----------+-------+; | 0 | 11 | 2.39e+01 | 4.32e-01 | 0 |; | 1 | 9 | 1.69e+01 | 7.82e-02 | 0 |; +-------+-------+----------+----------+-------+. Our simulated data was unweighted, so the null hypothesis appears true. In real datas",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:76964,Availability,fault,fault,76964,"phenotype is significantly associated with the genotype:. >>> skat = hl._linear_skat(; ... mt.gene,; ... mt.weight,; ... mt.phenotype,; ... mt.GT.n_alt_alleles(),; ... covariates=[1.0]); >>> skat.show(); +-------+-------+----------+----------+-------+; | group | size | q_stat | p_value | fault |; +-------+-------+----------+----------+-------+; | int32 | int64 | float64 | float64 | int32 |; +-------+-------+----------+----------+-------+; | 0 | 11 | 8.76e+02 | 1.23e-05 | 0 |; | 1 | 9 | 8.13e+02 | 3.95e-05 | 0 |; +-------+-------+----------+----------+-------+. The same test, but using the original paper's suggested weights which are derived from the; allele frequency. >>> mt = hl.variant_qc(mt); >>> skat = hl._linear_skat(; ... mt.gene,; ... hl.dbeta(mt.variant_qc.AF[0], 1, 25),; ... mt.phenotype,; ... mt.GT.n_alt_alleles(),; ... covariates=[1.0]); >>> skat.show(); +-------+-------+----------+----------+-------+; | group | size | q_stat | p_value | fault |; +-------+-------+----------+----------+-------+; | int32 | int64 | float64 | float64 | int32 |; +-------+-------+----------+----------+-------+; | 0 | 11 | 2.39e+01 | 4.32e-01 | 0 |; | 1 | 9 | 1.69e+01 | 7.82e-02 | 0 |; +-------+-------+----------+----------+-------+. Our simulated data was unweighted, so the null hypothesis appears true. In real datasets, we; expect the allele frequency to correlate with effect size. Notice that, in the second group, the fault flag is set to 1. This indicates that the numerical; integration to calculate the p-value failed to achieve the required accuracy (by default,; 1e-6). In this particular case, the null hypothesis is likely true and the numerical integration; returned a (nonsensical) value greater than one. The `max_size` parameter allows us to skip large genes that would cause ""out of memory"" errors:. >>> skat = hl._linear_skat(; ... mt.gene,; ... mt.weight,; ... mt.phenotype,; ... mt.GT.n_alt_alleles(),; ... covariates=[1.0],; ... max_size=10); >>> skat.show(); +-------+-",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:77433,Availability,fault,fault,77433,"--------+-------+; | 0 | 11 | 8.76e+02 | 1.23e-05 | 0 |; | 1 | 9 | 8.13e+02 | 3.95e-05 | 0 |; +-------+-------+----------+----------+-------+. The same test, but using the original paper's suggested weights which are derived from the; allele frequency. >>> mt = hl.variant_qc(mt); >>> skat = hl._linear_skat(; ... mt.gene,; ... hl.dbeta(mt.variant_qc.AF[0], 1, 25),; ... mt.phenotype,; ... mt.GT.n_alt_alleles(),; ... covariates=[1.0]); >>> skat.show(); +-------+-------+----------+----------+-------+; | group | size | q_stat | p_value | fault |; +-------+-------+----------+----------+-------+; | int32 | int64 | float64 | float64 | int32 |; +-------+-------+----------+----------+-------+; | 0 | 11 | 2.39e+01 | 4.32e-01 | 0 |; | 1 | 9 | 1.69e+01 | 7.82e-02 | 0 |; +-------+-------+----------+----------+-------+. Our simulated data was unweighted, so the null hypothesis appears true. In real datasets, we; expect the allele frequency to correlate with effect size. Notice that, in the second group, the fault flag is set to 1. This indicates that the numerical; integration to calculate the p-value failed to achieve the required accuracy (by default,; 1e-6). In this particular case, the null hypothesis is likely true and the numerical integration; returned a (nonsensical) value greater than one. The `max_size` parameter allows us to skip large genes that would cause ""out of memory"" errors:. >>> skat = hl._linear_skat(; ... mt.gene,; ... mt.weight,; ... mt.phenotype,; ... mt.GT.n_alt_alleles(),; ... covariates=[1.0],; ... max_size=10); >>> skat.show(); +-------+-------+----------+----------+-------+; | group | size | q_stat | p_value | fault |; +-------+-------+----------+----------+-------+; | int32 | int64 | float64 | float64 | int32 |; +-------+-------+----------+----------+-------+; | 0 | 11 | NA | NA | NA |; | 1 | 9 | 8.13e+02 | 3.95e-05 | 0 |; +-------+-------+----------+----------+-------+. Notes; -----. In the SKAT R package, the ""weights"" are actually the *square root* ",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:77818,Availability,error,errors,77818,"F[0], 1, 25),; ... mt.phenotype,; ... mt.GT.n_alt_alleles(),; ... covariates=[1.0]); >>> skat.show(); +-------+-------+----------+----------+-------+; | group | size | q_stat | p_value | fault |; +-------+-------+----------+----------+-------+; | int32 | int64 | float64 | float64 | int32 |; +-------+-------+----------+----------+-------+; | 0 | 11 | 2.39e+01 | 4.32e-01 | 0 |; | 1 | 9 | 1.69e+01 | 7.82e-02 | 0 |; +-------+-------+----------+----------+-------+. Our simulated data was unweighted, so the null hypothesis appears true. In real datasets, we; expect the allele frequency to correlate with effect size. Notice that, in the second group, the fault flag is set to 1. This indicates that the numerical; integration to calculate the p-value failed to achieve the required accuracy (by default,; 1e-6). In this particular case, the null hypothesis is likely true and the numerical integration; returned a (nonsensical) value greater than one. The `max_size` parameter allows us to skip large genes that would cause ""out of memory"" errors:. >>> skat = hl._linear_skat(; ... mt.gene,; ... mt.weight,; ... mt.phenotype,; ... mt.GT.n_alt_alleles(),; ... covariates=[1.0],; ... max_size=10); >>> skat.show(); +-------+-------+----------+----------+-------+; | group | size | q_stat | p_value | fault |; +-------+-------+----------+----------+-------+; | int32 | int64 | float64 | float64 | int32 |; +-------+-------+----------+----------+-------+; | 0 | 11 | NA | NA | NA |; | 1 | 9 | 8.13e+02 | 3.95e-05 | 0 |; +-------+-------+----------+----------+-------+. Notes; -----. In the SKAT R package, the ""weights"" are actually the *square root* of the weight expression; from the paper. This method uses the definition from the paper. The paper includes an explicit intercept term but this method expects the user to specify the; intercept as an extra covariate with the value 1. This method does not perform small sample size correction. The `q_stat` return value is *not* the :math:`Q` statistic ",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:78076,Availability,fault,fault,78076," | 2.39e+01 | 4.32e-01 | 0 |; | 1 | 9 | 1.69e+01 | 7.82e-02 | 0 |; +-------+-------+----------+----------+-------+. Our simulated data was unweighted, so the null hypothesis appears true. In real datasets, we; expect the allele frequency to correlate with effect size. Notice that, in the second group, the fault flag is set to 1. This indicates that the numerical; integration to calculate the p-value failed to achieve the required accuracy (by default,; 1e-6). In this particular case, the null hypothesis is likely true and the numerical integration; returned a (nonsensical) value greater than one. The `max_size` parameter allows us to skip large genes that would cause ""out of memory"" errors:. >>> skat = hl._linear_skat(; ... mt.gene,; ... mt.weight,; ... mt.phenotype,; ... mt.GT.n_alt_alleles(),; ... covariates=[1.0],; ... max_size=10); >>> skat.show(); +-------+-------+----------+----------+-------+; | group | size | q_stat | p_value | fault |; +-------+-------+----------+----------+-------+; | int32 | int64 | float64 | float64 | int32 |; +-------+-------+----------+----------+-------+; | 0 | 11 | NA | NA | NA |; | 1 | 9 | 8.13e+02 | 3.95e-05 | 0 |; +-------+-------+----------+----------+-------+. Notes; -----. In the SKAT R package, the ""weights"" are actually the *square root* of the weight expression; from the paper. This method uses the definition from the paper. The paper includes an explicit intercept term but this method expects the user to specify the; intercept as an extra covariate with the value 1. This method does not perform small sample size correction. The `q_stat` return value is *not* the :math:`Q` statistic from the paper. We match the output; of the SKAT R package which returns :math:`\tilde{Q}`:. .. math::. \tilde{Q} = \frac{Q}{2 \widehat{\sigma}^2}. Parameters; ----------; group : :class:`.Expression`; Row-indexed expression indicating to which group a variant belongs. This is typically a gene; name or an interval.; weight : :class:`.Float64Expre",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:79812,Availability,fault,fault,79812," We match the output; of the SKAT R package which returns :math:`\tilde{Q}`:. .. math::. \tilde{Q} = \frac{Q}{2 \widehat{\sigma}^2}. Parameters; ----------; group : :class:`.Expression`; Row-indexed expression indicating to which group a variant belongs. This is typically a gene; name or an interval.; weight : :class:`.Float64Expression`; Row-indexed expression for weights. Must be non-negative.; y : :class:`.Float64Expression`; Column-indexed response (dependent variable) expression.; x : :class:`.Float64Expression`; Entry-indexed expression for input (independent variable).; covariates : :obj:`list` of :class:`.Float64Expression`; List of column-indexed covariate expressions. You must explicitly provide an intercept term; if desired. You must provide at least one covariate.; max_size : :obj:`int`; Maximum size of group on which to run the test. Groups which exceed this size will have a; missing p-value and missing q statistic. Defaults to 46340.; accuracy : :obj:`float`; The accuracy of the p-value if fault value is zero. Defaults to 1e-6.; iterations : :obj:`int`; The maximum number of iterations used to calculate the p-value (which has no closed; form). Defaults to 1e5. Returns; -------; :class:`.Table`; One row per-group. The key is `group`. The row fields are:. - group : the `group` parameter. - size : :obj:`.tint64`, the number of variants in this group. - q_stat : :obj:`.tfloat64`, the :math:`Q` statistic, see Notes for why this differs from the paper. - p_value : :obj:`.tfloat64`, the test p-value for the null hypothesis that the genotypes; have no linear influence on the phenotypes. - fault : :obj:`.tint32`, the fault flag from :func:`.pgenchisq`. The global fields are:. - n_complete_samples : :obj:`.tint32`, the number of samples with neither a missing; phenotype nor a missing covariate. - y_residual : :obj:`.tint32`, the residual phenotype from the null model. This may be; interpreted as the component of the phenotype not explained by the covariates alon",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:80415,Availability,fault,fault,80415,"Expression`; List of column-indexed covariate expressions. You must explicitly provide an intercept term; if desired. You must provide at least one covariate.; max_size : :obj:`int`; Maximum size of group on which to run the test. Groups which exceed this size will have a; missing p-value and missing q statistic. Defaults to 46340.; accuracy : :obj:`float`; The accuracy of the p-value if fault value is zero. Defaults to 1e-6.; iterations : :obj:`int`; The maximum number of iterations used to calculate the p-value (which has no closed; form). Defaults to 1e5. Returns; -------; :class:`.Table`; One row per-group. The key is `group`. The row fields are:. - group : the `group` parameter. - size : :obj:`.tint64`, the number of variants in this group. - q_stat : :obj:`.tfloat64`, the :math:`Q` statistic, see Notes for why this differs from the paper. - p_value : :obj:`.tfloat64`, the test p-value for the null hypothesis that the genotypes; have no linear influence on the phenotypes. - fault : :obj:`.tint32`, the fault flag from :func:`.pgenchisq`. The global fields are:. - n_complete_samples : :obj:`.tint32`, the number of samples with neither a missing; phenotype nor a missing covariate. - y_residual : :obj:`.tint32`, the residual phenotype from the null model. This may be; interpreted as the component of the phenotype not explained by the covariates alone. - s2 : :obj:`.tfloat64`, the variance of the residuals, :math:`\sigma^2` in the paper. """"""; mt = matrix_table_source('skat/x', x); k = len(covariates); if k == 0:; raise ValueError('_linear_skat: at least one covariate is required.'); _warn_if_no_intercept('_linear_skat', covariates); mt = mt._select_all(; row_exprs=dict(group=group, weight=weight), col_exprs=dict(y=y, covariates=covariates), entry_exprs=dict(x=x); ); mt = mt.filter_cols(hl.all(hl.is_defined(mt.y), *[hl.is_defined(mt.covariates[i]) for i in range(k)])); yvec, covmat, n = mt.aggregate_cols(; (hl.agg.collect(hl.float(mt.y)), hl.agg.collect(mt.covariates",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:80443,Availability,fault,fault,80443,"-indexed covariate expressions. You must explicitly provide an intercept term; if desired. You must provide at least one covariate.; max_size : :obj:`int`; Maximum size of group on which to run the test. Groups which exceed this size will have a; missing p-value and missing q statistic. Defaults to 46340.; accuracy : :obj:`float`; The accuracy of the p-value if fault value is zero. Defaults to 1e-6.; iterations : :obj:`int`; The maximum number of iterations used to calculate the p-value (which has no closed; form). Defaults to 1e5. Returns; -------; :class:`.Table`; One row per-group. The key is `group`. The row fields are:. - group : the `group` parameter. - size : :obj:`.tint64`, the number of variants in this group. - q_stat : :obj:`.tfloat64`, the :math:`Q` statistic, see Notes for why this differs from the paper. - p_value : :obj:`.tfloat64`, the test p-value for the null hypothesis that the genotypes; have no linear influence on the phenotypes. - fault : :obj:`.tint32`, the fault flag from :func:`.pgenchisq`. The global fields are:. - n_complete_samples : :obj:`.tint32`, the number of samples with neither a missing; phenotype nor a missing covariate. - y_residual : :obj:`.tint32`, the residual phenotype from the null model. This may be; interpreted as the component of the phenotype not explained by the covariates alone. - s2 : :obj:`.tfloat64`, the variance of the residuals, :math:`\sigma^2` in the paper. """"""; mt = matrix_table_source('skat/x', x); k = len(covariates); if k == 0:; raise ValueError('_linear_skat: at least one covariate is required.'); _warn_if_no_intercept('_linear_skat', covariates); mt = mt._select_all(; row_exprs=dict(group=group, weight=weight), col_exprs=dict(y=y, covariates=covariates), entry_exprs=dict(x=x); ); mt = mt.filter_cols(hl.all(hl.is_defined(mt.y), *[hl.is_defined(mt.covariates[i]) for i in range(k)])); yvec, covmat, n = mt.aggregate_cols(; (hl.agg.collect(hl.float(mt.y)), hl.agg.collect(mt.covariates.map(hl.float)), hl.agg.coun",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:86545,Availability,fault,fault,86545,"prox filters the eigenvalues,; # presumably because a good estimate of the Generalized Chi-Sqaured CDF is not significantly; # affected by chi-squared components with very tiny weights.; threshold = 1e-5 * eigenvalues.sum() / eigenvalues.shape[0]; w = hl.array(eigenvalues).filter(lambda y: y >= threshold); genchisq_data = hl.pgenchisq(; ht.Q,; w=w,; k=hl.nd.ones(hl.len(w), dtype=hl.tint32),; lam=hl.nd.zeros(hl.len(w)),; mu=0,; sigma=0,; min_accuracy=accuracy,; max_iterations=iterations,; ); ht = ht.select(; 'size',; # for reasons unknown, the R implementation calls this expression the Q statistic (which is; # *not* what they write in the paper); q_stat=ht.Q / 2 / ht.s2,; # The reasoning for taking the complement of the CDF value is:; #; # 1. Q is a measure of variance and thus positive.; #; # 2. We want to know the probability of obtaining a variance even larger (""more extreme""); #; # Ergo, we want to check the right-tail of the distribution.; p_value=1.0 - genchisq_data.value,; fault=genchisq_data.fault,; ); return ht.select_globals('y_residual', 's2', 'n_complete_samples'). [docs]@typecheck(; group=expr_any,; weight=expr_float64,; y=expr_float64,; x=expr_float64,; covariates=sequenceof(expr_float64),; max_size=int,; null_max_iterations=int,; null_tolerance=float,; accuracy=numeric,; iterations=int,; ); def _logistic_skat(; group,; weight,; y,; x,; covariates,; max_size: int = 46340,; null_max_iterations: int = 25,; null_tolerance: float = 1e-6,; accuracy: float = 1e-6,; iterations: int = 10000,; ):; r""""""The logistic sequence kernel association test (SKAT). Logistic SKAT tests if the phenotype, `y`, is significantly associated with the genotype,; `x`. For :math:`N` samples, in a group of :math:`M` variants, with :math:`K` covariates, the; model is given by:. .. math::. \begin{align*}; X &: R^{N \times K} \\; G &: \{0, 1, 2\}^{N \times M} \\; \\; Y &\sim \textrm{Bernoulli}(\textrm{logit}^{-1}(\beta_0 X + \beta_1 G)); \end{align*}. The usual null hypothesis is :math:",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:86565,Availability,fault,fault,86565,"lues,; # presumably because a good estimate of the Generalized Chi-Sqaured CDF is not significantly; # affected by chi-squared components with very tiny weights.; threshold = 1e-5 * eigenvalues.sum() / eigenvalues.shape[0]; w = hl.array(eigenvalues).filter(lambda y: y >= threshold); genchisq_data = hl.pgenchisq(; ht.Q,; w=w,; k=hl.nd.ones(hl.len(w), dtype=hl.tint32),; lam=hl.nd.zeros(hl.len(w)),; mu=0,; sigma=0,; min_accuracy=accuracy,; max_iterations=iterations,; ); ht = ht.select(; 'size',; # for reasons unknown, the R implementation calls this expression the Q statistic (which is; # *not* what they write in the paper); q_stat=ht.Q / 2 / ht.s2,; # The reasoning for taking the complement of the CDF value is:; #; # 1. Q is a measure of variance and thus positive.; #; # 2. We want to know the probability of obtaining a variance even larger (""more extreme""); #; # Ergo, we want to check the right-tail of the distribution.; p_value=1.0 - genchisq_data.value,; fault=genchisq_data.fault,; ); return ht.select_globals('y_residual', 's2', 'n_complete_samples'). [docs]@typecheck(; group=expr_any,; weight=expr_float64,; y=expr_float64,; x=expr_float64,; covariates=sequenceof(expr_float64),; max_size=int,; null_max_iterations=int,; null_tolerance=float,; accuracy=numeric,; iterations=int,; ); def _logistic_skat(; group,; weight,; y,; x,; covariates,; max_size: int = 46340,; null_max_iterations: int = 25,; null_tolerance: float = 1e-6,; accuracy: float = 1e-6,; iterations: int = 10000,; ):; r""""""The logistic sequence kernel association test (SKAT). Logistic SKAT tests if the phenotype, `y`, is significantly associated with the genotype,; `x`. For :math:`N` samples, in a group of :math:`M` variants, with :math:`K` covariates, the; model is given by:. .. math::. \begin{align*}; X &: R^{N \times K} \\; G &: \{0, 1, 2\}^{N \times M} \\; \\; Y &\sim \textrm{Bernoulli}(\textrm{logit}^{-1}(\beta_0 X + \beta_1 G)); \end{align*}. The usual null hypothesis is :math:`\beta_1 = 0`. SKAT tests",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:92010,Availability,fault,fault,92010,"n testing for; sequencing data with the sequence kernel association test.* Am J Hum Genet. 2011 Jul; 15;89(1):82-93. doi: 10.1016/j.ajhg.2011.05.029. Epub 2011 Jul 7. PMID: 21737059; PMCID:; PMC3135811. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3135811/. Examples; --------. Generate a dataset with a phenotype noisily computed from the genotypes:. >>> hl.reset_global_randomness(); >>> mt = hl.balding_nichols_model(1, n_samples=100, n_variants=20); >>> mt = mt.annotate_rows(gene = mt.locus.position // 12); >>> mt = mt.annotate_rows(weight = 1); >>> mt = mt.annotate_cols(phenotype = (hl.agg.sum(mt.GT.n_alt_alleles()) - 20 + hl.rand_norm(0, 1)) > 0.5). Test if the phenotype is significantly associated with the genotype:. >>> skat = hl._logistic_skat(; ... mt.gene,; ... mt.weight,; ... mt.phenotype,; ... mt.GT.n_alt_alleles(),; ... covariates=[1.0]); >>> skat.show(); +-------+-------+----------+----------+-------+; | group | size | q_stat | p_value | fault |; +-------+-------+----------+----------+-------+; | int32 | int64 | float64 | float64 | int32 |; +-------+-------+----------+----------+-------+; | 0 | 11 | 1.78e+02 | 1.68e-04 | 0 |; | 1 | 9 | 1.39e+02 | 1.82e-03 | 0 |; +-------+-------+----------+----------+-------+. The same test, but using the original paper's suggested weights which are derived from the; allele frequency. >>> mt = hl.variant_qc(mt); >>> skat = hl._logistic_skat(; ... mt.gene,; ... hl.dbeta(mt.variant_qc.AF[0], 1, 25),; ... mt.phenotype,; ... mt.GT.n_alt_alleles(),; ... covariates=[1.0]); >>> skat.show(); +-------+-------+----------+----------+-------+; | group | size | q_stat | p_value | fault |; +-------+-------+----------+----------+-------+; | int32 | int64 | float64 | float64 | int32 |; +-------+-------+----------+----------+-------+; | 0 | 11 | 8.04e+00 | 3.50e-01 | 0 |; | 1 | 9 | 1.22e+00 | 5.04e-01 | 0 |; +-------+-------+----------+----------+-------+. Our simulated data was unweighted, so the null hypothesis appears true. In real dat",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:92686,Availability,fault,fault,92686,"otype is significantly associated with the genotype:. >>> skat = hl._logistic_skat(; ... mt.gene,; ... mt.weight,; ... mt.phenotype,; ... mt.GT.n_alt_alleles(),; ... covariates=[1.0]); >>> skat.show(); +-------+-------+----------+----------+-------+; | group | size | q_stat | p_value | fault |; +-------+-------+----------+----------+-------+; | int32 | int64 | float64 | float64 | int32 |; +-------+-------+----------+----------+-------+; | 0 | 11 | 1.78e+02 | 1.68e-04 | 0 |; | 1 | 9 | 1.39e+02 | 1.82e-03 | 0 |; +-------+-------+----------+----------+-------+. The same test, but using the original paper's suggested weights which are derived from the; allele frequency. >>> mt = hl.variant_qc(mt); >>> skat = hl._logistic_skat(; ... mt.gene,; ... hl.dbeta(mt.variant_qc.AF[0], 1, 25),; ... mt.phenotype,; ... mt.GT.n_alt_alleles(),; ... covariates=[1.0]); >>> skat.show(); +-------+-------+----------+----------+-------+; | group | size | q_stat | p_value | fault |; +-------+-------+----------+----------+-------+; | int32 | int64 | float64 | float64 | int32 |; +-------+-------+----------+----------+-------+; | 0 | 11 | 8.04e+00 | 3.50e-01 | 0 |; | 1 | 9 | 1.22e+00 | 5.04e-01 | 0 |; +-------+-------+----------+----------+-------+. Our simulated data was unweighted, so the null hypothesis appears true. In real datasets, we; expect the allele frequency to correlate with effect size. Notice that, in the second group, the fault flag is set to 1. This indicates that the numerical; integration to calculate the p-value failed to achieve the required accuracy (by default,; 1e-6). In this particular case, the null hypothesis is likely true and the numerical integration; returned a (nonsensical) value greater than one. The `max_size` parameter allows us to skip large genes that would cause ""out of memory"" errors:. >>> skat = hl._logistic_skat(; ... mt.gene,; ... mt.weight,; ... mt.phenotype,; ... mt.GT.n_alt_alleles(),; ... covariates=[1.0],; ... max_size=10); >>> skat.show(); +-------",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:93155,Availability,fault,fault,93155,"------+-------+; | 0 | 11 | 1.78e+02 | 1.68e-04 | 0 |; | 1 | 9 | 1.39e+02 | 1.82e-03 | 0 |; +-------+-------+----------+----------+-------+. The same test, but using the original paper's suggested weights which are derived from the; allele frequency. >>> mt = hl.variant_qc(mt); >>> skat = hl._logistic_skat(; ... mt.gene,; ... hl.dbeta(mt.variant_qc.AF[0], 1, 25),; ... mt.phenotype,; ... mt.GT.n_alt_alleles(),; ... covariates=[1.0]); >>> skat.show(); +-------+-------+----------+----------+-------+; | group | size | q_stat | p_value | fault |; +-------+-------+----------+----------+-------+; | int32 | int64 | float64 | float64 | int32 |; +-------+-------+----------+----------+-------+; | 0 | 11 | 8.04e+00 | 3.50e-01 | 0 |; | 1 | 9 | 1.22e+00 | 5.04e-01 | 0 |; +-------+-------+----------+----------+-------+. Our simulated data was unweighted, so the null hypothesis appears true. In real datasets, we; expect the allele frequency to correlate with effect size. Notice that, in the second group, the fault flag is set to 1. This indicates that the numerical; integration to calculate the p-value failed to achieve the required accuracy (by default,; 1e-6). In this particular case, the null hypothesis is likely true and the numerical integration; returned a (nonsensical) value greater than one. The `max_size` parameter allows us to skip large genes that would cause ""out of memory"" errors:. >>> skat = hl._logistic_skat(; ... mt.gene,; ... mt.weight,; ... mt.phenotype,; ... mt.GT.n_alt_alleles(),; ... covariates=[1.0],; ... max_size=10); >>> skat.show(); +-------+-------+----------+----------+-------+; | group | size | q_stat | p_value | fault |; +-------+-------+----------+----------+-------+; | int32 | int64 | float64 | float64 | int32 |; +-------+-------+----------+----------+-------+; | 0 | 11 | NA | NA | NA |; | 1 | 9 | 1.39e+02 | 1.82e-03 | 0 |; +-------+-------+----------+----------+-------+. Notes; -----. In the SKAT R package, the ""weights"" are actually the *square root",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:93540,Availability,error,errors,93540,"F[0], 1, 25),; ... mt.phenotype,; ... mt.GT.n_alt_alleles(),; ... covariates=[1.0]); >>> skat.show(); +-------+-------+----------+----------+-------+; | group | size | q_stat | p_value | fault |; +-------+-------+----------+----------+-------+; | int32 | int64 | float64 | float64 | int32 |; +-------+-------+----------+----------+-------+; | 0 | 11 | 8.04e+00 | 3.50e-01 | 0 |; | 1 | 9 | 1.22e+00 | 5.04e-01 | 0 |; +-------+-------+----------+----------+-------+. Our simulated data was unweighted, so the null hypothesis appears true. In real datasets, we; expect the allele frequency to correlate with effect size. Notice that, in the second group, the fault flag is set to 1. This indicates that the numerical; integration to calculate the p-value failed to achieve the required accuracy (by default,; 1e-6). In this particular case, the null hypothesis is likely true and the numerical integration; returned a (nonsensical) value greater than one. The `max_size` parameter allows us to skip large genes that would cause ""out of memory"" errors:. >>> skat = hl._logistic_skat(; ... mt.gene,; ... mt.weight,; ... mt.phenotype,; ... mt.GT.n_alt_alleles(),; ... covariates=[1.0],; ... max_size=10); >>> skat.show(); +-------+-------+----------+----------+-------+; | group | size | q_stat | p_value | fault |; +-------+-------+----------+----------+-------+; | int32 | int64 | float64 | float64 | int32 |; +-------+-------+----------+----------+-------+; | 0 | 11 | NA | NA | NA |; | 1 | 9 | 1.39e+02 | 1.82e-03 | 0 |; +-------+-------+----------+----------+-------+. Notes; -----. In the SKAT R package, the ""weights"" are actually the *square root* of the weight expression; from the paper. This method uses the definition from the paper. The paper includes an explicit intercept term but this method expects the user to specify the; intercept as an extra covariate with the value 1. This method does not perform small sample size correction. The `q_stat` return value is *not* the :math:`Q` statisti",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:93800,Availability,fault,fault,93800," 8.04e+00 | 3.50e-01 | 0 |; | 1 | 9 | 1.22e+00 | 5.04e-01 | 0 |; +-------+-------+----------+----------+-------+. Our simulated data was unweighted, so the null hypothesis appears true. In real datasets, we; expect the allele frequency to correlate with effect size. Notice that, in the second group, the fault flag is set to 1. This indicates that the numerical; integration to calculate the p-value failed to achieve the required accuracy (by default,; 1e-6). In this particular case, the null hypothesis is likely true and the numerical integration; returned a (nonsensical) value greater than one. The `max_size` parameter allows us to skip large genes that would cause ""out of memory"" errors:. >>> skat = hl._logistic_skat(; ... mt.gene,; ... mt.weight,; ... mt.phenotype,; ... mt.GT.n_alt_alleles(),; ... covariates=[1.0],; ... max_size=10); >>> skat.show(); +-------+-------+----------+----------+-------+; | group | size | q_stat | p_value | fault |; +-------+-------+----------+----------+-------+; | int32 | int64 | float64 | float64 | int32 |; +-------+-------+----------+----------+-------+; | 0 | 11 | NA | NA | NA |; | 1 | 9 | 1.39e+02 | 1.82e-03 | 0 |; +-------+-------+----------+----------+-------+. Notes; -----. In the SKAT R package, the ""weights"" are actually the *square root* of the weight expression; from the paper. This method uses the definition from the paper. The paper includes an explicit intercept term but this method expects the user to specify the; intercept as an extra covariate with the value 1. This method does not perform small sample size correction. The `q_stat` return value is *not* the :math:`Q` statistic from the paper. We match the output; of the SKAT R package which returns :math:`\tilde{Q}`:. .. math::. \tilde{Q} = \frac{Q}{2}. Parameters; ----------; group : :class:`.Expression`; Row-indexed expression indicating to which group a variant belongs. This is typically a gene; name or an interval.; weight : :class:`.Float64Expression`; Row-indexed",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:95669,Availability,error,errors,95669,"ters; ----------; group : :class:`.Expression`; Row-indexed expression indicating to which group a variant belongs. This is typically a gene; name or an interval.; weight : :class:`.Float64Expression`; Row-indexed expression for weights. Must be non-negative.; y : :class:`.Float64Expression`; Column-indexed response (dependent variable) expression.; x : :class:`.Float64Expression`; Entry-indexed expression for input (independent variable).; covariates : :obj:`list` of :class:`.Float64Expression`; List of column-indexed covariate expressions. You must explicitly provide an intercept term; if desired. You must provide at least one covariate.; max_size : :obj:`int`; Maximum size of group on which to run the test. Groups which exceed this size will have a; missing p-value and missing q statistic. Defaults to 46340.; null_max_iterations : :obj:`int`; The maximum number of iterations when fitting the logistic null model. Defaults to 25.; null_tolerance : :obj:`float`; The null model logisitic regression converges when the errors is less than this. Defaults to; 1e-6.; accuracy : :obj:`float`; The accuracy of the p-value if fault value is zero. Defaults to 1e-6.; iterations : :obj:`int`; The maximum number of iterations used to calculate the p-value (which has no closed; form). Defaults to 1e5. Returns; -------; :class:`.Table`; One row per-group. The key is `group`. The row fields are:. - group : the `group` parameter. - size : :obj:`.tint64`, the number of variants in this group. - q_stat : :obj:`.tfloat64`, the :math:`Q` statistic, see Notes for why this differs from the paper. - p_value : :obj:`.tfloat64`, the test p-value for the null hypothesis that the genotypes; have no linear influence on the phenotypes. - fault : :obj:`.tint32`, the fault flag from :func:`.pgenchisq`. The global fields are:. - n_complete_samples : :obj:`.tint32`, the number of samples with neither a missing; phenotype nor a missing covariate. - y_residual : :obj:`.tint32`, the residual phenotype fr",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:95771,Availability,fault,fault,95771," This is typically a gene; name or an interval.; weight : :class:`.Float64Expression`; Row-indexed expression for weights. Must be non-negative.; y : :class:`.Float64Expression`; Column-indexed response (dependent variable) expression.; x : :class:`.Float64Expression`; Entry-indexed expression for input (independent variable).; covariates : :obj:`list` of :class:`.Float64Expression`; List of column-indexed covariate expressions. You must explicitly provide an intercept term; if desired. You must provide at least one covariate.; max_size : :obj:`int`; Maximum size of group on which to run the test. Groups which exceed this size will have a; missing p-value and missing q statistic. Defaults to 46340.; null_max_iterations : :obj:`int`; The maximum number of iterations when fitting the logistic null model. Defaults to 25.; null_tolerance : :obj:`float`; The null model logisitic regression converges when the errors is less than this. Defaults to; 1e-6.; accuracy : :obj:`float`; The accuracy of the p-value if fault value is zero. Defaults to 1e-6.; iterations : :obj:`int`; The maximum number of iterations used to calculate the p-value (which has no closed; form). Defaults to 1e5. Returns; -------; :class:`.Table`; One row per-group. The key is `group`. The row fields are:. - group : the `group` parameter. - size : :obj:`.tint64`, the number of variants in this group. - q_stat : :obj:`.tfloat64`, the :math:`Q` statistic, see Notes for why this differs from the paper. - p_value : :obj:`.tfloat64`, the test p-value for the null hypothesis that the genotypes; have no linear influence on the phenotypes. - fault : :obj:`.tint32`, the fault flag from :func:`.pgenchisq`. The global fields are:. - n_complete_samples : :obj:`.tint32`, the number of samples with neither a missing; phenotype nor a missing covariate. - y_residual : :obj:`.tint32`, the residual phenotype from the null model. This may be; interpreted as the component of the phenotype not explained by the covariates alon",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:96374,Availability,fault,fault,96374,"s size will have a; missing p-value and missing q statistic. Defaults to 46340.; null_max_iterations : :obj:`int`; The maximum number of iterations when fitting the logistic null model. Defaults to 25.; null_tolerance : :obj:`float`; The null model logisitic regression converges when the errors is less than this. Defaults to; 1e-6.; accuracy : :obj:`float`; The accuracy of the p-value if fault value is zero. Defaults to 1e-6.; iterations : :obj:`int`; The maximum number of iterations used to calculate the p-value (which has no closed; form). Defaults to 1e5. Returns; -------; :class:`.Table`; One row per-group. The key is `group`. The row fields are:. - group : the `group` parameter. - size : :obj:`.tint64`, the number of variants in this group. - q_stat : :obj:`.tfloat64`, the :math:`Q` statistic, see Notes for why this differs from the paper. - p_value : :obj:`.tfloat64`, the test p-value for the null hypothesis that the genotypes; have no linear influence on the phenotypes. - fault : :obj:`.tint32`, the fault flag from :func:`.pgenchisq`. The global fields are:. - n_complete_samples : :obj:`.tint32`, the number of samples with neither a missing; phenotype nor a missing covariate. - y_residual : :obj:`.tint32`, the residual phenotype from the null model. This may be; interpreted as the component of the phenotype not explained by the covariates alone. - s2 : :obj:`.tfloat64`, the variance of the residuals, :math:`\sigma^2` in the paper. - null_fit:. - b : :obj:`.tndarray` vector of coefficients. - score : :obj:`.tndarray` vector of score statistics. - fisher : :obj:`.tndarray` matrix of fisher statistics. - mu : :obj:`.tndarray` the expected value under the null model. - n_iterations : :obj:`.tint32` the number of iterations before termination. - log_lkhd : :obj:`.tfloat64` the log-likelihood of the final iteration. - converged : :obj:`.tbool` True if the null model converged. - exploded : :obj:`.tbool` True if the null model failed to converge due to numerical; ex",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:96402,Availability,fault,fault,96402," p-value and missing q statistic. Defaults to 46340.; null_max_iterations : :obj:`int`; The maximum number of iterations when fitting the logistic null model. Defaults to 25.; null_tolerance : :obj:`float`; The null model logisitic regression converges when the errors is less than this. Defaults to; 1e-6.; accuracy : :obj:`float`; The accuracy of the p-value if fault value is zero. Defaults to 1e-6.; iterations : :obj:`int`; The maximum number of iterations used to calculate the p-value (which has no closed; form). Defaults to 1e5. Returns; -------; :class:`.Table`; One row per-group. The key is `group`. The row fields are:. - group : the `group` parameter. - size : :obj:`.tint64`, the number of variants in this group. - q_stat : :obj:`.tfloat64`, the :math:`Q` statistic, see Notes for why this differs from the paper. - p_value : :obj:`.tfloat64`, the test p-value for the null hypothesis that the genotypes; have no linear influence on the phenotypes. - fault : :obj:`.tint32`, the fault flag from :func:`.pgenchisq`. The global fields are:. - n_complete_samples : :obj:`.tint32`, the number of samples with neither a missing; phenotype nor a missing covariate. - y_residual : :obj:`.tint32`, the residual phenotype from the null model. This may be; interpreted as the component of the phenotype not explained by the covariates alone. - s2 : :obj:`.tfloat64`, the variance of the residuals, :math:`\sigma^2` in the paper. - null_fit:. - b : :obj:`.tndarray` vector of coefficients. - score : :obj:`.tndarray` vector of score statistics. - fisher : :obj:`.tndarray` matrix of fisher statistics. - mu : :obj:`.tndarray` the expected value under the null model. - n_iterations : :obj:`.tint32` the number of iterations before termination. - log_lkhd : :obj:`.tfloat64` the log-likelihood of the final iteration. - converged : :obj:`.tbool` True if the null model converged. - exploded : :obj:`.tbool` True if the null model failed to converge due to numerical; explosion. """"""; mt = matrix_ta",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:98435,Availability,toler,tolerance,98435," x); k = len(covariates); if k == 0:; raise ValueError('_logistic_skat: at least one covariate is required.'); _warn_if_no_intercept('_logistic_skat', covariates); mt = mt._select_all(; row_exprs=dict(group=group, weight=weight), col_exprs=dict(y=y, covariates=covariates), entry_exprs=dict(x=x); ); mt = mt.filter_cols(hl.all(hl.is_defined(mt.y), *[hl.is_defined(mt.covariates[i]) for i in range(k)])); if mt.y.dtype != hl.tbool:; mt = mt.annotate_cols(; y=(; hl.case(); .when(hl.any(mt.y == 0, mt.y == 1), hl.bool(mt.y)); .or_error(; hl.format(; f'hl._logistic_skat: phenotypes must either be True, False, 0, or 1, found: %s of type {mt.y.dtype}',; mt.y,; ); ); ); ); yvec, covmat, n = mt.aggregate_cols(; (hl.agg.collect(hl.float(mt.y)), hl.agg.collect(mt.covariates.map(hl.float)), hl.agg.count()), _localize=False; ); mt = mt.annotate_globals(yvec=hl.nd.array(yvec), covmat=hl.nd.array(covmat), n_complete_samples=n); null_fit = logreg_fit(mt.covmat, mt.yvec, None, max_iterations=null_max_iterations, tolerance=null_tolerance); mt = mt.annotate_globals(; null_fit=hl.case(); .when(null_fit.converged, null_fit); .or_error(hl.format('hl._logistic_skat: null model did not converge: %s', null_fit)); ); null_mu = mt.null_fit.mu; y_residual = mt.yvec - null_mu; mt = mt.annotate_globals(y_residual=y_residual, s2=null_mu * (1 - null_mu)); mt = mt.annotate_rows(G_row_mean=hl.agg.mean(mt.x)); mt = mt.annotate_rows(G_row=hl.agg.collect(hl.coalesce(mt.x, mt.G_row_mean))); ht = mt.rows(); ht = ht.filter(hl.all(hl.is_defined(ht.group), hl.is_defined(ht.weight))); ht = ht.group_by('group').aggregate(; weight_take=hl.agg.take(ht.weight, n=max_size + 1),; G_take=hl.agg.take(ht.G_row, n=max_size + 1),; size=hl.agg.count(),; ); ht = ht.annotate(; weight=hl.nd.array(hl.or_missing(hl.len(ht.weight_take) <= max_size, ht.weight_take)),; G=hl.nd.array(hl.or_missing(hl.len(ht.G_take) <= max_size, ht.G_take)).T,; ); ht = ht.annotate(; # Q=ht.y_residual @ (ht.G * ht.weight) @ ht.G.T @ ht.y_residual.T; Q=",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:101146,Availability,fault,fault,101146,"ambda_Approx filters the eigenvalues,; # presumably because a good estimate of the Generalized Chi-Sqaured CDF is not significantly; # affected by chi-squared components with very tiny weights.; threshold = 1e-5 * eigenvalues.sum() / eigenvalues.shape[0]; w = hl.array(eigenvalues).filter(lambda y: y >= threshold); genchisq_data = hl.pgenchisq(; ht.Q,; w=w,; k=hl.nd.ones(hl.len(w), dtype=hl.tint32),; lam=hl.nd.zeros(hl.len(w)),; mu=0,; sigma=0,; min_accuracy=accuracy,; max_iterations=iterations,; ); ht = ht.select(; 'size',; # for reasons unknown, the R implementation calls this expression the Q statistic (which is; # *not* what they write in the paper); q_stat=ht.Q / 2,; # The reasoning for taking the complement of the CDF value is:; #; # 1. Q is a measure of variance and thus positive.; #; # 2. We want to know the probability of obtaining a variance even larger (""more extreme""); #; # Ergo, we want to check the right-tail of the distribution.; p_value=1.0 - genchisq_data.value,; fault=genchisq_data.fault,; ); return ht.select_globals('y_residual', 's2', 'n_complete_samples', 'null_fit'). [docs]@typecheck(; key_expr=expr_any,; weight_expr=expr_float64,; y=expr_float64,; x=expr_float64,; covariates=sequenceof(expr_float64),; logistic=oneof(bool, sized_tupleof(nullable(int), nullable(float))),; max_size=int,; accuracy=numeric,; iterations=int,; ); def skat(; key_expr,; weight_expr,; y,; x,; covariates,; logistic: Union[bool, Tuple[int, float]] = False,; max_size: int = 46340,; accuracy: float = 1e-6,; iterations: int = 10000,; ) -> Table:; r""""""Test each keyed group of rows for association by linear or logistic; SKAT test. Examples; --------. Test each gene for association using the linear sequence kernel association; test:. >>> skat_table = hl.skat(key_expr=burden_ds.gene,; ... weight_expr=burden_ds.weight,; ... y=burden_ds.burden.pheno,; ... x=burden_ds.GT.n_alt_alleles(),; ... covariates=[1, burden_ds.burden.cov1, burden_ds.burden.cov2]). .. caution::. By default, th",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:101166,Availability,fault,fault,101166," eigenvalues,; # presumably because a good estimate of the Generalized Chi-Sqaured CDF is not significantly; # affected by chi-squared components with very tiny weights.; threshold = 1e-5 * eigenvalues.sum() / eigenvalues.shape[0]; w = hl.array(eigenvalues).filter(lambda y: y >= threshold); genchisq_data = hl.pgenchisq(; ht.Q,; w=w,; k=hl.nd.ones(hl.len(w), dtype=hl.tint32),; lam=hl.nd.zeros(hl.len(w)),; mu=0,; sigma=0,; min_accuracy=accuracy,; max_iterations=iterations,; ); ht = ht.select(; 'size',; # for reasons unknown, the R implementation calls this expression the Q statistic (which is; # *not* what they write in the paper); q_stat=ht.Q / 2,; # The reasoning for taking the complement of the CDF value is:; #; # 1. Q is a measure of variance and thus positive.; #; # 2. We want to know the probability of obtaining a variance even larger (""more extreme""); #; # Ergo, we want to check the right-tail of the distribution.; p_value=1.0 - genchisq_data.value,; fault=genchisq_data.fault,; ); return ht.select_globals('y_residual', 's2', 'n_complete_samples', 'null_fit'). [docs]@typecheck(; key_expr=expr_any,; weight_expr=expr_float64,; y=expr_float64,; x=expr_float64,; covariates=sequenceof(expr_float64),; logistic=oneof(bool, sized_tupleof(nullable(int), nullable(float))),; max_size=int,; accuracy=numeric,; iterations=int,; ); def skat(; key_expr,; weight_expr,; y,; x,; covariates,; logistic: Union[bool, Tuple[int, float]] = False,; max_size: int = 46340,; accuracy: float = 1e-6,; iterations: int = 10000,; ) -> Table:; r""""""Test each keyed group of rows for association by linear or logistic; SKAT test. Examples; --------. Test each gene for association using the linear sequence kernel association; test:. >>> skat_table = hl.skat(key_expr=burden_ds.gene,; ... weight_expr=burden_ds.weight,; ... y=burden_ds.burden.pheno,; ... x=burden_ds.GT.n_alt_alleles(),; ... covariates=[1, burden_ds.burden.cov1, burden_ds.burden.cov2]). .. caution::. By default, the Davies algorithm iterat",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:104187,Availability,fault,fault,104187,"icitly** if desired. Notes; -----. This method provides a scalable implementation of the score-based; variance-component test originally described in; `Rare-Variant Association Testing for Sequencing Data with the Sequence Kernel Association Test; <https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3135811/>`__. Row weights must be non-negative. Rows with missing weights are ignored. In; the R package ``skat``---which assumes rows are variants---default weights; are given by evaluating the Beta(1, 25) density at the minor allele; frequency. To replicate these weights in Hail using alternate allele; frequencies stored in a row-indexed field `AF`, one can use the expression:. >>> hl.dbeta(hl.min(ds2.AF), 1.0, 25.0) ** 2. In the logistic case, the response `y` must either be numeric (with all; present values 0 or 1) or Boolean, in which case true and false are coded; as 1 and 0, respectively. The resulting :class:`.Table` provides the group's key (`id`), thenumber of; rows in the group (`size`), the variance component score `q_stat`, the SKAT; `p-value`, and a `fault` flag. For the toy example above, the table has the; form:. +-------+------+--------+---------+-------+; | id | size | q_stat | p_value | fault |; +=======+======+========+=========+=======+; | geneA | 2 | 4.136 | 0.205 | 0 |; +-------+------+--------+---------+-------+; | geneB | 1 | 5.659 | 0.195 | 0 |; +-------+------+--------+---------+-------+; | geneC | 3 | 4.122 | 0.192 | 0 |; +-------+------+--------+---------+-------+. Groups larger than `max_size` appear with missing `q_stat`, `p_value`, and; `fault`. The hard limit on the number of rows in a group is 46340. Note that the variance component score `q_stat` agrees with ``Q`` in the R; package ``skat``, but both differ from :math:`Q` in the paper by the factor; :math:`\frac{1}{2\sigma^2}` in the linear case and :math:`\frac{1}{2}` in; the logistic case, where :math:`\sigma^2` is the unbiased estimator of; residual variance for the linear null model. The R ",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:104331,Availability,fault,fault,104331,"h the Sequence Kernel Association Test; <https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3135811/>`__. Row weights must be non-negative. Rows with missing weights are ignored. In; the R package ``skat``---which assumes rows are variants---default weights; are given by evaluating the Beta(1, 25) density at the minor allele; frequency. To replicate these weights in Hail using alternate allele; frequencies stored in a row-indexed field `AF`, one can use the expression:. >>> hl.dbeta(hl.min(ds2.AF), 1.0, 25.0) ** 2. In the logistic case, the response `y` must either be numeric (with all; present values 0 or 1) or Boolean, in which case true and false are coded; as 1 and 0, respectively. The resulting :class:`.Table` provides the group's key (`id`), thenumber of; rows in the group (`size`), the variance component score `q_stat`, the SKAT; `p-value`, and a `fault` flag. For the toy example above, the table has the; form:. +-------+------+--------+---------+-------+; | id | size | q_stat | p_value | fault |; +=======+======+========+=========+=======+; | geneA | 2 | 4.136 | 0.205 | 0 |; +-------+------+--------+---------+-------+; | geneB | 1 | 5.659 | 0.195 | 0 |; +-------+------+--------+---------+-------+; | geneC | 3 | 4.122 | 0.192 | 0 |; +-------+------+--------+---------+-------+. Groups larger than `max_size` appear with missing `q_stat`, `p_value`, and; `fault`. The hard limit on the number of rows in a group is 46340. Note that the variance component score `q_stat` agrees with ``Q`` in the R; package ``skat``, but both differ from :math:`Q` in the paper by the factor; :math:`\frac{1}{2\sigma^2}` in the linear case and :math:`\frac{1}{2}` in; the logistic case, where :math:`\sigma^2` is the unbiased estimator of; residual variance for the linear null model. The R package also applies a; ""small-sample adjustment"" to the null distribution in the logistic case; when the sample size is less than 2000. Hail does not apply this; adjustment. The fault flag is an integer indi",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:104702,Availability,fault,fault,104702,"icate these weights in Hail using alternate allele; frequencies stored in a row-indexed field `AF`, one can use the expression:. >>> hl.dbeta(hl.min(ds2.AF), 1.0, 25.0) ** 2. In the logistic case, the response `y` must either be numeric (with all; present values 0 or 1) or Boolean, in which case true and false are coded; as 1 and 0, respectively. The resulting :class:`.Table` provides the group's key (`id`), thenumber of; rows in the group (`size`), the variance component score `q_stat`, the SKAT; `p-value`, and a `fault` flag. For the toy example above, the table has the; form:. +-------+------+--------+---------+-------+; | id | size | q_stat | p_value | fault |; +=======+======+========+=========+=======+; | geneA | 2 | 4.136 | 0.205 | 0 |; +-------+------+--------+---------+-------+; | geneB | 1 | 5.659 | 0.195 | 0 |; +-------+------+--------+---------+-------+; | geneC | 3 | 4.122 | 0.192 | 0 |; +-------+------+--------+---------+-------+. Groups larger than `max_size` appear with missing `q_stat`, `p_value`, and; `fault`. The hard limit on the number of rows in a group is 46340. Note that the variance component score `q_stat` agrees with ``Q`` in the R; package ``skat``, but both differ from :math:`Q` in the paper by the factor; :math:`\frac{1}{2\sigma^2}` in the linear case and :math:`\frac{1}{2}` in; the logistic case, where :math:`\sigma^2` is the unbiased estimator of; residual variance for the linear null model. The R package also applies a; ""small-sample adjustment"" to the null distribution in the logistic case; when the sample size is less than 2000. Hail does not apply this; adjustment. The fault flag is an integer indicating whether any issues occurred when; running the Davies algorithm to compute the p-value as the right tail of a; weighted sum of :math:`\chi^2(1)` distributions. +-------------+-----------------------------------------+; | fault value | Description |; +=============+=========================================+; | 0 | no issues |; +-----",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:105298,Availability,fault,fault,105298," | 2 | 4.136 | 0.205 | 0 |; +-------+------+--------+---------+-------+; | geneB | 1 | 5.659 | 0.195 | 0 |; +-------+------+--------+---------+-------+; | geneC | 3 | 4.122 | 0.192 | 0 |; +-------+------+--------+---------+-------+. Groups larger than `max_size` appear with missing `q_stat`, `p_value`, and; `fault`. The hard limit on the number of rows in a group is 46340. Note that the variance component score `q_stat` agrees with ``Q`` in the R; package ``skat``, but both differ from :math:`Q` in the paper by the factor; :math:`\frac{1}{2\sigma^2}` in the linear case and :math:`\frac{1}{2}` in; the logistic case, where :math:`\sigma^2` is the unbiased estimator of; residual variance for the linear null model. The R package also applies a; ""small-sample adjustment"" to the null distribution in the logistic case; when the sample size is less than 2000. Hail does not apply this; adjustment. The fault flag is an integer indicating whether any issues occurred when; running the Davies algorithm to compute the p-value as the right tail of a; weighted sum of :math:`\chi^2(1)` distributions. +-------------+-----------------------------------------+; | fault value | Description |; +=============+=========================================+; | 0 | no issues |; +------+------+-----------------------------------------+; | 1 | accuracy NOT achieved |; +------+------+-----------------------------------------+; | 2 | round-off error possibly significant |; +------+------+-----------------------------------------+; | 3 | invalid parameters |; +------+------+-----------------------------------------+; | 4 | unable to locate integration parameters |; +------+------+-----------------------------------------+; | 5 | out of memory |; +------+------+-----------------------------------------+. Parameters; ----------; key_expr : :class:`.Expression`; Row-indexed expression for key associated to each row.; weight_expr : :class:`.Float64Expression`; Row-indexed expression for row weights.; y : ",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:105554,Availability,fault,fault,105554,"R; package ``skat``, but both differ from :math:`Q` in the paper by the factor; :math:`\frac{1}{2\sigma^2}` in the linear case and :math:`\frac{1}{2}` in; the logistic case, where :math:`\sigma^2` is the unbiased estimator of; residual variance for the linear null model. The R package also applies a; ""small-sample adjustment"" to the null distribution in the logistic case; when the sample size is less than 2000. Hail does not apply this; adjustment. The fault flag is an integer indicating whether any issues occurred when; running the Davies algorithm to compute the p-value as the right tail of a; weighted sum of :math:`\chi^2(1)` distributions. +-------------+-----------------------------------------+; | fault value | Description |; +=============+=========================================+; | 0 | no issues |; +------+------+-----------------------------------------+; | 1 | accuracy NOT achieved |; +------+------+-----------------------------------------+; | 2 | round-off error possibly significant |; +------+------+-----------------------------------------+; | 3 | invalid parameters |; +------+------+-----------------------------------------+; | 4 | unable to locate integration parameters |; +------+------+-----------------------------------------+; | 5 | out of memory |; +------+------+-----------------------------------------+. Parameters; ----------; key_expr : :class:`.Expression`; Row-indexed expression for key associated to each row.; weight_expr : :class:`.Float64Expression`; Row-indexed expression for row weights.; y : :class:`.Float64Expression`; Column-indexed response expression.; If `logistic` is ``True``, all non-missing values must evaluate to 0 or; 1. Note that a :class:`.BooleanExpression` will be implicitly converted; to a :class:`.Float64Expression` with this property.; x : :class:`.Float64Expression`; Entry-indexed expression for input variable.; covariates : :obj:`list` of :class:`.Float64Expression`; List of column-indexed covariate expressions.; ",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:105826,Availability,error,error,105826,"R; package ``skat``, but both differ from :math:`Q` in the paper by the factor; :math:`\frac{1}{2\sigma^2}` in the linear case and :math:`\frac{1}{2}` in; the logistic case, where :math:`\sigma^2` is the unbiased estimator of; residual variance for the linear null model. The R package also applies a; ""small-sample adjustment"" to the null distribution in the logistic case; when the sample size is less than 2000. Hail does not apply this; adjustment. The fault flag is an integer indicating whether any issues occurred when; running the Davies algorithm to compute the p-value as the right tail of a; weighted sum of :math:`\chi^2(1)` distributions. +-------------+-----------------------------------------+; | fault value | Description |; +=============+=========================================+; | 0 | no issues |; +------+------+-----------------------------------------+; | 1 | accuracy NOT achieved |; +------+------+-----------------------------------------+; | 2 | round-off error possibly significant |; +------+------+-----------------------------------------+; | 3 | invalid parameters |; +------+------+-----------------------------------------+; | 4 | unable to locate integration parameters |; +------+------+-----------------------------------------+; | 5 | out of memory |; +------+------+-----------------------------------------+. Parameters; ----------; key_expr : :class:`.Expression`; Row-indexed expression for key associated to each row.; weight_expr : :class:`.Float64Expression`; Row-indexed expression for row weights.; y : :class:`.Float64Expression`; Column-indexed response expression.; If `logistic` is ``True``, all non-missing values must evaluate to 0 or; 1. Note that a :class:`.BooleanExpression` will be implicitly converted; to a :class:`.Float64Expression` with this property.; x : :class:`.Float64Expression`; Entry-indexed expression for input variable.; covariates : :obj:`list` of :class:`.Float64Expression`; List of column-indexed covariate expressions.; ",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:107035,Availability,toler,tolerance,107035,"-+; | 4 | unable to locate integration parameters |; +------+------+-----------------------------------------+; | 5 | out of memory |; +------+------+-----------------------------------------+. Parameters; ----------; key_expr : :class:`.Expression`; Row-indexed expression for key associated to each row.; weight_expr : :class:`.Float64Expression`; Row-indexed expression for row weights.; y : :class:`.Float64Expression`; Column-indexed response expression.; If `logistic` is ``True``, all non-missing values must evaluate to 0 or; 1. Note that a :class:`.BooleanExpression` will be implicitly converted; to a :class:`.Float64Expression` with this property.; x : :class:`.Float64Expression`; Entry-indexed expression for input variable.; covariates : :obj:`list` of :class:`.Float64Expression`; List of column-indexed covariate expressions.; logistic : :obj:`bool` or :obj:`tuple` of :obj:`int` and :obj:`float`; If false, use the linear test. If true, use the logistic test with no; more than 25 logistic iterations and a convergence tolerance of 1e-6. If; a tuple is given, use the logistic test with the tuple elements as the; maximum nubmer of iterations and convergence tolerance, respectively.; max_size : :obj:`int`; Maximum size of group on which to run the test.; accuracy : :obj:`float`; Accuracy achieved by the Davies algorithm if fault value is zero.; iterations : :obj:`int`; Maximum number of iterations attempted by the Davies algorithm. Returns; -------; :class:`.Table`; Table of SKAT results. """"""; if hl.current_backend().requires_lowering:; if logistic:; kwargs = {'accuracy': accuracy, 'iterations': iterations}; if logistic is not True:; null_max_iterations, null_tolerance = logistic; kwargs['null_max_iterations'] = null_max_iterations; kwargs['null_tolerance'] = null_tolerance; ht = hl._logistic_skat(key_expr, weight_expr, y, x, covariates, max_size, **kwargs); else:; ht = hl._linear_skat(key_expr, weight_expr, y, x, covariates, max_size, accuracy, iterations); ht = ht",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:107175,Availability,toler,tolerance,107175,"ory |; +------+------+-----------------------------------------+. Parameters; ----------; key_expr : :class:`.Expression`; Row-indexed expression for key associated to each row.; weight_expr : :class:`.Float64Expression`; Row-indexed expression for row weights.; y : :class:`.Float64Expression`; Column-indexed response expression.; If `logistic` is ``True``, all non-missing values must evaluate to 0 or; 1. Note that a :class:`.BooleanExpression` will be implicitly converted; to a :class:`.Float64Expression` with this property.; x : :class:`.Float64Expression`; Entry-indexed expression for input variable.; covariates : :obj:`list` of :class:`.Float64Expression`; List of column-indexed covariate expressions.; logistic : :obj:`bool` or :obj:`tuple` of :obj:`int` and :obj:`float`; If false, use the linear test. If true, use the logistic test with no; more than 25 logistic iterations and a convergence tolerance of 1e-6. If; a tuple is given, use the logistic test with the tuple elements as the; maximum nubmer of iterations and convergence tolerance, respectively.; max_size : :obj:`int`; Maximum size of group on which to run the test.; accuracy : :obj:`float`; Accuracy achieved by the Davies algorithm if fault value is zero.; iterations : :obj:`int`; Maximum number of iterations attempted by the Davies algorithm. Returns; -------; :class:`.Table`; Table of SKAT results. """"""; if hl.current_backend().requires_lowering:; if logistic:; kwargs = {'accuracy': accuracy, 'iterations': iterations}; if logistic is not True:; null_max_iterations, null_tolerance = logistic; kwargs['null_max_iterations'] = null_max_iterations; kwargs['null_tolerance'] = null_tolerance; ht = hl._logistic_skat(key_expr, weight_expr, y, x, covariates, max_size, **kwargs); else:; ht = hl._linear_skat(key_expr, weight_expr, y, x, covariates, max_size, accuracy, iterations); ht = ht.select_globals(); return ht; mt = matrix_table_source('skat/x', x); raise_unless_entry_indexed('skat/x', x). analyze('skat/key_",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:107343,Availability,fault,fault,107343,": :class:`.Float64Expression`; Row-indexed expression for row weights.; y : :class:`.Float64Expression`; Column-indexed response expression.; If `logistic` is ``True``, all non-missing values must evaluate to 0 or; 1. Note that a :class:`.BooleanExpression` will be implicitly converted; to a :class:`.Float64Expression` with this property.; x : :class:`.Float64Expression`; Entry-indexed expression for input variable.; covariates : :obj:`list` of :class:`.Float64Expression`; List of column-indexed covariate expressions.; logistic : :obj:`bool` or :obj:`tuple` of :obj:`int` and :obj:`float`; If false, use the linear test. If true, use the logistic test with no; more than 25 logistic iterations and a convergence tolerance of 1e-6. If; a tuple is given, use the logistic test with the tuple elements as the; maximum nubmer of iterations and convergence tolerance, respectively.; max_size : :obj:`int`; Maximum size of group on which to run the test.; accuracy : :obj:`float`; Accuracy achieved by the Davies algorithm if fault value is zero.; iterations : :obj:`int`; Maximum number of iterations attempted by the Davies algorithm. Returns; -------; :class:`.Table`; Table of SKAT results. """"""; if hl.current_backend().requires_lowering:; if logistic:; kwargs = {'accuracy': accuracy, 'iterations': iterations}; if logistic is not True:; null_max_iterations, null_tolerance = logistic; kwargs['null_max_iterations'] = null_max_iterations; kwargs['null_tolerance'] = null_tolerance; ht = hl._logistic_skat(key_expr, weight_expr, y, x, covariates, max_size, **kwargs); else:; ht = hl._linear_skat(key_expr, weight_expr, y, x, covariates, max_size, accuracy, iterations); ht = ht.select_globals(); return ht; mt = matrix_table_source('skat/x', x); raise_unless_entry_indexed('skat/x', x). analyze('skat/key_expr', key_expr, mt._row_indices); analyze('skat/weight_expr', weight_expr, mt._row_indices); analyze('skat/y', y, mt._col_indices). all_exprs = [key_expr, weight_expr, y]; for e in covariate",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:109064,Availability,toler,tolerance,109064,"ntry_indexed('skat/x', x). analyze('skat/key_expr', key_expr, mt._row_indices); analyze('skat/weight_expr', weight_expr, mt._row_indices); analyze('skat/y', y, mt._col_indices). all_exprs = [key_expr, weight_expr, y]; for e in covariates:; all_exprs.append(e); analyze('skat/covariates', e, mt._col_indices). _warn_if_no_intercept('skat', covariates). # FIXME: remove this logic when annotation is better optimized; if x in mt._fields_inverse:; x_field_name = mt._fields_inverse[x]; entry_expr = {}; else:; x_field_name = Env.get_uid(); entry_expr = {x_field_name: x}. y_field_name = '__y'; weight_field_name = '__weight'; key_field_name = '__key'; cov_field_names = list(f'__cov{i}' for i in range(len(covariates))). mt = mt._select_all(; col_exprs=dict(**{y_field_name: y}, **dict(zip(cov_field_names, covariates))),; row_exprs={weight_field_name: weight_expr, key_field_name: key_expr},; entry_exprs=entry_expr,; ). if logistic is True:; use_logistic = True; max_iterations = 25; tolerance = 1e-6; elif logistic is False:; use_logistic = False; max_iterations = 0; tolerance = 0.0; else:; assert isinstance(logistic, tuple) and len(logistic) == 2; use_logistic = True; max_iterations, tolerance = logistic. config = {; 'name': 'Skat',; 'keyField': key_field_name,; 'weightField': weight_field_name,; 'xField': x_field_name,; 'yField': y_field_name,; 'covFields': cov_field_names,; 'logistic': use_logistic,; 'maxSize': max_size,; 'accuracy': accuracy,; 'iterations': iterations,; 'logistic_max_iterations': max_iterations,; 'logistic_tolerance': tolerance,; }. return Table(ir.MatrixToTableApply(mt._mir, config)).persist(). [docs]@typecheck(p_value=expr_numeric, approximate=bool); def lambda_gc(p_value, approximate=True):; """"""; Compute genomic inflation factor (lambda GC) from an Expression of p-values. .. include:: ../_templates/experimental.rst. Parameters; ----------; p_value : :class:`.NumericExpression`; Row-indexed numeric expression of p-values.; approximate : :obj:`bool`; If False,",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:109149,Availability,toler,tolerance,109149,"ntry_indexed('skat/x', x). analyze('skat/key_expr', key_expr, mt._row_indices); analyze('skat/weight_expr', weight_expr, mt._row_indices); analyze('skat/y', y, mt._col_indices). all_exprs = [key_expr, weight_expr, y]; for e in covariates:; all_exprs.append(e); analyze('skat/covariates', e, mt._col_indices). _warn_if_no_intercept('skat', covariates). # FIXME: remove this logic when annotation is better optimized; if x in mt._fields_inverse:; x_field_name = mt._fields_inverse[x]; entry_expr = {}; else:; x_field_name = Env.get_uid(); entry_expr = {x_field_name: x}. y_field_name = '__y'; weight_field_name = '__weight'; key_field_name = '__key'; cov_field_names = list(f'__cov{i}' for i in range(len(covariates))). mt = mt._select_all(; col_exprs=dict(**{y_field_name: y}, **dict(zip(cov_field_names, covariates))),; row_exprs={weight_field_name: weight_expr, key_field_name: key_expr},; entry_exprs=entry_expr,; ). if logistic is True:; use_logistic = True; max_iterations = 25; tolerance = 1e-6; elif logistic is False:; use_logistic = False; max_iterations = 0; tolerance = 0.0; else:; assert isinstance(logistic, tuple) and len(logistic) == 2; use_logistic = True; max_iterations, tolerance = logistic. config = {; 'name': 'Skat',; 'keyField': key_field_name,; 'weightField': weight_field_name,; 'xField': x_field_name,; 'yField': y_field_name,; 'covFields': cov_field_names,; 'logistic': use_logistic,; 'maxSize': max_size,; 'accuracy': accuracy,; 'iterations': iterations,; 'logistic_max_iterations': max_iterations,; 'logistic_tolerance': tolerance,; }. return Table(ir.MatrixToTableApply(mt._mir, config)).persist(). [docs]@typecheck(p_value=expr_numeric, approximate=bool); def lambda_gc(p_value, approximate=True):; """"""; Compute genomic inflation factor (lambda GC) from an Expression of p-values. .. include:: ../_templates/experimental.rst. Parameters; ----------; p_value : :class:`.NumericExpression`; Row-indexed numeric expression of p-values.; approximate : :obj:`bool`; If False,",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:109269,Availability,toler,tolerance,109269,"e('skat/y', y, mt._col_indices). all_exprs = [key_expr, weight_expr, y]; for e in covariates:; all_exprs.append(e); analyze('skat/covariates', e, mt._col_indices). _warn_if_no_intercept('skat', covariates). # FIXME: remove this logic when annotation is better optimized; if x in mt._fields_inverse:; x_field_name = mt._fields_inverse[x]; entry_expr = {}; else:; x_field_name = Env.get_uid(); entry_expr = {x_field_name: x}. y_field_name = '__y'; weight_field_name = '__weight'; key_field_name = '__key'; cov_field_names = list(f'__cov{i}' for i in range(len(covariates))). mt = mt._select_all(; col_exprs=dict(**{y_field_name: y}, **dict(zip(cov_field_names, covariates))),; row_exprs={weight_field_name: weight_expr, key_field_name: key_expr},; entry_exprs=entry_expr,; ). if logistic is True:; use_logistic = True; max_iterations = 25; tolerance = 1e-6; elif logistic is False:; use_logistic = False; max_iterations = 0; tolerance = 0.0; else:; assert isinstance(logistic, tuple) and len(logistic) == 2; use_logistic = True; max_iterations, tolerance = logistic. config = {; 'name': 'Skat',; 'keyField': key_field_name,; 'weightField': weight_field_name,; 'xField': x_field_name,; 'yField': y_field_name,; 'covFields': cov_field_names,; 'logistic': use_logistic,; 'maxSize': max_size,; 'accuracy': accuracy,; 'iterations': iterations,; 'logistic_max_iterations': max_iterations,; 'logistic_tolerance': tolerance,; }. return Table(ir.MatrixToTableApply(mt._mir, config)).persist(). [docs]@typecheck(p_value=expr_numeric, approximate=bool); def lambda_gc(p_value, approximate=True):; """"""; Compute genomic inflation factor (lambda GC) from an Expression of p-values. .. include:: ../_templates/experimental.rst. Parameters; ----------; p_value : :class:`.NumericExpression`; Row-indexed numeric expression of p-values.; approximate : :obj:`bool`; If False, computes exact lambda GC (slower and uses more memory). Returns; -------; :obj:`float`; Genomic inflation factor (lambda genomic control).; """"""; ",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:109630,Availability,toler,tolerance,109630,"notation is better optimized; if x in mt._fields_inverse:; x_field_name = mt._fields_inverse[x]; entry_expr = {}; else:; x_field_name = Env.get_uid(); entry_expr = {x_field_name: x}. y_field_name = '__y'; weight_field_name = '__weight'; key_field_name = '__key'; cov_field_names = list(f'__cov{i}' for i in range(len(covariates))). mt = mt._select_all(; col_exprs=dict(**{y_field_name: y}, **dict(zip(cov_field_names, covariates))),; row_exprs={weight_field_name: weight_expr, key_field_name: key_expr},; entry_exprs=entry_expr,; ). if logistic is True:; use_logistic = True; max_iterations = 25; tolerance = 1e-6; elif logistic is False:; use_logistic = False; max_iterations = 0; tolerance = 0.0; else:; assert isinstance(logistic, tuple) and len(logistic) == 2; use_logistic = True; max_iterations, tolerance = logistic. config = {; 'name': 'Skat',; 'keyField': key_field_name,; 'weightField': weight_field_name,; 'xField': x_field_name,; 'yField': y_field_name,; 'covFields': cov_field_names,; 'logistic': use_logistic,; 'maxSize': max_size,; 'accuracy': accuracy,; 'iterations': iterations,; 'logistic_max_iterations': max_iterations,; 'logistic_tolerance': tolerance,; }. return Table(ir.MatrixToTableApply(mt._mir, config)).persist(). [docs]@typecheck(p_value=expr_numeric, approximate=bool); def lambda_gc(p_value, approximate=True):; """"""; Compute genomic inflation factor (lambda GC) from an Expression of p-values. .. include:: ../_templates/experimental.rst. Parameters; ----------; p_value : :class:`.NumericExpression`; Row-indexed numeric expression of p-values.; approximate : :obj:`bool`; If False, computes exact lambda GC (slower and uses more memory). Returns; -------; :obj:`float`; Genomic inflation factor (lambda genomic control).; """"""; raise_unless_row_indexed('lambda_gc', p_value); t = table_source('lambda_gc', p_value); med_chisq = _lambda_gc_agg(p_value, approximate); return t.aggregate(med_chisq). @typecheck(p_value=expr_numeric, approximate=bool); def _lambda_gc_agg(",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:112309,Availability,error,errors,112309,"`.MatrixTable.select_entries`, :meth:`.MatrixTable.transmute_entries`. The resulting dataset will be keyed by the split locus and alleles. :func:`.split_multi` adds the following fields:. - `was_split` (*bool*) -- ``True`` if this variant was originally; multiallelic, otherwise ``False``. - `a_index` (*int*) -- The original index of this alternate allele in the; multiallelic representation (NB: 1 is the first alternate allele or the; only alternate allele in a biallelic variant). For example, 1:100:A:T,C; splits into two variants: 1:100:A:T with ``a_index = 1`` and 1:100:A:C; with ``a_index = 2``. - `old_locus` (*locus*) -- The original, unsplit locus. - `old_alleles` (*array<str>*) -- The original, unsplit alleles. All other fields are left unchanged. Warning; -------; This method assumes `ds` contains at most one non-split variant per locus. This assumption permits the; most efficient implementation of the splitting algorithm. If your queries involving `split_multi`; crash with errors about out-of-order keys, this assumption may be violated. Otherwise, this; warning likely does not apply to your dataset. If each locus in `ds` contains one multiallelic variant and one or more biallelic variants, you; can filter to the multiallelic variants, split those, and then combine the split variants with; the original biallelic variants. For example, the following code splits a dataset `mt` which contains a mixture of split and; non-split variants. >>> bi = mt.filter_rows(hl.len(mt.alleles) == 2); >>> bi = bi.annotate_rows(a_index=1, was_split=False, old_locus=bi.locus, old_alleles=bi.alleles); >>> multi = mt.filter_rows(hl.len(mt.alleles) > 2); >>> split = hl.split_multi(multi); >>> mt = split.union_rows(bi). Example; -------. :func:`.split_multi_hts`, which splits multiallelic variants for the HTS; genotype schema and updates the entry fields by downcoding the genotype, is; implemented as:. >>> sm = hl.split_multi(ds); >>> pl = hl.or_missing(; ... hl.is_defined(sm.PL),; ... ",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:113184,Availability,down,downcoding,113184,"t variant per locus. This assumption permits the; most efficient implementation of the splitting algorithm. If your queries involving `split_multi`; crash with errors about out-of-order keys, this assumption may be violated. Otherwise, this; warning likely does not apply to your dataset. If each locus in `ds` contains one multiallelic variant and one or more biallelic variants, you; can filter to the multiallelic variants, split those, and then combine the split variants with; the original biallelic variants. For example, the following code splits a dataset `mt` which contains a mixture of split and; non-split variants. >>> bi = mt.filter_rows(hl.len(mt.alleles) == 2); >>> bi = bi.annotate_rows(a_index=1, was_split=False, old_locus=bi.locus, old_alleles=bi.alleles); >>> multi = mt.filter_rows(hl.len(mt.alleles) > 2); >>> split = hl.split_multi(multi); >>> mt = split.union_rows(bi). Example; -------. :func:`.split_multi_hts`, which splits multiallelic variants for the HTS; genotype schema and updates the entry fields by downcoding the genotype, is; implemented as:. >>> sm = hl.split_multi(ds); >>> pl = hl.or_missing(; ... hl.is_defined(sm.PL),; ... (hl.range(0, 3).map(lambda i: hl.min(hl.range(0, hl.len(sm.PL)); ... .filter(lambda j: hl.downcode(hl.unphased_diploid_gt_index_call(j), sm.a_index) == hl.unphased_diploid_gt_index_call(i)); ... .map(lambda j: sm.PL[j]))))); >>> split_ds = sm.annotate_entries(; ... GT=hl.downcode(sm.GT, sm.a_index),; ... AD=hl.or_missing(hl.is_defined(sm.AD),; ... [hl.sum(sm.AD) - sm.AD[sm.a_index], sm.AD[sm.a_index]]),; ... DP=sm.DP,; ... PL=pl,; ... GQ=hl.gq_from_pl(pl)).drop('old_locus', 'old_alleles'). See Also; --------; :func:`.split_multi_hts`. Parameters; ----------; ds : :class:`.MatrixTable` or :class:`.Table`; An unsplit dataset.; keep_star : :obj:`bool`; Do not filter out * alleles.; left_aligned : :obj:`bool`; If ``True``, variants are assumed to be left aligned and have unique; loci. This avoids a shuffle. If the assumption is",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:113405,Availability,down,downcode,113405,"not apply to your dataset. If each locus in `ds` contains one multiallelic variant and one or more biallelic variants, you; can filter to the multiallelic variants, split those, and then combine the split variants with; the original biallelic variants. For example, the following code splits a dataset `mt` which contains a mixture of split and; non-split variants. >>> bi = mt.filter_rows(hl.len(mt.alleles) == 2); >>> bi = bi.annotate_rows(a_index=1, was_split=False, old_locus=bi.locus, old_alleles=bi.alleles); >>> multi = mt.filter_rows(hl.len(mt.alleles) > 2); >>> split = hl.split_multi(multi); >>> mt = split.union_rows(bi). Example; -------. :func:`.split_multi_hts`, which splits multiallelic variants for the HTS; genotype schema and updates the entry fields by downcoding the genotype, is; implemented as:. >>> sm = hl.split_multi(ds); >>> pl = hl.or_missing(; ... hl.is_defined(sm.PL),; ... (hl.range(0, 3).map(lambda i: hl.min(hl.range(0, hl.len(sm.PL)); ... .filter(lambda j: hl.downcode(hl.unphased_diploid_gt_index_call(j), sm.a_index) == hl.unphased_diploid_gt_index_call(i)); ... .map(lambda j: sm.PL[j]))))); >>> split_ds = sm.annotate_entries(; ... GT=hl.downcode(sm.GT, sm.a_index),; ... AD=hl.or_missing(hl.is_defined(sm.AD),; ... [hl.sum(sm.AD) - sm.AD[sm.a_index], sm.AD[sm.a_index]]),; ... DP=sm.DP,; ... PL=pl,; ... GQ=hl.gq_from_pl(pl)).drop('old_locus', 'old_alleles'). See Also; --------; :func:`.split_multi_hts`. Parameters; ----------; ds : :class:`.MatrixTable` or :class:`.Table`; An unsplit dataset.; keep_star : :obj:`bool`; Do not filter out * alleles.; left_aligned : :obj:`bool`; If ``True``, variants are assumed to be left aligned and have unique; loci. This avoids a shuffle. If the assumption is violated, an error; is generated.; permit_shuffle : :obj:`bool`; If ``True``, permit a data shuffle to sort out-of-order split results.; This will only be required if input data has duplicate loci, one of; which contains more than one alternate allele. Returns",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:113587,Availability,down,downcode,113587,"then combine the split variants with; the original biallelic variants. For example, the following code splits a dataset `mt` which contains a mixture of split and; non-split variants. >>> bi = mt.filter_rows(hl.len(mt.alleles) == 2); >>> bi = bi.annotate_rows(a_index=1, was_split=False, old_locus=bi.locus, old_alleles=bi.alleles); >>> multi = mt.filter_rows(hl.len(mt.alleles) > 2); >>> split = hl.split_multi(multi); >>> mt = split.union_rows(bi). Example; -------. :func:`.split_multi_hts`, which splits multiallelic variants for the HTS; genotype schema and updates the entry fields by downcoding the genotype, is; implemented as:. >>> sm = hl.split_multi(ds); >>> pl = hl.or_missing(; ... hl.is_defined(sm.PL),; ... (hl.range(0, 3).map(lambda i: hl.min(hl.range(0, hl.len(sm.PL)); ... .filter(lambda j: hl.downcode(hl.unphased_diploid_gt_index_call(j), sm.a_index) == hl.unphased_diploid_gt_index_call(i)); ... .map(lambda j: sm.PL[j]))))); >>> split_ds = sm.annotate_entries(; ... GT=hl.downcode(sm.GT, sm.a_index),; ... AD=hl.or_missing(hl.is_defined(sm.AD),; ... [hl.sum(sm.AD) - sm.AD[sm.a_index], sm.AD[sm.a_index]]),; ... DP=sm.DP,; ... PL=pl,; ... GQ=hl.gq_from_pl(pl)).drop('old_locus', 'old_alleles'). See Also; --------; :func:`.split_multi_hts`. Parameters; ----------; ds : :class:`.MatrixTable` or :class:`.Table`; An unsplit dataset.; keep_star : :obj:`bool`; Do not filter out * alleles.; left_aligned : :obj:`bool`; If ``True``, variants are assumed to be left aligned and have unique; loci. This avoids a shuffle. If the assumption is violated, an error; is generated.; permit_shuffle : :obj:`bool`; If ``True``, permit a data shuffle to sort out-of-order split results.; This will only be required if input data has duplicate loci, one of; which contains more than one alternate allele. Returns; -------; :class:`.MatrixTable` or :class:`.Table`; """""". require_row_key_variant(ds, ""split_multi""); new_id = Env.get_uid(); is_table = isinstance(ds, Table). old_row = ds.row if is",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:114164,Availability,error,error,114164,"updates the entry fields by downcoding the genotype, is; implemented as:. >>> sm = hl.split_multi(ds); >>> pl = hl.or_missing(; ... hl.is_defined(sm.PL),; ... (hl.range(0, 3).map(lambda i: hl.min(hl.range(0, hl.len(sm.PL)); ... .filter(lambda j: hl.downcode(hl.unphased_diploid_gt_index_call(j), sm.a_index) == hl.unphased_diploid_gt_index_call(i)); ... .map(lambda j: sm.PL[j]))))); >>> split_ds = sm.annotate_entries(; ... GT=hl.downcode(sm.GT, sm.a_index),; ... AD=hl.or_missing(hl.is_defined(sm.AD),; ... [hl.sum(sm.AD) - sm.AD[sm.a_index], sm.AD[sm.a_index]]),; ... DP=sm.DP,; ... PL=pl,; ... GQ=hl.gq_from_pl(pl)).drop('old_locus', 'old_alleles'). See Also; --------; :func:`.split_multi_hts`. Parameters; ----------; ds : :class:`.MatrixTable` or :class:`.Table`; An unsplit dataset.; keep_star : :obj:`bool`; Do not filter out * alleles.; left_aligned : :obj:`bool`; If ``True``, variants are assumed to be left aligned and have unique; loci. This avoids a shuffle. If the assumption is violated, an error; is generated.; permit_shuffle : :obj:`bool`; If ``True``, permit a data shuffle to sort out-of-order split results.; This will only be required if input data has duplicate loci, one of; which contains more than one alternate allele. Returns; -------; :class:`.MatrixTable` or :class:`.Table`; """""". require_row_key_variant(ds, ""split_multi""); new_id = Env.get_uid(); is_table = isinstance(ds, Table). old_row = ds.row if is_table else ds._rvrow; kept_alleles = hl.range(1, hl.len(old_row.alleles)); if not keep_star:; kept_alleles = kept_alleles.filter(lambda i: old_row.alleles[i] != ""*""). def new_struct(variant, i):; return hl.struct(alleles=variant.alleles, locus=variant.locus, a_index=i, was_split=hl.len(old_row.alleles) > 2). def split_rows(expr, rekey):; if isinstance(ds, MatrixTable):; mt = ds.annotate_rows(**{new_id: expr}).explode_rows(new_id); if rekey:; mt = mt.key_rows_by(); else:; mt = mt.key_rows_by('locus'); new_row_expr = mt._rvrow.annotate(; locus=mt[new_id]['loc",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:117932,Availability,error,errors,117932,"]), True); return left.union(moved) if is_table else left.union_rows(moved, _check_cols=False). [docs]@typecheck(ds=oneof(Table, MatrixTable), keep_star=bool, left_aligned=bool, vep_root=str, permit_shuffle=bool); def split_multi_hts(ds, keep_star=False, left_aligned=False, vep_root='vep', *, permit_shuffle=False):; """"""Split multiallelic variants for datasets that contain one or more fields; from a standard high-throughput sequencing entry schema. .. code-block:: text. struct {; GT: call,; AD: array<int32>,; DP: int32,; GQ: int32,; PL: array<int32>,; PGT: call,; PID: str; }. For other entry fields, write your own splitting logic using; :meth:`.MatrixTable.annotate_entries`. Examples; --------. >>> hl.split_multi_hts(dataset).write('output/split.mt'). Warning; -------; This method assumes `ds` contains at most one non-split variant per locus. This assumption permits the; most efficient implementation of the splitting algorithm. If your queries involving `split_multi_hts`; crash with errors about out-of-order keys, this assumption may be violated. Otherwise, this; warning likely does not apply to your dataset. If each locus in `ds` contains one multiallelic variant and one or more biallelic variants, you; can filter to the multiallelic variants, split those, and then combine the split variants with; the original biallelic variants. For example, the following code splits a dataset `mt` which contains a mixture of split and; non-split variants. >>> bi = mt.filter_rows(hl.len(mt.alleles) == 2); >>> bi = bi.annotate_rows(a_index=1, was_split=False); >>> multi = mt.filter_rows(hl.len(mt.alleles) > 2); >>> split = hl.split_multi_hts(multi); >>> mt = split.union_rows(bi). Notes; -----. We will explain by example. Consider a hypothetical 3-allelic; variant:. .. code-block:: text. A C,T 0/2:7,2,6:15:45:99,50,99,0,45,99. :func:`.split_multi_hts` will create two biallelic variants (one for each; alternate allele) at the same position. .. code-block:: text. A C 0/0:13,2:15:45:0,45",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:119009,Availability,down,downcoded,119009,"this; warning likely does not apply to your dataset. If each locus in `ds` contains one multiallelic variant and one or more biallelic variants, you; can filter to the multiallelic variants, split those, and then combine the split variants with; the original biallelic variants. For example, the following code splits a dataset `mt` which contains a mixture of split and; non-split variants. >>> bi = mt.filter_rows(hl.len(mt.alleles) == 2); >>> bi = bi.annotate_rows(a_index=1, was_split=False); >>> multi = mt.filter_rows(hl.len(mt.alleles) > 2); >>> split = hl.split_multi_hts(multi); >>> mt = split.union_rows(bi). Notes; -----. We will explain by example. Consider a hypothetical 3-allelic; variant:. .. code-block:: text. A C,T 0/2:7,2,6:15:45:99,50,99,0,45,99. :func:`.split_multi_hts` will create two biallelic variants (one for each; alternate allele) at the same position. .. code-block:: text. A C 0/0:13,2:15:45:0,45,99; A T 0/1:9,6:15:50:50,0,99. Each multiallelic `GT` or `PGT` field is downcoded once for each alternate allele. A; call for an alternate allele maps to 1 in the biallelic variant; corresponding to itself and 0 otherwise. For example, in the example above,; 0/2 maps to 0/0 and 0/1. The genotype 1/2 maps to 0/1 and 0/1. The biallelic alt `AD` entry is just the multiallelic `AD` entry; corresponding to the alternate allele. The ref AD entry is the sum of the; other multiallelic entries. The biallelic `DP` is the same as the multiallelic `DP`. The biallelic `PL` entry for a genotype g is the minimum over `PL` entries; for multiallelic genotypes that downcode to g. For example, the `PL` for (A,; T) at 0/1 is the minimum of the PLs for 0/1 (50) and 1/2 (45), and thus 45. Fixing an alternate allele and biallelic variant, downcoding gives a map; from multiallelic to biallelic alleles and genotypes. The biallelic `AD` entry; for an allele is just the sum of the multiallelic `AD` entries for alleles; that map to that allele. Similarly, the biallelic `PL` entry for",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:119593,Availability,down,downcode,119593,"eles) > 2); >>> split = hl.split_multi_hts(multi); >>> mt = split.union_rows(bi). Notes; -----. We will explain by example. Consider a hypothetical 3-allelic; variant:. .. code-block:: text. A C,T 0/2:7,2,6:15:45:99,50,99,0,45,99. :func:`.split_multi_hts` will create two biallelic variants (one for each; alternate allele) at the same position. .. code-block:: text. A C 0/0:13,2:15:45:0,45,99; A T 0/1:9,6:15:50:50,0,99. Each multiallelic `GT` or `PGT` field is downcoded once for each alternate allele. A; call for an alternate allele maps to 1 in the biallelic variant; corresponding to itself and 0 otherwise. For example, in the example above,; 0/2 maps to 0/0 and 0/1. The genotype 1/2 maps to 0/1 and 0/1. The biallelic alt `AD` entry is just the multiallelic `AD` entry; corresponding to the alternate allele. The ref AD entry is the sum of the; other multiallelic entries. The biallelic `DP` is the same as the multiallelic `DP`. The biallelic `PL` entry for a genotype g is the minimum over `PL` entries; for multiallelic genotypes that downcode to g. For example, the `PL` for (A,; T) at 0/1 is the minimum of the PLs for 0/1 (50) and 1/2 (45), and thus 45. Fixing an alternate allele and biallelic variant, downcoding gives a map; from multiallelic to biallelic alleles and genotypes. The biallelic `AD` entry; for an allele is just the sum of the multiallelic `AD` entries for alleles; that map to that allele. Similarly, the biallelic `PL` entry for a genotype is; the minimum over multiallelic `PL` entries for genotypes that map to that; genotype. `GQ` is recomputed from `PL` if `PL` is provided and is not; missing. If not, it is copied from the original GQ. Here is a second example for a het non-ref. .. code-block:: text. A C,T 1/2:2,8,6:16:45:99,50,99,45,0,99. splits as. .. code-block:: text. A C 0/1:8,8:16:45:45,0,99; A T 0/1:10,6:16:50:50,0,99. **VCF Info Fields**. Hail does not split fields in the info field. This means that if a; multiallelic site with `info.AC` value `",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:119765,Availability,down,downcoding,119765,"unc:`.split_multi_hts` will create two biallelic variants (one for each; alternate allele) at the same position. .. code-block:: text. A C 0/0:13,2:15:45:0,45,99; A T 0/1:9,6:15:50:50,0,99. Each multiallelic `GT` or `PGT` field is downcoded once for each alternate allele. A; call for an alternate allele maps to 1 in the biallelic variant; corresponding to itself and 0 otherwise. For example, in the example above,; 0/2 maps to 0/0 and 0/1. The genotype 1/2 maps to 0/1 and 0/1. The biallelic alt `AD` entry is just the multiallelic `AD` entry; corresponding to the alternate allele. The ref AD entry is the sum of the; other multiallelic entries. The biallelic `DP` is the same as the multiallelic `DP`. The biallelic `PL` entry for a genotype g is the minimum over `PL` entries; for multiallelic genotypes that downcode to g. For example, the `PL` for (A,; T) at 0/1 is the minimum of the PLs for 0/1 (50) and 1/2 (45), and thus 45. Fixing an alternate allele and biallelic variant, downcoding gives a map; from multiallelic to biallelic alleles and genotypes. The biallelic `AD` entry; for an allele is just the sum of the multiallelic `AD` entries for alleles; that map to that allele. Similarly, the biallelic `PL` entry for a genotype is; the minimum over multiallelic `PL` entries for genotypes that map to that; genotype. `GQ` is recomputed from `PL` if `PL` is provided and is not; missing. If not, it is copied from the original GQ. Here is a second example for a het non-ref. .. code-block:: text. A C,T 1/2:2,8,6:16:45:99,50,99,45,0,99. splits as. .. code-block:: text. A C 0/1:8,8:16:45:45,0,99; A T 0/1:10,6:16:50:50,0,99. **VCF Info Fields**. Hail does not split fields in the info field. This means that if a; multiallelic site with `info.AC` value ``[10, 2]`` is split, each split; site will contain the same array ``[10, 2]``. The provided allele index; field `a_index` can be used to select the value corresponding to the split; allele's position:. >>> split_ds = hl.split_multi_",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:122464,Availability,error,error,122464,"split_ds.info.AC[split_ds.a_index - 1])); >>> hl.export_vcf(split_ds, 'output/export.vcf') # doctest: +SKIP. The info field AC in *data/export.vcf* will have ``Number=1``. **New Fields**. :func:`.split_multi_hts` adds the following fields:. - `was_split` (*bool*) -- ``True`` if this variant was originally; multiallelic, otherwise ``False``. - `a_index` (*int*) -- The original index of this alternate allele in the; multiallelic representation (NB: 1 is the first alternate allele or the; only alternate allele in a biallelic variant). For example, 1:100:A:T,C; splits into two variants: 1:100:A:T with ``a_index = 1`` and 1:100:A:C; with ``a_index = 2``. See Also; --------; :func:`.split_multi`. Parameters; ----------; ds : :class:`.MatrixTable` or :class:`.Table`; An unsplit dataset.; keep_star : :obj:`bool`; Do not filter out * alleles.; left_aligned : :obj:`bool`; If ``True``, variants are assumed to be left; aligned and have unique loci. This avoids a shuffle. If the assumption; is violated, an error is generated.; vep_root : :class:`str`; Top-level location of vep data. All variable-length VEP fields; (intergenic_consequences, motif_feature_consequences,; regulatory_feature_consequences, and transcript_consequences); will be split properly (i.e. a_index corresponding to the VEP allele_num).; permit_shuffle : :obj:`bool`; If ``True``, permit a data shuffle to sort out-of-order split results.; This will only be required if input data has duplicate loci, one of; which contains more than one alternate allele. Returns; -------; :class:`.MatrixTable` or :class:`.Table`; A biallelic variant dataset. """""". split = split_multi(ds, keep_star=keep_star, left_aligned=left_aligned, permit_shuffle=permit_shuffle). row_fields = set(ds.row); update_rows_expression = {}; if vep_root in row_fields:; update_rows_expression[vep_root] = split[vep_root].annotate(**{; x: split[vep_root][x].filter(lambda csq: csq.allele_num == split.a_index); for x in (; 'intergenic_consequences',; 'motif_fe",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:124421,Availability,down,downcode,124421,"ic_consequences',; 'motif_feature_consequences',; 'regulatory_feature_consequences',; 'transcript_consequences',; ); }). if isinstance(ds, Table):; return split.annotate(**update_rows_expression).drop('old_locus', 'old_alleles'). split = split.annotate_rows(**update_rows_expression); entry_fields = ds.entry. expected_field_types = {; 'GT': hl.tcall,; 'AD': hl.tarray(hl.tint),; 'DP': hl.tint,; 'GQ': hl.tint,; 'PL': hl.tarray(hl.tint),; 'PGT': hl.tcall,; 'PID': hl.tstr,; }. bad_fields = []; for field in entry_fields:; if field in expected_field_types and entry_fields[field].dtype != expected_field_types[field]:; bad_fields.append((field, entry_fields[field].dtype, expected_field_types[field])). if bad_fields:; msg = '\n '.join([f""'{x[0]}'\tfound: {x[1]}\texpected: {x[2]}"" for x in bad_fields]); raise TypeError(""'split_multi_hts': Found invalid types for the following fields:\n "" + msg). update_entries_expression = {}; if 'GT' in entry_fields:; update_entries_expression['GT'] = hl.downcode(split.GT, split.a_index); if 'DP' in entry_fields:; update_entries_expression['DP'] = split.DP; if 'AD' in entry_fields:; update_entries_expression['AD'] = hl.or_missing(; hl.is_defined(split.AD), [hl.sum(split.AD) - split.AD[split.a_index], split.AD[split.a_index]]; ); if 'PL' in entry_fields:; pl = hl.or_missing(; hl.is_defined(split.PL),; (; hl.range(0, 3).map(; lambda i: hl.min(; (; hl.range(0, hl.triangle(split.old_alleles.length())); .filter(; lambda j: hl.downcode(; hl.unphased_diploid_gt_index_call(j), split.a_index; ).unphased_diploid_gt_index(); == i; ); .map(lambda j: split.PL[j]); ); ); ); ),; ); if 'GQ' in entry_fields:; update_entries_expression['PL'] = pl; update_entries_expression['GQ'] = hl.or_else(hl.gq_from_pl(pl), split.GQ); else:; update_entries_expression['PL'] = pl; elif 'GQ' in entry_fields:; update_entries_expression['GQ'] = split.GQ. if 'PGT' in entry_fields:; update_entries_expression['PGT'] = hl.downcode(split.PGT, split.a_index); if 'PID' in entry_fields:;",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:124897,Availability,down,downcode,124897," bad_fields = []; for field in entry_fields:; if field in expected_field_types and entry_fields[field].dtype != expected_field_types[field]:; bad_fields.append((field, entry_fields[field].dtype, expected_field_types[field])). if bad_fields:; msg = '\n '.join([f""'{x[0]}'\tfound: {x[1]}\texpected: {x[2]}"" for x in bad_fields]); raise TypeError(""'split_multi_hts': Found invalid types for the following fields:\n "" + msg). update_entries_expression = {}; if 'GT' in entry_fields:; update_entries_expression['GT'] = hl.downcode(split.GT, split.a_index); if 'DP' in entry_fields:; update_entries_expression['DP'] = split.DP; if 'AD' in entry_fields:; update_entries_expression['AD'] = hl.or_missing(; hl.is_defined(split.AD), [hl.sum(split.AD) - split.AD[split.a_index], split.AD[split.a_index]]; ); if 'PL' in entry_fields:; pl = hl.or_missing(; hl.is_defined(split.PL),; (; hl.range(0, 3).map(; lambda i: hl.min(; (; hl.range(0, hl.triangle(split.old_alleles.length())); .filter(; lambda j: hl.downcode(; hl.unphased_diploid_gt_index_call(j), split.a_index; ).unphased_diploid_gt_index(); == i; ); .map(lambda j: split.PL[j]); ); ); ); ),; ); if 'GQ' in entry_fields:; update_entries_expression['PL'] = pl; update_entries_expression['GQ'] = hl.or_else(hl.gq_from_pl(pl), split.GQ); else:; update_entries_expression['PL'] = pl; elif 'GQ' in entry_fields:; update_entries_expression['GQ'] = split.GQ. if 'PGT' in entry_fields:; update_entries_expression['PGT'] = hl.downcode(split.PGT, split.a_index); if 'PID' in entry_fields:; update_entries_expression['PID'] = split.PID; return split.annotate_entries(**update_entries_expression).drop('old_locus', 'old_alleles'). [docs]@typecheck(call_expr=expr_call); def genetic_relatedness_matrix(call_expr) -> BlockMatrix:; r""""""Compute the genetic relatedness matrix (GRM). Examples; --------. >>> grm = hl.genetic_relatedness_matrix(dataset.GT). Notes; -----; The genetic relationship matrix (GRM) :math:`G` encodes genetic correlation; between each pair of sa",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:125367,Availability,down,downcode,125367,"_fields:; update_entries_expression['GT'] = hl.downcode(split.GT, split.a_index); if 'DP' in entry_fields:; update_entries_expression['DP'] = split.DP; if 'AD' in entry_fields:; update_entries_expression['AD'] = hl.or_missing(; hl.is_defined(split.AD), [hl.sum(split.AD) - split.AD[split.a_index], split.AD[split.a_index]]; ); if 'PL' in entry_fields:; pl = hl.or_missing(; hl.is_defined(split.PL),; (; hl.range(0, 3).map(; lambda i: hl.min(; (; hl.range(0, hl.triangle(split.old_alleles.length())); .filter(; lambda j: hl.downcode(; hl.unphased_diploid_gt_index_call(j), split.a_index; ).unphased_diploid_gt_index(); == i; ); .map(lambda j: split.PL[j]); ); ); ); ),; ); if 'GQ' in entry_fields:; update_entries_expression['PL'] = pl; update_entries_expression['GQ'] = hl.or_else(hl.gq_from_pl(pl), split.GQ); else:; update_entries_expression['PL'] = pl; elif 'GQ' in entry_fields:; update_entries_expression['GQ'] = split.GQ. if 'PGT' in entry_fields:; update_entries_expression['PGT'] = hl.downcode(split.PGT, split.a_index); if 'PID' in entry_fields:; update_entries_expression['PID'] = split.PID; return split.annotate_entries(**update_entries_expression).drop('old_locus', 'old_alleles'). [docs]@typecheck(call_expr=expr_call); def genetic_relatedness_matrix(call_expr) -> BlockMatrix:; r""""""Compute the genetic relatedness matrix (GRM). Examples; --------. >>> grm = hl.genetic_relatedness_matrix(dataset.GT). Notes; -----; The genetic relationship matrix (GRM) :math:`G` encodes genetic correlation; between each pair of samples. It is defined by :math:`G = MM^T` where; :math:`M` is a standardized version of the genotype matrix, computed as; follows. Let :math:`C` be the :math:`n \times m` matrix of raw genotypes; in the variant dataset, with rows indexed by :math:`n` samples and columns; indexed by :math:`m` bialellic autosomal variants; :math:`C_{ij}` is the; number of alternate alleles of variant :math:`j` carried by sample; :math:`i`, which can be 0, 1, 2, or missing. For each vari",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:140007,Availability,error,error,140007,"ghborhood of the diagonal. If variants :math:`i` and :math:`j` are on the; same contig and within `radius` base pairs (inclusive) then the; :math:`(i, j)` element is their; `Pearson correlation coefficient <https://en.wikipedia.org/wiki/Pearson_correlation_coefficient>`__.; Otherwise, the :math:`(i, j)` element is ``0.0``. Rows with a constant value (i.e., zero variance) will result in ``nan``; correlation values. To avoid this, first check that all variants vary or; filter out constant variants (for example, with the help of; :func:`.aggregators.stats`). If the :meth:`.global_position` on `locus_expr` is not in ascending order,; this method will fail. Ascending order should hold for a matrix table keyed; by locus or variant (and the associated row table), or for a table that's; been ordered by `locus_expr`. Set `coord_expr` to use a value other than position to define the windows.; This row-indexed numeric expression must be non-missing, non-``nan``, on the; same source as `locus_expr`, and ascending with respect to locus; position for each contig; otherwise the method will raise an error. Warning; -------; See the warnings in :meth:`row_correlation`. In particular, for large; matrices it may be preferable to run its stages separately. `entry_expr` and `locus_expr` are implicitly aligned by row-index, though; they need not be on the same source. If their sources differ in the number; of rows, an error will be raised; otherwise, unintended misalignment may; silently produce unexpected results. Parameters; ----------; entry_expr : :class:`.Float64Expression`; Entry-indexed numeric expression on matrix table.; locus_expr : :class:`.LocusExpression`; Row-indexed locus expression on a table or matrix table that is; row-aligned with the matrix table of `entry_expr`.; radius: :obj:`int` or :obj:`float`; Radius of window for row values.; coord_expr: :class:`.Float64Expression`, optional; Row-indexed numeric expression for the row value on the same table or; matrix table as ",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:140326,Availability,error,error,140326,"k that all variants vary or; filter out constant variants (for example, with the help of; :func:`.aggregators.stats`). If the :meth:`.global_position` on `locus_expr` is not in ascending order,; this method will fail. Ascending order should hold for a matrix table keyed; by locus or variant (and the associated row table), or for a table that's; been ordered by `locus_expr`. Set `coord_expr` to use a value other than position to define the windows.; This row-indexed numeric expression must be non-missing, non-``nan``, on the; same source as `locus_expr`, and ascending with respect to locus; position for each contig; otherwise the method will raise an error. Warning; -------; See the warnings in :meth:`row_correlation`. In particular, for large; matrices it may be preferable to run its stages separately. `entry_expr` and `locus_expr` are implicitly aligned by row-index, though; they need not be on the same source. If their sources differ in the number; of rows, an error will be raised; otherwise, unintended misalignment may; silently produce unexpected results. Parameters; ----------; entry_expr : :class:`.Float64Expression`; Entry-indexed numeric expression on matrix table.; locus_expr : :class:`.LocusExpression`; Row-indexed locus expression on a table or matrix table that is; row-aligned with the matrix table of `entry_expr`.; radius: :obj:`int` or :obj:`float`; Radius of window for row values.; coord_expr: :class:`.Float64Expression`, optional; Row-indexed numeric expression for the row value on the same table or; matrix table as `locus_expr`.; By default, the row value is given by the locus position.; block_size : :obj:`int`, optional; Block size. Default given by :meth:`.BlockMatrix.default_block_size`. Returns; -------; :class:`.BlockMatrix`; Windowed correlation matrix between variants.; Row and column indices correspond to matrix table variant index.; """"""; starts_and_stops = hl.linalg.utils.locus_windows(locus_expr, radius, coord_expr, _localize=False); start",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:159403,Availability,down,downcode,159403," rearrange these fields if; necessary. The following new fields are generated:. - `old_locus` (``locus``) -- The old locus, before filtering and computing; the minimal representation.; - `old_alleles` (``array<str>``) -- The old alleles, before filtering and; computing the minimal representation.; - `old_to_new` (``array<int32>``) -- An array that maps old allele index to; new allele index. Its length is the same as `old_alleles`. Alleles that; are filtered are missing.; - `new_to_old` (``array<int32>``) -- An array that maps new allele index to; the old allele index. Its length is the same as the modified `alleles`; field. **Downcode algorithm**. We will illustrate the behavior on the example genotype below; when filtering the first alternate allele (allele 1) at a site; with 1 reference allele and 2 alternate alleles. .. code-block:: text. GT: 1/2; GQ: 10; AD: 0,50,35. 0 | 1000; 1 | 1000 10; 2 | 1000 0 20; +-----------------; 0 1 2. The downcode algorithm recodes occurances of filtered alleles; to occurances of the reference allele (e.g. 1 -> 0 in our; example). So the depths of filtered alleles in the AD field; are added to the depth of the reference allele. Where; downcoding filtered alleles merges distinct genotypes, the; minimum PL is used (since PL is on a log scale, this roughly; corresponds to adding probabilities). The PLs are then; re-normalized (shifted) so that the most likely genotype has a; PL of 0, and GT is set to this genotype. If an allele is; filtered, this algorithm acts similarly to; :func:`.split_multi_hts`. The downcode algorithm would produce the following:. .. code-block:: text. GT: 0/1; GQ: 10; AD: 35,50. 0 | 20; 1 | 0 10; +-----------; 0 1. In summary:. - GT: Downcode filtered alleles to reference.; - AD: Columns of filtered alleles are eliminated and their; values are added to the reference column, e.g., filtering; alleles 1 and 2 transforms ``25,5,10,20`` to ``40,20``.; - DP: No change.; - PL: Downcode filtered alleles to reference, comb",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:159637,Availability,down,downcoding,159637,"mputing the minimal representation.; - `old_to_new` (``array<int32>``) -- An array that maps old allele index to; new allele index. Its length is the same as `old_alleles`. Alleles that; are filtered are missing.; - `new_to_old` (``array<int32>``) -- An array that maps new allele index to; the old allele index. Its length is the same as the modified `alleles`; field. **Downcode algorithm**. We will illustrate the behavior on the example genotype below; when filtering the first alternate allele (allele 1) at a site; with 1 reference allele and 2 alternate alleles. .. code-block:: text. GT: 1/2; GQ: 10; AD: 0,50,35. 0 | 1000; 1 | 1000 10; 2 | 1000 0 20; +-----------------; 0 1 2. The downcode algorithm recodes occurances of filtered alleles; to occurances of the reference allele (e.g. 1 -> 0 in our; example). So the depths of filtered alleles in the AD field; are added to the depth of the reference allele. Where; downcoding filtered alleles merges distinct genotypes, the; minimum PL is used (since PL is on a log scale, this roughly; corresponds to adding probabilities). The PLs are then; re-normalized (shifted) so that the most likely genotype has a; PL of 0, and GT is set to this genotype. If an allele is; filtered, this algorithm acts similarly to; :func:`.split_multi_hts`. The downcode algorithm would produce the following:. .. code-block:: text. GT: 0/1; GQ: 10; AD: 35,50. 0 | 20; 1 | 0 10; +-----------; 0 1. In summary:. - GT: Downcode filtered alleles to reference.; - AD: Columns of filtered alleles are eliminated and their; values are added to the reference column, e.g., filtering; alleles 1 and 2 transforms ``25,5,10,20`` to ``40,20``.; - DP: No change.; - PL: Downcode filtered alleles to reference, combine PLs; using minimum for each overloaded genotype, and shift so; the overall minimum PL is 0.; - GQ: The second-lowest PL (after shifting). **Subset algorithm**. We will illustrate the behavior on the example genotype below; when filtering the first alternate ",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:160011,Availability,down,downcode,160011,"gth is the same as the modified `alleles`; field. **Downcode algorithm**. We will illustrate the behavior on the example genotype below; when filtering the first alternate allele (allele 1) at a site; with 1 reference allele and 2 alternate alleles. .. code-block:: text. GT: 1/2; GQ: 10; AD: 0,50,35. 0 | 1000; 1 | 1000 10; 2 | 1000 0 20; +-----------------; 0 1 2. The downcode algorithm recodes occurances of filtered alleles; to occurances of the reference allele (e.g. 1 -> 0 in our; example). So the depths of filtered alleles in the AD field; are added to the depth of the reference allele. Where; downcoding filtered alleles merges distinct genotypes, the; minimum PL is used (since PL is on a log scale, this roughly; corresponds to adding probabilities). The PLs are then; re-normalized (shifted) so that the most likely genotype has a; PL of 0, and GT is set to this genotype. If an allele is; filtered, this algorithm acts similarly to; :func:`.split_multi_hts`. The downcode algorithm would produce the following:. .. code-block:: text. GT: 0/1; GQ: 10; AD: 35,50. 0 | 20; 1 | 0 10; +-----------; 0 1. In summary:. - GT: Downcode filtered alleles to reference.; - AD: Columns of filtered alleles are eliminated and their; values are added to the reference column, e.g., filtering; alleles 1 and 2 transforms ``25,5,10,20`` to ``40,20``.; - DP: No change.; - PL: Downcode filtered alleles to reference, combine PLs; using minimum for each overloaded genotype, and shift so; the overall minimum PL is 0.; - GQ: The second-lowest PL (after shifting). **Subset algorithm**. We will illustrate the behavior on the example genotype below; when filtering the first alternate allele (allele 1) at a site; with 1 reference allele and 2 alternate alleles. .. code-block:: text. GT: 1/2; GQ: 10; AD: 0,50,35. 0 | 1000; 1 | 1000 10; 2 | 1000 0 20; +-----------------; 0 1 2. The subset algorithm subsets the AD and PL arrays; (i.e. removes entries corresponding to filtered alleles) and; then sets GT",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:162495,Availability,down,downcode,162495," | 980 0; +-----------; 0 1. In summary:. - GT: Set to most likely genotype based on the PLs ignoring; the filtered allele(s).; - AD: The filtered alleles' columns are eliminated, e.g.,; filtering alleles 1 and 2 transforms ``25,5,10,20`` to; ``25,20``.; - DP: Unchanged.; - PL: Columns involving filtered alleles are eliminated and; the remaining columns' values are shifted so the minimum; value is 0.; - GQ: The second-lowest PL (after shifting). Warning; -------; :func:`.filter_alleles_hts` does not update any row fields other than; `locus` and `alleles`. This means that row fields like allele count (AC) can; become meaningless unless they are also updated. You can update them with; :meth:`.annotate_rows`. See Also; --------; :func:`.filter_alleles`. Parameters; ----------; mt : :class:`.MatrixTable`; f : callable; Function from (allele: :class:`.StringExpression`, allele_index:; :class:`.Int32Expression`) to :class:`.BooleanExpression`; subset : :obj:`.bool`; Subset PL field if ``True``, otherwise downcode PL field. The; calculation of GT and GQ also depend on whether one subsets or; downcodes the PL. Returns; -------; :class:`.MatrixTable`; """"""; if mt.entry.dtype != hl.hts_entry_schema:; raise FatalError(; ""'filter_alleles_hts': entry schema must be the HTS entry schema:\n""; "" found: {}\n""; "" expected: {}\n""; "" Use 'hl.filter_alleles' to split entries with non-HTS entry fields."".format(; mt.entry.dtype, hl.hts_entry_schema; ); ). mt = filter_alleles(mt, f). if subset:; newPL = hl.if_else(; hl.is_defined(mt.PL),; hl.bind(; lambda unnorm: unnorm - hl.min(unnorm),; hl.range(0, hl.triangle(mt.alleles.length())).map(; lambda newi: hl.bind(; lambda newc: mt.PL[; hl.call(mt.new_to_old[newc[0]], mt.new_to_old[newc[1]]).unphased_diploid_gt_index(); ],; hl.unphased_diploid_gt_index_call(newi),; ); ),; ),; hl.missing(tarray(tint32)),; ); return mt.annotate_entries(; GT=hl.unphased_diploid_gt_index_call(hl.argmin(newPL, unique=True)),; AD=hl.if_else(; hl.is_defined(mt.AD),; h",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:162583,Availability,down,downcodes,162583," based on the PLs ignoring; the filtered allele(s).; - AD: The filtered alleles' columns are eliminated, e.g.,; filtering alleles 1 and 2 transforms ``25,5,10,20`` to; ``25,20``.; - DP: Unchanged.; - PL: Columns involving filtered alleles are eliminated and; the remaining columns' values are shifted so the minimum; value is 0.; - GQ: The second-lowest PL (after shifting). Warning; -------; :func:`.filter_alleles_hts` does not update any row fields other than; `locus` and `alleles`. This means that row fields like allele count (AC) can; become meaningless unless they are also updated. You can update them with; :meth:`.annotate_rows`. See Also; --------; :func:`.filter_alleles`. Parameters; ----------; mt : :class:`.MatrixTable`; f : callable; Function from (allele: :class:`.StringExpression`, allele_index:; :class:`.Int32Expression`) to :class:`.BooleanExpression`; subset : :obj:`.bool`; Subset PL field if ``True``, otherwise downcode PL field. The; calculation of GT and GQ also depend on whether one subsets or; downcodes the PL. Returns; -------; :class:`.MatrixTable`; """"""; if mt.entry.dtype != hl.hts_entry_schema:; raise FatalError(; ""'filter_alleles_hts': entry schema must be the HTS entry schema:\n""; "" found: {}\n""; "" expected: {}\n""; "" Use 'hl.filter_alleles' to split entries with non-HTS entry fields."".format(; mt.entry.dtype, hl.hts_entry_schema; ); ). mt = filter_alleles(mt, f). if subset:; newPL = hl.if_else(; hl.is_defined(mt.PL),; hl.bind(; lambda unnorm: unnorm - hl.min(unnorm),; hl.range(0, hl.triangle(mt.alleles.length())).map(; lambda newi: hl.bind(; lambda newc: mt.PL[; hl.call(mt.new_to_old[newc[0]], mt.new_to_old[newc[1]]).unphased_diploid_gt_index(); ],; hl.unphased_diploid_gt_index_call(newi),; ); ),; ),; hl.missing(tarray(tint32)),; ); return mt.annotate_entries(; GT=hl.unphased_diploid_gt_index_call(hl.argmin(newPL, unique=True)),; AD=hl.if_else(; hl.is_defined(mt.AD),; hl.range(0, mt.alleles.length()).map(lambda newi: mt.AD[mt.new_to_old[newi]])",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:163661,Availability,down,downcode,163661,"mt.entry.dtype != hl.hts_entry_schema:; raise FatalError(; ""'filter_alleles_hts': entry schema must be the HTS entry schema:\n""; "" found: {}\n""; "" expected: {}\n""; "" Use 'hl.filter_alleles' to split entries with non-HTS entry fields."".format(; mt.entry.dtype, hl.hts_entry_schema; ); ). mt = filter_alleles(mt, f). if subset:; newPL = hl.if_else(; hl.is_defined(mt.PL),; hl.bind(; lambda unnorm: unnorm - hl.min(unnorm),; hl.range(0, hl.triangle(mt.alleles.length())).map(; lambda newi: hl.bind(; lambda newc: mt.PL[; hl.call(mt.new_to_old[newc[0]], mt.new_to_old[newc[1]]).unphased_diploid_gt_index(); ],; hl.unphased_diploid_gt_index_call(newi),; ); ),; ),; hl.missing(tarray(tint32)),; ); return mt.annotate_entries(; GT=hl.unphased_diploid_gt_index_call(hl.argmin(newPL, unique=True)),; AD=hl.if_else(; hl.is_defined(mt.AD),; hl.range(0, mt.alleles.length()).map(lambda newi: mt.AD[mt.new_to_old[newi]]),; hl.missing(tarray(tint32)),; ),; # DP unchanged; GQ=hl.gq_from_pl(newPL),; PL=newPL,; ); # otherwise downcode; else:; mt = mt.annotate_rows(__old_to_new_no_na=mt.old_to_new.map(lambda x: hl.or_else(x, 0))); newPL = hl.if_else(; hl.is_defined(mt.PL),; (; hl.range(0, hl.triangle(hl.len(mt.alleles))).map(; lambda newi: hl.min(; hl.range(0, hl.triangle(hl.len(mt.old_alleles))); .filter(; lambda oldi: hl.bind(; lambda oldc: hl.call(mt.__old_to_new_no_na[oldc[0]], mt.__old_to_new_no_na[oldc[1]]); == hl.unphased_diploid_gt_index_call(newi),; hl.unphased_diploid_gt_index_call(oldi),; ); ); .map(lambda oldi: mt.PL[oldi]); ); ); ),; hl.missing(tarray(tint32)),; ); return mt.annotate_entries(; GT=hl.call(mt.__old_to_new_no_na[mt.GT[0]], mt.__old_to_new_no_na[mt.GT[1]]),; AD=hl.if_else(; hl.is_defined(mt.AD),; (; hl.range(0, hl.len(mt.alleles)).map(; lambda newi: hl.sum(; hl.range(0, hl.len(mt.old_alleles)); .filter(lambda oldi: mt.__old_to_new_no_na[oldi] == newi); .map(lambda oldi: mt.AD[oldi]); ); ); ),; hl.missing(tarray(tint32)),; ),; # DP unchanged; GQ=hl.gq_from_pl(newPL),; PL=ne",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:168667,Availability,error,errors,168667,"nor allele frequency is not taken into account. The; parallelism is the number of matrix table partitions. - The second, ""global correlation"" stage uses block-sparse matrix; multiplication to compute correlation between each pair of remaining; variants within `bp_window_size` base pairs, and then forms a graph of; correlated variants. The parallelism of writing the locally-pruned matrix; table as a block matrix is ``n_locally_pruned_variants / block_size``. - The third, ""global pruning"" stage applies :func:`.maximal_independent_set`; to prune variants from this graph until no edges remain. This algorithm; iteratively removes the variant with the highest vertex degree. If; `keep_higher_maf` is true, then in the case of a tie for highest degree,; the variant with lowest minor allele frequency is removed. Warning; -------; The locally-pruned matrix table and block matrix are stored as temporary files; on persistent disk. See the warnings on `BlockMatrix.from_entry_expr` with; regard to memory and Hadoop replication errors. Parameters; ----------; call_expr : :class:`.CallExpression`; Entry-indexed call expression on a matrix table with row-indexed; variants and column-indexed samples.; r2 : :obj:`float`; Squared correlation threshold (exclusive upper bound).; Must be in the range [0.0, 1.0].; bp_window_size: :obj:`int`; Window size in base pairs (inclusive upper bound).; memory_per_core : :obj:`int`; Memory in MB per core for local pruning queue.; keep_higher_maf: :obj:`int`; If ``True``, break ties at each step of the global pruning stage by; preferring to keep variants with higher minor allele frequency.; block_size: :obj:`int`, optional; Block size for block matrices in the second stage.; Default given by :meth:`.BlockMatrix.default_block_size`. Returns; -------; :class:`.Table`; Table of a maximal independent set of variants.; """"""; if block_size is None:; block_size = BlockMatrix.default_block_size(). if not 0.0 <= r2 <= 1:; raise ValueError(f'r2 must be in the ran",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:77492,Deployability,integrat,integration,77492,"-----+-------+----------+----------+-------+. The same test, but using the original paper's suggested weights which are derived from the; allele frequency. >>> mt = hl.variant_qc(mt); >>> skat = hl._linear_skat(; ... mt.gene,; ... hl.dbeta(mt.variant_qc.AF[0], 1, 25),; ... mt.phenotype,; ... mt.GT.n_alt_alleles(),; ... covariates=[1.0]); >>> skat.show(); +-------+-------+----------+----------+-------+; | group | size | q_stat | p_value | fault |; +-------+-------+----------+----------+-------+; | int32 | int64 | float64 | float64 | int32 |; +-------+-------+----------+----------+-------+; | 0 | 11 | 2.39e+01 | 4.32e-01 | 0 |; | 1 | 9 | 1.69e+01 | 7.82e-02 | 0 |; +-------+-------+----------+----------+-------+. Our simulated data was unweighted, so the null hypothesis appears true. In real datasets, we; expect the allele frequency to correlate with effect size. Notice that, in the second group, the fault flag is set to 1. This indicates that the numerical; integration to calculate the p-value failed to achieve the required accuracy (by default,; 1e-6). In this particular case, the null hypothesis is likely true and the numerical integration; returned a (nonsensical) value greater than one. The `max_size` parameter allows us to skip large genes that would cause ""out of memory"" errors:. >>> skat = hl._linear_skat(; ... mt.gene,; ... mt.weight,; ... mt.phenotype,; ... mt.GT.n_alt_alleles(),; ... covariates=[1.0],; ... max_size=10); >>> skat.show(); +-------+-------+----------+----------+-------+; | group | size | q_stat | p_value | fault |; +-------+-------+----------+----------+-------+; | int32 | int64 | float64 | float64 | int32 |; +-------+-------+----------+----------+-------+; | 0 | 11 | NA | NA | NA |; | 1 | 9 | 8.13e+02 | 3.95e-05 | 0 |; +-------+-------+----------+----------+-------+. Notes; -----. In the SKAT R package, the ""weights"" are actually the *square root* of the weight expression; from the paper. This method uses the definition from the paper. The pape",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:77668,Deployability,integrat,integration,77668," allele frequency. >>> mt = hl.variant_qc(mt); >>> skat = hl._linear_skat(; ... mt.gene,; ... hl.dbeta(mt.variant_qc.AF[0], 1, 25),; ... mt.phenotype,; ... mt.GT.n_alt_alleles(),; ... covariates=[1.0]); >>> skat.show(); +-------+-------+----------+----------+-------+; | group | size | q_stat | p_value | fault |; +-------+-------+----------+----------+-------+; | int32 | int64 | float64 | float64 | int32 |; +-------+-------+----------+----------+-------+; | 0 | 11 | 2.39e+01 | 4.32e-01 | 0 |; | 1 | 9 | 1.69e+01 | 7.82e-02 | 0 |; +-------+-------+----------+----------+-------+. Our simulated data was unweighted, so the null hypothesis appears true. In real datasets, we; expect the allele frequency to correlate with effect size. Notice that, in the second group, the fault flag is set to 1. This indicates that the numerical; integration to calculate the p-value failed to achieve the required accuracy (by default,; 1e-6). In this particular case, the null hypothesis is likely true and the numerical integration; returned a (nonsensical) value greater than one. The `max_size` parameter allows us to skip large genes that would cause ""out of memory"" errors:. >>> skat = hl._linear_skat(; ... mt.gene,; ... mt.weight,; ... mt.phenotype,; ... mt.GT.n_alt_alleles(),; ... covariates=[1.0],; ... max_size=10); >>> skat.show(); +-------+-------+----------+----------+-------+; | group | size | q_stat | p_value | fault |; +-------+-------+----------+----------+-------+; | int32 | int64 | float64 | float64 | int32 |; +-------+-------+----------+----------+-------+; | 0 | 11 | NA | NA | NA |; | 1 | 9 | 8.13e+02 | 3.95e-05 | 0 |; +-------+-------+----------+----------+-------+. Notes; -----. In the SKAT R package, the ""weights"" are actually the *square root* of the weight expression; from the paper. This method uses the definition from the paper. The paper includes an explicit intercept term but this method expects the user to specify the; intercept as an extra covariate with the value 1.",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:93214,Deployability,integrat,integration,93214,"---+-------+----------+----------+-------+. The same test, but using the original paper's suggested weights which are derived from the; allele frequency. >>> mt = hl.variant_qc(mt); >>> skat = hl._logistic_skat(; ... mt.gene,; ... hl.dbeta(mt.variant_qc.AF[0], 1, 25),; ... mt.phenotype,; ... mt.GT.n_alt_alleles(),; ... covariates=[1.0]); >>> skat.show(); +-------+-------+----------+----------+-------+; | group | size | q_stat | p_value | fault |; +-------+-------+----------+----------+-------+; | int32 | int64 | float64 | float64 | int32 |; +-------+-------+----------+----------+-------+; | 0 | 11 | 8.04e+00 | 3.50e-01 | 0 |; | 1 | 9 | 1.22e+00 | 5.04e-01 | 0 |; +-------+-------+----------+----------+-------+. Our simulated data was unweighted, so the null hypothesis appears true. In real datasets, we; expect the allele frequency to correlate with effect size. Notice that, in the second group, the fault flag is set to 1. This indicates that the numerical; integration to calculate the p-value failed to achieve the required accuracy (by default,; 1e-6). In this particular case, the null hypothesis is likely true and the numerical integration; returned a (nonsensical) value greater than one. The `max_size` parameter allows us to skip large genes that would cause ""out of memory"" errors:. >>> skat = hl._logistic_skat(; ... mt.gene,; ... mt.weight,; ... mt.phenotype,; ... mt.GT.n_alt_alleles(),; ... covariates=[1.0],; ... max_size=10); >>> skat.show(); +-------+-------+----------+----------+-------+; | group | size | q_stat | p_value | fault |; +-------+-------+----------+----------+-------+; | int32 | int64 | float64 | float64 | int32 |; +-------+-------+----------+----------+-------+; | 0 | 11 | NA | NA | NA |; | 1 | 9 | 1.39e+02 | 1.82e-03 | 0 |; +-------+-------+----------+----------+-------+. Notes; -----. In the SKAT R package, the ""weights"" are actually the *square root* of the weight expression; from the paper. This method uses the definition from the paper. The pa",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:93390,Deployability,integrat,integration,93390,"llele frequency. >>> mt = hl.variant_qc(mt); >>> skat = hl._logistic_skat(; ... mt.gene,; ... hl.dbeta(mt.variant_qc.AF[0], 1, 25),; ... mt.phenotype,; ... mt.GT.n_alt_alleles(),; ... covariates=[1.0]); >>> skat.show(); +-------+-------+----------+----------+-------+; | group | size | q_stat | p_value | fault |; +-------+-------+----------+----------+-------+; | int32 | int64 | float64 | float64 | int32 |; +-------+-------+----------+----------+-------+; | 0 | 11 | 8.04e+00 | 3.50e-01 | 0 |; | 1 | 9 | 1.22e+00 | 5.04e-01 | 0 |; +-------+-------+----------+----------+-------+. Our simulated data was unweighted, so the null hypothesis appears true. In real datasets, we; expect the allele frequency to correlate with effect size. Notice that, in the second group, the fault flag is set to 1. This indicates that the numerical; integration to calculate the p-value failed to achieve the required accuracy (by default,; 1e-6). In this particular case, the null hypothesis is likely true and the numerical integration; returned a (nonsensical) value greater than one. The `max_size` parameter allows us to skip large genes that would cause ""out of memory"" errors:. >>> skat = hl._logistic_skat(; ... mt.gene,; ... mt.weight,; ... mt.phenotype,; ... mt.GT.n_alt_alleles(),; ... covariates=[1.0],; ... max_size=10); >>> skat.show(); +-------+-------+----------+----------+-------+; | group | size | q_stat | p_value | fault |; +-------+-------+----------+----------+-------+; | int32 | int64 | float64 | float64 | int32 |; +-------+-------+----------+----------+-------+; | 0 | 11 | NA | NA | NA |; | 1 | 9 | 1.39e+02 | 1.82e-03 | 0 |; +-------+-------+----------+----------+-------+. Notes; -----. In the SKAT R package, the ""weights"" are actually the *square root* of the weight expression; from the paper. This method uses the definition from the paper. The paper includes an explicit intercept term but this method expects the user to specify the; intercept as an extra covariate with the value ",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:106025,Deployability,integrat,integration,106025,"R; package ``skat``, but both differ from :math:`Q` in the paper by the factor; :math:`\frac{1}{2\sigma^2}` in the linear case and :math:`\frac{1}{2}` in; the logistic case, where :math:`\sigma^2` is the unbiased estimator of; residual variance for the linear null model. The R package also applies a; ""small-sample adjustment"" to the null distribution in the logistic case; when the sample size is less than 2000. Hail does not apply this; adjustment. The fault flag is an integer indicating whether any issues occurred when; running the Davies algorithm to compute the p-value as the right tail of a; weighted sum of :math:`\chi^2(1)` distributions. +-------------+-----------------------------------------+; | fault value | Description |; +=============+=========================================+; | 0 | no issues |; +------+------+-----------------------------------------+; | 1 | accuracy NOT achieved |; +------+------+-----------------------------------------+; | 2 | round-off error possibly significant |; +------+------+-----------------------------------------+; | 3 | invalid parameters |; +------+------+-----------------------------------------+; | 4 | unable to locate integration parameters |; +------+------+-----------------------------------------+; | 5 | out of memory |; +------+------+-----------------------------------------+. Parameters; ----------; key_expr : :class:`.Expression`; Row-indexed expression for key associated to each row.; weight_expr : :class:`.Float64Expression`; Row-indexed expression for row weights.; y : :class:`.Float64Expression`; Column-indexed response expression.; If `logistic` is ``True``, all non-missing values must evaluate to 0 or; 1. Note that a :class:`.BooleanExpression` will be implicitly converted; to a :class:`.Float64Expression` with this property.; x : :class:`.Float64Expression`; Entry-indexed expression for input variable.; covariates : :obj:`list` of :class:`.Float64Expression`; List of column-indexed covariate expressions.; ",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:113156,Deployability,update,updates,113156,"t variant per locus. This assumption permits the; most efficient implementation of the splitting algorithm. If your queries involving `split_multi`; crash with errors about out-of-order keys, this assumption may be violated. Otherwise, this; warning likely does not apply to your dataset. If each locus in `ds` contains one multiallelic variant and one or more biallelic variants, you; can filter to the multiallelic variants, split those, and then combine the split variants with; the original biallelic variants. For example, the following code splits a dataset `mt` which contains a mixture of split and; non-split variants. >>> bi = mt.filter_rows(hl.len(mt.alleles) == 2); >>> bi = bi.annotate_rows(a_index=1, was_split=False, old_locus=bi.locus, old_alleles=bi.alleles); >>> multi = mt.filter_rows(hl.len(mt.alleles) > 2); >>> split = hl.split_multi(multi); >>> mt = split.union_rows(bi). Example; -------. :func:`.split_multi_hts`, which splits multiallelic variants for the HTS; genotype schema and updates the entry fields by downcoding the genotype, is; implemented as:. >>> sm = hl.split_multi(ds); >>> pl = hl.or_missing(; ... hl.is_defined(sm.PL),; ... (hl.range(0, 3).map(lambda i: hl.min(hl.range(0, hl.len(sm.PL)); ... .filter(lambda j: hl.downcode(hl.unphased_diploid_gt_index_call(j), sm.a_index) == hl.unphased_diploid_gt_index_call(i)); ... .map(lambda j: sm.PL[j]))))); >>> split_ds = sm.annotate_entries(; ... GT=hl.downcode(sm.GT, sm.a_index),; ... AD=hl.or_missing(hl.is_defined(sm.AD),; ... [hl.sum(sm.AD) - sm.AD[sm.a_index], sm.AD[sm.a_index]]),; ... DP=sm.DP,; ... PL=pl,; ... GQ=hl.gq_from_pl(pl)).drop('old_locus', 'old_alleles'). See Also; --------; :func:`.split_multi_hts`. Parameters; ----------; ds : :class:`.MatrixTable` or :class:`.Table`; An unsplit dataset.; keep_star : :obj:`bool`; Do not filter out * alleles.; left_aligned : :obj:`bool`; If ``True``, variants are assumed to be left aligned and have unique; loci. This avoids a shuffle. If the assumption is",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:146646,Deployability,continuous,continuous,146646,"omogeneous modern populations that have; each diverged from a single ancestral population (a `star phylogeny`). Each; sample is assigned a population by sampling from the categorical; distribution :math:`\pi`. Note that the actual size of each population is; random. Variants are modeled as biallelic and unlinked. Ancestral allele; frequencies are drawn independently for each variant from a frequency; spectrum :math:`P_0`. The extent of genetic drift of each modern population; from the ancestral population is defined by the corresponding :math:`F_{ST}`; parameter :math:`F_k` (here and below, lowercase indices run over a range; bounded by the corresponding uppercase parameter, e.g. :math:`k = 1, \ldots,; K`). For each variant and population, allele frequencies are drawn from a; `beta distribution <https://en.wikipedia.org/wiki/Beta_distribution>`__; whose parameters are determined by the ancestral allele frequency and; :math:`F_{ST}` parameter. The beta distribution gives a continuous; approximation of the effect of genetic drift. We denote sample population; assignments by :math:`k_n`, ancestral allele frequencies by :math:`p_m`,; population allele frequencies by :math:`p_{k, m}`, and diploid, unphased; genotype calls by :math:`g_{n, m}` (0, 1, and 2 correspond to homozygous; reference, heterozygous, and homozygous variant, respectively). The generative model is then given by:. .. math::; \begin{aligned}; k_n \,&\sim\, \pi \\; p_m \,&\sim\, P_0 \\; p_{k,m} \mid p_m\,&\sim\, \mathrm{Beta}(\mu = p_m,\, \sigma^2 = F_k p_m (1 - p_m)) \\; g_{n,m} \mid k_n, p_{k, m} \,&\sim\, \mathrm{Binomial}(2, p_{k_n, m}); \end{aligned}. The beta distribution by its mean and variance above; the usual parameters; are :math:`a = (1 - p) \frac{1 - F}{F}` and :math:`b = p \frac{1 - F}{F}` with; :math:`F = F_k` and :math:`p = p_m`. The resulting dataset has the following fields. Global fields:. - `bn.n_populations` (:py:data:`.tint32`) -- Number of populations.; - `bn.n_samples` (:py:data:`.",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:155564,Deployability,update,update,155564,"s the modified `alleles`; field. If all alternate alleles of a variant are filtered out, the variant itself; is filtered out. **Using** `f`. The `f` argument is a function or lambda evaluated per alternate allele to; determine whether that allele is kept. If `f` evaluates to ``True``, the; allele is kept. If `f` evaluates to ``False`` or missing, the allele is; removed. `f` is a function that takes two arguments: the allele string (of type; :class:`.StringExpression`) and the allele index (of type; :class:`.Int32Expression`), and returns a boolean expression. This can; be either a defined function or a lambda. For example, these two usages; are equivalent:. (with a lambda). >>> ds_result = hl.filter_alleles(ds, lambda allele, i: hl.is_snp(ds.alleles[0], allele)). (with a defined function). >>> def filter_f(allele, allele_index):; ... return hl.is_snp(ds.alleles[0], allele); >>> ds_result = hl.filter_alleles(ds, filter_f). Warning; -------; :func:`.filter_alleles` does not update any fields other than `locus` and; `alleles`. This means that row fields like allele count (AC) and entry; fields like allele depth (AD) can become meaningless unless they are also; updated. You can update them with :meth:`.annotate_rows` and; :meth:`.annotate_entries`. See Also; --------; :func:`.filter_alleles_hts`. Parameters; ----------; mt : :class:`.MatrixTable`; Dataset.; f : callable; Function from (allele: :class:`.StringExpression`, allele_index:; :class:`.Int32Expression`) to :class:`.BooleanExpression`. Returns; -------; :class:`.MatrixTable`; """"""; require_row_key_variant(mt, 'filter_alleles'); inclusion = hl.range(0, hl.len(mt.alleles)).map(lambda i: (i == 0) | hl.bind(lambda ii: f(mt.alleles[ii], ii), i)). # old locus, old alleles, new to old, old to new; mt = mt.annotate_rows(__allele_inclusion=inclusion, old_locus=mt.locus, old_alleles=mt.alleles); new_to_old = hl.enumerate(mt.__allele_inclusion).filter(lambda elt: elt[1]).map(lambda elt: elt[0]); old_to_new_dict = hl.dict(; h",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:155753,Deployability,update,updated,155753," filtered out. **Using** `f`. The `f` argument is a function or lambda evaluated per alternate allele to; determine whether that allele is kept. If `f` evaluates to ``True``, the; allele is kept. If `f` evaluates to ``False`` or missing, the allele is; removed. `f` is a function that takes two arguments: the allele string (of type; :class:`.StringExpression`) and the allele index (of type; :class:`.Int32Expression`), and returns a boolean expression. This can; be either a defined function or a lambda. For example, these two usages; are equivalent:. (with a lambda). >>> ds_result = hl.filter_alleles(ds, lambda allele, i: hl.is_snp(ds.alleles[0], allele)). (with a defined function). >>> def filter_f(allele, allele_index):; ... return hl.is_snp(ds.alleles[0], allele); >>> ds_result = hl.filter_alleles(ds, filter_f). Warning; -------; :func:`.filter_alleles` does not update any fields other than `locus` and; `alleles`. This means that row fields like allele count (AC) and entry; fields like allele depth (AD) can become meaningless unless they are also; updated. You can update them with :meth:`.annotate_rows` and; :meth:`.annotate_entries`. See Also; --------; :func:`.filter_alleles_hts`. Parameters; ----------; mt : :class:`.MatrixTable`; Dataset.; f : callable; Function from (allele: :class:`.StringExpression`, allele_index:; :class:`.Int32Expression`) to :class:`.BooleanExpression`. Returns; -------; :class:`.MatrixTable`; """"""; require_row_key_variant(mt, 'filter_alleles'); inclusion = hl.range(0, hl.len(mt.alleles)).map(lambda i: (i == 0) | hl.bind(lambda ii: f(mt.alleles[ii], ii), i)). # old locus, old alleles, new to old, old to new; mt = mt.annotate_rows(__allele_inclusion=inclusion, old_locus=mt.locus, old_alleles=mt.alleles); new_to_old = hl.enumerate(mt.__allele_inclusion).filter(lambda elt: elt[1]).map(lambda elt: elt[0]); old_to_new_dict = hl.dict(; hl.enumerate(hl.enumerate(mt.alleles).filter(lambda elt: mt.__allele_inclusion[elt[0]])).map(; lambda elt: (elt[",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:155770,Deployability,update,update,155770,"nate allele to; determine whether that allele is kept. If `f` evaluates to ``True``, the; allele is kept. If `f` evaluates to ``False`` or missing, the allele is; removed. `f` is a function that takes two arguments: the allele string (of type; :class:`.StringExpression`) and the allele index (of type; :class:`.Int32Expression`), and returns a boolean expression. This can; be either a defined function or a lambda. For example, these two usages; are equivalent:. (with a lambda). >>> ds_result = hl.filter_alleles(ds, lambda allele, i: hl.is_snp(ds.alleles[0], allele)). (with a defined function). >>> def filter_f(allele, allele_index):; ... return hl.is_snp(ds.alleles[0], allele); >>> ds_result = hl.filter_alleles(ds, filter_f). Warning; -------; :func:`.filter_alleles` does not update any fields other than `locus` and; `alleles`. This means that row fields like allele count (AC) and entry; fields like allele depth (AD) can become meaningless unless they are also; updated. You can update them with :meth:`.annotate_rows` and; :meth:`.annotate_entries`. See Also; --------; :func:`.filter_alleles_hts`. Parameters; ----------; mt : :class:`.MatrixTable`; Dataset.; f : callable; Function from (allele: :class:`.StringExpression`, allele_index:; :class:`.Int32Expression`) to :class:`.BooleanExpression`. Returns; -------; :class:`.MatrixTable`; """"""; require_row_key_variant(mt, 'filter_alleles'); inclusion = hl.range(0, hl.len(mt.alleles)).map(lambda i: (i == 0) | hl.bind(lambda ii: f(mt.alleles[ii], ii), i)). # old locus, old alleles, new to old, old to new; mt = mt.annotate_rows(__allele_inclusion=inclusion, old_locus=mt.locus, old_alleles=mt.alleles); new_to_old = hl.enumerate(mt.__allele_inclusion).filter(lambda elt: elt[1]).map(lambda elt: elt[0]); old_to_new_dict = hl.dict(; hl.enumerate(hl.enumerate(mt.alleles).filter(lambda elt: mt.__allele_inclusion[elt[0]])).map(; lambda elt: (elt[1][1], elt[0]); ); ). old_to_new = hl.bind(lambda d: mt.alleles.map(lambda a: d.get(a)), ",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:157652,Deployability,update,update,157652,"hl.enumerate(hl.enumerate(mt.alleles).filter(lambda elt: mt.__allele_inclusion[elt[0]])).map(; lambda elt: (elt[1][1], elt[0]); ); ). old_to_new = hl.bind(lambda d: mt.alleles.map(lambda a: d.get(a)), old_to_new_dict); mt = mt.annotate_rows(old_to_new=old_to_new, new_to_old=new_to_old); new_locus_alleles = hl.min_rep(mt.locus, mt.new_to_old.map(lambda i: mt.alleles[i])); mt = mt.annotate_rows(__new_locus=new_locus_alleles.locus, __new_alleles=new_locus_alleles.alleles); mt = mt.filter_rows(hl.len(mt.__new_alleles) > 1); left = mt.filter_rows((mt.locus == mt.__new_locus) & (mt.alleles == mt.__new_alleles)). right = mt.filter_rows((mt.locus != mt.__new_locus) | (mt.alleles != mt.__new_alleles)); right = right.key_rows_by(locus=right.__new_locus, alleles=right.__new_alleles); return left.union_rows(right, _check_cols=False).drop('__allele_inclusion', '__new_locus', '__new_alleles'). [docs]@typecheck(mt=MatrixTable, f=anytype, subset=bool); def filter_alleles_hts(mt: MatrixTable, f: Callable, subset: bool = False) -> MatrixTable:; """"""Filter alternate alleles and update standard GATK entry fields. Examples; --------; Filter to SNP alleles using the subset strategy:. >>> ds_result = hl.filter_alleles_hts(; ... ds,; ... lambda allele, _: hl.is_snp(ds.alleles[0], allele),; ... subset=True). Update the AC field of the resulting dataset:. >>> updated_info = ds_result.info.annotate(AC = ds_result.new_to_old.map(lambda i: ds_result.info.AC[i-1])); >>> ds_result = ds_result.annotate_rows(info = updated_info). Notes; -----; For usage of the `f` argument, see the :func:`.filter_alleles`; documentation. :func:`.filter_alleles_hts` requires the dataset have the GATK VCF schema,; namely the following entry fields in this order:. .. code-block:: text. GT: call; AD: array<int32>; DP: int32; GQ: int32; PL: array<int32>. Use :meth:`.MatrixTable.select_entries` to rearrange these fields if; necessary. The following new fields are generated:. - `old_locus` (``locus``) -- The old locus, befo",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:161986,Deployability,update,update,161986,"iltered alleles) and; then sets GT to the genotype with the minimum PL. Note that; if the genotype changes (as in the example), the PLs are; re-normalized (shifted) so that the most likely genotype has a; PL of 0. Qualitatively, subsetting corresponds to the belief; that the filtered alleles are not real so we should discard; any probability mass associated with them. The subset algorithm would produce the following:. .. code-block:: text. GT: 1/1; GQ: 980; AD: 0,50. 0 | 980; 1 | 980 0; +-----------; 0 1. In summary:. - GT: Set to most likely genotype based on the PLs ignoring; the filtered allele(s).; - AD: The filtered alleles' columns are eliminated, e.g.,; filtering alleles 1 and 2 transforms ``25,5,10,20`` to; ``25,20``.; - DP: Unchanged.; - PL: Columns involving filtered alleles are eliminated and; the remaining columns' values are shifted so the minimum; value is 0.; - GQ: The second-lowest PL (after shifting). Warning; -------; :func:`.filter_alleles_hts` does not update any row fields other than; `locus` and `alleles`. This means that row fields like allele count (AC) can; become meaningless unless they are also updated. You can update them with; :meth:`.annotate_rows`. See Also; --------; :func:`.filter_alleles`. Parameters; ----------; mt : :class:`.MatrixTable`; f : callable; Function from (allele: :class:`.StringExpression`, allele_index:; :class:`.Int32Expression`) to :class:`.BooleanExpression`; subset : :obj:`.bool`; Subset PL field if ``True``, otherwise downcode PL field. The; calculation of GT and GQ also depend on whether one subsets or; downcodes the PL. Returns; -------; :class:`.MatrixTable`; """"""; if mt.entry.dtype != hl.hts_entry_schema:; raise FatalError(; ""'filter_alleles_hts': entry schema must be the HTS entry schema:\n""; "" found: {}\n""; "" expected: {}\n""; "" Use 'hl.filter_alleles' to split entries with non-HTS entry fields."".format(; mt.entry.dtype, hl.hts_entry_schema; ); ). mt = filter_alleles(mt, f). if subset:; newPL = hl.if_else(; hl",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:162138,Deployability,update,updated,162138,"ype changes (as in the example), the PLs are; re-normalized (shifted) so that the most likely genotype has a; PL of 0. Qualitatively, subsetting corresponds to the belief; that the filtered alleles are not real so we should discard; any probability mass associated with them. The subset algorithm would produce the following:. .. code-block:: text. GT: 1/1; GQ: 980; AD: 0,50. 0 | 980; 1 | 980 0; +-----------; 0 1. In summary:. - GT: Set to most likely genotype based on the PLs ignoring; the filtered allele(s).; - AD: The filtered alleles' columns are eliminated, e.g.,; filtering alleles 1 and 2 transforms ``25,5,10,20`` to; ``25,20``.; - DP: Unchanged.; - PL: Columns involving filtered alleles are eliminated and; the remaining columns' values are shifted so the minimum; value is 0.; - GQ: The second-lowest PL (after shifting). Warning; -------; :func:`.filter_alleles_hts` does not update any row fields other than; `locus` and `alleles`. This means that row fields like allele count (AC) can; become meaningless unless they are also updated. You can update them with; :meth:`.annotate_rows`. See Also; --------; :func:`.filter_alleles`. Parameters; ----------; mt : :class:`.MatrixTable`; f : callable; Function from (allele: :class:`.StringExpression`, allele_index:; :class:`.Int32Expression`) to :class:`.BooleanExpression`; subset : :obj:`.bool`; Subset PL field if ``True``, otherwise downcode PL field. The; calculation of GT and GQ also depend on whether one subsets or; downcodes the PL. Returns; -------; :class:`.MatrixTable`; """"""; if mt.entry.dtype != hl.hts_entry_schema:; raise FatalError(; ""'filter_alleles_hts': entry schema must be the HTS entry schema:\n""; "" found: {}\n""; "" expected: {}\n""; "" Use 'hl.filter_alleles' to split entries with non-HTS entry fields."".format(; mt.entry.dtype, hl.hts_entry_schema; ); ). mt = filter_alleles(mt, f). if subset:; newPL = hl.if_else(; hl.is_defined(mt.PL),; hl.bind(; lambda unnorm: unnorm - hl.min(unnorm),; hl.range(0, hl.triangl",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:162155,Deployability,update,update,162155," so that the most likely genotype has a; PL of 0. Qualitatively, subsetting corresponds to the belief; that the filtered alleles are not real so we should discard; any probability mass associated with them. The subset algorithm would produce the following:. .. code-block:: text. GT: 1/1; GQ: 980; AD: 0,50. 0 | 980; 1 | 980 0; +-----------; 0 1. In summary:. - GT: Set to most likely genotype based on the PLs ignoring; the filtered allele(s).; - AD: The filtered alleles' columns are eliminated, e.g.,; filtering alleles 1 and 2 transforms ``25,5,10,20`` to; ``25,20``.; - DP: Unchanged.; - PL: Columns involving filtered alleles are eliminated and; the remaining columns' values are shifted so the minimum; value is 0.; - GQ: The second-lowest PL (after shifting). Warning; -------; :func:`.filter_alleles_hts` does not update any row fields other than; `locus` and `alleles`. This means that row fields like allele count (AC) can; become meaningless unless they are also updated. You can update them with; :meth:`.annotate_rows`. See Also; --------; :func:`.filter_alleles`. Parameters; ----------; mt : :class:`.MatrixTable`; f : callable; Function from (allele: :class:`.StringExpression`, allele_index:; :class:`.Int32Expression`) to :class:`.BooleanExpression`; subset : :obj:`.bool`; Subset PL field if ``True``, otherwise downcode PL field. The; calculation of GT and GQ also depend on whether one subsets or; downcodes the PL. Returns; -------; :class:`.MatrixTable`; """"""; if mt.entry.dtype != hl.hts_entry_schema:; raise FatalError(; ""'filter_alleles_hts': entry schema must be the HTS entry schema:\n""; "" found: {}\n""; "" expected: {}\n""; "" Use 'hl.filter_alleles' to split entries with non-HTS entry fields."".format(; mt.entry.dtype, hl.hts_entry_schema; ); ). mt = filter_alleles(mt, f). if subset:; newPL = hl.if_else(; hl.is_defined(mt.PL),; hl.bind(; lambda unnorm: unnorm - hl.min(unnorm),; hl.range(0, hl.triangle(mt.alleles.length())).map(; lambda newi: hl.bind(; lambda newc: mt.P",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:172830,Deployability,update,updated,172830,"pruned_table.locus, bp_window_size). entries = r2_bm.sparsify_row_intervals(range(stops.size), stops, blocks_only=True).entries(keyed=False); entries = entries.filter((entries.entry >= r2) & (entries.i < entries.j)); entries = entries.select(i=hl.int32(entries.i), j=hl.int32(entries.j)). if keep_higher_maf:; fields = ['mean', 'locus']; else:; fields = ['locus']. info = locally_pruned_table.aggregate(; hl.agg.collect(locally_pruned_table.row.select('idx', *fields)), _localize=False; ); info = hl.sorted(info, key=lambda x: x.idx). entries = entries.annotate_globals(info=info). entries = entries.filter(; (entries.info[entries.i].locus.contig == entries.info[entries.j].locus.contig); & (entries.info[entries.j].locus.position - entries.info[entries.i].locus.position <= bp_window_size); ). if keep_higher_maf:; entries = entries.annotate(; i=hl.struct(; idx=entries.i, twice_maf=hl.min(entries.info[entries.i].mean, 2.0 - entries.info[entries.i].mean); ),; j=hl.struct(; idx=entries.j, twice_maf=hl.min(entries.info[entries.j].mean, 2.0 - entries.info[entries.j].mean); ),; ). def tie_breaker(left, right):; return hl.sign(right.twice_maf - left.twice_maf). else:; tie_breaker = None. variants_to_remove = hl.maximal_independent_set(; entries.i, entries.j, keep=False, tie_breaker=tie_breaker, keyed=False; ). locally_pruned_table = locally_pruned_table.annotate_globals(; variants_to_remove=variants_to_remove.aggregate(; hl.agg.collect_as_set(variants_to_remove.node.idx), _localize=False; ); ); return (; locally_pruned_table.filter(; locally_pruned_table.variants_to_remove.contains(hl.int32(locally_pruned_table.idx)), keep=False; ); .select(); .persist(); ). def _warn_if_no_intercept(caller, covariates):; if all([e._indices.axes for e in covariates]):; warning(; f'{caller}: model appears to have no intercept covariate.'; '\n To include an intercept, add 1.0 to the list of covariates.'; ); return True; return False. © Copyright 2015-2024, Hail Team.; Last updated on Oct 04, 2024.; . ",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:33668,Energy Efficiency,reduce,reduces,33668,"=== ====== === ======; Status HomRef Het HomVar; ======= ====== === ======; Case 1000 10 0; Control 1000 0 0; ======= ====== === ======. The following R code fits the (standard) logistic, Firth logistic,; and linear regression models to this data, where ``x`` is genotype,; ``y`` is phenotype, and ``logistf`` is from the logistf package:. .. code-block:: R. x <- c(rep(0,1000), rep(1,1000), rep(1,10); y <- c(rep(0,1000), rep(0,1000), rep(1,10)); logfit <- glm(y ~ x, family=binomial()); firthfit <- logistf(y ~ x); linfit <- lm(y ~ x). The resulting p-values for the genotype coefficient are 0.991, 0.00085,; and 0.0016, respectively. The erroneous value 0.991 is due to; quasi-complete separation. Moving one of the 10 hets from case to control; eliminates this quasi-complete separation; the p-values from R are then; 0.0373, 0.0111, and 0.0116, respectively, as expected for a less; significant association. The Firth test reduces bias from small counts and resolves the issue of; separation by penalizing maximum likelihood estimation by the `Jeffrey's; invariant prior <https://en.wikipedia.org/wiki/Jeffreys_prior>`__. This test; is slower, as both the null and full model must be fit per variant, and; convergence of the modified Newton method is linear rather than; quadratic. For Firth, 100 iterations are attempted by default for the null; model and, if that is successful, for the full model as well. In testing we; find 20 iterations nearly always suffices. If the null model fails to; converge, then the `logreg.fit` fields reflect the null model; otherwise,; they reflect the full model. See; `Recommended joint and meta-analysis strategies for case-control association testing of single low-count variants <http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4049324/>`__; for an empirical comparison of the logistic Wald, LRT, score, and Firth; tests. The theoretical foundations of the Wald, likelihood ratio, and score; tests may be found in Chapter 3 of Gesine Reinert's notes; `Statisti",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:54124,Energy Efficiency,reduce,reduces,54124,"=== ====== === ======; Status HomRef Het HomVar; ======= ====== === ======; Case 1000 10 0; Control 1000 0 0; ======= ====== === ======. The following R code fits the (standard) logistic, Firth logistic,; and linear regression models to this data, where ``x`` is genotype,; ``y`` is phenotype, and ``logistf`` is from the logistf package:. .. code-block:: R. x <- c(rep(0,1000), rep(1,1000), rep(1,10); y <- c(rep(0,1000), rep(0,1000), rep(1,10)); logfit <- glm(y ~ x, family=binomial()); firthfit <- logistf(y ~ x); linfit <- lm(y ~ x). The resulting p-values for the genotype coefficient are 0.991, 0.00085,; and 0.0016, respectively. The erroneous value 0.991 is due to; quasi-complete separation. Moving one of the 10 hets from case to control; eliminates this quasi-complete separation; the p-values from R are then; 0.0373, 0.0111, and 0.0116, respectively, as expected for a less; significant association. The Firth test reduces bias from small counts and resolves the issue of; separation by penalizing maximum likelihood estimation by the `Jeffrey's; invariant prior <https://en.wikipedia.org/wiki/Jeffreys_prior>`__. This; test is slower, as both the null and full model must be fit per variant,; and convergence of the modified Newton method is linear rather than; quadratic. For Firth, 100 iterations are attempted for the null model; and, if that is successful, for the full model as well. In testing we; find 20 iterations nearly always suffices. If the null model fails to; converge, then the `logreg.fit` fields reflect the null model;; otherwise, they reflect the full model. See; `Recommended joint and meta-analysis strategies for case-control association testing of single low-count variants <http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4049324/>`__; for an empirical comparison of the logistic Wald, LRT, score, and Firth; tests. The theoretical foundations of the Wald, likelihood ratio, and score; tests may be found in Chapter 3 of Gesine Reinert's notes; `Statistical Theory ",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:81671,Energy Efficiency,reduce,reduced,81671,"ot explained by the covariates alone. - s2 : :obj:`.tfloat64`, the variance of the residuals, :math:`\sigma^2` in the paper. """"""; mt = matrix_table_source('skat/x', x); k = len(covariates); if k == 0:; raise ValueError('_linear_skat: at least one covariate is required.'); _warn_if_no_intercept('_linear_skat', covariates); mt = mt._select_all(; row_exprs=dict(group=group, weight=weight), col_exprs=dict(y=y, covariates=covariates), entry_exprs=dict(x=x); ); mt = mt.filter_cols(hl.all(hl.is_defined(mt.y), *[hl.is_defined(mt.covariates[i]) for i in range(k)])); yvec, covmat, n = mt.aggregate_cols(; (hl.agg.collect(hl.float(mt.y)), hl.agg.collect(mt.covariates.map(hl.float)), hl.agg.count()), _localize=False; ); mt = mt.annotate_globals(yvec=hl.nd.array(yvec), covmat=hl.nd.array(covmat), n_complete_samples=n); # Instead of finding the best-fit beta, we go directly to the best-predicted value using the; # reduced QR decomposition:; #; # Q @ R = X; # y = X beta; # X^T y = X^T X beta; # (X^T X)^-1 X^T y = beta; # (R^T Q^T Q R)^-1 R^T Q^T y = beta; # (R^T R)^-1 R^T Q^T y = beta; # R^-1 R^T^-1 R^T Q^T y = beta; # R^-1 Q^T y = beta; #; # X beta = X R^-1 Q^T y; # = Q R R^-1 Q^T y; # = Q Q^T y; #; covmat_Q, _ = hl.nd.qr(mt.covmat); mt = mt.annotate_globals(covmat_Q=covmat_Q); null_mu = mt.covmat_Q @ (mt.covmat_Q.T @ mt.yvec); y_residual = mt.yvec - null_mu; mt = mt.annotate_globals(y_residual=y_residual, s2=y_residual @ y_residual.T / (n - k)); mt = mt.annotate_rows(G_row_mean=hl.agg.mean(mt.x)); mt = mt.annotate_rows(G_row=hl.agg.collect(hl.coalesce(mt.x, mt.G_row_mean))); ht = mt.rows(); ht = ht.filter(hl.all(hl.is_defined(ht.group), hl.is_defined(ht.weight))); ht = ht.group_by('group').aggregate(; weight_take=hl.agg.take(ht.weight, n=max_size + 1),; G_take=hl.agg.take(ht.G_row, n=max_size + 1),; size=hl.agg.count(),; ); ht = ht.annotate(; weight=hl.nd.array(hl.or_missing(hl.len(ht.weight_take) <= max_size, ht.weight_take)),; G=hl.nd.array(hl.or_missing(hl.len(ht.G_take) <= ma",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:83030,Energy Efficiency,reduce,reduced,83030,"); null_mu = mt.covmat_Q @ (mt.covmat_Q.T @ mt.yvec); y_residual = mt.yvec - null_mu; mt = mt.annotate_globals(y_residual=y_residual, s2=y_residual @ y_residual.T / (n - k)); mt = mt.annotate_rows(G_row_mean=hl.agg.mean(mt.x)); mt = mt.annotate_rows(G_row=hl.agg.collect(hl.coalesce(mt.x, mt.G_row_mean))); ht = mt.rows(); ht = ht.filter(hl.all(hl.is_defined(ht.group), hl.is_defined(ht.weight))); ht = ht.group_by('group').aggregate(; weight_take=hl.agg.take(ht.weight, n=max_size + 1),; G_take=hl.agg.take(ht.G_row, n=max_size + 1),; size=hl.agg.count(),; ); ht = ht.annotate(; weight=hl.nd.array(hl.or_missing(hl.len(ht.weight_take) <= max_size, ht.weight_take)),; G=hl.nd.array(hl.or_missing(hl.len(ht.G_take) <= max_size, ht.G_take)).T,; ); ht = ht.annotate(Q=((ht.y_residual @ ht.G).map(lambda x: x**2) * ht.weight).sum(0)). # Null model:; #; # y = X b + e, e ~ N(0, \sigma^2); #; # We can find a best-fit b, bhat, and a best-fit y, yhat:; #; # bhat = (X.T X).inv X.T y; #; # Q R = X (reduced QR decomposition); # bhat = R.inv Q.T y; #; # yhat = X bhat; # = Q R R.inv Q.T y; # = Q Q.T y; #; # The residual phenotype not captured by the covariates alone is r:; #; # r = y - yhat; # = (I - Q Q.T) y; #; # We can factor the Q-statistic (note there are two Qs: the Q from the QR decomposition and the; # Q-statistic from the paper):; #; # Q = r.T G diag(w) G.T r; # Z = r.T G diag(sqrt(w)); # Q = Z Z.T; #; # Plugging in our expresion for r:; #; # Z = y.T (I - Q Q.T) G diag(sqrt(w)); #; # Notice that I - Q Q.T is symmetric (ergo X = X.T) because each summand is symmetric and sums; # of symmetric matrices are symmetric matrices.; #; # We have asserted that; #; # y ~ N(0, \sigma^2); #; # It will soon be apparent that the distribution of Q is easier to characterize if our random; # variables are standard normals:; #; # h ~ N(0, 1); # y = \sigma h; #; # We set \sigma^2 to the sample variance of the residual vectors.; #; # Returning to Z:; #; # Z = h.T \sigma (I - Q Q.T) G diag(sqrt(w)); # Q =",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:89697,Energy Efficiency,reduce,reduced,89697,"etric positive-definite matrix when the weights are non-negative. We describe below our interpretation of the mathematics as described in the main body and; appendix of Wu, et al. According to the paper, the distribution of :math:`Q` is given by a; generalized chi-squared distribution whose weights are the eigenvalues of a symmetric matrix; which we call :math:`Z Z^T`:. .. math::. \begin{align*}; V_{ii} &= \sigma^2_i \\; W_{ii} &= w_i \quad\quad \textrm{the weight for variant } i \\; \\; P_0 &= V - V X (X^T V X)^{-1} X^T V \\; Z Z^T &= P_0^{1/2} G W G^T P_0^{1/2}; \end{align*}. The eigenvalues of :math:`Z Z^T` and :math:`Z^T Z` are the squared singular values of :math:`Z`;; therefore, we instead focus on :math:`Z^T Z`. In the expressions below, we elide transpositions; of symmetric matrices:. .. math::. \begin{align*}; Z Z^T &= P_0^{1/2} G W G^T P_0^{1/2} \\; Z &= P_0^{1/2} G W^{1/2} \\; Z^T Z &= W^{1/2} G^T P_0 G W^{1/2}; \end{align*}. Before substituting the definition of :math:`P_0`, simplify it using the reduced QR; decomposition:. .. math::. \begin{align*}; Q R &= V^{1/2} X \\; R^T Q^T &= X^T V^{1/2} \\; \\; P_0 &= V - V X (X^T V X)^{-1} X^T V \\; &= V - V X (R^T Q^T Q R)^{-1} X^T V \\; &= V - V X (R^T R)^{-1} X^T V \\; &= V - V X R^{-1} (R^T)^{-1} X^T V \\; &= V - V^{1/2} Q (R^T)^{-1} X^T V^{1/2} \\; &= V - V^{1/2} Q Q^T V^{1/2} \\; &= V^{1/2} (I - Q Q^T) V^{1/2} \\; \end{align*}. Substitute this simplified expression into :math:`Z`:. .. math::. \begin{align*}; Z^T Z &= W^{1/2} G^T V^{1/2} (I - Q Q^T) V^{1/2} G W^{1/2} \\; \end{align*}. Split this symmetric matrix by observing that :math:`I - Q Q^T` is idempotent:. .. math::. \begin{align*}; I - Q Q^T &= (I - Q Q^T)(I - Q Q^T)^T \\; \\; Z &= (I - Q Q^T) V^{1/2} G W^{1/2} \\; Z &= (G - Q Q^T G) V^{1/2} W^{1/2}; \end{align*}. Finally, the squared singular values of :math:`Z` are the eigenvalues of :math:`Z^T Z`, so; :math:`Q` should be distributed as follows:. .. math::. \begin{align*}; U S V^T &= Z \quad\quad \t",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
https://hail.is/docs/0.2/_modules/hail/methods/statgen.html:112204,Energy Efficiency,efficient,efficient,112204," yourself using; one of the entry modification methods: :meth:`.MatrixTable.annotate_entries`,; :meth:`.MatrixTable.select_entries`, :meth:`.MatrixTable.transmute_entries`. The resulting dataset will be keyed by the split locus and alleles. :func:`.split_multi` adds the following fields:. - `was_split` (*bool*) -- ``True`` if this variant was originally; multiallelic, otherwise ``False``. - `a_index` (*int*) -- The original index of this alternate allele in the; multiallelic representation (NB: 1 is the first alternate allele or the; only alternate allele in a biallelic variant). For example, 1:100:A:T,C; splits into two variants: 1:100:A:T with ``a_index = 1`` and 1:100:A:C; with ``a_index = 2``. - `old_locus` (*locus*) -- The original, unsplit locus. - `old_alleles` (*array<str>*) -- The original, unsplit alleles. All other fields are left unchanged. Warning; -------; This method assumes `ds` contains at most one non-split variant per locus. This assumption permits the; most efficient implementation of the splitting algorithm. If your queries involving `split_multi`; crash with errors about out-of-order keys, this assumption may be violated. Otherwise, this; warning likely does not apply to your dataset. If each locus in `ds` contains one multiallelic variant and one or more biallelic variants, you; can filter to the multiallelic variants, split those, and then combine the split variants with; the original biallelic variants. For example, the following code splits a dataset `mt` which contains a mixture of split and; non-split variants. >>> bi = mt.filter_rows(hl.len(mt.alleles) == 2); >>> bi = bi.annotate_rows(a_index=1, was_split=False, old_locus=bi.locus, old_alleles=bi.alleles); >>> multi = mt.filter_rows(hl.len(mt.alleles) > 2); >>> split = hl.split_multi(multi); >>> mt = split.union_rows(bi). Example; -------. :func:`.split_multi_hts`, which splits multiallelic variants for the HTS; genotype schema and updates the entry fields by downcoding the genotype, is; ",MatchSource.WIKI,docs/0.2/_modules/hail/methods/statgen.html,hail-is,hail,0.2.133,https://hail.is,https://hail.is/docs/0.2/_modules/hail/methods/statgen.html
