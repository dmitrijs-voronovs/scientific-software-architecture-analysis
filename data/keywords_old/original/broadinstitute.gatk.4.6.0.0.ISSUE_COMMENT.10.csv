id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/broadinstitute/gatk/issues/5499#issuecomment-446254485:46,Deployability,upgrade,upgrade,46,gradle people are also saying that you should upgrade to the latest version of gradle: https://github.com/gradle/gradle/issues/7973,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5499#issuecomment-446254485
https://github.com/broadinstitute/gatk/pull/5510#issuecomment-446687690:26,Testability,test,test,26,@takutosato sorry for the test fails. They are resolved now.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5510#issuecomment-446687690
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446225974:42,Availability,failure,failures,42,"@rick-heig I wouldn't expect to see those failures, so I think something is wrong. Are these the only tests in the entire suite that fail ? We pretty regularly run these tests on Ubuntu 16.04. Also please verify that you did install git-lfs and fetched the large files per the instructions in the README.md file ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446225974
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446225974:225,Deployability,install,install,225,"@rick-heig I wouldn't expect to see those failures, so I think something is wrong. Are these the only tests in the entire suite that fail ? We pretty regularly run these tests on Ubuntu 16.04. Also please verify that you did install git-lfs and fetched the large files per the instructions in the README.md file ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446225974
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446225974:102,Testability,test,tests,102,"@rick-heig I wouldn't expect to see those failures, so I think something is wrong. Are these the only tests in the entire suite that fail ? We pretty regularly run these tests on Ubuntu 16.04. Also please verify that you did install git-lfs and fetched the large files per the instructions in the README.md file ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446225974
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446225974:170,Testability,test,tests,170,"@rick-heig I wouldn't expect to see those failures, so I think something is wrong. Are these the only tests in the entire suite that fail ? We pretty regularly run these tests on Ubuntu 16.04. Also please verify that you did install git-lfs and fetched the large files per the instructions in the README.md file ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446225974
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446230121:465,Availability,down,downloaded,465,"I get : `500032 tests completed, 20 failed, 1 skipped`. The 2 extra failed tests are spark related (I don't have a spark setup so I assume this is normal); `ExampleAssemblyRegionWalkerSparkIntegrationTest. testExampleAssemblyRegionWalkerNonStrict`; `ExampleAssemblyRegionWalkerSparkIntegrationTest. testExampleAssemblyRegionWalkerStrict`; The skipped test is `testLikelihoodsFromHaplotypes[2](null, false)` in the `VectorPairHMMUnitTest`. I did install git-lfs and downloaded all the required files per the instructions, the files are up to date.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446230121
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446230121:445,Deployability,install,install,445,"I get : `500032 tests completed, 20 failed, 1 skipped`. The 2 extra failed tests are spark related (I don't have a spark setup so I assume this is normal); `ExampleAssemblyRegionWalkerSparkIntegrationTest. testExampleAssemblyRegionWalkerNonStrict`; `ExampleAssemblyRegionWalkerSparkIntegrationTest. testExampleAssemblyRegionWalkerStrict`; The skipped test is `testLikelihoodsFromHaplotypes[2](null, false)` in the `VectorPairHMMUnitTest`. I did install git-lfs and downloaded all the required files per the instructions, the files are up to date.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446230121
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446230121:16,Testability,test,tests,16,"I get : `500032 tests completed, 20 failed, 1 skipped`. The 2 extra failed tests are spark related (I don't have a spark setup so I assume this is normal); `ExampleAssemblyRegionWalkerSparkIntegrationTest. testExampleAssemblyRegionWalkerNonStrict`; `ExampleAssemblyRegionWalkerSparkIntegrationTest. testExampleAssemblyRegionWalkerStrict`; The skipped test is `testLikelihoodsFromHaplotypes[2](null, false)` in the `VectorPairHMMUnitTest`. I did install git-lfs and downloaded all the required files per the instructions, the files are up to date.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446230121
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446230121:75,Testability,test,tests,75,"I get : `500032 tests completed, 20 failed, 1 skipped`. The 2 extra failed tests are spark related (I don't have a spark setup so I assume this is normal); `ExampleAssemblyRegionWalkerSparkIntegrationTest. testExampleAssemblyRegionWalkerNonStrict`; `ExampleAssemblyRegionWalkerSparkIntegrationTest. testExampleAssemblyRegionWalkerStrict`; The skipped test is `testLikelihoodsFromHaplotypes[2](null, false)` in the `VectorPairHMMUnitTest`. I did install git-lfs and downloaded all the required files per the instructions, the files are up to date.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446230121
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446230121:206,Testability,test,testExampleAssemblyRegionWalkerNonStrict,206,"I get : `500032 tests completed, 20 failed, 1 skipped`. The 2 extra failed tests are spark related (I don't have a spark setup so I assume this is normal); `ExampleAssemblyRegionWalkerSparkIntegrationTest. testExampleAssemblyRegionWalkerNonStrict`; `ExampleAssemblyRegionWalkerSparkIntegrationTest. testExampleAssemblyRegionWalkerStrict`; The skipped test is `testLikelihoodsFromHaplotypes[2](null, false)` in the `VectorPairHMMUnitTest`. I did install git-lfs and downloaded all the required files per the instructions, the files are up to date.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446230121
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446230121:299,Testability,test,testExampleAssemblyRegionWalkerStrict,299,"I get : `500032 tests completed, 20 failed, 1 skipped`. The 2 extra failed tests are spark related (I don't have a spark setup so I assume this is normal); `ExampleAssemblyRegionWalkerSparkIntegrationTest. testExampleAssemblyRegionWalkerNonStrict`; `ExampleAssemblyRegionWalkerSparkIntegrationTest. testExampleAssemblyRegionWalkerStrict`; The skipped test is `testLikelihoodsFromHaplotypes[2](null, false)` in the `VectorPairHMMUnitTest`. I did install git-lfs and downloaded all the required files per the instructions, the files are up to date.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446230121
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446230121:351,Testability,test,test,351,"I get : `500032 tests completed, 20 failed, 1 skipped`. The 2 extra failed tests are spark related (I don't have a spark setup so I assume this is normal); `ExampleAssemblyRegionWalkerSparkIntegrationTest. testExampleAssemblyRegionWalkerNonStrict`; `ExampleAssemblyRegionWalkerSparkIntegrationTest. testExampleAssemblyRegionWalkerStrict`; The skipped test is `testLikelihoodsFromHaplotypes[2](null, false)` in the `VectorPairHMMUnitTest`. I did install git-lfs and downloaded all the required files per the instructions, the files are up to date.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446230121
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446230121:360,Testability,test,testLikelihoodsFromHaplotypes,360,"I get : `500032 tests completed, 20 failed, 1 skipped`. The 2 extra failed tests are spark related (I don't have a spark setup so I assume this is normal); `ExampleAssemblyRegionWalkerSparkIntegrationTest. testExampleAssemblyRegionWalkerNonStrict`; `ExampleAssemblyRegionWalkerSparkIntegrationTest. testExampleAssemblyRegionWalkerStrict`; The skipped test is `testLikelihoodsFromHaplotypes[2](null, false)` in the `VectorPairHMMUnitTest`. I did install git-lfs and downloaded all the required files per the instructions, the files are up to date.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446230121
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446578316:260,Availability,failure,failures,260,"Hello.; If I launch the tests by themselves with the following command they all pass; ```; $ ./gradlew test --tests org.broadinstitute.hellbender.tools.walkers.variantutils.LeftAlignAndTrimVariantsUnitTest; ...; Results: SUCCESS (3611 tests, 3611 successes, 0 failures, 0 skipped). BUILD SUCCESSFUL. Total time: 22.445 secs; ```. But when launching all the tests altogether I get; ```; $ ./gradlew test; ...; Results: FAILURE (500032 tests, 500011 successes, 20 failures, 1 skipped). 500032 tests completed, 20 failed, 1 skipped; ...; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446578316
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446578316:418,Availability,FAILURE,FAILURE,418,"Hello.; If I launch the tests by themselves with the following command they all pass; ```; $ ./gradlew test --tests org.broadinstitute.hellbender.tools.walkers.variantutils.LeftAlignAndTrimVariantsUnitTest; ...; Results: SUCCESS (3611 tests, 3611 successes, 0 failures, 0 skipped). BUILD SUCCESSFUL. Total time: 22.445 secs; ```. But when launching all the tests altogether I get; ```; $ ./gradlew test; ...; Results: FAILURE (500032 tests, 500011 successes, 20 failures, 1 skipped). 500032 tests completed, 20 failed, 1 skipped; ...; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446578316
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446578316:462,Availability,failure,failures,462,"Hello.; If I launch the tests by themselves with the following command they all pass; ```; $ ./gradlew test --tests org.broadinstitute.hellbender.tools.walkers.variantutils.LeftAlignAndTrimVariantsUnitTest; ...; Results: SUCCESS (3611 tests, 3611 successes, 0 failures, 0 skipped). BUILD SUCCESSFUL. Total time: 22.445 secs; ```. But when launching all the tests altogether I get; ```; $ ./gradlew test; ...; Results: FAILURE (500032 tests, 500011 successes, 20 failures, 1 skipped). 500032 tests completed, 20 failed, 1 skipped; ...; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446578316
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446578316:24,Testability,test,tests,24,"Hello.; If I launch the tests by themselves with the following command they all pass; ```; $ ./gradlew test --tests org.broadinstitute.hellbender.tools.walkers.variantutils.LeftAlignAndTrimVariantsUnitTest; ...; Results: SUCCESS (3611 tests, 3611 successes, 0 failures, 0 skipped). BUILD SUCCESSFUL. Total time: 22.445 secs; ```. But when launching all the tests altogether I get; ```; $ ./gradlew test; ...; Results: FAILURE (500032 tests, 500011 successes, 20 failures, 1 skipped). 500032 tests completed, 20 failed, 1 skipped; ...; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446578316
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446578316:103,Testability,test,test,103,"Hello.; If I launch the tests by themselves with the following command they all pass; ```; $ ./gradlew test --tests org.broadinstitute.hellbender.tools.walkers.variantutils.LeftAlignAndTrimVariantsUnitTest; ...; Results: SUCCESS (3611 tests, 3611 successes, 0 failures, 0 skipped). BUILD SUCCESSFUL. Total time: 22.445 secs; ```. But when launching all the tests altogether I get; ```; $ ./gradlew test; ...; Results: FAILURE (500032 tests, 500011 successes, 20 failures, 1 skipped). 500032 tests completed, 20 failed, 1 skipped; ...; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446578316
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446578316:110,Testability,test,tests,110,"Hello.; If I launch the tests by themselves with the following command they all pass; ```; $ ./gradlew test --tests org.broadinstitute.hellbender.tools.walkers.variantutils.LeftAlignAndTrimVariantsUnitTest; ...; Results: SUCCESS (3611 tests, 3611 successes, 0 failures, 0 skipped). BUILD SUCCESSFUL. Total time: 22.445 secs; ```. But when launching all the tests altogether I get; ```; $ ./gradlew test; ...; Results: FAILURE (500032 tests, 500011 successes, 20 failures, 1 skipped). 500032 tests completed, 20 failed, 1 skipped; ...; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446578316
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446578316:235,Testability,test,tests,235,"Hello.; If I launch the tests by themselves with the following command they all pass; ```; $ ./gradlew test --tests org.broadinstitute.hellbender.tools.walkers.variantutils.LeftAlignAndTrimVariantsUnitTest; ...; Results: SUCCESS (3611 tests, 3611 successes, 0 failures, 0 skipped). BUILD SUCCESSFUL. Total time: 22.445 secs; ```. But when launching all the tests altogether I get; ```; $ ./gradlew test; ...; Results: FAILURE (500032 tests, 500011 successes, 20 failures, 1 skipped). 500032 tests completed, 20 failed, 1 skipped; ...; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446578316
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446578316:357,Testability,test,tests,357,"Hello.; If I launch the tests by themselves with the following command they all pass; ```; $ ./gradlew test --tests org.broadinstitute.hellbender.tools.walkers.variantutils.LeftAlignAndTrimVariantsUnitTest; ...; Results: SUCCESS (3611 tests, 3611 successes, 0 failures, 0 skipped). BUILD SUCCESSFUL. Total time: 22.445 secs; ```. But when launching all the tests altogether I get; ```; $ ./gradlew test; ...; Results: FAILURE (500032 tests, 500011 successes, 20 failures, 1 skipped). 500032 tests completed, 20 failed, 1 skipped; ...; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446578316
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446578316:398,Testability,test,test,398,"Hello.; If I launch the tests by themselves with the following command they all pass; ```; $ ./gradlew test --tests org.broadinstitute.hellbender.tools.walkers.variantutils.LeftAlignAndTrimVariantsUnitTest; ...; Results: SUCCESS (3611 tests, 3611 successes, 0 failures, 0 skipped). BUILD SUCCESSFUL. Total time: 22.445 secs; ```. But when launching all the tests altogether I get; ```; $ ./gradlew test; ...; Results: FAILURE (500032 tests, 500011 successes, 20 failures, 1 skipped). 500032 tests completed, 20 failed, 1 skipped; ...; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446578316
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446578316:434,Testability,test,tests,434,"Hello.; If I launch the tests by themselves with the following command they all pass; ```; $ ./gradlew test --tests org.broadinstitute.hellbender.tools.walkers.variantutils.LeftAlignAndTrimVariantsUnitTest; ...; Results: SUCCESS (3611 tests, 3611 successes, 0 failures, 0 skipped). BUILD SUCCESSFUL. Total time: 22.445 secs; ```. But when launching all the tests altogether I get; ```; $ ./gradlew test; ...; Results: FAILURE (500032 tests, 500011 successes, 20 failures, 1 skipped). 500032 tests completed, 20 failed, 1 skipped; ...; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446578316
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446578316:491,Testability,test,tests,491,"Hello.; If I launch the tests by themselves with the following command they all pass; ```; $ ./gradlew test --tests org.broadinstitute.hellbender.tools.walkers.variantutils.LeftAlignAndTrimVariantsUnitTest; ...; Results: SUCCESS (3611 tests, 3611 successes, 0 failures, 0 skipped). BUILD SUCCESSFUL. Total time: 22.445 secs; ```. But when launching all the tests altogether I get; ```; $ ./gradlew test; ...; Results: FAILURE (500032 tests, 500011 successes, 20 failures, 1 skipped). 500032 tests completed, 20 failed, 1 skipped; ...; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446578316
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446584198:104,Testability,test,tests,104,@rick-heig Ah - thats super helpful - I think I see the problem. Is is possible for you try running the tests with [this branch](https://github.com/broadinstitute/gatk/tree/cn_left_align) ?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446584198
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446901562:144,Availability,FAILURE,FAILURE,144,"Ok, this seems to solve it. I ran :; ```; $ git checkout cn_left_align ; $ ./gradlew clean; $ ./gradlew bundle; $ ./gradlew test; ...; Results: FAILURE (500060 tests, 500057 successes, 2 failures, 1 skipped). 500060 tests completed, 2 failed, 1 skipped; ```. And got all the tests to succeed (except the two spark related ones as before).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446901562
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446901562:187,Availability,failure,failures,187,"Ok, this seems to solve it. I ran :; ```; $ git checkout cn_left_align ; $ ./gradlew clean; $ ./gradlew bundle; $ ./gradlew test; ...; Results: FAILURE (500060 tests, 500057 successes, 2 failures, 1 skipped). 500060 tests completed, 2 failed, 1 skipped; ```. And got all the tests to succeed (except the two spark related ones as before).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446901562
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446901562:124,Testability,test,test,124,"Ok, this seems to solve it. I ran :; ```; $ git checkout cn_left_align ; $ ./gradlew clean; $ ./gradlew bundle; $ ./gradlew test; ...; Results: FAILURE (500060 tests, 500057 successes, 2 failures, 1 skipped). 500060 tests completed, 2 failed, 1 skipped; ```. And got all the tests to succeed (except the two spark related ones as before).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446901562
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446901562:160,Testability,test,tests,160,"Ok, this seems to solve it. I ran :; ```; $ git checkout cn_left_align ; $ ./gradlew clean; $ ./gradlew bundle; $ ./gradlew test; ...; Results: FAILURE (500060 tests, 500057 successes, 2 failures, 1 skipped). 500060 tests completed, 2 failed, 1 skipped; ```. And got all the tests to succeed (except the two spark related ones as before).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446901562
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446901562:216,Testability,test,tests,216,"Ok, this seems to solve it. I ran :; ```; $ git checkout cn_left_align ; $ ./gradlew clean; $ ./gradlew bundle; $ ./gradlew test; ...; Results: FAILURE (500060 tests, 500057 successes, 2 failures, 1 skipped). 500060 tests completed, 2 failed, 1 skipped; ```. And got all the tests to succeed (except the two spark related ones as before).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446901562
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446901562:275,Testability,test,tests,275,"Ok, this seems to solve it. I ran :; ```; $ git checkout cn_left_align ; $ ./gradlew clean; $ ./gradlew bundle; $ ./gradlew test; ...; Results: FAILURE (500060 tests, 500057 successes, 2 failures, 1 skipped). 500060 tests completed, 2 failed, 1 skipped; ```. And got all the tests to succeed (except the two spark related ones as before).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446901562
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446964064:183,Availability,failure,failures,183,"Ok, thanks for validating that. I'll make a PR for this change (the way those unit tests are written is a little sketchy so I may fix that at the same time). I forgot about the spark failures - can you post the log output for those failures as well ?. Also, to answer your original question, you should generally always be able to work directly from head of master and all tests should pass, though sometimes things like this can slip through. Also, to answer your original question",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446964064
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446964064:232,Availability,failure,failures,232,"Ok, thanks for validating that. I'll make a PR for this change (the way those unit tests are written is a little sketchy so I may fix that at the same time). I forgot about the spark failures - can you post the log output for those failures as well ?. Also, to answer your original question, you should generally always be able to work directly from head of master and all tests should pass, though sometimes things like this can slip through. Also, to answer your original question",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446964064
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446964064:15,Security,validat,validating,15,"Ok, thanks for validating that. I'll make a PR for this change (the way those unit tests are written is a little sketchy so I may fix that at the same time). I forgot about the spark failures - can you post the log output for those failures as well ?. Also, to answer your original question, you should generally always be able to work directly from head of master and all tests should pass, though sometimes things like this can slip through. Also, to answer your original question",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446964064
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446964064:83,Testability,test,tests,83,"Ok, thanks for validating that. I'll make a PR for this change (the way those unit tests are written is a little sketchy so I may fix that at the same time). I forgot about the spark failures - can you post the log output for those failures as well ?. Also, to answer your original question, you should generally always be able to work directly from head of master and all tests should pass, though sometimes things like this can slip through. Also, to answer your original question",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446964064
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446964064:211,Testability,log,log,211,"Ok, thanks for validating that. I'll make a PR for this change (the way those unit tests are written is a little sketchy so I may fix that at the same time). I forgot about the spark failures - can you post the log output for those failures as well ?. Also, to answer your original question, you should generally always be able to work directly from head of master and all tests should pass, though sometimes things like this can slip through. Also, to answer your original question",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446964064
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446964064:373,Testability,test,tests,373,"Ok, thanks for validating that. I'll make a PR for this change (the way those unit tests are written is a little sketchy so I may fix that at the same time). I forgot about the spark failures - can you post the log output for those failures as well ?. Also, to answer your original question, you should generally always be able to work directly from head of master and all tests should pass, though sometimes things like this can slip through. Also, to answer your original question",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-446964064
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-447759121:70,Availability,failure,failures,70,Hello.; Thank you for your answer. Attached are the logs of the Spark failures.; [org.broadinstitute.hellbender.tools.examples.ExampleAssemblyRegionWalkerSparkIntegrationTest.html.zip](https://github.com/broadinstitute/gatk/files/2685031/org.broadinstitute.hellbender.tools.examples.ExampleAssemblyRegionWalkerSparkIntegrationTest.html.zip),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-447759121
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-447759121:52,Testability,log,logs,52,Hello.; Thank you for your answer. Attached are the logs of the Spark failures.; [org.broadinstitute.hellbender.tools.examples.ExampleAssemblyRegionWalkerSparkIntegrationTest.html.zip](https://github.com/broadinstitute/gatk/files/2685031/org.broadinstitute.hellbender.tools.examples.ExampleAssemblyRegionWalkerSparkIntegrationTest.html.zip),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-447759121
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-448261095:85,Testability,test,tests,85,@tomwhite @jamesemery Any insight as to why these `ExampleAssemblyRegionWalkerSpark` tests might be failing ?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-448261095
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-448275058:43,Testability,test,tests,43,"It's not immediately obvious why the Spark tests are failing. It could be something to do with the Spark context which is shared between tests, and which may be picking up some state that is not cleared from one test to the next. The tests are passing on Travis, which also runs all of them. Do they fail if you run them individually?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-448275058
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-448275058:137,Testability,test,tests,137,"It's not immediately obvious why the Spark tests are failing. It could be something to do with the Spark context which is shared between tests, and which may be picking up some state that is not cleared from one test to the next. The tests are passing on Travis, which also runs all of them. Do they fail if you run them individually?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-448275058
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-448275058:212,Testability,test,test,212,"It's not immediately obvious why the Spark tests are failing. It could be something to do with the Spark context which is shared between tests, and which may be picking up some state that is not cleared from one test to the next. The tests are passing on Travis, which also runs all of them. Do they fail if you run them individually?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-448275058
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-448275058:234,Testability,test,tests,234,"It's not immediately obvious why the Spark tests are failing. It could be something to do with the Spark context which is shared between tests, and which may be picking up some state that is not cleared from one test to the next. The tests are passing on Travis, which also runs all of them. Do they fail if you run them individually?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-448275058
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-448275058:195,Usability,clear,cleared,195,"It's not immediately obvious why the Spark tests are failing. It could be something to do with the Spark context which is shared between tests, and which may be picking up some state that is not cleared from one test to the next. The tests are passing on Travis, which also runs all of them. Do they fail if you run them individually?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-448275058
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-448972714:236,Availability,failure,failures,236,"Sorry for the delay, when running the tests individually I get : ; ```; ./gradlew test --tests org.broadinstitute.hellbender.tools.examples.ExampleAssemblyRegionWalkerSparkIntegrationTest; ...; Results: SUCCESS (2 tests, 2 successes, 0 failures, 0 skipped). BUILD SUCCESSFUL; ```; It works when the tests are launched individually, like the other tests.; So it seem like there is a similar problem for these tests.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-448972714
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-448972714:38,Testability,test,tests,38,"Sorry for the delay, when running the tests individually I get : ; ```; ./gradlew test --tests org.broadinstitute.hellbender.tools.examples.ExampleAssemblyRegionWalkerSparkIntegrationTest; ...; Results: SUCCESS (2 tests, 2 successes, 0 failures, 0 skipped). BUILD SUCCESSFUL; ```; It works when the tests are launched individually, like the other tests.; So it seem like there is a similar problem for these tests.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-448972714
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-448972714:82,Testability,test,test,82,"Sorry for the delay, when running the tests individually I get : ; ```; ./gradlew test --tests org.broadinstitute.hellbender.tools.examples.ExampleAssemblyRegionWalkerSparkIntegrationTest; ...; Results: SUCCESS (2 tests, 2 successes, 0 failures, 0 skipped). BUILD SUCCESSFUL; ```; It works when the tests are launched individually, like the other tests.; So it seem like there is a similar problem for these tests.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-448972714
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-448972714:89,Testability,test,tests,89,"Sorry for the delay, when running the tests individually I get : ; ```; ./gradlew test --tests org.broadinstitute.hellbender.tools.examples.ExampleAssemblyRegionWalkerSparkIntegrationTest; ...; Results: SUCCESS (2 tests, 2 successes, 0 failures, 0 skipped). BUILD SUCCESSFUL; ```; It works when the tests are launched individually, like the other tests.; So it seem like there is a similar problem for these tests.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-448972714
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-448972714:214,Testability,test,tests,214,"Sorry for the delay, when running the tests individually I get : ; ```; ./gradlew test --tests org.broadinstitute.hellbender.tools.examples.ExampleAssemblyRegionWalkerSparkIntegrationTest; ...; Results: SUCCESS (2 tests, 2 successes, 0 failures, 0 skipped). BUILD SUCCESSFUL; ```; It works when the tests are launched individually, like the other tests.; So it seem like there is a similar problem for these tests.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-448972714
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-448972714:299,Testability,test,tests,299,"Sorry for the delay, when running the tests individually I get : ; ```; ./gradlew test --tests org.broadinstitute.hellbender.tools.examples.ExampleAssemblyRegionWalkerSparkIntegrationTest; ...; Results: SUCCESS (2 tests, 2 successes, 0 failures, 0 skipped). BUILD SUCCESSFUL; ```; It works when the tests are launched individually, like the other tests.; So it seem like there is a similar problem for these tests.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-448972714
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-448972714:347,Testability,test,tests,347,"Sorry for the delay, when running the tests individually I get : ; ```; ./gradlew test --tests org.broadinstitute.hellbender.tools.examples.ExampleAssemblyRegionWalkerSparkIntegrationTest; ...; Results: SUCCESS (2 tests, 2 successes, 0 failures, 0 skipped). BUILD SUCCESSFUL; ```; It works when the tests are launched individually, like the other tests.; So it seem like there is a similar problem for these tests.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-448972714
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-448972714:408,Testability,test,tests,408,"Sorry for the delay, when running the tests individually I get : ; ```; ./gradlew test --tests org.broadinstitute.hellbender.tools.examples.ExampleAssemblyRegionWalkerSparkIntegrationTest; ...; Results: SUCCESS (2 tests, 2 successes, 0 failures, 0 skipped). BUILD SUCCESSFUL; ```; It works when the tests are launched individually, like the other tests.; So it seem like there is a similar problem for these tests.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-448972714
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-451907673:21,Testability,test,test,21,"When I run the whole test suite with `./gradlew test` ExampleAssemblyRegionWalkerSparkIntegrationTest passes (both its tests). So I'm not sure how to reproduce this, which makes it a bit tricky to fix. BTW I'm using a later version of Java, not sure if this is relevant though. ```; java version ""1.8.0_171""; Java(TM) SE Runtime Environment (build 1.8.0_171-b11); Java HotSpot(TM) 64-Bit Server VM (build 25.171-b11, mixed mode); ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-451907673
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-451907673:48,Testability,test,test,48,"When I run the whole test suite with `./gradlew test` ExampleAssemblyRegionWalkerSparkIntegrationTest passes (both its tests). So I'm not sure how to reproduce this, which makes it a bit tricky to fix. BTW I'm using a later version of Java, not sure if this is relevant though. ```; java version ""1.8.0_171""; Java(TM) SE Runtime Environment (build 1.8.0_171-b11); Java HotSpot(TM) 64-Bit Server VM (build 25.171-b11, mixed mode); ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-451907673
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-451907673:119,Testability,test,tests,119,"When I run the whole test suite with `./gradlew test` ExampleAssemblyRegionWalkerSparkIntegrationTest passes (both its tests). So I'm not sure how to reproduce this, which makes it a bit tricky to fix. BTW I'm using a later version of Java, not sure if this is relevant though. ```; java version ""1.8.0_171""; Java(TM) SE Runtime Environment (build 1.8.0_171-b11); Java HotSpot(TM) 64-Bit Server VM (build 25.171-b11, mixed mode); ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-451907673
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-451930915:430,Availability,FAILURE,FAILURE,430,"It doesn't seem related to the version of java. I updated my version of java to; ```; javac -version; javac 1.8.0_191. java -version; java version ""1.8.0_191""; Java(TM) SE Runtime Environment (build 1.8.0_191-b12); Java HotSpot(TM) 64-Bit Server VM (build 25.191-b12, mixed mode); ```. The issue remains the same, I pulled the latest commit on master and ran; ```; ./gradlew clean; ./gradlew bundle; ./gradlew test; ...; Results: FAILURE (500075 tests, 500072 successes, 2 failures, 1 skipped). 500075 tests completed, 2 failed, 1 skipped; ```; The behavior is the same, the exact two same tests fail.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-451930915
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-451930915:473,Availability,failure,failures,473,"It doesn't seem related to the version of java. I updated my version of java to; ```; javac -version; javac 1.8.0_191. java -version; java version ""1.8.0_191""; Java(TM) SE Runtime Environment (build 1.8.0_191-b12); Java HotSpot(TM) 64-Bit Server VM (build 25.191-b12, mixed mode); ```. The issue remains the same, I pulled the latest commit on master and ran; ```; ./gradlew clean; ./gradlew bundle; ./gradlew test; ...; Results: FAILURE (500075 tests, 500072 successes, 2 failures, 1 skipped). 500075 tests completed, 2 failed, 1 skipped; ```; The behavior is the same, the exact two same tests fail.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-451930915
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-451930915:50,Deployability,update,updated,50,"It doesn't seem related to the version of java. I updated my version of java to; ```; javac -version; javac 1.8.0_191. java -version; java version ""1.8.0_191""; Java(TM) SE Runtime Environment (build 1.8.0_191-b12); Java HotSpot(TM) 64-Bit Server VM (build 25.191-b12, mixed mode); ```. The issue remains the same, I pulled the latest commit on master and ran; ```; ./gradlew clean; ./gradlew bundle; ./gradlew test; ...; Results: FAILURE (500075 tests, 500072 successes, 2 failures, 1 skipped). 500075 tests completed, 2 failed, 1 skipped; ```; The behavior is the same, the exact two same tests fail.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-451930915
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-451930915:410,Testability,test,test,410,"It doesn't seem related to the version of java. I updated my version of java to; ```; javac -version; javac 1.8.0_191. java -version; java version ""1.8.0_191""; Java(TM) SE Runtime Environment (build 1.8.0_191-b12); Java HotSpot(TM) 64-Bit Server VM (build 25.191-b12, mixed mode); ```. The issue remains the same, I pulled the latest commit on master and ran; ```; ./gradlew clean; ./gradlew bundle; ./gradlew test; ...; Results: FAILURE (500075 tests, 500072 successes, 2 failures, 1 skipped). 500075 tests completed, 2 failed, 1 skipped; ```; The behavior is the same, the exact two same tests fail.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-451930915
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-451930915:446,Testability,test,tests,446,"It doesn't seem related to the version of java. I updated my version of java to; ```; javac -version; javac 1.8.0_191. java -version; java version ""1.8.0_191""; Java(TM) SE Runtime Environment (build 1.8.0_191-b12); Java HotSpot(TM) 64-Bit Server VM (build 25.191-b12, mixed mode); ```. The issue remains the same, I pulled the latest commit on master and ran; ```; ./gradlew clean; ./gradlew bundle; ./gradlew test; ...; Results: FAILURE (500075 tests, 500072 successes, 2 failures, 1 skipped). 500075 tests completed, 2 failed, 1 skipped; ```; The behavior is the same, the exact two same tests fail.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-451930915
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-451930915:502,Testability,test,tests,502,"It doesn't seem related to the version of java. I updated my version of java to; ```; javac -version; javac 1.8.0_191. java -version; java version ""1.8.0_191""; Java(TM) SE Runtime Environment (build 1.8.0_191-b12); Java HotSpot(TM) 64-Bit Server VM (build 25.191-b12, mixed mode); ```. The issue remains the same, I pulled the latest commit on master and ran; ```; ./gradlew clean; ./gradlew bundle; ./gradlew test; ...; Results: FAILURE (500075 tests, 500072 successes, 2 failures, 1 skipped). 500075 tests completed, 2 failed, 1 skipped; ```; The behavior is the same, the exact two same tests fail.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-451930915
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-451930915:590,Testability,test,tests,590,"It doesn't seem related to the version of java. I updated my version of java to; ```; javac -version; javac 1.8.0_191. java -version; java version ""1.8.0_191""; Java(TM) SE Runtime Environment (build 1.8.0_191-b12); Java HotSpot(TM) 64-Bit Server VM (build 25.191-b12, mixed mode); ```. The issue remains the same, I pulled the latest commit on master and ran; ```; ./gradlew clean; ./gradlew bundle; ./gradlew test; ...; Results: FAILURE (500075 tests, 500072 successes, 2 failures, 1 skipped). 500075 tests completed, 2 failed, 1 skipped; ```; The behavior is the same, the exact two same tests fail.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-451930915
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-452639052:46,Testability,test,tests,46,"@rick-heig thanks for trying again. I ran the tests on Ubuntu 18.04 (the previous attempts were on a Mac), and the Spark tests didn't fail for me there either...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-452639052
https://github.com/broadinstitute/gatk/issues/5511#issuecomment-452639052:121,Testability,test,tests,121,"@rick-heig thanks for trying again. I ran the tests on Ubuntu 18.04 (the previous attempts were on a Mac), and the Spark tests didn't fail for me there either...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5511#issuecomment-452639052
https://github.com/broadinstitute/gatk/issues/5513#issuecomment-446315089:8,Security,access,access,8,"We have access to data that should reproduce this issue, but can't post it here because it's not publicly shareable BAMs. Please let me know how I can share the data if someone decides to look at this issue. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5513#issuecomment-446315089
https://github.com/broadinstitute/gatk/issues/5513#issuecomment-447033286:80,Safety,avoid,avoids,80,"When the engine ""marginalizes"" haplotype likelihoods into allele likelihoods it avoids double-counting of both the MNP at 151 and the SNP at 152. That is, the CT->TC MNP haplotype is consistent at 152 with the T->C SNP, but it has a different start position and therefore is not marginalized into the evidence for the SNP. So the fact that the DP in sample1 is much less at 152 than at 151 makes sense. I am also confused about sample2. If we're both still confused tomorrow, let's take a look in IGV. Might even need IntelliJ. Might even be a bug -- if you look in `AssemblyBasedCallerGenotypingEngine.createAlleleMapper`, you'll see that the overlapping event logic assumes we're dealing with upstream spanning deletions. Maybe MNPs need to be treated differently.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5513#issuecomment-447033286
https://github.com/broadinstitute/gatk/issues/5513#issuecomment-447033286:662,Testability,log,logic,662,"When the engine ""marginalizes"" haplotype likelihoods into allele likelihoods it avoids double-counting of both the MNP at 151 and the SNP at 152. That is, the CT->TC MNP haplotype is consistent at 152 with the T->C SNP, but it has a different start position and therefore is not marginalized into the evidence for the SNP. So the fact that the DP in sample1 is much less at 152 than at 151 makes sense. I am also confused about sample2. If we're both still confused tomorrow, let's take a look in IGV. Might even need IntelliJ. Might even be a bug -- if you look in `AssemblyBasedCallerGenotypingEngine.createAlleleMapper`, you'll see that the overlapping event logic assumes we're dealing with upstream spanning deletions. Maybe MNPs need to be treated differently.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5513#issuecomment-447033286
https://github.com/broadinstitute/gatk/issues/5513#issuecomment-447039462:18,Availability,fault,fault,18,"I doubt it's your fault, but it could easily be mine for blithely giving M2 a GGA mode and figuring this kind of thing would just work out somehow.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5513#issuecomment-447039462
https://github.com/broadinstitute/gatk/issues/5517#issuecomment-446769514:487,Modifiability,polymorphi,polymorphisms,487,"According to this paper https://www.nature.com/articles/s41467-018-03590-5. it is: ""Each resulting qualified captured library with the SureSelect Human; All Exon kit (Aglient) was then loaded on *BGISEQ-5000 *sequencing; platforms, and we performed high-throughput sequencing for each captured; library. High-quality reads were aligned to the human reference genome; (GRCh37) using the Burrows-Wheeler Aligner (BWA v0.7.15) software. All; genomic variations, including single-nucleotide polymorphisms and InDels; were detected by *HaplotypeCaller of GATK *(v3.0.0).; "". On Wed, Dec 12, 2018 at 3:18 PM Louis Bergelson <notifications@github.com>; wrote:. > @yfarjoun <https://github.com/yfarjoun> Do you know if BGI's sequencing; > is compatible with our tools without any special treatment?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/5517#issuecomment-446729153>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACnk0mujY7YzxUJ-6IPU8B7jPiZWQuzMks5u4WR3gaJpZM4ZQNxZ>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5517#issuecomment-446769514
https://github.com/broadinstitute/gatk/issues/5517#issuecomment-446769514:185,Performance,load,loaded,185,"According to this paper https://www.nature.com/articles/s41467-018-03590-5. it is: ""Each resulting qualified captured library with the SureSelect Human; All Exon kit (Aglient) was then loaded on *BGISEQ-5000 *sequencing; platforms, and we performed high-throughput sequencing for each captured; library. High-quality reads were aligned to the human reference genome; (GRCh37) using the Burrows-Wheeler Aligner (BWA v0.7.15) software. All; genomic variations, including single-nucleotide polymorphisms and InDels; were detected by *HaplotypeCaller of GATK *(v3.0.0).; "". On Wed, Dec 12, 2018 at 3:18 PM Louis Bergelson <notifications@github.com>; wrote:. > @yfarjoun <https://github.com/yfarjoun> Do you know if BGI's sequencing; > is compatible with our tools without any special treatment?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/5517#issuecomment-446729153>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACnk0mujY7YzxUJ-6IPU8B7jPiZWQuzMks5u4WR3gaJpZM4ZQNxZ>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5517#issuecomment-446769514
https://github.com/broadinstitute/gatk/issues/5517#issuecomment-446769514:239,Performance,perform,performed,239,"According to this paper https://www.nature.com/articles/s41467-018-03590-5. it is: ""Each resulting qualified captured library with the SureSelect Human; All Exon kit (Aglient) was then loaded on *BGISEQ-5000 *sequencing; platforms, and we performed high-throughput sequencing for each captured; library. High-quality reads were aligned to the human reference genome; (GRCh37) using the Burrows-Wheeler Aligner (BWA v0.7.15) software. All; genomic variations, including single-nucleotide polymorphisms and InDels; were detected by *HaplotypeCaller of GATK *(v3.0.0).; "". On Wed, Dec 12, 2018 at 3:18 PM Louis Bergelson <notifications@github.com>; wrote:. > @yfarjoun <https://github.com/yfarjoun> Do you know if BGI's sequencing; > is compatible with our tools without any special treatment?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/5517#issuecomment-446729153>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACnk0mujY7YzxUJ-6IPU8B7jPiZWQuzMks5u4WR3gaJpZM4ZQNxZ>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5517#issuecomment-446769514
https://github.com/broadinstitute/gatk/issues/5517#issuecomment-446769514:254,Performance,throughput,throughput,254,"According to this paper https://www.nature.com/articles/s41467-018-03590-5. it is: ""Each resulting qualified captured library with the SureSelect Human; All Exon kit (Aglient) was then loaded on *BGISEQ-5000 *sequencing; platforms, and we performed high-throughput sequencing for each captured; library. High-quality reads were aligned to the human reference genome; (GRCh37) using the Burrows-Wheeler Aligner (BWA v0.7.15) software. All; genomic variations, including single-nucleotide polymorphisms and InDels; were detected by *HaplotypeCaller of GATK *(v3.0.0).; "". On Wed, Dec 12, 2018 at 3:18 PM Louis Bergelson <notifications@github.com>; wrote:. > @yfarjoun <https://github.com/yfarjoun> Do you know if BGI's sequencing; > is compatible with our tools without any special treatment?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/5517#issuecomment-446729153>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACnk0mujY7YzxUJ-6IPU8B7jPiZWQuzMks5u4WR3gaJpZM4ZQNxZ>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5517#issuecomment-446769514
https://github.com/broadinstitute/gatk/issues/5517#issuecomment-446769514:518,Safety,detect,detected,518,"According to this paper https://www.nature.com/articles/s41467-018-03590-5. it is: ""Each resulting qualified captured library with the SureSelect Human; All Exon kit (Aglient) was then loaded on *BGISEQ-5000 *sequencing; platforms, and we performed high-throughput sequencing for each captured; library. High-quality reads were aligned to the human reference genome; (GRCh37) using the Burrows-Wheeler Aligner (BWA v0.7.15) software. All; genomic variations, including single-nucleotide polymorphisms and InDels; were detected by *HaplotypeCaller of GATK *(v3.0.0).; "". On Wed, Dec 12, 2018 at 3:18 PM Louis Bergelson <notifications@github.com>; wrote:. > @yfarjoun <https://github.com/yfarjoun> Do you know if BGI's sequencing; > is compatible with our tools without any special treatment?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/5517#issuecomment-446729153>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACnk0mujY7YzxUJ-6IPU8B7jPiZWQuzMks5u4WR3gaJpZM4ZQNxZ>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5517#issuecomment-446769514
https://github.com/broadinstitute/gatk/pull/5522#issuecomment-447141409:63,Deployability,release,release,63,"Note that before this is merged, we'll need to do a datasource release in which the following property is added to the gencode config files:. ```; # Required field for GENCODE files.; # NCBI build version:; ncbi_build_version = X; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5522#issuecomment-447141409
https://github.com/broadinstitute/gatk/pull/5522#issuecomment-447141409:127,Modifiability,config,config,127,"Note that before this is merged, we'll need to do a datasource release in which the following property is added to the gencode config files:. ```; # Required field for GENCODE files.; # NCBI build version:; ncbi_build_version = X; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5522#issuecomment-447141409
https://github.com/broadinstitute/gatk/issues/5523#issuecomment-447369490:411,Integrability,inject,injected,411,I'm actually a little surprised that it's not emitting a 1/* at the second location (despite that perhaps not being compatible with the spec; I agree with @bhandsaker 's view of what `*` should mean) given the changes I made in https://github.com/broadinstitute/gatk/pull/4963 to support spanning deletions. Those changes were not made with MNPs in mind but reading the code I'm surprised the `*` allele is not injected into the variant context. What version of HaplotypeCaller are you using @tfenne?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5523#issuecomment-447369490
https://github.com/broadinstitute/gatk/issues/5523#issuecomment-447369490:411,Security,inject,injected,411,I'm actually a little surprised that it's not emitting a 1/* at the second location (despite that perhaps not being compatible with the spec; I agree with @bhandsaker 's view of what `*` should mean) given the changes I made in https://github.com/broadinstitute/gatk/pull/4963 to support spanning deletions. Those changes were not made with MNPs in mind but reading the code I'm surprised the `*` allele is not injected into the variant context. What version of HaplotypeCaller are you using @tfenne?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5523#issuecomment-447369490
https://github.com/broadinstitute/gatk/issues/5523#issuecomment-447374216:312,Deployability,release,release,312,Thanks for the input @bhandsaker and @cwhelan. The calls were made with version `4.0.10.0`. I thought that was the latest - but it looks like we're a couple of minor versions behind. I'll retry making those calls with the latest version and see if it persists. Are the changes you're talking about in the latest release version or just on master?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5523#issuecomment-447374216
https://github.com/broadinstitute/gatk/issues/5523#issuecomment-449758576:103,Deployability,release,release,103,"@cwhelan & @ldgauthier sorry for the delay on getting back this issue. Firstly, I just grabbed the new release (4.0.12.0) and re-ran with that to generate both gVCF and VCF. The VCF output still generates the 1/1 genotype unfortunately. What's interesting though is that the gVCF is capturing the spanning allele! So it looks like `GenotypeGVCFs` is causing the problem. Here are the rows from the gVCF and VCF respectively (with INFO elided for compactness):. ```; # gVCF; chr6 42932200 . GGC TGT,<NON_REF> 1623.73 . GT:AD:DP:GQ:PL:SB 0/1:39,44,0:83:99:1661,0,1458,1778,1591,3369:10,29,14,30; chr6 42932202 . C T,*,<NON_REF> 3439.77 . GT:AD:DP:GQ:PL:SB 1/2:1,37,44,0:82:99:3468,1802,1661,1518,0,1449,3406,1802,1577,3436:0,1,24,57. # VCF; chr6 42932200 . GGC TGT 1632.77 . GT:AD:DP:GQ:PL 0/1:39,44:83:99:1661,0,1458; chr6 42932202 . C T 3439.77 . GT:AD:DP:GQ:PL 1/1:1,37:82:99:1807,141,0; ```. For completeness I also ran HaplotypeCaller going direct to VCF without making a gVCF first. The results are fairly similar to the VCF above, except for some AD/DP differences:. ```; # Direct to VCF; chr6 42932200 . GGC TGT 1623.73 . GT:AD:DP:GQ:PL 0/1:39,44:83:99:1661,0,1458; chr6 42932202 . C T 3439.77 . GT:AD:DP:GQ:PL 1/1:1,50:51:99:1807,141,0; ```. Going back to what's the right representation - I think I largely agree with @nh13 and @ldgauthier that long term it would be nice, when running with MNP support, to integrate the two haplotypes into a single variant output. But that sounds like it might be a big project and not happening any time soon? In the meantime if there's an easier fix to have the `*`/spanning allele called in the VCF propagated into the genotyped VCF that would really help.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5523#issuecomment-449758576
https://github.com/broadinstitute/gatk/issues/5523#issuecomment-449758576:1415,Deployability,integrat,integrate,1415,"@cwhelan & @ldgauthier sorry for the delay on getting back this issue. Firstly, I just grabbed the new release (4.0.12.0) and re-ran with that to generate both gVCF and VCF. The VCF output still generates the 1/1 genotype unfortunately. What's interesting though is that the gVCF is capturing the spanning allele! So it looks like `GenotypeGVCFs` is causing the problem. Here are the rows from the gVCF and VCF respectively (with INFO elided for compactness):. ```; # gVCF; chr6 42932200 . GGC TGT,<NON_REF> 1623.73 . GT:AD:DP:GQ:PL:SB 0/1:39,44,0:83:99:1661,0,1458,1778,1591,3369:10,29,14,30; chr6 42932202 . C T,*,<NON_REF> 3439.77 . GT:AD:DP:GQ:PL:SB 1/2:1,37,44,0:82:99:3468,1802,1661,1518,0,1449,3406,1802,1577,3436:0,1,24,57. # VCF; chr6 42932200 . GGC TGT 1632.77 . GT:AD:DP:GQ:PL 0/1:39,44:83:99:1661,0,1458; chr6 42932202 . C T 3439.77 . GT:AD:DP:GQ:PL 1/1:1,37:82:99:1807,141,0; ```. For completeness I also ran HaplotypeCaller going direct to VCF without making a gVCF first. The results are fairly similar to the VCF above, except for some AD/DP differences:. ```; # Direct to VCF; chr6 42932200 . GGC TGT 1623.73 . GT:AD:DP:GQ:PL 0/1:39,44:83:99:1661,0,1458; chr6 42932202 . C T 3439.77 . GT:AD:DP:GQ:PL 1/1:1,50:51:99:1807,141,0; ```. Going back to what's the right representation - I think I largely agree with @nh13 and @ldgauthier that long term it would be nice, when running with MNP support, to integrate the two haplotypes into a single variant output. But that sounds like it might be a big project and not happening any time soon? In the meantime if there's an easier fix to have the `*`/spanning allele called in the VCF propagated into the genotyped VCF that would really help.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5523#issuecomment-449758576
https://github.com/broadinstitute/gatk/issues/5523#issuecomment-449758576:1415,Integrability,integrat,integrate,1415,"@cwhelan & @ldgauthier sorry for the delay on getting back this issue. Firstly, I just grabbed the new release (4.0.12.0) and re-ran with that to generate both gVCF and VCF. The VCF output still generates the 1/1 genotype unfortunately. What's interesting though is that the gVCF is capturing the spanning allele! So it looks like `GenotypeGVCFs` is causing the problem. Here are the rows from the gVCF and VCF respectively (with INFO elided for compactness):. ```; # gVCF; chr6 42932200 . GGC TGT,<NON_REF> 1623.73 . GT:AD:DP:GQ:PL:SB 0/1:39,44,0:83:99:1661,0,1458,1778,1591,3369:10,29,14,30; chr6 42932202 . C T,*,<NON_REF> 3439.77 . GT:AD:DP:GQ:PL:SB 1/2:1,37,44,0:82:99:3468,1802,1661,1518,0,1449,3406,1802,1577,3436:0,1,24,57. # VCF; chr6 42932200 . GGC TGT 1632.77 . GT:AD:DP:GQ:PL 0/1:39,44:83:99:1661,0,1458; chr6 42932202 . C T 3439.77 . GT:AD:DP:GQ:PL 1/1:1,37:82:99:1807,141,0; ```. For completeness I also ran HaplotypeCaller going direct to VCF without making a gVCF first. The results are fairly similar to the VCF above, except for some AD/DP differences:. ```; # Direct to VCF; chr6 42932200 . GGC TGT 1623.73 . GT:AD:DP:GQ:PL 0/1:39,44:83:99:1661,0,1458; chr6 42932202 . C T 3439.77 . GT:AD:DP:GQ:PL 1/1:1,50:51:99:1807,141,0; ```. Going back to what's the right representation - I think I largely agree with @nh13 and @ldgauthier that long term it would be nice, when running with MNP support, to integrate the two haplotypes into a single variant output. But that sounds like it might be a big project and not happening any time soon? In the meantime if there's an easier fix to have the `*`/spanning allele called in the VCF propagated into the genotyped VCF that would really help.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5523#issuecomment-449758576
https://github.com/broadinstitute/gatk/pull/5526#issuecomment-452033717:42,Deployability,update,update,42,@cmnbroad thanks and we expect to need to update our tool w/ GATK changes,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5526#issuecomment-452033717
https://github.com/broadinstitute/gatk/pull/5526#issuecomment-457751714:356,Deployability,update,updated,356,"@lbergelson I added the ClassLoader fallback code in to `GATKPathSpecifier`. In doing so, I expected some of the `PathSpecifier` negative unit tests to produce different exceptions, but they didn't. This was because the tests were all using the `PathSpecifier` base class (because I took them from htsjdk-next which has only the base implementation). So I updated the tests to use `GATKPathSpecifier` (they all passed), then integrated the fallback code and changed 3 negative tests that went from FileSystemNotFoundException to ProviderNotFoundException. Finally I renamed the test class file to correctly reflect the class being tested. Sorry this was such a pain.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5526#issuecomment-457751714
https://github.com/broadinstitute/gatk/pull/5526#issuecomment-457751714:425,Deployability,integrat,integrated,425,"@lbergelson I added the ClassLoader fallback code in to `GATKPathSpecifier`. In doing so, I expected some of the `PathSpecifier` negative unit tests to produce different exceptions, but they didn't. This was because the tests were all using the `PathSpecifier` base class (because I took them from htsjdk-next which has only the base implementation). So I updated the tests to use `GATKPathSpecifier` (they all passed), then integrated the fallback code and changed 3 negative tests that went from FileSystemNotFoundException to ProviderNotFoundException. Finally I renamed the test class file to correctly reflect the class being tested. Sorry this was such a pain.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5526#issuecomment-457751714
https://github.com/broadinstitute/gatk/pull/5526#issuecomment-457751714:425,Integrability,integrat,integrated,425,"@lbergelson I added the ClassLoader fallback code in to `GATKPathSpecifier`. In doing so, I expected some of the `PathSpecifier` negative unit tests to produce different exceptions, but they didn't. This was because the tests were all using the `PathSpecifier` base class (because I took them from htsjdk-next which has only the base implementation). So I updated the tests to use `GATKPathSpecifier` (they all passed), then integrated the fallback code and changed 3 negative tests that went from FileSystemNotFoundException to ProviderNotFoundException. Finally I renamed the test class file to correctly reflect the class being tested. Sorry this was such a pain.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5526#issuecomment-457751714
https://github.com/broadinstitute/gatk/pull/5526#issuecomment-457751714:143,Testability,test,tests,143,"@lbergelson I added the ClassLoader fallback code in to `GATKPathSpecifier`. In doing so, I expected some of the `PathSpecifier` negative unit tests to produce different exceptions, but they didn't. This was because the tests were all using the `PathSpecifier` base class (because I took them from htsjdk-next which has only the base implementation). So I updated the tests to use `GATKPathSpecifier` (they all passed), then integrated the fallback code and changed 3 negative tests that went from FileSystemNotFoundException to ProviderNotFoundException. Finally I renamed the test class file to correctly reflect the class being tested. Sorry this was such a pain.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5526#issuecomment-457751714
https://github.com/broadinstitute/gatk/pull/5526#issuecomment-457751714:220,Testability,test,tests,220,"@lbergelson I added the ClassLoader fallback code in to `GATKPathSpecifier`. In doing so, I expected some of the `PathSpecifier` negative unit tests to produce different exceptions, but they didn't. This was because the tests were all using the `PathSpecifier` base class (because I took them from htsjdk-next which has only the base implementation). So I updated the tests to use `GATKPathSpecifier` (they all passed), then integrated the fallback code and changed 3 negative tests that went from FileSystemNotFoundException to ProviderNotFoundException. Finally I renamed the test class file to correctly reflect the class being tested. Sorry this was such a pain.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5526#issuecomment-457751714
https://github.com/broadinstitute/gatk/pull/5526#issuecomment-457751714:368,Testability,test,tests,368,"@lbergelson I added the ClassLoader fallback code in to `GATKPathSpecifier`. In doing so, I expected some of the `PathSpecifier` negative unit tests to produce different exceptions, but they didn't. This was because the tests were all using the `PathSpecifier` base class (because I took them from htsjdk-next which has only the base implementation). So I updated the tests to use `GATKPathSpecifier` (they all passed), then integrated the fallback code and changed 3 negative tests that went from FileSystemNotFoundException to ProviderNotFoundException. Finally I renamed the test class file to correctly reflect the class being tested. Sorry this was such a pain.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5526#issuecomment-457751714
https://github.com/broadinstitute/gatk/pull/5526#issuecomment-457751714:477,Testability,test,tests,477,"@lbergelson I added the ClassLoader fallback code in to `GATKPathSpecifier`. In doing so, I expected some of the `PathSpecifier` negative unit tests to produce different exceptions, but they didn't. This was because the tests were all using the `PathSpecifier` base class (because I took them from htsjdk-next which has only the base implementation). So I updated the tests to use `GATKPathSpecifier` (they all passed), then integrated the fallback code and changed 3 negative tests that went from FileSystemNotFoundException to ProviderNotFoundException. Finally I renamed the test class file to correctly reflect the class being tested. Sorry this was such a pain.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5526#issuecomment-457751714
https://github.com/broadinstitute/gatk/pull/5526#issuecomment-457751714:578,Testability,test,test,578,"@lbergelson I added the ClassLoader fallback code in to `GATKPathSpecifier`. In doing so, I expected some of the `PathSpecifier` negative unit tests to produce different exceptions, but they didn't. This was because the tests were all using the `PathSpecifier` base class (because I took them from htsjdk-next which has only the base implementation). So I updated the tests to use `GATKPathSpecifier` (they all passed), then integrated the fallback code and changed 3 negative tests that went from FileSystemNotFoundException to ProviderNotFoundException. Finally I renamed the test class file to correctly reflect the class being tested. Sorry this was such a pain.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5526#issuecomment-457751714
https://github.com/broadinstitute/gatk/pull/5526#issuecomment-457751714:631,Testability,test,tested,631,"@lbergelson I added the ClassLoader fallback code in to `GATKPathSpecifier`. In doing so, I expected some of the `PathSpecifier` negative unit tests to produce different exceptions, but they didn't. This was because the tests were all using the `PathSpecifier` base class (because I took them from htsjdk-next which has only the base implementation). So I updated the tests to use `GATKPathSpecifier` (they all passed), then integrated the fallback code and changed 3 negative tests that went from FileSystemNotFoundException to ProviderNotFoundException. Finally I renamed the test class file to correctly reflect the class being tested. Sorry this was such a pain.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5526#issuecomment-457751714
https://github.com/broadinstitute/gatk/pull/5526#issuecomment-457752282:15,Testability,test,tests,15,"Also, once the tests pass, I'm going to rebase on master and then run them one more time.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5526#issuecomment-457752282
https://github.com/broadinstitute/gatk/issues/5527#issuecomment-876514964:66,Deployability,pipeline,pipeline,66,I would also find this feature helpful in terms of streamlining a pipeline I am working on. Any updates on this feature request?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5527#issuecomment-876514964
https://github.com/broadinstitute/gatk/issues/5527#issuecomment-876514964:96,Deployability,update,updates,96,I would also find this feature helpful in terms of streamlining a pipeline I am working on. Any updates on this feature request?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5527#issuecomment-876514964
https://github.com/broadinstitute/gatk/pull/5528#issuecomment-447774744:2449,Deployability,pipeline,pipelines,2449,<ø> (ø)` | `24 <0> (ø)` | :arrow_down: |; | [...hellbender/utils/pairhmm/VectorLoglessPairHMM.java](https://codecov.io/gh/broadinstitute/gatk/pull/5528/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9wYWlyaG1tL1ZlY3RvckxvZ2xlc3NQYWlySE1NLmphdmE=) | `86.842% <ø> (ø)` | `12 <0> (ø)` | :arrow_down: |; | [...ils/nio/NioFileCopierWithProgressMeterResults.java](https://codecov.io/gh/broadinstitute/gatk/pull/5528/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9uaW8vTmlvRmlsZUNvcGllcldpdGhQcm9ncmVzc01ldGVyUmVzdWx0cy5qYXZh) | `0% <0%> (-94.737%)` | `0% <0%> (-9%)` | |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5528/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-74.257%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5528/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...ols/funcotator/FuncotatorDataSourceDownloader.java](https://codecov.io/gh/broadinstitute/gatk/pull/5528/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0Z1bmNvdGF0b3JEYXRhU291cmNlRG93bmxvYWRlci5qYXZh) | `0% <0%> (-66.197%)` | `0% <0%> (-14%)` | |; | [...nder/utils/nio/NioFileCopierWithProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5528/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9uaW8vTmlvRmlsZUNvcGllcldpdGhQcm9ncmVzc01ldGVyLmphdmE=) | `17% <0%> (-52.5%)` | `9% <0%> (-30%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5528/d,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5528#issuecomment-447774744
https://github.com/broadinstitute/gatk/issues/5532#issuecomment-447985785:121,Deployability,release,release,121,May I pass on this? I would like to devote my non-M2 extracurricular time to fixing assembly issues in HC before the 4.1 release.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5532#issuecomment-447985785
https://github.com/broadinstitute/gatk/issues/5536#issuecomment-451711941:76,Usability,resume,resumes,76,Closing because I haven't heard back from the user. If the forum discussion resumes and it turns out that there is a bug I will re-open a more specific ticket.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5536#issuecomment-451711941
https://github.com/broadinstitute/gatk/pull/5537#issuecomment-448713272:84,Deployability,install,install,84,"```; ./gatk --version; Using GATK wrapper script /Users/louisb/Workspace/gatk/build/install/gatk/bin/gatk; Running:; /Users/louisb/Workspace/gatk/build/install/gatk/bin/gatk --version; The Genome Analysis Toolkit (GATK) v4.0.12.0-1-g10aa8c7-SNAPSHOT; ```. This is different than the output of the tool --version...; ```; Using GATK wrapper script /Users/louisb/Workspace/gatk/build/install/gatk/bin/gatk; Running:; /Users/louisb/Workspace/gatk/build/install/gatk/bin/gatk PrintReads --version; Version:4.0.12.0-1-g10aa8c7-SNAPSHOT; Tool returned:; 0; ```. I can change this to be that version, or we can change barclay to do it differently and provide more info. It might be useful to print the library versions with both commands as well.. that's printed during the normal run...; ```; 14:19:57.172 INFO PrintReads - HTSJDK Version: 2.18.1; 14:19:57.173 INFO PrintReads - Picard Version: 2.18.16; ```. @cmnbroad What do you think?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5537#issuecomment-448713272
https://github.com/broadinstitute/gatk/pull/5537#issuecomment-448713272:152,Deployability,install,install,152,"```; ./gatk --version; Using GATK wrapper script /Users/louisb/Workspace/gatk/build/install/gatk/bin/gatk; Running:; /Users/louisb/Workspace/gatk/build/install/gatk/bin/gatk --version; The Genome Analysis Toolkit (GATK) v4.0.12.0-1-g10aa8c7-SNAPSHOT; ```. This is different than the output of the tool --version...; ```; Using GATK wrapper script /Users/louisb/Workspace/gatk/build/install/gatk/bin/gatk; Running:; /Users/louisb/Workspace/gatk/build/install/gatk/bin/gatk PrintReads --version; Version:4.0.12.0-1-g10aa8c7-SNAPSHOT; Tool returned:; 0; ```. I can change this to be that version, or we can change barclay to do it differently and provide more info. It might be useful to print the library versions with both commands as well.. that's printed during the normal run...; ```; 14:19:57.172 INFO PrintReads - HTSJDK Version: 2.18.1; 14:19:57.173 INFO PrintReads - Picard Version: 2.18.16; ```. @cmnbroad What do you think?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5537#issuecomment-448713272
https://github.com/broadinstitute/gatk/pull/5537#issuecomment-448713272:382,Deployability,install,install,382,"```; ./gatk --version; Using GATK wrapper script /Users/louisb/Workspace/gatk/build/install/gatk/bin/gatk; Running:; /Users/louisb/Workspace/gatk/build/install/gatk/bin/gatk --version; The Genome Analysis Toolkit (GATK) v4.0.12.0-1-g10aa8c7-SNAPSHOT; ```. This is different than the output of the tool --version...; ```; Using GATK wrapper script /Users/louisb/Workspace/gatk/build/install/gatk/bin/gatk; Running:; /Users/louisb/Workspace/gatk/build/install/gatk/bin/gatk PrintReads --version; Version:4.0.12.0-1-g10aa8c7-SNAPSHOT; Tool returned:; 0; ```. I can change this to be that version, or we can change barclay to do it differently and provide more info. It might be useful to print the library versions with both commands as well.. that's printed during the normal run...; ```; 14:19:57.172 INFO PrintReads - HTSJDK Version: 2.18.1; 14:19:57.173 INFO PrintReads - Picard Version: 2.18.16; ```. @cmnbroad What do you think?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5537#issuecomment-448713272
https://github.com/broadinstitute/gatk/pull/5537#issuecomment-448713272:450,Deployability,install,install,450,"```; ./gatk --version; Using GATK wrapper script /Users/louisb/Workspace/gatk/build/install/gatk/bin/gatk; Running:; /Users/louisb/Workspace/gatk/build/install/gatk/bin/gatk --version; The Genome Analysis Toolkit (GATK) v4.0.12.0-1-g10aa8c7-SNAPSHOT; ```. This is different than the output of the tool --version...; ```; Using GATK wrapper script /Users/louisb/Workspace/gatk/build/install/gatk/bin/gatk; Running:; /Users/louisb/Workspace/gatk/build/install/gatk/bin/gatk PrintReads --version; Version:4.0.12.0-1-g10aa8c7-SNAPSHOT; Tool returned:; 0; ```. I can change this to be that version, or we can change barclay to do it differently and provide more info. It might be useful to print the library versions with both commands as well.. that's printed during the normal run...; ```; 14:19:57.172 INFO PrintReads - HTSJDK Version: 2.18.1; 14:19:57.173 INFO PrintReads - Picard Version: 2.18.16; ```. @cmnbroad What do you think?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5537#issuecomment-448713272
https://github.com/broadinstitute/gatk/pull/5537#issuecomment-448713272:34,Integrability,wrap,wrapper,34,"```; ./gatk --version; Using GATK wrapper script /Users/louisb/Workspace/gatk/build/install/gatk/bin/gatk; Running:; /Users/louisb/Workspace/gatk/build/install/gatk/bin/gatk --version; The Genome Analysis Toolkit (GATK) v4.0.12.0-1-g10aa8c7-SNAPSHOT; ```. This is different than the output of the tool --version...; ```; Using GATK wrapper script /Users/louisb/Workspace/gatk/build/install/gatk/bin/gatk; Running:; /Users/louisb/Workspace/gatk/build/install/gatk/bin/gatk PrintReads --version; Version:4.0.12.0-1-g10aa8c7-SNAPSHOT; Tool returned:; 0; ```. I can change this to be that version, or we can change barclay to do it differently and provide more info. It might be useful to print the library versions with both commands as well.. that's printed during the normal run...; ```; 14:19:57.172 INFO PrintReads - HTSJDK Version: 2.18.1; 14:19:57.173 INFO PrintReads - Picard Version: 2.18.16; ```. @cmnbroad What do you think?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5537#issuecomment-448713272
https://github.com/broadinstitute/gatk/pull/5537#issuecomment-448713272:332,Integrability,wrap,wrapper,332,"```; ./gatk --version; Using GATK wrapper script /Users/louisb/Workspace/gatk/build/install/gatk/bin/gatk; Running:; /Users/louisb/Workspace/gatk/build/install/gatk/bin/gatk --version; The Genome Analysis Toolkit (GATK) v4.0.12.0-1-g10aa8c7-SNAPSHOT; ```. This is different than the output of the tool --version...; ```; Using GATK wrapper script /Users/louisb/Workspace/gatk/build/install/gatk/bin/gatk; Running:; /Users/louisb/Workspace/gatk/build/install/gatk/bin/gatk PrintReads --version; Version:4.0.12.0-1-g10aa8c7-SNAPSHOT; Tool returned:; 0; ```. I can change this to be that version, or we can change barclay to do it differently and provide more info. It might be useful to print the library versions with both commands as well.. that's printed during the normal run...; ```; 14:19:57.172 INFO PrintReads - HTSJDK Version: 2.18.1; 14:19:57.173 INFO PrintReads - Picard Version: 2.18.16; ```. @cmnbroad What do you think?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5537#issuecomment-448713272
https://github.com/broadinstitute/gatk/pull/5537#issuecomment-449460839:154,Testability,test,test,154,@cmnbroad I extracted a bunch of methods to RunTimeUtils and made it cleaner. I fixed a todo in CommandLineProgram that was related as well. It's hard to test these things because the tests sometimes but don't always the jar with a manifest so I didn't test most of the new methods. I can try to do something more clever if you think it's necessary though...,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5537#issuecomment-449460839
https://github.com/broadinstitute/gatk/pull/5537#issuecomment-449460839:184,Testability,test,tests,184,@cmnbroad I extracted a bunch of methods to RunTimeUtils and made it cleaner. I fixed a todo in CommandLineProgram that was related as well. It's hard to test these things because the tests sometimes but don't always the jar with a manifest so I didn't test most of the new methods. I can try to do something more clever if you think it's necessary though...,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5537#issuecomment-449460839
https://github.com/broadinstitute/gatk/pull/5537#issuecomment-449460839:253,Testability,test,test,253,@cmnbroad I extracted a bunch of methods to RunTimeUtils and made it cleaner. I fixed a todo in CommandLineProgram that was related as well. It's hard to test these things because the tests sometimes but don't always the jar with a manifest so I didn't test most of the new methods. I can try to do something more clever if you think it's necessary though...,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5537#issuecomment-449460839
https://github.com/broadinstitute/gatk/pull/5537#issuecomment-451000856:30,Testability,test,test,30,@cmnbroad You're ok with this test being removed? Just wanted to double check before merging.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5537#issuecomment-451000856
https://github.com/broadinstitute/gatk/pull/5537#issuecomment-451021915:103,Integrability,depend,dependent,103,"@lbergelson Yes - this test is a leftover artifact of the original implementation, but we're no longer dependent on the features tested it so its fine to remove.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5537#issuecomment-451021915
https://github.com/broadinstitute/gatk/pull/5537#issuecomment-451021915:23,Testability,test,test,23,"@lbergelson Yes - this test is a leftover artifact of the original implementation, but we're no longer dependent on the features tested it so its fine to remove.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5537#issuecomment-451021915
https://github.com/broadinstitute/gatk/pull/5537#issuecomment-451021915:129,Testability,test,tested,129,"@lbergelson Yes - this test is a leftover artifact of the original implementation, but we're no longer dependent on the features tested it so its fine to remove.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5537#issuecomment-451021915
https://github.com/broadinstitute/gatk/pull/5539#issuecomment-449065825:2412,Deployability,update,update,2412,"rage Diff @@; ## master #5539 +/- ##; ============================================; - Coverage 87.06% 87.06% -0.01% ; + Complexity 31324 31322 -2 ; ============================================; Files 1921 1921 ; Lines 144579 144579 ; Branches 15949 15949 ; ============================================; - Hits 125884 125880 -4 ; - Misses 12902 12906 +4 ; Partials 5793 5793; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5539?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5539/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-30%)` | `1% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5539/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `79.87% <0%> (-0.61%)` | `42% <0%> (ø)` | |; | [...ithwaterman/SmithWatermanIntelAlignerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5539/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXJVbml0VGVzdC5qYXZh) | `60% <0%> (ø)` | `2% <0%> (ø)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5539?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5539?src=pr&el=footer). Last update [10aa8c7...3aec594](https://codecov.io/gh/broadinstitute/gatk/pull/5539?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5539#issuecomment-449065825
https://github.com/broadinstitute/gatk/pull/5539#issuecomment-449065825:2315,Energy Efficiency,Power,Powered,2315,"rage Diff @@; ## master #5539 +/- ##; ============================================; - Coverage 87.06% 87.06% -0.01% ; + Complexity 31324 31322 -2 ; ============================================; Files 1921 1921 ; Lines 144579 144579 ; Branches 15949 15949 ; ============================================; - Hits 125884 125880 -4 ; - Misses 12902 12906 +4 ; Partials 5793 5793; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5539?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5539/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-30%)` | `1% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5539/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `79.87% <0%> (-0.61%)` | `42% <0%> (ø)` | |; | [...ithwaterman/SmithWatermanIntelAlignerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5539/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXJVbml0VGVzdC5qYXZh) | `60% <0%> (ø)` | `2% <0%> (ø)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5539?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5539?src=pr&el=footer). Last update [10aa8c7...3aec594](https://codecov.io/gh/broadinstitute/gatk/pull/5539?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5539#issuecomment-449065825
https://github.com/broadinstitute/gatk/pull/5539#issuecomment-449065825:2178,Usability,learn,learn,2178,"rage Diff @@; ## master #5539 +/- ##; ============================================; - Coverage 87.06% 87.06% -0.01% ; + Complexity 31324 31322 -2 ; ============================================; Files 1921 1921 ; Lines 144579 144579 ; Branches 15949 15949 ; ============================================; - Hits 125884 125880 -4 ; - Misses 12902 12906 +4 ; Partials 5793 5793; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5539?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5539/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-30%)` | `1% <0%> (-2%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5539/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `79.87% <0%> (-0.61%)` | `42% <0%> (ø)` | |; | [...ithwaterman/SmithWatermanIntelAlignerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5539/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXJVbml0VGVzdC5qYXZh) | `60% <0%> (ø)` | `2% <0%> (ø)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5539?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5539?src=pr&el=footer). Last update [10aa8c7...3aec594](https://codecov.io/gh/broadinstitute/gatk/pull/5539?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5539#issuecomment-449065825
https://github.com/broadinstitute/gatk/pull/5541#issuecomment-449068030:204,Availability,Avail,Available,204,"@Unip0rn Thank you for the pr. I'm not sure I understand what you're trying to do here though. currently when I run `./gatk --list` it prints the list of gatk tools. ex:; ```; USAGE: <program name> [-h]. Available Programs:; --------------------------------------------------------------------------------------; Base Calling: Tools that process sequencing machine data, e.g. Illumina base calls, and detect sequencing level attributes, e.g. adapters; CheckIlluminaDirectory (Picard) Asserts the validity for specified Illumina basecalling data.; CollectIlluminaBasecallingMetrics (Picard) Collects Illumina Basecalling metrics for a sequencing run.; CollectIlluminaLaneMetrics (Picard) Collects Illumina lane metrics for the given BaseCalling analysis directory.; ExtractIlluminaBarcodes (Picard) Tool determines the barcode for each read in an Illumina lane.; IlluminaBasecallsToFastq (Picard) Generate FASTQ file(s) from Illumina basecall read data. ...; ```. With this change it instead prints the gatk launcher help, which is not the intended result. ; ```; Usage template for all tools (uses --spark-runner LOCAL when used with a Spark tool); gatk AnyTool toolArgs. Usage template for Spark tools (will NOT work on non-Spark tools); gatk SparkTool toolArgs [ -- --spark-runner <LOCAL | SPARK | GCS> sparkArgs ]. Getting help; gatk --list Print the list of available tools. gatk Tool --help Print help on a particular tool. Configuration File Specification; --gatk-config-file PATH/TO/GATK/PROPERTIES/FILE. gatk forwards commands to GATK and adds some sugar for submitting spark jobs. --spark-runner <target> controls how spark tools are run; valid targets are:; LOCAL: run using the in-memory spark runner; SPARK: run using spark-submit on an existing cluster; --spark-master must be specified; --spark-submit-command may be specified to control the Spark submit command; arguments to spark-submit may optionally be specified after --; GCS: run using Google cloud dataproc; commands after the --",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5541#issuecomment-449068030
https://github.com/broadinstitute/gatk/pull/5541#issuecomment-449068030:1362,Availability,avail,available,1362,"equencing machine data, e.g. Illumina base calls, and detect sequencing level attributes, e.g. adapters; CheckIlluminaDirectory (Picard) Asserts the validity for specified Illumina basecalling data.; CollectIlluminaBasecallingMetrics (Picard) Collects Illumina Basecalling metrics for a sequencing run.; CollectIlluminaLaneMetrics (Picard) Collects Illumina lane metrics for the given BaseCalling analysis directory.; ExtractIlluminaBarcodes (Picard) Tool determines the barcode for each read in an Illumina lane.; IlluminaBasecallsToFastq (Picard) Generate FASTQ file(s) from Illumina basecall read data. ...; ```. With this change it instead prints the gatk launcher help, which is not the intended result. ; ```; Usage template for all tools (uses --spark-runner LOCAL when used with a Spark tool); gatk AnyTool toolArgs. Usage template for Spark tools (will NOT work on non-Spark tools); gatk SparkTool toolArgs [ -- --spark-runner <LOCAL | SPARK | GCS> sparkArgs ]. Getting help; gatk --list Print the list of available tools. gatk Tool --help Print help on a particular tool. Configuration File Specification; --gatk-config-file PATH/TO/GATK/PROPERTIES/FILE. gatk forwards commands to GATK and adds some sugar for submitting spark jobs. --spark-runner <target> controls how spark tools are run; valid targets are:; LOCAL: run using the in-memory spark runner; SPARK: run using spark-submit on an existing cluster; --spark-master must be specified; --spark-submit-command may be specified to control the Spark submit command; arguments to spark-submit may optionally be specified after --; GCS: run using Google cloud dataproc; commands after the -- will be passed to dataproc; --cluster <your-cluster> must be specified after the --; spark properties and some common spark-submit parameters will be translated; to dataproc equivalents. --dry-run may be specified to output the generated command line without running it; --java-options 'OPTION1[ OPTION2=Y ... ]' optional - pass the given string ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5541#issuecomment-449068030
https://github.com/broadinstitute/gatk/pull/5541#issuecomment-449068030:1429,Deployability,Configurat,Configuration,1429,"ctory (Picard) Asserts the validity for specified Illumina basecalling data.; CollectIlluminaBasecallingMetrics (Picard) Collects Illumina Basecalling metrics for a sequencing run.; CollectIlluminaLaneMetrics (Picard) Collects Illumina lane metrics for the given BaseCalling analysis directory.; ExtractIlluminaBarcodes (Picard) Tool determines the barcode for each read in an Illumina lane.; IlluminaBasecallsToFastq (Picard) Generate FASTQ file(s) from Illumina basecall read data. ...; ```. With this change it instead prints the gatk launcher help, which is not the intended result. ; ```; Usage template for all tools (uses --spark-runner LOCAL when used with a Spark tool); gatk AnyTool toolArgs. Usage template for Spark tools (will NOT work on non-Spark tools); gatk SparkTool toolArgs [ -- --spark-runner <LOCAL | SPARK | GCS> sparkArgs ]. Getting help; gatk --list Print the list of available tools. gatk Tool --help Print help on a particular tool. Configuration File Specification; --gatk-config-file PATH/TO/GATK/PROPERTIES/FILE. gatk forwards commands to GATK and adds some sugar for submitting spark jobs. --spark-runner <target> controls how spark tools are run; valid targets are:; LOCAL: run using the in-memory spark runner; SPARK: run using spark-submit on an existing cluster; --spark-master must be specified; --spark-submit-command may be specified to control the Spark submit command; arguments to spark-submit may optionally be specified after --; GCS: run using Google cloud dataproc; commands after the -- will be passed to dataproc; --cluster <your-cluster> must be specified after the --; spark properties and some common spark-submit parameters will be translated; to dataproc equivalents. --dry-run may be specified to output the generated command line without running it; --java-options 'OPTION1[ OPTION2=Y ... ]' optional - pass the given string of options to the; java JVM at runtime.; Java options MUST be passed inside a single string with space-separated values.; ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5541#issuecomment-449068030
https://github.com/broadinstitute/gatk/pull/5541#issuecomment-449068030:442,Energy Efficiency,adapt,adapters,442,"@Unip0rn Thank you for the pr. I'm not sure I understand what you're trying to do here though. currently when I run `./gatk --list` it prints the list of gatk tools. ex:; ```; USAGE: <program name> [-h]. Available Programs:; --------------------------------------------------------------------------------------; Base Calling: Tools that process sequencing machine data, e.g. Illumina base calls, and detect sequencing level attributes, e.g. adapters; CheckIlluminaDirectory (Picard) Asserts the validity for specified Illumina basecalling data.; CollectIlluminaBasecallingMetrics (Picard) Collects Illumina Basecalling metrics for a sequencing run.; CollectIlluminaLaneMetrics (Picard) Collects Illumina lane metrics for the given BaseCalling analysis directory.; ExtractIlluminaBarcodes (Picard) Tool determines the barcode for each read in an Illumina lane.; IlluminaBasecallsToFastq (Picard) Generate FASTQ file(s) from Illumina basecall read data. ...; ```. With this change it instead prints the gatk launcher help, which is not the intended result. ; ```; Usage template for all tools (uses --spark-runner LOCAL when used with a Spark tool); gatk AnyTool toolArgs. Usage template for Spark tools (will NOT work on non-Spark tools); gatk SparkTool toolArgs [ -- --spark-runner <LOCAL | SPARK | GCS> sparkArgs ]. Getting help; gatk --list Print the list of available tools. gatk Tool --help Print help on a particular tool. Configuration File Specification; --gatk-config-file PATH/TO/GATK/PROPERTIES/FILE. gatk forwards commands to GATK and adds some sugar for submitting spark jobs. --spark-runner <target> controls how spark tools are run; valid targets are:; LOCAL: run using the in-memory spark runner; SPARK: run using spark-submit on an existing cluster; --spark-master must be specified; --spark-submit-command may be specified to control the Spark submit command; arguments to spark-submit may optionally be specified after --; GCS: run using Google cloud dataproc; commands after the --",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5541#issuecomment-449068030
https://github.com/broadinstitute/gatk/pull/5541#issuecomment-449068030:442,Integrability,adapter,adapters,442,"@Unip0rn Thank you for the pr. I'm not sure I understand what you're trying to do here though. currently when I run `./gatk --list` it prints the list of gatk tools. ex:; ```; USAGE: <program name> [-h]. Available Programs:; --------------------------------------------------------------------------------------; Base Calling: Tools that process sequencing machine data, e.g. Illumina base calls, and detect sequencing level attributes, e.g. adapters; CheckIlluminaDirectory (Picard) Asserts the validity for specified Illumina basecalling data.; CollectIlluminaBasecallingMetrics (Picard) Collects Illumina Basecalling metrics for a sequencing run.; CollectIlluminaLaneMetrics (Picard) Collects Illumina lane metrics for the given BaseCalling analysis directory.; ExtractIlluminaBarcodes (Picard) Tool determines the barcode for each read in an Illumina lane.; IlluminaBasecallsToFastq (Picard) Generate FASTQ file(s) from Illumina basecall read data. ...; ```. With this change it instead prints the gatk launcher help, which is not the intended result. ; ```; Usage template for all tools (uses --spark-runner LOCAL when used with a Spark tool); gatk AnyTool toolArgs. Usage template for Spark tools (will NOT work on non-Spark tools); gatk SparkTool toolArgs [ -- --spark-runner <LOCAL | SPARK | GCS> sparkArgs ]. Getting help; gatk --list Print the list of available tools. gatk Tool --help Print help on a particular tool. Configuration File Specification; --gatk-config-file PATH/TO/GATK/PROPERTIES/FILE. gatk forwards commands to GATK and adds some sugar for submitting spark jobs. --spark-runner <target> controls how spark tools are run; valid targets are:; LOCAL: run using the in-memory spark runner; SPARK: run using spark-submit on an existing cluster; --spark-master must be specified; --spark-submit-command may be specified to control the Spark submit command; arguments to spark-submit may optionally be specified after --; GCS: run using Google cloud dataproc; commands after the --",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5541#issuecomment-449068030
https://github.com/broadinstitute/gatk/pull/5541#issuecomment-449068030:442,Modifiability,adapt,adapters,442,"@Unip0rn Thank you for the pr. I'm not sure I understand what you're trying to do here though. currently when I run `./gatk --list` it prints the list of gatk tools. ex:; ```; USAGE: <program name> [-h]. Available Programs:; --------------------------------------------------------------------------------------; Base Calling: Tools that process sequencing machine data, e.g. Illumina base calls, and detect sequencing level attributes, e.g. adapters; CheckIlluminaDirectory (Picard) Asserts the validity for specified Illumina basecalling data.; CollectIlluminaBasecallingMetrics (Picard) Collects Illumina Basecalling metrics for a sequencing run.; CollectIlluminaLaneMetrics (Picard) Collects Illumina lane metrics for the given BaseCalling analysis directory.; ExtractIlluminaBarcodes (Picard) Tool determines the barcode for each read in an Illumina lane.; IlluminaBasecallsToFastq (Picard) Generate FASTQ file(s) from Illumina basecall read data. ...; ```. With this change it instead prints the gatk launcher help, which is not the intended result. ; ```; Usage template for all tools (uses --spark-runner LOCAL when used with a Spark tool); gatk AnyTool toolArgs. Usage template for Spark tools (will NOT work on non-Spark tools); gatk SparkTool toolArgs [ -- --spark-runner <LOCAL | SPARK | GCS> sparkArgs ]. Getting help; gatk --list Print the list of available tools. gatk Tool --help Print help on a particular tool. Configuration File Specification; --gatk-config-file PATH/TO/GATK/PROPERTIES/FILE. gatk forwards commands to GATK and adds some sugar for submitting spark jobs. --spark-runner <target> controls how spark tools are run; valid targets are:; LOCAL: run using the in-memory spark runner; SPARK: run using spark-submit on an existing cluster; --spark-master must be specified; --spark-submit-command may be specified to control the Spark submit command; arguments to spark-submit may optionally be specified after --; GCS: run using Google cloud dataproc; commands after the --",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5541#issuecomment-449068030
https://github.com/broadinstitute/gatk/pull/5541#issuecomment-449068030:1429,Modifiability,Config,Configuration,1429,"ctory (Picard) Asserts the validity for specified Illumina basecalling data.; CollectIlluminaBasecallingMetrics (Picard) Collects Illumina Basecalling metrics for a sequencing run.; CollectIlluminaLaneMetrics (Picard) Collects Illumina lane metrics for the given BaseCalling analysis directory.; ExtractIlluminaBarcodes (Picard) Tool determines the barcode for each read in an Illumina lane.; IlluminaBasecallsToFastq (Picard) Generate FASTQ file(s) from Illumina basecall read data. ...; ```. With this change it instead prints the gatk launcher help, which is not the intended result. ; ```; Usage template for all tools (uses --spark-runner LOCAL when used with a Spark tool); gatk AnyTool toolArgs. Usage template for Spark tools (will NOT work on non-Spark tools); gatk SparkTool toolArgs [ -- --spark-runner <LOCAL | SPARK | GCS> sparkArgs ]. Getting help; gatk --list Print the list of available tools. gatk Tool --help Print help on a particular tool. Configuration File Specification; --gatk-config-file PATH/TO/GATK/PROPERTIES/FILE. gatk forwards commands to GATK and adds some sugar for submitting spark jobs. --spark-runner <target> controls how spark tools are run; valid targets are:; LOCAL: run using the in-memory spark runner; SPARK: run using spark-submit on an existing cluster; --spark-master must be specified; --spark-submit-command may be specified to control the Spark submit command; arguments to spark-submit may optionally be specified after --; GCS: run using Google cloud dataproc; commands after the -- will be passed to dataproc; --cluster <your-cluster> must be specified after the --; spark properties and some common spark-submit parameters will be translated; to dataproc equivalents. --dry-run may be specified to output the generated command line without running it; --java-options 'OPTION1[ OPTION2=Y ... ]' optional - pass the given string of options to the; java JVM at runtime.; Java options MUST be passed inside a single string with space-separated values.; ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5541#issuecomment-449068030
https://github.com/broadinstitute/gatk/pull/5541#issuecomment-449068030:1470,Modifiability,config,config-file,1470,"ctory (Picard) Asserts the validity for specified Illumina basecalling data.; CollectIlluminaBasecallingMetrics (Picard) Collects Illumina Basecalling metrics for a sequencing run.; CollectIlluminaLaneMetrics (Picard) Collects Illumina lane metrics for the given BaseCalling analysis directory.; ExtractIlluminaBarcodes (Picard) Tool determines the barcode for each read in an Illumina lane.; IlluminaBasecallsToFastq (Picard) Generate FASTQ file(s) from Illumina basecall read data. ...; ```. With this change it instead prints the gatk launcher help, which is not the intended result. ; ```; Usage template for all tools (uses --spark-runner LOCAL when used with a Spark tool); gatk AnyTool toolArgs. Usage template for Spark tools (will NOT work on non-Spark tools); gatk SparkTool toolArgs [ -- --spark-runner <LOCAL | SPARK | GCS> sparkArgs ]. Getting help; gatk --list Print the list of available tools. gatk Tool --help Print help on a particular tool. Configuration File Specification; --gatk-config-file PATH/TO/GATK/PROPERTIES/FILE. gatk forwards commands to GATK and adds some sugar for submitting spark jobs. --spark-runner <target> controls how spark tools are run; valid targets are:; LOCAL: run using the in-memory spark runner; SPARK: run using spark-submit on an existing cluster; --spark-master must be specified; --spark-submit-command may be specified to control the Spark submit command; arguments to spark-submit may optionally be specified after --; GCS: run using Google cloud dataproc; commands after the -- will be passed to dataproc; --cluster <your-cluster> must be specified after the --; spark properties and some common spark-submit parameters will be translated; to dataproc equivalents. --dry-run may be specified to output the generated command line without running it; --java-options 'OPTION1[ OPTION2=Y ... ]' optional - pass the given string of options to the; java JVM at runtime.; Java options MUST be passed inside a single string with space-separated values.; ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5541#issuecomment-449068030
https://github.com/broadinstitute/gatk/pull/5541#issuecomment-449068030:401,Safety,detect,detect,401,"@Unip0rn Thank you for the pr. I'm not sure I understand what you're trying to do here though. currently when I run `./gatk --list` it prints the list of gatk tools. ex:; ```; USAGE: <program name> [-h]. Available Programs:; --------------------------------------------------------------------------------------; Base Calling: Tools that process sequencing machine data, e.g. Illumina base calls, and detect sequencing level attributes, e.g. adapters; CheckIlluminaDirectory (Picard) Asserts the validity for specified Illumina basecalling data.; CollectIlluminaBasecallingMetrics (Picard) Collects Illumina Basecalling metrics for a sequencing run.; CollectIlluminaLaneMetrics (Picard) Collects Illumina lane metrics for the given BaseCalling analysis directory.; ExtractIlluminaBarcodes (Picard) Tool determines the barcode for each read in an Illumina lane.; IlluminaBasecallsToFastq (Picard) Generate FASTQ file(s) from Illumina basecall read data. ...; ```. With this change it instead prints the gatk launcher help, which is not the intended result. ; ```; Usage template for all tools (uses --spark-runner LOCAL when used with a Spark tool); gatk AnyTool toolArgs. Usage template for Spark tools (will NOT work on non-Spark tools); gatk SparkTool toolArgs [ -- --spark-runner <LOCAL | SPARK | GCS> sparkArgs ]. Getting help; gatk --list Print the list of available tools. gatk Tool --help Print help on a particular tool. Configuration File Specification; --gatk-config-file PATH/TO/GATK/PROPERTIES/FILE. gatk forwards commands to GATK and adds some sugar for submitting spark jobs. --spark-runner <target> controls how spark tools are run; valid targets are:; LOCAL: run using the in-memory spark runner; SPARK: run using spark-submit on an existing cluster; --spark-master must be specified; --spark-submit-command may be specified to control the Spark submit command; arguments to spark-submit may optionally be specified after --; GCS: run using Google cloud dataproc; commands after the --",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5541#issuecomment-449068030
https://github.com/broadinstitute/gatk/pull/5541#issuecomment-449068030:484,Testability,Assert,Asserts,484,"@Unip0rn Thank you for the pr. I'm not sure I understand what you're trying to do here though. currently when I run `./gatk --list` it prints the list of gatk tools. ex:; ```; USAGE: <program name> [-h]. Available Programs:; --------------------------------------------------------------------------------------; Base Calling: Tools that process sequencing machine data, e.g. Illumina base calls, and detect sequencing level attributes, e.g. adapters; CheckIlluminaDirectory (Picard) Asserts the validity for specified Illumina basecalling data.; CollectIlluminaBasecallingMetrics (Picard) Collects Illumina Basecalling metrics for a sequencing run.; CollectIlluminaLaneMetrics (Picard) Collects Illumina lane metrics for the given BaseCalling analysis directory.; ExtractIlluminaBarcodes (Picard) Tool determines the barcode for each read in an Illumina lane.; IlluminaBasecallsToFastq (Picard) Generate FASTQ file(s) from Illumina basecall read data. ...; ```. With this change it instead prints the gatk launcher help, which is not the intended result. ; ```; Usage template for all tools (uses --spark-runner LOCAL when used with a Spark tool); gatk AnyTool toolArgs. Usage template for Spark tools (will NOT work on non-Spark tools); gatk SparkTool toolArgs [ -- --spark-runner <LOCAL | SPARK | GCS> sparkArgs ]. Getting help; gatk --list Print the list of available tools. gatk Tool --help Print help on a particular tool. Configuration File Specification; --gatk-config-file PATH/TO/GATK/PROPERTIES/FILE. gatk forwards commands to GATK and adds some sugar for submitting spark jobs. --spark-runner <target> controls how spark tools are run; valid targets are:; LOCAL: run using the in-memory spark runner; SPARK: run using spark-submit on an existing cluster; --spark-master must be specified; --spark-submit-command may be specified to control the Spark submit command; arguments to spark-submit may optionally be specified after --; GCS: run using Google cloud dataproc; commands after the --",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5541#issuecomment-449068030
https://github.com/broadinstitute/gatk/pull/5541#issuecomment-449084425:3505,Deployability,pipeline,pipelines,3505,| [...tools/walkers/haplotypecaller/HaplotypeCaller.java](https://codecov.io/gh/broadinstitute/gatk/pull/5541/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9IYXBsb3R5cGVDYWxsZXIuamF2YQ==) | `0% <0%> (-84.211%)` | `0% <0%> (-23%)` | |; | [...aplotypecaller/HaplotypeCallerIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5541/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9IYXBsb3R5cGVDYWxsZXJJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `5.656% <0%> (-82.579%)` | `9% <0%> (-75%)` | |; | [...ls/genomicsdb/GenomicsDBImportIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5541/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9nZW5vbWljc2RiL0dlbm9taWNzREJJbXBvcnRJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `9.481% <0%> (-77.201%)` | `2% <0%> (-75%)` | |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5541/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-74.257%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5541/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...ols/funcotator/FuncotatorDataSourceDownloader.java](https://codecov.io/gh/broadinstitute/gatk/pull/5541/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0Z1bmNvdGF0b3JEYXRhU291cmNlRG93bmxvYWRlci5qYXZh) | `0% <0%> (-66.197%)` | `0% <0%> (-14%)` | |; | ... and [67 more](https://codecov.io/gh/broadinstitute/gatk/pull/5541/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5541#issuecomment-449084425
https://github.com/broadinstitute/gatk/pull/5541#issuecomment-449125641:62,Deployability,install,installation,62,"@lbergelson Ah, I was misunderstanding something there. On an installation on Linux Mint it ran into an exception, basically saying there were some binary incompatibilities (unfortunatly it was no installation for myself, so I cannot remember the exact Exception right now). Then reading the comment I got confused and supposed my PR was providing the desired behaviour.; However now seeing your setup working different I realize that my installation was not yet succesful. ; So this PR does not fix anything.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5541#issuecomment-449125641
https://github.com/broadinstitute/gatk/pull/5541#issuecomment-449125641:197,Deployability,install,installation,197,"@lbergelson Ah, I was misunderstanding something there. On an installation on Linux Mint it ran into an exception, basically saying there were some binary incompatibilities (unfortunatly it was no installation for myself, so I cannot remember the exact Exception right now). Then reading the comment I got confused and supposed my PR was providing the desired behaviour.; However now seeing your setup working different I realize that my installation was not yet succesful. ; So this PR does not fix anything.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5541#issuecomment-449125641
https://github.com/broadinstitute/gatk/pull/5541#issuecomment-449125641:438,Deployability,install,installation,438,"@lbergelson Ah, I was misunderstanding something there. On an installation on Linux Mint it ran into an exception, basically saying there were some binary incompatibilities (unfortunatly it was no installation for myself, so I cannot remember the exact Exception right now). Then reading the comment I got confused and supposed my PR was providing the desired behaviour.; However now seeing your setup working different I realize that my installation was not yet succesful. ; So this PR does not fix anything.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5541#issuecomment-449125641
https://github.com/broadinstitute/gatk/issues/5543#issuecomment-463926822:18,Availability,avail,available,18,"Hi, are there any available updates on this bug ? ; I have run into it many times with gatk-4.1.0.0.; Thank you!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5543#issuecomment-463926822
https://github.com/broadinstitute/gatk/issues/5543#issuecomment-463926822:28,Deployability,update,updates,28,"Hi, are there any available updates on this bug ? ; I have run into it many times with gatk-4.1.0.0.; Thank you!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5543#issuecomment-463926822
https://github.com/broadinstitute/gatk/issues/5543#issuecomment-465193131:353,Safety,avoid,avoids,353,@davidbenjamin Could you take a look at this? @TedBrookings thinks it might be as simple as changing the check to allow 0 length reads when initializing the pairHmm. Neither of us are sure that that's a great solution though. . It seems like if you have no read bases you can't do any useful calculation. Should there be an earlier check in mutect that avoids assembling a region if there aren't any reads with bases?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5543#issuecomment-465193131
https://github.com/broadinstitute/gatk/issues/5543#issuecomment-465193131:82,Usability,simpl,simple,82,@davidbenjamin Could you take a look at this? @TedBrookings thinks it might be as simple as changing the check to allow 0 length reads when initializing the pairHmm. Neither of us are sure that that's a great solution though. . It seems like if you have no read bases you can't do any useful calculation. Should there be an earlier check in mutect that avoids assembling a region if there aren't any reads with bases?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5543#issuecomment-465193131
https://github.com/broadinstitute/gatk/issues/5543#issuecomment-466277823:37,Usability,simpl,simply,37,"@TedBrookings is correct that we can simply waive the check. We could check for an empty region upstream in Mutect2, but we would also have to do it for HaplotypeCaller, which would be annoying. There's basically no cost to running PairHMM on an empty set of reads once we have already assembled, so I don't see a good reason to treat this as a special case.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5543#issuecomment-466277823
https://github.com/broadinstitute/gatk/issues/5543#issuecomment-466489687:70,Deployability,release,releases,70,@JJBio Unfortunately GATK 3 is end-of-life and will not have any more releases/bug-fixes.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5543#issuecomment-466489687
https://github.com/broadinstitute/gatk/issues/5543#issuecomment-466662922:86,Availability,avail,available,86,"Just for information, when do you think a new release with this corrected bug will be available (possibly also in bioconda) ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5543#issuecomment-466662922
https://github.com/broadinstitute/gatk/issues/5543#issuecomment-466662922:46,Deployability,release,release,46,"Just for information, when do you think a new release with this corrected bug will be available (possibly also in bioconda) ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5543#issuecomment-466662922
https://github.com/broadinstitute/gatk/issues/5543#issuecomment-470579844:4464,Availability,down,down,4464,"709 INFO ProgressMeter - 1:16264047 3.3 56380 17024.5; 09:52:36.145 INFO ProgressMeter - 1:16891523 3.5 58590 16809.0; 09:52:50.980 INFO ProgressMeter - 1:16893022 3.7 58600 15698.3; 09:53:01.463 INFO ProgressMeter - 1:17740440 3.9 61570 15756.5; 09:53:12.294 INFO ProgressMeter - 1:19379390 4.1 67150 16425.7; 09:53:22.294 INFO ProgressMeter - 1:20576686 4.3 71380 16776.4; 09:53:32.681 INFO ProgressMeter - 1:21106727 4.4 73230 16538.3; 09:53:44.258 INFO ProgressMeter - 1:21270052 4.6 73820 15975.4; 09:53:54.757 INFO ProgressMeter - 1:21754504 4.8 75500 15742.8; 09:54:04.928 INFO ProgressMeter - 1:23419224 5.0 81370 16387.6; 09:54:15.956 INFO ProgressMeter - 1:23812728 5.1 82750 16070.6; 09:54:31.008 INFO ProgressMeter - 1:24023237 5.4 83470 15457.4; 09:54:33.610 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 58.921665822; 09:54:33.611 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 72.92 sec; 09:54:33.612 INFO Mutect2 - Shutting down engine; [March 7, 2019 9:54:33 AM EST] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 5.51 minutes.; Runtime.totalMemory()=193003520; java.lang.IllegalArgumentException: readMaxLength must be > 0 but got 0; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:730); 	at org.broadinstitute.hellbender.utils.pairhmm.PairHMM.initialize(PairHMM.java:152); 	at org.broadinstitute.hellbender.utils.pairhmm.N2MemoryPairHMM.initialize(N2MemoryPairHMM.java:28); 	at org.broadinstitute.hellbender.utils.pairhmm.LoglessPairHMM.initialize(LoglessPairHMM.java:7); 	at org.broadinstitute.hellbender.utils.pairhmm.PairHMM.initialize(PairHMM.java:177); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.initializePairHMM(PairHMMLikelihoodCalculationEngine.java:242); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngine.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5543#issuecomment-470579844
https://github.com/broadinstitute/gatk/issues/5543#issuecomment-470579844:261,Performance,Load,Loading,261,"mutect2 stopped at chromosome 1 . $ java -jar -Xmx12g gatk-4.1.0.0/gatk-package-4.1.0.0-local.jar Mutect2 -R Homo_sapiens_assembly19.fasta -I Specimen_SNCR.10_1.bam -tumor Specimen_10_1 -O mutect2/10_1.vcf&; [1] 40657; $ 09:49:03.454 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/Tools/gatk-4.1.0.0/gatk-package-4.1.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 09:49:05.899 INFO Mutect2 - ------------------------------------------------------------; 09:49:05.899 INFO Mutect2 - The Genome Analysis Toolkit (GATK) v4.1.0.0; 09:49:05.900 INFO Mutect2 - For support and documentation go to https://software.broadinstitute.org/gatk/. 09:49:05.900 INFO Mutect2 - Java runtime: IBM J9 VM v8.0.5.25 - pxa6480sr5fp25-20181030_01(SR5 FP25); 09:49:05.901 INFO Mutect2 - Start Date/Time: March 7, 2019 9:49:03 AM EST; 09:49:05.901 INFO Mutect2 - ------------------------------------------------------------; 09:49:05.901 INFO Mutect2 - ------------------------------------------------------------; 09:49:05.901 INFO Mutect2 - HTSJDK Version: 2.18.2; 09:49:05.901 INFO Mutect2 - Picard Version: 2.18.25; 09:49:05.902 INFO Mutect2 - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 09:49:05.902 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 09:49:05.902 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 09:49:05.902 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 09:49:05.902 INFO Mutect2 - Deflater: IntelDeflater; 09:49:05.902 INFO Mutect2 - Inflater: IntelInflater; 09:49:05.902 INFO Mutect2 - GCS max retries/reopens: 20; 09:49:05.902 INFO Mutect2 - Requester pays: disabled; 09:49:05.902 INFO Mutect2 - Initializing engine; 09:49:06.887 INFO Mutect2 - Done initializing engine; 09:49:06.935 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/Tools/gatk-4.1.0.0/gatk-package-4.1.0.0-local.jar!/com/intel/gkl/native/libgkl_utils.so; 09:49:06.937 INFO PairHMM - OpenMP multi-threaded A",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5543#issuecomment-470579844
https://github.com/broadinstitute/gatk/issues/5543#issuecomment-470579844:1817,Performance,Load,Loading,1817,"Date/Time: March 7, 2019 9:49:03 AM EST; 09:49:05.901 INFO Mutect2 - ------------------------------------------------------------; 09:49:05.901 INFO Mutect2 - ------------------------------------------------------------; 09:49:05.901 INFO Mutect2 - HTSJDK Version: 2.18.2; 09:49:05.901 INFO Mutect2 - Picard Version: 2.18.25; 09:49:05.902 INFO Mutect2 - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 09:49:05.902 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 09:49:05.902 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 09:49:05.902 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 09:49:05.902 INFO Mutect2 - Deflater: IntelDeflater; 09:49:05.902 INFO Mutect2 - Inflater: IntelInflater; 09:49:05.902 INFO Mutect2 - GCS max retries/reopens: 20; 09:49:05.902 INFO Mutect2 - Requester pays: disabled; 09:49:05.902 INFO Mutect2 - Initializing engine; 09:49:06.887 INFO Mutect2 - Done initializing engine; 09:49:06.935 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/Tools/gatk-4.1.0.0/gatk-package-4.1.0.0-local.jar!/com/intel/gkl/native/libgkl_utils.so; 09:49:06.937 INFO PairHMM - OpenMP multi-threaded AVX-accelerated native PairHMM implementation is not supported; 09:49:06.937 WARN PairHMM - ***WARNING: Machine does not have the AVX instruction set support needed for the accelerated AVX PairHmm. Falling back to the MUCH slower LOGLESS_CACHING implementation!; 09:49:07.007 INFO ProgressMeter - Starting traversal; 09:49:07.007 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 09:49:17.023 INFO ProgressMeter - 1:139173 0.2 480 2875.7; 09:49:27.704 INFO ProgressMeter - 1:763661 0.3 2590 7508.3; 09:49:38.001 INFO ProgressMeter - 1:958723 0.5 3290 6369.0; 09:49:49.182 INFO ProgressMeter - 1:981050 0.7 3380 4808.5; 09:50:02.383 INFO ProgressMeter - 1:988991 0.9 3440 3727.3; 09:50:13.586 INFO ProgressMeter - 1:1227096 1.1 4290 3866.1; 09:50:23.594 INFO ProgressMeter - 1:1",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5543#issuecomment-470579844
https://github.com/broadinstitute/gatk/issues/5543#issuecomment-470579844:1985,Performance,multi-thread,multi-threaded,1985,---------------; 09:49:05.901 INFO Mutect2 - HTSJDK Version: 2.18.2; 09:49:05.901 INFO Mutect2 - Picard Version: 2.18.25; 09:49:05.902 INFO Mutect2 - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 09:49:05.902 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 09:49:05.902 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 09:49:05.902 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 09:49:05.902 INFO Mutect2 - Deflater: IntelDeflater; 09:49:05.902 INFO Mutect2 - Inflater: IntelInflater; 09:49:05.902 INFO Mutect2 - GCS max retries/reopens: 20; 09:49:05.902 INFO Mutect2 - Requester pays: disabled; 09:49:05.902 INFO Mutect2 - Initializing engine; 09:49:06.887 INFO Mutect2 - Done initializing engine; 09:49:06.935 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/Tools/gatk-4.1.0.0/gatk-package-4.1.0.0-local.jar!/com/intel/gkl/native/libgkl_utils.so; 09:49:06.937 INFO PairHMM - OpenMP multi-threaded AVX-accelerated native PairHMM implementation is not supported; 09:49:06.937 WARN PairHMM - ***WARNING: Machine does not have the AVX instruction set support needed for the accelerated AVX PairHmm. Falling back to the MUCH slower LOGLESS_CACHING implementation!; 09:49:07.007 INFO ProgressMeter - Starting traversal; 09:49:07.007 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 09:49:17.023 INFO ProgressMeter - 1:139173 0.2 480 2875.7; 09:49:27.704 INFO ProgressMeter - 1:763661 0.3 2590 7508.3; 09:49:38.001 INFO ProgressMeter - 1:958723 0.5 3290 6369.0; 09:49:49.182 INFO ProgressMeter - 1:981050 0.7 3380 4808.5; 09:50:02.383 INFO ProgressMeter - 1:988991 0.9 3440 3727.3; 09:50:13.586 INFO ProgressMeter - 1:1227096 1.1 4290 3866.1; 09:50:23.594 INFO ProgressMeter - 1:1460850 1.3 5240 4105.1; 09:50:34.165 INFO ProgressMeter - 1:1960541 1.5 7060 4860.1; 09:50:46.537 INFO ProgressMeter - 1:2489135 1.7 8930 5383.3; 09:50:56.541 INFO ProgressMeter - 1:3195743 1.8 11330 6206,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5543#issuecomment-470579844
https://github.com/broadinstitute/gatk/issues/5543#issuecomment-470579844:4754,Security,validat,validateArg,4754,"90 4.1 67150 16425.7; 09:53:22.294 INFO ProgressMeter - 1:20576686 4.3 71380 16776.4; 09:53:32.681 INFO ProgressMeter - 1:21106727 4.4 73230 16538.3; 09:53:44.258 INFO ProgressMeter - 1:21270052 4.6 73820 15975.4; 09:53:54.757 INFO ProgressMeter - 1:21754504 4.8 75500 15742.8; 09:54:04.928 INFO ProgressMeter - 1:23419224 5.0 81370 16387.6; 09:54:15.956 INFO ProgressMeter - 1:23812728 5.1 82750 16070.6; 09:54:31.008 INFO ProgressMeter - 1:24023237 5.4 83470 15457.4; 09:54:33.610 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 58.921665822; 09:54:33.611 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 72.92 sec; 09:54:33.612 INFO Mutect2 - Shutting down engine; [March 7, 2019 9:54:33 AM EST] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 5.51 minutes.; Runtime.totalMemory()=193003520; java.lang.IllegalArgumentException: readMaxLength must be > 0 but got 0; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:730); 	at org.broadinstitute.hellbender.utils.pairhmm.PairHMM.initialize(PairHMM.java:152); 	at org.broadinstitute.hellbender.utils.pairhmm.N2MemoryPairHMM.initialize(N2MemoryPairHMM.java:28); 	at org.broadinstitute.hellbender.utils.pairhmm.LoglessPairHMM.initialize(LoglessPairHMM.java:7); 	at org.broadinstitute.hellbender.utils.pairhmm.PairHMM.initialize(PairHMM.java:177); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.initializePairHMM(PairHMMLikelihoodCalculationEngine.java:242); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngine.java:177); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2Engine.callRegion(Mutect2Engine.java:229); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2.apply(Mutect2.java:232); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(Assemb",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5543#issuecomment-470579844
https://github.com/broadinstitute/gatk/issues/5543#issuecomment-470579844:5018,Testability,Log,LoglessPairHMM,5018," 75500 15742.8; 09:54:04.928 INFO ProgressMeter - 1:23419224 5.0 81370 16387.6; 09:54:15.956 INFO ProgressMeter - 1:23812728 5.1 82750 16070.6; 09:54:31.008 INFO ProgressMeter - 1:24023237 5.4 83470 15457.4; 09:54:33.610 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 58.921665822; 09:54:33.611 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 72.92 sec; 09:54:33.612 INFO Mutect2 - Shutting down engine; [March 7, 2019 9:54:33 AM EST] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 5.51 minutes.; Runtime.totalMemory()=193003520; java.lang.IllegalArgumentException: readMaxLength must be > 0 but got 0; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:730); 	at org.broadinstitute.hellbender.utils.pairhmm.PairHMM.initialize(PairHMM.java:152); 	at org.broadinstitute.hellbender.utils.pairhmm.N2MemoryPairHMM.initialize(N2MemoryPairHMM.java:28); 	at org.broadinstitute.hellbender.utils.pairhmm.LoglessPairHMM.initialize(LoglessPairHMM.java:7); 	at org.broadinstitute.hellbender.utils.pairhmm.PairHMM.initialize(PairHMM.java:177); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.initializePairHMM(PairHMMLikelihoodCalculationEngine.java:242); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngine.java:177); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2Engine.callRegion(Mutect2Engine.java:229); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2.apply(Mutect2.java:232); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:291); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:267); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:966); 	at org.broadinstitute.hellbender.cmdline.CommandLineProg",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5543#issuecomment-470579844
https://github.com/broadinstitute/gatk/issues/5543#issuecomment-470579844:5044,Testability,Log,LoglessPairHMM,5044,":04.928 INFO ProgressMeter - 1:23419224 5.0 81370 16387.6; 09:54:15.956 INFO ProgressMeter - 1:23812728 5.1 82750 16070.6; 09:54:31.008 INFO ProgressMeter - 1:24023237 5.4 83470 15457.4; 09:54:33.610 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 58.921665822; 09:54:33.611 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 72.92 sec; 09:54:33.612 INFO Mutect2 - Shutting down engine; [March 7, 2019 9:54:33 AM EST] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 5.51 minutes.; Runtime.totalMemory()=193003520; java.lang.IllegalArgumentException: readMaxLength must be > 0 but got 0; 	at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:730); 	at org.broadinstitute.hellbender.utils.pairhmm.PairHMM.initialize(PairHMM.java:152); 	at org.broadinstitute.hellbender.utils.pairhmm.N2MemoryPairHMM.initialize(N2MemoryPairHMM.java:28); 	at org.broadinstitute.hellbender.utils.pairhmm.LoglessPairHMM.initialize(LoglessPairHMM.java:7); 	at org.broadinstitute.hellbender.utils.pairhmm.PairHMM.initialize(PairHMM.java:177); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.initializePairHMM(PairHMMLikelihoodCalculationEngine.java:242); 	at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.PairHMMLikelihoodCalculationEngine.computeReadLikelihoods(PairHMMLikelihoodCalculationEngine.java:177); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2Engine.callRegion(Mutect2Engine.java:229); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2.apply(Mutect2.java:232); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:291); 	at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:267); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:966); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandL",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5543#issuecomment-470579844
https://github.com/broadinstitute/gatk/issues/5543#issuecomment-470610582:36,Deployability,release,release,36,@af8 We are tentatively planning to release 4.1.1.0 with this bug fix next week.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5543#issuecomment-470610582
https://github.com/broadinstitute/gatk/issues/5543#issuecomment-470610965:143,Deployability,release,release,143,"@rong923 it looks like you are encountering the same issue. You can build the the gatk master branch to get a fix now, or wait for the 4.1.1.0 release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5543#issuecomment-470610965
https://github.com/broadinstitute/gatk/issues/5543#issuecomment-470662216:212,Availability,error,errors,212,"Thanks a lot @davidbenjamin ; In the meantime I have compiled the master branch when I saw this issue was resolved and it worked fine. I tried also to create a pon with this fresh compiled version but I got some errors (don't remember exactly what right now). Looks like you are in the middle of changing the pipeline of pon creation by integrating GenomicsDB as an intermediate, right ? Do you think it will also be ready for this next release ? I would like to create the pon with the same GATK version. Problem is I can not fall back on an earlier version because I would definitely get the bug we are talking about in this thread :-). Perhaps we should also change our computing nodes at some point I guess :). Thanks again",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5543#issuecomment-470662216
https://github.com/broadinstitute/gatk/issues/5543#issuecomment-470662216:309,Deployability,pipeline,pipeline,309,"Thanks a lot @davidbenjamin ; In the meantime I have compiled the master branch when I saw this issue was resolved and it worked fine. I tried also to create a pon with this fresh compiled version but I got some errors (don't remember exactly what right now). Looks like you are in the middle of changing the pipeline of pon creation by integrating GenomicsDB as an intermediate, right ? Do you think it will also be ready for this next release ? I would like to create the pon with the same GATK version. Problem is I can not fall back on an earlier version because I would definitely get the bug we are talking about in this thread :-). Perhaps we should also change our computing nodes at some point I guess :). Thanks again",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5543#issuecomment-470662216
https://github.com/broadinstitute/gatk/issues/5543#issuecomment-470662216:337,Deployability,integrat,integrating,337,"Thanks a lot @davidbenjamin ; In the meantime I have compiled the master branch when I saw this issue was resolved and it worked fine. I tried also to create a pon with this fresh compiled version but I got some errors (don't remember exactly what right now). Looks like you are in the middle of changing the pipeline of pon creation by integrating GenomicsDB as an intermediate, right ? Do you think it will also be ready for this next release ? I would like to create the pon with the same GATK version. Problem is I can not fall back on an earlier version because I would definitely get the bug we are talking about in this thread :-). Perhaps we should also change our computing nodes at some point I guess :). Thanks again",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5543#issuecomment-470662216
https://github.com/broadinstitute/gatk/issues/5543#issuecomment-470662216:437,Deployability,release,release,437,"Thanks a lot @davidbenjamin ; In the meantime I have compiled the master branch when I saw this issue was resolved and it worked fine. I tried also to create a pon with this fresh compiled version but I got some errors (don't remember exactly what right now). Looks like you are in the middle of changing the pipeline of pon creation by integrating GenomicsDB as an intermediate, right ? Do you think it will also be ready for this next release ? I would like to create the pon with the same GATK version. Problem is I can not fall back on an earlier version because I would definitely get the bug we are talking about in this thread :-). Perhaps we should also change our computing nodes at some point I guess :). Thanks again",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5543#issuecomment-470662216
https://github.com/broadinstitute/gatk/issues/5543#issuecomment-470662216:337,Integrability,integrat,integrating,337,"Thanks a lot @davidbenjamin ; In the meantime I have compiled the master branch when I saw this issue was resolved and it worked fine. I tried also to create a pon with this fresh compiled version but I got some errors (don't remember exactly what right now). Looks like you are in the middle of changing the pipeline of pon creation by integrating GenomicsDB as an intermediate, right ? Do you think it will also be ready for this next release ? I would like to create the pon with the same GATK version. Problem is I can not fall back on an earlier version because I would definitely get the bug we are talking about in this thread :-). Perhaps we should also change our computing nodes at some point I guess :). Thanks again",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5543#issuecomment-470662216
https://github.com/broadinstitute/gatk/issues/5543#issuecomment-470666407:14,Deployability,release,release,14,@af8 The next release will also have a WDL workflow for creating the pon in the new way.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5543#issuecomment-470666407
https://github.com/broadinstitute/gatk/issues/5543#issuecomment-487724137:81,Deployability,pipeline,pipelines,81,"Yes @rong923, go with >= 4.1.1.0 and you are safe. I ve been running hundreds of pipelines without a problem now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5543#issuecomment-487724137
https://github.com/broadinstitute/gatk/issues/5543#issuecomment-487724137:45,Safety,safe,safe,45,"Yes @rong923, go with >= 4.1.1.0 and you are safe. I ve been running hundreds of pipelines without a problem now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5543#issuecomment-487724137
https://github.com/broadinstitute/gatk/pull/5544#issuecomment-449424951:2272,Energy Efficiency,Adapt,AdaptiveChainPruner,2272,erArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/5544/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9SZWFkVGhyZWFkaW5nQXNzZW1ibGVyQXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `94.118% <ø> (ø)` | `1 <0> (ø)` | :arrow_down: |; | [...kers/haplotypecaller/AssemblyBasedCallerUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5544/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9Bc3NlbWJseUJhc2VkQ2FsbGVyVXRpbHMuamF2YQ==) | `76.923% <ø> (-0.946%)` | `34 <0> (-1)` | |; | [...walkers/haplotypecaller/HaplotypeCallerEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/5544/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9IYXBsb3R5cGVDYWxsZXJFbmdpbmUuamF2YQ==) | `78.425% <100%> (ø)` | `76 <0> (ø)` | :arrow_down: |; | [...rs/haplotypecaller/graphs/AdaptiveChainPruner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5544/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9ncmFwaHMvQWRhcHRpdmVDaGFpblBydW5lci5qYXZh) | `95.349% <100%> (+0.111%)` | `16 <0> (ø)` | :arrow_down: |; | [...hellbender/tools/walkers/mutect/Mutect2Engine.java](https://codecov.io/gh/broadinstitute/gatk/pull/5544/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9NdXRlY3QyRW5naW5lLmphdmE=) | `90.173% <100%> (ø)` | `65 <0> (ø)` | :arrow_down: |; | [...otypecaller/HaplotypeCallerArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/5544/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9IYXBsb3R5cGVDYWxsZXJBcmd1bWVudENvbGxlY3Rpb24uamF2YQ==) | `100% <100%> (ø)` | `3 <1> (+1)` | :arrow_up: |; | [...r/tools/walkers/mutect/Mutect2Integrati,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5544#issuecomment-449424951
https://github.com/broadinstitute/gatk/pull/5544#issuecomment-449424951:2272,Modifiability,Adapt,AdaptiveChainPruner,2272,erArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/5544/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9SZWFkVGhyZWFkaW5nQXNzZW1ibGVyQXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `94.118% <ø> (ø)` | `1 <0> (ø)` | :arrow_down: |; | [...kers/haplotypecaller/AssemblyBasedCallerUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5544/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9Bc3NlbWJseUJhc2VkQ2FsbGVyVXRpbHMuamF2YQ==) | `76.923% <ø> (-0.946%)` | `34 <0> (-1)` | |; | [...walkers/haplotypecaller/HaplotypeCallerEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/5544/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9IYXBsb3R5cGVDYWxsZXJFbmdpbmUuamF2YQ==) | `78.425% <100%> (ø)` | `76 <0> (ø)` | :arrow_down: |; | [...rs/haplotypecaller/graphs/AdaptiveChainPruner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5544/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9ncmFwaHMvQWRhcHRpdmVDaGFpblBydW5lci5qYXZh) | `95.349% <100%> (+0.111%)` | `16 <0> (ø)` | :arrow_down: |; | [...hellbender/tools/walkers/mutect/Mutect2Engine.java](https://codecov.io/gh/broadinstitute/gatk/pull/5544/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9NdXRlY3QyRW5naW5lLmphdmE=) | `90.173% <100%> (ø)` | `65 <0> (ø)` | :arrow_down: |; | [...otypecaller/HaplotypeCallerArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/5544/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9IYXBsb3R5cGVDYWxsZXJBcmd1bWVudENvbGxlY3Rpb24uamF2YQ==) | `100% <100%> (ø)` | `3 <1> (+1)` | :arrow_up: |; | [...r/tools/walkers/mutect/Mutect2Integrati,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5544#issuecomment-449424951
https://github.com/broadinstitute/gatk/issues/5545#issuecomment-449440744:180,Availability,robust,robust,180,@tomwhite I think this might have been from the first run of the jenkins tests since the disq change over - not sure though. You should have access to the `broad-gatk-test-jenkins-robust` bucket now if you need it.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5545#issuecomment-449440744
https://github.com/broadinstitute/gatk/issues/5545#issuecomment-449440744:141,Security,access,access,141,@tomwhite I think this might have been from the first run of the jenkins tests since the disq change over - not sure though. You should have access to the `broad-gatk-test-jenkins-robust` bucket now if you need it.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5545#issuecomment-449440744
https://github.com/broadinstitute/gatk/issues/5545#issuecomment-449440744:73,Testability,test,tests,73,@tomwhite I think this might have been from the first run of the jenkins tests since the disq change over - not sure though. You should have access to the `broad-gatk-test-jenkins-robust` bucket now if you need it.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5545#issuecomment-449440744
https://github.com/broadinstitute/gatk/issues/5545#issuecomment-449440744:167,Testability,test,test-jenkins-robust,167,@tomwhite I think this might have been from the first run of the jenkins tests since the disq change over - not sure though. You should have access to the `broad-gatk-test-jenkins-robust` bucket now if you need it.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5545#issuecomment-449440744
https://github.com/broadinstitute/gatk/issues/5545#issuecomment-451945287:134,Testability,test,testing,134,"@davidbernick @cmnbroad Thanks for reporting this. It looks like there is a bug with writing sharded BAM output to GCS. I'm currently testing a fix in Disq, but in the meantime you could drop `--sharded-output true` as a workaround to see if that fixes the problem.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5545#issuecomment-451945287
https://github.com/broadinstitute/gatk/pull/5546#issuecomment-449481249:66,Deployability,update,updated,66,@lbergelson looks like `RandomDNA.java` needs to have it's import updated to `com.google.common.annotations.VisibleForTesting`,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5546#issuecomment-449481249
https://github.com/broadinstitute/gatk/pull/5546#issuecomment-449505781:248,Deployability,release,released,248,"@cmnbroad . The warning -> info change is from https://github.com/googleapis/google-auth-library-java/pull/199; That didn't get rid of the stack trace though, just made it an info trace which is still gross. I made a pr which is merged but not yet released which will move the stack trace to debug. . It should be in 0.75 I think...; https://github.com/googleapis/google-auth-library-java/pull/214. This includes two other prs that I made to fix other output issues in the auth library which made it into the 0.74 release. ; https://github.com/googleapis/google-auth-library-java/pull/205 ; https://github.com/googleapis/google-auth-library-java/pull/207",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5546#issuecomment-449505781
https://github.com/broadinstitute/gatk/pull/5546#issuecomment-449505781:514,Deployability,release,release,514,"@cmnbroad . The warning -> info change is from https://github.com/googleapis/google-auth-library-java/pull/199; That didn't get rid of the stack trace though, just made it an info trace which is still gross. I made a pr which is merged but not yet released which will move the stack trace to debug. . It should be in 0.75 I think...; https://github.com/googleapis/google-auth-library-java/pull/214. This includes two other prs that I made to fix other output issues in the auth library which made it into the 0.74 release. ; https://github.com/googleapis/google-auth-library-java/pull/205 ; https://github.com/googleapis/google-auth-library-java/pull/207",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5546#issuecomment-449505781
https://github.com/broadinstitute/gatk/pull/5546#issuecomment-449505884:16,Testability,test,test,16,"The only way to test would be scraping the logs, which we could do... but it seems gross.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5546#issuecomment-449505884
https://github.com/broadinstitute/gatk/pull/5546#issuecomment-449505884:43,Testability,log,logs,43,"The only way to test would be scraping the logs, which we could do... but it seems gross.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5546#issuecomment-449505884
https://github.com/broadinstitute/gatk/pull/5546#issuecomment-449549539:188,Testability,test,test,188,"There seems to be a change in how gcs recognizes directories that breaks things. Something in `Files.isDirectory` changed. Previously:; `Files.isDirectory(IOUtils.getPath(""gs://hellbender/test/resources/parallel_copy/"")) == true`; now it's false. Weirdly, without the slash it's now true where previously it wasn't... @jean-philippe-martin This seems related to https://github.com/googleapis/google-cloud-java/pull/3775",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5546#issuecomment-449549539
https://github.com/broadinstitute/gatk/pull/5546#issuecomment-450400675:115,Testability,test,test,115,"@lbergelson The situation is rather odd: you seem to have **both** a file **and** a folder named ""`gs://hellbender/test/resources/parallel_copy/`"". Observe the first line of output:. ```bash; $ gsutil ls gs://hellbender/test/resources/parallel_copy/; gs://hellbender/test/resources/parallel_copy/; gs://hellbender/test/resources/parallel_copy/bar.txt; gs://hellbender/test/resources/parallel_copy/foo.txt; ```. The file exists and is empty. For evidence, observe that I can cat the file (note how it behaves differently from normal folders):. ```bash; $ gsutil cat gs://hellbender/test/resources/; CommandException: No URLs matched: gs://hellbender/test/resources/; $ gsutil cat gs://hellbender/test/resources/parallel_copy/; $; ```. So NIO is technically correct, `gs://hellbender/test/resources/parallel_copy/` is a file. Did you do anything unusual with regards to this path?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5546#issuecomment-450400675
https://github.com/broadinstitute/gatk/pull/5546#issuecomment-450400675:220,Testability,test,test,220,"@lbergelson The situation is rather odd: you seem to have **both** a file **and** a folder named ""`gs://hellbender/test/resources/parallel_copy/`"". Observe the first line of output:. ```bash; $ gsutil ls gs://hellbender/test/resources/parallel_copy/; gs://hellbender/test/resources/parallel_copy/; gs://hellbender/test/resources/parallel_copy/bar.txt; gs://hellbender/test/resources/parallel_copy/foo.txt; ```. The file exists and is empty. For evidence, observe that I can cat the file (note how it behaves differently from normal folders):. ```bash; $ gsutil cat gs://hellbender/test/resources/; CommandException: No URLs matched: gs://hellbender/test/resources/; $ gsutil cat gs://hellbender/test/resources/parallel_copy/; $; ```. So NIO is technically correct, `gs://hellbender/test/resources/parallel_copy/` is a file. Did you do anything unusual with regards to this path?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5546#issuecomment-450400675
https://github.com/broadinstitute/gatk/pull/5546#issuecomment-450400675:267,Testability,test,test,267,"@lbergelson The situation is rather odd: you seem to have **both** a file **and** a folder named ""`gs://hellbender/test/resources/parallel_copy/`"". Observe the first line of output:. ```bash; $ gsutil ls gs://hellbender/test/resources/parallel_copy/; gs://hellbender/test/resources/parallel_copy/; gs://hellbender/test/resources/parallel_copy/bar.txt; gs://hellbender/test/resources/parallel_copy/foo.txt; ```. The file exists and is empty. For evidence, observe that I can cat the file (note how it behaves differently from normal folders):. ```bash; $ gsutil cat gs://hellbender/test/resources/; CommandException: No URLs matched: gs://hellbender/test/resources/; $ gsutil cat gs://hellbender/test/resources/parallel_copy/; $; ```. So NIO is technically correct, `gs://hellbender/test/resources/parallel_copy/` is a file. Did you do anything unusual with regards to this path?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5546#issuecomment-450400675
https://github.com/broadinstitute/gatk/pull/5546#issuecomment-450400675:314,Testability,test,test,314,"@lbergelson The situation is rather odd: you seem to have **both** a file **and** a folder named ""`gs://hellbender/test/resources/parallel_copy/`"". Observe the first line of output:. ```bash; $ gsutil ls gs://hellbender/test/resources/parallel_copy/; gs://hellbender/test/resources/parallel_copy/; gs://hellbender/test/resources/parallel_copy/bar.txt; gs://hellbender/test/resources/parallel_copy/foo.txt; ```. The file exists and is empty. For evidence, observe that I can cat the file (note how it behaves differently from normal folders):. ```bash; $ gsutil cat gs://hellbender/test/resources/; CommandException: No URLs matched: gs://hellbender/test/resources/; $ gsutil cat gs://hellbender/test/resources/parallel_copy/; $; ```. So NIO is technically correct, `gs://hellbender/test/resources/parallel_copy/` is a file. Did you do anything unusual with regards to this path?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5546#issuecomment-450400675
https://github.com/broadinstitute/gatk/pull/5546#issuecomment-450400675:368,Testability,test,test,368,"@lbergelson The situation is rather odd: you seem to have **both** a file **and** a folder named ""`gs://hellbender/test/resources/parallel_copy/`"". Observe the first line of output:. ```bash; $ gsutil ls gs://hellbender/test/resources/parallel_copy/; gs://hellbender/test/resources/parallel_copy/; gs://hellbender/test/resources/parallel_copy/bar.txt; gs://hellbender/test/resources/parallel_copy/foo.txt; ```. The file exists and is empty. For evidence, observe that I can cat the file (note how it behaves differently from normal folders):. ```bash; $ gsutil cat gs://hellbender/test/resources/; CommandException: No URLs matched: gs://hellbender/test/resources/; $ gsutil cat gs://hellbender/test/resources/parallel_copy/; $; ```. So NIO is technically correct, `gs://hellbender/test/resources/parallel_copy/` is a file. Did you do anything unusual with regards to this path?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5546#issuecomment-450400675
https://github.com/broadinstitute/gatk/pull/5546#issuecomment-450400675:581,Testability,test,test,581,"@lbergelson The situation is rather odd: you seem to have **both** a file **and** a folder named ""`gs://hellbender/test/resources/parallel_copy/`"". Observe the first line of output:. ```bash; $ gsutil ls gs://hellbender/test/resources/parallel_copy/; gs://hellbender/test/resources/parallel_copy/; gs://hellbender/test/resources/parallel_copy/bar.txt; gs://hellbender/test/resources/parallel_copy/foo.txt; ```. The file exists and is empty. For evidence, observe that I can cat the file (note how it behaves differently from normal folders):. ```bash; $ gsutil cat gs://hellbender/test/resources/; CommandException: No URLs matched: gs://hellbender/test/resources/; $ gsutil cat gs://hellbender/test/resources/parallel_copy/; $; ```. So NIO is technically correct, `gs://hellbender/test/resources/parallel_copy/` is a file. Did you do anything unusual with regards to this path?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5546#issuecomment-450400675
https://github.com/broadinstitute/gatk/pull/5546#issuecomment-450400675:649,Testability,test,test,649,"@lbergelson The situation is rather odd: you seem to have **both** a file **and** a folder named ""`gs://hellbender/test/resources/parallel_copy/`"". Observe the first line of output:. ```bash; $ gsutil ls gs://hellbender/test/resources/parallel_copy/; gs://hellbender/test/resources/parallel_copy/; gs://hellbender/test/resources/parallel_copy/bar.txt; gs://hellbender/test/resources/parallel_copy/foo.txt; ```. The file exists and is empty. For evidence, observe that I can cat the file (note how it behaves differently from normal folders):. ```bash; $ gsutil cat gs://hellbender/test/resources/; CommandException: No URLs matched: gs://hellbender/test/resources/; $ gsutil cat gs://hellbender/test/resources/parallel_copy/; $; ```. So NIO is technically correct, `gs://hellbender/test/resources/parallel_copy/` is a file. Did you do anything unusual with regards to this path?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5546#issuecomment-450400675
https://github.com/broadinstitute/gatk/pull/5546#issuecomment-450400675:695,Testability,test,test,695,"@lbergelson The situation is rather odd: you seem to have **both** a file **and** a folder named ""`gs://hellbender/test/resources/parallel_copy/`"". Observe the first line of output:. ```bash; $ gsutil ls gs://hellbender/test/resources/parallel_copy/; gs://hellbender/test/resources/parallel_copy/; gs://hellbender/test/resources/parallel_copy/bar.txt; gs://hellbender/test/resources/parallel_copy/foo.txt; ```. The file exists and is empty. For evidence, observe that I can cat the file (note how it behaves differently from normal folders):. ```bash; $ gsutil cat gs://hellbender/test/resources/; CommandException: No URLs matched: gs://hellbender/test/resources/; $ gsutil cat gs://hellbender/test/resources/parallel_copy/; $; ```. So NIO is technically correct, `gs://hellbender/test/resources/parallel_copy/` is a file. Did you do anything unusual with regards to this path?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5546#issuecomment-450400675
https://github.com/broadinstitute/gatk/pull/5546#issuecomment-450400675:782,Testability,test,test,782,"@lbergelson The situation is rather odd: you seem to have **both** a file **and** a folder named ""`gs://hellbender/test/resources/parallel_copy/`"". Observe the first line of output:. ```bash; $ gsutil ls gs://hellbender/test/resources/parallel_copy/; gs://hellbender/test/resources/parallel_copy/; gs://hellbender/test/resources/parallel_copy/bar.txt; gs://hellbender/test/resources/parallel_copy/foo.txt; ```. The file exists and is empty. For evidence, observe that I can cat the file (note how it behaves differently from normal folders):. ```bash; $ gsutil cat gs://hellbender/test/resources/; CommandException: No URLs matched: gs://hellbender/test/resources/; $ gsutil cat gs://hellbender/test/resources/parallel_copy/; $; ```. So NIO is technically correct, `gs://hellbender/test/resources/parallel_copy/` is a file. Did you do anything unusual with regards to this path?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5546#issuecomment-450400675
https://github.com/broadinstitute/gatk/pull/5546#issuecomment-454958697:101,Deployability,release,release,101,@lbergelson Should this PR be closed? It seems like we'll need a PR to bump us to a different gcloud release that fixes the issue you ran into here.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5546#issuecomment-454958697
https://github.com/broadinstitute/gatk/pull/5546#issuecomment-458257202:83,Deployability,release,released,83,"A fix for the shading issue has been merged into google-cloud-java, but is not yet released.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5546#issuecomment-458257202
https://github.com/broadinstitute/gatk/pull/5546#issuecomment-458264518:61,Deployability,release,release,61,"@ldgauthier No, we've been on the official google-cloud-java release for a long time now -- our fork is long dead. We're just trying to update to the latest version to fix some edge-case issues with empty files in GCS buckets, but it's not a blocker for the 4.1 release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5546#issuecomment-458264518
https://github.com/broadinstitute/gatk/pull/5546#issuecomment-458264518:136,Deployability,update,update,136,"@ldgauthier No, we've been on the official google-cloud-java release for a long time now -- our fork is long dead. We're just trying to update to the latest version to fix some edge-case issues with empty files in GCS buckets, but it's not a blocker for the 4.1 release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5546#issuecomment-458264518
https://github.com/broadinstitute/gatk/pull/5546#issuecomment-458264518:262,Deployability,release,release,262,"@ldgauthier No, we've been on the official google-cloud-java release for a long time now -- our fork is long dead. We're just trying to update to the latest version to fix some edge-case issues with empty files in GCS buckets, but it's not a blocker for the 4.1 release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5546#issuecomment-458264518
https://github.com/broadinstitute/gatk/pull/5546#issuecomment-458267899:18,Deployability,update,update,18,Excellent! I will update my GATK dockers soon and then _I_ won't have to look at that message any more either.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5546#issuecomment-458267899
https://github.com/broadinstitute/gatk/pull/5546#issuecomment-458267899:86,Integrability,message,message,86,Excellent! I will update my GATK dockers soon and then _I_ won't have to look at that message any more either.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5546#issuecomment-458267899
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449485244:16,Availability,error,error,16,"@jjfarrell That error message usually indicates that the reference supplied isn't the same (exact) same one that was used to create the cram. Can you try using `samtools view` on the same file/ref pair, and see if that works.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449485244
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449485244:22,Integrability,message,message,22,"@jjfarrell That error message usually indicates that the reference supplied isn't the same (exact) same one that was used to create the cram. Can you try using `samtools view` on the same file/ref pair, and see if that works.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449485244
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725:11505,Availability,down,down,11505,"bender.engine.spark.SparkContextFactory.getSparkContext(SparkContextFactory.java:110); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:28); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:134); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 18/12/21 13:48:33 WARN util.Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.; 18/12/21 13:48:33 WARN shortcircuit.DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.; 18/12/21 13:48:37 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.; 806177853; 14:54:41.938 INFO CountReadsSpark - Shutting down engine; [December 21, 2018 2:54:41 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 66.18 minutes. ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725:185,Deployability,upgrade,upgrade,185,@cmnbroad @tomwhite . Here it works fine with the earlier 4.0.3.0 with the Hadoop-Bam library (except it is very slow). It counted 806177853 reads. The issue is probably related to the upgrade from Hadoop-BAM library to the newly-developed Disq library. ```; gatk CountReadsSpark --input /project/casa/gcad/adsp.cc/cram/A-ADC-AD010072-BL-NCR-11AD44210.hg38.realign.bqsr.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -- --spark-runner SPARK --spark-master yarn; Using GATK jar /share/pkg/gatk/4.0.3.0/install/bin/gatk-package-4.0.3.0-spark.jar; Running:; /share/pkg/spark/2.1.0/install/bin/spark-submit --master yarn --conf spark.kryoserializer.buffer.max=512m --conf spark.driver.maxResultSize=0 --conf spark.driver.userClassPathFirst=false --conf spark.io.compression.codec=lzf --conf spark.yarn.executor.memoryOverhead=600 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 /share/pkg/gatk/4.0.3.0/install/bin/gatk-package-4.0.3.0-spark.jar CountReadsSpark --input /project/casa/gcad/adsp.cc/cram/A-ADC-AD010072-BL-NCR-11AD44210.hg38.realign.bqsr.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --spark-master yarn; 13:48:31.261 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 13:48:31.426 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg/gatk/4.0.3.0/install/bin/gatk-package-4.0.3.0-spark.jar!/com/intel/g,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725:552,Deployability,install,install,552,@cmnbroad @tomwhite . Here it works fine with the earlier 4.0.3.0 with the Hadoop-Bam library (except it is very slow). It counted 806177853 reads. The issue is probably related to the upgrade from Hadoop-BAM library to the newly-developed Disq library. ```; gatk CountReadsSpark --input /project/casa/gcad/adsp.cc/cram/A-ADC-AD010072-BL-NCR-11AD44210.hg38.realign.bqsr.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -- --spark-runner SPARK --spark-master yarn; Using GATK jar /share/pkg/gatk/4.0.3.0/install/bin/gatk-package-4.0.3.0-spark.jar; Running:; /share/pkg/spark/2.1.0/install/bin/spark-submit --master yarn --conf spark.kryoserializer.buffer.max=512m --conf spark.driver.maxResultSize=0 --conf spark.driver.userClassPathFirst=false --conf spark.io.compression.codec=lzf --conf spark.yarn.executor.memoryOverhead=600 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 /share/pkg/gatk/4.0.3.0/install/bin/gatk-package-4.0.3.0-spark.jar CountReadsSpark --input /project/casa/gcad/adsp.cc/cram/A-ADC-AD010072-BL-NCR-11AD44210.hg38.realign.bqsr.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --spark-master yarn; 13:48:31.261 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 13:48:31.426 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg/gatk/4.0.3.0/install/bin/gatk-package-4.0.3.0-spark.jar!/com/intel/g,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725:629,Deployability,install,install,629,@cmnbroad @tomwhite . Here it works fine with the earlier 4.0.3.0 with the Hadoop-Bam library (except it is very slow). It counted 806177853 reads. The issue is probably related to the upgrade from Hadoop-BAM library to the newly-developed Disq library. ```; gatk CountReadsSpark --input /project/casa/gcad/adsp.cc/cram/A-ADC-AD010072-BL-NCR-11AD44210.hg38.realign.bqsr.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -- --spark-runner SPARK --spark-master yarn; Using GATK jar /share/pkg/gatk/4.0.3.0/install/bin/gatk-package-4.0.3.0-spark.jar; Running:; /share/pkg/spark/2.1.0/install/bin/spark-submit --master yarn --conf spark.kryoserializer.buffer.max=512m --conf spark.driver.maxResultSize=0 --conf spark.driver.userClassPathFirst=false --conf spark.io.compression.codec=lzf --conf spark.yarn.executor.memoryOverhead=600 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 /share/pkg/gatk/4.0.3.0/install/bin/gatk-package-4.0.3.0-spark.jar CountReadsSpark --input /project/casa/gcad/adsp.cc/cram/A-ADC-AD010072-BL-NCR-11AD44210.hg38.realign.bqsr.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --spark-master yarn; 13:48:31.261 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 13:48:31.426 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg/gatk/4.0.3.0/install/bin/gatk-package-4.0.3.0-spark.jar!/com/intel/g,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725:1371,Deployability,install,install,1371,nce file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -- --spark-runner SPARK --spark-master yarn; Using GATK jar /share/pkg/gatk/4.0.3.0/install/bin/gatk-package-4.0.3.0-spark.jar; Running:; /share/pkg/spark/2.1.0/install/bin/spark-submit --master yarn --conf spark.kryoserializer.buffer.max=512m --conf spark.driver.maxResultSize=0 --conf spark.driver.userClassPathFirst=false --conf spark.io.compression.codec=lzf --conf spark.yarn.executor.memoryOverhead=600 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 /share/pkg/gatk/4.0.3.0/install/bin/gatk-package-4.0.3.0-spark.jar CountReadsSpark --input /project/casa/gcad/adsp.cc/cram/A-ADC-AD010072-BL-NCR-11AD44210.hg38.realign.bqsr.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --spark-master yarn; 13:48:31.261 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 13:48:31.426 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg/gatk/4.0.3.0/install/bin/gatk-package-4.0.3.0-spark.jar!/com/intel/gkl/native/libgkl_compression.so; 13:48:31.693 INFO CountReadsSpark - ------------------------------------------------------------; 13:48:31.693 INFO CountReadsSpark - The Genome Analysis Toolkit (GATK) v4.0.3.0; 13:48:31.693 INFO CountReadsSpark - For support and documentation go to https://software.broadinstitute.org/gatk/; 13:48:31.694 INFO CountReadsSpark - Executing as farrell,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725:1946,Deployability,install,install,1946,"amjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 /share/pkg/gatk/4.0.3.0/install/bin/gatk-package-4.0.3.0-spark.jar CountReadsSpark --input /project/casa/gcad/adsp.cc/cram/A-ADC-AD010072-BL-NCR-11AD44210.hg38.realign.bqsr.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --spark-master yarn; 13:48:31.261 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 13:48:31.426 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg/gatk/4.0.3.0/install/bin/gatk-package-4.0.3.0-spark.jar!/com/intel/gkl/native/libgkl_compression.so; 13:48:31.693 INFO CountReadsSpark - ------------------------------------------------------------; 13:48:31.693 INFO CountReadsSpark - The Genome Analysis Toolkit (GATK) v4.0.3.0; 13:48:31.693 INFO CountReadsSpark - For support and documentation go to https://software.broadinstitute.org/gatk/; 13:48:31.694 INFO CountReadsSpark - Executing as farrell@scc-hadoop.bu.edu on Linux v2.6.32-754.6.3.el6.x86_64 amd64; 13:48:31.694 INFO CountReadsSpark - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_121-b13; 13:48:31.694 INFO CountReadsSpark - Start Date/Time: December 21, 2018 1:48:31 PM EST; 13:48:31.694 INFO CountReadsSpark - ------------------------------------------------------------; 13:48:31.694 INFO CountReadsSpark - ------------------------------------------------------------; 13:48:31.695 INFO CountReadsSpark - HTSJDK Version: 2.14.3; 13:48:31.695 INFO CountReadsSpark - Picard Version: 2.17.2; 13:48:31.6",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725:3548,Deployability,patch,patch,3548,"94 INFO CountReadsSpark - Start Date/Time: December 21, 2018 1:48:31 PM EST; 13:48:31.694 INFO CountReadsSpark - ------------------------------------------------------------; 13:48:31.694 INFO CountReadsSpark - ------------------------------------------------------------; 13:48:31.695 INFO CountReadsSpark - HTSJDK Version: 2.14.3; 13:48:31.695 INFO CountReadsSpark - Picard Version: 2.17.2; 13:48:31.695 INFO CountReadsSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 13:48:31.695 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 13:48:31.695 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 13:48:31.695 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 13:48:31.695 INFO CountReadsSpark - Deflater: IntelDeflater; 13:48:31.695 INFO CountReadsSpark - Inflater: IntelInflater; 13:48:31.696 INFO CountReadsSpark - GCS max retries/reopens: 20; 13:48:31.696 INFO CountReadsSpark - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 13:48:31.696 WARN CountReadsSpark -. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: CountReadsSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 13:48:31.696 INFO CountReadsSpark - Initializing engine; 13:48:31.696 INFO CountReadsSpark - Done initializing engine; 18/12/21 13:48:32 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 18/12/21 13:48:33 WARN component.AbstractLifeCycle: FAILED ServerConnector@1cba0321{HTTP/1.1}{0.0.0.0:4040}: java.net.BindException: Address already in use; java.net.BindException: Address already in use; at sun.nio.ch.Net.bind0(Native Method); at sun.nio.ch.Net.bind(Net.java:433); at sun.nio.ch.Net.bind(Net.java:425); at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocke",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725:7251,Deployability,deploy,deploy,7251,ontextFactory.getSparkContext(SparkContextFactory.java:110); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:28); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:134); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 18/12/21 13:48:33 WARN component.AbstractLifeCycle: FAILED org.eclipse.jetty.server.Server@3e0a9b1d: java.net.BindException: Address already in use; java.net.BindException: Address already in use; at sun.nio.ch.Net.bind0(Native Method); at sun.nio.ch.Net.bind(Net.java:433); at sun.nio.ch.Net.bind(Net.java:425); at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223); at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74); at org.eclipse.jetty.server.ServerConnector.open(ServerConnector.java:321); at org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80); at ,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725:7288,Deployability,deploy,deploy,7288,tory.java:110); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:28); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:134); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 18/12/21 13:48:33 WARN component.AbstractLifeCycle: FAILED org.eclipse.jetty.server.Server@3e0a9b1d: java.net.BindException: Address already in use; java.net.BindException: Address already in use; at sun.nio.ch.Net.bind0(Native Method); at sun.nio.ch.Net.bind(Net.java:433); at sun.nio.ch.Net.bind(Net.java:425); at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223); at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74); at org.eclipse.jetty.server.ServerConnector.open(ServerConnector.java:321); at org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80); at org.eclipse.jetty.server.ServerConnector.doSt,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725:7360,Deployability,deploy,deploy,7360,arkCommandLineProgram.doWork(SparkCommandLineProgram.java:28); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:134); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 18/12/21 13:48:33 WARN component.AbstractLifeCycle: FAILED org.eclipse.jetty.server.Server@3e0a9b1d: java.net.BindException: Address already in use; java.net.BindException: Address already in use; at sun.nio.ch.Net.bind0(Native Method); at sun.nio.ch.Net.bind(Net.java:433); at sun.nio.ch.Net.bind(Net.java:425); at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223); at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74); at org.eclipse.jetty.server.ServerConnector.open(ServerConnector.java:321); at org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80); at org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:236); at org.eclipse.jetty.util.compone,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725:7436,Deployability,deploy,deploy,7436,nstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:134); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 18/12/21 13:48:33 WARN component.AbstractLifeCycle: FAILED org.eclipse.jetty.server.Server@3e0a9b1d: java.net.BindException: Address already in use; java.net.BindException: Address already in use; at sun.nio.ch.Net.bind0(Native Method); at sun.nio.ch.Net.bind(Net.java:433); at sun.nio.ch.Net.bind(Net.java:425); at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223); at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74); at org.eclipse.jetty.server.ServerConnector.open(ServerConnector.java:321); at org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80); at org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:236); at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68); at org.eclipse.jetty.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725:7507,Deployability,deploy,deploy,7507,am.java:134); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 18/12/21 13:48:33 WARN component.AbstractLifeCycle: FAILED org.eclipse.jetty.server.Server@3e0a9b1d: java.net.BindException: Address already in use; java.net.BindException: Address already in use; at sun.nio.ch.Net.bind0(Native Method); at sun.nio.ch.Net.bind(Net.java:433); at sun.nio.ch.Net.bind(Net.java:425); at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223); at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74); at org.eclipse.jetty.server.ServerConnector.open(ServerConnector.java:321); at org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80); at org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:236); at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68); at org.eclipse.jetty.server.Server.doStart(Server.java:366); at org.eclipse.jetty.util.compo,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725:7576,Deployability,deploy,deploy,7576,gram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 18/12/21 13:48:33 WARN component.AbstractLifeCycle: FAILED org.eclipse.jetty.server.Server@3e0a9b1d: java.net.BindException: Address already in use; java.net.BindException: Address already in use; at sun.nio.ch.Net.bind0(Native Method); at sun.nio.ch.Net.bind(Net.java:433); at sun.nio.ch.Net.bind(Net.java:425); at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223); at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74); at org.eclipse.jetty.server.ServerConnector.open(ServerConnector.java:321); at org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80); at org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:236); at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68); at org.eclipse.jetty.server.Server.doStart(Server.java:366); at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68); at org.apach,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725:10682,Deployability,deploy,deploy,10682,"bender.engine.spark.SparkContextFactory.getSparkContext(SparkContextFactory.java:110); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:28); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:134); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 18/12/21 13:48:33 WARN util.Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.; 18/12/21 13:48:33 WARN shortcircuit.DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.; 18/12/21 13:48:37 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.; 806177853; 14:54:41.938 INFO CountReadsSpark - Shutting down engine; [December 21, 2018 2:54:41 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 66.18 minutes. ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725:10719,Deployability,deploy,deploy,10719,"bender.engine.spark.SparkContextFactory.getSparkContext(SparkContextFactory.java:110); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:28); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:134); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 18/12/21 13:48:33 WARN util.Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.; 18/12/21 13:48:33 WARN shortcircuit.DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.; 18/12/21 13:48:37 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.; 806177853; 14:54:41.938 INFO CountReadsSpark - Shutting down engine; [December 21, 2018 2:54:41 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 66.18 minutes. ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725:10791,Deployability,deploy,deploy,10791,"bender.engine.spark.SparkContextFactory.getSparkContext(SparkContextFactory.java:110); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:28); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:134); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 18/12/21 13:48:33 WARN util.Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.; 18/12/21 13:48:33 WARN shortcircuit.DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.; 18/12/21 13:48:37 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.; 806177853; 14:54:41.938 INFO CountReadsSpark - Shutting down engine; [December 21, 2018 2:54:41 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 66.18 minutes. ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725:10867,Deployability,deploy,deploy,10867,"bender.engine.spark.SparkContextFactory.getSparkContext(SparkContextFactory.java:110); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:28); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:134); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 18/12/21 13:48:33 WARN util.Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.; 18/12/21 13:48:33 WARN shortcircuit.DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.; 18/12/21 13:48:37 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.; 806177853; 14:54:41.938 INFO CountReadsSpark - Shutting down engine; [December 21, 2018 2:54:41 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 66.18 minutes. ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725:10938,Deployability,deploy,deploy,10938,"bender.engine.spark.SparkContextFactory.getSparkContext(SparkContextFactory.java:110); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:28); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:134); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 18/12/21 13:48:33 WARN util.Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.; 18/12/21 13:48:33 WARN shortcircuit.DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.; 18/12/21 13:48:37 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.; 806177853; 14:54:41.938 INFO CountReadsSpark - Shutting down engine; [December 21, 2018 2:54:41 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 66.18 minutes. ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725:11007,Deployability,deploy,deploy,11007,"bender.engine.spark.SparkContextFactory.getSparkContext(SparkContextFactory.java:110); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:28); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:134); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 18/12/21 13:48:33 WARN util.Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.; 18/12/21 13:48:33 WARN shortcircuit.DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.; 18/12/21 13:48:37 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.; 806177853; 14:54:41.938 INFO CountReadsSpark - Shutting down engine; [December 21, 2018 2:54:41 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 66.18 minutes. ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725:11595,Deployability,pipeline,pipelines,11595,"bender.engine.spark.SparkContextFactory.getSparkContext(SparkContextFactory.java:110); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:28); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:134); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 18/12/21 13:48:33 WARN util.Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.; 18/12/21 13:48:33 WARN shortcircuit.DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.; 18/12/21 13:48:37 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.; 806177853; 14:54:41.938 INFO CountReadsSpark - Shutting down engine; [December 21, 2018 2:54:41 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 66.18 minutes. ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725:1691,Modifiability,variab,variables,1691," --conf spark.driver.userClassPathFirst=false --conf spark.io.compression.codec=lzf --conf spark.yarn.executor.memoryOverhead=600 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 /share/pkg/gatk/4.0.3.0/install/bin/gatk-package-4.0.3.0-spark.jar CountReadsSpark --input /project/casa/gcad/adsp.cc/cram/A-ADC-AD010072-BL-NCR-11AD44210.hg38.realign.bqsr.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --spark-master yarn; 13:48:31.261 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 13:48:31.426 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg/gatk/4.0.3.0/install/bin/gatk-package-4.0.3.0-spark.jar!/com/intel/gkl/native/libgkl_compression.so; 13:48:31.693 INFO CountReadsSpark - ------------------------------------------------------------; 13:48:31.693 INFO CountReadsSpark - The Genome Analysis Toolkit (GATK) v4.0.3.0; 13:48:31.693 INFO CountReadsSpark - For support and documentation go to https://software.broadinstitute.org/gatk/; 13:48:31.694 INFO CountReadsSpark - Executing as farrell@scc-hadoop.bu.edu on Linux v2.6.32-754.6.3.el6.x86_64 amd64; 13:48:31.694 INFO CountReadsSpark - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_121-b13; 13:48:31.694 INFO CountReadsSpark - Start Date/Time: December 21, 2018 1:48:31 PM EST; 13:48:31.694 INFO CountReadsSpark - ------------------------------------------------------------; 13:48:31.694 INFO",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725:1817,Modifiability,config,configured,1817," --conf spark.driver.userClassPathFirst=false --conf spark.io.compression.codec=lzf --conf spark.yarn.executor.memoryOverhead=600 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 /share/pkg/gatk/4.0.3.0/install/bin/gatk-package-4.0.3.0-spark.jar CountReadsSpark --input /project/casa/gcad/adsp.cc/cram/A-ADC-AD010072-BL-NCR-11AD44210.hg38.realign.bqsr.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --spark-master yarn; 13:48:31.261 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 13:48:31.426 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg/gatk/4.0.3.0/install/bin/gatk-package-4.0.3.0-spark.jar!/com/intel/gkl/native/libgkl_compression.so; 13:48:31.693 INFO CountReadsSpark - ------------------------------------------------------------; 13:48:31.693 INFO CountReadsSpark - The Genome Analysis Toolkit (GATK) v4.0.3.0; 13:48:31.693 INFO CountReadsSpark - For support and documentation go to https://software.broadinstitute.org/gatk/; 13:48:31.694 INFO CountReadsSpark - Executing as farrell@scc-hadoop.bu.edu on Linux v2.6.32-754.6.3.el6.x86_64 amd64; 13:48:31.694 INFO CountReadsSpark - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_121-b13; 13:48:31.694 INFO CountReadsSpark - Start Date/Time: December 21, 2018 1:48:31 PM EST; 13:48:31.694 INFO CountReadsSpark - ------------------------------------------------------------; 13:48:31.694 INFO",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725:1878,Performance,Load,Loading,1878," --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 /share/pkg/gatk/4.0.3.0/install/bin/gatk-package-4.0.3.0-spark.jar CountReadsSpark --input /project/casa/gcad/adsp.cc/cram/A-ADC-AD010072-BL-NCR-11AD44210.hg38.realign.bqsr.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --spark-master yarn; 13:48:31.261 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 13:48:31.426 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg/gatk/4.0.3.0/install/bin/gatk-package-4.0.3.0-spark.jar!/com/intel/gkl/native/libgkl_compression.so; 13:48:31.693 INFO CountReadsSpark - ------------------------------------------------------------; 13:48:31.693 INFO CountReadsSpark - The Genome Analysis Toolkit (GATK) v4.0.3.0; 13:48:31.693 INFO CountReadsSpark - For support and documentation go to https://software.broadinstitute.org/gatk/; 13:48:31.694 INFO CountReadsSpark - Executing as farrell@scc-hadoop.bu.edu on Linux v2.6.32-754.6.3.el6.x86_64 amd64; 13:48:31.694 INFO CountReadsSpark - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_121-b13; 13:48:31.694 INFO CountReadsSpark - Start Date/Time: December 21, 2018 1:48:31 PM EST; 13:48:31.694 INFO CountReadsSpark - ------------------------------------------------------------; 13:48:31.694 INFO CountReadsSpark - ------------------------------------------------------------; 13:48:31.695 INFO CountReadsSpark - HTSJDK Vers",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725:4088,Performance,load,load,4088,R_SAMTOOLS : false; 13:48:31.695 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 13:48:31.695 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 13:48:31.695 INFO CountReadsSpark - Deflater: IntelDeflater; 13:48:31.695 INFO CountReadsSpark - Inflater: IntelInflater; 13:48:31.696 INFO CountReadsSpark - GCS max retries/reopens: 20; 13:48:31.696 INFO CountReadsSpark - Using google-cloud-java patch 6d11bef1c81f885c26b2b56c8616b7a705171e4f from https://github.com/droazen/google-cloud-java/tree/dr_all_nio_fixes; 13:48:31.696 WARN CountReadsSpark -. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: CountReadsSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 13:48:31.696 INFO CountReadsSpark - Initializing engine; 13:48:31.696 INFO CountReadsSpark - Done initializing engine; 18/12/21 13:48:32 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 18/12/21 13:48:33 WARN component.AbstractLifeCycle: FAILED ServerConnector@1cba0321{HTTP/1.1}{0.0.0.0:4040}: java.net.BindException: Address already in use; java.net.BindException: Address already in use; at sun.nio.ch.Net.bind0(Native Method); at sun.nio.ch.Net.bind(Net.java:433); at sun.nio.ch.Net.bind(Net.java:425); at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:223); at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74); at org.eclipse.jetty.server.ServerConnector.open(ServerConnector.java:321); at org.eclipse.jetty.server.AbstractNetworkConnector.doStart(AbstractNetworkConnector.java:80); at org.eclipse.jetty.server.ServerConnector.doStart(ServerConnector.java:236); at org.eclipse.jetty.util.component.AbstractLifeCycle.start(AbstractLifeCycle.java:68); at org.eclipse.jetty.server.Server.doStart(Server.java:366); at org.eclipse.jetty.util.component.AbstractLife,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725:11294,Performance,load,loaded,11294,"bender.engine.spark.SparkContextFactory.getSparkContext(SparkContextFactory.java:110); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:28); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:134); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:179); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:738); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:187); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:212); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:126); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); 18/12/21 13:48:33 WARN util.Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.; 18/12/21 13:48:33 WARN shortcircuit.DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.; 18/12/21 13:48:37 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.; 806177853; 14:54:41.938 INFO CountReadsSpark - Shutting down engine; [December 21, 2018 2:54:41 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 66.18 minutes. ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-449510725
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-450884370:246,Availability,down,down,246,"@jjfarrell In addition to the switch to disq, GATK 4.0.12.0 also included an updated htsjdk that had CRAM changes. It would be helpful to know if CountReads (non-spark) from that same GATK version works on this file, since that would help narrow down whether its disq-related. Is it possible to run that and let us know the results ? Thx.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-450884370
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-450884370:77,Deployability,update,updated,77,"@jjfarrell In addition to the switch to disq, GATK 4.0.12.0 also included an updated htsjdk that had CRAM changes. It would be helpful to know if CountReads (non-spark) from that same GATK version works on this file, since that would help narrow down whether its disq-related. Is it possible to run that and let us know the results ? Thx.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-450884370
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-450983210:6306,Availability,down,down,6306,"1000 8953837.7; 15:22:58.267 INFO ProgressMeter - chr1:155131495 4.2 37471000 8957853.6; 15:23:08.313 INFO ProgressMeter - chr1:161688288 4.4 39051000 8976244.0; 15:23:18.314 INFO ProgressMeter - chr1:168387593 4.5 40651000 8999225.2; 15:23:28.331 INFO ProgressMeter - chr1:174890255 4.7 42191000 9007247.9; 15:23:38.353 INFO ProgressMeter - chr1:181322766 4.9 43731000 9014563.6; 15:23:48.390 INFO ProgressMeter - chr1:187703141 5.0 45241000 9014994.8; 15:23:58.429 INFO ProgressMeter - chr1:194472259 5.2 46831000 9030709.2; 15:24:08.429 INFO ProgressMeter - chr1:201344987 5.4 48445000 9051051.7; 15:24:18.433 INFO ProgressMeter - chr1:207948168 5.5 50041000 9066794.7; 15:24:28.449 INFO ProgressMeter - chr1:214803619 5.7 51681000 9089033.2; 15:24:38.487 INFO ProgressMeter - chr1:221753713 5.9 53331000 9111140.9; ///////; 16:47:24.218 INFO ProgressMeter - unmapped 88.6 792343000 8941352.3; 16:47:34.221 INFO ProgressMeter - unmapped 88.8 793813000 8941119.4; 16:47:44.239 INFO ProgressMeter - unmapped 88.9 795293000 8940974.8; 16:47:54.256 INFO ProgressMeter - unmapped 89.1 796783000 8940944.5; 16:48:04.283 INFO ProgressMeter - unmapped 89.3 798253000 8940673.7; 16:48:14.335 INFO ProgressMeter - unmapped 89.5 799653000 8939579.7; 16:48:24.361 INFO ProgressMeter - unmapped 89.6 801133000 8939425.6; 16:48:34.392 INFO ProgressMeter - unmapped 89.8 802633000 8939486.6; 16:48:44.420 INFO ProgressMeter - unmapped 90.0 804113000 8939330.0; 16:48:54.443 INFO ProgressMeter - unmapped 90.1 805593000 8939182.3; 16:48:58.375 INFO CountReads - No reads filtered by: WellformedReadFilter; 16:48:58.376 INFO ProgressMeter - unmapped 90.2 806177853 8939171.6; 16:48:58.376 INFO ProgressMeter - Traversal complete. Processed 806177853 total reads in 90.2 minutes.; 16:48:58.376 INFO CountReads - Shutting down engine; [January 2, 2019 4:48:58 PM EST] org.broadinstitute.hellbender.tools.CountReads done. Elapsed time: 90.25 minutes.; Runtime.totalMemory()=10568073216; Tool returned:; 806177853. ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-450983210
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-450983210:925,Performance,Load,Loading,925,"@cmnbroad . The non-spark version of CountReads runs fine...... ```; gatk-4.0.12.0/gatk CountReads --input /restricted/projectnb/adsp/wgs.hg38/adsp.cc/cram/A-ADC-AD010072-BL-NCR-11AD44210.hg38.realign.bqsr.cram --reference /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa; Using GATK jar /restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/gatk-4.0.12.0/gatk-package-4.0.12.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/gatk-4.0.12.0/gatk-package-4.0.12.0-local.jar CountReads --input /restricted/projectnb/adsp/wgs.hg38/adsp.cc/cram/A-ADC-AD010072-BL-NCR-11AD44210.hg38.realign.bqsr.cram --reference /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa; 15:18:43.541 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/gatk-4.0.12.0/gatk-package-4.0.12.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 15:18:45.267 INFO CountReads - ------------------------------------------------------------; 15:18:45.267 INFO CountReads - The Genome Analysis Toolkit (GATK) v4.0.12.0; 15:18:45.268 INFO CountReads - For support and documentation go to https://software.broadinstitute.org/gatk/; 15:18:45.268 INFO CountReads - Executing as farrell@scc-hadoop.bu.edu on Linux v2.6.32-754.6.3.el6.x86_64 amd64; 15:18:45.268 INFO CountReads - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_121-b13; 15:18:45.269 INFO CountReads - Start Date/Time: January 2, 2019 3:18:43 PM EST; 15:18:45.269 INFO CountReads - ------------------------------------------------------------; 15:18:45.269 INFO CountReads - ------------------------------------------------------------; 15:18:45.270 INFO CountReads - HTSJDK Version: 2.18.1; 15:18:45.270 INFO CountReads - Picard Version: 2.18.16; 15:18:45.270 INFO CountReads ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-450983210
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451880631:146,Security,access,access,146,"Disq uses different code for finding container offsets compared to Hadoop-BAM, so that might be where the problem is coming from. However, I need access to the file that it's failing with to diagnose the issue. @jjfarrell how can I get a copy?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451880631
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:67,Availability,error,error,67,@tomwhite . I found this 1000 genomes cram that also generates the error. The test cram above would take a lot of paper work to make available. ```; wget ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/1000_genomes_project/data/GBR/HG04302/alignment/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram; wget ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/1000_genomes_project/data/GBR/HG04302/alignment/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram.crai. ```. Here is the error with this cram.... ```; gatk CountReadsSpark --input /project/casa/gcad/test/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -- --spark-runner SPARK --spark-master yarn; Using GATK jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar; Running:; /share/pkg/spark/2.3.0/install/bin/spark-submit --master yarn --conf spark.kryoserializer.buffer.max=512m --conf spark.driver.maxResultSize=0 --conf spark.driver.userClassPathFirst=false --conf spark.io.compression.codec=lzf --conf spark.yarn.executor.memoryOverhead=600 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar CountReadsSpark --input /project/casa/gcad/test/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --spark-master yarn; 2019-01-07 11:33:18 WARN SparkConf:66 - The configuration key 'spark.yarn.executor,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:133,Availability,avail,available,133,@tomwhite . I found this 1000 genomes cram that also generates the error. The test cram above would take a lot of paper work to make available. ```; wget ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/1000_genomes_project/data/GBR/HG04302/alignment/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram; wget ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/1000_genomes_project/data/GBR/HG04302/alignment/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram.crai. ```. Here is the error with this cram.... ```; gatk CountReadsSpark --input /project/casa/gcad/test/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -- --spark-runner SPARK --spark-master yarn; Using GATK jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar; Running:; /share/pkg/spark/2.3.0/install/bin/spark-submit --master yarn --conf spark.kryoserializer.buffer.max=512m --conf spark.driver.maxResultSize=0 --conf spark.driver.userClassPathFirst=false --conf spark.io.compression.codec=lzf --conf spark.yarn.executor.memoryOverhead=600 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar CountReadsSpark --input /project/casa/gcad/test/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --spark-master yarn; 2019-01-07 11:33:18 WARN SparkConf:66 - The configuration key 'spark.yarn.executor,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:513,Availability,error,error,513,@tomwhite . I found this 1000 genomes cram that also generates the error. The test cram above would take a lot of paper work to make available. ```; wget ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/1000_genomes_project/data/GBR/HG04302/alignment/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram; wget ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/1000_genomes_project/data/GBR/HG04302/alignment/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram.crai. ```. Here is the error with this cram.... ```; gatk CountReadsSpark --input /project/casa/gcad/test/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -- --spark-runner SPARK --spark-master yarn; Using GATK jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar; Running:; /share/pkg/spark/2.3.0/install/bin/spark-submit --master yarn --conf spark.kryoserializer.buffer.max=512m --conf spark.driver.maxResultSize=0 --conf spark.driver.userClassPathFirst=false --conf spark.io.compression.codec=lzf --conf spark.yarn.executor.memoryOverhead=600 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar CountReadsSpark --input /project/casa/gcad/test/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --spark-master yarn; 2019-01-07 11:33:18 WARN SparkConf:66 - The configuration key 'spark.yarn.executor,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:6907,Availability,AVAIL,AVAILABLE,6907,"ormation; 2019-01-07 11:33:27 INFO BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up; 2019-01-07 11:33:27 INFO DiskBlockManager:54 - Created local directory at /tmp/blockmgr-08460386-3abb-4431-ba8d-5b7d41a2a05c; 2019-01-07 11:33:27 INFO MemoryStore:54 - MemoryStore started with capacity 408.6 MB; 2019-01-07 11:33:27 INFO SparkEnv:54 - Registering OutputCommitCoordinator; 2019-01-07 11:33:27 INFO log:192 - Logging initialized @10679ms; 2019-01-07 11:33:27 INFO Server:346 - jetty-9.3.z-SNAPSHOT; 2019-01-07 11:33:27 INFO Server:414 - Started @10862ms; 2019-01-07 11:33:27 WARN Utils:66 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.; 2019-01-07 11:33:27 INFO AbstractConnector:278 - Started ServerConnector@f1d88ea{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-07 11:33:27 INFO Utils:54 - Successfully started service 'SparkUI' on port 4041.; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5a39e554{/jobs,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@67941d{/jobs/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2ad2b274{/jobs/job,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7114e780{/jobs/job/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4def42c3{/stages,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@72110818{/stages/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6eabe718{/stages/stage,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7530090a{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4492b39",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:7033,Availability,AVAIL,AVAILABLE,7033,"skBlockManager:54 - Created local directory at /tmp/blockmgr-08460386-3abb-4431-ba8d-5b7d41a2a05c; 2019-01-07 11:33:27 INFO MemoryStore:54 - MemoryStore started with capacity 408.6 MB; 2019-01-07 11:33:27 INFO SparkEnv:54 - Registering OutputCommitCoordinator; 2019-01-07 11:33:27 INFO log:192 - Logging initialized @10679ms; 2019-01-07 11:33:27 INFO Server:346 - jetty-9.3.z-SNAPSHOT; 2019-01-07 11:33:27 INFO Server:414 - Started @10862ms; 2019-01-07 11:33:27 WARN Utils:66 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.; 2019-01-07 11:33:27 INFO AbstractConnector:278 - Started ServerConnector@f1d88ea{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-07 11:33:27 INFO Utils:54 - Successfully started service 'SparkUI' on port 4041.; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5a39e554{/jobs,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@67941d{/jobs/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2ad2b274{/jobs/job,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7114e780{/jobs/job/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4def42c3{/stages,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@72110818{/stages/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6eabe718{/stages/stage,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7530090a{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4492b393{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:7160,Availability,AVAIL,AVAILABLE,7160,"moryStore:54 - MemoryStore started with capacity 408.6 MB; 2019-01-07 11:33:27 INFO SparkEnv:54 - Registering OutputCommitCoordinator; 2019-01-07 11:33:27 INFO log:192 - Logging initialized @10679ms; 2019-01-07 11:33:27 INFO Server:346 - jetty-9.3.z-SNAPSHOT; 2019-01-07 11:33:27 INFO Server:414 - Started @10862ms; 2019-01-07 11:33:27 WARN Utils:66 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.; 2019-01-07 11:33:27 INFO AbstractConnector:278 - Started ServerConnector@f1d88ea{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-07 11:33:27 INFO Utils:54 - Successfully started service 'SparkUI' on port 4041.; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5a39e554{/jobs,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@67941d{/jobs/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2ad2b274{/jobs/job,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7114e780{/jobs/job/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4def42c3{/stages,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@72110818{/stages/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6eabe718{/stages/stage,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7530090a{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4492b393{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@55fb36de{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextH",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:7292,Availability,AVAIL,AVAILABLE,7292,"tor; 2019-01-07 11:33:27 INFO log:192 - Logging initialized @10679ms; 2019-01-07 11:33:27 INFO Server:346 - jetty-9.3.z-SNAPSHOT; 2019-01-07 11:33:27 INFO Server:414 - Started @10862ms; 2019-01-07 11:33:27 WARN Utils:66 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.; 2019-01-07 11:33:27 INFO AbstractConnector:278 - Started ServerConnector@f1d88ea{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-07 11:33:27 INFO Utils:54 - Successfully started service 'SparkUI' on port 4041.; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5a39e554{/jobs,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@67941d{/jobs/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2ad2b274{/jobs/job,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7114e780{/jobs/job/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4def42c3{/stages,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@72110818{/stages/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6eabe718{/stages/stage,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7530090a{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4492b393{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@55fb36de{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@63a7781{/storage,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandl",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:7417,Availability,AVAIL,AVAILABLE,7417,"; 2019-01-07 11:33:27 INFO Server:414 - Started @10862ms; 2019-01-07 11:33:27 WARN Utils:66 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.; 2019-01-07 11:33:27 INFO AbstractConnector:278 - Started ServerConnector@f1d88ea{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-07 11:33:27 INFO Utils:54 - Successfully started service 'SparkUI' on port 4041.; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5a39e554{/jobs,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@67941d{/jobs/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2ad2b274{/jobs/job,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7114e780{/jobs/job/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4def42c3{/stages,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@72110818{/stages/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6eabe718{/stages/stage,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7530090a{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4492b393{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@55fb36de{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@63a7781{/storage,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@73b74615{/storage/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHan",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:7547,Availability,AVAIL,AVAILABLE,7547,"n port 4040. Attempting port 4041.; 2019-01-07 11:33:27 INFO AbstractConnector:278 - Started ServerConnector@f1d88ea{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-07 11:33:27 INFO Utils:54 - Successfully started service 'SparkUI' on port 4041.; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5a39e554{/jobs,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@67941d{/jobs/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2ad2b274{/jobs/job,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7114e780{/jobs/job/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4def42c3{/stages,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@72110818{/stages/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6eabe718{/stages/stage,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7530090a{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4492b393{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@55fb36de{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@63a7781{/storage,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@73b74615{/storage/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@22686ddb{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContext",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:7678,Availability,AVAIL,AVAILABLE,7678,"p/1.1]}{0.0.0.0:4041}; 2019-01-07 11:33:27 INFO Utils:54 - Successfully started service 'SparkUI' on port 4041.; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5a39e554{/jobs,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@67941d{/jobs/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2ad2b274{/jobs/job,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7114e780{/jobs/job/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4def42c3{/stages,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@72110818{/stages/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6eabe718{/stages/stage,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7530090a{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4492b393{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@55fb36de{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@63a7781{/storage,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@73b74615{/storage/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@22686ddb{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2e29f28e{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletCon",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:7814,Availability,AVAIL,AVAILABLE,7814,"NFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5a39e554{/jobs,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@67941d{/jobs/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2ad2b274{/jobs/job,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7114e780{/jobs/job/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4def42c3{/stages,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@72110818{/stages/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6eabe718{/stages/stage,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7530090a{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4492b393{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@55fb36de{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@63a7781{/storage,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@73b74615{/storage/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@22686ddb{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2e29f28e{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bfa1eb5{/environment,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContex",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:7944,Availability,AVAIL,AVAILABLE,7944,"tHandler:781 - Started o.s.j.s.ServletContextHandler@67941d{/jobs/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2ad2b274{/jobs/job,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7114e780{/jobs/job/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4def42c3{/stages,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@72110818{/stages/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6eabe718{/stages/stage,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7530090a{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4492b393{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@55fb36de{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@63a7781{/storage,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@73b74615{/storage/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@22686ddb{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2e29f28e{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bfa1eb5{/environment,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32b46831{/environment/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletCont",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:8079,Availability,AVAIL,AVAILABLE,8079,"er:781 - Started o.s.j.s.ServletContextHandler@2ad2b274{/jobs/job,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7114e780{/jobs/job/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4def42c3{/stages,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@72110818{/stages/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6eabe718{/stages/stage,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7530090a{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4492b393{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@55fb36de{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@63a7781{/storage,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@73b74615{/storage/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@22686ddb{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2e29f28e{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bfa1eb5{/environment,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32b46831{/environment/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5353dd09{/executors,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHa",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:8204,Availability,AVAIL,AVAILABLE,8204,"781 - Started o.s.j.s.ServletContextHandler@7114e780{/jobs/job/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4def42c3{/stages,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@72110818{/stages/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6eabe718{/stages/stage,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7530090a{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4492b393{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@55fb36de{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@63a7781{/storage,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@73b74615{/storage/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@22686ddb{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2e29f28e{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bfa1eb5{/environment,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32b46831{/environment/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5353dd09{/executors,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@320ff86f{/executors/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContex",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:8335,Availability,AVAIL,AVAILABLE,8335,"ler:781 - Started o.s.j.s.ServletContextHandler@4def42c3{/stages,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@72110818{/stages/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6eabe718{/stages/stage,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7530090a{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4492b393{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@55fb36de{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@63a7781{/storage,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@73b74615{/storage/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@22686ddb{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2e29f28e{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bfa1eb5{/environment,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32b46831{/environment/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5353dd09{/executors,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@320ff86f{/executors/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@192b472d{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.Se",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:8465,Availability,AVAIL,AVAILABLE,8465,"1 - Started o.s.j.s.ServletContextHandler@72110818{/stages/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6eabe718{/stages/stage,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7530090a{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4492b393{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@55fb36de{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@63a7781{/storage,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@73b74615{/storage/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@22686ddb{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2e29f28e{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bfa1eb5{/environment,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32b46831{/environment/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5353dd09{/executors,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@320ff86f{/executors/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@192b472d{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@84f51d9{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Start",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:8600,Availability,AVAIL,AVAILABLE,8600,"- Started o.s.j.s.ServletContextHandler@6eabe718{/stages/stage,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7530090a{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4492b393{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@55fb36de{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@63a7781{/storage,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@73b74615{/storage/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@22686ddb{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2e29f28e{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bfa1eb5{/environment,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32b46831{/environment/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5353dd09{/executors,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@320ff86f{/executors/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@192b472d{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@84f51d9{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@45b96e4c{/static,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:8730,Availability,AVAIL,AVAILABLE,8730,"Started o.s.j.s.ServletContextHandler@7530090a{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4492b393{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@55fb36de{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@63a7781{/storage,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@73b74615{/storage/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@22686ddb{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2e29f28e{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bfa1eb5{/environment,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32b46831{/environment/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5353dd09{/executors,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@320ff86f{/executors/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@192b472d{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@84f51d9{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@45b96e4c{/static,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3688baab{/,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletCon",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:8865,Availability,AVAIL,AVAILABLE,8865,"1 - Started o.s.j.s.ServletContextHandler@4492b393{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@55fb36de{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@63a7781{/storage,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@73b74615{/storage/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@22686ddb{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2e29f28e{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bfa1eb5{/environment,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32b46831{/environment/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5353dd09{/executors,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@320ff86f{/executors/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@192b472d{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@84f51d9{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@45b96e4c{/static,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3688baab{/,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4fe2dd02{/api,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:8993,Availability,AVAIL,AVAILABLE,8993,"- Started o.s.j.s.ServletContextHandler@55fb36de{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@63a7781{/storage,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@73b74615{/storage/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@22686ddb{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2e29f28e{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bfa1eb5{/environment,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32b46831{/environment/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5353dd09{/executors,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@320ff86f{/executors/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@192b472d{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@84f51d9{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@45b96e4c{/static,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3688baab{/,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4fe2dd02{/api,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@726a8729{/jobs/job/kill,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandle",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:9126,Availability,AVAIL,AVAILABLE,9126,":781 - Started o.s.j.s.ServletContextHandler@63a7781{/storage,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@73b74615{/storage/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@22686ddb{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2e29f28e{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bfa1eb5{/environment,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32b46831{/environment/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5353dd09{/executors,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@320ff86f{/executors/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@192b472d{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@84f51d9{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@45b96e4c{/static,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3688baab{/,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4fe2dd02{/api,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@726a8729{/jobs/job/kill,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1a2724d3{/stages/stage/kill,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO SparkUI:54 - Bound SparkUI to 0.0.0.0, and started a",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:9265,Availability,AVAIL,AVAILABLE,9265,"ted o.s.j.s.ServletContextHandler@73b74615{/storage/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@22686ddb{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2e29f28e{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bfa1eb5{/environment,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32b46831{/environment/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5353dd09{/executors,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@320ff86f{/executors/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@192b472d{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@84f51d9{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@45b96e4c{/static,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3688baab{/,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4fe2dd02{/api,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@726a8729{/jobs/job/kill,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1a2724d3{/stages/stage/kill,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://scc-hadoop.bu.edu:4041; 2019-01-07 11:33:27 INFO SparkContext:54 - Added JAR file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-pac",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:9408,Availability,AVAIL,AVAILABLE,9408,"s.ServletContextHandler@22686ddb{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2e29f28e{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bfa1eb5{/environment,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32b46831{/environment/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5353dd09{/executors,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@320ff86f{/executors/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@192b472d{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@84f51d9{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@45b96e4c{/static,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3688baab{/,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4fe2dd02{/api,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@726a8729{/jobs/job/kill,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1a2724d3{/stages/stage/kill,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://scc-hadoop.bu.edu:4041; 2019-01-07 11:33:27 INFO SparkContext:54 - Added JAR file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar at spark://scc-hadoop.bu.edu:46828/jars/gatk-package-4.0.12.0-spark.jar with timestamp 1546878807984; 2019-01-07 11:3",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:9533,Availability,AVAIL,AVAILABLE,9533,"rvletContextHandler@2e29f28e{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bfa1eb5{/environment,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32b46831{/environment/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5353dd09{/executors,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@320ff86f{/executors/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@192b472d{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@84f51d9{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@45b96e4c{/static,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3688baab{/,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4fe2dd02{/api,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@726a8729{/jobs/job/kill,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1a2724d3{/stages/stage/kill,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://scc-hadoop.bu.edu:4041; 2019-01-07 11:33:27 INFO SparkContext:54 - Added JAR file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar at spark://scc-hadoop.bu.edu:46828/jars/gatk-package-4.0.12.0-spark.jar with timestamp 1546878807984; 2019-01-07 11:33:28 INFO GoogleHadoopFileSystemBase:607 - GHFS version: 1.6.3-hadoop2; 2019-01-07 11:33:29 WARN DomainSocketFactory:117 - The short-c",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:9652,Availability,AVAIL,AVAILABLE,9652,"ed o.s.j.s.ServletContextHandler@7bfa1eb5{/environment,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32b46831{/environment/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5353dd09{/executors,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@320ff86f{/executors/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@192b472d{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@84f51d9{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@45b96e4c{/static,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3688baab{/,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4fe2dd02{/api,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@726a8729{/jobs/job/kill,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1a2724d3{/stages/stage/kill,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://scc-hadoop.bu.edu:4041; 2019-01-07 11:33:27 INFO SparkContext:54 - Added JAR file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar at spark://scc-hadoop.bu.edu:46828/jars/gatk-package-4.0.12.0-spark.jar with timestamp 1546878807984; 2019-01-07 11:33:28 INFO GoogleHadoopFileSystemBase:607 - GHFS version: 1.6.3-hadoop2; 2019-01-07 11:33:29 WARN DomainSocketFactory:117 - The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.; 2019-01-07 11:33:30 INFO Client:54 - Reques",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:9774,Availability,AVAIL,AVAILABLE,9774,"1 - Started o.s.j.s.ServletContextHandler@32b46831{/environment/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5353dd09{/executors,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@320ff86f{/executors/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@192b472d{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@84f51d9{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@45b96e4c{/static,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3688baab{/,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4fe2dd02{/api,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@726a8729{/jobs/job/kill,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1a2724d3{/stages/stage/kill,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://scc-hadoop.bu.edu:4041; 2019-01-07 11:33:27 INFO SparkContext:54 - Added JAR file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar at spark://scc-hadoop.bu.edu:46828/jars/gatk-package-4.0.12.0-spark.jar with timestamp 1546878807984; 2019-01-07 11:33:28 INFO GoogleHadoopFileSystemBase:607 - GHFS version: 1.6.3-hadoop2; 2019-01-07 11:33:29 WARN DomainSocketFactory:117 - The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.; 2019-01-07 11:33:30 INFO Client:54 - Requesting a new application from cluster with 21 NodeManagers; 2019-01-07 11:33:30 INFO Client:54 - Verifying our application",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:9906,Availability,AVAIL,AVAILABLE,9906,"ndler:781 - Started o.s.j.s.ServletContextHandler@5353dd09{/executors,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@320ff86f{/executors/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@192b472d{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@84f51d9{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@45b96e4c{/static,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3688baab{/,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4fe2dd02{/api,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@726a8729{/jobs/job/kill,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1a2724d3{/stages/stage/kill,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://scc-hadoop.bu.edu:4041; 2019-01-07 11:33:27 INFO SparkContext:54 - Added JAR file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar at spark://scc-hadoop.bu.edu:46828/jars/gatk-package-4.0.12.0-spark.jar with timestamp 1546878807984; 2019-01-07 11:33:28 INFO GoogleHadoopFileSystemBase:607 - GHFS version: 1.6.3-hadoop2; 2019-01-07 11:33:29 WARN DomainSocketFactory:117 - The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.; 2019-01-07 11:33:30 INFO Client:54 - Requesting a new application from cluster with 21 NodeManagers; 2019-01-07 11:33:30 INFO Client:54 - Verifying our application has not requested more than the maximum memory capability of the cluster (204800 MB per container); 2019-01-07 11:33:30 INFO C",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:10042,Availability,AVAIL,AVAILABLE,10042,"781 - Started o.s.j.s.ServletContextHandler@320ff86f{/executors/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@192b472d{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@84f51d9{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@45b96e4c{/static,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3688baab{/,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4fe2dd02{/api,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@726a8729{/jobs/job/kill,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1a2724d3{/stages/stage/kill,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://scc-hadoop.bu.edu:4041; 2019-01-07 11:33:27 INFO SparkContext:54 - Added JAR file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar at spark://scc-hadoop.bu.edu:46828/jars/gatk-package-4.0.12.0-spark.jar with timestamp 1546878807984; 2019-01-07 11:33:28 INFO GoogleHadoopFileSystemBase:607 - GHFS version: 1.6.3-hadoop2; 2019-01-07 11:33:29 WARN DomainSocketFactory:117 - The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.; 2019-01-07 11:33:30 INFO Client:54 - Requesting a new application from cluster with 21 NodeManagers; 2019-01-07 11:33:30 INFO Client:54 - Verifying our application has not requested more than the maximum memory capability of the cluster (204800 MB per container); 2019-01-07 11:33:30 INFO Client:54 - Will allocate AM container, with 896 MB memory including 384 MB overhead; 2019-01-07 11:33:30 INFO Client:54 - Setting up co",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:17237,Availability,AVAIL,AVAILABLE,17237,"ce:54 - Server created on scc-hadoop.bu.edu:45270; 2019-01-07 11:33:53 INFO BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy; 2019-01-07 11:33:53 INFO BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, scc-hadoop.bu.edu, 45270, None); 2019-01-07 11:33:53 INFO BlockManagerMasterEndpoint:54 - Registering block manager scc-hadoop.bu.edu:45270 with 408.6 MB RAM, BlockManagerId(driver, scc-hadoop.bu.edu, 45270, None); 2019-01-07 11:33:53 INFO BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, scc-hadoop.bu.edu, 45270, None); 2019-01-07 11:33:53 INFO BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, scc-hadoop.bu.edu, 45270, None); 2019-01-07 11:33:54 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@60251ddb{/metrics/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:58 INFO YarnClientSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after waiting maxRegisteredResourcesWaitingTime: 30000(ms); 2019-01-07 11:33:59 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.18.196:49862) with ID 2; 2019-01-07 11:33:59 INFO BlockManagerMasterEndpoint:54 - Registering block manager scc-q12.scc.bu.edu:38418 with 366.3 MB RAM, BlockManagerId(2, scc-q12.scc.bu.edu, 38418, None); 2019-01-07 11:33:59 INFO MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 1229.0 KB, free 407.4 MB); 2019-01-07 11:34:00 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.18.229:59962) with ID 1; 2019-01-07 11:34:00 INFO BlockManagerMasterEndpoint:54 - Registering block manager scc-q21.scc.bu.edu:41630 with 366.3 MB RAM, BlockManagerId(1, scc-q21.scc.bu.edu, 41630, None); 2019-01-07 11:34:00 INFO MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 113.9 KB, free 40",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:33138,Availability,ERROR,ERROR,33138," sequence MD5 mismatch for slice: sequence id 1, start 4924320, span 190238, expected MD5 8a9ef2f91a78ffdc56561ece832e9f5d) [duplicate 2]; 2019-01-07 11:34:11 INFO TaskSetManager:54 - Starting task 9.1 in stage 0.0 (TID 10, scc-q12.scc.bu.edu, executor 2, partition 9, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:11 INFO TaskSetManager:54 - Lost task 2.1 in stage 0.0 (TID 7) on scc-q12.scc.bu.edu, executor 2: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 0, start 160972515, span 170618, expected MD5 0cc5e1f5ec5c1b06d5a4bd5fff11b77f) [duplicate 1]; 2019-01-07 11:34:12 INFO TaskSetManager:54 - Starting task 3.3 in stage 0.0 (TID 11, scc-q21.scc.bu.edu, executor 1, partition 3, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:12 INFO TaskSetManager:54 - Lost task 1.3 in stage 0.0 (TID 9) on scc-q21.scc.bu.edu, executor 1: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae) [duplicate 3]; 2019-01-07 11:34:12 ERROR TaskSetManager:70 - Task 1 in stage 0.0 failed 4 times; aborting job; 2019-01-07 11:34:12 INFO YarnScheduler:54 - Cancelling stage 0; 2019-01-07 11:34:12 INFO YarnScheduler:54 - Stage 0 was cancelled; 2019-01-07 11:34:12 INFO DAGScheduler:54 - ResultStage 0 (count at CountReadsSpark.java:80) failed in 9.293 s due to Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 9, scc-q21.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIte",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:33487,Availability,failure,failure,33487,"dk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 0, start 160972515, span 170618, expected MD5 0cc5e1f5ec5c1b06d5a4bd5fff11b77f) [duplicate 1]; 2019-01-07 11:34:12 INFO TaskSetManager:54 - Starting task 3.3 in stage 0.0 (TID 11, scc-q21.scc.bu.edu, executor 1, partition 3, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:12 INFO TaskSetManager:54 - Lost task 1.3 in stage 0.0 (TID 9) on scc-q21.scc.bu.edu, executor 1: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae) [duplicate 3]; 2019-01-07 11:34:12 ERROR TaskSetManager:70 - Task 1 in stage 0.0 failed 4 times; aborting job; 2019-01-07 11:34:12 INFO YarnScheduler:54 - Cancelling stage 0; 2019-01-07 11:34:12 INFO YarnScheduler:54 - Stage 0 was cancelled; 2019-01-07 11:34:12 INFO DAGScheduler:54 - ResultStage 0 (count at CountReadsSpark.java:80) failed in 9.293 s due to Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 9, scc-q21.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:33544,Availability,failure,failure,33544,"match for slice: sequence id 0, start 160972515, span 170618, expected MD5 0cc5e1f5ec5c1b06d5a4bd5fff11b77f) [duplicate 1]; 2019-01-07 11:34:12 INFO TaskSetManager:54 - Starting task 3.3 in stage 0.0 (TID 11, scc-q21.scc.bu.edu, executor 1, partition 3, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:12 INFO TaskSetManager:54 - Lost task 1.3 in stage 0.0 (TID 9) on scc-q21.scc.bu.edu, executor 1: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae) [duplicate 3]; 2019-01-07 11:34:12 ERROR TaskSetManager:70 - Task 1 in stage 0.0 failed 4 times; aborting job; 2019-01-07 11:34:12 INFO YarnScheduler:54 - Cancelling stage 0; 2019-01-07 11:34:12 INFO YarnScheduler:54 - Stage 0 was cancelled; 2019-01-07 11:34:12 INFO DAGScheduler:54 - ResultStage 0 (count at CountReadsSpark.java:80) failed in 9.293 s due to Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 9, scc-q21.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkCo",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:35570,Availability,down,down,35570,"ecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 2019-01-07 11:34:12 INFO DAGScheduler:54 - Job 0 failed: count at CountReadsSpark.java:80, took 9.419880 s; 2019-01-07 11:34:12 INFO AbstractConnector:318 - Stopped Spark@f1d88ea{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-07 11:34:12 INFO SparkUI:54 - Stopped Spark web UI at http://scc-hadoop.bu.edu:4041; 2019-01-07 11:34:12 INFO YarnClientSchedulerBackend:54 - Interrupting monitor thread; 2019-01-07 11:34:12 INFO YarnClientSchedulerBackend:54 - Shutting down all executors; 2019-01-07 11:34:12 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-01-07 11:34:12 INFO SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-01-07 11:34:12 INFO YarnClientSchedulerBackend:54 - Stopped; 2019-01-07 11:34:12 INFO MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!; 2019-01-07 11:34:12 INFO MemoryStore:54 - MemoryStore cleared; 2019-01-07 11:34:12 INFO BlockManager:54 - BlockManager stopped; 2019-01-07 11:34:12 INFO BlockManagerMaster:54 - BlockManagerMaster stopped; 2019-01-07 11:34:12 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-01-07 11:34:12 INFO SparkContext:54 - Successfully stopped SparkContext; 11:34:12.605 INFO CountReadsSpark - Shutting down engine; [January 7, 2019 11:34:12 AM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.80 minutes.; Runtime.totalMemory()=1003487232; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 9, scc-q21.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: s",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:35689,Availability,down,down,35689,"ecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 2019-01-07 11:34:12 INFO DAGScheduler:54 - Job 0 failed: count at CountReadsSpark.java:80, took 9.419880 s; 2019-01-07 11:34:12 INFO AbstractConnector:318 - Stopped Spark@f1d88ea{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-07 11:34:12 INFO SparkUI:54 - Stopped Spark web UI at http://scc-hadoop.bu.edu:4041; 2019-01-07 11:34:12 INFO YarnClientSchedulerBackend:54 - Interrupting monitor thread; 2019-01-07 11:34:12 INFO YarnClientSchedulerBackend:54 - Shutting down all executors; 2019-01-07 11:34:12 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-01-07 11:34:12 INFO SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-01-07 11:34:12 INFO YarnClientSchedulerBackend:54 - Stopped; 2019-01-07 11:34:12 INFO MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!; 2019-01-07 11:34:12 INFO MemoryStore:54 - MemoryStore cleared; 2019-01-07 11:34:12 INFO BlockManager:54 - BlockManager stopped; 2019-01-07 11:34:12 INFO BlockManagerMaster:54 - BlockManagerMaster stopped; 2019-01-07 11:34:12 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-01-07 11:34:12 INFO SparkContext:54 - Successfully stopped SparkContext; 11:34:12.605 INFO CountReadsSpark - Shutting down engine; [January 7, 2019 11:34:12 AM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.80 minutes.; Runtime.totalMemory()=1003487232; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 9, scc-q21.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: s",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:36461,Availability,down,down,36461,"d:54 - Interrupting monitor thread; 2019-01-07 11:34:12 INFO YarnClientSchedulerBackend:54 - Shutting down all executors; 2019-01-07 11:34:12 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-01-07 11:34:12 INFO SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-01-07 11:34:12 INFO YarnClientSchedulerBackend:54 - Stopped; 2019-01-07 11:34:12 INFO MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!; 2019-01-07 11:34:12 INFO MemoryStore:54 - MemoryStore cleared; 2019-01-07 11:34:12 INFO BlockManager:54 - BlockManager stopped; 2019-01-07 11:34:12 INFO BlockManagerMaster:54 - BlockManagerMaster stopped; 2019-01-07 11:34:12 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-01-07 11:34:12 INFO SparkContext:54 - Successfully stopped SparkContext; 11:34:12.605 INFO CountReadsSpark - Shutting down engine; [January 7, 2019 11:34:12 AM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.80 minutes.; Runtime.totalMemory()=1003487232; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 9, scc-q21.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.c",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:36703,Availability,failure,failure,36703,"019-01-07 11:34:12 INFO SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-01-07 11:34:12 INFO YarnClientSchedulerBackend:54 - Stopped; 2019-01-07 11:34:12 INFO MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!; 2019-01-07 11:34:12 INFO MemoryStore:54 - MemoryStore cleared; 2019-01-07 11:34:12 INFO BlockManager:54 - BlockManager stopped; 2019-01-07 11:34:12 INFO BlockManagerMaster:54 - BlockManagerMaster stopped; 2019-01-07 11:34:12 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-01-07 11:34:12 INFO SparkContext:54 - Successfully stopped SparkContext; 11:34:12.605 INFO CountReadsSpark - Shutting down engine; [January 7, 2019 11:34:12 AM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.80 minutes.; Runtime.totalMemory()=1003487232; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 9, scc-q21.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfu",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:36760,Availability,failure,failure,36760,"pping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-01-07 11:34:12 INFO YarnClientSchedulerBackend:54 - Stopped; 2019-01-07 11:34:12 INFO MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!; 2019-01-07 11:34:12 INFO MemoryStore:54 - MemoryStore cleared; 2019-01-07 11:34:12 INFO BlockManager:54 - BlockManager stopped; 2019-01-07 11:34:12 INFO BlockManagerMaster:54 - BlockManagerMaster stopped; 2019-01-07 11:34:12 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-01-07 11:34:12 INFO SparkContext:54 - Successfully stopped SparkContext; 11:34:12.605 INFO CountReadsSpark - Shutting down engine; [January 7, 2019 11:34:12 AM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.80 minutes.; Runtime.totalMemory()=1003487232; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 9, scc-q21.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkCo",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:833,Deployability,install,install,833,@tomwhite . I found this 1000 genomes cram that also generates the error. The test cram above would take a lot of paper work to make available. ```; wget ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/1000_genomes_project/data/GBR/HG04302/alignment/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram; wget ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/1000_genomes_project/data/GBR/HG04302/alignment/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram.crai. ```. Here is the error with this cram.... ```; gatk CountReadsSpark --input /project/casa/gcad/test/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -- --spark-runner SPARK --spark-master yarn; Using GATK jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar; Running:; /share/pkg/spark/2.3.0/install/bin/spark-submit --master yarn --conf spark.kryoserializer.buffer.max=512m --conf spark.driver.maxResultSize=0 --conf spark.driver.userClassPathFirst=false --conf spark.io.compression.codec=lzf --conf spark.yarn.executor.memoryOverhead=600 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar CountReadsSpark --input /project/casa/gcad/test/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --spark-master yarn; 2019-01-07 11:33:18 WARN SparkConf:66 - The configuration key 'spark.yarn.executor,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:911,Deployability,install,install,911,@tomwhite . I found this 1000 genomes cram that also generates the error. The test cram above would take a lot of paper work to make available. ```; wget ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/1000_genomes_project/data/GBR/HG04302/alignment/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram; wget ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/1000_genomes_project/data/GBR/HG04302/alignment/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram.crai. ```. Here is the error with this cram.... ```; gatk CountReadsSpark --input /project/casa/gcad/test/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -- --spark-runner SPARK --spark-master yarn; Using GATK jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar; Running:; /share/pkg/spark/2.3.0/install/bin/spark-submit --master yarn --conf spark.kryoserializer.buffer.max=512m --conf spark.driver.maxResultSize=0 --conf spark.driver.userClassPathFirst=false --conf spark.io.compression.codec=lzf --conf spark.yarn.executor.memoryOverhead=600 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar CountReadsSpark --input /project/casa/gcad/test/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --spark-master yarn; 2019-01-07 11:33:18 WARN SparkConf:66 - The configuration key 'spark.yarn.executor,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:1654,Deployability,install,install,1654, file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -- --spark-runner SPARK --spark-master yarn; Using GATK jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar; Running:; /share/pkg/spark/2.3.0/install/bin/spark-submit --master yarn --conf spark.kryoserializer.buffer.max=512m --conf spark.driver.maxResultSize=0 --conf spark.driver.userClassPathFirst=false --conf spark.io.compression.codec=lzf --conf spark.yarn.executor.memoryOverhead=600 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar CountReadsSpark --input /project/casa/gcad/test/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --spark-master yarn; 2019-01-07 11:33:18 WARN SparkConf:66 - The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 2019-01-07 11:33:19 WARN NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 11:33:24.377 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 11:33:24.549 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar!/com/intel/g,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:1963,Deployability,configurat,configuration,1963,ter yarn --conf spark.kryoserializer.buffer.max=512m --conf spark.driver.maxResultSize=0 --conf spark.driver.userClassPathFirst=false --conf spark.io.compression.codec=lzf --conf spark.yarn.executor.memoryOverhead=600 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar CountReadsSpark --input /project/casa/gcad/test/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --spark-master yarn; 2019-01-07 11:33:18 WARN SparkConf:66 - The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 2019-01-07 11:33:19 WARN NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 11:33:24.377 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 11:33:24.549 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar!/com/intel/gkl/native/libgkl_compression.so; 11:33:26.271 INFO CountReadsSpark - ------------------------------------------------------------; 11:33:26.272 INFO CountReadsSpark - The Genome Analysis Toolkit (GATK) v4.0.12.0; 11:33:26.272 INFO CountReadsSpark - For support and documentat,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:2611,Deployability,install,install,2611,"vel=2 /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar CountReadsSpark --input /project/casa/gcad/test/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --spark-master yarn; 2019-01-07 11:33:18 WARN SparkConf:66 - The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 2019-01-07 11:33:19 WARN NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 11:33:24.377 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 11:33:24.549 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar!/com/intel/gkl/native/libgkl_compression.so; 11:33:26.271 INFO CountReadsSpark - ------------------------------------------------------------; 11:33:26.272 INFO CountReadsSpark - The Genome Analysis Toolkit (GATK) v4.0.12.0; 11:33:26.272 INFO CountReadsSpark - For support and documentation go to https://software.broadinstitute.org/gatk/; 11:33:26.272 INFO CountReadsSpark - Executing as farrell@scc-hadoop.bu.edu on Linux v2.6.32-754.6.3.el6.x86_64 amd64; 11:33:26.273 INFO CountReadsSpark - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_121-b13; 11:33:26.273 INFO CountReadsSpark - Start Date/Time: January 7, 2019 11:33:24 AM EST; 11:33:26.273 INFO CountReadsSpark - ------------------------------------------------------------; 11:33:26.273 INFO CountReadsSpark - ------------------------------------------------------------; 11:33:26.275 INFO CountReadsSpark - HTSJDK Version: 2.18.1; 11:33:26.275 INFO CountReadsSpark - Picard Version: 2.18.16; 11:33:26",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:4625,Deployability,configurat,configuration,4625,- Picard Version: 2.18.16; 11:33:26.275 INFO CountReadsSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 11:33:26.275 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 11:33:26.275 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 11:33:26.276 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 11:33:26.276 INFO CountReadsSpark - Deflater: IntelDeflater; 11:33:26.276 INFO CountReadsSpark - Inflater: IntelInflater; 11:33:26.276 INFO CountReadsSpark - GCS max retries/reopens: 20; 11:33:26.276 INFO CountReadsSpark - Requester pays: disabled; 11:33:26.277 WARN CountReadsSpark -. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: CountReadsSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 11:33:26.277 INFO CountReadsSpark - Initializing engine; 11:33:26.277 INFO CountReadsSpark - Done initializing engine; 2019-01-07 11:33:26 WARN SparkConf:66 - The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 2019-01-07 11:33:26 INFO SparkContext:54 - Running Spark version 2.3.0; 2019-01-07 11:33:26 INFO SparkContext:54 - Submitted application: CountReadsSpark; 2019-01-07 11:33:26 INFO SecurityManager:54 - Changing view acls to: farrell; 2019-01-07 11:33:26 INFO SecurityManager:54 - Changing modify acls to: farrell; 2019-01-07 11:33:26 INFO SecurityManager:54 - Changing view acls groups to:; 2019-01-07 11:33:26 INFO SecurityManager:54 - Changing modify acls groups to:; 2019-01-07 11:33:26 INFO SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(farrell); groups with view permissions: Set(); users with modify permissions: Set(farrell); groups with modify permissions: Set(); 2019-01-07 11:33:27 INFO Utils:54 -,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:10254,Deployability,install,install,10254,"VAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@84f51d9{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@45b96e4c{/static,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3688baab{/,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4fe2dd02{/api,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@726a8729{/jobs/job/kill,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1a2724d3{/stages/stage/kill,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://scc-hadoop.bu.edu:4041; 2019-01-07 11:33:27 INFO SparkContext:54 - Added JAR file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar at spark://scc-hadoop.bu.edu:46828/jars/gatk-package-4.0.12.0-spark.jar with timestamp 1546878807984; 2019-01-07 11:33:28 INFO GoogleHadoopFileSystemBase:607 - GHFS version: 1.6.3-hadoop2; 2019-01-07 11:33:29 WARN DomainSocketFactory:117 - The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.; 2019-01-07 11:33:30 INFO Client:54 - Requesting a new application from cluster with 21 NodeManagers; 2019-01-07 11:33:30 INFO Client:54 - Verifying our application has not requested more than the maximum memory capability of the cluster (204800 MB per container); 2019-01-07 11:33:30 INFO Client:54 - Will allocate AM container, with 896 MB memory including 384 MB overhead; 2019-01-07 11:33:30 INFO Client:54 - Setting up container launch context for our AM; 2019-01-07 11:33:30 INFO Client:54 - Setting up the launch environment for our AM container; 2019-01-07 11:33:30 INFO Client:54 - Preparing resources for our AM container; 2019-01",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:36550,Deployability,pipeline,pipelines,36550,":54 - Shutting down all executors; 2019-01-07 11:34:12 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-01-07 11:34:12 INFO SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-01-07 11:34:12 INFO YarnClientSchedulerBackend:54 - Stopped; 2019-01-07 11:34:12 INFO MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!; 2019-01-07 11:34:12 INFO MemoryStore:54 - MemoryStore cleared; 2019-01-07 11:34:12 INFO BlockManager:54 - BlockManager stopped; 2019-01-07 11:34:12 INFO BlockManagerMaster:54 - BlockManagerMaster stopped; 2019-01-07 11:34:12 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-01-07 11:34:12 INFO SparkContext:54 - Successfully stopped SparkContext; 11:34:12.605 INFO CountReadsSpark - Shutting down engine; [January 7, 2019 11:34:12 AM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.80 minutes.; Runtime.totalMemory()=1003487232; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 9, scc-q21.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Util",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:40178,Deployability,pipeline,pipelines,40178,uler.handleTaskSetFailed(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2027); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2048); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2092); at org.apache.spark.rdd.RDD.count(RDD.scala:1162); at org.apache.spark.api.java.JavaRDDLike$class.count(JavaRDDLike.scala:455); at org.apache.spark.api.java.AbstractJavaRDDLike.count(JavaRDDLike.scala:45); at org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark.runTool(CountReadsSpark.java:80); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:470); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessor,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:41271,Deployability,deploy,deploy,41271,"ine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:470); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:879); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:197); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:227); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:136); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:41352,Deployability,deploy,deploy,41352,"e.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:879); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:197); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:227); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:136); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:41389,Deployability,deploy,deploy,41389,"gram.doWork(SparkCommandLineProgram.java:30); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:879); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:197); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:227); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:136); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(I",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:41461,Deployability,deploy,deploy,41461,"ute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:879); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:197); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:227); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:136); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorS",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:41537,Deployability,deploy,deploy,41537,"9); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:879); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:197); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:227); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:136); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RD",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:41608,Deployability,deploy,deploy,41608,"eMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:879); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:197); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:227); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:136); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.s",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:41677,Deployability,deploy,deploy,41677,"e.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:879); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:197); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:227); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:136); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:43762,Deployability,install,install,43762,xt.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); 2019-01-07 11:34:12 INFO ShutdownHookManager:54 - Shutdown hook called; 2019-01-07 11:34:12 INFO ShutdownHookManager:54 - Deleting directory /tmp/spark-1ac79f09-1a36-4668-92d9-0739775f98ed; 2019-01-07 11:34:12 INFO ShutdownHookManager:54 - Deleting directory /tmp/spark-ed279998-3783-4f41-8fe5-f44a4fac3ee4; ```. CountReads runs fine..... ```; gatk CountReads --input HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa; Using GATK jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-local.jar CountReads --input HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa; 11:36:23.022 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 11:36:25.027 INFO CountReads - ------------------------------------------------------------; 11:36:25.028 INFO CountReads - The Genome Analysis Toolkit (GATK) v4.0.12.0; 11:36:25.028 INFO CountReads - For support and documentation go to https://software.broadinstitute.org/gatk/; 11:36:25.029 INFO CountReads - Executing as farrell@scc-hadoop.bu.edu on L,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:44007,Deployability,install,install,44007,"adPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); 2019-01-07 11:34:12 INFO ShutdownHookManager:54 - Shutdown hook called; 2019-01-07 11:34:12 INFO ShutdownHookManager:54 - Deleting directory /tmp/spark-1ac79f09-1a36-4668-92d9-0739775f98ed; 2019-01-07 11:34:12 INFO ShutdownHookManager:54 - Deleting directory /tmp/spark-ed279998-3783-4f41-8fe5-f44a4fac3ee4; ```. CountReads runs fine..... ```; gatk CountReads --input HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa; Using GATK jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-local.jar CountReads --input HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa; 11:36:23.022 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 11:36:25.027 INFO CountReads - ------------------------------------------------------------; 11:36:25.028 INFO CountReads - The Genome Analysis Toolkit (GATK) v4.0.12.0; 11:36:25.028 INFO CountReads - For support and documentation go to https://software.broadinstitute.org/gatk/; 11:36:25.029 INFO CountReads - Executing as farrell@scc-hadoop.bu.edu on Linux v2.6.32-754.6.3.el6.x86_64 amd64; 11:36:25.029 INFO CountReads - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_121-b13; 11:36:25.030 INFO CountReads - Start Date/Time: January 7, 2019 11:36:22 AM EST; 11:36:25.030 INFO CountReads -",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:44332,Deployability,install,install,44332,"mp/spark-1ac79f09-1a36-4668-92d9-0739775f98ed; 2019-01-07 11:34:12 INFO ShutdownHookManager:54 - Deleting directory /tmp/spark-ed279998-3783-4f41-8fe5-f44a4fac3ee4; ```. CountReads runs fine..... ```; gatk CountReads --input HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa; Using GATK jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-local.jar CountReads --input HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa; 11:36:23.022 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 11:36:25.027 INFO CountReads - ------------------------------------------------------------; 11:36:25.028 INFO CountReads - The Genome Analysis Toolkit (GATK) v4.0.12.0; 11:36:25.028 INFO CountReads - For support and documentation go to https://software.broadinstitute.org/gatk/; 11:36:25.029 INFO CountReads - Executing as farrell@scc-hadoop.bu.edu on Linux v2.6.32-754.6.3.el6.x86_64 amd64; 11:36:25.029 INFO CountReads - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_121-b13; 11:36:25.030 INFO CountReads - Start Date/Time: January 7, 2019 11:36:22 AM EST; 11:36:25.030 INFO CountReads - ------------------------------------------------------------; 11:36:25.031 INFO CountReads - ------------------------------------------------------------; 11:36:25.032 INFO CountReads - HTSJDK Version: 2.18.1; 11:36:25.033 INFO CountReads - Picard Version: 2.18.16; 11:36:25.033 INFO CountReads - HTSJDK Defaults.COMPRESSION",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:10934,Energy Efficiency,allocate,allocate,10934,"ges/stage/kill,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://scc-hadoop.bu.edu:4041; 2019-01-07 11:33:27 INFO SparkContext:54 - Added JAR file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar at spark://scc-hadoop.bu.edu:46828/jars/gatk-package-4.0.12.0-spark.jar with timestamp 1546878807984; 2019-01-07 11:33:28 INFO GoogleHadoopFileSystemBase:607 - GHFS version: 1.6.3-hadoop2; 2019-01-07 11:33:29 WARN DomainSocketFactory:117 - The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.; 2019-01-07 11:33:30 INFO Client:54 - Requesting a new application from cluster with 21 NodeManagers; 2019-01-07 11:33:30 INFO Client:54 - Verifying our application has not requested more than the maximum memory capability of the cluster (204800 MB per container); 2019-01-07 11:33:30 INFO Client:54 - Will allocate AM container, with 896 MB memory including 384 MB overhead; 2019-01-07 11:33:30 INFO Client:54 - Setting up container launch context for our AM; 2019-01-07 11:33:30 INFO Client:54 - Setting up the launch environment for our AM container; 2019-01-07 11:33:30 INFO Client:54 - Preparing resources for our AM container; 2019-01-07 11:33:30 INFO HadoopFSDelegationTokenProvider:54 - getting token for: DFS[DFSClient[clientName=DFSClient_NONMAPREDUCE_-1883879239_1, ugi=farrell@AD.BU.EDU (auth:KERBEROS)]]; 2019-01-07 11:33:30 INFO DFSClient:1023 - Created HDFS_DELEGATION_TOKEN token 11334 for farrell on ha-hdfs:scc; 2019-01-07 11:33:32 WARN Client:66 - Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.; 2019-01-07 11:33:36 INFO Client:54 - Uploading resource file:/tmp/spark-1ac79f09-1a36-4668-92d9-0739775f98ed/__spark_libs__7473738539612638927.zip -> hdfs://scc/user/farrell/.sparkStaging/application_1542127286896_0153/__spark_libs__7473738539612638927.zip; 2019-01-07 11:33:38 INFO Client:54 - Uploading resource file:",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:13021,Energy Efficiency,Schedul,SchedulerExtensionServices,13021,"c/user/farrell/.sparkStaging/application_1542127286896_0153/__spark_libs__7473738539612638927.zip; 2019-01-07 11:33:38 INFO Client:54 - Uploading resource file:/tmp/spark-1ac79f09-1a36-4668-92d9-0739775f98ed/__spark_conf__4147634812449814799.zip -> hdfs://scc/user/farrell/.sparkStaging/application_1542127286896_0153/__spark_conf__.zip; 2019-01-07 11:33:38 INFO SecurityManager:54 - Changing view acls to: farrell; 2019-01-07 11:33:38 INFO SecurityManager:54 - Changing modify acls to: farrell; 2019-01-07 11:33:38 INFO SecurityManager:54 - Changing view acls groups to:; 2019-01-07 11:33:38 INFO SecurityManager:54 - Changing modify acls groups to:; 2019-01-07 11:33:38 INFO SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(farrell); groups with view permissions: Set(); users with modify permissions: Set(farrell); groups with modify permissions: Set(); 2019-01-07 11:33:38 INFO Client:54 - Submitting application application_1542127286896_0153 to ResourceManager; 2019-01-07 11:33:38 INFO YarnClientImpl:251 - Submitted application application_1542127286896_0153; 2019-01-07 11:33:38 INFO SchedulerExtensionServices:54 - Starting Yarn extension services with app application_1542127286896_0153 and attemptId None; 2019-01-07 11:33:39 INFO Client:54 - Application report for application_1542127286896_0153 (state: ACCEPTED); 2019-01-07 11:33:39 INFO Client:54 -; client token: Token { kind: YARN_CLIENT_TOKEN, service: }; diagnostics: N/A; ApplicationMaster host: N/A; ApplicationMaster RPC port: -1; queue: default; start time: 1546878818531; final status: UNDEFINED; tracking URL: https://scc-hsn1.scc.bu.edu:8090/proxy/application_1542127286896_0153/; user: farrell; 2019-01-07 11:33:40 INFO Client:54 - Application report for application_1542127286896_0153 (state: ACCEPTED); 2019-01-07 11:33:41 INFO Client:54 - Application report for application_1542127286896_0153 (state: ACCEPTED); 2019-01-07 11:33:42 INFO Client:54 - Applic",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:17313,Energy Efficiency,Schedul,SchedulerBackend,17313,"ce:54 - Server created on scc-hadoop.bu.edu:45270; 2019-01-07 11:33:53 INFO BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy; 2019-01-07 11:33:53 INFO BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, scc-hadoop.bu.edu, 45270, None); 2019-01-07 11:33:53 INFO BlockManagerMasterEndpoint:54 - Registering block manager scc-hadoop.bu.edu:45270 with 408.6 MB RAM, BlockManagerId(driver, scc-hadoop.bu.edu, 45270, None); 2019-01-07 11:33:53 INFO BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, scc-hadoop.bu.edu, 45270, None); 2019-01-07 11:33:53 INFO BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, scc-hadoop.bu.edu, 45270, None); 2019-01-07 11:33:54 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@60251ddb{/metrics/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:58 INFO YarnClientSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after waiting maxRegisteredResourcesWaitingTime: 30000(ms); 2019-01-07 11:33:59 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.18.196:49862) with ID 2; 2019-01-07 11:33:59 INFO BlockManagerMasterEndpoint:54 - Registering block manager scc-q12.scc.bu.edu:38418 with 366.3 MB RAM, BlockManagerId(2, scc-q12.scc.bu.edu, 38418, None); 2019-01-07 11:33:59 INFO MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 1229.0 KB, free 407.4 MB); 2019-01-07 11:34:00 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.18.229:59962) with ID 1; 2019-01-07 11:34:00 INFO BlockManagerMasterEndpoint:54 - Registering block manager scc-q21.scc.bu.edu:41630 with 366.3 MB RAM, BlockManagerId(1, scc-q21.scc.bu.edu, 41630, None); 2019-01-07 11:34:00 INFO MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 113.9 KB, free 40",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:17343,Energy Efficiency,schedul,scheduling,17343,"ce:54 - Server created on scc-hadoop.bu.edu:45270; 2019-01-07 11:33:53 INFO BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy; 2019-01-07 11:33:53 INFO BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, scc-hadoop.bu.edu, 45270, None); 2019-01-07 11:33:53 INFO BlockManagerMasterEndpoint:54 - Registering block manager scc-hadoop.bu.edu:45270 with 408.6 MB RAM, BlockManagerId(driver, scc-hadoop.bu.edu, 45270, None); 2019-01-07 11:33:53 INFO BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, scc-hadoop.bu.edu, 45270, None); 2019-01-07 11:33:53 INFO BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, scc-hadoop.bu.edu, 45270, None); 2019-01-07 11:33:54 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@60251ddb{/metrics/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:58 INFO YarnClientSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after waiting maxRegisteredResourcesWaitingTime: 30000(ms); 2019-01-07 11:33:59 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.18.196:49862) with ID 2; 2019-01-07 11:33:59 INFO BlockManagerMasterEndpoint:54 - Registering block manager scc-q12.scc.bu.edu:38418 with 366.3 MB RAM, BlockManagerId(2, scc-q12.scc.bu.edu, 38418, None); 2019-01-07 11:33:59 INFO MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 1229.0 KB, free 407.4 MB); 2019-01-07 11:34:00 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.18.229:59962) with ID 1; 2019-01-07 11:34:00 INFO BlockManagerMasterEndpoint:54 - Registering block manager scc-q21.scc.bu.edu:41630 with 366.3 MB RAM, BlockManagerId(1, scc-q21.scc.bu.edu, 41630, None); 2019-01-07 11:34:00 INFO MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 113.9 KB, free 40",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:24794,Energy Efficiency,schedul,scheduler,24794,"ence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-07 11:34:07 INFO TaskSetManager:54 - Starting task 1.1 in stage 0.0 (TID 3, scc-q21.scc.bu.edu, executor 1, partition 1, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:07 WARN TaskSetManager:66 - Lost task 3.0 in stage 0.0 (TID 2, scc-q21.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 1, start 4924320, span 190238, expected MD5 8a9ef2f91a78ffdc56561ece832e9f5d; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseI",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:24865,Energy Efficiency,schedul,scheduler,24865,"de06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-07 11:34:07 INFO TaskSetManager:54 - Starting task 1.1 in stage 0.0 (TID 3, scc-q21.scc.bu.edu, executor 1, partition 1, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:07 WARN TaskSetManager:66 - Lost task 3.0 in stage 0.0 (TID 2, scc-q21.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 1, start 4924320, span 190238, expected MD5 8a9ef2f91a78ffdc56561ece832e9f5d; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.coll",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:26529,Energy Efficiency,schedul,scheduler,26529,"uence id 1, start 4924320, span 190238, expected MD5 8a9ef2f91a78ffdc56561ece832e9f5d; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-07 11:34:08 INFO TaskSetManager:54 - Starting task 3.1 in stage 0.0 (TID 4, scc-q21.scc.bu.edu, executor 1, partition 3, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:08 INFO TaskSetManager:54 - Lost task 1.1 in stage 0.0 (TID 3) on scc-q21.scc.bu.edu, executor 1: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae) [duplicate 1]; 2019-01-07 11:34:09 INFO TaskSetManager:54 - Starting task 9.0 in stage 0.0 (TID 5, scc-q12.scc.bu.edu, executor 2, partition 9, NODE_LOCAL, 7992 bytes); 2019-0",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:26600,Energy Efficiency,schedul,scheduler,26600,"561ece832e9f5d; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-07 11:34:08 INFO TaskSetManager:54 - Starting task 3.1 in stage 0.0 (TID 4, scc-q21.scc.bu.edu, executor 1, partition 3, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:08 INFO TaskSetManager:54 - Lost task 1.1 in stage 0.0 (TID 3) on scc-q21.scc.bu.edu, executor 1: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae) [duplicate 1]; 2019-01-07 11:34:09 INFO TaskSetManager:54 - Starting task 9.0 in stage 0.0 (TID 5, scc-q12.scc.bu.edu, executor 2, partition 9, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:09 WARN TaskSetManager:66 - Lost task 2.0 in stage 0.0 (TID ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:28720,Energy Efficiency,schedul,scheduler,28720,"nce id 0, start 160972515, span 170618, expected MD5 0cc5e1f5ec5c1b06d5a4bd5fff11b77f; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-07 11:34:09 INFO TaskSetManager:54 - Starting task 1.2 in stage 0.0 (TID 6, scc-q21.scc.bu.edu, executor 1, partition 1, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:09 INFO TaskSetManager:54 - Lost task 3.1 in stage 0.0 (TID 4) on scc-q21.scc.bu.edu, executor 1: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 1, start 4924320, span 190238, expected MD5 8a9ef2f91a78ffdc56561ece832e9f5d) [duplicate 1]; 2019-01-07 11:34:10 INFO TaskSetManager:54 - Starting task 2.1 in stage 0.0 (TID 7, scc-q12.scc.bu.edu, executor 2, partition 2, NODE_LOCAL, 7992 bytes); 2019-01",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:28791,Energy Efficiency,schedul,scheduler,28791,"a4bd5fff11b77f; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-07 11:34:09 INFO TaskSetManager:54 - Starting task 1.2 in stage 0.0 (TID 6, scc-q21.scc.bu.edu, executor 1, partition 1, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:09 INFO TaskSetManager:54 - Lost task 3.1 in stage 0.0 (TID 4) on scc-q21.scc.bu.edu, executor 1: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 1, start 4924320, span 190238, expected MD5 8a9ef2f91a78ffdc56561ece832e9f5d) [duplicate 1]; 2019-01-07 11:34:10 INFO TaskSetManager:54 - Starting task 2.1 in stage 0.0 (TID 7, scc-q12.scc.bu.edu, executor 2, partition 2, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:10 WARN TaskSetManager:66 - Lost task 9.0 in stage 0.0 (TID 5",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:30909,Energy Efficiency,schedul,scheduler,30909,"ence id 3, start 97885291, span 192458, expected MD5 ef90368731b6e0be845bc82cd92b0c6a; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-07 11:34:10 INFO TaskSetManager:54 - Starting task 3.2 in stage 0.0 (TID 8, scc-q21.scc.bu.edu, executor 1, partition 3, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:10 INFO TaskSetManager:54 - Lost task 1.2 in stage 0.0 (TID 6) on scc-q21.scc.bu.edu, executor 1: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae) [duplicate 2]; 2019-01-07 11:34:11 INFO TaskSetManager:54 - Starting task 1.3 in stage 0.0 (TID 9, scc-q21.scc.bu.edu, executor 1, partition 1, NODE_LOCAL, 7992 bytes); 2019-0",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:30980,Energy Efficiency,schedul,scheduler,30980,"5bc82cd92b0c6a; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-07 11:34:10 INFO TaskSetManager:54 - Starting task 3.2 in stage 0.0 (TID 8, scc-q21.scc.bu.edu, executor 1, partition 3, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:10 INFO TaskSetManager:54 - Lost task 1.2 in stage 0.0 (TID 6) on scc-q21.scc.bu.edu, executor 1: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae) [duplicate 2]; 2019-01-07 11:34:11 INFO TaskSetManager:54 - Starting task 1.3 in stage 0.0 (TID 9, scc-q21.scc.bu.edu, executor 1, partition 1, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:11 INFO TaskSetManager:54 - Lost task 3.2 in stage 0.0 (TID ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:34699,Energy Efficiency,schedul,scheduler,34699,"ence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 2019-01-07 11:34:12 INFO DAGScheduler:54 - Job 0 failed: count at CountReadsSpark.java:80, took 9.419880 s; 2019-01-07 11:34:12 INFO AbstractConnector:318 - Stopped Spark@f1d88ea{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-07 11:34:12 INFO SparkUI:54 - Stopped Spark web UI at http://scc-hadoop.bu.edu:4041; 2019-01-07 11:34:12 INFO YarnClientSchedulerBackend:54 - Interrupting monitor thread; 2019-01-07 11:34:12 INFO YarnClientSchedulerBackend:54 - Shutting down all executors; 2019-01-07 11:34:12 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-01-0",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:34770,Energy Efficiency,schedul,scheduler,34770,"de06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 2019-01-07 11:34:12 INFO DAGScheduler:54 - Job 0 failed: count at CountReadsSpark.java:80, took 9.419880 s; 2019-01-07 11:34:12 INFO AbstractConnector:318 - Stopped Spark@f1d88ea{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-07 11:34:12 INFO SparkUI:54 - Stopped Spark web UI at http://scc-hadoop.bu.edu:4041; 2019-01-07 11:34:12 INFO YarnClientSchedulerBackend:54 - Interrupting monitor thread; 2019-01-07 11:34:12 INFO YarnClientSchedulerBackend:54 - Shutting down all executors; 2019-01-07 11:34:12 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-01-07 11:34:12 INFO SchedulerExtensionServices:54 - Stopping SchedulerExten",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:35488,Energy Efficiency,monitor,monitor,35488,"ecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 2019-01-07 11:34:12 INFO DAGScheduler:54 - Job 0 failed: count at CountReadsSpark.java:80, took 9.419880 s; 2019-01-07 11:34:12 INFO AbstractConnector:318 - Stopped Spark@f1d88ea{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-07 11:34:12 INFO SparkUI:54 - Stopped Spark web UI at http://scc-hadoop.bu.edu:4041; 2019-01-07 11:34:12 INFO YarnClientSchedulerBackend:54 - Interrupting monitor thread; 2019-01-07 11:34:12 INFO YarnClientSchedulerBackend:54 - Shutting down all executors; 2019-01-07 11:34:12 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-01-07 11:34:12 INFO SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-01-07 11:34:12 INFO YarnClientSchedulerBackend:54 - Stopped; 2019-01-07 11:34:12 INFO MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!; 2019-01-07 11:34:12 INFO MemoryStore:54 - MemoryStore cleared; 2019-01-07 11:34:12 INFO BlockManager:54 - BlockManager stopped; 2019-01-07 11:34:12 INFO BlockManagerMaster:54 - BlockManagerMaster stopped; 2019-01-07 11:34:12 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-01-07 11:34:12 INFO SparkContext:54 - Successfully stopped SparkContext; 11:34:12.605 INFO CountReadsSpark - Shutting down engine; [January 7, 2019 11:34:12 AM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.80 minutes.; Runtime.totalMemory()=1003487232; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 9, scc-q21.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: s",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:35720,Energy Efficiency,Schedul,SchedulerExtensionServices,35720,"ecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 2019-01-07 11:34:12 INFO DAGScheduler:54 - Job 0 failed: count at CountReadsSpark.java:80, took 9.419880 s; 2019-01-07 11:34:12 INFO AbstractConnector:318 - Stopped Spark@f1d88ea{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-07 11:34:12 INFO SparkUI:54 - Stopped Spark web UI at http://scc-hadoop.bu.edu:4041; 2019-01-07 11:34:12 INFO YarnClientSchedulerBackend:54 - Interrupting monitor thread; 2019-01-07 11:34:12 INFO YarnClientSchedulerBackend:54 - Shutting down all executors; 2019-01-07 11:34:12 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-01-07 11:34:12 INFO SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-01-07 11:34:12 INFO YarnClientSchedulerBackend:54 - Stopped; 2019-01-07 11:34:12 INFO MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!; 2019-01-07 11:34:12 INFO MemoryStore:54 - MemoryStore cleared; 2019-01-07 11:34:12 INFO BlockManager:54 - BlockManager stopped; 2019-01-07 11:34:12 INFO BlockManagerMaster:54 - BlockManagerMaster stopped; 2019-01-07 11:34:12 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-01-07 11:34:12 INFO SparkContext:54 - Successfully stopped SparkContext; 11:34:12.605 INFO CountReadsSpark - Shutting down engine; [January 7, 2019 11:34:12 AM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.80 minutes.; Runtime.totalMemory()=1003487232; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 9, scc-q21.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: s",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:35761,Energy Efficiency,Schedul,SchedulerExtensionServices,35761,"ecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 2019-01-07 11:34:12 INFO DAGScheduler:54 - Job 0 failed: count at CountReadsSpark.java:80, took 9.419880 s; 2019-01-07 11:34:12 INFO AbstractConnector:318 - Stopped Spark@f1d88ea{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-07 11:34:12 INFO SparkUI:54 - Stopped Spark web UI at http://scc-hadoop.bu.edu:4041; 2019-01-07 11:34:12 INFO YarnClientSchedulerBackend:54 - Interrupting monitor thread; 2019-01-07 11:34:12 INFO YarnClientSchedulerBackend:54 - Shutting down all executors; 2019-01-07 11:34:12 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-01-07 11:34:12 INFO SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-01-07 11:34:12 INFO YarnClientSchedulerBackend:54 - Stopped; 2019-01-07 11:34:12 INFO MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!; 2019-01-07 11:34:12 INFO MemoryStore:54 - MemoryStore cleared; 2019-01-07 11:34:12 INFO BlockManager:54 - BlockManager stopped; 2019-01-07 11:34:12 INFO BlockManagerMaster:54 - BlockManagerMaster stopped; 2019-01-07 11:34:12 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-01-07 11:34:12 INFO SparkContext:54 - Successfully stopped SparkContext; 11:34:12.605 INFO CountReadsSpark - Shutting down engine; [January 7, 2019 11:34:12 AM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.80 minutes.; Runtime.totalMemory()=1003487232; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 9, scc-q21.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: s",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:37915,Energy Efficiency,schedul,scheduler,37915,"ence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.schedule",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:37986,Energy Efficiency,schedul,scheduler,37986,de06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:38346,Energy Efficiency,schedul,scheduler,38346,or$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820); at org.apache.spark.s,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:38386,Energy Efficiency,schedul,scheduler,38386,n.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGSchedule,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:38484,Energy Efficiency,schedul,scheduler,38484,anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onRec,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:38581,Energy Efficiency,schedul,scheduler,38581,1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:38832,Energy Efficiency,schedul,scheduler,38832,Context$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2027); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2048); at org.apache.spark.SparkContext.runJob(Sp,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:38912,Energy Efficiency,schedul,scheduler,38912,heduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2027); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2048); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067); at org.apache.spark.SparkContext.runJob(SparkContext.sca,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:39017,Energy Efficiency,schedul,scheduler,39017,at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2027); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2048); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2092); at org.apache.spark.rdd.RDD.count(RDD.scala:1162); at org.apache.spark.api.java.JavaRDDLike$cla,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:39165,Energy Efficiency,schedul,scheduler,39165,va:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2027); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2048); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2092); at org.apache.spark.rdd.RDD.count(RDD.scala:1162); at org.apache.spark.api.java.JavaRDDLike$class.count(JavaRDDLike.scala:455); at org.apache.spark.api.java.AbstractJavaRDDLike.count(JavaRDDLike.scala:45); at org.broadinstitute.hellbender.tool,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:39253,Energy Efficiency,schedul,scheduler,39253,617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2027); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2048); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2092); at org.apache.spark.rdd.RDD.count(RDD.scala:1162); at org.apache.spark.api.java.JavaRDDLike$class.count(JavaRDDLike.scala:455); at org.apache.spark.api.java.AbstractJavaRDDLike.count(JavaRDDLike.scala:45); at org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark.runTool(CountReadsSpark.java:80); at org.broadinstitut,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:39350,Energy Efficiency,schedul,scheduler,39350,.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2027); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2048); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2092); at org.apache.spark.rdd.RDD.count(RDD.scala:1162); at org.apache.spark.api.java.JavaRDDLike$class.count(JavaRDDLike.scala:455); at org.apache.spark.api.java.AbstractJavaRDDLike.count(JavaRDDLike.scala:45); at org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark.runTool(CountReadsSpark.java:80); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:470); at org.broadinstitut,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:39445,Energy Efficiency,schedul,scheduler,39445,.scala:1599); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2027); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2048); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2092); at org.apache.spark.rdd.RDD.count(RDD.scala:1162); at org.apache.spark.api.java.JavaRDDLike$class.count(JavaRDDLike.scala:455); at org.apache.spark.api.java.AbstractJavaRDDLike.count(JavaRDDLike.scala:45); at org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark.runTool(CountReadsSpark.java:80); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:470); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); at o,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:39608,Energy Efficiency,schedul,scheduler,39608,abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2027); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2048); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2092); at org.apache.spark.rdd.RDD.count(RDD.scala:1162); at org.apache.spark.api.java.JavaRDDLike$class.count(JavaRDDLike.scala:455); at org.apache.spark.api.java.AbstractJavaRDDLike.count(JavaRDDLike.scala:45); at org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark.runTool(CountReadsSpark.java:80); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:470); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceM,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:42810,Energy Efficiency,schedul,scheduler,42810,"ence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); 2019-01-07 11:34:12 INFO ShutdownHookManager:54 - Shutdown hook called; 2019-01-07 11:34:12 INFO ShutdownHookManager:54 - Deleting directory /tmp/spark-1ac79f09-1a36-4668-92d9-0739775f98ed; 2019-01-07 11:34:12 INFO ShutdownHookManager:54 - Deleting directory /tmp/spark-ed279998-3783-4f41-8fe5-f44a4fac3ee4; ```. CountReads runs fine..... ```; gatk CountReads --input HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa; Using GATK jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-local.jar; Running:",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:42881,Energy Efficiency,schedul,scheduler,42881,de06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); 2019-01-07 11:34:12 INFO ShutdownHookManager:54 - Shutdown hook called; 2019-01-07 11:34:12 INFO ShutdownHookManager:54 - Deleting directory /tmp/spark-1ac79f09-1a36-4668-92d9-0739775f98ed; 2019-01-07 11:34:12 INFO ShutdownHookManager:54 - Deleting directory /tmp/spark-ed279998-3783-4f41-8fe5-f44a4fac3ee4; ```. CountReads runs fine..... ```; gatk CountReads --input HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa; Using GATK jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:24150,Integrability,Wrap,Wrappers,24150,"019-01-07 11:34:05 INFO BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on scc-q12.scc.bu.edu:38418 (size: 25.4 KB, free: 365.9 MB); 2019-01-07 11:34:05 INFO BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on scc-q12.scc.bu.edu:38418 (size: 113.9 KB, free: 365.8 MB); 2019-01-07 11:34:06 INFO TaskSetManager:54 - Starting task 3.0 in stage 0.0 (TID 2, scc-q21.scc.bu.edu, executor 1, partition 3, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:06 WARN TaskSetManager:66 - Lost task 1.0 in stage 0.0 (TID 1, scc-q21.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:24184,Integrability,Wrap,Wrappers,24184,"FO BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on scc-q12.scc.bu.edu:38418 (size: 25.4 KB, free: 365.9 MB); 2019-01-07 11:34:05 INFO BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on scc-q12.scc.bu.edu:38418 (size: 113.9 KB, free: 365.8 MB); 2019-01-07 11:34:06 INFO TaskSetManager:54 - Starting task 3.0 in stage 0.0 (TID 2, scc-q21.scc.bu.edu, executor 1, partition 3, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:06 WARN TaskSetManager:66 - Lost task 1.0 in stage 0.0 (TID 1, scc-q21.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:25885,Integrability,Wrap,Wrappers,25885,"); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-07 11:34:07 INFO TaskSetManager:54 - Starting task 1.1 in stage 0.0 (TID 3, scc-q21.scc.bu.edu, executor 1, partition 1, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:07 WARN TaskSetManager:66 - Lost task 3.0 in stage 0.0 (TID 2, scc-q21.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 1, start 4924320, span 190238, expected MD5 8a9ef2f91a78ffdc56561ece832e9f5d; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:25919,Integrability,Wrap,Wrappers,25919,"k.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-07 11:34:07 INFO TaskSetManager:54 - Starting task 1.1 in stage 0.0 (TID 3, scc-q21.scc.bu.edu, executor 1, partition 1, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:07 WARN TaskSetManager:66 - Lost task 3.0 in stage 0.0 (TID 2, scc-q21.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 1, start 4924320, span 190238, expected MD5 8a9ef2f91a78ffdc56561ece832e9f5d; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:28076,Integrability,Wrap,Wrappers,28076,"4:08 INFO TaskSetManager:54 - Lost task 1.1 in stage 0.0 (TID 3) on scc-q21.scc.bu.edu, executor 1: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae) [duplicate 1]; 2019-01-07 11:34:09 INFO TaskSetManager:54 - Starting task 9.0 in stage 0.0 (TID 5, scc-q12.scc.bu.edu, executor 2, partition 9, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:09 WARN TaskSetManager:66 - Lost task 2.0 in stage 0.0 (TID 0, scc-q12.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 160972515, span 170618, expected MD5 0cc5e1f5ec5c1b06d5a4bd5fff11b77f; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:28110,Integrability,Wrap,Wrappers,28110,"ger:54 - Lost task 1.1 in stage 0.0 (TID 3) on scc-q21.scc.bu.edu, executor 1: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae) [duplicate 1]; 2019-01-07 11:34:09 INFO TaskSetManager:54 - Starting task 9.0 in stage 0.0 (TID 5, scc-q12.scc.bu.edu, executor 2, partition 9, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:09 WARN TaskSetManager:66 - Lost task 2.0 in stage 0.0 (TID 0, scc-q12.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 160972515, span 170618, expected MD5 0cc5e1f5ec5c1b06d5a4bd5fff11b77f; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:30265,Integrability,Wrap,Wrappers,30265,":34:09 INFO TaskSetManager:54 - Lost task 3.1 in stage 0.0 (TID 4) on scc-q21.scc.bu.edu, executor 1: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 1, start 4924320, span 190238, expected MD5 8a9ef2f91a78ffdc56561ece832e9f5d) [duplicate 1]; 2019-01-07 11:34:10 INFO TaskSetManager:54 - Starting task 2.1 in stage 0.0 (TID 7, scc-q12.scc.bu.edu, executor 2, partition 2, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:10 WARN TaskSetManager:66 - Lost task 9.0 in stage 0.0 (TID 5, scc-q12.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 3, start 97885291, span 192458, expected MD5 ef90368731b6e0be845bc82cd92b0c6a; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:30299,Integrability,Wrap,Wrappers,30299,"nager:54 - Lost task 3.1 in stage 0.0 (TID 4) on scc-q21.scc.bu.edu, executor 1: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 1, start 4924320, span 190238, expected MD5 8a9ef2f91a78ffdc56561ece832e9f5d) [duplicate 1]; 2019-01-07 11:34:10 INFO TaskSetManager:54 - Starting task 2.1 in stage 0.0 (TID 7, scc-q12.scc.bu.edu, executor 2, partition 2, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:10 WARN TaskSetManager:66 - Lost task 9.0 in stage 0.0 (TID 5, scc-q12.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 3, start 97885291, span 192458, expected MD5 ef90368731b6e0be845bc82cd92b0c6a; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:34055,Integrability,Wrap,Wrappers,34055," 492a29f6d7d6fcaf8dde06834861e7ae) [duplicate 3]; 2019-01-07 11:34:12 ERROR TaskSetManager:70 - Task 1 in stage 0.0 failed 4 times; aborting job; 2019-01-07 11:34:12 INFO YarnScheduler:54 - Cancelling stage 0; 2019-01-07 11:34:12 INFO YarnScheduler:54 - Stage 0 was cancelled; 2019-01-07 11:34:12 INFO DAGScheduler:54 - ResultStage 0 (count at CountReadsSpark.java:80) failed in 9.293 s due to Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 9, scc-q21.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:34089,Integrability,Wrap,Wrappers,34089,"06834861e7ae) [duplicate 3]; 2019-01-07 11:34:12 ERROR TaskSetManager:70 - Task 1 in stage 0.0 failed 4 times; aborting job; 2019-01-07 11:34:12 INFO YarnScheduler:54 - Cancelling stage 0; 2019-01-07 11:34:12 INFO YarnScheduler:54 - Stage 0 was cancelled; 2019-01-07 11:34:12 INFO DAGScheduler:54 - ResultStage 0 (count at CountReadsSpark.java:80) failed in 9.293 s due to Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 9, scc-q21.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:37271,Integrability,Wrap,Wrappers,37271,"inatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-01-07 11:34:12 INFO SparkContext:54 - Successfully stopped SparkContext; 11:34:12.605 INFO CountReadsSpark - Shutting down engine; [January 7, 2019 11:34:12 AM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.80 minutes.; Runtime.totalMemory()=1003487232; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 9, scc-q21.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:37305,Integrability,Wrap,Wrappers,37305,"utputCommitCoordinator stopped!; 2019-01-07 11:34:12 INFO SparkContext:54 - Successfully stopped SparkContext; 11:34:12.605 INFO CountReadsSpark - Shutting down engine; [January 7, 2019 11:34:12 AM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.80 minutes.; Runtime.totalMemory()=1003487232; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 9, scc-q21.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:42166,Integrability,Wrap,Wrappers,42166,"ssorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:879); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:197); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:227); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:136); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:42200,Integrability,Wrap,Wrappers,42200," java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:879); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:197); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:227); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:136); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:1963,Modifiability,config,configuration,1963,ter yarn --conf spark.kryoserializer.buffer.max=512m --conf spark.driver.maxResultSize=0 --conf spark.driver.userClassPathFirst=false --conf spark.io.compression.codec=lzf --conf spark.yarn.executor.memoryOverhead=600 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar CountReadsSpark --input /project/casa/gcad/test/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --spark-master yarn; 2019-01-07 11:33:18 WARN SparkConf:66 - The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 2019-01-07 11:33:19 WARN NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 11:33:24.377 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 11:33:24.549 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar!/com/intel/gkl/native/libgkl_compression.so; 11:33:26.271 INFO CountReadsSpark - ------------------------------------------------------------; 11:33:26.272 INFO CountReadsSpark - The Genome Analysis Toolkit (GATK) v4.0.12.0; 11:33:26.272 INFO CountReadsSpark - For support and documentat,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:2355,Modifiability,variab,variables,2355,"tor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar CountReadsSpark --input /project/casa/gcad/test/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --spark-master yarn; 2019-01-07 11:33:18 WARN SparkConf:66 - The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 2019-01-07 11:33:19 WARN NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 11:33:24.377 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 11:33:24.549 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar!/com/intel/gkl/native/libgkl_compression.so; 11:33:26.271 INFO CountReadsSpark - ------------------------------------------------------------; 11:33:26.272 INFO CountReadsSpark - The Genome Analysis Toolkit (GATK) v4.0.12.0; 11:33:26.272 INFO CountReadsSpark - For support and documentation go to https://software.broadinstitute.org/gatk/; 11:33:26.272 INFO CountReadsSpark - Executing as farrell@scc-hadoop.bu.edu on Linux v2.6.32-754.6.3.el6.x86_64 amd64; 11:33:26.273 INFO CountReadsSpark - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_121-b13; 11:33:26.273 INFO CountReadsSpark - Start Date/Time: January 7, 2019 11:33:24 AM EST; 11:33:26.273 INFO CountReadsSpark - ------------------------------------------------------------; 11:33:26.273 IN",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:2481,Modifiability,config,configured,2481,"tor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar CountReadsSpark --input /project/casa/gcad/test/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --spark-master yarn; 2019-01-07 11:33:18 WARN SparkConf:66 - The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 2019-01-07 11:33:19 WARN NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 11:33:24.377 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 11:33:24.549 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar!/com/intel/gkl/native/libgkl_compression.so; 11:33:26.271 INFO CountReadsSpark - ------------------------------------------------------------; 11:33:26.272 INFO CountReadsSpark - The Genome Analysis Toolkit (GATK) v4.0.12.0; 11:33:26.272 INFO CountReadsSpark - For support and documentation go to https://software.broadinstitute.org/gatk/; 11:33:26.272 INFO CountReadsSpark - Executing as farrell@scc-hadoop.bu.edu on Linux v2.6.32-754.6.3.el6.x86_64 amd64; 11:33:26.273 INFO CountReadsSpark - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_121-b13; 11:33:26.273 INFO CountReadsSpark - Start Date/Time: January 7, 2019 11:33:24 AM EST; 11:33:26.273 INFO CountReadsSpark - ------------------------------------------------------------; 11:33:26.273 IN",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:4625,Modifiability,config,configuration,4625,- Picard Version: 2.18.16; 11:33:26.275 INFO CountReadsSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 11:33:26.275 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 11:33:26.275 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 11:33:26.276 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 11:33:26.276 INFO CountReadsSpark - Deflater: IntelDeflater; 11:33:26.276 INFO CountReadsSpark - Inflater: IntelInflater; 11:33:26.276 INFO CountReadsSpark - GCS max retries/reopens: 20; 11:33:26.276 INFO CountReadsSpark - Requester pays: disabled; 11:33:26.277 WARN CountReadsSpark -. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: CountReadsSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 11:33:26.277 INFO CountReadsSpark - Initializing engine; 11:33:26.277 INFO CountReadsSpark - Done initializing engine; 2019-01-07 11:33:26 WARN SparkConf:66 - The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 2019-01-07 11:33:26 INFO SparkContext:54 - Running Spark version 2.3.0; 2019-01-07 11:33:26 INFO SparkContext:54 - Submitted application: CountReadsSpark; 2019-01-07 11:33:26 INFO SecurityManager:54 - Changing view acls to: farrell; 2019-01-07 11:33:26 INFO SecurityManager:54 - Changing modify acls to: farrell; 2019-01-07 11:33:26 INFO SecurityManager:54 - Changing view acls groups to:; 2019-01-07 11:33:26 INFO SecurityManager:54 - Changing modify acls groups to:; 2019-01-07 11:33:26 INFO SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(farrell); groups with view permissions: Set(); users with modify permissions: Set(farrell); groups with modify permissions: Set(); 2019-01-07 11:33:27 INFO Utils:54 -,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:2210,Performance,load,load,2210,STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar CountReadsSpark --input /project/casa/gcad/test/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --spark-master yarn; 2019-01-07 11:33:18 WARN SparkConf:66 - The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 2019-01-07 11:33:19 WARN NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 11:33:24.377 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 11:33:24.549 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar!/com/intel/gkl/native/libgkl_compression.so; 11:33:26.271 INFO CountReadsSpark - ------------------------------------------------------------; 11:33:26.272 INFO CountReadsSpark - The Genome Analysis Toolkit (GATK) v4.0.12.0; 11:33:26.272 INFO CountReadsSpark - For support and documentation go to https://software.broadinstitute.org/gatk/; 11:33:26.272 INFO CountReadsSpark - Executing as farrell@scc-hadoop.bu.edu on Linux v2.6.32-754.6.3.el6.x86_64 amd64; 11:33:26.273 INFO CountReadsSpark - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:2542,Performance,Load,Loading,2542,"te_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar CountReadsSpark --input /project/casa/gcad/test/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --spark-master yarn; 2019-01-07 11:33:18 WARN SparkConf:66 - The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 2019-01-07 11:33:19 WARN NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 11:33:24.377 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 11:33:24.549 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar!/com/intel/gkl/native/libgkl_compression.so; 11:33:26.271 INFO CountReadsSpark - ------------------------------------------------------------; 11:33:26.272 INFO CountReadsSpark - The Genome Analysis Toolkit (GATK) v4.0.12.0; 11:33:26.272 INFO CountReadsSpark - For support and documentation go to https://software.broadinstitute.org/gatk/; 11:33:26.272 INFO CountReadsSpark - Executing as farrell@scc-hadoop.bu.edu on Linux v2.6.32-754.6.3.el6.x86_64 amd64; 11:33:26.273 INFO CountReadsSpark - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_121-b13; 11:33:26.273 INFO CountReadsSpark - Start Date/Time: January 7, 2019 11:33:24 AM EST; 11:33:26.273 INFO CountReadsSpark - ------------------------------------------------------------; 11:33:26.273 INFO CountReadsSpark - ------------------------------------------------------------; 11:33:26.275 INFO CountReadsSpark - HTSJDK Ve",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:10619,Performance,load,loaded,10619," 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3688baab{/,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4fe2dd02{/api,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@726a8729{/jobs/job/kill,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1a2724d3{/stages/stage/kill,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://scc-hadoop.bu.edu:4041; 2019-01-07 11:33:27 INFO SparkContext:54 - Added JAR file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar at spark://scc-hadoop.bu.edu:46828/jars/gatk-package-4.0.12.0-spark.jar with timestamp 1546878807984; 2019-01-07 11:33:28 INFO GoogleHadoopFileSystemBase:607 - GHFS version: 1.6.3-hadoop2; 2019-01-07 11:33:29 WARN DomainSocketFactory:117 - The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.; 2019-01-07 11:33:30 INFO Client:54 - Requesting a new application from cluster with 21 NodeManagers; 2019-01-07 11:33:30 INFO Client:54 - Verifying our application has not requested more than the maximum memory capability of the cluster (204800 MB per container); 2019-01-07 11:33:30 INFO Client:54 - Will allocate AM container, with 896 MB memory including 384 MB overhead; 2019-01-07 11:33:30 INFO Client:54 - Setting up container launch context for our AM; 2019-01-07 11:33:30 INFO Client:54 - Setting up the launch environment for our AM container; 2019-01-07 11:33:30 INFO Client:54 - Preparing resources for our AM container; 2019-01-07 11:33:30 INFO HadoopFSDelegationTokenProvider:54 - getting token for: DFS[DFSClient[clientName=DFSClient_NONMAPREDUCE_-1883879239_1, ugi=farrell@AD.BU.EDU (auth:KERBEROS)]]; 2019-01-07 11:33:30 INFO DFSClient:1023 - Created HDFS_DELEGATION_TOKEN token 11334 for farrell on ha-hdfs",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:13432,Performance,queue,queue,13432,"c/user/farrell/.sparkStaging/application_1542127286896_0153/__spark_libs__7473738539612638927.zip; 2019-01-07 11:33:38 INFO Client:54 - Uploading resource file:/tmp/spark-1ac79f09-1a36-4668-92d9-0739775f98ed/__spark_conf__4147634812449814799.zip -> hdfs://scc/user/farrell/.sparkStaging/application_1542127286896_0153/__spark_conf__.zip; 2019-01-07 11:33:38 INFO SecurityManager:54 - Changing view acls to: farrell; 2019-01-07 11:33:38 INFO SecurityManager:54 - Changing modify acls to: farrell; 2019-01-07 11:33:38 INFO SecurityManager:54 - Changing view acls groups to:; 2019-01-07 11:33:38 INFO SecurityManager:54 - Changing modify acls groups to:; 2019-01-07 11:33:38 INFO SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(farrell); groups with view permissions: Set(); users with modify permissions: Set(farrell); groups with modify permissions: Set(); 2019-01-07 11:33:38 INFO Client:54 - Submitting application application_1542127286896_0153 to ResourceManager; 2019-01-07 11:33:38 INFO YarnClientImpl:251 - Submitted application application_1542127286896_0153; 2019-01-07 11:33:38 INFO SchedulerExtensionServices:54 - Starting Yarn extension services with app application_1542127286896_0153 and attemptId None; 2019-01-07 11:33:39 INFO Client:54 - Application report for application_1542127286896_0153 (state: ACCEPTED); 2019-01-07 11:33:39 INFO Client:54 -; client token: Token { kind: YARN_CLIENT_TOKEN, service: }; diagnostics: N/A; ApplicationMaster host: N/A; ApplicationMaster RPC port: -1; queue: default; start time: 1546878818531; final status: UNDEFINED; tracking URL: https://scc-hsn1.scc.bu.edu:8090/proxy/application_1542127286896_0153/; user: farrell; 2019-01-07 11:33:40 INFO Client:54 - Application report for application_1542127286896_0153 (state: ACCEPTED); 2019-01-07 11:33:41 INFO Client:54 - Application report for application_1542127286896_0153 (state: ACCEPTED); 2019-01-07 11:33:42 INFO Client:54 - Applic",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:15896,Performance,queue,queue,15896,"1-07 11:33:52 INFO YarnClientSchedulerBackend:54 - Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> scc-hsn1.scc.bu.edu, PROXY_URI_BASES -> https://scc-hsn1.scc.bu.edu:8090/proxy/application_1542127286896_0153), /proxy/application_1542127286896_0153; 2019-01-07 11:33:52 INFO JettyUtils:54 - Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter; 2019-01-07 11:33:52 INFO Client:54 - Application report for application_1542127286896_0153 (state: ACCEPTED); 2019-01-07 11:33:53 INFO YarnSchedulerBackend$YarnSchedulerEndpoint:54 - ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM); 2019-01-07 11:33:53 INFO Client:54 - Application report for application_1542127286896_0153 (state: RUNNING); 2019-01-07 11:33:53 INFO Client:54 -; client token: Token { kind: YARN_CLIENT_TOKEN, service: }; diagnostics: N/A; ApplicationMaster host: 192.168.18.193; ApplicationMaster RPC port: 0; queue: default; start time: 1546878818531; final status: UNDEFINED; tracking URL: https://scc-hsn1.scc.bu.edu:8090/proxy/application_1542127286896_0153/; user: farrell; 2019-01-07 11:33:53 INFO YarnClientSchedulerBackend:54 - Application application_1542127286896_0153 has started running.; 2019-01-07 11:33:53 INFO Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45270.; 2019-01-07 11:33:53 INFO NettyBlockTransferService:54 - Server created on scc-hadoop.bu.edu:45270; 2019-01-07 11:33:53 INFO BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy; 2019-01-07 11:33:53 INFO BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, scc-hadoop.bu.edu, 45270, None); 2019-01-07 11:33:53 INFO BlockManagerMasterEndpoint:54 - Registering block manager scc-hadoop.bu.edu:45270 with 408.6 MB RAM, BlockManagerId(driver, scc-hadoop.bu.edu, 45270, None); 2019-01-07 11:33:53 INFO BlockManagerMaster:54 - Register",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:24988,Performance,concurren,concurrent,24988,"xt(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-07 11:34:07 INFO TaskSetManager:54 - Starting task 1.1 in stage 0.0 (TID 3, scc-q21.scc.bu.edu, executor 1, partition 1, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:07 WARN TaskSetManager:66 - Lost task 3.0 in stage 0.0 (TID 2, scc-q21.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 1, start 4924320, span 190238, expected MD5 8a9ef2f91a78ffdc56561ece832e9f5d; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:25072,Performance,concurren,concurrent,25072,"r.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-07 11:34:07 INFO TaskSetManager:54 - Starting task 1.1 in stage 0.0 (TID 3, scc-q21.scc.bu.edu, executor 1, partition 1, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:07 WARN TaskSetManager:66 - Lost task 3.0 in stage 0.0 (TID 2, scc-q21.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 1, start 4924320, span 190238, expected MD5 8a9ef2f91a78ffdc56561ece832e9f5d; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at sc",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:26723,Performance,concurren,concurrent,26723,"xt(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-07 11:34:08 INFO TaskSetManager:54 - Starting task 3.1 in stage 0.0 (TID 4, scc-q21.scc.bu.edu, executor 1, partition 3, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:08 INFO TaskSetManager:54 - Lost task 1.1 in stage 0.0 (TID 3) on scc-q21.scc.bu.edu, executor 1: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae) [duplicate 1]; 2019-01-07 11:34:09 INFO TaskSetManager:54 - Starting task 9.0 in stage 0.0 (TID 5, scc-q12.scc.bu.edu, executor 2, partition 9, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:09 WARN TaskSetManager:66 - Lost task 2.0 in stage 0.0 (TID 0, scc-q12.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:26807,Performance,concurren,concurrent,26807,"r.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-07 11:34:08 INFO TaskSetManager:54 - Starting task 3.1 in stage 0.0 (TID 4, scc-q21.scc.bu.edu, executor 1, partition 3, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:08 INFO TaskSetManager:54 - Lost task 1.1 in stage 0.0 (TID 3) on scc-q21.scc.bu.edu, executor 1: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae) [duplicate 1]; 2019-01-07 11:34:09 INFO TaskSetManager:54 - Starting task 9.0 in stage 0.0 (TID 5, scc-q12.scc.bu.edu, executor 2, partition 9, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:09 WARN TaskSetManager:66 - Lost task 2.0 in stage 0.0 (TID 0, scc-q12.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 160972515, span 170618, expected MD5 0cc5e1f5ec5c1b06d5a4bd5fff11b77f; a",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:28914,Performance,concurren,concurrent,28914,"xt(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-07 11:34:09 INFO TaskSetManager:54 - Starting task 1.2 in stage 0.0 (TID 6, scc-q21.scc.bu.edu, executor 1, partition 1, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:09 INFO TaskSetManager:54 - Lost task 3.1 in stage 0.0 (TID 4) on scc-q21.scc.bu.edu, executor 1: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 1, start 4924320, span 190238, expected MD5 8a9ef2f91a78ffdc56561ece832e9f5d) [duplicate 1]; 2019-01-07 11:34:10 INFO TaskSetManager:54 - Starting task 2.1 in stage 0.0 (TID 7, scc-q12.scc.bu.edu, executor 2, partition 2, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:10 WARN TaskSetManager:66 - Lost task 9.0 in stage 0.0 (TID 5, scc-q12.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence i",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:28998,Performance,concurren,concurrent,28998,"r.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-07 11:34:09 INFO TaskSetManager:54 - Starting task 1.2 in stage 0.0 (TID 6, scc-q21.scc.bu.edu, executor 1, partition 1, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:09 INFO TaskSetManager:54 - Lost task 3.1 in stage 0.0 (TID 4) on scc-q21.scc.bu.edu, executor 1: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 1, start 4924320, span 190238, expected MD5 8a9ef2f91a78ffdc56561ece832e9f5d) [duplicate 1]; 2019-01-07 11:34:10 INFO TaskSetManager:54 - Starting task 2.1 in stage 0.0 (TID 7, scc-q12.scc.bu.edu, executor 2, partition 2, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:10 WARN TaskSetManager:66 - Lost task 9.0 in stage 0.0 (TID 5, scc-q12.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 3, start 97885291, span 192458, expected MD5 ef90368731b6e0be845bc82cd92b0c6a; at ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:31103,Performance,concurren,concurrent,31103,"xt(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-07 11:34:10 INFO TaskSetManager:54 - Starting task 3.2 in stage 0.0 (TID 8, scc-q21.scc.bu.edu, executor 1, partition 3, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:10 INFO TaskSetManager:54 - Lost task 1.2 in stage 0.0 (TID 6) on scc-q21.scc.bu.edu, executor 1: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae) [duplicate 2]; 2019-01-07 11:34:11 INFO TaskSetManager:54 - Starting task 1.3 in stage 0.0 (TID 9, scc-q21.scc.bu.edu, executor 1, partition 1, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:11 INFO TaskSetManager:54 - Lost task 3.2 in stage 0.0 (TID 8) on scc-q21.scc.bu.edu, executor 1: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequenc",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:31187,Performance,concurren,concurrent,31187,"r.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-07 11:34:10 INFO TaskSetManager:54 - Starting task 3.2 in stage 0.0 (TID 8, scc-q21.scc.bu.edu, executor 1, partition 3, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:10 INFO TaskSetManager:54 - Lost task 1.2 in stage 0.0 (TID 6) on scc-q21.scc.bu.edu, executor 1: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae) [duplicate 2]; 2019-01-07 11:34:11 INFO TaskSetManager:54 - Starting task 1.3 in stage 0.0 (TID 9, scc-q21.scc.bu.edu, executor 1, partition 1, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:11 INFO TaskSetManager:54 - Lost task 3.2 in stage 0.0 (TID 8) on scc-q21.scc.bu.edu, executor 1: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 1, start 4924320, span 190238, expected MD5 8a9ef2f91a78ffdc56561ece832e9f5d) [",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:34893,Performance,concurren,concurrent,34893,"xt(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 2019-01-07 11:34:12 INFO DAGScheduler:54 - Job 0 failed: count at CountReadsSpark.java:80, took 9.419880 s; 2019-01-07 11:34:12 INFO AbstractConnector:318 - Stopped Spark@f1d88ea{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-07 11:34:12 INFO SparkUI:54 - Stopped Spark web UI at http://scc-hadoop.bu.edu:4041; 2019-01-07 11:34:12 INFO YarnClientSchedulerBackend:54 - Interrupting monitor thread; 2019-01-07 11:34:12 INFO YarnClientSchedulerBackend:54 - Shutting down all executors; 2019-01-07 11:34:12 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-01-07 11:34:12 INFO SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-01-07 11:34:12 INFO YarnClientSchedulerBackend:54",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:34977,Performance,concurren,concurrent,34977,"r.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 2019-01-07 11:34:12 INFO DAGScheduler:54 - Job 0 failed: count at CountReadsSpark.java:80, took 9.419880 s; 2019-01-07 11:34:12 INFO AbstractConnector:318 - Stopped Spark@f1d88ea{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-07 11:34:12 INFO SparkUI:54 - Stopped Spark web UI at http://scc-hadoop.bu.edu:4041; 2019-01-07 11:34:12 INFO YarnClientSchedulerBackend:54 - Interrupting monitor thread; 2019-01-07 11:34:12 INFO YarnClientSchedulerBackend:54 - Shutting down all executors; 2019-01-07 11:34:12 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-01-07 11:34:12 INFO SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-01-07 11:34:12 INFO YarnClientSchedulerBackend:54 - Stopped; 2019-01-07 11:34:12 INFO MapOutputTrackerMasterEndpoint:54 - MapOutputTr",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:38109,Performance,concurren,concurrent,38109,xt(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at scala.Opti,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:38193,Performance,concurren,concurrent,38193,r.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskS,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:43004,Performance,concurren,concurrent,43004,xt(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); 2019-01-07 11:34:12 INFO ShutdownHookManager:54 - Shutdown hook called; 2019-01-07 11:34:12 INFO ShutdownHookManager:54 - Deleting directory /tmp/spark-1ac79f09-1a36-4668-92d9-0739775f98ed; 2019-01-07 11:34:12 INFO ShutdownHookManager:54 - Deleting directory /tmp/spark-ed279998-3783-4f41-8fe5-f44a4fac3ee4; ```. CountReads runs fine..... ```; gatk CountReads --input HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa; Using GATK jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /share/pkg/gatk/4.0.12.0/ins,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:43088,Performance,concurren,concurrent,43088,r.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); 2019-01-07 11:34:12 INFO ShutdownHookManager:54 - Shutdown hook called; 2019-01-07 11:34:12 INFO ShutdownHookManager:54 - Deleting directory /tmp/spark-1ac79f09-1a36-4668-92d9-0739775f98ed; 2019-01-07 11:34:12 INFO ShutdownHookManager:54 - Deleting directory /tmp/spark-ed279998-3783-4f41-8fe5-f44a4fac3ee4; ```. CountReads runs fine..... ```; gatk CountReads --input HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa; Using GATK jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-local.jar CountReads --input HG04302.alt_bwamem_GRCh3,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:44263,Performance,Load,Loading,44263,"ook called; 2019-01-07 11:34:12 INFO ShutdownHookManager:54 - Deleting directory /tmp/spark-1ac79f09-1a36-4668-92d9-0739775f98ed; 2019-01-07 11:34:12 INFO ShutdownHookManager:54 - Deleting directory /tmp/spark-ed279998-3783-4f41-8fe5-f44a4fac3ee4; ```. CountReads runs fine..... ```; gatk CountReads --input HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa; Using GATK jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-local.jar CountReads --input HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa; 11:36:23.022 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 11:36:25.027 INFO CountReads - ------------------------------------------------------------; 11:36:25.028 INFO CountReads - The Genome Analysis Toolkit (GATK) v4.0.12.0; 11:36:25.028 INFO CountReads - For support and documentation go to https://software.broadinstitute.org/gatk/; 11:36:25.029 INFO CountReads - Executing as farrell@scc-hadoop.bu.edu on Linux v2.6.32-754.6.3.el6.x86_64 amd64; 11:36:25.029 INFO CountReads - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_121-b13; 11:36:25.030 INFO CountReads - Start Date/Time: January 7, 2019 11:36:22 AM EST; 11:36:25.030 INFO CountReads - ------------------------------------------------------------; 11:36:25.031 INFO CountReads - ------------------------------------------------------------; 11:36:25.032 INFO CountReads - HTSJDK Version: 2.18.1; 11:36:25.033 INFO CountReads -",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:33200,Safety,abort,aborting,33200,"u.edu, executor 2, partition 9, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:11 INFO TaskSetManager:54 - Lost task 2.1 in stage 0.0 (TID 7) on scc-q12.scc.bu.edu, executor 2: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 0, start 160972515, span 170618, expected MD5 0cc5e1f5ec5c1b06d5a4bd5fff11b77f) [duplicate 1]; 2019-01-07 11:34:12 INFO TaskSetManager:54 - Starting task 3.3 in stage 0.0 (TID 11, scc-q21.scc.bu.edu, executor 1, partition 3, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:12 INFO TaskSetManager:54 - Lost task 1.3 in stage 0.0 (TID 9) on scc-q21.scc.bu.edu, executor 1: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae) [duplicate 3]; 2019-01-07 11:34:12 ERROR TaskSetManager:70 - Task 1 in stage 0.0 failed 4 times; aborting job; 2019-01-07 11:34:12 INFO YarnScheduler:54 - Cancelling stage 0; 2019-01-07 11:34:12 INFO YarnScheduler:54 - Stage 0 was cancelled; 2019-01-07 11:34:12 INFO DAGScheduler:54 - ResultStage 0 (count at CountReadsSpark.java:80) failed in 9.293 s due to Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 9, scc-q21.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:4",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:33466,Safety,abort,aborted,33466,"dk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 0, start 160972515, span 170618, expected MD5 0cc5e1f5ec5c1b06d5a4bd5fff11b77f) [duplicate 1]; 2019-01-07 11:34:12 INFO TaskSetManager:54 - Starting task 3.3 in stage 0.0 (TID 11, scc-q21.scc.bu.edu, executor 1, partition 3, NODE_LOCAL, 7992 bytes); 2019-01-07 11:34:12 INFO TaskSetManager:54 - Lost task 1.3 in stage 0.0 (TID 9) on scc-q21.scc.bu.edu, executor 1: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae) [duplicate 3]; 2019-01-07 11:34:12 ERROR TaskSetManager:70 - Task 1 in stage 0.0 failed 4 times; aborting job; 2019-01-07 11:34:12 INFO YarnScheduler:54 - Cancelling stage 0; 2019-01-07 11:34:12 INFO YarnScheduler:54 - Stage 0 was cancelled; 2019-01-07 11:34:12 INFO DAGScheduler:54 - ResultStage 0 (count at CountReadsSpark.java:80) failed in 9.293 s due to Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 9, scc-q21.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:36682,Safety,abort,aborted,36682,"019-01-07 11:34:12 INFO SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-01-07 11:34:12 INFO YarnClientSchedulerBackend:54 - Stopped; 2019-01-07 11:34:12 INFO MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!; 2019-01-07 11:34:12 INFO MemoryStore:54 - MemoryStore cleared; 2019-01-07 11:34:12 INFO BlockManager:54 - BlockManager stopped; 2019-01-07 11:34:12 INFO BlockManagerMaster:54 - BlockManagerMaster stopped; 2019-01-07 11:34:12 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-01-07 11:34:12 INFO SparkContext:54 - Successfully stopped SparkContext; 11:34:12.605 INFO CountReadsSpark - Shutting down engine; [January 7, 2019 11:34:12 AM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.80 minutes.; Runtime.totalMemory()=1003487232; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 9, scc-q21.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfu",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:38516,Safety,abort,abortStage,38516,or.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:38613,Safety,abort,abortStage,38613,park.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.s,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:38855,Safety,abort,abortStage,38855,y(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2027); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2048); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067); at org,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:4995,Security,Secur,SecurityManager,4995,!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: CountReadsSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 11:33:26.277 INFO CountReadsSpark - Initializing engine; 11:33:26.277 INFO CountReadsSpark - Done initializing engine; 2019-01-07 11:33:26 WARN SparkConf:66 - The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 2019-01-07 11:33:26 INFO SparkContext:54 - Running Spark version 2.3.0; 2019-01-07 11:33:26 INFO SparkContext:54 - Submitted application: CountReadsSpark; 2019-01-07 11:33:26 INFO SecurityManager:54 - Changing view acls to: farrell; 2019-01-07 11:33:26 INFO SecurityManager:54 - Changing modify acls to: farrell; 2019-01-07 11:33:26 INFO SecurityManager:54 - Changing view acls groups to:; 2019-01-07 11:33:26 INFO SecurityManager:54 - Changing modify acls groups to:; 2019-01-07 11:33:26 INFO SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(farrell); groups with view permissions: Set(); users with modify permissions: Set(farrell); groups with modify permissions: Set(); 2019-01-07 11:33:27 INFO Utils:54 - Successfully started service 'sparkDriver' on port 46828.; 2019-01-07 11:33:27 INFO SparkEnv:54 - Registering MapOutputTracker; 2019-01-07 11:33:27 INFO SparkEnv:54 - Registering BlockManagerMaster; 2019-01-07 11:33:27 INFO BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 2019-01-07 11:33:27 INFO BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up; 2019-01-07 11:33:27 INFO DiskBlockManager:54 - Created local directory at /tmp/blockmgr-08460386-3abb-4431-ba8d-5b7d41a2a05c; 2019-01-07 11:33:27 INFO MemoryStore:54 - MemoryStore started with capacity 408.6 MB; 2019-01-07 11:33:27 INFO SparkEnv,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:5073,Security,Secur,SecurityManager,5073,!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: CountReadsSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 11:33:26.277 INFO CountReadsSpark - Initializing engine; 11:33:26.277 INFO CountReadsSpark - Done initializing engine; 2019-01-07 11:33:26 WARN SparkConf:66 - The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 2019-01-07 11:33:26 INFO SparkContext:54 - Running Spark version 2.3.0; 2019-01-07 11:33:26 INFO SparkContext:54 - Submitted application: CountReadsSpark; 2019-01-07 11:33:26 INFO SecurityManager:54 - Changing view acls to: farrell; 2019-01-07 11:33:26 INFO SecurityManager:54 - Changing modify acls to: farrell; 2019-01-07 11:33:26 INFO SecurityManager:54 - Changing view acls groups to:; 2019-01-07 11:33:26 INFO SecurityManager:54 - Changing modify acls groups to:; 2019-01-07 11:33:26 INFO SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(farrell); groups with view permissions: Set(); users with modify permissions: Set(farrell); groups with modify permissions: Set(); 2019-01-07 11:33:27 INFO Utils:54 - Successfully started service 'sparkDriver' on port 46828.; 2019-01-07 11:33:27 INFO SparkEnv:54 - Registering MapOutputTracker; 2019-01-07 11:33:27 INFO SparkEnv:54 - Registering BlockManagerMaster; 2019-01-07 11:33:27 INFO BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 2019-01-07 11:33:27 INFO BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up; 2019-01-07 11:33:27 INFO DiskBlockManager:54 - Created local directory at /tmp/blockmgr-08460386-3abb-4431-ba8d-5b7d41a2a05c; 2019-01-07 11:33:27 INFO MemoryStore:54 - MemoryStore started with capacity 408.6 MB; 2019-01-07 11:33:27 INFO SparkEnv,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:5153,Security,Secur,SecurityManager,5153,!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: CountReadsSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 11:33:26.277 INFO CountReadsSpark - Initializing engine; 11:33:26.277 INFO CountReadsSpark - Done initializing engine; 2019-01-07 11:33:26 WARN SparkConf:66 - The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 2019-01-07 11:33:26 INFO SparkContext:54 - Running Spark version 2.3.0; 2019-01-07 11:33:26 INFO SparkContext:54 - Submitted application: CountReadsSpark; 2019-01-07 11:33:26 INFO SecurityManager:54 - Changing view acls to: farrell; 2019-01-07 11:33:26 INFO SecurityManager:54 - Changing modify acls to: farrell; 2019-01-07 11:33:26 INFO SecurityManager:54 - Changing view acls groups to:; 2019-01-07 11:33:26 INFO SecurityManager:54 - Changing modify acls groups to:; 2019-01-07 11:33:26 INFO SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(farrell); groups with view permissions: Set(); users with modify permissions: Set(farrell); groups with modify permissions: Set(); 2019-01-07 11:33:27 INFO Utils:54 - Successfully started service 'sparkDriver' on port 46828.; 2019-01-07 11:33:27 INFO SparkEnv:54 - Registering MapOutputTracker; 2019-01-07 11:33:27 INFO SparkEnv:54 - Registering BlockManagerMaster; 2019-01-07 11:33:27 INFO BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 2019-01-07 11:33:27 INFO BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up; 2019-01-07 11:33:27 INFO DiskBlockManager:54 - Created local directory at /tmp/blockmgr-08460386-3abb-4431-ba8d-5b7d41a2a05c; 2019-01-07 11:33:27 INFO MemoryStore:54 - MemoryStore started with capacity 408.6 MB; 2019-01-07 11:33:27 INFO SparkEnv,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:5230,Security,Secur,SecurityManager,5230,!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: CountReadsSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 11:33:26.277 INFO CountReadsSpark - Initializing engine; 11:33:26.277 INFO CountReadsSpark - Done initializing engine; 2019-01-07 11:33:26 WARN SparkConf:66 - The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 2019-01-07 11:33:26 INFO SparkContext:54 - Running Spark version 2.3.0; 2019-01-07 11:33:26 INFO SparkContext:54 - Submitted application: CountReadsSpark; 2019-01-07 11:33:26 INFO SecurityManager:54 - Changing view acls to: farrell; 2019-01-07 11:33:26 INFO SecurityManager:54 - Changing modify acls to: farrell; 2019-01-07 11:33:26 INFO SecurityManager:54 - Changing view acls groups to:; 2019-01-07 11:33:26 INFO SecurityManager:54 - Changing modify acls groups to:; 2019-01-07 11:33:26 INFO SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(farrell); groups with view permissions: Set(); users with modify permissions: Set(farrell); groups with modify permissions: Set(); 2019-01-07 11:33:27 INFO Utils:54 - Successfully started service 'sparkDriver' on port 46828.; 2019-01-07 11:33:27 INFO SparkEnv:54 - Registering MapOutputTracker; 2019-01-07 11:33:27 INFO SparkEnv:54 - Registering BlockManagerMaster; 2019-01-07 11:33:27 INFO BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 2019-01-07 11:33:27 INFO BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up; 2019-01-07 11:33:27 INFO DiskBlockManager:54 - Created local directory at /tmp/blockmgr-08460386-3abb-4431-ba8d-5b7d41a2a05c; 2019-01-07 11:33:27 INFO MemoryStore:54 - MemoryStore started with capacity 408.6 MB; 2019-01-07 11:33:27 INFO SparkEnv,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:5309,Security,Secur,SecurityManager,5309,!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: CountReadsSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 11:33:26.277 INFO CountReadsSpark - Initializing engine; 11:33:26.277 INFO CountReadsSpark - Done initializing engine; 2019-01-07 11:33:26 WARN SparkConf:66 - The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 2019-01-07 11:33:26 INFO SparkContext:54 - Running Spark version 2.3.0; 2019-01-07 11:33:26 INFO SparkContext:54 - Submitted application: CountReadsSpark; 2019-01-07 11:33:26 INFO SecurityManager:54 - Changing view acls to: farrell; 2019-01-07 11:33:26 INFO SecurityManager:54 - Changing modify acls to: farrell; 2019-01-07 11:33:26 INFO SecurityManager:54 - Changing view acls groups to:; 2019-01-07 11:33:26 INFO SecurityManager:54 - Changing modify acls groups to:; 2019-01-07 11:33:26 INFO SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(farrell); groups with view permissions: Set(); users with modify permissions: Set(farrell); groups with modify permissions: Set(); 2019-01-07 11:33:27 INFO Utils:54 - Successfully started service 'sparkDriver' on port 46828.; 2019-01-07 11:33:27 INFO SparkEnv:54 - Registering MapOutputTracker; 2019-01-07 11:33:27 INFO SparkEnv:54 - Registering BlockManagerMaster; 2019-01-07 11:33:27 INFO BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 2019-01-07 11:33:27 INFO BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up; 2019-01-07 11:33:27 INFO DiskBlockManager:54 - Created local directory at /tmp/blockmgr-08460386-3abb-4431-ba8d-5b7d41a2a05c; 2019-01-07 11:33:27 INFO MemoryStore:54 - MemoryStore started with capacity 408.6 MB; 2019-01-07 11:33:27 INFO SparkEnv,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:5330,Security,Secur,SecurityManager,5330,!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: CountReadsSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 11:33:26.277 INFO CountReadsSpark - Initializing engine; 11:33:26.277 INFO CountReadsSpark - Done initializing engine; 2019-01-07 11:33:26 WARN SparkConf:66 - The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 2019-01-07 11:33:26 INFO SparkContext:54 - Running Spark version 2.3.0; 2019-01-07 11:33:26 INFO SparkContext:54 - Submitted application: CountReadsSpark; 2019-01-07 11:33:26 INFO SecurityManager:54 - Changing view acls to: farrell; 2019-01-07 11:33:26 INFO SecurityManager:54 - Changing modify acls to: farrell; 2019-01-07 11:33:26 INFO SecurityManager:54 - Changing view acls groups to:; 2019-01-07 11:33:26 INFO SecurityManager:54 - Changing modify acls groups to:; 2019-01-07 11:33:26 INFO SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(farrell); groups with view permissions: Set(); users with modify permissions: Set(farrell); groups with modify permissions: Set(); 2019-01-07 11:33:27 INFO Utils:54 - Successfully started service 'sparkDriver' on port 46828.; 2019-01-07 11:33:27 INFO SparkEnv:54 - Registering MapOutputTracker; 2019-01-07 11:33:27 INFO SparkEnv:54 - Registering BlockManagerMaster; 2019-01-07 11:33:27 INFO BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 2019-01-07 11:33:27 INFO BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up; 2019-01-07 11:33:27 INFO DiskBlockManager:54 - Created local directory at /tmp/blockmgr-08460386-3abb-4431-ba8d-5b7d41a2a05c; 2019-01-07 11:33:27 INFO MemoryStore:54 - MemoryStore started with capacity 408.6 MB; 2019-01-07 11:33:27 INFO SparkEnv,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:5347,Security,authenticat,authentication,5347,!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: CountReadsSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 11:33:26.277 INFO CountReadsSpark - Initializing engine; 11:33:26.277 INFO CountReadsSpark - Done initializing engine; 2019-01-07 11:33:26 WARN SparkConf:66 - The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 2019-01-07 11:33:26 INFO SparkContext:54 - Running Spark version 2.3.0; 2019-01-07 11:33:26 INFO SparkContext:54 - Submitted application: CountReadsSpark; 2019-01-07 11:33:26 INFO SecurityManager:54 - Changing view acls to: farrell; 2019-01-07 11:33:26 INFO SecurityManager:54 - Changing modify acls to: farrell; 2019-01-07 11:33:26 INFO SecurityManager:54 - Changing view acls groups to:; 2019-01-07 11:33:26 INFO SecurityManager:54 - Changing modify acls groups to:; 2019-01-07 11:33:26 INFO SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(farrell); groups with view permissions: Set(); users with modify permissions: Set(farrell); groups with modify permissions: Set(); 2019-01-07 11:33:27 INFO Utils:54 - Successfully started service 'sparkDriver' on port 46828.; 2019-01-07 11:33:27 INFO SparkEnv:54 - Registering MapOutputTracker; 2019-01-07 11:33:27 INFO SparkEnv:54 - Registering BlockManagerMaster; 2019-01-07 11:33:27 INFO BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 2019-01-07 11:33:27 INFO BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up; 2019-01-07 11:33:27 INFO DiskBlockManager:54 - Created local directory at /tmp/blockmgr-08460386-3abb-4431-ba8d-5b7d41a2a05c; 2019-01-07 11:33:27 INFO MemoryStore:54 - MemoryStore started with capacity 408.6 MB; 2019-01-07 11:33:27 INFO SparkEnv,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:12226,Security,Secur,SecurityManager,12226,"c/user/farrell/.sparkStaging/application_1542127286896_0153/__spark_libs__7473738539612638927.zip; 2019-01-07 11:33:38 INFO Client:54 - Uploading resource file:/tmp/spark-1ac79f09-1a36-4668-92d9-0739775f98ed/__spark_conf__4147634812449814799.zip -> hdfs://scc/user/farrell/.sparkStaging/application_1542127286896_0153/__spark_conf__.zip; 2019-01-07 11:33:38 INFO SecurityManager:54 - Changing view acls to: farrell; 2019-01-07 11:33:38 INFO SecurityManager:54 - Changing modify acls to: farrell; 2019-01-07 11:33:38 INFO SecurityManager:54 - Changing view acls groups to:; 2019-01-07 11:33:38 INFO SecurityManager:54 - Changing modify acls groups to:; 2019-01-07 11:33:38 INFO SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(farrell); groups with view permissions: Set(); users with modify permissions: Set(farrell); groups with modify permissions: Set(); 2019-01-07 11:33:38 INFO Client:54 - Submitting application application_1542127286896_0153 to ResourceManager; 2019-01-07 11:33:38 INFO YarnClientImpl:251 - Submitted application application_1542127286896_0153; 2019-01-07 11:33:38 INFO SchedulerExtensionServices:54 - Starting Yarn extension services with app application_1542127286896_0153 and attemptId None; 2019-01-07 11:33:39 INFO Client:54 - Application report for application_1542127286896_0153 (state: ACCEPTED); 2019-01-07 11:33:39 INFO Client:54 -; client token: Token { kind: YARN_CLIENT_TOKEN, service: }; diagnostics: N/A; ApplicationMaster host: N/A; ApplicationMaster RPC port: -1; queue: default; start time: 1546878818531; final status: UNDEFINED; tracking URL: https://scc-hsn1.scc.bu.edu:8090/proxy/application_1542127286896_0153/; user: farrell; 2019-01-07 11:33:40 INFO Client:54 - Application report for application_1542127286896_0153 (state: ACCEPTED); 2019-01-07 11:33:41 INFO Client:54 - Application report for application_1542127286896_0153 (state: ACCEPTED); 2019-01-07 11:33:42 INFO Client:54 - Applic",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:12304,Security,Secur,SecurityManager,12304,"c/user/farrell/.sparkStaging/application_1542127286896_0153/__spark_libs__7473738539612638927.zip; 2019-01-07 11:33:38 INFO Client:54 - Uploading resource file:/tmp/spark-1ac79f09-1a36-4668-92d9-0739775f98ed/__spark_conf__4147634812449814799.zip -> hdfs://scc/user/farrell/.sparkStaging/application_1542127286896_0153/__spark_conf__.zip; 2019-01-07 11:33:38 INFO SecurityManager:54 - Changing view acls to: farrell; 2019-01-07 11:33:38 INFO SecurityManager:54 - Changing modify acls to: farrell; 2019-01-07 11:33:38 INFO SecurityManager:54 - Changing view acls groups to:; 2019-01-07 11:33:38 INFO SecurityManager:54 - Changing modify acls groups to:; 2019-01-07 11:33:38 INFO SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(farrell); groups with view permissions: Set(); users with modify permissions: Set(farrell); groups with modify permissions: Set(); 2019-01-07 11:33:38 INFO Client:54 - Submitting application application_1542127286896_0153 to ResourceManager; 2019-01-07 11:33:38 INFO YarnClientImpl:251 - Submitted application application_1542127286896_0153; 2019-01-07 11:33:38 INFO SchedulerExtensionServices:54 - Starting Yarn extension services with app application_1542127286896_0153 and attemptId None; 2019-01-07 11:33:39 INFO Client:54 - Application report for application_1542127286896_0153 (state: ACCEPTED); 2019-01-07 11:33:39 INFO Client:54 -; client token: Token { kind: YARN_CLIENT_TOKEN, service: }; diagnostics: N/A; ApplicationMaster host: N/A; ApplicationMaster RPC port: -1; queue: default; start time: 1546878818531; final status: UNDEFINED; tracking URL: https://scc-hsn1.scc.bu.edu:8090/proxy/application_1542127286896_0153/; user: farrell; 2019-01-07 11:33:40 INFO Client:54 - Application report for application_1542127286896_0153 (state: ACCEPTED); 2019-01-07 11:33:41 INFO Client:54 - Application report for application_1542127286896_0153 (state: ACCEPTED); 2019-01-07 11:33:42 INFO Client:54 - Applic",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:12384,Security,Secur,SecurityManager,12384,"c/user/farrell/.sparkStaging/application_1542127286896_0153/__spark_libs__7473738539612638927.zip; 2019-01-07 11:33:38 INFO Client:54 - Uploading resource file:/tmp/spark-1ac79f09-1a36-4668-92d9-0739775f98ed/__spark_conf__4147634812449814799.zip -> hdfs://scc/user/farrell/.sparkStaging/application_1542127286896_0153/__spark_conf__.zip; 2019-01-07 11:33:38 INFO SecurityManager:54 - Changing view acls to: farrell; 2019-01-07 11:33:38 INFO SecurityManager:54 - Changing modify acls to: farrell; 2019-01-07 11:33:38 INFO SecurityManager:54 - Changing view acls groups to:; 2019-01-07 11:33:38 INFO SecurityManager:54 - Changing modify acls groups to:; 2019-01-07 11:33:38 INFO SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(farrell); groups with view permissions: Set(); users with modify permissions: Set(farrell); groups with modify permissions: Set(); 2019-01-07 11:33:38 INFO Client:54 - Submitting application application_1542127286896_0153 to ResourceManager; 2019-01-07 11:33:38 INFO YarnClientImpl:251 - Submitted application application_1542127286896_0153; 2019-01-07 11:33:38 INFO SchedulerExtensionServices:54 - Starting Yarn extension services with app application_1542127286896_0153 and attemptId None; 2019-01-07 11:33:39 INFO Client:54 - Application report for application_1542127286896_0153 (state: ACCEPTED); 2019-01-07 11:33:39 INFO Client:54 -; client token: Token { kind: YARN_CLIENT_TOKEN, service: }; diagnostics: N/A; ApplicationMaster host: N/A; ApplicationMaster RPC port: -1; queue: default; start time: 1546878818531; final status: UNDEFINED; tracking URL: https://scc-hsn1.scc.bu.edu:8090/proxy/application_1542127286896_0153/; user: farrell; 2019-01-07 11:33:40 INFO Client:54 - Application report for application_1542127286896_0153 (state: ACCEPTED); 2019-01-07 11:33:41 INFO Client:54 - Application report for application_1542127286896_0153 (state: ACCEPTED); 2019-01-07 11:33:42 INFO Client:54 - Applic",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:12461,Security,Secur,SecurityManager,12461,"c/user/farrell/.sparkStaging/application_1542127286896_0153/__spark_libs__7473738539612638927.zip; 2019-01-07 11:33:38 INFO Client:54 - Uploading resource file:/tmp/spark-1ac79f09-1a36-4668-92d9-0739775f98ed/__spark_conf__4147634812449814799.zip -> hdfs://scc/user/farrell/.sparkStaging/application_1542127286896_0153/__spark_conf__.zip; 2019-01-07 11:33:38 INFO SecurityManager:54 - Changing view acls to: farrell; 2019-01-07 11:33:38 INFO SecurityManager:54 - Changing modify acls to: farrell; 2019-01-07 11:33:38 INFO SecurityManager:54 - Changing view acls groups to:; 2019-01-07 11:33:38 INFO SecurityManager:54 - Changing modify acls groups to:; 2019-01-07 11:33:38 INFO SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(farrell); groups with view permissions: Set(); users with modify permissions: Set(farrell); groups with modify permissions: Set(); 2019-01-07 11:33:38 INFO Client:54 - Submitting application application_1542127286896_0153 to ResourceManager; 2019-01-07 11:33:38 INFO YarnClientImpl:251 - Submitted application application_1542127286896_0153; 2019-01-07 11:33:38 INFO SchedulerExtensionServices:54 - Starting Yarn extension services with app application_1542127286896_0153 and attemptId None; 2019-01-07 11:33:39 INFO Client:54 - Application report for application_1542127286896_0153 (state: ACCEPTED); 2019-01-07 11:33:39 INFO Client:54 -; client token: Token { kind: YARN_CLIENT_TOKEN, service: }; diagnostics: N/A; ApplicationMaster host: N/A; ApplicationMaster RPC port: -1; queue: default; start time: 1546878818531; final status: UNDEFINED; tracking URL: https://scc-hsn1.scc.bu.edu:8090/proxy/application_1542127286896_0153/; user: farrell; 2019-01-07 11:33:40 INFO Client:54 - Application report for application_1542127286896_0153 (state: ACCEPTED); 2019-01-07 11:33:41 INFO Client:54 - Application report for application_1542127286896_0153 (state: ACCEPTED); 2019-01-07 11:33:42 INFO Client:54 - Applic",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:12540,Security,Secur,SecurityManager,12540,"c/user/farrell/.sparkStaging/application_1542127286896_0153/__spark_libs__7473738539612638927.zip; 2019-01-07 11:33:38 INFO Client:54 - Uploading resource file:/tmp/spark-1ac79f09-1a36-4668-92d9-0739775f98ed/__spark_conf__4147634812449814799.zip -> hdfs://scc/user/farrell/.sparkStaging/application_1542127286896_0153/__spark_conf__.zip; 2019-01-07 11:33:38 INFO SecurityManager:54 - Changing view acls to: farrell; 2019-01-07 11:33:38 INFO SecurityManager:54 - Changing modify acls to: farrell; 2019-01-07 11:33:38 INFO SecurityManager:54 - Changing view acls groups to:; 2019-01-07 11:33:38 INFO SecurityManager:54 - Changing modify acls groups to:; 2019-01-07 11:33:38 INFO SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(farrell); groups with view permissions: Set(); users with modify permissions: Set(farrell); groups with modify permissions: Set(); 2019-01-07 11:33:38 INFO Client:54 - Submitting application application_1542127286896_0153 to ResourceManager; 2019-01-07 11:33:38 INFO YarnClientImpl:251 - Submitted application application_1542127286896_0153; 2019-01-07 11:33:38 INFO SchedulerExtensionServices:54 - Starting Yarn extension services with app application_1542127286896_0153 and attemptId None; 2019-01-07 11:33:39 INFO Client:54 - Application report for application_1542127286896_0153 (state: ACCEPTED); 2019-01-07 11:33:39 INFO Client:54 -; client token: Token { kind: YARN_CLIENT_TOKEN, service: }; diagnostics: N/A; ApplicationMaster host: N/A; ApplicationMaster RPC port: -1; queue: default; start time: 1546878818531; final status: UNDEFINED; tracking URL: https://scc-hsn1.scc.bu.edu:8090/proxy/application_1542127286896_0153/; user: farrell; 2019-01-07 11:33:40 INFO Client:54 - Application report for application_1542127286896_0153 (state: ACCEPTED); 2019-01-07 11:33:41 INFO Client:54 - Application report for application_1542127286896_0153 (state: ACCEPTED); 2019-01-07 11:33:42 INFO Client:54 - Applic",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:12561,Security,Secur,SecurityManager,12561,"c/user/farrell/.sparkStaging/application_1542127286896_0153/__spark_libs__7473738539612638927.zip; 2019-01-07 11:33:38 INFO Client:54 - Uploading resource file:/tmp/spark-1ac79f09-1a36-4668-92d9-0739775f98ed/__spark_conf__4147634812449814799.zip -> hdfs://scc/user/farrell/.sparkStaging/application_1542127286896_0153/__spark_conf__.zip; 2019-01-07 11:33:38 INFO SecurityManager:54 - Changing view acls to: farrell; 2019-01-07 11:33:38 INFO SecurityManager:54 - Changing modify acls to: farrell; 2019-01-07 11:33:38 INFO SecurityManager:54 - Changing view acls groups to:; 2019-01-07 11:33:38 INFO SecurityManager:54 - Changing modify acls groups to:; 2019-01-07 11:33:38 INFO SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(farrell); groups with view permissions: Set(); users with modify permissions: Set(farrell); groups with modify permissions: Set(); 2019-01-07 11:33:38 INFO Client:54 - Submitting application application_1542127286896_0153 to ResourceManager; 2019-01-07 11:33:38 INFO YarnClientImpl:251 - Submitted application application_1542127286896_0153; 2019-01-07 11:33:38 INFO SchedulerExtensionServices:54 - Starting Yarn extension services with app application_1542127286896_0153 and attemptId None; 2019-01-07 11:33:39 INFO Client:54 - Application report for application_1542127286896_0153 (state: ACCEPTED); 2019-01-07 11:33:39 INFO Client:54 -; client token: Token { kind: YARN_CLIENT_TOKEN, service: }; diagnostics: N/A; ApplicationMaster host: N/A; ApplicationMaster RPC port: -1; queue: default; start time: 1546878818531; final status: UNDEFINED; tracking URL: https://scc-hsn1.scc.bu.edu:8090/proxy/application_1542127286896_0153/; user: farrell; 2019-01-07 11:33:40 INFO Client:54 - Application report for application_1542127286896_0153 (state: ACCEPTED); 2019-01-07 11:33:41 INFO Client:54 - Application report for application_1542127286896_0153 (state: ACCEPTED); 2019-01-07 11:33:42 INFO Client:54 - Applic",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:12578,Security,authenticat,authentication,12578,"c/user/farrell/.sparkStaging/application_1542127286896_0153/__spark_libs__7473738539612638927.zip; 2019-01-07 11:33:38 INFO Client:54 - Uploading resource file:/tmp/spark-1ac79f09-1a36-4668-92d9-0739775f98ed/__spark_conf__4147634812449814799.zip -> hdfs://scc/user/farrell/.sparkStaging/application_1542127286896_0153/__spark_conf__.zip; 2019-01-07 11:33:38 INFO SecurityManager:54 - Changing view acls to: farrell; 2019-01-07 11:33:38 INFO SecurityManager:54 - Changing modify acls to: farrell; 2019-01-07 11:33:38 INFO SecurityManager:54 - Changing view acls groups to:; 2019-01-07 11:33:38 INFO SecurityManager:54 - Changing modify acls groups to:; 2019-01-07 11:33:38 INFO SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(farrell); groups with view permissions: Set(); users with modify permissions: Set(farrell); groups with modify permissions: Set(); 2019-01-07 11:33:38 INFO Client:54 - Submitting application application_1542127286896_0153 to ResourceManager; 2019-01-07 11:33:38 INFO YarnClientImpl:251 - Submitted application application_1542127286896_0153; 2019-01-07 11:33:38 INFO SchedulerExtensionServices:54 - Starting Yarn extension services with app application_1542127286896_0153 and attemptId None; 2019-01-07 11:33:39 INFO Client:54 - Application report for application_1542127286896_0153 (state: ACCEPTED); 2019-01-07 11:33:39 INFO Client:54 -; client token: Token { kind: YARN_CLIENT_TOKEN, service: }; diagnostics: N/A; ApplicationMaster host: N/A; ApplicationMaster RPC port: -1; queue: default; start time: 1546878818531; final status: UNDEFINED; tracking URL: https://scc-hsn1.scc.bu.edu:8090/proxy/application_1542127286896_0153/; user: farrell; 2019-01-07 11:33:40 INFO Client:54 - Application report for application_1542127286896_0153 (state: ACCEPTED); 2019-01-07 11:33:41 INFO Client:54 - Application report for application_1542127286896_0153 (state: ACCEPTED); 2019-01-07 11:33:42 INFO Client:54 - Applic",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:78,Testability,test,test,78,@tomwhite . I found this 1000 genomes cram that also generates the error. The test cram above would take a lot of paper work to make available. ```; wget ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/1000_genomes_project/data/GBR/HG04302/alignment/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram; wget ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/1000_genomes_project/data/GBR/HG04302/alignment/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram.crai. ```. Here is the error with this cram.... ```; gatk CountReadsSpark --input /project/casa/gcad/test/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -- --spark-runner SPARK --spark-master yarn; Using GATK jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar; Running:; /share/pkg/spark/2.3.0/install/bin/spark-submit --master yarn --conf spark.kryoserializer.buffer.max=512m --conf spark.driver.maxResultSize=0 --conf spark.driver.userClassPathFirst=false --conf spark.io.compression.codec=lzf --conf spark.yarn.executor.memoryOverhead=600 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar CountReadsSpark --input /project/casa/gcad/test/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --spark-master yarn; 2019-01-07 11:33:18 WARN SparkConf:66 - The configuration key 'spark.yarn.executor,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:591,Testability,test,test,591,@tomwhite . I found this 1000 genomes cram that also generates the error. The test cram above would take a lot of paper work to make available. ```; wget ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/1000_genomes_project/data/GBR/HG04302/alignment/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram; wget ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/1000_genomes_project/data/GBR/HG04302/alignment/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram.crai. ```. Here is the error with this cram.... ```; gatk CountReadsSpark --input /project/casa/gcad/test/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -- --spark-runner SPARK --spark-master yarn; Using GATK jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar; Running:; /share/pkg/spark/2.3.0/install/bin/spark-submit --master yarn --conf spark.kryoserializer.buffer.max=512m --conf spark.driver.maxResultSize=0 --conf spark.driver.userClassPathFirst=false --conf spark.io.compression.codec=lzf --conf spark.yarn.executor.memoryOverhead=600 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar CountReadsSpark --input /project/casa/gcad/test/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --spark-master yarn; 2019-01-07 11:33:18 WARN SparkConf:66 - The configuration key 'spark.yarn.executor,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:1741,Testability,test,test,1741,s_set_plus_decoy_hla.fa -- --spark-runner SPARK --spark-master yarn; Using GATK jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar; Running:; /share/pkg/spark/2.3.0/install/bin/spark-submit --master yarn --conf spark.kryoserializer.buffer.max=512m --conf spark.driver.maxResultSize=0 --conf spark.driver.userClassPathFirst=false --conf spark.io.compression.codec=lzf --conf spark.yarn.executor.memoryOverhead=600 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar CountReadsSpark --input /project/casa/gcad/test/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --spark-master yarn; 2019-01-07 11:33:18 WARN SparkConf:66 - The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 2019-01-07 11:33:19 WARN NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 11:33:24.377 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 11:33:24.549 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar!/com/intel/gkl/native/libgkl_compression.so; 11:33:26.271 INFO CountR,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:6334,Testability,log,log,6334,"r:54 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(farrell); groups with view permissions: Set(); users with modify permissions: Set(farrell); groups with modify permissions: Set(); 2019-01-07 11:33:27 INFO Utils:54 - Successfully started service 'sparkDriver' on port 46828.; 2019-01-07 11:33:27 INFO SparkEnv:54 - Registering MapOutputTracker; 2019-01-07 11:33:27 INFO SparkEnv:54 - Registering BlockManagerMaster; 2019-01-07 11:33:27 INFO BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 2019-01-07 11:33:27 INFO BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up; 2019-01-07 11:33:27 INFO DiskBlockManager:54 - Created local directory at /tmp/blockmgr-08460386-3abb-4431-ba8d-5b7d41a2a05c; 2019-01-07 11:33:27 INFO MemoryStore:54 - MemoryStore started with capacity 408.6 MB; 2019-01-07 11:33:27 INFO SparkEnv:54 - Registering OutputCommitCoordinator; 2019-01-07 11:33:27 INFO log:192 - Logging initialized @10679ms; 2019-01-07 11:33:27 INFO Server:346 - jetty-9.3.z-SNAPSHOT; 2019-01-07 11:33:27 INFO Server:414 - Started @10862ms; 2019-01-07 11:33:27 WARN Utils:66 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.; 2019-01-07 11:33:27 INFO AbstractConnector:278 - Started ServerConnector@f1d88ea{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-07 11:33:27 INFO Utils:54 - Successfully started service 'SparkUI' on port 4041.; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5a39e554{/jobs,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@67941d{/jobs/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2ad2b274{/jobs/job,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7114e780{/jobs/job/json,null,AVAILABLE,@Spark}; 2019-01-07 11",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:6344,Testability,Log,Logging,6344,"r:54 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(farrell); groups with view permissions: Set(); users with modify permissions: Set(farrell); groups with modify permissions: Set(); 2019-01-07 11:33:27 INFO Utils:54 - Successfully started service 'sparkDriver' on port 46828.; 2019-01-07 11:33:27 INFO SparkEnv:54 - Registering MapOutputTracker; 2019-01-07 11:33:27 INFO SparkEnv:54 - Registering BlockManagerMaster; 2019-01-07 11:33:27 INFO BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 2019-01-07 11:33:27 INFO BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up; 2019-01-07 11:33:27 INFO DiskBlockManager:54 - Created local directory at /tmp/blockmgr-08460386-3abb-4431-ba8d-5b7d41a2a05c; 2019-01-07 11:33:27 INFO MemoryStore:54 - MemoryStore started with capacity 408.6 MB; 2019-01-07 11:33:27 INFO SparkEnv:54 - Registering OutputCommitCoordinator; 2019-01-07 11:33:27 INFO log:192 - Logging initialized @10679ms; 2019-01-07 11:33:27 INFO Server:346 - jetty-9.3.z-SNAPSHOT; 2019-01-07 11:33:27 INFO Server:414 - Started @10862ms; 2019-01-07 11:33:27 WARN Utils:66 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.; 2019-01-07 11:33:27 INFO AbstractConnector:278 - Started ServerConnector@f1d88ea{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-07 11:33:27 INFO Utils:54 - Successfully started service 'SparkUI' on port 4041.; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5a39e554{/jobs,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@67941d{/jobs/json,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2ad2b274{/jobs/job,null,AVAILABLE,@Spark}; 2019-01-07 11:33:27 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7114e780{/jobs/job/json,null,AVAILABLE,@Spark}; 2019-01-07 11",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969:36067,Usability,clear,cleared,36067,"ecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 2019-01-07 11:34:12 INFO DAGScheduler:54 - Job 0 failed: count at CountReadsSpark.java:80, took 9.419880 s; 2019-01-07 11:34:12 INFO AbstractConnector:318 - Stopped Spark@f1d88ea{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-07 11:34:12 INFO SparkUI:54 - Stopped Spark web UI at http://scc-hadoop.bu.edu:4041; 2019-01-07 11:34:12 INFO YarnClientSchedulerBackend:54 - Interrupting monitor thread; 2019-01-07 11:34:12 INFO YarnClientSchedulerBackend:54 - Shutting down all executors; 2019-01-07 11:34:12 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-01-07 11:34:12 INFO SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-01-07 11:34:12 INFO YarnClientSchedulerBackend:54 - Stopped; 2019-01-07 11:34:12 INFO MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!; 2019-01-07 11:34:12 INFO MemoryStore:54 - MemoryStore cleared; 2019-01-07 11:34:12 INFO BlockManager:54 - BlockManager stopped; 2019-01-07 11:34:12 INFO BlockManagerMaster:54 - BlockManagerMaster stopped; 2019-01-07 11:34:12 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-01-07 11:34:12 INFO SparkContext:54 - Successfully stopped SparkContext; 11:34:12.605 INFO CountReadsSpark - Shutting down engine; [January 7, 2019 11:34:12 AM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.80 minutes.; Runtime.totalMemory()=1003487232; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 9, scc-q21.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: s",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-451999969
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452676624:43,Availability,down,down,43,"@jjfarrell @cmnbroad I tracked the problem down to htsjdk, see https://github.com/samtools/htsjdk/pull/1255. What seems to be happening is that `SeekableStream#available()` is returning a negative value due to int overflow, which `ReadableByteChannelImpl` is relying on to fill its byte buffer (from `AbstractIndexedFastaSequenceFile#getSubsequenceAt`). When it gets a negative value it returns early, without filling the buffer. The end result is that the reference is not read correctly, hence the MD5 mismatch errors. The reason we haven't seen this before is that we've only tested on CRAMs with FASTA files that are less than 2GB (ones that don't cover the whole genome, or ones that are gzipped). When the file is less than 2GB there's no int overflow, so we don't see the error.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452676624
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452676624:160,Availability,avail,available,160,"@jjfarrell @cmnbroad I tracked the problem down to htsjdk, see https://github.com/samtools/htsjdk/pull/1255. What seems to be happening is that `SeekableStream#available()` is returning a negative value due to int overflow, which `ReadableByteChannelImpl` is relying on to fill its byte buffer (from `AbstractIndexedFastaSequenceFile#getSubsequenceAt`). When it gets a negative value it returns early, without filling the buffer. The end result is that the reference is not read correctly, hence the MD5 mismatch errors. The reason we haven't seen this before is that we've only tested on CRAMs with FASTA files that are less than 2GB (ones that don't cover the whole genome, or ones that are gzipped). When the file is less than 2GB there's no int overflow, so we don't see the error.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452676624
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452676624:513,Availability,error,errors,513,"@jjfarrell @cmnbroad I tracked the problem down to htsjdk, see https://github.com/samtools/htsjdk/pull/1255. What seems to be happening is that `SeekableStream#available()` is returning a negative value due to int overflow, which `ReadableByteChannelImpl` is relying on to fill its byte buffer (from `AbstractIndexedFastaSequenceFile#getSubsequenceAt`). When it gets a negative value it returns early, without filling the buffer. The end result is that the reference is not read correctly, hence the MD5 mismatch errors. The reason we haven't seen this before is that we've only tested on CRAMs with FASTA files that are less than 2GB (ones that don't cover the whole genome, or ones that are gzipped). When the file is less than 2GB there's no int overflow, so we don't see the error.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452676624
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452676624:779,Availability,error,error,779,"@jjfarrell @cmnbroad I tracked the problem down to htsjdk, see https://github.com/samtools/htsjdk/pull/1255. What seems to be happening is that `SeekableStream#available()` is returning a negative value due to int overflow, which `ReadableByteChannelImpl` is relying on to fill its byte buffer (from `AbstractIndexedFastaSequenceFile#getSubsequenceAt`). When it gets a negative value it returns early, without filling the buffer. The end result is that the reference is not read correctly, hence the MD5 mismatch errors. The reason we haven't seen this before is that we've only tested on CRAMs with FASTA files that are less than 2GB (ones that don't cover the whole genome, or ones that are gzipped). When the file is less than 2GB there's no int overflow, so we don't see the error.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452676624
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452676624:579,Testability,test,tested,579,"@jjfarrell @cmnbroad I tracked the problem down to htsjdk, see https://github.com/samtools/htsjdk/pull/1255. What seems to be happening is that `SeekableStream#available()` is returning a negative value due to int overflow, which `ReadableByteChannelImpl` is relying on to fill its byte buffer (from `AbstractIndexedFastaSequenceFile#getSubsequenceAt`). When it gets a negative value it returns early, without filling the buffer. The end result is that the reference is not read correctly, hence the MD5 mismatch errors. The reason we haven't seen this before is that we've only tested on CRAMs with FASTA files that are less than 2GB (ones that don't cover the whole genome, or ones that are gzipped). When the file is less than 2GB there's no int overflow, so we don't see the error.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452676624
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:108,Availability,error,error,108,"@tomwhite . I tried rerunning the job using a bgzip reference to work around the problem. However, the same error is being generated (htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice). . ```; gatk CountReadsSpark --input /project/casa/gcad/test/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/wgs.hg38/pipelines/hc/cram.test/GRCh38_full_analysis_set_plus_decoy_hla.fa.gz -- --spark-runner SPARK --spark-master yarn. Using GATK jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar; Running:; /share/pkg/spark/2.3.0/install/bin/spark-submit --master yarn --conf spark.kryoserializer.buffer.max=512m --conf spark.driver.maxResultSize=0 --conf spark.driver.userClassPathFirst=false --conf spark.io.compression.codec=lzf --conf spark.yarn.executor.memoryOverhead=600 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar CountReadsSpark --input /project/casa/gcad/test/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/wgs.hg38/pipelines/hc/cram.test/GRCh38_full_analysis_set_plus_decoy_hla.fa.gz --spark-master yarn; 2019-01-09 13:35:04 WARN SparkConf:66 - The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 2019-01-09 13:35:05 WARN NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... usi",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:6645,Availability,AVAIL,AVAILABLE,6645,"formation; 2019-01-09 13:35:12 INFO BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up; 2019-01-09 13:35:12 INFO DiskBlockManager:54 - Created local directory at /tmp/blockmgr-dd94d6fb-7e3d-4def-a895-6e60f05d7a05; 2019-01-09 13:35:12 INFO MemoryStore:54 - MemoryStore started with capacity 372.6 MB; 2019-01-09 13:35:12 INFO SparkEnv:54 - Registering OutputCommitCoordinator; 2019-01-09 13:35:12 INFO log:192 - Logging initialized @9845ms; 2019-01-09 13:35:12 INFO Server:346 - jetty-9.3.z-SNAPSHOT; 2019-01-09 13:35:12 INFO Server:414 - Started @9981ms; 2019-01-09 13:35:12 WARN Utils:66 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.; 2019-01-09 13:35:12 INFO AbstractConnector:278 - Started ServerConnector@22fda322{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-09 13:35:12 INFO Utils:54 - Successfully started service 'SparkUI' on port 4041.; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@44084713{/jobs,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@43c0c13a{/jobs/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@731db93f{/jobs/job,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2ad2b274{/jobs/job/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6fde6f05{/stages,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7114e780{/stages/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4def42c3{/stages/stage,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@38d525aa{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f9b81",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:6773,Availability,AVAIL,AVAILABLE,6773,"skBlockManager:54 - Created local directory at /tmp/blockmgr-dd94d6fb-7e3d-4def-a895-6e60f05d7a05; 2019-01-09 13:35:12 INFO MemoryStore:54 - MemoryStore started with capacity 372.6 MB; 2019-01-09 13:35:12 INFO SparkEnv:54 - Registering OutputCommitCoordinator; 2019-01-09 13:35:12 INFO log:192 - Logging initialized @9845ms; 2019-01-09 13:35:12 INFO Server:346 - jetty-9.3.z-SNAPSHOT; 2019-01-09 13:35:12 INFO Server:414 - Started @9981ms; 2019-01-09 13:35:12 WARN Utils:66 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.; 2019-01-09 13:35:12 INFO AbstractConnector:278 - Started ServerConnector@22fda322{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-09 13:35:12 INFO Utils:54 - Successfully started service 'SparkUI' on port 4041.; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@44084713{/jobs,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@43c0c13a{/jobs/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@731db93f{/jobs/job,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2ad2b274{/jobs/job/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6fde6f05{/stages,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7114e780{/stages/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4def42c3{/stages/stage,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@38d525aa{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f9b8129{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:6900,Availability,AVAIL,AVAILABLE,6900,"oryStore:54 - MemoryStore started with capacity 372.6 MB; 2019-01-09 13:35:12 INFO SparkEnv:54 - Registering OutputCommitCoordinator; 2019-01-09 13:35:12 INFO log:192 - Logging initialized @9845ms; 2019-01-09 13:35:12 INFO Server:346 - jetty-9.3.z-SNAPSHOT; 2019-01-09 13:35:12 INFO Server:414 - Started @9981ms; 2019-01-09 13:35:12 WARN Utils:66 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.; 2019-01-09 13:35:12 INFO AbstractConnector:278 - Started ServerConnector@22fda322{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-09 13:35:12 INFO Utils:54 - Successfully started service 'SparkUI' on port 4041.; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@44084713{/jobs,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@43c0c13a{/jobs/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@731db93f{/jobs/job,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2ad2b274{/jobs/job/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6fde6f05{/stages,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7114e780{/stages/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4def42c3{/stages/stage,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@38d525aa{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f9b8129{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7530090a{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHa",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:7032,Availability,AVAIL,AVAILABLE,7032,"or; 2019-01-09 13:35:12 INFO log:192 - Logging initialized @9845ms; 2019-01-09 13:35:12 INFO Server:346 - jetty-9.3.z-SNAPSHOT; 2019-01-09 13:35:12 INFO Server:414 - Started @9981ms; 2019-01-09 13:35:12 WARN Utils:66 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.; 2019-01-09 13:35:12 INFO AbstractConnector:278 - Started ServerConnector@22fda322{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-09 13:35:12 INFO Utils:54 - Successfully started service 'SparkUI' on port 4041.; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@44084713{/jobs,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@43c0c13a{/jobs/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@731db93f{/jobs/job,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2ad2b274{/jobs/job/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6fde6f05{/stages,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7114e780{/stages/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4def42c3{/stages/stage,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@38d525aa{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f9b8129{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7530090a{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4492b393{/storage,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandl",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:7157,Availability,AVAIL,AVAILABLE,7157,"2019-01-09 13:35:12 INFO Server:414 - Started @9981ms; 2019-01-09 13:35:12 WARN Utils:66 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.; 2019-01-09 13:35:12 INFO AbstractConnector:278 - Started ServerConnector@22fda322{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-09 13:35:12 INFO Utils:54 - Successfully started service 'SparkUI' on port 4041.; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@44084713{/jobs,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@43c0c13a{/jobs/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@731db93f{/jobs/job,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2ad2b274{/jobs/job/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6fde6f05{/stages,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7114e780{/stages/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4def42c3{/stages/stage,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@38d525aa{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f9b8129{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7530090a{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4492b393{/storage,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@55fb36de{/storage/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHan",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:7287,Availability,AVAIL,AVAILABLE,7287,"ort 4040. Attempting port 4041.; 2019-01-09 13:35:12 INFO AbstractConnector:278 - Started ServerConnector@22fda322{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-09 13:35:12 INFO Utils:54 - Successfully started service 'SparkUI' on port 4041.; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@44084713{/jobs,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@43c0c13a{/jobs/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@731db93f{/jobs/job,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2ad2b274{/jobs/job/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6fde6f05{/stages,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7114e780{/stages/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4def42c3{/stages/stage,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@38d525aa{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f9b8129{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7530090a{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4492b393{/storage,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@55fb36de{/storage/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@63a7781{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextH",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:7418,Availability,AVAIL,AVAILABLE,7418,"1.1]}{0.0.0.0:4041}; 2019-01-09 13:35:12 INFO Utils:54 - Successfully started service 'SparkUI' on port 4041.; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@44084713{/jobs,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@43c0c13a{/jobs/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@731db93f{/jobs/job,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2ad2b274{/jobs/job/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6fde6f05{/stages,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7114e780{/stages/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4def42c3{/stages/stage,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@38d525aa{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f9b8129{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7530090a{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4492b393{/storage,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@55fb36de{/storage/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@63a7781{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@73b74615{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletCont",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:7554,Availability,AVAIL,AVAILABLE,7554,"O ContextHandler:781 - Started o.s.j.s.ServletContextHandler@44084713{/jobs,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@43c0c13a{/jobs/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@731db93f{/jobs/job,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2ad2b274{/jobs/job/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6fde6f05{/stages,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7114e780{/stages/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4def42c3{/stages/stage,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@38d525aa{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f9b8129{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7530090a{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4492b393{/storage,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@55fb36de{/storage/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@63a7781{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@73b74615{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@22686ddb{/environment,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContext",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:7683,Availability,AVAIL,AVAILABLE,7683,"Handler:781 - Started o.s.j.s.ServletContextHandler@43c0c13a{/jobs/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@731db93f{/jobs/job,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2ad2b274{/jobs/job/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6fde6f05{/stages,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7114e780{/stages/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4def42c3{/stages/stage,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@38d525aa{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f9b8129{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7530090a{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4492b393{/storage,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@55fb36de{/storage/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@63a7781{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@73b74615{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@22686ddb{/environment,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2e29f28e{/environment/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletConte",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:7818,Availability,AVAIL,AVAILABLE,7818,"ler:781 - Started o.s.j.s.ServletContextHandler@731db93f{/jobs/job,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2ad2b274{/jobs/job/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6fde6f05{/stages,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7114e780{/stages/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4def42c3{/stages/stage,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@38d525aa{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f9b8129{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7530090a{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4492b393{/storage,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@55fb36de{/storage/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@63a7781{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@73b74615{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@22686ddb{/environment,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2e29f28e{/environment/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bfa1eb5{/executors,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHa",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:7944,Availability,AVAIL,AVAILABLE,7944,"781 - Started o.s.j.s.ServletContextHandler@2ad2b274{/jobs/job/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6fde6f05{/stages,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7114e780{/stages/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4def42c3{/stages/stage,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@38d525aa{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f9b8129{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7530090a{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4492b393{/storage,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@55fb36de{/storage/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@63a7781{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@73b74615{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@22686ddb{/environment,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2e29f28e{/environment/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bfa1eb5{/executors,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32b46831{/executors/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContex",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:8075,Availability,AVAIL,AVAILABLE,8075,"ler:781 - Started o.s.j.s.ServletContextHandler@6fde6f05{/stages,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7114e780{/stages/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4def42c3{/stages/stage,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@38d525aa{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f9b8129{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7530090a{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4492b393{/storage,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@55fb36de{/storage/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@63a7781{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@73b74615{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@22686ddb{/environment,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2e29f28e{/environment/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bfa1eb5{/executors,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32b46831{/executors/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5353dd09{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.Ser",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:8204,Availability,AVAIL,AVAILABLE,8204,"81 - Started o.s.j.s.ServletContextHandler@7114e780{/stages/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4def42c3{/stages/stage,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@38d525aa{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f9b8129{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7530090a{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4492b393{/storage,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@55fb36de{/storage/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@63a7781{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@73b74615{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@22686ddb{/environment,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2e29f28e{/environment/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bfa1eb5{/executors,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32b46831{/executors/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5353dd09{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@320ff86f{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Start",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:8339,Availability,AVAIL,AVAILABLE,8339," - Started o.s.j.s.ServletContextHandler@4def42c3{/stages/stage,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@38d525aa{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f9b8129{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7530090a{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4492b393{/storage,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@55fb36de{/storage/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@63a7781{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@73b74615{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@22686ddb{/environment,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2e29f28e{/environment/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bfa1eb5{/executors,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32b46831{/executors/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5353dd09{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@320ff86f{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@192b472d{/static,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:8469,Availability,AVAIL,AVAILABLE,8469," Started o.s.j.s.ServletContextHandler@38d525aa{/stages/stage/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f9b8129{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7530090a{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4492b393{/storage,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@55fb36de{/storage/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@63a7781{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@73b74615{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@22686ddb{/environment,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2e29f28e{/environment/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bfa1eb5{/executors,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32b46831{/executors/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5353dd09{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@320ff86f{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@192b472d{/static,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@16b64a03{/,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletCo",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:8604,Availability,AVAIL,AVAILABLE,8604,"81 - Started o.s.j.s.ServletContextHandler@f9b8129{/stages/pool,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7530090a{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4492b393{/storage,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@55fb36de{/storage/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@63a7781{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@73b74615{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@22686ddb{/environment,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2e29f28e{/environment/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bfa1eb5{/executors,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32b46831{/executors/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5353dd09{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@320ff86f{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@192b472d{/static,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@16b64a03{/,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1584c019{/api,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandle",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:8732,Availability,AVAIL,AVAILABLE,8732,"- Started o.s.j.s.ServletContextHandler@7530090a{/stages/pool/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4492b393{/storage,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@55fb36de{/storage/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@63a7781{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@73b74615{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@22686ddb{/environment,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2e29f28e{/environment/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bfa1eb5{/executors,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32b46831{/executors/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5353dd09{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@320ff86f{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@192b472d{/static,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@16b64a03{/,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1584c019{/api,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5817f1ca{/jobs/job/kill,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandl",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:8865,Availability,AVAIL,AVAILABLE,8865,":781 - Started o.s.j.s.ServletContextHandler@4492b393{/storage,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@55fb36de{/storage/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@63a7781{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@73b74615{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@22686ddb{/environment,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2e29f28e{/environment/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bfa1eb5{/executors,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32b46831{/executors/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5353dd09{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@320ff86f{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@192b472d{/static,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@16b64a03{/,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1584c019{/api,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5817f1ca{/jobs/job/kill,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2b395581{/stages/stage/kill,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO SparkUI:54 - Bound SparkUI to 0.0.0.0, and started ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:9004,Availability,AVAIL,AVAILABLE,9004,"rted o.s.j.s.ServletContextHandler@55fb36de{/storage/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@63a7781{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@73b74615{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@22686ddb{/environment,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2e29f28e{/environment/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bfa1eb5{/executors,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32b46831{/executors/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5353dd09{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@320ff86f{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@192b472d{/static,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@16b64a03{/,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1584c019{/api,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5817f1ca{/jobs/job/kill,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2b395581{/stages/stage/kill,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://scc-hadoop.bu.edu:4041; 2019-01-09 13:35:12 INFO SparkContext:54 - Added JAR file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-pa",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:9148,Availability,AVAIL,AVAILABLE,9148,"s.ServletContextHandler@63a7781{/storage/rdd,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@73b74615{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@22686ddb{/environment,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2e29f28e{/environment/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bfa1eb5{/executors,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32b46831{/executors/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5353dd09{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@320ff86f{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@192b472d{/static,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@16b64a03{/,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1584c019{/api,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5817f1ca{/jobs/job/kill,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2b395581{/stages/stage/kill,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://scc-hadoop.bu.edu:4041; 2019-01-09 13:35:12 INFO SparkContext:54 - Added JAR file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar at spark://scc-hadoop.bu.edu:42689/jars/gatk-package-4.0.12.0-spark.jar with timestamp 1547058912934; 2019-01-09 13:",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:9273,Availability,AVAIL,AVAILABLE,9273,"vletContextHandler@73b74615{/storage/rdd/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@22686ddb{/environment,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2e29f28e{/environment/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bfa1eb5{/executors,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32b46831{/executors/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5353dd09{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@320ff86f{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@192b472d{/static,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@16b64a03{/,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1584c019{/api,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5817f1ca{/jobs/job/kill,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2b395581{/stages/stage/kill,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://scc-hadoop.bu.edu:4041; 2019-01-09 13:35:12 INFO SparkContext:54 - Added JAR file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar at spark://scc-hadoop.bu.edu:42689/jars/gatk-package-4.0.12.0-spark.jar with timestamp 1547058912934; 2019-01-09 13:35:13 INFO GoogleHadoopFileSystemBase:607 - GHFS version: 1.6.3-hadoop2; 2019-01-09 13:35:13 WARN DomainSocketFactory:117 - The short-c",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:9392,Availability,AVAIL,AVAILABLE,9392,"d o.s.j.s.ServletContextHandler@22686ddb{/environment,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2e29f28e{/environment/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bfa1eb5{/executors,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32b46831{/executors/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5353dd09{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@320ff86f{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@192b472d{/static,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@16b64a03{/,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1584c019{/api,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5817f1ca{/jobs/job/kill,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2b395581{/stages/stage/kill,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://scc-hadoop.bu.edu:4041; 2019-01-09 13:35:12 INFO SparkContext:54 - Added JAR file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar at spark://scc-hadoop.bu.edu:42689/jars/gatk-package-4.0.12.0-spark.jar with timestamp 1547058912934; 2019-01-09 13:35:13 INFO GoogleHadoopFileSystemBase:607 - GHFS version: 1.6.3-hadoop2; 2019-01-09 13:35:13 WARN DomainSocketFactory:117 - The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.; 2019-01-09 13:35:14 INFO Client:54 - Reques",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:9514,Availability,AVAIL,AVAILABLE,9514," - Started o.s.j.s.ServletContextHandler@2e29f28e{/environment/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7bfa1eb5{/executors,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32b46831{/executors/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5353dd09{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@320ff86f{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@192b472d{/static,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@16b64a03{/,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1584c019{/api,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5817f1ca{/jobs/job/kill,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2b395581{/stages/stage/kill,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://scc-hadoop.bu.edu:4041; 2019-01-09 13:35:12 INFO SparkContext:54 - Added JAR file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar at spark://scc-hadoop.bu.edu:42689/jars/gatk-package-4.0.12.0-spark.jar with timestamp 1547058912934; 2019-01-09 13:35:13 INFO GoogleHadoopFileSystemBase:607 - GHFS version: 1.6.3-hadoop2; 2019-01-09 13:35:13 WARN DomainSocketFactory:117 - The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.; 2019-01-09 13:35:14 INFO Client:54 - Requesting a new application from cluster with 21 NodeManagers; 2019-01-09 13:35:14 INFO Client:54 - Verifying our application",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:9646,Availability,AVAIL,AVAILABLE,9646,"dler:781 - Started o.s.j.s.ServletContextHandler@7bfa1eb5{/executors,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32b46831{/executors/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5353dd09{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@320ff86f{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@192b472d{/static,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@16b64a03{/,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1584c019{/api,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5817f1ca{/jobs/job/kill,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2b395581{/stages/stage/kill,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://scc-hadoop.bu.edu:4041; 2019-01-09 13:35:12 INFO SparkContext:54 - Added JAR file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar at spark://scc-hadoop.bu.edu:42689/jars/gatk-package-4.0.12.0-spark.jar with timestamp 1547058912934; 2019-01-09 13:35:13 INFO GoogleHadoopFileSystemBase:607 - GHFS version: 1.6.3-hadoop2; 2019-01-09 13:35:13 WARN DomainSocketFactory:117 - The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.; 2019-01-09 13:35:14 INFO Client:54 - Requesting a new application from cluster with 21 NodeManagers; 2019-01-09 13:35:14 INFO Client:54 - Verifying our application has not requested more than the maximum memory capability of the cluster (204800 MB per container); 2019-01-09 13:35:14 INFO C",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:9782,Availability,AVAIL,AVAILABLE,9782,"81 - Started o.s.j.s.ServletContextHandler@32b46831{/executors/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5353dd09{/executors/threadDump,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@320ff86f{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@192b472d{/static,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@16b64a03{/,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1584c019{/api,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5817f1ca{/jobs/job/kill,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2b395581{/stages/stage/kill,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://scc-hadoop.bu.edu:4041; 2019-01-09 13:35:12 INFO SparkContext:54 - Added JAR file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar at spark://scc-hadoop.bu.edu:42689/jars/gatk-package-4.0.12.0-spark.jar with timestamp 1547058912934; 2019-01-09 13:35:13 INFO GoogleHadoopFileSystemBase:607 - GHFS version: 1.6.3-hadoop2; 2019-01-09 13:35:13 WARN DomainSocketFactory:117 - The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.; 2019-01-09 13:35:14 INFO Client:54 - Requesting a new application from cluster with 21 NodeManagers; 2019-01-09 13:35:14 INFO Client:54 - Verifying our application has not requested more than the maximum memory capability of the cluster (204800 MB per container); 2019-01-09 13:35:14 INFO Client:54 - Will allocate AM container, with 896 MB memory including 384 MB overhead; 2019-01-09 13:35:14 INFO Client:54 - Setting up co",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:16536,Availability,AVAIL,AVAILABLE,16536,"ockTransferService' on port 43627.; 2019-01-09 13:35:33 INFO NettyBlockTransferService:54 - Server created on scc-hadoop.bu.edu:43627; 2019-01-09 13:35:33 INFO BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy; 2019-01-09 13:35:33 INFO BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, scc-hadoop.bu.edu, 43627, None); 2019-01-09 13:35:33 INFO BlockManagerMasterEndpoint:54 - Registering block manager scc-hadoop.bu.edu:43627 with 372.6 MB RAM, BlockManagerId(driver, scc-hadoop.bu.edu, 43627, None); 2019-01-09 13:35:33 INFO BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, scc-hadoop.bu.edu, 43627, None); 2019-01-09 13:35:33 INFO BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, scc-hadoop.bu.edu, 43627, None); 2019-01-09 13:35:34 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@53f94afe{/metrics/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:37 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.18.204:36598) with ID 2; 2019-01-09 13:35:37 INFO BlockManagerMasterEndpoint:54 - Registering block manager scc-q20.scc.bu.edu:42946 with 366.3 MB RAM, BlockManagerId(2, scc-q20.scc.bu.edu, 42946, None); 2019-01-09 13:35:39 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.18.185:34050) with ID 1; 2019-01-09 13:35:39 INFO BlockManagerMasterEndpoint:54 - Registering block manager scc-q01.scc.bu.edu:41129 with 366.3 MB RAM, BlockManagerId(1, scc-q01.scc.bu.edu, 41129, None); 2019-01-09 13:35:39 INFO YarnClientSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8; 2019-01-09 13:35:41 INFO MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 1229.0 KB, free 371.4 MB); 2019-01-09 13:35:42 INFO MemoryStore:54 - Block broadc",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:32886,Availability,ERROR,ERROR,32886,"equence MD5 mismatch for slice: sequence id 2, start 131325815, span 181534, expected MD5 c240a972d49aa89fb57dae94d1d90d36) [duplicate 1]; 2019-01-09 13:35:54 INFO TaskSetManager:54 - Starting task 1.3 in stage 0.0 (TID 11, scc-q20.scc.bu.edu, executor 2, partition 1, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:54 INFO TaskSetManager:54 - Lost task 4.2 in stage 0.0 (TID 9) on scc-q20.scc.bu.edu, executor 2: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 1, start 93925364, span 266689, expected MD5 54babf05a23e9e88a8738dfbb20a1683) [duplicate 2]; 2019-01-09 13:35:56 INFO TaskSetManager:54 - Starting task 4.3 in stage 0.0 (TID 12, scc-q20.scc.bu.edu, executor 2, partition 4, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:56 INFO TaskSetManager:54 - Lost task 1.3 in stage 0.0 (TID 11) on scc-q20.scc.bu.edu, executor 2: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae) [duplicate 3]; 2019-01-09 13:35:56 ERROR TaskSetManager:70 - Task 1 in stage 0.0 failed 4 times; aborting job; 2019-01-09 13:35:56 INFO YarnScheduler:54 - Cancelling stage 0; 2019-01-09 13:35:56 INFO YarnScheduler:54 - Stage 0 was cancelled; 2019-01-09 13:35:56 INFO DAGScheduler:54 - ResultStage 0 (count at CountReadsSpark.java:80) failed in 12.543 s due to Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 11, scc-q20.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JI",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:33236,Availability,failure,failure,33236,"k.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 1, start 93925364, span 266689, expected MD5 54babf05a23e9e88a8738dfbb20a1683) [duplicate 2]; 2019-01-09 13:35:56 INFO TaskSetManager:54 - Starting task 4.3 in stage 0.0 (TID 12, scc-q20.scc.bu.edu, executor 2, partition 4, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:56 INFO TaskSetManager:54 - Lost task 1.3 in stage 0.0 (TID 11) on scc-q20.scc.bu.edu, executor 2: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae) [duplicate 3]; 2019-01-09 13:35:56 ERROR TaskSetManager:70 - Task 1 in stage 0.0 failed 4 times; aborting job; 2019-01-09 13:35:56 INFO YarnScheduler:54 - Cancelling stage 0; 2019-01-09 13:35:56 INFO YarnScheduler:54 - Stage 0 was cancelled; 2019-01-09 13:35:56 INFO DAGScheduler:54 - ResultStage 0 (count at CountReadsSpark.java:80) failed in 12.543 s due to Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 11, scc-q20.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:33293,Availability,failure,failure,33293,"atch for slice: sequence id 1, start 93925364, span 266689, expected MD5 54babf05a23e9e88a8738dfbb20a1683) [duplicate 2]; 2019-01-09 13:35:56 INFO TaskSetManager:54 - Starting task 4.3 in stage 0.0 (TID 12, scc-q20.scc.bu.edu, executor 2, partition 4, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:56 INFO TaskSetManager:54 - Lost task 1.3 in stage 0.0 (TID 11) on scc-q20.scc.bu.edu, executor 2: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae) [duplicate 3]; 2019-01-09 13:35:56 ERROR TaskSetManager:70 - Task 1 in stage 0.0 failed 4 times; aborting job; 2019-01-09 13:35:56 INFO YarnScheduler:54 - Cancelling stage 0; 2019-01-09 13:35:56 INFO YarnScheduler:54 - Stage 0 was cancelled; 2019-01-09 13:35:56 INFO DAGScheduler:54 - ResultStage 0 (count at CountReadsSpark.java:80) failed in 12.543 s due to Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 11, scc-q20.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkC",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:35322,Availability,down,down,35322,"utor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 2019-01-09 13:35:56 INFO DAGScheduler:54 - Job 0 failed: count at CountReadsSpark.java:80, took 12.691336 s; 2019-01-09 13:35:56 INFO AbstractConnector:318 - Stopped Spark@22fda322{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-09 13:35:56 INFO SparkUI:54 - Stopped Spark web UI at http://scc-hadoop.bu.edu:4041; 2019-01-09 13:35:56 INFO YarnClientSchedulerBackend:54 - Interrupting monitor thread; 2019-01-09 13:35:56 INFO YarnClientSchedulerBackend:54 - Shutting down all executors; 2019-01-09 13:35:56 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-01-09 13:35:56 INFO SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-01-09 13:35:56 INFO YarnClientSchedulerBackend:54 - Stopped; 2019-01-09 13:35:56 INFO MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!; 2019-01-09 13:35:56 INFO MemoryStore:54 - MemoryStore cleared; 2019-01-09 13:35:56 INFO BlockManager:54 - BlockManager stopped; 2019-01-09 13:35:56 INFO BlockManagerMaster:54 - BlockManagerMaster stopped; 2019-01-09 13:35:56 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-01-09 13:35:56 INFO SparkContext:54 - Successfully stopped SparkContext; 13:35:56.383 INFO CountReadsSpark - Shutting down engine; [January 9, 2019 1:35:56 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.78 minutes.; Runtime.totalMemory()=1009254400; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 11, scc-q20.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: s",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:35441,Availability,down,down,35441,"utor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 2019-01-09 13:35:56 INFO DAGScheduler:54 - Job 0 failed: count at CountReadsSpark.java:80, took 12.691336 s; 2019-01-09 13:35:56 INFO AbstractConnector:318 - Stopped Spark@22fda322{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-09 13:35:56 INFO SparkUI:54 - Stopped Spark web UI at http://scc-hadoop.bu.edu:4041; 2019-01-09 13:35:56 INFO YarnClientSchedulerBackend:54 - Interrupting monitor thread; 2019-01-09 13:35:56 INFO YarnClientSchedulerBackend:54 - Shutting down all executors; 2019-01-09 13:35:56 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-01-09 13:35:56 INFO SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-01-09 13:35:56 INFO YarnClientSchedulerBackend:54 - Stopped; 2019-01-09 13:35:56 INFO MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!; 2019-01-09 13:35:56 INFO MemoryStore:54 - MemoryStore cleared; 2019-01-09 13:35:56 INFO BlockManager:54 - BlockManager stopped; 2019-01-09 13:35:56 INFO BlockManagerMaster:54 - BlockManagerMaster stopped; 2019-01-09 13:35:56 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-01-09 13:35:56 INFO SparkContext:54 - Successfully stopped SparkContext; 13:35:56.383 INFO CountReadsSpark - Shutting down engine; [January 9, 2019 1:35:56 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.78 minutes.; Runtime.totalMemory()=1009254400; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 11, scc-q20.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: s",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:36213,Availability,down,down,36213,"d:54 - Interrupting monitor thread; 2019-01-09 13:35:56 INFO YarnClientSchedulerBackend:54 - Shutting down all executors; 2019-01-09 13:35:56 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-01-09 13:35:56 INFO SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-01-09 13:35:56 INFO YarnClientSchedulerBackend:54 - Stopped; 2019-01-09 13:35:56 INFO MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!; 2019-01-09 13:35:56 INFO MemoryStore:54 - MemoryStore cleared; 2019-01-09 13:35:56 INFO BlockManager:54 - BlockManager stopped; 2019-01-09 13:35:56 INFO BlockManagerMaster:54 - BlockManagerMaster stopped; 2019-01-09 13:35:56 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-01-09 13:35:56 INFO SparkContext:54 - Successfully stopped SparkContext; 13:35:56.383 INFO CountReadsSpark - Shutting down engine; [January 9, 2019 1:35:56 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.78 minutes.; Runtime.totalMemory()=1009254400; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 11, scc-q20.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:36454,Availability,failure,failure,36454,"2019-01-09 13:35:56 INFO SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-01-09 13:35:56 INFO YarnClientSchedulerBackend:54 - Stopped; 2019-01-09 13:35:56 INFO MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!; 2019-01-09 13:35:56 INFO MemoryStore:54 - MemoryStore cleared; 2019-01-09 13:35:56 INFO BlockManager:54 - BlockManager stopped; 2019-01-09 13:35:56 INFO BlockManagerMaster:54 - BlockManagerMaster stopped; 2019-01-09 13:35:56 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-01-09 13:35:56 INFO SparkContext:54 - Successfully stopped SparkContext; 13:35:56.383 INFO CountReadsSpark - Shutting down engine; [January 9, 2019 1:35:56 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.78 minutes.; Runtime.totalMemory()=1009254400; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 11, scc-q20.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonf",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:36511,Availability,failure,failure,36511,"opping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-01-09 13:35:56 INFO YarnClientSchedulerBackend:54 - Stopped; 2019-01-09 13:35:56 INFO MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!; 2019-01-09 13:35:56 INFO MemoryStore:54 - MemoryStore cleared; 2019-01-09 13:35:56 INFO BlockManager:54 - BlockManager stopped; 2019-01-09 13:35:56 INFO BlockManagerMaster:54 - BlockManagerMaster stopped; 2019-01-09 13:35:56 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-01-09 13:35:56 INFO SparkContext:54 - Successfully stopped SparkContext; 13:35:56.383 INFO CountReadsSpark - Shutting down engine; [January 9, 2019 1:35:56 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.78 minutes.; Runtime.totalMemory()=1009254400; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 11, scc-q20.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkC",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:388,Deployability,pipeline,pipelines,388,"@tomwhite . I tried rerunning the job using a bgzip reference to work around the problem. However, the same error is being generated (htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice). . ```; gatk CountReadsSpark --input /project/casa/gcad/test/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/wgs.hg38/pipelines/hc/cram.test/GRCh38_full_analysis_set_plus_decoy_hla.fa.gz -- --spark-runner SPARK --spark-master yarn. Using GATK jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar; Running:; /share/pkg/spark/2.3.0/install/bin/spark-submit --master yarn --conf spark.kryoserializer.buffer.max=512m --conf spark.driver.maxResultSize=0 --conf spark.driver.userClassPathFirst=false --conf spark.io.compression.codec=lzf --conf spark.yarn.executor.memoryOverhead=600 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar CountReadsSpark --input /project/casa/gcad/test/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/wgs.hg38/pipelines/hc/cram.test/GRCh38_full_analysis_set_plus_decoy_hla.fa.gz --spark-master yarn; 2019-01-09 13:35:04 WARN SparkConf:66 - The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 2019-01-09 13:35:05 WARN NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... usi",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:542,Deployability,install,install,542,"@tomwhite . I tried rerunning the job using a bgzip reference to work around the problem. However, the same error is being generated (htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice). . ```; gatk CountReadsSpark --input /project/casa/gcad/test/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/wgs.hg38/pipelines/hc/cram.test/GRCh38_full_analysis_set_plus_decoy_hla.fa.gz -- --spark-runner SPARK --spark-master yarn. Using GATK jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar; Running:; /share/pkg/spark/2.3.0/install/bin/spark-submit --master yarn --conf spark.kryoserializer.buffer.max=512m --conf spark.driver.maxResultSize=0 --conf spark.driver.userClassPathFirst=false --conf spark.io.compression.codec=lzf --conf spark.yarn.executor.memoryOverhead=600 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar CountReadsSpark --input /project/casa/gcad/test/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/wgs.hg38/pipelines/hc/cram.test/GRCh38_full_analysis_set_plus_decoy_hla.fa.gz --spark-master yarn; 2019-01-09 13:35:04 WARN SparkConf:66 - The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 2019-01-09 13:35:05 WARN NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... usi",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:620,Deployability,install,install,620,"@tomwhite . I tried rerunning the job using a bgzip reference to work around the problem. However, the same error is being generated (htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice). . ```; gatk CountReadsSpark --input /project/casa/gcad/test/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/wgs.hg38/pipelines/hc/cram.test/GRCh38_full_analysis_set_plus_decoy_hla.fa.gz -- --spark-runner SPARK --spark-master yarn. Using GATK jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar; Running:; /share/pkg/spark/2.3.0/install/bin/spark-submit --master yarn --conf spark.kryoserializer.buffer.max=512m --conf spark.driver.maxResultSize=0 --conf spark.driver.userClassPathFirst=false --conf spark.io.compression.codec=lzf --conf spark.yarn.executor.memoryOverhead=600 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar CountReadsSpark --input /project/casa/gcad/test/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/wgs.hg38/pipelines/hc/cram.test/GRCh38_full_analysis_set_plus_decoy_hla.fa.gz --spark-master yarn; 2019-01-09 13:35:04 WARN SparkConf:66 - The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 2019-01-09 13:35:05 WARN NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... usi",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:1363,Deployability,install,install,1363,asa/wgs.hg38/pipelines/hc/cram.test/GRCh38_full_analysis_set_plus_decoy_hla.fa.gz -- --spark-runner SPARK --spark-master yarn. Using GATK jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar; Running:; /share/pkg/spark/2.3.0/install/bin/spark-submit --master yarn --conf spark.kryoserializer.buffer.max=512m --conf spark.driver.maxResultSize=0 --conf spark.driver.userClassPathFirst=false --conf spark.io.compression.codec=lzf --conf spark.yarn.executor.memoryOverhead=600 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar CountReadsSpark --input /project/casa/gcad/test/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/wgs.hg38/pipelines/hc/cram.test/GRCh38_full_analysis_set_plus_decoy_hla.fa.gz --spark-master yarn; 2019-01-09 13:35:04 WARN SparkConf:66 - The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 2019-01-09 13:35:05 WARN NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 13:35:09.640 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 13:35:09.799 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:1569,Deployability,pipeline,pipelines,1569,-spark.jar; Running:; /share/pkg/spark/2.3.0/install/bin/spark-submit --master yarn --conf spark.kryoserializer.buffer.max=512m --conf spark.driver.maxResultSize=0 --conf spark.driver.userClassPathFirst=false --conf spark.io.compression.codec=lzf --conf spark.yarn.executor.memoryOverhead=600 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar CountReadsSpark --input /project/casa/gcad/test/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/wgs.hg38/pipelines/hc/cram.test/GRCh38_full_analysis_set_plus_decoy_hla.fa.gz --spark-master yarn; 2019-01-09 13:35:04 WARN SparkConf:66 - The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 2019-01-09 13:35:05 WARN NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 13:35:09.640 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 13:35:09.799 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar!/com/intel/gkl/native/libgkl_compression.so; 13:35:11.507 INFO CountReadsSpark - ------------------------------------------------------------; 13:35:11.508 INFO CountReadsSpark - Th,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:1703,Deployability,configurat,configuration,1703,lizer.buffer.max=512m --conf spark.driver.maxResultSize=0 --conf spark.driver.userClassPathFirst=false --conf spark.io.compression.codec=lzf --conf spark.yarn.executor.memoryOverhead=600 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar CountReadsSpark --input /project/casa/gcad/test/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/wgs.hg38/pipelines/hc/cram.test/GRCh38_full_analysis_set_plus_decoy_hla.fa.gz --spark-master yarn; 2019-01-09 13:35:04 WARN SparkConf:66 - The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 2019-01-09 13:35:05 WARN NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 13:35:09.640 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 13:35:09.799 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar!/com/intel/gkl/native/libgkl_compression.so; 13:35:11.507 INFO CountReadsSpark - ------------------------------------------------------------; 13:35:11.508 INFO CountReadsSpark - The Genome Analysis Toolkit (GATK) v4.0.12.0; 13:35:11.508 INFO CountReadsSpark - For support and documentat,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:2351,Deployability,install,install,2351,"install/bin/gatk-package-4.0.12.0-spark.jar CountReadsSpark --input /project/casa/gcad/test/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/wgs.hg38/pipelines/hc/cram.test/GRCh38_full_analysis_set_plus_decoy_hla.fa.gz --spark-master yarn; 2019-01-09 13:35:04 WARN SparkConf:66 - The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 2019-01-09 13:35:05 WARN NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 13:35:09.640 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 13:35:09.799 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar!/com/intel/gkl/native/libgkl_compression.so; 13:35:11.507 INFO CountReadsSpark - ------------------------------------------------------------; 13:35:11.508 INFO CountReadsSpark - The Genome Analysis Toolkit (GATK) v4.0.12.0; 13:35:11.508 INFO CountReadsSpark - For support and documentation go to https://software.broadinstitute.org/gatk/; 13:35:11.508 INFO CountReadsSpark - Executing as farrell@scc-hadoop.bu.edu on Linux v2.6.32-754.6.3.el6.x86_64 amd64; 13:35:11.508 INFO CountReadsSpark - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_121-b13; 13:35:11.509 INFO CountReadsSpark - Start Date/Time: January 9, 2019 1:35:09 PM EST; 13:35:11.509 INFO CountReadsSpark - ------------------------------------------------------------; 13:35:11.509 INFO CountReadsSpark - ------------------------------------------------------------; 13:35:11.510 INFO CountReadsSpark - HTSJDK Version: 2.18.1; 13:35:11.511 INFO CountReadsSpark - Picard Version: 2.18.16; 13:35:11.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:4364,Deployability,configurat,configuration,4364,- Picard Version: 2.18.16; 13:35:11.511 INFO CountReadsSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 13:35:11.511 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 13:35:11.511 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 13:35:11.511 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 13:35:11.511 INFO CountReadsSpark - Deflater: IntelDeflater; 13:35:11.511 INFO CountReadsSpark - Inflater: IntelInflater; 13:35:11.512 INFO CountReadsSpark - GCS max retries/reopens: 20; 13:35:11.512 INFO CountReadsSpark - Requester pays: disabled; 13:35:11.512 WARN CountReadsSpark -. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: CountReadsSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 13:35:11.512 INFO CountReadsSpark - Initializing engine; 13:35:11.512 INFO CountReadsSpark - Done initializing engine; 2019-01-09 13:35:11 WARN SparkConf:66 - The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 2019-01-09 13:35:11 INFO SparkContext:54 - Running Spark version 2.3.0; 2019-01-09 13:35:11 INFO SparkContext:54 - Submitted application: CountReadsSpark; 2019-01-09 13:35:11 INFO SecurityManager:54 - Changing view acls to: farrell; 2019-01-09 13:35:11 INFO SecurityManager:54 - Changing modify acls to: farrell; 2019-01-09 13:35:11 INFO SecurityManager:54 - Changing view acls groups to:; 2019-01-09 13:35:11 INFO SecurityManager:54 - Changing modify acls groups to:; 2019-01-09 13:35:11 INFO SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(farrell); groups with view permissions: Set(); users with modify permissions: Set(farrell); groups with modify permissions: Set(); 2019-01-09 13:35:12 INFO Utils:54 -,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:9994,Deployability,install,install,9994,"AILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@320ff86f{/executors/threadDump/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@192b472d{/static,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@16b64a03{/,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1584c019{/api,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5817f1ca{/jobs/job/kill,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2b395581{/stages/stage/kill,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://scc-hadoop.bu.edu:4041; 2019-01-09 13:35:12 INFO SparkContext:54 - Added JAR file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar at spark://scc-hadoop.bu.edu:42689/jars/gatk-package-4.0.12.0-spark.jar with timestamp 1547058912934; 2019-01-09 13:35:13 INFO GoogleHadoopFileSystemBase:607 - GHFS version: 1.6.3-hadoop2; 2019-01-09 13:35:13 WARN DomainSocketFactory:117 - The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.; 2019-01-09 13:35:14 INFO Client:54 - Requesting a new application from cluster with 21 NodeManagers; 2019-01-09 13:35:14 INFO Client:54 - Verifying our application has not requested more than the maximum memory capability of the cluster (204800 MB per container); 2019-01-09 13:35:14 INFO Client:54 - Will allocate AM container, with 896 MB memory including 384 MB overhead; 2019-01-09 13:35:14 INFO Client:54 - Setting up container launch context for our AM; 2019-01-09 13:35:14 INFO Client:54 - Setting up the launch environment for our AM container; 2019-01-09 13:35:14 INFO Client:54 - Preparing resources for our AM container; 2019-01",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:36301,Deployability,pipeline,pipelines,36301,"d:54 - Shutting down all executors; 2019-01-09 13:35:56 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-01-09 13:35:56 INFO SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-01-09 13:35:56 INFO YarnClientSchedulerBackend:54 - Stopped; 2019-01-09 13:35:56 INFO MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!; 2019-01-09 13:35:56 INFO MemoryStore:54 - MemoryStore cleared; 2019-01-09 13:35:56 INFO BlockManager:54 - BlockManager stopped; 2019-01-09 13:35:56 INFO BlockManagerMaster:54 - BlockManagerMaster stopped; 2019-01-09 13:35:56 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-01-09 13:35:56 INFO SparkContext:54 - Successfully stopped SparkContext; 13:35:56.383 INFO CountReadsSpark - Shutting down engine; [January 9, 2019 1:35:56 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.78 minutes.; Runtime.totalMemory()=1009254400; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 11, scc-q20.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Uti",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:39930,Deployability,pipeline,pipelines,39930,uler.handleTaskSetFailed(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2027); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2048); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2092); at org.apache.spark.rdd.RDD.count(RDD.scala:1162); at org.apache.spark.api.java.JavaRDDLike$class.count(JavaRDDLike.scala:455); at org.apache.spark.api.java.AbstractJavaRDDLike.count(JavaRDDLike.scala:45); at org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark.runTool(CountReadsSpark.java:80); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:470); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessor,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:41023,Deployability,deploy,deploy,41023,"ine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:470); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:879); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:197); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:227); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:136); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:41104,Deployability,deploy,deploy,41104,"e.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:879); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:197); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:227); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:136); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:41141,Deployability,deploy,deploy,41141,"gram.doWork(SparkCommandLineProgram.java:30); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:879); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:197); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:227); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:136); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(I",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:41213,Deployability,deploy,deploy,41213,"ute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:879); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:197); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:227); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:136); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorS",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:41289,Deployability,deploy,deploy,41289,"9); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:879); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:197); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:227); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:136); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RD",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:41360,Deployability,deploy,deploy,41360,"eMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:879); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:197); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:227); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:136); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.s",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:41429,Deployability,deploy,deploy,41429,"e.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:879); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:197); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:227); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:136); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:43537,Deployability,install,install,43537,"apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); 2019-01-09 13:35:56 INFO ShutdownHookManager:54 - Shutdown hook called; 2019-01-09 13:35:56 INFO ShutdownHookManager:54 - Deleting directory /tmp/spark-69cc5c72-eff6-4259-8b3b-12fa6f8c42b0; 2019-01-09 13:35:56 INFO ShutdownHookManager:54 - Deleting directory /tmp/spark-0bd07e00-4f6d-43bd-b9d2-b1999376c72b; ```. Just to verify, the non-spark version still runs fine with the compressed fasta.... ```; gatk CountReads --input HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference GRCh38_full_analysis_set_plus_decoy_hla.fa.gz; Using GATK jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-local.jar CountReads --input HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference GRCh38_full_analysis_set_plus_decoy_hla.fa.gz; 13:38:54.168 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 13:38:55.869 INFO CountReads - ------------------------------------------------------------; 13:38:55.870 INFO CountReads - The Genome Analysis Toolkit (GATK) v4.0.12.0; 13:38:55.870 INFO CountReads - For support and documentation go to https://software.broadinstitute.org/gatk/; 13:38:55.871 INFO CountReads - Executing as farrell@scc-hadoop.bu.edu on Linux v2.6.32-754.6.3.el6.x86_64 amd",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:43782,Deployability,install,install,43782,"r(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); 2019-01-09 13:35:56 INFO ShutdownHookManager:54 - Shutdown hook called; 2019-01-09 13:35:56 INFO ShutdownHookManager:54 - Deleting directory /tmp/spark-69cc5c72-eff6-4259-8b3b-12fa6f8c42b0; 2019-01-09 13:35:56 INFO ShutdownHookManager:54 - Deleting directory /tmp/spark-0bd07e00-4f6d-43bd-b9d2-b1999376c72b; ```. Just to verify, the non-spark version still runs fine with the compressed fasta.... ```; gatk CountReads --input HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference GRCh38_full_analysis_set_plus_decoy_hla.fa.gz; Using GATK jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-local.jar CountReads --input HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference GRCh38_full_analysis_set_plus_decoy_hla.fa.gz; 13:38:54.168 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 13:38:55.869 INFO CountReads - ------------------------------------------------------------; 13:38:55.870 INFO CountReads - The Genome Analysis Toolkit (GATK) v4.0.12.0; 13:38:55.870 INFO CountReads - For support and documentation go to https://software.broadinstitute.org/gatk/; 13:38:55.871 INFO CountReads - Executing as farrell@scc-hadoop.bu.edu on Linux v2.6.32-754.6.3.el6.x86_64 amd64; 13:38:55.871 INFO CountReads - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_121-b13; 13:38:55.871 INFO CountReads - Start Date/Time: January 9, 2019 1:38:54 PM EST; 13:38:55.871 INFO CountReads - -----------------------------------",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:44072,Deployability,install,install,44072,"directory /tmp/spark-69cc5c72-eff6-4259-8b3b-12fa6f8c42b0; 2019-01-09 13:35:56 INFO ShutdownHookManager:54 - Deleting directory /tmp/spark-0bd07e00-4f6d-43bd-b9d2-b1999376c72b; ```. Just to verify, the non-spark version still runs fine with the compressed fasta.... ```; gatk CountReads --input HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference GRCh38_full_analysis_set_plus_decoy_hla.fa.gz; Using GATK jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-local.jar CountReads --input HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference GRCh38_full_analysis_set_plus_decoy_hla.fa.gz; 13:38:54.168 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 13:38:55.869 INFO CountReads - ------------------------------------------------------------; 13:38:55.870 INFO CountReads - The Genome Analysis Toolkit (GATK) v4.0.12.0; 13:38:55.870 INFO CountReads - For support and documentation go to https://software.broadinstitute.org/gatk/; 13:38:55.871 INFO CountReads - Executing as farrell@scc-hadoop.bu.edu on Linux v2.6.32-754.6.3.el6.x86_64 amd64; 13:38:55.871 INFO CountReads - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_121-b13; 13:38:55.871 INFO CountReads - Start Date/Time: January 9, 2019 1:38:54 PM EST; 13:38:55.871 INFO CountReads - ------------------------------------------------------------; 13:38:55.871 INFO CountReads - ------------------------------------------------------------; 13:38:55.872 INFO CountReads - HTSJDK Version: 2.18.1; 13:38:55.873 INFO CountReads - Picard Version: 2.18.16; 13:38:55.873 INFO CountReads - HTSJDK Defaults.COMPRESSION_",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:10674,Energy Efficiency,allocate,allocate,10674,"ges/stage/kill,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://scc-hadoop.bu.edu:4041; 2019-01-09 13:35:12 INFO SparkContext:54 - Added JAR file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar at spark://scc-hadoop.bu.edu:42689/jars/gatk-package-4.0.12.0-spark.jar with timestamp 1547058912934; 2019-01-09 13:35:13 INFO GoogleHadoopFileSystemBase:607 - GHFS version: 1.6.3-hadoop2; 2019-01-09 13:35:13 WARN DomainSocketFactory:117 - The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.; 2019-01-09 13:35:14 INFO Client:54 - Requesting a new application from cluster with 21 NodeManagers; 2019-01-09 13:35:14 INFO Client:54 - Verifying our application has not requested more than the maximum memory capability of the cluster (204800 MB per container); 2019-01-09 13:35:14 INFO Client:54 - Will allocate AM container, with 896 MB memory including 384 MB overhead; 2019-01-09 13:35:14 INFO Client:54 - Setting up container launch context for our AM; 2019-01-09 13:35:14 INFO Client:54 - Setting up the launch environment for our AM container; 2019-01-09 13:35:14 INFO Client:54 - Preparing resources for our AM container; 2019-01-09 13:35:14 INFO HadoopFSDelegationTokenProvider:54 - getting token for: DFS[DFSClient[clientName=DFSClient_NONMAPREDUCE_-682487019_1, ugi=farrell@AD.BU.EDU (auth:KERBEROS)]]; 2019-01-09 13:35:14 INFO DFSClient:1023 - Created HDFS_DELEGATION_TOKEN token 11353 for farrell on ha-hdfs:scc; 2019-01-09 13:35:16 WARN Client:66 - Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.; 2019-01-09 13:35:20 INFO Client:54 - Uploading resource file:/tmp/spark-69cc5c72-eff6-4259-8b3b-12fa6f8c42b0/__spark_libs__7821719163562430010.zip -> hdfs://scc/user/farrell/.sparkStaging/application_1542127286896_0166/__spark_libs__7821719163562430010.zip; 2019-01-09 13:35:22 INFO Client:54 - Uploading resource file:",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:12760,Energy Efficiency,Schedul,SchedulerExtensionServices,12760,"c/user/farrell/.sparkStaging/application_1542127286896_0166/__spark_libs__7821719163562430010.zip; 2019-01-09 13:35:22 INFO Client:54 - Uploading resource file:/tmp/spark-69cc5c72-eff6-4259-8b3b-12fa6f8c42b0/__spark_conf__4520928824604875683.zip -> hdfs://scc/user/farrell/.sparkStaging/application_1542127286896_0166/__spark_conf__.zip; 2019-01-09 13:35:22 INFO SecurityManager:54 - Changing view acls to: farrell; 2019-01-09 13:35:22 INFO SecurityManager:54 - Changing modify acls to: farrell; 2019-01-09 13:35:22 INFO SecurityManager:54 - Changing view acls groups to:; 2019-01-09 13:35:22 INFO SecurityManager:54 - Changing modify acls groups to:; 2019-01-09 13:35:22 INFO SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(farrell); groups with view permissions: Set(); users with modify permissions: Set(farrell); groups with modify permissions: Set(); 2019-01-09 13:35:22 INFO Client:54 - Submitting application application_1542127286896_0166 to ResourceManager; 2019-01-09 13:35:22 INFO YarnClientImpl:251 - Submitted application application_1542127286896_0166; 2019-01-09 13:35:22 INFO SchedulerExtensionServices:54 - Starting Yarn extension services with app application_1542127286896_0166 and attemptId None; 2019-01-09 13:35:23 INFO Client:54 - Application report for application_1542127286896_0166 (state: ACCEPTED); 2019-01-09 13:35:23 INFO Client:54 -; client token: Token { kind: YARN_CLIENT_TOKEN, service: }; diagnostics: N/A; ApplicationMaster host: N/A; ApplicationMaster RPC port: -1; queue: default; start time: 1547058922320; final status: UNDEFINED; tracking URL: https://scc-hsn1.scc.bu.edu:8090/proxy/application_1542127286896_0166/; user: farrell; 2019-01-09 13:35:24 INFO Client:54 - Application report for application_1542127286896_0166 (state: ACCEPTED); 2019-01-09 13:35:25 INFO Client:54 - Application report for application_1542127286896_0166 (state: ACCEPTED); 2019-01-09 13:35:26 INFO Client:54 - Applic",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:17308,Energy Efficiency,Schedul,SchedulerBackend,17308," INFO BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, scc-hadoop.bu.edu, 43627, None); 2019-01-09 13:35:34 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@53f94afe{/metrics/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:37 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.18.204:36598) with ID 2; 2019-01-09 13:35:37 INFO BlockManagerMasterEndpoint:54 - Registering block manager scc-q20.scc.bu.edu:42946 with 366.3 MB RAM, BlockManagerId(2, scc-q20.scc.bu.edu, 42946, None); 2019-01-09 13:35:39 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.18.185:34050) with ID 1; 2019-01-09 13:35:39 INFO BlockManagerMasterEndpoint:54 - Registering block manager scc-q01.scc.bu.edu:41129 with 366.3 MB RAM, BlockManagerId(1, scc-q01.scc.bu.edu, 41129, None); 2019-01-09 13:35:39 INFO YarnClientSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8; 2019-01-09 13:35:41 INFO MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 1229.0 KB, free 371.4 MB); 2019-01-09 13:35:42 INFO MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 113.9 KB, free 371.3 MB); 2019-01-09 13:35:42 INFO BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on scc-hadoop.bu.edu:43627 (size: 113.9 KB, free: 372.5 MB); 2019-01-09 13:35:42 INFO SparkContext:54 - Created broadcast 0 from broadcast at CramSource.java:115; 2019-01-09 13:35:42 INFO MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 252.3 KB, free 371.0 MB); 2019-01-09 13:35:42 INFO MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 25.4 KB, free 371.0 MB); 2019-01-09 13:35:42 INFO BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on scc-hadoop.bu.edu:43627 (size: 25.4 KB, free: 372.5 M",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:17338,Energy Efficiency,schedul,scheduling,17338," INFO BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, scc-hadoop.bu.edu, 43627, None); 2019-01-09 13:35:34 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@53f94afe{/metrics/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:37 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.18.204:36598) with ID 2; 2019-01-09 13:35:37 INFO BlockManagerMasterEndpoint:54 - Registering block manager scc-q20.scc.bu.edu:42946 with 366.3 MB RAM, BlockManagerId(2, scc-q20.scc.bu.edu, 42946, None); 2019-01-09 13:35:39 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.18.185:34050) with ID 1; 2019-01-09 13:35:39 INFO BlockManagerMasterEndpoint:54 - Registering block manager scc-q01.scc.bu.edu:41129 with 366.3 MB RAM, BlockManagerId(1, scc-q01.scc.bu.edu, 41129, None); 2019-01-09 13:35:39 INFO YarnClientSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8; 2019-01-09 13:35:41 INFO MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 1229.0 KB, free 371.4 MB); 2019-01-09 13:35:42 INFO MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 113.9 KB, free 371.3 MB); 2019-01-09 13:35:42 INFO BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on scc-hadoop.bu.edu:43627 (size: 113.9 KB, free: 372.5 MB); 2019-01-09 13:35:42 INFO SparkContext:54 - Created broadcast 0 from broadcast at CramSource.java:115; 2019-01-09 13:35:42 INFO MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 252.3 KB, free 371.0 MB); 2019-01-09 13:35:42 INFO MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 25.4 KB, free 371.0 MB); 2019-01-09 13:35:42 INFO BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on scc-hadoop.bu.edu:43627 (size: 25.4 KB, free: 372.5 M",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:24081,Energy Efficiency,schedul,scheduler,24081,"ence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-09 13:35:49 INFO TaskSetManager:54 - Starting task 7.0 in stage 0.0 (TID 3, scc-q01.scc.bu.edu, executor 1, partition 7, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:49 WARN TaskSetManager:66 - Lost task 2.0 in stage 0.0 (TID 1, scc-q01.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 160972515, span 170618, expected MD5 0cc5e1f5ec5c1b06d5a4bd5fff11b77f; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.Autoclos",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:24152,Energy Efficiency,schedul,scheduler,24152,"de06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-09 13:35:49 INFO TaskSetManager:54 - Starting task 7.0 in stage 0.0 (TID 3, scc-q01.scc.bu.edu, executor 1, partition 7, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:49 WARN TaskSetManager:66 - Lost task 2.0 in stage 0.0 (TID 1, scc-q01.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 160972515, span 170618, expected MD5 0cc5e1f5ec5c1b06d5a4bd5fff11b77f; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.co",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:25818,Energy Efficiency,schedul,scheduler,25818,"nce id 0, start 160972515, span 170618, expected MD5 0cc5e1f5ec5c1b06d5a4bd5fff11b77f; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-09 13:35:50 INFO TaskSetManager:54 - Starting task 1.1 in stage 0.0 (TID 4, scc-q20.scc.bu.edu, executor 2, partition 1, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:50 WARN TaskSetManager:66 - Lost task 4.0 in stage 0.0 (TID 2, scc-q20.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 1, start 93925364, span 266689, expected MD5 54babf05a23e9e88a8738dfbb20a1683; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.Autoclose",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:25889,Energy Efficiency,schedul,scheduler,25889,"a4bd5fff11b77f; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-09 13:35:50 INFO TaskSetManager:54 - Starting task 1.1 in stage 0.0 (TID 4, scc-q20.scc.bu.edu, executor 2, partition 1, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:50 WARN TaskSetManager:66 - Lost task 4.0 in stage 0.0 (TID 2, scc-q20.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 1, start 93925364, span 266689, expected MD5 54babf05a23e9e88a8738dfbb20a1683; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.col",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:27554,Energy Efficiency,schedul,scheduler,27554,"ence id 1, start 93925364, span 266689, expected MD5 54babf05a23e9e88a8738dfbb20a1683; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-09 13:35:51 INFO TaskSetManager:54 - Starting task 4.1 in stage 0.0 (TID 5, scc-q20.scc.bu.edu, executor 2, partition 4, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:51 INFO TaskSetManager:54 - Lost task 1.1 in stage 0.0 (TID 4) on scc-q20.scc.bu.edu, executor 2: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae) [duplicate 1]; 2019-01-09 13:35:52 INFO TaskSetManager:54 - Starting task 2.1 in stage 0.0 (TID 6, scc-q01.scc.bu.edu, executor 1, partition 2, NODE_LOCAL, 7992 bytes); 2019-0",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:27625,Energy Efficiency,schedul,scheduler,27625,"738dfbb20a1683; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-09 13:35:51 INFO TaskSetManager:54 - Starting task 4.1 in stage 0.0 (TID 5, scc-q20.scc.bu.edu, executor 2, partition 4, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:51 INFO TaskSetManager:54 - Lost task 1.1 in stage 0.0 (TID 4) on scc-q20.scc.bu.edu, executor 2: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae) [duplicate 1]; 2019-01-09 13:35:52 INFO TaskSetManager:54 - Starting task 2.1 in stage 0.0 (TID 6, scc-q01.scc.bu.edu, executor 1, partition 2, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:52 WARN TaskSetManager:66 - Lost task 7.0 in stage 0.0 (TID ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:29745,Energy Efficiency,schedul,scheduler,29745,"nce id 2, start 131325815, span 181534, expected MD5 c240a972d49aa89fb57dae94d1d90d36; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-09 13:35:52 INFO TaskSetManager:54 - Starting task 1.2 in stage 0.0 (TID 7, scc-q20.scc.bu.edu, executor 2, partition 1, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:52 INFO TaskSetManager:54 - Lost task 4.1 in stage 0.0 (TID 5) on scc-q20.scc.bu.edu, executor 2: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 1, start 93925364, span 266689, expected MD5 54babf05a23e9e88a8738dfbb20a1683) [duplicate 1]; 2019-01-09 13:35:53 INFO TaskSetManager:54 - Starting task 7.1 in stage 0.0 (TID 8, scc-q01.scc.bu.edu, executor 1, partition 7, NODE_LOCAL, 7992 bytes); 2019-0",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:29816,Energy Efficiency,schedul,scheduler,29816,"7dae94d1d90d36; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-09 13:35:52 INFO TaskSetManager:54 - Starting task 1.2 in stage 0.0 (TID 7, scc-q20.scc.bu.edu, executor 2, partition 1, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:52 INFO TaskSetManager:54 - Lost task 4.1 in stage 0.0 (TID 5) on scc-q20.scc.bu.edu, executor 2: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 1, start 93925364, span 266689, expected MD5 54babf05a23e9e88a8738dfbb20a1683) [duplicate 1]; 2019-01-09 13:35:53 INFO TaskSetManager:54 - Starting task 7.1 in stage 0.0 (TID 8, scc-q01.scc.bu.edu, executor 1, partition 7, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:53 INFO TaskSetManager:54 - Lost task 2.1 in stage 0.0 (TID ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:34449,Energy Efficiency,schedul,scheduler,34449,"ence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 2019-01-09 13:35:56 INFO DAGScheduler:54 - Job 0 failed: count at CountReadsSpark.java:80, took 12.691336 s; 2019-01-09 13:35:56 INFO AbstractConnector:318 - Stopped Spark@22fda322{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-09 13:35:56 INFO SparkUI:54 - Stopped Spark web UI at http://scc-hadoop.bu.edu:4041; 2019-01-09 13:35:56 INFO YarnClientSchedulerBackend:54 - Interrupting monitor thread; 2019-01-09 13:35:56 INFO YarnClientSchedulerBackend:54 - Shutting down all executors; 2019-01-09 13:35:56 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-01",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:34520,Energy Efficiency,schedul,scheduler,34520,"de06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 2019-01-09 13:35:56 INFO DAGScheduler:54 - Job 0 failed: count at CountReadsSpark.java:80, took 12.691336 s; 2019-01-09 13:35:56 INFO AbstractConnector:318 - Stopped Spark@22fda322{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-09 13:35:56 INFO SparkUI:54 - Stopped Spark web UI at http://scc-hadoop.bu.edu:4041; 2019-01-09 13:35:56 INFO YarnClientSchedulerBackend:54 - Interrupting monitor thread; 2019-01-09 13:35:56 INFO YarnClientSchedulerBackend:54 - Shutting down all executors; 2019-01-09 13:35:56 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-01-09 13:35:56 INFO SchedulerExtensionServices:54 - Stopping SchedulerExt",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:35240,Energy Efficiency,monitor,monitor,35240,"utor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 2019-01-09 13:35:56 INFO DAGScheduler:54 - Job 0 failed: count at CountReadsSpark.java:80, took 12.691336 s; 2019-01-09 13:35:56 INFO AbstractConnector:318 - Stopped Spark@22fda322{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-09 13:35:56 INFO SparkUI:54 - Stopped Spark web UI at http://scc-hadoop.bu.edu:4041; 2019-01-09 13:35:56 INFO YarnClientSchedulerBackend:54 - Interrupting monitor thread; 2019-01-09 13:35:56 INFO YarnClientSchedulerBackend:54 - Shutting down all executors; 2019-01-09 13:35:56 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-01-09 13:35:56 INFO SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-01-09 13:35:56 INFO YarnClientSchedulerBackend:54 - Stopped; 2019-01-09 13:35:56 INFO MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!; 2019-01-09 13:35:56 INFO MemoryStore:54 - MemoryStore cleared; 2019-01-09 13:35:56 INFO BlockManager:54 - BlockManager stopped; 2019-01-09 13:35:56 INFO BlockManagerMaster:54 - BlockManagerMaster stopped; 2019-01-09 13:35:56 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-01-09 13:35:56 INFO SparkContext:54 - Successfully stopped SparkContext; 13:35:56.383 INFO CountReadsSpark - Shutting down engine; [January 9, 2019 1:35:56 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.78 minutes.; Runtime.totalMemory()=1009254400; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 11, scc-q20.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: s",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:35472,Energy Efficiency,Schedul,SchedulerExtensionServices,35472,"utor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 2019-01-09 13:35:56 INFO DAGScheduler:54 - Job 0 failed: count at CountReadsSpark.java:80, took 12.691336 s; 2019-01-09 13:35:56 INFO AbstractConnector:318 - Stopped Spark@22fda322{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-09 13:35:56 INFO SparkUI:54 - Stopped Spark web UI at http://scc-hadoop.bu.edu:4041; 2019-01-09 13:35:56 INFO YarnClientSchedulerBackend:54 - Interrupting monitor thread; 2019-01-09 13:35:56 INFO YarnClientSchedulerBackend:54 - Shutting down all executors; 2019-01-09 13:35:56 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-01-09 13:35:56 INFO SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-01-09 13:35:56 INFO YarnClientSchedulerBackend:54 - Stopped; 2019-01-09 13:35:56 INFO MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!; 2019-01-09 13:35:56 INFO MemoryStore:54 - MemoryStore cleared; 2019-01-09 13:35:56 INFO BlockManager:54 - BlockManager stopped; 2019-01-09 13:35:56 INFO BlockManagerMaster:54 - BlockManagerMaster stopped; 2019-01-09 13:35:56 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-01-09 13:35:56 INFO SparkContext:54 - Successfully stopped SparkContext; 13:35:56.383 INFO CountReadsSpark - Shutting down engine; [January 9, 2019 1:35:56 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.78 minutes.; Runtime.totalMemory()=1009254400; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 11, scc-q20.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: s",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:35513,Energy Efficiency,Schedul,SchedulerExtensionServices,35513,"utor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 2019-01-09 13:35:56 INFO DAGScheduler:54 - Job 0 failed: count at CountReadsSpark.java:80, took 12.691336 s; 2019-01-09 13:35:56 INFO AbstractConnector:318 - Stopped Spark@22fda322{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-09 13:35:56 INFO SparkUI:54 - Stopped Spark web UI at http://scc-hadoop.bu.edu:4041; 2019-01-09 13:35:56 INFO YarnClientSchedulerBackend:54 - Interrupting monitor thread; 2019-01-09 13:35:56 INFO YarnClientSchedulerBackend:54 - Shutting down all executors; 2019-01-09 13:35:56 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-01-09 13:35:56 INFO SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-01-09 13:35:56 INFO YarnClientSchedulerBackend:54 - Stopped; 2019-01-09 13:35:56 INFO MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!; 2019-01-09 13:35:56 INFO MemoryStore:54 - MemoryStore cleared; 2019-01-09 13:35:56 INFO BlockManager:54 - BlockManager stopped; 2019-01-09 13:35:56 INFO BlockManagerMaster:54 - BlockManagerMaster stopped; 2019-01-09 13:35:56 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-01-09 13:35:56 INFO SparkContext:54 - Successfully stopped SparkContext; 13:35:56.383 INFO CountReadsSpark - Shutting down engine; [January 9, 2019 1:35:56 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.78 minutes.; Runtime.totalMemory()=1009254400; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 11, scc-q20.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: s",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:37667,Energy Efficiency,schedul,scheduler,37667,"ence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.schedule",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:37738,Energy Efficiency,schedul,scheduler,37738,de06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:38098,Energy Efficiency,schedul,scheduler,38098,or$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820); at org.apache.spark.s,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:38138,Energy Efficiency,schedul,scheduler,38138,n.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGSchedule,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:38236,Energy Efficiency,schedul,scheduler,38236,anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onRec,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:38333,Energy Efficiency,schedul,scheduler,38333,1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:38584,Energy Efficiency,schedul,scheduler,38584,Context$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2027); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2048); at org.apache.spark.SparkContext.runJob(Sp,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:38664,Energy Efficiency,schedul,scheduler,38664,heduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2027); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2048); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067); at org.apache.spark.SparkContext.runJob(SparkContext.sca,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:38769,Energy Efficiency,schedul,scheduler,38769,at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2027); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2048); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2092); at org.apache.spark.rdd.RDD.count(RDD.scala:1162); at org.apache.spark.api.java.JavaRDDLike$cla,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:38917,Energy Efficiency,schedul,scheduler,38917,va:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2027); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2048); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2092); at org.apache.spark.rdd.RDD.count(RDD.scala:1162); at org.apache.spark.api.java.JavaRDDLike$class.count(JavaRDDLike.scala:455); at org.apache.spark.api.java.AbstractJavaRDDLike.count(JavaRDDLike.scala:45); at org.broadinstitute.hellbender.tool,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:39005,Energy Efficiency,schedul,scheduler,39005,617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2027); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2048); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2092); at org.apache.spark.rdd.RDD.count(RDD.scala:1162); at org.apache.spark.api.java.JavaRDDLike$class.count(JavaRDDLike.scala:455); at org.apache.spark.api.java.AbstractJavaRDDLike.count(JavaRDDLike.scala:45); at org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark.runTool(CountReadsSpark.java:80); at org.broadinstitut,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:39102,Energy Efficiency,schedul,scheduler,39102,.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2027); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2048); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2092); at org.apache.spark.rdd.RDD.count(RDD.scala:1162); at org.apache.spark.api.java.JavaRDDLike$class.count(JavaRDDLike.scala:455); at org.apache.spark.api.java.AbstractJavaRDDLike.count(JavaRDDLike.scala:45); at org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark.runTool(CountReadsSpark.java:80); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:470); at org.broadinstitut,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:39197,Energy Efficiency,schedul,scheduler,39197,.scala:1599); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2027); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2048); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2092); at org.apache.spark.rdd.RDD.count(RDD.scala:1162); at org.apache.spark.api.java.JavaRDDLike$class.count(JavaRDDLike.scala:455); at org.apache.spark.api.java.AbstractJavaRDDLike.count(JavaRDDLike.scala:45); at org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark.runTool(CountReadsSpark.java:80); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:470); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); at o,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:39360,Energy Efficiency,schedul,scheduler,39360,abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2027); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2048); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2092); at org.apache.spark.rdd.RDD.count(RDD.scala:1162); at org.apache.spark.api.java.JavaRDDLike$class.count(JavaRDDLike.scala:455); at org.apache.spark.api.java.AbstractJavaRDDLike.count(JavaRDDLike.scala:45); at org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark.runTool(CountReadsSpark.java:80); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:470); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceM,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:42562,Energy Efficiency,schedul,scheduler,42562,"ence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); 2019-01-09 13:35:56 INFO ShutdownHookManager:54 - Shutdown hook called; 2019-01-09 13:35:56 INFO ShutdownHookManager:54 - Deleting directory /tmp/spark-69cc5c72-eff6-4259-8b3b-12fa6f8c42b0; 2019-01-09 13:35:56 INFO ShutdownHookManager:54 - Deleting directory /tmp/spark-0bd07e00-4f6d-43bd-b9d2-b1999376c72b; ```. Just to verify, the non-spark version still runs fine with the compressed fasta.... ```; gatk CountReads --input HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference GRCh38_full_analysis_set_plus_decoy_hla.fa.gz; Using GATK jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.1",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:42633,Energy Efficiency,schedul,scheduler,42633,"de06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); 2019-01-09 13:35:56 INFO ShutdownHookManager:54 - Shutdown hook called; 2019-01-09 13:35:56 INFO ShutdownHookManager:54 - Deleting directory /tmp/spark-69cc5c72-eff6-4259-8b3b-12fa6f8c42b0; 2019-01-09 13:35:56 INFO ShutdownHookManager:54 - Deleting directory /tmp/spark-0bd07e00-4f6d-43bd-b9d2-b1999376c72b; ```. Just to verify, the non-spark version still runs fine with the compressed fasta.... ```; gatk CountReads --input HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference GRCh38_full_analysis_set_plus_decoy_hla.fa.gz; Using GATK jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:23437,Integrability,Wrap,Wrappers,23437,"019-01-09 13:35:46 INFO BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on scc-q01.scc.bu.edu:41129 (size: 25.4 KB, free: 365.9 MB); 2019-01-09 13:35:46 INFO BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on scc-q01.scc.bu.edu:41129 (size: 113.9 KB, free: 365.8 MB); 2019-01-09 13:35:48 INFO TaskSetManager:54 - Starting task 4.0 in stage 0.0 (TID 2, scc-q20.scc.bu.edu, executor 2, partition 4, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:48 WARN TaskSetManager:66 - Lost task 1.0 in stage 0.0 (TID 0, scc-q20.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:23471,Integrability,Wrap,Wrappers,23471,"FO BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on scc-q01.scc.bu.edu:41129 (size: 25.4 KB, free: 365.9 MB); 2019-01-09 13:35:46 INFO BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on scc-q01.scc.bu.edu:41129 (size: 113.9 KB, free: 365.8 MB); 2019-01-09 13:35:48 INFO TaskSetManager:54 - Starting task 4.0 in stage 0.0 (TID 2, scc-q20.scc.bu.edu, executor 2, partition 4, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:48 WARN TaskSetManager:66 - Lost task 1.0 in stage 0.0 (TID 0, scc-q20.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:25174,Integrability,Wrap,Wrappers,25174," at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-09 13:35:49 INFO TaskSetManager:54 - Starting task 7.0 in stage 0.0 (TID 3, scc-q01.scc.bu.edu, executor 1, partition 7, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:49 WARN TaskSetManager:66 - Lost task 2.0 in stage 0.0 (TID 1, scc-q01.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 160972515, span 170618, expected MD5 0cc5e1f5ec5c1b06d5a4bd5fff11b77f; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:25208,Integrability,Wrap,Wrappers,25208,"executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-09 13:35:49 INFO TaskSetManager:54 - Starting task 7.0 in stage 0.0 (TID 3, scc-q01.scc.bu.edu, executor 1, partition 7, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:49 WARN TaskSetManager:66 - Lost task 2.0 in stage 0.0 (TID 1, scc-q01.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 160972515, span 170618, expected MD5 0cc5e1f5ec5c1b06d5a4bd5fff11b77f; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:26910,Integrability,Wrap,Wrappers,26910,"; at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-09 13:35:50 INFO TaskSetManager:54 - Starting task 1.1 in stage 0.0 (TID 4, scc-q20.scc.bu.edu, executor 2, partition 1, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:50 WARN TaskSetManager:66 - Lost task 4.0 in stage 0.0 (TID 2, scc-q20.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 1, start 93925364, span 266689, expected MD5 54babf05a23e9e88a8738dfbb20a1683; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:26944,Integrability,Wrap,Wrappers,26944,".executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-09 13:35:50 INFO TaskSetManager:54 - Starting task 1.1 in stage 0.0 (TID 4, scc-q20.scc.bu.edu, executor 2, partition 1, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:50 WARN TaskSetManager:66 - Lost task 4.0 in stage 0.0 (TID 2, scc-q20.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 1, start 93925364, span 266689, expected MD5 54babf05a23e9e88a8738dfbb20a1683; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:29101,Integrability,Wrap,Wrappers,29101,"5:51 INFO TaskSetManager:54 - Lost task 1.1 in stage 0.0 (TID 4) on scc-q20.scc.bu.edu, executor 2: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae) [duplicate 1]; 2019-01-09 13:35:52 INFO TaskSetManager:54 - Starting task 2.1 in stage 0.0 (TID 6, scc-q01.scc.bu.edu, executor 1, partition 2, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:52 WARN TaskSetManager:66 - Lost task 7.0 in stage 0.0 (TID 3, scc-q01.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 2, start 131325815, span 181534, expected MD5 c240a972d49aa89fb57dae94d1d90d36; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:29135,Integrability,Wrap,Wrappers,29135,"ger:54 - Lost task 1.1 in stage 0.0 (TID 4) on scc-q20.scc.bu.edu, executor 2: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae) [duplicate 1]; 2019-01-09 13:35:52 INFO TaskSetManager:54 - Starting task 2.1 in stage 0.0 (TID 6, scc-q01.scc.bu.edu, executor 1, partition 2, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:52 WARN TaskSetManager:66 - Lost task 7.0 in stage 0.0 (TID 3, scc-q01.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 2, start 131325815, span 181534, expected MD5 c240a972d49aa89fb57dae94d1d90d36; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:33805,Integrability,Wrap,Wrappers,33805,"92a29f6d7d6fcaf8dde06834861e7ae) [duplicate 3]; 2019-01-09 13:35:56 ERROR TaskSetManager:70 - Task 1 in stage 0.0 failed 4 times; aborting job; 2019-01-09 13:35:56 INFO YarnScheduler:54 - Cancelling stage 0; 2019-01-09 13:35:56 INFO YarnScheduler:54 - Stage 0 was cancelled; 2019-01-09 13:35:56 INFO DAGScheduler:54 - ResultStage 0 (count at CountReadsSpark.java:80) failed in 12.543 s due to Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 11, scc-q20.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:33839,Integrability,Wrap,Wrappers,33839,"834861e7ae) [duplicate 3]; 2019-01-09 13:35:56 ERROR TaskSetManager:70 - Task 1 in stage 0.0 failed 4 times; aborting job; 2019-01-09 13:35:56 INFO YarnScheduler:54 - Cancelling stage 0; 2019-01-09 13:35:56 INFO YarnScheduler:54 - Stage 0 was cancelled; 2019-01-09 13:35:56 INFO DAGScheduler:54 - ResultStage 0 (count at CountReadsSpark.java:80) failed in 12.543 s due to Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 11, scc-q20.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:37023,Integrability,Wrap,Wrappers,37023,"inatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-01-09 13:35:56 INFO SparkContext:54 - Successfully stopped SparkContext; 13:35:56.383 INFO CountReadsSpark - Shutting down engine; [January 9, 2019 1:35:56 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.78 minutes.; Runtime.totalMemory()=1009254400; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 11, scc-q20.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:37057,Integrability,Wrap,Wrappers,37057,"utputCommitCoordinator stopped!; 2019-01-09 13:35:56 INFO SparkContext:54 - Successfully stopped SparkContext; 13:35:56.383 INFO CountReadsSpark - Shutting down engine; [January 9, 2019 1:35:56 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.78 minutes.; Runtime.totalMemory()=1009254400; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 11, scc-q20.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:41918,Integrability,Wrap,Wrappers,41918,"ssorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:879); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:197); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:227); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:136); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:41952,Integrability,Wrap,Wrappers,41952," java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:879); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:197); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:227); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:136); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:1703,Modifiability,config,configuration,1703,lizer.buffer.max=512m --conf spark.driver.maxResultSize=0 --conf spark.driver.userClassPathFirst=false --conf spark.io.compression.codec=lzf --conf spark.yarn.executor.memoryOverhead=600 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar CountReadsSpark --input /project/casa/gcad/test/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/wgs.hg38/pipelines/hc/cram.test/GRCh38_full_analysis_set_plus_decoy_hla.fa.gz --spark-master yarn; 2019-01-09 13:35:04 WARN SparkConf:66 - The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 2019-01-09 13:35:05 WARN NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 13:35:09.640 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 13:35:09.799 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar!/com/intel/gkl/native/libgkl_compression.so; 13:35:11.507 INFO CountReadsSpark - ------------------------------------------------------------; 13:35:11.508 INFO CountReadsSpark - The Genome Analysis Toolkit (GATK) v4.0.12.0; 13:35:11.508 INFO CountReadsSpark - For support and documentat,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:2095,Modifiability,variab,variables,2095,"CKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar CountReadsSpark --input /project/casa/gcad/test/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/wgs.hg38/pipelines/hc/cram.test/GRCh38_full_analysis_set_plus_decoy_hla.fa.gz --spark-master yarn; 2019-01-09 13:35:04 WARN SparkConf:66 - The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 2019-01-09 13:35:05 WARN NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 13:35:09.640 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 13:35:09.799 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar!/com/intel/gkl/native/libgkl_compression.so; 13:35:11.507 INFO CountReadsSpark - ------------------------------------------------------------; 13:35:11.508 INFO CountReadsSpark - The Genome Analysis Toolkit (GATK) v4.0.12.0; 13:35:11.508 INFO CountReadsSpark - For support and documentation go to https://software.broadinstitute.org/gatk/; 13:35:11.508 INFO CountReadsSpark - Executing as farrell@scc-hadoop.bu.edu on Linux v2.6.32-754.6.3.el6.x86_64 amd64; 13:35:11.508 INFO CountReadsSpark - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_121-b13; 13:35:11.509 INFO CountReadsSpark - Start Date/Time: January 9, 2019 1:35:09 PM EST; 13:35:11.509 INFO CountReadsSpark - ------------------------------------------------------------; 13:35:11.509 INF",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:2221,Modifiability,config,configured,2221,"CKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar CountReadsSpark --input /project/casa/gcad/test/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/wgs.hg38/pipelines/hc/cram.test/GRCh38_full_analysis_set_plus_decoy_hla.fa.gz --spark-master yarn; 2019-01-09 13:35:04 WARN SparkConf:66 - The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 2019-01-09 13:35:05 WARN NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 13:35:09.640 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 13:35:09.799 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar!/com/intel/gkl/native/libgkl_compression.so; 13:35:11.507 INFO CountReadsSpark - ------------------------------------------------------------; 13:35:11.508 INFO CountReadsSpark - The Genome Analysis Toolkit (GATK) v4.0.12.0; 13:35:11.508 INFO CountReadsSpark - For support and documentation go to https://software.broadinstitute.org/gatk/; 13:35:11.508 INFO CountReadsSpark - Executing as farrell@scc-hadoop.bu.edu on Linux v2.6.32-754.6.3.el6.x86_64 amd64; 13:35:11.508 INFO CountReadsSpark - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_121-b13; 13:35:11.509 INFO CountReadsSpark - Start Date/Time: January 9, 2019 1:35:09 PM EST; 13:35:11.509 INFO CountReadsSpark - ------------------------------------------------------------; 13:35:11.509 INF",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:4364,Modifiability,config,configuration,4364,- Picard Version: 2.18.16; 13:35:11.511 INFO CountReadsSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 13:35:11.511 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 13:35:11.511 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 13:35:11.511 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 13:35:11.511 INFO CountReadsSpark - Deflater: IntelDeflater; 13:35:11.511 INFO CountReadsSpark - Inflater: IntelInflater; 13:35:11.512 INFO CountReadsSpark - GCS max retries/reopens: 20; 13:35:11.512 INFO CountReadsSpark - Requester pays: disabled; 13:35:11.512 WARN CountReadsSpark -. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: CountReadsSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 13:35:11.512 INFO CountReadsSpark - Initializing engine; 13:35:11.512 INFO CountReadsSpark - Done initializing engine; 2019-01-09 13:35:11 WARN SparkConf:66 - The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 2019-01-09 13:35:11 INFO SparkContext:54 - Running Spark version 2.3.0; 2019-01-09 13:35:11 INFO SparkContext:54 - Submitted application: CountReadsSpark; 2019-01-09 13:35:11 INFO SecurityManager:54 - Changing view acls to: farrell; 2019-01-09 13:35:11 INFO SecurityManager:54 - Changing modify acls to: farrell; 2019-01-09 13:35:11 INFO SecurityManager:54 - Changing view acls groups to:; 2019-01-09 13:35:11 INFO SecurityManager:54 - Changing modify acls groups to:; 2019-01-09 13:35:11 INFO SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(farrell); groups with view permissions: Set(); users with modify permissions: Set(farrell); groups with modify permissions: Set(); 2019-01-09 13:35:12 INFO Utils:54 -,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:1950,Performance,load,load,1950,ue -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar CountReadsSpark --input /project/casa/gcad/test/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/wgs.hg38/pipelines/hc/cram.test/GRCh38_full_analysis_set_plus_decoy_hla.fa.gz --spark-master yarn; 2019-01-09 13:35:04 WARN SparkConf:66 - The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 2019-01-09 13:35:05 WARN NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 13:35:09.640 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 13:35:09.799 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar!/com/intel/gkl/native/libgkl_compression.so; 13:35:11.507 INFO CountReadsSpark - ------------------------------------------------------------; 13:35:11.508 INFO CountReadsSpark - The Genome Analysis Toolkit (GATK) v4.0.12.0; 13:35:11.508 INFO CountReadsSpark - For support and documentation go to https://software.broadinstitute.org/gatk/; 13:35:11.508 INFO CountReadsSpark - Executing as farrell@scc-hadoop.bu.edu on Linux v2.6.32-754.6.3.el6.x86_64 amd64; 13:35:11.508 INFO CountReadsSpark - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:2282,Performance,Load,Loading,2282,"async_io_write_tribble=false -Dsamjdk.compression_level=2 /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar CountReadsSpark --input /project/casa/gcad/test/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/wgs.hg38/pipelines/hc/cram.test/GRCh38_full_analysis_set_plus_decoy_hla.fa.gz --spark-master yarn; 2019-01-09 13:35:04 WARN SparkConf:66 - The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 2019-01-09 13:35:05 WARN NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 13:35:09.640 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 13:35:09.799 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar!/com/intel/gkl/native/libgkl_compression.so; 13:35:11.507 INFO CountReadsSpark - ------------------------------------------------------------; 13:35:11.508 INFO CountReadsSpark - The Genome Analysis Toolkit (GATK) v4.0.12.0; 13:35:11.508 INFO CountReadsSpark - For support and documentation go to https://software.broadinstitute.org/gatk/; 13:35:11.508 INFO CountReadsSpark - Executing as farrell@scc-hadoop.bu.edu on Linux v2.6.32-754.6.3.el6.x86_64 amd64; 13:35:11.508 INFO CountReadsSpark - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_121-b13; 13:35:11.509 INFO CountReadsSpark - Start Date/Time: January 9, 2019 1:35:09 PM EST; 13:35:11.509 INFO CountReadsSpark - ------------------------------------------------------------; 13:35:11.509 INFO CountReadsSpark - ------------------------------------------------------------; 13:35:11.510 INFO CountReadsSpark - HTSJDK Ver",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:10359,Performance,load,loaded,10359," 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@16b64a03{/,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1584c019{/api,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5817f1ca{/jobs/job/kill,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2b395581{/stages/stage/kill,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://scc-hadoop.bu.edu:4041; 2019-01-09 13:35:12 INFO SparkContext:54 - Added JAR file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar at spark://scc-hadoop.bu.edu:42689/jars/gatk-package-4.0.12.0-spark.jar with timestamp 1547058912934; 2019-01-09 13:35:13 INFO GoogleHadoopFileSystemBase:607 - GHFS version: 1.6.3-hadoop2; 2019-01-09 13:35:13 WARN DomainSocketFactory:117 - The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.; 2019-01-09 13:35:14 INFO Client:54 - Requesting a new application from cluster with 21 NodeManagers; 2019-01-09 13:35:14 INFO Client:54 - Verifying our application has not requested more than the maximum memory capability of the cluster (204800 MB per container); 2019-01-09 13:35:14 INFO Client:54 - Will allocate AM container, with 896 MB memory including 384 MB overhead; 2019-01-09 13:35:14 INFO Client:54 - Setting up container launch context for our AM; 2019-01-09 13:35:14 INFO Client:54 - Setting up the launch environment for our AM container; 2019-01-09 13:35:14 INFO Client:54 - Preparing resources for our AM container; 2019-01-09 13:35:14 INFO HadoopFSDelegationTokenProvider:54 - getting token for: DFS[DFSClient[clientName=DFSClient_NONMAPREDUCE_-682487019_1, ugi=farrell@AD.BU.EDU (auth:KERBEROS)]]; 2019-01-09 13:35:14 INFO DFSClient:1023 - Created HDFS_DELEGATION_TOKEN token 11353 for farrell on ha-hdfs:",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:13171,Performance,queue,queue,13171,"c/user/farrell/.sparkStaging/application_1542127286896_0166/__spark_libs__7821719163562430010.zip; 2019-01-09 13:35:22 INFO Client:54 - Uploading resource file:/tmp/spark-69cc5c72-eff6-4259-8b3b-12fa6f8c42b0/__spark_conf__4520928824604875683.zip -> hdfs://scc/user/farrell/.sparkStaging/application_1542127286896_0166/__spark_conf__.zip; 2019-01-09 13:35:22 INFO SecurityManager:54 - Changing view acls to: farrell; 2019-01-09 13:35:22 INFO SecurityManager:54 - Changing modify acls to: farrell; 2019-01-09 13:35:22 INFO SecurityManager:54 - Changing view acls groups to:; 2019-01-09 13:35:22 INFO SecurityManager:54 - Changing modify acls groups to:; 2019-01-09 13:35:22 INFO SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(farrell); groups with view permissions: Set(); users with modify permissions: Set(farrell); groups with modify permissions: Set(); 2019-01-09 13:35:22 INFO Client:54 - Submitting application application_1542127286896_0166 to ResourceManager; 2019-01-09 13:35:22 INFO YarnClientImpl:251 - Submitted application application_1542127286896_0166; 2019-01-09 13:35:22 INFO SchedulerExtensionServices:54 - Starting Yarn extension services with app application_1542127286896_0166 and attemptId None; 2019-01-09 13:35:23 INFO Client:54 - Application report for application_1542127286896_0166 (state: ACCEPTED); 2019-01-09 13:35:23 INFO Client:54 -; client token: Token { kind: YARN_CLIENT_TOKEN, service: }; diagnostics: N/A; ApplicationMaster host: N/A; ApplicationMaster RPC port: -1; queue: default; start time: 1547058922320; final status: UNDEFINED; tracking URL: https://scc-hsn1.scc.bu.edu:8090/proxy/application_1542127286896_0166/; user: farrell; 2019-01-09 13:35:24 INFO Client:54 - Application report for application_1542127286896_0166 (state: ACCEPTED); 2019-01-09 13:35:25 INFO Client:54 - Application report for application_1542127286896_0166 (state: ACCEPTED); 2019-01-09 13:35:26 INFO Client:54 - Applic",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:15195,Performance,queue,queue,15195,"1-09 13:35:32 INFO Client:54 - Application report for application_1542127286896_0166 (state: ACCEPTED); 2019-01-09 13:35:33 INFO YarnClientSchedulerBackend:54 - Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> scc-hsn1.scc.bu.edu, PROXY_URI_BASES -> https://scc-hsn1.scc.bu.edu:8090/proxy/application_1542127286896_0166), /proxy/application_1542127286896_0166; 2019-01-09 13:35:33 INFO JettyUtils:54 - Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter; 2019-01-09 13:35:33 INFO YarnSchedulerBackend$YarnSchedulerEndpoint:54 - ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM); 2019-01-09 13:35:33 INFO Client:54 - Application report for application_1542127286896_0166 (state: RUNNING); 2019-01-09 13:35:33 INFO Client:54 -; client token: Token { kind: YARN_CLIENT_TOKEN, service: }; diagnostics: N/A; ApplicationMaster host: 192.168.18.195; ApplicationMaster RPC port: 0; queue: default; start time: 1547058922320; final status: UNDEFINED; tracking URL: https://scc-hsn1.scc.bu.edu:8090/proxy/application_1542127286896_0166/; user: farrell; 2019-01-09 13:35:33 INFO YarnClientSchedulerBackend:54 - Application application_1542127286896_0166 has started running.; 2019-01-09 13:35:33 INFO Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43627.; 2019-01-09 13:35:33 INFO NettyBlockTransferService:54 - Server created on scc-hadoop.bu.edu:43627; 2019-01-09 13:35:33 INFO BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy; 2019-01-09 13:35:33 INFO BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, scc-hadoop.bu.edu, 43627, None); 2019-01-09 13:35:33 INFO BlockManagerMasterEndpoint:54 - Registering block manager scc-hadoop.bu.edu:43627 with 372.6 MB RAM, BlockManagerId(driver, scc-hadoop.bu.edu, 43627, None); 2019-01-09 13:35:33 INFO BlockManagerMaster:54 - Register",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:24275,Performance,concurren,concurrent,24275,"xt(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-09 13:35:49 INFO TaskSetManager:54 - Starting task 7.0 in stage 0.0 (TID 3, scc-q01.scc.bu.edu, executor 1, partition 7, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:49 WARN TaskSetManager:66 - Lost task 2.0 in stage 0.0 (TID 1, scc-q01.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 160972515, span 170618, expected MD5 0cc5e1f5ec5c1b06d5a4bd5fff11b77f; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterato",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:24359,Performance,concurren,concurrent,24359,"r.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-09 13:35:49 INFO TaskSetManager:54 - Starting task 7.0 in stage 0.0 (TID 3, scc-q01.scc.bu.edu, executor 1, partition 7, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:49 WARN TaskSetManager:66 - Lost task 2.0 in stage 0.0 (TID 1, scc-q01.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 160972515, span 170618, expected MD5 0cc5e1f5ec5c1b06d5a4bd5fff11b77f; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:26012,Performance,concurren,concurrent,26012,"xt(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-09 13:35:50 INFO TaskSetManager:54 - Starting task 1.1 in stage 0.0 (TID 4, scc-q20.scc.bu.edu, executor 2, partition 1, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:50 WARN TaskSetManager:66 - Lost task 4.0 in stage 0.0 (TID 2, scc-q20.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 1, start 93925364, span 266689, expected MD5 54babf05a23e9e88a8738dfbb20a1683; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:26096,Performance,concurren,concurrent,26096,"r.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-09 13:35:50 INFO TaskSetManager:54 - Starting task 1.1 in stage 0.0 (TID 4, scc-q20.scc.bu.edu, executor 2, partition 1, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:50 WARN TaskSetManager:66 - Lost task 4.0 in stage 0.0 (TID 2, scc-q20.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 1, start 93925364, span 266689, expected MD5 54babf05a23e9e88a8738dfbb20a1683; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at s",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:27748,Performance,concurren,concurrent,27748,"xt(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-09 13:35:51 INFO TaskSetManager:54 - Starting task 4.1 in stage 0.0 (TID 5, scc-q20.scc.bu.edu, executor 2, partition 4, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:51 INFO TaskSetManager:54 - Lost task 1.1 in stage 0.0 (TID 4) on scc-q20.scc.bu.edu, executor 2: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae) [duplicate 1]; 2019-01-09 13:35:52 INFO TaskSetManager:54 - Starting task 2.1 in stage 0.0 (TID 6, scc-q01.scc.bu.edu, executor 1, partition 2, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:52 WARN TaskSetManager:66 - Lost task 7.0 in stage 0.0 (TID 3, scc-q01.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:27832,Performance,concurren,concurrent,27832,"r.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-09 13:35:51 INFO TaskSetManager:54 - Starting task 4.1 in stage 0.0 (TID 5, scc-q20.scc.bu.edu, executor 2, partition 4, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:51 INFO TaskSetManager:54 - Lost task 1.1 in stage 0.0 (TID 4) on scc-q20.scc.bu.edu, executor 2: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae) [duplicate 1]; 2019-01-09 13:35:52 INFO TaskSetManager:54 - Starting task 2.1 in stage 0.0 (TID 6, scc-q01.scc.bu.edu, executor 1, partition 2, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:52 WARN TaskSetManager:66 - Lost task 7.0 in stage 0.0 (TID 3, scc-q01.scc.bu.edu, executor 1): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 2, start 131325815, span 181534, expected MD5 c240a972d49aa89fb57dae94d1d90d36; a",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:29939,Performance,concurren,concurrent,29939,"xt(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-09 13:35:52 INFO TaskSetManager:54 - Starting task 1.2 in stage 0.0 (TID 7, scc-q20.scc.bu.edu, executor 2, partition 1, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:52 INFO TaskSetManager:54 - Lost task 4.1 in stage 0.0 (TID 5) on scc-q20.scc.bu.edu, executor 2: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 1, start 93925364, span 266689, expected MD5 54babf05a23e9e88a8738dfbb20a1683) [duplicate 1]; 2019-01-09 13:35:53 INFO TaskSetManager:54 - Starting task 7.1 in stage 0.0 (TID 8, scc-q01.scc.bu.edu, executor 1, partition 7, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:53 INFO TaskSetManager:54 - Lost task 2.1 in stage 0.0 (TID 6) on scc-q01.scc.bu.edu, executor 1: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequenc",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:30023,Performance,concurren,concurrent,30023,"r.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). 2019-01-09 13:35:52 INFO TaskSetManager:54 - Starting task 1.2 in stage 0.0 (TID 7, scc-q20.scc.bu.edu, executor 2, partition 1, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:52 INFO TaskSetManager:54 - Lost task 4.1 in stage 0.0 (TID 5) on scc-q20.scc.bu.edu, executor 2: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 1, start 93925364, span 266689, expected MD5 54babf05a23e9e88a8738dfbb20a1683) [duplicate 1]; 2019-01-09 13:35:53 INFO TaskSetManager:54 - Starting task 7.1 in stage 0.0 (TID 8, scc-q01.scc.bu.edu, executor 1, partition 7, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:53 INFO TaskSetManager:54 - Lost task 2.1 in stage 0.0 (TID 6) on scc-q01.scc.bu.edu, executor 1: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 0, start 160972515, span 170618, expected MD5 0cc5e1f5ec5c1b06d5a4bd5fff11b77f)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:34643,Performance,concurren,concurrent,34643,"xt(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 2019-01-09 13:35:56 INFO DAGScheduler:54 - Job 0 failed: count at CountReadsSpark.java:80, took 12.691336 s; 2019-01-09 13:35:56 INFO AbstractConnector:318 - Stopped Spark@22fda322{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-09 13:35:56 INFO SparkUI:54 - Stopped Spark web UI at http://scc-hadoop.bu.edu:4041; 2019-01-09 13:35:56 INFO YarnClientSchedulerBackend:54 - Interrupting monitor thread; 2019-01-09 13:35:56 INFO YarnClientSchedulerBackend:54 - Shutting down all executors; 2019-01-09 13:35:56 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-01-09 13:35:56 INFO SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-01-09 13:35:56 INFO YarnClientSchedulerBackend:",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:34727,Performance,concurren,concurrent,34727,"r.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 2019-01-09 13:35:56 INFO DAGScheduler:54 - Job 0 failed: count at CountReadsSpark.java:80, took 12.691336 s; 2019-01-09 13:35:56 INFO AbstractConnector:318 - Stopped Spark@22fda322{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-09 13:35:56 INFO SparkUI:54 - Stopped Spark web UI at http://scc-hadoop.bu.edu:4041; 2019-01-09 13:35:56 INFO YarnClientSchedulerBackend:54 - Interrupting monitor thread; 2019-01-09 13:35:56 INFO YarnClientSchedulerBackend:54 - Shutting down all executors; 2019-01-09 13:35:56 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-01-09 13:35:56 INFO SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-01-09 13:35:56 INFO YarnClientSchedulerBackend:54 - Stopped; 2019-01-09 13:35:56 INFO MapOutputTrackerMasterEndpoint:54 - MapOutput",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:37861,Performance,concurren,concurrent,37861,xt(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at scala.Opti,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:37945,Performance,concurren,concurrent,37945,r.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskS,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:42756,Performance,concurren,concurrent,42756,"xt(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); 2019-01-09 13:35:56 INFO ShutdownHookManager:54 - Shutdown hook called; 2019-01-09 13:35:56 INFO ShutdownHookManager:54 - Deleting directory /tmp/spark-69cc5c72-eff6-4259-8b3b-12fa6f8c42b0; 2019-01-09 13:35:56 INFO ShutdownHookManager:54 - Deleting directory /tmp/spark-0bd07e00-4f6d-43bd-b9d2-b1999376c72b; ```. Just to verify, the non-spark version still runs fine with the compressed fasta.... ```; gatk CountReads --input HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference GRCh38_full_analysis_set_plus_decoy_hla.fa.gz; Using GATK jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /shar",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:42840,Performance,concurren,concurrent,42840,"r.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); 2019-01-09 13:35:56 INFO ShutdownHookManager:54 - Shutdown hook called; 2019-01-09 13:35:56 INFO ShutdownHookManager:54 - Deleting directory /tmp/spark-69cc5c72-eff6-4259-8b3b-12fa6f8c42b0; 2019-01-09 13:35:56 INFO ShutdownHookManager:54 - Deleting directory /tmp/spark-0bd07e00-4f6d-43bd-b9d2-b1999376c72b; ```. Just to verify, the non-spark version still runs fine with the compressed fasta.... ```; gatk CountReads --input HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference GRCh38_full_analysis_set_plus_decoy_hla.fa.gz; Using GATK jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-local.jar CountReads --input H",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:44003,Performance,Load,Loading,44003,"- Shutdown hook called; 2019-01-09 13:35:56 INFO ShutdownHookManager:54 - Deleting directory /tmp/spark-69cc5c72-eff6-4259-8b3b-12fa6f8c42b0; 2019-01-09 13:35:56 INFO ShutdownHookManager:54 - Deleting directory /tmp/spark-0bd07e00-4f6d-43bd-b9d2-b1999376c72b; ```. Just to verify, the non-spark version still runs fine with the compressed fasta.... ```; gatk CountReads --input HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference GRCh38_full_analysis_set_plus_decoy_hla.fa.gz; Using GATK jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-local.jar CountReads --input HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference GRCh38_full_analysis_set_plus_decoy_hla.fa.gz; 13:38:54.168 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 13:38:55.869 INFO CountReads - ------------------------------------------------------------; 13:38:55.870 INFO CountReads - The Genome Analysis Toolkit (GATK) v4.0.12.0; 13:38:55.870 INFO CountReads - For support and documentation go to https://software.broadinstitute.org/gatk/; 13:38:55.871 INFO CountReads - Executing as farrell@scc-hadoop.bu.edu on Linux v2.6.32-754.6.3.el6.x86_64 amd64; 13:38:55.871 INFO CountReads - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_121-b13; 13:38:55.871 INFO CountReads - Start Date/Time: January 9, 2019 1:38:54 PM EST; 13:38:55.871 INFO CountReads - ------------------------------------------------------------; 13:38:55.871 INFO CountReads - ------------------------------------------------------------; 13:38:55.872 INFO CountReads - HTSJDK Version: 2.18.1; 13:38:55.873 INFO CountReads - ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:32948,Safety,abort,aborting,32948,"u.edu, executor 2, partition 1, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:54 INFO TaskSetManager:54 - Lost task 4.2 in stage 0.0 (TID 9) on scc-q20.scc.bu.edu, executor 2: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 1, start 93925364, span 266689, expected MD5 54babf05a23e9e88a8738dfbb20a1683) [duplicate 2]; 2019-01-09 13:35:56 INFO TaskSetManager:54 - Starting task 4.3 in stage 0.0 (TID 12, scc-q20.scc.bu.edu, executor 2, partition 4, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:56 INFO TaskSetManager:54 - Lost task 1.3 in stage 0.0 (TID 11) on scc-q20.scc.bu.edu, executor 2: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae) [duplicate 3]; 2019-01-09 13:35:56 ERROR TaskSetManager:70 - Task 1 in stage 0.0 failed 4 times; aborting job; 2019-01-09 13:35:56 INFO YarnScheduler:54 - Cancelling stage 0; 2019-01-09 13:35:56 INFO YarnScheduler:54 - Stage 0 was cancelled; 2019-01-09 13:35:56 INFO DAGScheduler:54 - ResultStage 0 (count at CountReadsSpark.java:80) failed in 12.543 s due to Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 11, scc-q20.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:33215,Safety,abort,aborted,33215,"k.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 1, start 93925364, span 266689, expected MD5 54babf05a23e9e88a8738dfbb20a1683) [duplicate 2]; 2019-01-09 13:35:56 INFO TaskSetManager:54 - Starting task 4.3 in stage 0.0 (TID 12, scc-q20.scc.bu.edu, executor 2, partition 4, NODE_LOCAL, 7992 bytes); 2019-01-09 13:35:56 INFO TaskSetManager:54 - Lost task 1.3 in stage 0.0 (TID 11) on scc-q20.scc.bu.edu, executor 2: htsjdk.samtools.cram.CRAMException (Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae) [duplicate 3]; 2019-01-09 13:35:56 ERROR TaskSetManager:70 - Task 1 in stage 0.0 failed 4 times; aborting job; 2019-01-09 13:35:56 INFO YarnScheduler:54 - Cancelling stage 0; 2019-01-09 13:35:56 INFO YarnScheduler:54 - Stage 0 was cancelled; 2019-01-09 13:35:56 INFO DAGScheduler:54 - ResultStage 0 (count at CountReadsSpark.java:80) failed in 12.543 s due to Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 11, scc-q20.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:36433,Safety,abort,aborted,36433,"2019-01-09 13:35:56 INFO SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-01-09 13:35:56 INFO YarnClientSchedulerBackend:54 - Stopped; 2019-01-09 13:35:56 INFO MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!; 2019-01-09 13:35:56 INFO MemoryStore:54 - MemoryStore cleared; 2019-01-09 13:35:56 INFO BlockManager:54 - BlockManager stopped; 2019-01-09 13:35:56 INFO BlockManagerMaster:54 - BlockManagerMaster stopped; 2019-01-09 13:35:56 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-01-09 13:35:56 INFO SparkContext:54 - Successfully stopped SparkContext; 13:35:56.383 INFO CountReadsSpark - Shutting down engine; [January 9, 2019 1:35:56 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.78 minutes.; Runtime.totalMemory()=1009254400; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 11, scc-q20.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: sequence id 0, start 87545719, span 186383, expected MD5 492a29f6d7d6fcaf8dde06834861e7ae; at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:184); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:258); at org.disq_bio.disq.impl.formats.AutocloseIteratorWrapper.hasNext(AutocloseIteratorWrapper.java:52); at scala.collection.convert.Wrappers$JIteratorWrapper.hasNext(Wrappers.scala:42); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonf",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:38268,Safety,abort,abortStage,38268,or.scala:461); at org.apache.spark.util.Utils$.getIteratorSize(Utils.scala:1833); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:38365,Safety,abort,abortStage,38365,park.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.rdd.RDD$$anonfun$count$1.apply(RDD.scala:1162); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.SparkContext$$anonfun$runJob$5.apply(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.s,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:38607,Safety,abort,abortStage,38607,y(SparkContext.scala:2067); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87); at org.apache.spark.scheduler.Task.run(Task.scala:109); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:345); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1599); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587); at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1586); at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48); at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1586); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:831); at scala.Option.foreach(Option.scala:257); at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:831); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1820); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1769); at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1758); at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:642); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2027); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2048); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2067); at org,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:4734,Security,Secur,SecurityManager,4734,!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: CountReadsSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 13:35:11.512 INFO CountReadsSpark - Initializing engine; 13:35:11.512 INFO CountReadsSpark - Done initializing engine; 2019-01-09 13:35:11 WARN SparkConf:66 - The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 2019-01-09 13:35:11 INFO SparkContext:54 - Running Spark version 2.3.0; 2019-01-09 13:35:11 INFO SparkContext:54 - Submitted application: CountReadsSpark; 2019-01-09 13:35:11 INFO SecurityManager:54 - Changing view acls to: farrell; 2019-01-09 13:35:11 INFO SecurityManager:54 - Changing modify acls to: farrell; 2019-01-09 13:35:11 INFO SecurityManager:54 - Changing view acls groups to:; 2019-01-09 13:35:11 INFO SecurityManager:54 - Changing modify acls groups to:; 2019-01-09 13:35:11 INFO SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(farrell); groups with view permissions: Set(); users with modify permissions: Set(farrell); groups with modify permissions: Set(); 2019-01-09 13:35:12 INFO Utils:54 - Successfully started service 'sparkDriver' on port 42689.; 2019-01-09 13:35:12 INFO SparkEnv:54 - Registering MapOutputTracker; 2019-01-09 13:35:12 INFO SparkEnv:54 - Registering BlockManagerMaster; 2019-01-09 13:35:12 INFO BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 2019-01-09 13:35:12 INFO BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up; 2019-01-09 13:35:12 INFO DiskBlockManager:54 - Created local directory at /tmp/blockmgr-dd94d6fb-7e3d-4def-a895-6e60f05d7a05; 2019-01-09 13:35:12 INFO MemoryStore:54 - MemoryStore started with capacity 372.6 MB; 2019-01-09 13:35:12 INFO SparkEnv,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:4812,Security,Secur,SecurityManager,4812,!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: CountReadsSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 13:35:11.512 INFO CountReadsSpark - Initializing engine; 13:35:11.512 INFO CountReadsSpark - Done initializing engine; 2019-01-09 13:35:11 WARN SparkConf:66 - The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 2019-01-09 13:35:11 INFO SparkContext:54 - Running Spark version 2.3.0; 2019-01-09 13:35:11 INFO SparkContext:54 - Submitted application: CountReadsSpark; 2019-01-09 13:35:11 INFO SecurityManager:54 - Changing view acls to: farrell; 2019-01-09 13:35:11 INFO SecurityManager:54 - Changing modify acls to: farrell; 2019-01-09 13:35:11 INFO SecurityManager:54 - Changing view acls groups to:; 2019-01-09 13:35:11 INFO SecurityManager:54 - Changing modify acls groups to:; 2019-01-09 13:35:11 INFO SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(farrell); groups with view permissions: Set(); users with modify permissions: Set(farrell); groups with modify permissions: Set(); 2019-01-09 13:35:12 INFO Utils:54 - Successfully started service 'sparkDriver' on port 42689.; 2019-01-09 13:35:12 INFO SparkEnv:54 - Registering MapOutputTracker; 2019-01-09 13:35:12 INFO SparkEnv:54 - Registering BlockManagerMaster; 2019-01-09 13:35:12 INFO BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 2019-01-09 13:35:12 INFO BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up; 2019-01-09 13:35:12 INFO DiskBlockManager:54 - Created local directory at /tmp/blockmgr-dd94d6fb-7e3d-4def-a895-6e60f05d7a05; 2019-01-09 13:35:12 INFO MemoryStore:54 - MemoryStore started with capacity 372.6 MB; 2019-01-09 13:35:12 INFO SparkEnv,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:4892,Security,Secur,SecurityManager,4892,!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: CountReadsSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 13:35:11.512 INFO CountReadsSpark - Initializing engine; 13:35:11.512 INFO CountReadsSpark - Done initializing engine; 2019-01-09 13:35:11 WARN SparkConf:66 - The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 2019-01-09 13:35:11 INFO SparkContext:54 - Running Spark version 2.3.0; 2019-01-09 13:35:11 INFO SparkContext:54 - Submitted application: CountReadsSpark; 2019-01-09 13:35:11 INFO SecurityManager:54 - Changing view acls to: farrell; 2019-01-09 13:35:11 INFO SecurityManager:54 - Changing modify acls to: farrell; 2019-01-09 13:35:11 INFO SecurityManager:54 - Changing view acls groups to:; 2019-01-09 13:35:11 INFO SecurityManager:54 - Changing modify acls groups to:; 2019-01-09 13:35:11 INFO SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(farrell); groups with view permissions: Set(); users with modify permissions: Set(farrell); groups with modify permissions: Set(); 2019-01-09 13:35:12 INFO Utils:54 - Successfully started service 'sparkDriver' on port 42689.; 2019-01-09 13:35:12 INFO SparkEnv:54 - Registering MapOutputTracker; 2019-01-09 13:35:12 INFO SparkEnv:54 - Registering BlockManagerMaster; 2019-01-09 13:35:12 INFO BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 2019-01-09 13:35:12 INFO BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up; 2019-01-09 13:35:12 INFO DiskBlockManager:54 - Created local directory at /tmp/blockmgr-dd94d6fb-7e3d-4def-a895-6e60f05d7a05; 2019-01-09 13:35:12 INFO MemoryStore:54 - MemoryStore started with capacity 372.6 MB; 2019-01-09 13:35:12 INFO SparkEnv,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:4969,Security,Secur,SecurityManager,4969,!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: CountReadsSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 13:35:11.512 INFO CountReadsSpark - Initializing engine; 13:35:11.512 INFO CountReadsSpark - Done initializing engine; 2019-01-09 13:35:11 WARN SparkConf:66 - The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 2019-01-09 13:35:11 INFO SparkContext:54 - Running Spark version 2.3.0; 2019-01-09 13:35:11 INFO SparkContext:54 - Submitted application: CountReadsSpark; 2019-01-09 13:35:11 INFO SecurityManager:54 - Changing view acls to: farrell; 2019-01-09 13:35:11 INFO SecurityManager:54 - Changing modify acls to: farrell; 2019-01-09 13:35:11 INFO SecurityManager:54 - Changing view acls groups to:; 2019-01-09 13:35:11 INFO SecurityManager:54 - Changing modify acls groups to:; 2019-01-09 13:35:11 INFO SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(farrell); groups with view permissions: Set(); users with modify permissions: Set(farrell); groups with modify permissions: Set(); 2019-01-09 13:35:12 INFO Utils:54 - Successfully started service 'sparkDriver' on port 42689.; 2019-01-09 13:35:12 INFO SparkEnv:54 - Registering MapOutputTracker; 2019-01-09 13:35:12 INFO SparkEnv:54 - Registering BlockManagerMaster; 2019-01-09 13:35:12 INFO BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 2019-01-09 13:35:12 INFO BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up; 2019-01-09 13:35:12 INFO DiskBlockManager:54 - Created local directory at /tmp/blockmgr-dd94d6fb-7e3d-4def-a895-6e60f05d7a05; 2019-01-09 13:35:12 INFO MemoryStore:54 - MemoryStore started with capacity 372.6 MB; 2019-01-09 13:35:12 INFO SparkEnv,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:5048,Security,Secur,SecurityManager,5048,!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: CountReadsSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 13:35:11.512 INFO CountReadsSpark - Initializing engine; 13:35:11.512 INFO CountReadsSpark - Done initializing engine; 2019-01-09 13:35:11 WARN SparkConf:66 - The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 2019-01-09 13:35:11 INFO SparkContext:54 - Running Spark version 2.3.0; 2019-01-09 13:35:11 INFO SparkContext:54 - Submitted application: CountReadsSpark; 2019-01-09 13:35:11 INFO SecurityManager:54 - Changing view acls to: farrell; 2019-01-09 13:35:11 INFO SecurityManager:54 - Changing modify acls to: farrell; 2019-01-09 13:35:11 INFO SecurityManager:54 - Changing view acls groups to:; 2019-01-09 13:35:11 INFO SecurityManager:54 - Changing modify acls groups to:; 2019-01-09 13:35:11 INFO SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(farrell); groups with view permissions: Set(); users with modify permissions: Set(farrell); groups with modify permissions: Set(); 2019-01-09 13:35:12 INFO Utils:54 - Successfully started service 'sparkDriver' on port 42689.; 2019-01-09 13:35:12 INFO SparkEnv:54 - Registering MapOutputTracker; 2019-01-09 13:35:12 INFO SparkEnv:54 - Registering BlockManagerMaster; 2019-01-09 13:35:12 INFO BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 2019-01-09 13:35:12 INFO BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up; 2019-01-09 13:35:12 INFO DiskBlockManager:54 - Created local directory at /tmp/blockmgr-dd94d6fb-7e3d-4def-a895-6e60f05d7a05; 2019-01-09 13:35:12 INFO MemoryStore:54 - MemoryStore started with capacity 372.6 MB; 2019-01-09 13:35:12 INFO SparkEnv,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:5069,Security,Secur,SecurityManager,5069,!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: CountReadsSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 13:35:11.512 INFO CountReadsSpark - Initializing engine; 13:35:11.512 INFO CountReadsSpark - Done initializing engine; 2019-01-09 13:35:11 WARN SparkConf:66 - The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 2019-01-09 13:35:11 INFO SparkContext:54 - Running Spark version 2.3.0; 2019-01-09 13:35:11 INFO SparkContext:54 - Submitted application: CountReadsSpark; 2019-01-09 13:35:11 INFO SecurityManager:54 - Changing view acls to: farrell; 2019-01-09 13:35:11 INFO SecurityManager:54 - Changing modify acls to: farrell; 2019-01-09 13:35:11 INFO SecurityManager:54 - Changing view acls groups to:; 2019-01-09 13:35:11 INFO SecurityManager:54 - Changing modify acls groups to:; 2019-01-09 13:35:11 INFO SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(farrell); groups with view permissions: Set(); users with modify permissions: Set(farrell); groups with modify permissions: Set(); 2019-01-09 13:35:12 INFO Utils:54 - Successfully started service 'sparkDriver' on port 42689.; 2019-01-09 13:35:12 INFO SparkEnv:54 - Registering MapOutputTracker; 2019-01-09 13:35:12 INFO SparkEnv:54 - Registering BlockManagerMaster; 2019-01-09 13:35:12 INFO BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 2019-01-09 13:35:12 INFO BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up; 2019-01-09 13:35:12 INFO DiskBlockManager:54 - Created local directory at /tmp/blockmgr-dd94d6fb-7e3d-4def-a895-6e60f05d7a05; 2019-01-09 13:35:12 INFO MemoryStore:54 - MemoryStore started with capacity 372.6 MB; 2019-01-09 13:35:12 INFO SparkEnv,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:5086,Security,authenticat,authentication,5086,!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: CountReadsSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 13:35:11.512 INFO CountReadsSpark - Initializing engine; 13:35:11.512 INFO CountReadsSpark - Done initializing engine; 2019-01-09 13:35:11 WARN SparkConf:66 - The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 2019-01-09 13:35:11 INFO SparkContext:54 - Running Spark version 2.3.0; 2019-01-09 13:35:11 INFO SparkContext:54 - Submitted application: CountReadsSpark; 2019-01-09 13:35:11 INFO SecurityManager:54 - Changing view acls to: farrell; 2019-01-09 13:35:11 INFO SecurityManager:54 - Changing modify acls to: farrell; 2019-01-09 13:35:11 INFO SecurityManager:54 - Changing view acls groups to:; 2019-01-09 13:35:11 INFO SecurityManager:54 - Changing modify acls groups to:; 2019-01-09 13:35:11 INFO SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(farrell); groups with view permissions: Set(); users with modify permissions: Set(farrell); groups with modify permissions: Set(); 2019-01-09 13:35:12 INFO Utils:54 - Successfully started service 'sparkDriver' on port 42689.; 2019-01-09 13:35:12 INFO SparkEnv:54 - Registering MapOutputTracker; 2019-01-09 13:35:12 INFO SparkEnv:54 - Registering BlockManagerMaster; 2019-01-09 13:35:12 INFO BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 2019-01-09 13:35:12 INFO BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up; 2019-01-09 13:35:12 INFO DiskBlockManager:54 - Created local directory at /tmp/blockmgr-dd94d6fb-7e3d-4def-a895-6e60f05d7a05; 2019-01-09 13:35:12 INFO MemoryStore:54 - MemoryStore started with capacity 372.6 MB; 2019-01-09 13:35:12 INFO SparkEnv,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:11965,Security,Secur,SecurityManager,11965,"c/user/farrell/.sparkStaging/application_1542127286896_0166/__spark_libs__7821719163562430010.zip; 2019-01-09 13:35:22 INFO Client:54 - Uploading resource file:/tmp/spark-69cc5c72-eff6-4259-8b3b-12fa6f8c42b0/__spark_conf__4520928824604875683.zip -> hdfs://scc/user/farrell/.sparkStaging/application_1542127286896_0166/__spark_conf__.zip; 2019-01-09 13:35:22 INFO SecurityManager:54 - Changing view acls to: farrell; 2019-01-09 13:35:22 INFO SecurityManager:54 - Changing modify acls to: farrell; 2019-01-09 13:35:22 INFO SecurityManager:54 - Changing view acls groups to:; 2019-01-09 13:35:22 INFO SecurityManager:54 - Changing modify acls groups to:; 2019-01-09 13:35:22 INFO SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(farrell); groups with view permissions: Set(); users with modify permissions: Set(farrell); groups with modify permissions: Set(); 2019-01-09 13:35:22 INFO Client:54 - Submitting application application_1542127286896_0166 to ResourceManager; 2019-01-09 13:35:22 INFO YarnClientImpl:251 - Submitted application application_1542127286896_0166; 2019-01-09 13:35:22 INFO SchedulerExtensionServices:54 - Starting Yarn extension services with app application_1542127286896_0166 and attemptId None; 2019-01-09 13:35:23 INFO Client:54 - Application report for application_1542127286896_0166 (state: ACCEPTED); 2019-01-09 13:35:23 INFO Client:54 -; client token: Token { kind: YARN_CLIENT_TOKEN, service: }; diagnostics: N/A; ApplicationMaster host: N/A; ApplicationMaster RPC port: -1; queue: default; start time: 1547058922320; final status: UNDEFINED; tracking URL: https://scc-hsn1.scc.bu.edu:8090/proxy/application_1542127286896_0166/; user: farrell; 2019-01-09 13:35:24 INFO Client:54 - Application report for application_1542127286896_0166 (state: ACCEPTED); 2019-01-09 13:35:25 INFO Client:54 - Application report for application_1542127286896_0166 (state: ACCEPTED); 2019-01-09 13:35:26 INFO Client:54 - Applic",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:12043,Security,Secur,SecurityManager,12043,"c/user/farrell/.sparkStaging/application_1542127286896_0166/__spark_libs__7821719163562430010.zip; 2019-01-09 13:35:22 INFO Client:54 - Uploading resource file:/tmp/spark-69cc5c72-eff6-4259-8b3b-12fa6f8c42b0/__spark_conf__4520928824604875683.zip -> hdfs://scc/user/farrell/.sparkStaging/application_1542127286896_0166/__spark_conf__.zip; 2019-01-09 13:35:22 INFO SecurityManager:54 - Changing view acls to: farrell; 2019-01-09 13:35:22 INFO SecurityManager:54 - Changing modify acls to: farrell; 2019-01-09 13:35:22 INFO SecurityManager:54 - Changing view acls groups to:; 2019-01-09 13:35:22 INFO SecurityManager:54 - Changing modify acls groups to:; 2019-01-09 13:35:22 INFO SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(farrell); groups with view permissions: Set(); users with modify permissions: Set(farrell); groups with modify permissions: Set(); 2019-01-09 13:35:22 INFO Client:54 - Submitting application application_1542127286896_0166 to ResourceManager; 2019-01-09 13:35:22 INFO YarnClientImpl:251 - Submitted application application_1542127286896_0166; 2019-01-09 13:35:22 INFO SchedulerExtensionServices:54 - Starting Yarn extension services with app application_1542127286896_0166 and attemptId None; 2019-01-09 13:35:23 INFO Client:54 - Application report for application_1542127286896_0166 (state: ACCEPTED); 2019-01-09 13:35:23 INFO Client:54 -; client token: Token { kind: YARN_CLIENT_TOKEN, service: }; diagnostics: N/A; ApplicationMaster host: N/A; ApplicationMaster RPC port: -1; queue: default; start time: 1547058922320; final status: UNDEFINED; tracking URL: https://scc-hsn1.scc.bu.edu:8090/proxy/application_1542127286896_0166/; user: farrell; 2019-01-09 13:35:24 INFO Client:54 - Application report for application_1542127286896_0166 (state: ACCEPTED); 2019-01-09 13:35:25 INFO Client:54 - Application report for application_1542127286896_0166 (state: ACCEPTED); 2019-01-09 13:35:26 INFO Client:54 - Applic",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:12123,Security,Secur,SecurityManager,12123,"c/user/farrell/.sparkStaging/application_1542127286896_0166/__spark_libs__7821719163562430010.zip; 2019-01-09 13:35:22 INFO Client:54 - Uploading resource file:/tmp/spark-69cc5c72-eff6-4259-8b3b-12fa6f8c42b0/__spark_conf__4520928824604875683.zip -> hdfs://scc/user/farrell/.sparkStaging/application_1542127286896_0166/__spark_conf__.zip; 2019-01-09 13:35:22 INFO SecurityManager:54 - Changing view acls to: farrell; 2019-01-09 13:35:22 INFO SecurityManager:54 - Changing modify acls to: farrell; 2019-01-09 13:35:22 INFO SecurityManager:54 - Changing view acls groups to:; 2019-01-09 13:35:22 INFO SecurityManager:54 - Changing modify acls groups to:; 2019-01-09 13:35:22 INFO SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(farrell); groups with view permissions: Set(); users with modify permissions: Set(farrell); groups with modify permissions: Set(); 2019-01-09 13:35:22 INFO Client:54 - Submitting application application_1542127286896_0166 to ResourceManager; 2019-01-09 13:35:22 INFO YarnClientImpl:251 - Submitted application application_1542127286896_0166; 2019-01-09 13:35:22 INFO SchedulerExtensionServices:54 - Starting Yarn extension services with app application_1542127286896_0166 and attemptId None; 2019-01-09 13:35:23 INFO Client:54 - Application report for application_1542127286896_0166 (state: ACCEPTED); 2019-01-09 13:35:23 INFO Client:54 -; client token: Token { kind: YARN_CLIENT_TOKEN, service: }; diagnostics: N/A; ApplicationMaster host: N/A; ApplicationMaster RPC port: -1; queue: default; start time: 1547058922320; final status: UNDEFINED; tracking URL: https://scc-hsn1.scc.bu.edu:8090/proxy/application_1542127286896_0166/; user: farrell; 2019-01-09 13:35:24 INFO Client:54 - Application report for application_1542127286896_0166 (state: ACCEPTED); 2019-01-09 13:35:25 INFO Client:54 - Application report for application_1542127286896_0166 (state: ACCEPTED); 2019-01-09 13:35:26 INFO Client:54 - Applic",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:12200,Security,Secur,SecurityManager,12200,"c/user/farrell/.sparkStaging/application_1542127286896_0166/__spark_libs__7821719163562430010.zip; 2019-01-09 13:35:22 INFO Client:54 - Uploading resource file:/tmp/spark-69cc5c72-eff6-4259-8b3b-12fa6f8c42b0/__spark_conf__4520928824604875683.zip -> hdfs://scc/user/farrell/.sparkStaging/application_1542127286896_0166/__spark_conf__.zip; 2019-01-09 13:35:22 INFO SecurityManager:54 - Changing view acls to: farrell; 2019-01-09 13:35:22 INFO SecurityManager:54 - Changing modify acls to: farrell; 2019-01-09 13:35:22 INFO SecurityManager:54 - Changing view acls groups to:; 2019-01-09 13:35:22 INFO SecurityManager:54 - Changing modify acls groups to:; 2019-01-09 13:35:22 INFO SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(farrell); groups with view permissions: Set(); users with modify permissions: Set(farrell); groups with modify permissions: Set(); 2019-01-09 13:35:22 INFO Client:54 - Submitting application application_1542127286896_0166 to ResourceManager; 2019-01-09 13:35:22 INFO YarnClientImpl:251 - Submitted application application_1542127286896_0166; 2019-01-09 13:35:22 INFO SchedulerExtensionServices:54 - Starting Yarn extension services with app application_1542127286896_0166 and attemptId None; 2019-01-09 13:35:23 INFO Client:54 - Application report for application_1542127286896_0166 (state: ACCEPTED); 2019-01-09 13:35:23 INFO Client:54 -; client token: Token { kind: YARN_CLIENT_TOKEN, service: }; diagnostics: N/A; ApplicationMaster host: N/A; ApplicationMaster RPC port: -1; queue: default; start time: 1547058922320; final status: UNDEFINED; tracking URL: https://scc-hsn1.scc.bu.edu:8090/proxy/application_1542127286896_0166/; user: farrell; 2019-01-09 13:35:24 INFO Client:54 - Application report for application_1542127286896_0166 (state: ACCEPTED); 2019-01-09 13:35:25 INFO Client:54 - Application report for application_1542127286896_0166 (state: ACCEPTED); 2019-01-09 13:35:26 INFO Client:54 - Applic",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:12279,Security,Secur,SecurityManager,12279,"c/user/farrell/.sparkStaging/application_1542127286896_0166/__spark_libs__7821719163562430010.zip; 2019-01-09 13:35:22 INFO Client:54 - Uploading resource file:/tmp/spark-69cc5c72-eff6-4259-8b3b-12fa6f8c42b0/__spark_conf__4520928824604875683.zip -> hdfs://scc/user/farrell/.sparkStaging/application_1542127286896_0166/__spark_conf__.zip; 2019-01-09 13:35:22 INFO SecurityManager:54 - Changing view acls to: farrell; 2019-01-09 13:35:22 INFO SecurityManager:54 - Changing modify acls to: farrell; 2019-01-09 13:35:22 INFO SecurityManager:54 - Changing view acls groups to:; 2019-01-09 13:35:22 INFO SecurityManager:54 - Changing modify acls groups to:; 2019-01-09 13:35:22 INFO SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(farrell); groups with view permissions: Set(); users with modify permissions: Set(farrell); groups with modify permissions: Set(); 2019-01-09 13:35:22 INFO Client:54 - Submitting application application_1542127286896_0166 to ResourceManager; 2019-01-09 13:35:22 INFO YarnClientImpl:251 - Submitted application application_1542127286896_0166; 2019-01-09 13:35:22 INFO SchedulerExtensionServices:54 - Starting Yarn extension services with app application_1542127286896_0166 and attemptId None; 2019-01-09 13:35:23 INFO Client:54 - Application report for application_1542127286896_0166 (state: ACCEPTED); 2019-01-09 13:35:23 INFO Client:54 -; client token: Token { kind: YARN_CLIENT_TOKEN, service: }; diagnostics: N/A; ApplicationMaster host: N/A; ApplicationMaster RPC port: -1; queue: default; start time: 1547058922320; final status: UNDEFINED; tracking URL: https://scc-hsn1.scc.bu.edu:8090/proxy/application_1542127286896_0166/; user: farrell; 2019-01-09 13:35:24 INFO Client:54 - Application report for application_1542127286896_0166 (state: ACCEPTED); 2019-01-09 13:35:25 INFO Client:54 - Application report for application_1542127286896_0166 (state: ACCEPTED); 2019-01-09 13:35:26 INFO Client:54 - Applic",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:12300,Security,Secur,SecurityManager,12300,"c/user/farrell/.sparkStaging/application_1542127286896_0166/__spark_libs__7821719163562430010.zip; 2019-01-09 13:35:22 INFO Client:54 - Uploading resource file:/tmp/spark-69cc5c72-eff6-4259-8b3b-12fa6f8c42b0/__spark_conf__4520928824604875683.zip -> hdfs://scc/user/farrell/.sparkStaging/application_1542127286896_0166/__spark_conf__.zip; 2019-01-09 13:35:22 INFO SecurityManager:54 - Changing view acls to: farrell; 2019-01-09 13:35:22 INFO SecurityManager:54 - Changing modify acls to: farrell; 2019-01-09 13:35:22 INFO SecurityManager:54 - Changing view acls groups to:; 2019-01-09 13:35:22 INFO SecurityManager:54 - Changing modify acls groups to:; 2019-01-09 13:35:22 INFO SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(farrell); groups with view permissions: Set(); users with modify permissions: Set(farrell); groups with modify permissions: Set(); 2019-01-09 13:35:22 INFO Client:54 - Submitting application application_1542127286896_0166 to ResourceManager; 2019-01-09 13:35:22 INFO YarnClientImpl:251 - Submitted application application_1542127286896_0166; 2019-01-09 13:35:22 INFO SchedulerExtensionServices:54 - Starting Yarn extension services with app application_1542127286896_0166 and attemptId None; 2019-01-09 13:35:23 INFO Client:54 - Application report for application_1542127286896_0166 (state: ACCEPTED); 2019-01-09 13:35:23 INFO Client:54 -; client token: Token { kind: YARN_CLIENT_TOKEN, service: }; diagnostics: N/A; ApplicationMaster host: N/A; ApplicationMaster RPC port: -1; queue: default; start time: 1547058922320; final status: UNDEFINED; tracking URL: https://scc-hsn1.scc.bu.edu:8090/proxy/application_1542127286896_0166/; user: farrell; 2019-01-09 13:35:24 INFO Client:54 - Application report for application_1542127286896_0166 (state: ACCEPTED); 2019-01-09 13:35:25 INFO Client:54 - Application report for application_1542127286896_0166 (state: ACCEPTED); 2019-01-09 13:35:26 INFO Client:54 - Applic",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:12317,Security,authenticat,authentication,12317,"c/user/farrell/.sparkStaging/application_1542127286896_0166/__spark_libs__7821719163562430010.zip; 2019-01-09 13:35:22 INFO Client:54 - Uploading resource file:/tmp/spark-69cc5c72-eff6-4259-8b3b-12fa6f8c42b0/__spark_conf__4520928824604875683.zip -> hdfs://scc/user/farrell/.sparkStaging/application_1542127286896_0166/__spark_conf__.zip; 2019-01-09 13:35:22 INFO SecurityManager:54 - Changing view acls to: farrell; 2019-01-09 13:35:22 INFO SecurityManager:54 - Changing modify acls to: farrell; 2019-01-09 13:35:22 INFO SecurityManager:54 - Changing view acls groups to:; 2019-01-09 13:35:22 INFO SecurityManager:54 - Changing modify acls groups to:; 2019-01-09 13:35:22 INFO SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(farrell); groups with view permissions: Set(); users with modify permissions: Set(farrell); groups with modify permissions: Set(); 2019-01-09 13:35:22 INFO Client:54 - Submitting application application_1542127286896_0166 to ResourceManager; 2019-01-09 13:35:22 INFO YarnClientImpl:251 - Submitted application application_1542127286896_0166; 2019-01-09 13:35:22 INFO SchedulerExtensionServices:54 - Starting Yarn extension services with app application_1542127286896_0166 and attemptId None; 2019-01-09 13:35:23 INFO Client:54 - Application report for application_1542127286896_0166 (state: ACCEPTED); 2019-01-09 13:35:23 INFO Client:54 -; client token: Token { kind: YARN_CLIENT_TOKEN, service: }; diagnostics: N/A; ApplicationMaster host: N/A; ApplicationMaster RPC port: -1; queue: default; start time: 1547058922320; final status: UNDEFINED; tracking URL: https://scc-hsn1.scc.bu.edu:8090/proxy/application_1542127286896_0166/; user: farrell; 2019-01-09 13:35:24 INFO Client:54 - Application report for application_1542127286896_0166 (state: ACCEPTED); 2019-01-09 13:35:25 INFO Client:54 - Application report for application_1542127286896_0166 (state: ACCEPTED); 2019-01-09 13:35:26 INFO Client:54 - Applic",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:269,Testability,test,test,269,"@tomwhite . I tried rerunning the job using a bgzip reference to work around the problem. However, the same error is being generated (htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice). . ```; gatk CountReadsSpark --input /project/casa/gcad/test/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/wgs.hg38/pipelines/hc/cram.test/GRCh38_full_analysis_set_plus_decoy_hla.fa.gz -- --spark-runner SPARK --spark-master yarn. Using GATK jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar; Running:; /share/pkg/spark/2.3.0/install/bin/spark-submit --master yarn --conf spark.kryoserializer.buffer.max=512m --conf spark.driver.maxResultSize=0 --conf spark.driver.userClassPathFirst=false --conf spark.io.compression.codec=lzf --conf spark.yarn.executor.memoryOverhead=600 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar CountReadsSpark --input /project/casa/gcad/test/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/wgs.hg38/pipelines/hc/cram.test/GRCh38_full_analysis_set_plus_decoy_hla.fa.gz --spark-master yarn; 2019-01-09 13:35:04 WARN SparkConf:66 - The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 2019-01-09 13:35:05 WARN NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... usi",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:406,Testability,test,test,406,"@tomwhite . I tried rerunning the job using a bgzip reference to work around the problem. However, the same error is being generated (htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice). . ```; gatk CountReadsSpark --input /project/casa/gcad/test/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/wgs.hg38/pipelines/hc/cram.test/GRCh38_full_analysis_set_plus_decoy_hla.fa.gz -- --spark-runner SPARK --spark-master yarn. Using GATK jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar; Running:; /share/pkg/spark/2.3.0/install/bin/spark-submit --master yarn --conf spark.kryoserializer.buffer.max=512m --conf spark.driver.maxResultSize=0 --conf spark.driver.userClassPathFirst=false --conf spark.io.compression.codec=lzf --conf spark.yarn.executor.memoryOverhead=600 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar CountReadsSpark --input /project/casa/gcad/test/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/wgs.hg38/pipelines/hc/cram.test/GRCh38_full_analysis_set_plus_decoy_hla.fa.gz --spark-master yarn; 2019-01-09 13:35:04 WARN SparkConf:66 - The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 2019-01-09 13:35:05 WARN NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... usi",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:1450,Testability,test,test,1450,et_plus_decoy_hla.fa.gz -- --spark-runner SPARK --spark-master yarn. Using GATK jar /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar; Running:; /share/pkg/spark/2.3.0/install/bin/spark-submit --master yarn --conf spark.kryoserializer.buffer.max=512m --conf spark.driver.maxResultSize=0 --conf spark.driver.userClassPathFirst=false --conf spark.io.compression.codec=lzf --conf spark.yarn.executor.memoryOverhead=600 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar CountReadsSpark --input /project/casa/gcad/test/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/wgs.hg38/pipelines/hc/cram.test/GRCh38_full_analysis_set_plus_decoy_hla.fa.gz --spark-master yarn; 2019-01-09 13:35:04 WARN SparkConf:66 - The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 2019-01-09 13:35:05 WARN NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 13:35:09.640 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 13:35:09.799 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar!/com/intel/gkl/native/libgkl_compressi,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:1587,Testability,test,test,1587,park/2.3.0/install/bin/spark-submit --master yarn --conf spark.kryoserializer.buffer.max=512m --conf spark.driver.maxResultSize=0 --conf spark.driver.userClassPathFirst=false --conf spark.io.compression.codec=lzf --conf spark.yarn.executor.memoryOverhead=600 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 /share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar CountReadsSpark --input /project/casa/gcad/test/HG04302.alt_bwamem_GRCh38DH.20150718.GBR.low_coverage.cram --reference file:///restricted/projectnb/casa/wgs.hg38/pipelines/hc/cram.test/GRCh38_full_analysis_set_plus_decoy_hla.fa.gz --spark-master yarn; 2019-01-09 13:35:04 WARN SparkConf:66 - The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.; 2019-01-09 13:35:05 WARN NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 13:35:09.640 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 13:35:09.799 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg/gatk/4.0.12.0/install/bin/gatk-package-4.0.12.0-spark.jar!/com/intel/gkl/native/libgkl_compression.so; 13:35:11.507 INFO CountReadsSpark - ------------------------------------------------------------; 13:35:11.508 INFO CountReadsSpark - The Genome Analysis Toolkit (GATK) v,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:6073,Testability,log,log,6073,"r:54 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(farrell); groups with view permissions: Set(); users with modify permissions: Set(farrell); groups with modify permissions: Set(); 2019-01-09 13:35:12 INFO Utils:54 - Successfully started service 'sparkDriver' on port 42689.; 2019-01-09 13:35:12 INFO SparkEnv:54 - Registering MapOutputTracker; 2019-01-09 13:35:12 INFO SparkEnv:54 - Registering BlockManagerMaster; 2019-01-09 13:35:12 INFO BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 2019-01-09 13:35:12 INFO BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up; 2019-01-09 13:35:12 INFO DiskBlockManager:54 - Created local directory at /tmp/blockmgr-dd94d6fb-7e3d-4def-a895-6e60f05d7a05; 2019-01-09 13:35:12 INFO MemoryStore:54 - MemoryStore started with capacity 372.6 MB; 2019-01-09 13:35:12 INFO SparkEnv:54 - Registering OutputCommitCoordinator; 2019-01-09 13:35:12 INFO log:192 - Logging initialized @9845ms; 2019-01-09 13:35:12 INFO Server:346 - jetty-9.3.z-SNAPSHOT; 2019-01-09 13:35:12 INFO Server:414 - Started @9981ms; 2019-01-09 13:35:12 WARN Utils:66 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.; 2019-01-09 13:35:12 INFO AbstractConnector:278 - Started ServerConnector@22fda322{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-09 13:35:12 INFO Utils:54 - Successfully started service 'SparkUI' on port 4041.; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@44084713{/jobs,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@43c0c13a{/jobs/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@731db93f{/jobs/job,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2ad2b274{/jobs/job/json,null,AVAILABLE,@Spark}; 2019-01-09 ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:6083,Testability,Log,Logging,6083,"r:54 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(farrell); groups with view permissions: Set(); users with modify permissions: Set(farrell); groups with modify permissions: Set(); 2019-01-09 13:35:12 INFO Utils:54 - Successfully started service 'sparkDriver' on port 42689.; 2019-01-09 13:35:12 INFO SparkEnv:54 - Registering MapOutputTracker; 2019-01-09 13:35:12 INFO SparkEnv:54 - Registering BlockManagerMaster; 2019-01-09 13:35:12 INFO BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 2019-01-09 13:35:12 INFO BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up; 2019-01-09 13:35:12 INFO DiskBlockManager:54 - Created local directory at /tmp/blockmgr-dd94d6fb-7e3d-4def-a895-6e60f05d7a05; 2019-01-09 13:35:12 INFO MemoryStore:54 - MemoryStore started with capacity 372.6 MB; 2019-01-09 13:35:12 INFO SparkEnv:54 - Registering OutputCommitCoordinator; 2019-01-09 13:35:12 INFO log:192 - Logging initialized @9845ms; 2019-01-09 13:35:12 INFO Server:346 - jetty-9.3.z-SNAPSHOT; 2019-01-09 13:35:12 INFO Server:414 - Started @9981ms; 2019-01-09 13:35:12 WARN Utils:66 - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.; 2019-01-09 13:35:12 INFO AbstractConnector:278 - Started ServerConnector@22fda322{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-09 13:35:12 INFO Utils:54 - Successfully started service 'SparkUI' on port 4041.; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@44084713{/jobs,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@43c0c13a{/jobs/json,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@731db93f{/jobs/job,null,AVAILABLE,@Spark}; 2019-01-09 13:35:12 INFO ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2ad2b274{/jobs/job/json,null,AVAILABLE,@Spark}; 2019-01-09 ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616:35819,Usability,clear,cleared,35819,"utor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). Driver stacktrace:; 2019-01-09 13:35:56 INFO DAGScheduler:54 - Job 0 failed: count at CountReadsSpark.java:80, took 12.691336 s; 2019-01-09 13:35:56 INFO AbstractConnector:318 - Stopped Spark@22fda322{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}; 2019-01-09 13:35:56 INFO SparkUI:54 - Stopped Spark web UI at http://scc-hadoop.bu.edu:4041; 2019-01-09 13:35:56 INFO YarnClientSchedulerBackend:54 - Interrupting monitor thread; 2019-01-09 13:35:56 INFO YarnClientSchedulerBackend:54 - Shutting down all executors; 2019-01-09 13:35:56 INFO YarnSchedulerBackend$YarnDriverEndpoint:54 - Asking each executor to shut down; 2019-01-09 13:35:56 INFO SchedulerExtensionServices:54 - Stopping SchedulerExtensionServices; (serviceOption=None,; services=List(),; started=false); 2019-01-09 13:35:56 INFO YarnClientSchedulerBackend:54 - Stopped; 2019-01-09 13:35:56 INFO MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!; 2019-01-09 13:35:56 INFO MemoryStore:54 - MemoryStore cleared; 2019-01-09 13:35:56 INFO BlockManager:54 - BlockManager stopped; 2019-01-09 13:35:56 INFO BlockManagerMaster:54 - BlockManagerMaster stopped; 2019-01-09 13:35:56 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!; 2019-01-09 13:35:56 INFO SparkContext:54 - Successfully stopped SparkContext; 13:35:56.383 INFO CountReadsSpark - Shutting down engine; [January 9, 2019 1:35:56 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 0.78 minutes.; Runtime.totalMemory()=1009254400; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 11, scc-q20.scc.bu.edu, executor 2): htsjdk.samtools.cram.CRAMException: Reference sequence MD5 mismatch for slice: s",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-452814616
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-460895912:5888,Availability,ERROR,ERROR,5888,"8.2; 23:10:12.683 INFO CountReadsSpark - Picard Version: 2.18.25; 23:10:12.683 INFO CountReadsSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 23:10:12.683 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 23:10:12.683 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 23:10:12.683 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 23:10:12.684 INFO CountReadsSpark - Deflater: IntelDeflater; 23:10:12.684 INFO CountReadsSpark - Inflater: IntelInflater; 23:10:12.684 INFO CountReadsSpark - GCS max retries/reopens: 20; 23:10:12.684 INFO CountReadsSpark - Requester pays: disabled; 23:10:12.684 WARN CountReadsSpark -. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: CountReadsSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 23:10:12.685 INFO CountReadsSpark - Initializing engine; 23:10:12.685 INFO CountReadsSpark - Done initializing engine; 19/02/05 23:10:13 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 19/02/05 23:10:15 WARN shortcircuit.DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.; 19/02/05 23:10:18 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.; 806177853; 19/02/05 23:11:51 ERROR scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(6,WrappedArray()); 19/02/05 23:11:51 ERROR scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(13,WrappedArray()); 23:11:51.429 INFO CountReadsSpark - Shutting down engine; [February 5, 2019 11:11:51 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 1.67 minutes.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-460895912
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-460895912:6046,Availability,ERROR,ERROR,6046,"8.2; 23:10:12.683 INFO CountReadsSpark - Picard Version: 2.18.25; 23:10:12.683 INFO CountReadsSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 23:10:12.683 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 23:10:12.683 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 23:10:12.683 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 23:10:12.684 INFO CountReadsSpark - Deflater: IntelDeflater; 23:10:12.684 INFO CountReadsSpark - Inflater: IntelInflater; 23:10:12.684 INFO CountReadsSpark - GCS max retries/reopens: 20; 23:10:12.684 INFO CountReadsSpark - Requester pays: disabled; 23:10:12.684 WARN CountReadsSpark -. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: CountReadsSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 23:10:12.685 INFO CountReadsSpark - Initializing engine; 23:10:12.685 INFO CountReadsSpark - Done initializing engine; 19/02/05 23:10:13 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 19/02/05 23:10:15 WARN shortcircuit.DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.; 19/02/05 23:10:18 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.; 806177853; 19/02/05 23:11:51 ERROR scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(6,WrappedArray()); 19/02/05 23:11:51 ERROR scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(13,WrappedArray()); 23:11:51.429 INFO CountReadsSpark - Shutting down engine; [February 5, 2019 11:11:51 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 1.67 minutes.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-460895912
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-460895912:6232,Availability,down,down,6232,"8.2; 23:10:12.683 INFO CountReadsSpark - Picard Version: 2.18.25; 23:10:12.683 INFO CountReadsSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 23:10:12.683 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 23:10:12.683 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 23:10:12.683 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 23:10:12.684 INFO CountReadsSpark - Deflater: IntelDeflater; 23:10:12.684 INFO CountReadsSpark - Inflater: IntelInflater; 23:10:12.684 INFO CountReadsSpark - GCS max retries/reopens: 20; 23:10:12.684 INFO CountReadsSpark - Requester pays: disabled; 23:10:12.684 WARN CountReadsSpark -. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: CountReadsSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 23:10:12.685 INFO CountReadsSpark - Initializing engine; 23:10:12.685 INFO CountReadsSpark - Done initializing engine; 19/02/05 23:10:13 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 19/02/05 23:10:15 WARN shortcircuit.DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.; 19/02/05 23:10:18 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.; 806177853; 19/02/05 23:11:51 ERROR scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(6,WrappedArray()); 19/02/05 23:11:51 ERROR scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(13,WrappedArray()); 23:11:51.429 INFO CountReadsSpark - Shutting down engine; [February 5, 2019 11:11:51 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 1.67 minutes.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-460895912
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-460895912:501,Deployability,install,install,501,"Yes, the count of the 30x cram took a very fast 1.67 minutes. . .```; /gatk-4.1.0.0/gatk CountReadsSpark --input /project/casa/gcad/adsp.cc/cram/A-ADC-AD010072-BL-NCR-11AD44210.hg38.realign.bqsr.cram --reference ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -- --spark-runner SPARK --spark-master yarn --num-executors 20 --executor-cores 6 --driver-memory 6g; Using GATK jar /restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/gatk-4.1.0.0/gatk-package-4.1.0.0-spark.jar; Running:; /share/pkg/spark/2.1.0/install/bin/spark-submit --master yarn --conf spark.driver.userClassPathFirst=false --conf spark.io.compression.codec=lzf --conf spark.driver.maxResultSize=0 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.kryoserializer.buffer.max=512m --conf spark.yarn.executor.memoryOverhead=600 --num-executors 20 --executor-cores 6 --driver-memory 6g /restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/gatk-4.1.0.0/gatk-package-4.1.0.0-spark.jar CountReadsSpark --input /project/casa/gcad/adsp.cc/cram/A-ADC-AD010072-BL-NCR-11AD44210.hg38.realign.bqsr.cram --reference ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --spark-master yarn; ^C[farrell@scc-hadoop gatk.sv]$ ^C; [farrell@scc-hadoop gatk.sv]$ ./gatk-4.1.0.0/gatk CountReadsSpark --input /project/casa/gcad/adsp.cc/cram/A-ADC-AD010072-BL-NCR-11AD44210.hg38.realign.bqsr.cram --reference ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -- --spark-runner SPARK --spark-master yarn --num-executors 20 --executor-cores 6 --executor-memory 6g; Using GATK jar /restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/gatk-4.1.0.0/gatk-pac",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-460895912
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-460895912:2058,Deployability,install,install,2058,te_tribble=false -Dsamjdk.compression_level=2 --conf spark.kryoserializer.buffer.max=512m --conf spark.yarn.executor.memoryOverhead=600 --num-executors 20 --executor-cores 6 --driver-memory 6g /restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/gatk-4.1.0.0/gatk-package-4.1.0.0-spark.jar CountReadsSpark --input /project/casa/gcad/adsp.cc/cram/A-ADC-AD010072-BL-NCR-11AD44210.hg38.realign.bqsr.cram --reference ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --spark-master yarn; ^C[farrell@scc-hadoop gatk.sv]$ ^C; [farrell@scc-hadoop gatk.sv]$ ./gatk-4.1.0.0/gatk CountReadsSpark --input /project/casa/gcad/adsp.cc/cram/A-ADC-AD010072-BL-NCR-11AD44210.hg38.realign.bqsr.cram --reference ref/GRCh38_full_analysis_set_plus_decoy_hla.fa -- --spark-runner SPARK --spark-master yarn --num-executors 20 --executor-cores 6 --executor-memory 6g; Using GATK jar /restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/gatk-4.1.0.0/gatk-package-4.1.0.0-spark.jar; Running:; /share/pkg/spark/2.1.0/install/bin/spark-submit --master yarn --conf spark.driver.userClassPathFirst=false --conf spark.io.compression.codec=lzf --conf spark.driver.maxResultSize=0 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.kryoserializer.buffer.max=512m --conf spark.yarn.executor.memoryOverhead=600 --num-executors 20 --executor-cores 6 --executor-memory 6g /restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/gatk-4.1.0.0/gatk-package-4.1.0.0-spark.jar CountReadsSpark --input /project/casa/gcad/adsp.cc/cram/A-ADC-AD010072-BL-NCR-11AD44210.hg38.realign.bqsr.cram --reference ref/GRCh38_full_analysis_set_plus_,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-460895912
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-460895912:6322,Deployability,pipeline,pipelines,6322,"8.2; 23:10:12.683 INFO CountReadsSpark - Picard Version: 2.18.25; 23:10:12.683 INFO CountReadsSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 23:10:12.683 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 23:10:12.683 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 23:10:12.683 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 23:10:12.684 INFO CountReadsSpark - Deflater: IntelDeflater; 23:10:12.684 INFO CountReadsSpark - Inflater: IntelInflater; 23:10:12.684 INFO CountReadsSpark - GCS max retries/reopens: 20; 23:10:12.684 INFO CountReadsSpark - Requester pays: disabled; 23:10:12.684 WARN CountReadsSpark -. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: CountReadsSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 23:10:12.685 INFO CountReadsSpark - Initializing engine; 23:10:12.685 INFO CountReadsSpark - Done initializing engine; 19/02/05 23:10:13 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 19/02/05 23:10:15 WARN shortcircuit.DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.; 19/02/05 23:10:18 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.; 806177853; 19/02/05 23:11:51 ERROR scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(6,WrappedArray()); 19/02/05 23:11:51 ERROR scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(13,WrappedArray()); 23:11:51.429 INFO CountReadsSpark - Shutting down engine; [February 5, 2019 11:11:51 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 1.67 minutes.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-460895912
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-460895912:5894,Energy Efficiency,schedul,scheduler,5894,"8.2; 23:10:12.683 INFO CountReadsSpark - Picard Version: 2.18.25; 23:10:12.683 INFO CountReadsSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 23:10:12.683 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 23:10:12.683 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 23:10:12.683 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 23:10:12.684 INFO CountReadsSpark - Deflater: IntelDeflater; 23:10:12.684 INFO CountReadsSpark - Inflater: IntelInflater; 23:10:12.684 INFO CountReadsSpark - GCS max retries/reopens: 20; 23:10:12.684 INFO CountReadsSpark - Requester pays: disabled; 23:10:12.684 WARN CountReadsSpark -. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: CountReadsSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 23:10:12.685 INFO CountReadsSpark - Initializing engine; 23:10:12.685 INFO CountReadsSpark - Done initializing engine; 19/02/05 23:10:13 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 19/02/05 23:10:15 WARN shortcircuit.DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.; 19/02/05 23:10:18 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.; 806177853; 19/02/05 23:11:51 ERROR scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(6,WrappedArray()); 19/02/05 23:11:51 ERROR scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(13,WrappedArray()); 23:11:51.429 INFO CountReadsSpark - Shutting down engine; [February 5, 2019 11:11:51 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 1.67 minutes.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-460895912
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-460895912:6052,Energy Efficiency,schedul,scheduler,6052,"8.2; 23:10:12.683 INFO CountReadsSpark - Picard Version: 2.18.25; 23:10:12.683 INFO CountReadsSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 23:10:12.683 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 23:10:12.683 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 23:10:12.683 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 23:10:12.684 INFO CountReadsSpark - Deflater: IntelDeflater; 23:10:12.684 INFO CountReadsSpark - Inflater: IntelInflater; 23:10:12.684 INFO CountReadsSpark - GCS max retries/reopens: 20; 23:10:12.684 INFO CountReadsSpark - Requester pays: disabled; 23:10:12.684 WARN CountReadsSpark -. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: CountReadsSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 23:10:12.685 INFO CountReadsSpark - Initializing engine; 23:10:12.685 INFO CountReadsSpark - Done initializing engine; 19/02/05 23:10:13 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 19/02/05 23:10:15 WARN shortcircuit.DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.; 19/02/05 23:10:18 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.; 806177853; 19/02/05 23:11:51 ERROR scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(6,WrappedArray()); 19/02/05 23:11:51 ERROR scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(13,WrappedArray()); 23:11:51.429 INFO CountReadsSpark - Shutting down engine; [February 5, 2019 11:11:51 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 1.67 minutes.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-460895912
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-460895912:6011,Integrability,Wrap,WrappedArray,6011,"8.2; 23:10:12.683 INFO CountReadsSpark - Picard Version: 2.18.25; 23:10:12.683 INFO CountReadsSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 23:10:12.683 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 23:10:12.683 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 23:10:12.683 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 23:10:12.684 INFO CountReadsSpark - Deflater: IntelDeflater; 23:10:12.684 INFO CountReadsSpark - Inflater: IntelInflater; 23:10:12.684 INFO CountReadsSpark - GCS max retries/reopens: 20; 23:10:12.684 INFO CountReadsSpark - Requester pays: disabled; 23:10:12.684 WARN CountReadsSpark -. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: CountReadsSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 23:10:12.685 INFO CountReadsSpark - Initializing engine; 23:10:12.685 INFO CountReadsSpark - Done initializing engine; 19/02/05 23:10:13 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 19/02/05 23:10:15 WARN shortcircuit.DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.; 19/02/05 23:10:18 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.; 806177853; 19/02/05 23:11:51 ERROR scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(6,WrappedArray()); 19/02/05 23:11:51 ERROR scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(13,WrappedArray()); 23:11:51.429 INFO CountReadsSpark - Shutting down engine; [February 5, 2019 11:11:51 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 1.67 minutes.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-460895912
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-460895912:6170,Integrability,Wrap,WrappedArray,6170,"8.2; 23:10:12.683 INFO CountReadsSpark - Picard Version: 2.18.25; 23:10:12.683 INFO CountReadsSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 23:10:12.683 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 23:10:12.683 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 23:10:12.683 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 23:10:12.684 INFO CountReadsSpark - Deflater: IntelDeflater; 23:10:12.684 INFO CountReadsSpark - Inflater: IntelInflater; 23:10:12.684 INFO CountReadsSpark - GCS max retries/reopens: 20; 23:10:12.684 INFO CountReadsSpark - Requester pays: disabled; 23:10:12.684 WARN CountReadsSpark -. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: CountReadsSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 23:10:12.685 INFO CountReadsSpark - Initializing engine; 23:10:12.685 INFO CountReadsSpark - Done initializing engine; 19/02/05 23:10:13 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 19/02/05 23:10:15 WARN shortcircuit.DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.; 19/02/05 23:10:18 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.; 806177853; 19/02/05 23:11:51 ERROR scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(6,WrappedArray()); 19/02/05 23:11:51 ERROR scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(13,WrappedArray()); 23:11:51.429 INFO CountReadsSpark - Shutting down engine; [February 5, 2019 11:11:51 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 1.67 minutes.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-460895912
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-460895912:3169,Modifiability,variab,variables,3169,"ark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.kryoserializer.buffer.max=512m --conf spark.yarn.executor.memoryOverhead=600 --num-executors 20 --executor-cores 6 --executor-memory 6g /restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/gatk-4.1.0.0/gatk-package-4.1.0.0-spark.jar CountReadsSpark --input /project/casa/gcad/adsp.cc/cram/A-ADC-AD010072-BL-NCR-11AD44210.hg38.realign.bqsr.cram --reference ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --spark-master yarn; 23:10:10.737 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 23:10:10.965 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/gatk-4.1.0.0/gatk-package-4.1.0.0-spark.jar!/com/intel/gkl/native/libgkl_compression.so; 23:10:12.679 INFO CountReadsSpark - ------------------------------------------------------------; 23:10:12.680 INFO CountReadsSpark - The Genome Analysis Toolkit (GATK) v4.1.0.0; 23:10:12.680 INFO CountReadsSpark - For support and documentation go to https://software.broadinstitute.org/gatk/; 23:10:12.680 INFO CountReadsSpark - Executing as farrell@scc-hadoop.bu.edu on Linux v2.6.32-754.6.3.el6.x86_64 amd64; 23:10:12.681 INFO CountReadsSpark - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_121-b13; 23:10:12.681 INFO CountReadsSpark - Start Date/Time: February 5, 2019 11:10:10 PM EST; 23:10:12.681 INFO CountReadsSpark - -------------------------------------------------------",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-460895912
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-460895912:3295,Modifiability,config,configured,3295,"ark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.kryoserializer.buffer.max=512m --conf spark.yarn.executor.memoryOverhead=600 --num-executors 20 --executor-cores 6 --executor-memory 6g /restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/gatk-4.1.0.0/gatk-package-4.1.0.0-spark.jar CountReadsSpark --input /project/casa/gcad/adsp.cc/cram/A-ADC-AD010072-BL-NCR-11AD44210.hg38.realign.bqsr.cram --reference ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --spark-master yarn; 23:10:10.737 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 23:10:10.965 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/gatk-4.1.0.0/gatk-package-4.1.0.0-spark.jar!/com/intel/gkl/native/libgkl_compression.so; 23:10:12.679 INFO CountReadsSpark - ------------------------------------------------------------; 23:10:12.680 INFO CountReadsSpark - The Genome Analysis Toolkit (GATK) v4.1.0.0; 23:10:12.680 INFO CountReadsSpark - For support and documentation go to https://software.broadinstitute.org/gatk/; 23:10:12.680 INFO CountReadsSpark - Executing as farrell@scc-hadoop.bu.edu on Linux v2.6.32-754.6.3.el6.x86_64 amd64; 23:10:12.681 INFO CountReadsSpark - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_121-b13; 23:10:12.681 INFO CountReadsSpark - Start Date/Time: February 5, 2019 11:10:10 PM EST; 23:10:12.681 INFO CountReadsSpark - -------------------------------------------------------",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-460895912
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-460895912:3356,Performance,Load,Loading,3356,"nc_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.kryoserializer.buffer.max=512m --conf spark.yarn.executor.memoryOverhead=600 --num-executors 20 --executor-cores 6 --executor-memory 6g /restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/gatk-4.1.0.0/gatk-package-4.1.0.0-spark.jar CountReadsSpark --input /project/casa/gcad/adsp.cc/cram/A-ADC-AD010072-BL-NCR-11AD44210.hg38.realign.bqsr.cram --reference ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --spark-master yarn; 23:10:10.737 WARN SparkContextFactory - Environment variables HELLBENDER_TEST_PROJECT and HELLBENDER_JSON_SERVICE_ACCOUNT_KEY must be set or the GCS hadoop connector will not be configured properly; 23:10:10.965 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/restricted/projectnb/casa/wgs.hg38/sv/gatk.sv/gatk-4.1.0.0/gatk-package-4.1.0.0-spark.jar!/com/intel/gkl/native/libgkl_compression.so; 23:10:12.679 INFO CountReadsSpark - ------------------------------------------------------------; 23:10:12.680 INFO CountReadsSpark - The Genome Analysis Toolkit (GATK) v4.1.0.0; 23:10:12.680 INFO CountReadsSpark - For support and documentation go to https://software.broadinstitute.org/gatk/; 23:10:12.680 INFO CountReadsSpark - Executing as farrell@scc-hadoop.bu.edu on Linux v2.6.32-754.6.3.el6.x86_64 amd64; 23:10:12.681 INFO CountReadsSpark - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_121-b13; 23:10:12.681 INFO CountReadsSpark - Start Date/Time: February 5, 2019 11:10:10 PM EST; 23:10:12.681 INFO CountReadsSpark - ------------------------------------------------------------; 23:10:12.681 INFO CountReadsSpark - ------------------------------------------------------------; 23:10:12.683 INFO Count",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-460895912
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-460895912:5473,Performance,load,load,5473,"8.2; 23:10:12.683 INFO CountReadsSpark - Picard Version: 2.18.25; 23:10:12.683 INFO CountReadsSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 23:10:12.683 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 23:10:12.683 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 23:10:12.683 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 23:10:12.684 INFO CountReadsSpark - Deflater: IntelDeflater; 23:10:12.684 INFO CountReadsSpark - Inflater: IntelInflater; 23:10:12.684 INFO CountReadsSpark - GCS max retries/reopens: 20; 23:10:12.684 INFO CountReadsSpark - Requester pays: disabled; 23:10:12.684 WARN CountReadsSpark -. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: CountReadsSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 23:10:12.685 INFO CountReadsSpark - Initializing engine; 23:10:12.685 INFO CountReadsSpark - Done initializing engine; 19/02/05 23:10:13 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 19/02/05 23:10:15 WARN shortcircuit.DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.; 19/02/05 23:10:18 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.; 806177853; 19/02/05 23:11:51 ERROR scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(6,WrappedArray()); 19/02/05 23:11:51 ERROR scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(13,WrappedArray()); 23:11:51.429 INFO CountReadsSpark - Shutting down engine; [February 5, 2019 11:11:51 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 1.67 minutes.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-460895912
https://github.com/broadinstitute/gatk/issues/5547#issuecomment-460895912:5704,Performance,load,loaded,5704,"8.2; 23:10:12.683 INFO CountReadsSpark - Picard Version: 2.18.25; 23:10:12.683 INFO CountReadsSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 23:10:12.683 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 23:10:12.683 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : false; 23:10:12.683 INFO CountReadsSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 23:10:12.684 INFO CountReadsSpark - Deflater: IntelDeflater; 23:10:12.684 INFO CountReadsSpark - Inflater: IntelInflater; 23:10:12.684 INFO CountReadsSpark - GCS max retries/reopens: 20; 23:10:12.684 INFO CountReadsSpark - Requester pays: disabled; 23:10:12.684 WARN CountReadsSpark -. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: CountReadsSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 23:10:12.685 INFO CountReadsSpark - Initializing engine; 23:10:12.685 INFO CountReadsSpark - Done initializing engine; 19/02/05 23:10:13 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 19/02/05 23:10:15 WARN shortcircuit.DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.; 19/02/05 23:10:18 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.; 806177853; 19/02/05 23:11:51 ERROR scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(6,WrappedArray()); 19/02/05 23:11:51 ERROR scheduler.LiveListenerBus: SparkListenerBus has already stopped! Dropping event SparkListenerExecutorMetricsUpdate(13,WrappedArray()); 23:11:51.429 INFO CountReadsSpark - Shutting down engine; [February 5, 2019 11:11:51 PM EST] org.broadinstitute.hellbender.tools.spark.pipelines.CountReadsSpark done. Elapsed time: 1.67 minutes.; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5547#issuecomment-460895912
https://github.com/broadinstitute/gatk/pull/5548#issuecomment-452818246:287,Usability,clear,clear,287,"@lucidtronix @cmnbroad, I see for v4.0.12.0, CNNScoreVariants falls under the `EXPERIMENTAL Tool` label. When you say the tool will come out of beta, do you mean there will be a change in this label or something else? I'm writing a document that links to the CNN workflow and need to be clear on the status of the workflow. Thanks.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5548#issuecomment-452818246
https://github.com/broadinstitute/gatk/pull/5548#issuecomment-458580273:109,Availability,down,downsampling,109,"Looks like we're mostly there, except for adding a model version, which @lucidtronix is working on, and java downsampling, which probably won't make it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5548#issuecomment-458580273
https://github.com/broadinstitute/gatk/pull/5549#issuecomment-449525248:1260,Usability,Simpl,SimpleInterval,1260,50a084e1068618908de4f5e?src=pr&el=desc) will **decrease** coverage by `0.072%`.; > The diff coverage is `92.824%`. ```diff; @@ Coverage Diff @@; ## master #5549 +/- ##; ==============================================; - Coverage 87.09% 87.018% -0.072% ; - Complexity 31524 31706 +182 ; ==============================================; Files 1930 1943 +13 ; Lines 145231 146064 +833 ; Branches 16095 16137 +42 ; ==============================================; + Hits 126482 127102 +620 ; - Misses 12900 13077 +177 ; - Partials 5849 5885 +36; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5549?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...institute/hellbender/utils/help/HelpConstants.java](https://codecov.io/gh/broadinstitute/gatk/pull/5549/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9oZWxwL0hlbHBDb25zdGFudHMuamF2YQ==) | `4.167% <ø> (ø)` | `1 <0> (ø)` | :arrow_down: |; | [...roadinstitute/hellbender/utils/SimpleInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/5549/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9TaW1wbGVJbnRlcnZhbC5qYXZh) | `93.182% <ø> (ø)` | `48 <0> (ø)` | :arrow_down: |; | [...dinstitute/hellbender/engine/ReferenceContext.java](https://codecov.io/gh/broadinstitute/gatk/pull/5549/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUmVmZXJlbmNlQ29udGV4dC5qYXZh) | `83.908% <ø> (ø)` | `39 <0> (ø)` | :arrow_down: |; | [...lbender/utils/iterators/IntervalLocusIterator.java](https://codecov.io/gh/broadinstitute/gatk/pull/5549/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9pdGVyYXRvcnMvSW50ZXJ2YWxMb2N1c0l0ZXJhdG9yLmphdmE=) | `92.593% <ø> (ø)` | `11 <0> (ø)` | :arrow_down: |; | [...org/broadinstitute/hellbender/utils/BaseUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5549/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9v,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5549#issuecomment-449525248
https://github.com/broadinstitute/gatk/pull/5551#issuecomment-450184780:1274,Deployability,pipeline,pipelines,1274,pr&el=desc) will **increase** coverage by `0.002%`.; > The diff coverage is `90.909%`. ```diff; @@ Coverage Diff @@; ## master #5551 +/- ##; ===============================================; + Coverage 87.001% 87.003% +0.002% ; + Complexity 32105 32104 -1 ; ===============================================; Files 1974 1974 ; Lines 147223 147235 +12 ; Branches 16216 16219 +3 ; ===============================================; + Hits 128086 128099 +13 ; Misses 13231 13231 ; + Partials 5906 5905 -1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5551?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...umber/utils/MergeAnnotatedRegionsByAnnotation.java](https://codecov.io/gh/broadinstitute/gatk/pull/5551/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL3V0aWxzL01lcmdlQW5ub3RhdGVkUmVnaW9uc0J5QW5ub3RhdGlvbi5qYXZh) | `94.737% <ø> (ø)` | `4 <0> (ø)` | :arrow_down: |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5551/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `0% <ø> (ø)` | `0 <0> (ø)` | :arrow_down: |; | [.../tools/copynumber/utils/MergeAnnotatedRegions.java](https://codecov.io/gh/broadinstitute/gatk/pull/5551/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL3V0aWxzL01lcmdlQW5ub3RhdGVkUmVnaW9ucy5qYXZh) | `100% <ø> (ø)` | `3 <0> (ø)` | :arrow_down: |; | [...tmutpileup/ValidateBasicSomaticShortMutations.java](https://codecov.io/gh/broadinstitute/gatk/pull/5551/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vYmFzaWNzaG9ydG11dHBpbGV1cC9WYWxpZGF0ZUJhc2ljU29tYXRpY1Nob3J0TXV0YXRpb25zLmphdmE=) | `80.172% <ø> (ø)` | `19 <0> (ø)` | :arrow_down: |; | [...tute/hellbender/tools/AnnotatePairOrientation.j,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5551#issuecomment-450184780
https://github.com/broadinstitute/gatk/pull/5551#issuecomment-450184780:3447,Modifiability,Polymorphi,PolymorphicNuMT,3447,hc2ljU29tYXRpY1Nob3J0TXV0YXRpb25zLmphdmE=) | `80.172% <ø> (ø)` | `19 <0> (ø)` | :arrow_down: |; | [...tute/hellbender/tools/AnnotatePairOrientation.java](https://codecov.io/gh/broadinstitute/gatk/pull/5551/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9Bbm5vdGF0ZVBhaXJPcmllbnRhdGlvbi5qYXZh) | `96.429% <ø> (ø)` | `8 <0> (ø)` | :arrow_down: |; | [...nder/tools/copynumber/utils/TagGermlineEvents.java](https://codecov.io/gh/broadinstitute/gatk/pull/5551/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL3V0aWxzL1RhZ0dlcm1saW5lRXZlbnRzLmphdmE=) | `100% <ø> (ø)` | `3 <0> (ø)` | :arrow_down: |; | [...t/java/org/broadinstitute/hellbender/MainTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5551/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9NYWluVGVzdC5qYXZh) | `85.714% <90.909%> (+2.787%)` | `15 <9> (+9)` | :arrow_up: |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5551/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-30%)` | `1% <0%> (-2%)` | |; | [...ender/tools/walkers/annotator/PolymorphicNuMT.java](https://codecov.io/gh/broadinstitute/gatk/pull/5551/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9Qb2x5bW9ycGhpY051TVQuamF2YQ==) | `92.593% <0%> (-3.704%)` | `8% <0%> (-1%)` | |; | [...r/tools/walkers/mutect/Mutect2IntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5551/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9NdXRlY3QySW50ZWdyYXRpb25UZXN0LmphdmE=) | `87.586% <0%> (-0.517%)` | `89% <0%> (-2%)` | |; | ... and [13 more](https://codecov.io/gh/broadinstitute/gatk/pull/5551/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5551#issuecomment-450184780
https://github.com/broadinstitute/gatk/pull/5551#issuecomment-450184780:1882,Security,Validat,ValidateBasicSomaticShortMutations,1882,y Δ | |; |---|---|---|---|; | [...umber/utils/MergeAnnotatedRegionsByAnnotation.java](https://codecov.io/gh/broadinstitute/gatk/pull/5551/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL3V0aWxzL01lcmdlQW5ub3RhdGVkUmVnaW9uc0J5QW5ub3RhdGlvbi5qYXZh) | `94.737% <ø> (ø)` | `4 <0> (ø)` | :arrow_down: |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5551/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `0% <ø> (ø)` | `0 <0> (ø)` | :arrow_down: |; | [.../tools/copynumber/utils/MergeAnnotatedRegions.java](https://codecov.io/gh/broadinstitute/gatk/pull/5551/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL3V0aWxzL01lcmdlQW5ub3RhdGVkUmVnaW9ucy5qYXZh) | `100% <ø> (ø)` | `3 <0> (ø)` | :arrow_down: |; | [...tmutpileup/ValidateBasicSomaticShortMutations.java](https://codecov.io/gh/broadinstitute/gatk/pull/5551/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vYmFzaWNzaG9ydG11dHBpbGV1cC9WYWxpZGF0ZUJhc2ljU29tYXRpY1Nob3J0TXV0YXRpb25zLmphdmE=) | `80.172% <ø> (ø)` | `19 <0> (ø)` | :arrow_down: |; | [...tute/hellbender/tools/AnnotatePairOrientation.java](https://codecov.io/gh/broadinstitute/gatk/pull/5551/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9Bbm5vdGF0ZVBhaXJPcmllbnRhdGlvbi5qYXZh) | `96.429% <ø> (ø)` | `8 <0> (ø)` | :arrow_down: |; | [...nder/tools/copynumber/utils/TagGermlineEvents.java](https://codecov.io/gh/broadinstitute/gatk/pull/5551/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL3V0aWxzL1RhZ0dlcm1saW5lRXZlbnRzLmphdmE=) | `100% <ø> (ø)` | `3 <0> (ø)` | :arrow_down: |; | [...t/java/org/broadinstitute/hellbender/MainTest.java](https://co,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5551#issuecomment-450184780
https://github.com/broadinstitute/gatk/pull/5551#issuecomment-451970908:11,Testability,test,test,11,Adding the test in lieu of truncation sounds good. But I need to wait until we have a version of Picard that conforms to enable it.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5551#issuecomment-451970908
https://github.com/broadinstitute/gatk/pull/5551#issuecomment-472552477:65,Testability,test,test,65,"@droazen Actually, its not. When I switched over to relying on a test instead of truncation, I omitted the picard tools from the test since there is a corresponding PR/test for Picard, so there is no need to wait. I'm going to rebase on current master to re-run the test, and then we can merge this (pending of course that we resolve the `AnnotatePairOrientation` status. @LeeTL1220 - should `AnnotatePairOrientation` be `@Experimental` or `@Beta` ? Currently now its tagged `@Beta` but says `Experimental` in the command line description.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5551#issuecomment-472552477
https://github.com/broadinstitute/gatk/pull/5551#issuecomment-472552477:129,Testability,test,test,129,"@droazen Actually, its not. When I switched over to relying on a test instead of truncation, I omitted the picard tools from the test since there is a corresponding PR/test for Picard, so there is no need to wait. I'm going to rebase on current master to re-run the test, and then we can merge this (pending of course that we resolve the `AnnotatePairOrientation` status. @LeeTL1220 - should `AnnotatePairOrientation` be `@Experimental` or `@Beta` ? Currently now its tagged `@Beta` but says `Experimental` in the command line description.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5551#issuecomment-472552477
https://github.com/broadinstitute/gatk/pull/5551#issuecomment-472552477:168,Testability,test,test,168,"@droazen Actually, its not. When I switched over to relying on a test instead of truncation, I omitted the picard tools from the test since there is a corresponding PR/test for Picard, so there is no need to wait. I'm going to rebase on current master to re-run the test, and then we can merge this (pending of course that we resolve the `AnnotatePairOrientation` status. @LeeTL1220 - should `AnnotatePairOrientation` be `@Experimental` or `@Beta` ? Currently now its tagged `@Beta` but says `Experimental` in the command line description.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5551#issuecomment-472552477
https://github.com/broadinstitute/gatk/pull/5551#issuecomment-472552477:266,Testability,test,test,266,"@droazen Actually, its not. When I switched over to relying on a test instead of truncation, I omitted the picard tools from the test since there is a corresponding PR/test for Picard, so there is no need to wait. I'm going to rebase on current master to re-run the test, and then we can merge this (pending of course that we resolve the `AnnotatePairOrientation` status. @LeeTL1220 - should `AnnotatePairOrientation` be `@Experimental` or `@Beta` ? Currently now its tagged `@Beta` but says `Experimental` in the command line description.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5551#issuecomment-472552477
https://github.com/broadinstitute/gatk/issues/5553#issuecomment-450606674:364,Availability,error,error,364,"@byoo Could you take the unfiltered vcf: `/gpfs/data/software/cromwell/log/cromwell-executions/Mutect2/0c2281d2-9d90-4ee3-88bb-f0bb015cdb7c/call-Filter/attempt-4/inputs/-356078842/Ameloblastoma_FFPE_P5-unfiltered.vcf.gz`, and restrict it to a small interval (at big as one chromosome and small as just the problematic site) surrounding the variant that causes the error? If the stderr isn't enough to identify the site approximately, you could run `gatk FilterMutectCalls -V unfiltered.vcf -O tmp.vcf` locally without any of the optional inputs and I believe tmp.vcf would be produced with every site up to but not including the problematic one.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5553#issuecomment-450606674
https://github.com/broadinstitute/gatk/issues/5553#issuecomment-450606674:71,Testability,log,log,71,"@byoo Could you take the unfiltered vcf: `/gpfs/data/software/cromwell/log/cromwell-executions/Mutect2/0c2281d2-9d90-4ee3-88bb-f0bb015cdb7c/call-Filter/attempt-4/inputs/-356078842/Ameloblastoma_FFPE_P5-unfiltered.vcf.gz`, and restrict it to a small interval (at big as one chromosome and small as just the problematic site) surrounding the variant that causes the error? If the stderr isn't enough to identify the site approximately, you could run `gatk FilterMutectCalls -V unfiltered.vcf -O tmp.vcf` locally without any of the optional inputs and I believe tmp.vcf would be produced with every site up to but not including the problematic one.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5553#issuecomment-450606674
https://github.com/broadinstitute/gatk/issues/5553#issuecomment-451464446:113,Availability,error,error,113,"I've hit the same issue. I can't say for certain the files I'm using run cleanly, because I had been getting the error associated with 'AF=.' #5442. . ```; 2019-01-04T14:02:27.214488889Z [January 4, 2019 2:02:27 PM UTC] org.broadinstitute.hellbender.tools.walkers.mutect.FilterMutectCalls done. Elapsed time: 0.05 minutes.; 2019-01-04T14:02:27.214810448Z Runtime.totalMemory()=407896064; 2019-01-04T14:02:27.215613324Z java.lang.IllegalArgumentException: errorRateLog10 must be good probability but got NaN; 2019-01-04T14:02:27.216082142Z 	at org.broadinstitute.hellbender.utils.QualityUtils.phredScaleLog10ErrorRate(QualityUtils.java:321); 2019-01-04T14:02:27.216288993Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.lambda$applyGermlineVariantFilter$10(Mutect2FilteringEngine.java:207); 2019-01-04T14:02:27.216482786Z 	at java.util.stream.DoublePipeline$3$1.accept(DoublePipeline.java:231); 2019-01-04T14:02:27.216675396Z 	at java.util.Spliterators$DoubleArraySpliterator.forEachRemaining(Spliterators.java:1198); 2019-01-04T14:02:27.216858104Z 	at java.util.Spliterator$OfDouble.forEachRemaining(Spliterator.java:822); 2019-01-04T14:02:27.217027544Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 2019-01-04T14:02:27.234512924Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 2019-01-04T14:02:27.234886181Z 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:545); 2019-01-04T14:02:27.235138770Z 	at java.util.stream.AbstractPipeline.evaluateToArrayNode(AbstractPipeline.java:260); 2019-01-04T14:02:27.235509109Z 	at java.util.stream.IntPipeline.toArray(IntPipeline.java:502); 2019-01-04T14:02:27.235661751Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.applyGermlineVariantFilter(Mutect2FilteringEngine.java:207); 2019-01-04T14:02:27.235931663Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.calculateFilters(Mutect2Filteri",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5553#issuecomment-451464446
https://github.com/broadinstitute/gatk/issues/5553#issuecomment-451464446:1329,Integrability,wrap,wrapAndCopyInto,1329,14810448Z Runtime.totalMemory()=407896064; 2019-01-04T14:02:27.215613324Z java.lang.IllegalArgumentException: errorRateLog10 must be good probability but got NaN; 2019-01-04T14:02:27.216082142Z 	at org.broadinstitute.hellbender.utils.QualityUtils.phredScaleLog10ErrorRate(QualityUtils.java:321); 2019-01-04T14:02:27.216288993Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.lambda$applyGermlineVariantFilter$10(Mutect2FilteringEngine.java:207); 2019-01-04T14:02:27.216482786Z 	at java.util.stream.DoublePipeline$3$1.accept(DoublePipeline.java:231); 2019-01-04T14:02:27.216675396Z 	at java.util.Spliterators$DoubleArraySpliterator.forEachRemaining(Spliterators.java:1198); 2019-01-04T14:02:27.216858104Z 	at java.util.Spliterator$OfDouble.forEachRemaining(Spliterator.java:822); 2019-01-04T14:02:27.217027544Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 2019-01-04T14:02:27.234512924Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 2019-01-04T14:02:27.234886181Z 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:545); 2019-01-04T14:02:27.235138770Z 	at java.util.stream.AbstractPipeline.evaluateToArrayNode(AbstractPipeline.java:260); 2019-01-04T14:02:27.235509109Z 	at java.util.stream.IntPipeline.toArray(IntPipeline.java:502); 2019-01-04T14:02:27.235661751Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.applyGermlineVariantFilter(Mutect2FilteringEngine.java:207); 2019-01-04T14:02:27.235931663Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.calculateFilters(Mutect2FilteringEngine.java:436); 2019-01-04T14:02:27.236174900Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.FilterMutectCalls.firstPassApply(FilterMutectCalls.java:120); 2019-01-04T14:02:27.236322702Z 	at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.lambda$traverseVariants$0(TwoPassVariantWalker.java:76); 2019-01-04T14:02:27.2371714,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5553#issuecomment-451464446
https://github.com/broadinstitute/gatk/issues/5553#issuecomment-451464446:2923,Integrability,wrap,wrapAndCopyInto,2923,.mutect.Mutect2FilteringEngine.calculateFilters(Mutect2FilteringEngine.java:436); 2019-01-04T14:02:27.236174900Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.FilterMutectCalls.firstPassApply(FilterMutectCalls.java:120); 2019-01-04T14:02:27.236322702Z 	at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.lambda$traverseVariants$0(TwoPassVariantWalker.java:76); 2019-01-04T14:02:27.237171464Z 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 2019-01-04T14:02:27.237239651Z 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 2019-01-04T14:02:27.237250455Z 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 2019-01-04T14:02:27.237256726Z 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 2019-01-04T14:02:27.237294098Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 2019-01-04T14:02:27.237302853Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 2019-01-04T14:02:27.237308231Z 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 2019-01-04T14:02:27.237342232Z 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 2019-01-04T14:02:27.237377382Z 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 2019-01-04T14:02:27.237384696Z 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 2019-01-04T14:02:27.237442143Z 	at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.traverseVariants(TwoPassVariantWalker.java:74); 2019-01-04T14:02:27.237452377Z 	at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.traverse(TwoPassVariantWalker.java:27); 2019-01-04T14:02:27.237457367Z 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:966); 2019-01-04T14:02:27.237461597Z 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 2019-01-04T14:,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5553#issuecomment-451464446
https://github.com/broadinstitute/gatk/issues/5553#issuecomment-451476776:345,Availability,error,error,345,"Unfortunately, these data are not public so I can not share them. . My Mutect2 runs were already split by chr. I've run one chr within a docker container built from `docker pull broadinstitute/gatk` using the command you provided above: `gatk FilterMutectCalls -V chr1.vcf -O temp.vcf`. That crashes out immediately (0.05 runtime) with the same error, and `temp.vcf` has the vcf header but nothing beyond the `#CHROM` line.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5553#issuecomment-451476776
https://github.com/broadinstitute/gatk/issues/5553#issuecomment-451711763:36,Availability,error,errors,36,"@byoo @MikeWLloyd I reproduced your errors and fixed them, at least on my laptop, in PR #5563. Thank you for your help, and please don't hesitate to speak up if the bug remains for you once this PR goes in.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5553#issuecomment-451711763
https://github.com/broadinstitute/gatk/issues/5553#issuecomment-451749085:20,Availability,error,error,20,"I just got the same error:. ```; Using GATK jar /software/anaconda2/share/gatk4-4.0.12.0-0/gatk-package-4.0.12.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx16G -jar /software/anaconda2/share/gatk4-4.0.12.0-0/gatk-package-4.0.12.0-local.jar FilterMutectCalls -V tumor-vs-normal.mutect.temp1.vcf -O tumor-vs-normal.mutect.temp2.vcf; 22:58:25.052 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/software/anaconda2/share/gatk4-4.0.12.0-0/gatk-package-4.0.12.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 22:58:26.911 INFO FilterMutectCalls - ------------------------------------------------------------; 22:58:26.912 INFO FilterMutectCalls - The Genome Analysis Toolkit (GATK) v4.0.12.0; 22:58:26.912 INFO FilterMutectCalls - For support and documentation go to https://software.broadinstitute.org/gatk/; 22:58:26.912 INFO FilterMutectCalls - Executing as www-data@SpongeBob on Linux v4.15.0-39-generic amd64; 22:58:26.912 INFO FilterMutectCalls - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_152-release-1056-b12; 22:58:26.912 INFO FilterMutectCalls - Start Date/Time: January 6, 2019 10:58:24 PM SGT; 22:58:26.913 INFO FilterMutectCalls - ------------------------------------------------------------; 22:58:26.913 INFO FilterMutectCalls - ------------------------------------------------------------; 22:58:26.913 INFO FilterMutectCalls - HTSJDK Version: 2.18.1; 22:58:26.913 INFO FilterMutectCalls - Picard Version: 2.18.16; 22:58:26.913 INFO FilterMutectCalls - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 22:58:26.913 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 22:58:26.913 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 22:58:26.913 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 22:58:26.914 INFO FilterMutectCalls - De",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5553#issuecomment-451749085
https://github.com/broadinstitute/gatk/issues/5553#issuecomment-451749085:2732,Availability,down,down,2732,"SYNC_IO_READ_FOR_SAMTOOLS : false; 22:58:26.913 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 22:58:26.913 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 22:58:26.914 INFO FilterMutectCalls - Deflater: IntelDeflater; 22:58:26.914 INFO FilterMutectCalls - Inflater: IntelInflater; 22:58:26.914 INFO FilterMutectCalls - GCS max retries/reopens: 20; 22:58:26.914 INFO FilterMutectCalls - Requester pays: disabled; 22:58:26.914 INFO FilterMutectCalls - Initializing engine; 22:58:27.401 INFO FeatureManager - Using codec VCFCodec to read file file://tumor-vs-normal.mutect.temp1.vcf; 22:58:27.518 INFO FilterMutectCalls - Done initializing engine; 22:58:27.570 INFO ProgressMeter - Starting traversal; 22:58:27.571 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 22:58:27.571 INFO FilterMutectCalls - Starting first pass through the variants; 22:58:28.484 INFO FilterMutectCalls - Shutting down engine; [January 6, 2019 10:58:28 PM SGT] org.broadinstitute.hellbender.tools.walkers.mutect.FilterMutectCalls done. Elapsed time: 0.06 minutes.; Runtime.totalMemory()=2141192192; java.lang.IllegalArgumentException: errorRateLog10 must be good probability but got NaN; 	at org.broadinstitute.hellbender.utils.QualityUtils.phredScaleLog10ErrorRate(QualityUtils.java:321); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.lambda$applyGermlineVariantFilter$10(Mutect2FilteringEngine.java:207); 	at java.util.stream.DoublePipeline$3$1.accept(DoublePipeline.java:231); 	at java.util.Spliterators$DoubleArraySpliterator.forEachRemaining(Spliterators.java:1198); 	at java.util.Spliterator$OfDouble.forEachRemaining(Spliterator.java:822); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:545); 	at java.u",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5553#issuecomment-451749085
https://github.com/broadinstitute/gatk/issues/5553#issuecomment-451749085:1171,Deployability,release,release-,1171,"-Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx16G -jar /software/anaconda2/share/gatk4-4.0.12.0-0/gatk-package-4.0.12.0-local.jar FilterMutectCalls -V tumor-vs-normal.mutect.temp1.vcf -O tumor-vs-normal.mutect.temp2.vcf; 22:58:25.052 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/software/anaconda2/share/gatk4-4.0.12.0-0/gatk-package-4.0.12.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 22:58:26.911 INFO FilterMutectCalls - ------------------------------------------------------------; 22:58:26.912 INFO FilterMutectCalls - The Genome Analysis Toolkit (GATK) v4.0.12.0; 22:58:26.912 INFO FilterMutectCalls - For support and documentation go to https://software.broadinstitute.org/gatk/; 22:58:26.912 INFO FilterMutectCalls - Executing as www-data@SpongeBob on Linux v4.15.0-39-generic amd64; 22:58:26.912 INFO FilterMutectCalls - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_152-release-1056-b12; 22:58:26.912 INFO FilterMutectCalls - Start Date/Time: January 6, 2019 10:58:24 PM SGT; 22:58:26.913 INFO FilterMutectCalls - ------------------------------------------------------------; 22:58:26.913 INFO FilterMutectCalls - ------------------------------------------------------------; 22:58:26.913 INFO FilterMutectCalls - HTSJDK Version: 2.18.1; 22:58:26.913 INFO FilterMutectCalls - Picard Version: 2.18.16; 22:58:26.913 INFO FilterMutectCalls - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 22:58:26.913 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 22:58:26.913 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 22:58:26.913 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 22:58:26.914 INFO FilterMutectCalls - Deflater: IntelDeflater; 22:58:26.914 INFO FilterMutectCalls - Inflater: IntelInflater; 22:58:26.914 INFO FilterMutectCalls - GCS max retries/reopens: 20; 22:58:26.914 INFO FilterMute",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5553#issuecomment-451749085
https://github.com/broadinstitute/gatk/issues/5553#issuecomment-451749085:3610,Integrability,wrap,wrapAndCopyInto,3610,"terMutectCalls - Starting first pass through the variants; 22:58:28.484 INFO FilterMutectCalls - Shutting down engine; [January 6, 2019 10:58:28 PM SGT] org.broadinstitute.hellbender.tools.walkers.mutect.FilterMutectCalls done. Elapsed time: 0.06 minutes.; Runtime.totalMemory()=2141192192; java.lang.IllegalArgumentException: errorRateLog10 must be good probability but got NaN; 	at org.broadinstitute.hellbender.utils.QualityUtils.phredScaleLog10ErrorRate(QualityUtils.java:321); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.lambda$applyGermlineVariantFilter$10(Mutect2FilteringEngine.java:207); 	at java.util.stream.DoublePipeline$3$1.accept(DoublePipeline.java:231); 	at java.util.Spliterators$DoubleArraySpliterator.forEachRemaining(Spliterators.java:1198); 	at java.util.Spliterator$OfDouble.forEachRemaining(Spliterator.java:822); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:545); 	at java.util.stream.AbstractPipeline.evaluateToArrayNode(AbstractPipeline.java:260); 	at java.util.stream.IntPipeline.toArray(IntPipeline.java:502); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.applyGermlineVariantFilter(Mutect2FilteringEngine.java:207); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.calculateFilters(Mutect2FilteringEngine.java:436); 	at org.broadinstitute.hellbender.tools.walkers.mutect.FilterMutectCalls.firstPassApply(FilterMutectCalls.java:120); 	at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.lambda$traverseVariants$0(TwoPassVariantWalker.java:76); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$I",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5553#issuecomment-451749085
https://github.com/broadinstitute/gatk/issues/5553#issuecomment-451749085:4801,Integrability,wrap,wrapAndCopyInto,4801,t java.util.stream.IntPipeline.toArray(IntPipeline.java:502); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.applyGermlineVariantFilter(Mutect2FilteringEngine.java:207); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.calculateFilters(Mutect2FilteringEngine.java:436); 	at org.broadinstitute.hellbender.tools.walkers.mutect.FilterMutectCalls.firstPassApply(FilterMutectCalls.java:120); 	at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.lambda$traverseVariants$0(TwoPassVariantWalker.java:76); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.traverseVariants(TwoPassVariantWalker.java:74); 	at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.traverse(TwoPassVariantWalker.java:27); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:966); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.ru,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5553#issuecomment-451749085
https://github.com/broadinstitute/gatk/issues/5553#issuecomment-451749085:513,Performance,Load,Loading,513,"I just got the same error:. ```; Using GATK jar /software/anaconda2/share/gatk4-4.0.12.0-0/gatk-package-4.0.12.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx16G -jar /software/anaconda2/share/gatk4-4.0.12.0-0/gatk-package-4.0.12.0-local.jar FilterMutectCalls -V tumor-vs-normal.mutect.temp1.vcf -O tumor-vs-normal.mutect.temp2.vcf; 22:58:25.052 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/software/anaconda2/share/gatk4-4.0.12.0-0/gatk-package-4.0.12.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 22:58:26.911 INFO FilterMutectCalls - ------------------------------------------------------------; 22:58:26.912 INFO FilterMutectCalls - The Genome Analysis Toolkit (GATK) v4.0.12.0; 22:58:26.912 INFO FilterMutectCalls - For support and documentation go to https://software.broadinstitute.org/gatk/; 22:58:26.912 INFO FilterMutectCalls - Executing as www-data@SpongeBob on Linux v4.15.0-39-generic amd64; 22:58:26.912 INFO FilterMutectCalls - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_152-release-1056-b12; 22:58:26.912 INFO FilterMutectCalls - Start Date/Time: January 6, 2019 10:58:24 PM SGT; 22:58:26.913 INFO FilterMutectCalls - ------------------------------------------------------------; 22:58:26.913 INFO FilterMutectCalls - ------------------------------------------------------------; 22:58:26.913 INFO FilterMutectCalls - HTSJDK Version: 2.18.1; 22:58:26.913 INFO FilterMutectCalls - Picard Version: 2.18.16; 22:58:26.913 INFO FilterMutectCalls - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 22:58:26.913 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 22:58:26.913 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 22:58:26.913 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 22:58:26.914 INFO FilterMutectCalls - De",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5553#issuecomment-451749085
https://github.com/broadinstitute/gatk/issues/5553#issuecomment-485476488:139,Security,validat,validateArg,139,"```; java.lang.IllegalArgumentException: errorRateLog10 must be good probability but got NaN; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:730); at org.broadinstitute.hellbender.utils.QualityUtils.phredScaleLog10ErrorRate(QualityUtils.java:321); at org.broadinstitute.hellbender.utils.QualityUtils.phredScaleErrorRate(QualityUtils.java:307); at org.broadinstitute.hellbender.tools.exome.orientationbiasvariantfilter.PreAdapterOrientationScorer.scoreOrientationBiasMetricsOverContext(PreAdapterOrientationScorer.java:78); at org.broadinstitute.hellbender.tools.exome.FilterByOrientationBias.onTraversalStart(FilterByOrientationBias.java:191); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:964); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); at org.broadinstitute.hellbender.Main.main(Main.java:291); ```. These calls are from IonTorrent platform (not Illumina), maybe that could be an issue?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5553#issuecomment-485476488
https://github.com/broadinstitute/gatk/issues/5553#issuecomment-485923047:428,Usability,Learn,LearnReadOrientationModel,428,"@sahilseth This is actually a different issue. The solution is to not run `CollectSequencingArtifactMetrics` and any other tools involved in orientation bias filtering. Single-end reads do not have orientation bias artifacts and the whole model assumes paired reads. For the record, we recently deprecated `CollectSequencingArtifactMetrics` and `FilterByOrientationBias` in favor of our new orientation bias workflow that uses `LearnReadOrientationModel`. But for single-end sequencing you shouldn't use the old workflow or the new workflow.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5553#issuecomment-485923047
https://github.com/broadinstitute/gatk/pull/5556#issuecomment-451482997:58,Testability,test,tests,58,"@LeeTL1220 @jonn-smith apologies for the blips in getting tests to pass on Travis, but I think this branch should be OK now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5556#issuecomment-451482997
https://github.com/broadinstitute/gatk/issues/5559#issuecomment-634752181:45,Testability,test,tests,45,"It should be possible to do this now, though tests need to be added.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5559#issuecomment-634752181
https://github.com/broadinstitute/gatk/pull/5560#issuecomment-452017370:3461,Usability,Learn,LearnReadOrientationModelEngineUnitTest,3461,KVCFConstants.java](https://codecov.io/gh/broadinstitute/gatk/pull/5560/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L0dBVEtWQ0ZDb25zdGFudHMuamF2YQ==) | `75% <ø> (-5%)` | `4 <0> (ø)` | |; | [...ntamination/GetPileupSummariesIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5560/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2NvbnRhbWluYXRpb24vR2V0UGlsZXVwU3VtbWFyaWVzSW50ZWdyYXRpb25UZXN0LmphdmE=) | `95.745% <100%> (+0.29%)` | `4 <0> (ø)` | :arrow_down: |; | [...e/hellbender/utils/variant/GATKVCFHeaderLines.java](https://codecov.io/gh/broadinstitute/gatk/pull/5560/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L0dBVEtWQ0ZIZWFkZXJMaW5lcy5qYXZh) | `95.906% <100%> (+0.073%)` | `10 <0> (ø)` | :arrow_down: |; | [...walkers/readorientation/ArtifactPriorUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5560/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3JlYWRvcmllbnRhdGlvbi9BcnRpZmFjdFByaW9yVW5pdFRlc3QuamF2YQ==) | `100% <100%> (ø)` | `7 <0> (ø)` | :arrow_down: |; | [...ation/LearnReadOrientationModelEngineUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5560/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3JlYWRvcmllbnRhdGlvbi9MZWFyblJlYWRPcmllbnRhdGlvbk1vZGVsRW5naW5lVW5pdFRlc3QuamF2YQ==) | `95.671% <100%> (ø)` | `43 <0> (ø)` | :arrow_down: |; | [...ols/walkers/contamination/ContaminationRecord.java](https://codecov.io/gh/broadinstitute/gatk/pull/5560/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2NvbnRhbWluYXRpb24vQ29udGFtaW5hdGlvblJlY29yZC5qYXZh) | `89.744% <100%> (+1.508%)` | `6 <2> (+1)` | :arrow_up: |; | ... and [42 more](https://codecov.io/gh/broadinstitute/gatk/pull/5560/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5560#issuecomment-452017370
https://github.com/broadinstitute/gatk/pull/5562#issuecomment-467604200:34,Testability,test,test,34,@ldgauthier I put in a regression test from the user's data.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5562#issuecomment-467604200
https://github.com/broadinstitute/gatk/pull/5563#issuecomment-452010770:22,Deployability,patch,patched,22,"Awesome, glad this is patched up so fast. Will this get picked up by the nightly docker build? I can test tomorrow if so.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5563#issuecomment-452010770
https://github.com/broadinstitute/gatk/pull/5563#issuecomment-452010770:101,Testability,test,test,101,"Awesome, glad this is patched up so fast. Will this get picked up by the nightly docker build? I can test tomorrow if so.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5563#issuecomment-452010770
https://github.com/broadinstitute/gatk/pull/5563#issuecomment-452016657:66,Deployability,release,release,66,Thank you! I also wonder if you could advise timeline for the new release with this fix.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5563#issuecomment-452016657
https://github.com/broadinstitute/gatk/pull/5563#issuecomment-452020693:195,Availability,avail,available,195,"The next release is going to be a big 4.1 minor version release, so there are a lot of new features we're trying to finish up. Hopefully it will be by the end of the month, but a nightly will be available with this change by tomorrow: https://hub.docker.com/r/broadinstitute/gatk-nightly",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5563#issuecomment-452020693
https://github.com/broadinstitute/gatk/pull/5563#issuecomment-452020693:9,Deployability,release,release,9,"The next release is going to be a big 4.1 minor version release, so there are a lot of new features we're trying to finish up. Hopefully it will be by the end of the month, but a nightly will be available with this change by tomorrow: https://hub.docker.com/r/broadinstitute/gatk-nightly",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5563#issuecomment-452020693
https://github.com/broadinstitute/gatk/pull/5563#issuecomment-452020693:56,Deployability,release,release,56,"The next release is going to be a big 4.1 minor version release, so there are a lot of new features we're trying to finish up. Hopefully it will be by the end of the month, but a nightly will be available with this change by tomorrow: https://hub.docker.com/r/broadinstitute/gatk-nightly",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5563#issuecomment-452020693
https://github.com/broadinstitute/gatk/pull/5563#issuecomment-452022519:45,Availability,error,error,45,"Just wanted to mention, I'm able to get this error when I use --af-of-alleles-not-in-resource 0.00003125. Noticed the edge case just mentioned 0, but if this hasn't already been dealt with in this fix, I can provide more information. . Edit: I've noticed that this happens when I supply -I tumor.bam -I normal.bam -tumor SAMPLE1 and I don't specify a -normal SAMPLE2. If I do include the -normal SAMPLE2, it works fine without error. Not sure if intended or not.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5563#issuecomment-452022519
https://github.com/broadinstitute/gatk/pull/5563#issuecomment-452022519:427,Availability,error,error,427,"Just wanted to mention, I'm able to get this error when I use --af-of-alleles-not-in-resource 0.00003125. Noticed the edge case just mentioned 0, but if this hasn't already been dealt with in this fix, I can provide more information. . Edit: I've noticed that this happens when I supply -I tumor.bam -I normal.bam -tumor SAMPLE1 and I don't specify a -normal SAMPLE2. If I do include the -normal SAMPLE2, it works fine without error. Not sure if intended or not.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5563#issuecomment-452022519
https://github.com/broadinstitute/gatk/pull/5563#issuecomment-452334334:87,Availability,error,error,87,"@ldgauthier the nightly docker build you pointed to seems behind 4.0.12.0. The Mutect2 error fixed in #5442 is present in the nightly docker build, so I can't test this fix.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5563#issuecomment-452334334
https://github.com/broadinstitute/gatk/pull/5563#issuecomment-452334334:159,Testability,test,test,159,"@ldgauthier the nightly docker build you pointed to seems behind 4.0.12.0. The Mutect2 error fixed in #5442 is present in the nightly docker build, so I can't test this fix.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5563#issuecomment-452334334
https://github.com/broadinstitute/gatk/pull/5563#issuecomment-452485251:67,Testability,test,tested,67,"@davidbenjamin Hmm, it doesn't seem to resolve the issue for me. I tested as below and same exception was thrown. Could you confirm if I tested correctly?. ```; java -jar gatk-package-4.0.12.0-18-g0570670-SNAPSHOT-local.jar FilterMutectCalls -V test-unfiltered.vcf -O test-filtered.vcf.gz; ```. $ cat test-unfiltered.vcf; ```; ##fileformat=VCFv4.2; ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Allelic depths for the ref and alt alleles in the order listed"">; ##FORMAT=<ID=AF,Number=A,Type=Float,Description=""Allele fractions of alternate alleles in the tumor"">; ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Approximate read depth (reads with MQ=255 or with bad mates are filtered)"">; ##FORMAT=<ID=F1R2,Number=R,Type=Integer,Description=""Count of reads in F1R2 pair orientation supporting each allele"">; ##FORMAT=<ID=F2R1,Number=R,Type=Integer,Description=""Count of reads in F2R1 pair orientation supporting each allele"">; ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Genotype Quality"">; ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">; ##FORMAT=<ID=PGT,Number=1,Type=String,Description=""Physical phasing haplotype information, describing how the alternate alleles are phased in relation to one another"">; ##FORMAT=<ID=PID,Number=1,Type=String,Description=""Physical phasing ID information, where each unique ID within a given sample (but not across samples) connects records within a phasing group"">; ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification"">; ##FORMAT=<ID=PS,Number=1,Type=Integer,Description=""Phasing set (typically the position of the first variant in the set)"">; ##FORMAT=<ID=P_PRIOR_RO,Number=1,Type=Float,Description=""prior probability of read orientation-based artifacts under the present referene context"">; ##FORMAT=<ID=P_RO,Number=1,Type=Float,Description=""posterior probability of read orientation-based artifacts"">; ##FORMAT=<ID=ROF_TYPE,Number=1,Type=String,D",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5563#issuecomment-452485251
https://github.com/broadinstitute/gatk/pull/5563#issuecomment-452485251:137,Testability,test,tested,137,"@davidbenjamin Hmm, it doesn't seem to resolve the issue for me. I tested as below and same exception was thrown. Could you confirm if I tested correctly?. ```; java -jar gatk-package-4.0.12.0-18-g0570670-SNAPSHOT-local.jar FilterMutectCalls -V test-unfiltered.vcf -O test-filtered.vcf.gz; ```. $ cat test-unfiltered.vcf; ```; ##fileformat=VCFv4.2; ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Allelic depths for the ref and alt alleles in the order listed"">; ##FORMAT=<ID=AF,Number=A,Type=Float,Description=""Allele fractions of alternate alleles in the tumor"">; ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Approximate read depth (reads with MQ=255 or with bad mates are filtered)"">; ##FORMAT=<ID=F1R2,Number=R,Type=Integer,Description=""Count of reads in F1R2 pair orientation supporting each allele"">; ##FORMAT=<ID=F2R1,Number=R,Type=Integer,Description=""Count of reads in F2R1 pair orientation supporting each allele"">; ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Genotype Quality"">; ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">; ##FORMAT=<ID=PGT,Number=1,Type=String,Description=""Physical phasing haplotype information, describing how the alternate alleles are phased in relation to one another"">; ##FORMAT=<ID=PID,Number=1,Type=String,Description=""Physical phasing ID information, where each unique ID within a given sample (but not across samples) connects records within a phasing group"">; ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification"">; ##FORMAT=<ID=PS,Number=1,Type=Integer,Description=""Phasing set (typically the position of the first variant in the set)"">; ##FORMAT=<ID=P_PRIOR_RO,Number=1,Type=Float,Description=""prior probability of read orientation-based artifacts under the present referene context"">; ##FORMAT=<ID=P_RO,Number=1,Type=Float,Description=""posterior probability of read orientation-based artifacts"">; ##FORMAT=<ID=ROF_TYPE,Number=1,Type=String,D",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5563#issuecomment-452485251
https://github.com/broadinstitute/gatk/pull/5563#issuecomment-452485251:245,Testability,test,test-unfiltered,245,"@davidbenjamin Hmm, it doesn't seem to resolve the issue for me. I tested as below and same exception was thrown. Could you confirm if I tested correctly?. ```; java -jar gatk-package-4.0.12.0-18-g0570670-SNAPSHOT-local.jar FilterMutectCalls -V test-unfiltered.vcf -O test-filtered.vcf.gz; ```. $ cat test-unfiltered.vcf; ```; ##fileformat=VCFv4.2; ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Allelic depths for the ref and alt alleles in the order listed"">; ##FORMAT=<ID=AF,Number=A,Type=Float,Description=""Allele fractions of alternate alleles in the tumor"">; ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Approximate read depth (reads with MQ=255 or with bad mates are filtered)"">; ##FORMAT=<ID=F1R2,Number=R,Type=Integer,Description=""Count of reads in F1R2 pair orientation supporting each allele"">; ##FORMAT=<ID=F2R1,Number=R,Type=Integer,Description=""Count of reads in F2R1 pair orientation supporting each allele"">; ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Genotype Quality"">; ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">; ##FORMAT=<ID=PGT,Number=1,Type=String,Description=""Physical phasing haplotype information, describing how the alternate alleles are phased in relation to one another"">; ##FORMAT=<ID=PID,Number=1,Type=String,Description=""Physical phasing ID information, where each unique ID within a given sample (but not across samples) connects records within a phasing group"">; ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification"">; ##FORMAT=<ID=PS,Number=1,Type=Integer,Description=""Phasing set (typically the position of the first variant in the set)"">; ##FORMAT=<ID=P_PRIOR_RO,Number=1,Type=Float,Description=""prior probability of read orientation-based artifacts under the present referene context"">; ##FORMAT=<ID=P_RO,Number=1,Type=Float,Description=""posterior probability of read orientation-based artifacts"">; ##FORMAT=<ID=ROF_TYPE,Number=1,Type=String,D",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5563#issuecomment-452485251
https://github.com/broadinstitute/gatk/pull/5563#issuecomment-452485251:268,Testability,test,test-filtered,268,"@davidbenjamin Hmm, it doesn't seem to resolve the issue for me. I tested as below and same exception was thrown. Could you confirm if I tested correctly?. ```; java -jar gatk-package-4.0.12.0-18-g0570670-SNAPSHOT-local.jar FilterMutectCalls -V test-unfiltered.vcf -O test-filtered.vcf.gz; ```. $ cat test-unfiltered.vcf; ```; ##fileformat=VCFv4.2; ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Allelic depths for the ref and alt alleles in the order listed"">; ##FORMAT=<ID=AF,Number=A,Type=Float,Description=""Allele fractions of alternate alleles in the tumor"">; ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Approximate read depth (reads with MQ=255 or with bad mates are filtered)"">; ##FORMAT=<ID=F1R2,Number=R,Type=Integer,Description=""Count of reads in F1R2 pair orientation supporting each allele"">; ##FORMAT=<ID=F2R1,Number=R,Type=Integer,Description=""Count of reads in F2R1 pair orientation supporting each allele"">; ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Genotype Quality"">; ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">; ##FORMAT=<ID=PGT,Number=1,Type=String,Description=""Physical phasing haplotype information, describing how the alternate alleles are phased in relation to one another"">; ##FORMAT=<ID=PID,Number=1,Type=String,Description=""Physical phasing ID information, where each unique ID within a given sample (but not across samples) connects records within a phasing group"">; ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification"">; ##FORMAT=<ID=PS,Number=1,Type=Integer,Description=""Phasing set (typically the position of the first variant in the set)"">; ##FORMAT=<ID=P_PRIOR_RO,Number=1,Type=Float,Description=""prior probability of read orientation-based artifacts under the present referene context"">; ##FORMAT=<ID=P_RO,Number=1,Type=Float,Description=""posterior probability of read orientation-based artifacts"">; ##FORMAT=<ID=ROF_TYPE,Number=1,Type=String,D",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5563#issuecomment-452485251
https://github.com/broadinstitute/gatk/pull/5563#issuecomment-452485251:301,Testability,test,test-unfiltered,301,"@davidbenjamin Hmm, it doesn't seem to resolve the issue for me. I tested as below and same exception was thrown. Could you confirm if I tested correctly?. ```; java -jar gatk-package-4.0.12.0-18-g0570670-SNAPSHOT-local.jar FilterMutectCalls -V test-unfiltered.vcf -O test-filtered.vcf.gz; ```. $ cat test-unfiltered.vcf; ```; ##fileformat=VCFv4.2; ##FORMAT=<ID=AD,Number=R,Type=Integer,Description=""Allelic depths for the ref and alt alleles in the order listed"">; ##FORMAT=<ID=AF,Number=A,Type=Float,Description=""Allele fractions of alternate alleles in the tumor"">; ##FORMAT=<ID=DP,Number=1,Type=Integer,Description=""Approximate read depth (reads with MQ=255 or with bad mates are filtered)"">; ##FORMAT=<ID=F1R2,Number=R,Type=Integer,Description=""Count of reads in F1R2 pair orientation supporting each allele"">; ##FORMAT=<ID=F2R1,Number=R,Type=Integer,Description=""Count of reads in F2R1 pair orientation supporting each allele"">; ##FORMAT=<ID=GQ,Number=1,Type=Integer,Description=""Genotype Quality"">; ##FORMAT=<ID=GT,Number=1,Type=String,Description=""Genotype"">; ##FORMAT=<ID=PGT,Number=1,Type=String,Description=""Physical phasing haplotype information, describing how the alternate alleles are phased in relation to one another"">; ##FORMAT=<ID=PID,Number=1,Type=String,Description=""Physical phasing ID information, where each unique ID within a given sample (but not across samples) connects records within a phasing group"">; ##FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification"">; ##FORMAT=<ID=PS,Number=1,Type=Integer,Description=""Phasing set (typically the position of the first variant in the set)"">; ##FORMAT=<ID=P_PRIOR_RO,Number=1,Type=Float,Description=""prior probability of read orientation-based artifacts under the present referene context"">; ##FORMAT=<ID=P_RO,Number=1,Type=Float,Description=""posterior probability of read orientation-based artifacts"">; ##FORMAT=<ID=ROF_TYPE,Number=1,Type=String,D",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5563#issuecomment-452485251
https://github.com/broadinstitute/gatk/pull/5563#issuecomment-452485251:3076,Testability,log,log,3076,"rmalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification"">; ##FORMAT=<ID=PS,Number=1,Type=Integer,Description=""Phasing set (typically the position of the first variant in the set)"">; ##FORMAT=<ID=P_PRIOR_RO,Number=1,Type=Float,Description=""prior probability of read orientation-based artifacts under the present referene context"">; ##FORMAT=<ID=P_RO,Number=1,Type=Float,Description=""posterior probability of read orientation-based artifacts"">; ##FORMAT=<ID=ROF_TYPE,Number=1,Type=String,Description=""type of read orientation artifact (F1R2 or F2R1)"">; ##FORMAT=<ID=SAAF,Number=3,Type=Float,Description=""MAP estimates of allele fraction given z"">; ##FORMAT=<ID=SAPP,Number=3,Type=Float,Description=""posterior probabilities of the presence of strand artifact"">; ##INFO=<ID=CONTQ,Number=1,Type=Float,Description=""Phred-scaled qualities that alt allele are not due to contamination"">; ##INFO=<ID=DP,Number=1,Type=Integer,Description=""Approximate read depth; some reads may have been filtered"">; ##INFO=<ID=ECNT,Number=1,Type=Integer,Description=""Number of events in this haplotype"">; ##INFO=<ID=GERMQ,Number=A,Type=Integer,Description=""Phred-scaled qualities that alt allele are not germline variants"">; ##INFO=<ID=MBQ,Number=R,Type=Integer,Description=""median base quality"">; ##INFO=<ID=MFRL,Number=R,Type=Integer,Description=""median fragment length"">; ##INFO=<ID=MMQ,Number=R,Type=Integer,Description=""median mapping quality"">; ##INFO=<ID=MPOS,Number=A,Type=Integer,Description=""median distance from end of read"">; ##INFO=<ID=NALOD,Number=A,Type=Float,Description=""log odds of artifact in normal with same allele fraction as tumor"">; ##INFO=<ID=NLOD,Number=A,Type=Float,Description=""Normal LOD score"">; ##INFO=<ID=PON,Number=0,Type=Flag,Description=""site found in panel of normals"">; ##INFO=<ID=POPAF,Number=A,Type=Float,Description=""negative-log-10 population allele frequencies of alt alleles"">; ##INFO=<ID=REF_BASES,Number=1,Type=String,Description=""local reference bases.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5563#issuecomment-452485251
https://github.com/broadinstitute/gatk/pull/5563#issuecomment-452485251:3354,Testability,log,log-,3354,"rmalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification"">; ##FORMAT=<ID=PS,Number=1,Type=Integer,Description=""Phasing set (typically the position of the first variant in the set)"">; ##FORMAT=<ID=P_PRIOR_RO,Number=1,Type=Float,Description=""prior probability of read orientation-based artifacts under the present referene context"">; ##FORMAT=<ID=P_RO,Number=1,Type=Float,Description=""posterior probability of read orientation-based artifacts"">; ##FORMAT=<ID=ROF_TYPE,Number=1,Type=String,Description=""type of read orientation artifact (F1R2 or F2R1)"">; ##FORMAT=<ID=SAAF,Number=3,Type=Float,Description=""MAP estimates of allele fraction given z"">; ##FORMAT=<ID=SAPP,Number=3,Type=Float,Description=""posterior probabilities of the presence of strand artifact"">; ##INFO=<ID=CONTQ,Number=1,Type=Float,Description=""Phred-scaled qualities that alt allele are not due to contamination"">; ##INFO=<ID=DP,Number=1,Type=Integer,Description=""Approximate read depth; some reads may have been filtered"">; ##INFO=<ID=ECNT,Number=1,Type=Integer,Description=""Number of events in this haplotype"">; ##INFO=<ID=GERMQ,Number=A,Type=Integer,Description=""Phred-scaled qualities that alt allele are not germline variants"">; ##INFO=<ID=MBQ,Number=R,Type=Integer,Description=""median base quality"">; ##INFO=<ID=MFRL,Number=R,Type=Integer,Description=""median fragment length"">; ##INFO=<ID=MMQ,Number=R,Type=Integer,Description=""median mapping quality"">; ##INFO=<ID=MPOS,Number=A,Type=Integer,Description=""median distance from end of read"">; ##INFO=<ID=NALOD,Number=A,Type=Float,Description=""log odds of artifact in normal with same allele fraction as tumor"">; ##INFO=<ID=NLOD,Number=A,Type=Float,Description=""Normal LOD score"">; ##INFO=<ID=PON,Number=0,Type=Flag,Description=""site found in panel of normals"">; ##INFO=<ID=POPAF,Number=A,Type=Float,Description=""negative-log-10 population allele frequencies of alt alleles"">; ##INFO=<ID=REF_BASES,Number=1,Type=String,Description=""local reference bases.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5563#issuecomment-452485251
https://github.com/broadinstitute/gatk/pull/5563#issuecomment-452485251:3839,Testability,Log,Log,3839,"riants"">; ##INFO=<ID=MBQ,Number=R,Type=Integer,Description=""median base quality"">; ##INFO=<ID=MFRL,Number=R,Type=Integer,Description=""median fragment length"">; ##INFO=<ID=MMQ,Number=R,Type=Integer,Description=""median mapping quality"">; ##INFO=<ID=MPOS,Number=A,Type=Integer,Description=""median distance from end of read"">; ##INFO=<ID=NALOD,Number=A,Type=Float,Description=""log odds of artifact in normal with same allele fraction as tumor"">; ##INFO=<ID=NLOD,Number=A,Type=Float,Description=""Normal LOD score"">; ##INFO=<ID=PON,Number=0,Type=Flag,Description=""site found in panel of normals"">; ##INFO=<ID=POPAF,Number=A,Type=Float,Description=""negative-log-10 population allele frequencies of alt alleles"">; ##INFO=<ID=REF_BASES,Number=1,Type=String,Description=""local reference bases."">; ##INFO=<ID=RPA,Number=.,Type=Integer,Description=""Number of times tandem repeat unit is repeated, for each allele (including reference)"">; ##INFO=<ID=RU,Number=1,Type=String,Description=""Tandem repeat unit (bases)"">; ##INFO=<ID=STR,Number=0,Type=Flag,Description=""Variant is a short tandem repeat"">; ##INFO=<ID=TLOD,Number=A,Type=Float,Description=""Log odds ratio score for variant"">; ##MutectVersion=2.1; ##contig=<ID=1,length=249250621>; ##contig=<ID=2,length=243199373>; ##contig=<ID=3,length=198022430>; ##contig=<ID=4,length=191154276>; ##contig=<ID=5,length=180915260>; ##contig=<ID=6,length=171115067>; ##contig=<ID=7,length=159138663>; ##contig=<ID=8,length=146364022>; ##contig=<ID=9,length=141213431>; ##contig=<ID=10,length=135534747>; ##contig=<ID=11,length=135006516>; ##contig=<ID=12,length=133851895>; ##contig=<ID=13,length=115169878>; ##contig=<ID=14,length=107349540>; ##contig=<ID=15,length=102531392>; ##contig=<ID=16,length=90354753>; ##contig=<ID=17,length=81195210>; ##contig=<ID=18,length=78077248>; ##contig=<ID=19,length=59128983>; ##contig=<ID=20,length=63025520>; ##contig=<ID=21,length=48129895>; ##contig=<ID=22,length=51304566>; ##contig=<ID=X,length=155270560>; ##contig=<ID=Y,leng",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5563#issuecomment-452485251
https://github.com/broadinstitute/gatk/pull/5563#issuecomment-452818901:1307,Integrability,wrap,wrapAndCopyInto,1307," DP=72;ECNT=2;MBQ=0,0;MFRL=0,0;MMQ=0,0;MPOS=0;POPAF=7.30;REF_BASES=GGTATACAAGGTTTGACATCT;SAAF=0.00,0.00,NaN;SAPP=0.025,0.025,0.950;TLOD=6.82 GT:AD:AF:DP:F1R2:F2R1:PGT:PID:PS:P_PRIOR_RO:P_RO:ROF_TYPE 0|1:0,0:0.962:0:0,0:0,0:0|1:53302899_G_C:53302899:1.444e-05:2.931e-03:F2R1; ```. Stacktrace:; ```; java.lang.IllegalArgumentException: errorRateLog10 must be good probability but got NaN; at org.broadinstitute.hellbender.utils.QualityUtils.phredScaleLog10ErrorRate(QualityUtils.java:321); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.lambda$applyGermlineVariantFilter$16(Mutect2FilteringEngine.java:286); at java.util.stream.DoublePipeline$3$1.accept(DoublePipeline.java:231); at java.util.Spliterators$DoubleArraySpliterator.forEachRemaining(Spliterators.java:1198); at java.util.Spliterator$OfDouble.forEachRemaining(Spliterator.java:822); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:545); at java.util.stream.AbstractPipeline.evaluateToArrayNode(AbstractPipeline.java:260); at java.util.stream.IntPipeline.toArray(IntPipeline.java:502); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.applyGermlineVariantFilter(Mutect2FilteringEngine.java:286); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.calculateFilters(Mutect2FilteringEngine.java:519); at org.broadinstitute.hellbender.tools.walkers.mutect.FilterMutectCalls.firstPassApply(FilterMutectCalls.java:130); at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.lambda$traverseVariants$0(TwoPassVariantWalker.java:76); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpli",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5563#issuecomment-452818901
https://github.com/broadinstitute/gatk/pull/5563#issuecomment-452818901:2485,Integrability,wrap,wrapAndCopyInto,2485,va:260); at java.util.stream.IntPipeline.toArray(IntPipeline.java:502); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.applyGermlineVariantFilter(Mutect2FilteringEngine.java:286); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.calculateFilters(Mutect2FilteringEngine.java:519); at org.broadinstitute.hellbender.tools.walkers.mutect.FilterMutectCalls.firstPassApply(FilterMutectCalls.java:130); at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.lambda$traverseVariants$0(TwoPassVariantWalker.java:76); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.traverseVariants(TwoPassVariantWalker.java:74); at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.traverse(TwoPassVariantWalker.java:27); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:966); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLin,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5563#issuecomment-452818901
https://github.com/broadinstitute/gatk/pull/5563#issuecomment-452818901:176,Testability,test,tested,176,"@davidbenjamin Thank you for your kind explanations! It motivated me to read JVM spec.; BTW, it looks that at least another edge case exists, which is not fixed by the PRs.; I tested with `gatk-4.0.12.0-20-gf9a2e5c-SNAPSHOT`. Variant (also wonder how 0 values for DP and AD can be interpreted) :; ```; 19 53302899 . G C . . DP=72;ECNT=2;MBQ=0,0;MFRL=0,0;MMQ=0,0;MPOS=0;POPAF=7.30;REF_BASES=GGTATACAAGGTTTGACATCT;SAAF=0.00,0.00,NaN;SAPP=0.025,0.025,0.950;TLOD=6.82 GT:AD:AF:DP:F1R2:F2R1:PGT:PID:PS:P_PRIOR_RO:P_RO:ROF_TYPE 0|1:0,0:0.962:0:0,0:0,0:0|1:53302899_G_C:53302899:1.444e-05:2.931e-03:F2R1; ```. Stacktrace:; ```; java.lang.IllegalArgumentException: errorRateLog10 must be good probability but got NaN; at org.broadinstitute.hellbender.utils.QualityUtils.phredScaleLog10ErrorRate(QualityUtils.java:321); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.lambda$applyGermlineVariantFilter$16(Mutect2FilteringEngine.java:286); at java.util.stream.DoublePipeline$3$1.accept(DoublePipeline.java:231); at java.util.Spliterators$DoubleArraySpliterator.forEachRemaining(Spliterators.java:1198); at java.util.Spliterator$OfDouble.forEachRemaining(Spliterator.java:822); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:545); at java.util.stream.AbstractPipeline.evaluateToArrayNode(AbstractPipeline.java:260); at java.util.stream.IntPipeline.toArray(IntPipeline.java:502); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.applyGermlineVariantFilter(Mutect2FilteringEngine.java:286); at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2FilteringEngine.calculateFilters(Mutect2FilteringEngine.java:519); at org.broadinstitute.hellbender.tools.walkers.mutect.FilterMutectCalls.firstPassApply(FilterMutectCalls.java:130); at org.broadinstitute.hellbender.engine.TwoPas",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5563#issuecomment-452818901
https://github.com/broadinstitute/gatk/pull/5563#issuecomment-452851947:72,Modifiability,refactor,refactoring,72,"@byoo Thanks, we will fix that one ASAP. By the way, we are doing a big refactoring of Mutect2 filtering, which won't change the outputs but will improve the internal software engineering so that we can write better unit tests to catch these sorts of things.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5563#issuecomment-452851947
https://github.com/broadinstitute/gatk/pull/5563#issuecomment-452851947:221,Testability,test,tests,221,"@byoo Thanks, we will fix that one ASAP. By the way, we are doing a big refactoring of Mutect2 filtering, which won't change the outputs but will improve the internal software engineering so that we can write better unit tests to catch these sorts of things.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5563#issuecomment-452851947
https://github.com/broadinstitute/gatk/issues/5564#issuecomment-478308694:0,Deployability,Update,Update,0,Update: there's another example on that thread now. If no one objects I'm going to do this.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-478308694
https://github.com/broadinstitute/gatk/issues/5564#issuecomment-478586914:236,Deployability,Update,Update,236,"Let's do it. There are a lot of weirdly represented complex events in the; gnomAD browser that have come up and I expect this should fix 99% of them. On Sat, Mar 30, 2019 at 11:28 PM David Benjamin <notifications@github.com>; wrote:. > Update: there's another example on that thread now. If no one objects I'm; > going to do this.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/5564#issuecomment-478308694>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdEXlYsOHiNeV5drfdrjIuDbiY6fpks5vcCtLgaJpZM4Zyez7>; > .; >. -- ; Laura Doyle Gauthier, Ph.D.; Associate Director, Germline Methods; Data Sciences Platform; gauthier@broadinstitute.org; Broad Institute of MIT & Harvard; 320 Charles St.; Cambridge MA 0214",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-478586914
https://github.com/broadinstitute/gatk/issues/5564#issuecomment-489654799:115,Usability,simpl,simple,115,"So, I tried this out and it's harder than it seems. Some calls get better, some get worse. There probably exists a simple set of heuristics to make reasonable alignments, but I don't think that it can be represented as a single set of SW parameters. We might need to have some kind post-processing to judge whether a better alignment than the Smith-Waterman one exists.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-489654799
https://github.com/broadinstitute/gatk/issues/5564#issuecomment-710107566:1273,Availability,avail,availability,1273,"r -> vcfeval F1 on NA12878 chr22 (with F1 optimized on GQ threshold and enabling decomposition of variants) as the target. This is probably not what we want to ultimately do in practice---we may want to more heavily weight sensitivity after calling, hook up variant filtering, stratify on high/low confidence regions or variant characteristics, etc.---but I'm just curious to see what happens. I see two potentially useful outcomes: 1) we demonstrate that parameters don't have much of an effect and can be consolidated, or 2) we find more optimal sets of parameters. Potentially we could also show that 3) our parameters are already optimal (I'd say this would be by pure dumb luck), in which case we could at least demonstrate and document some justification for them. If the parameters don't have much of an impact on NA12878, I'm curious to see whether this holds for low coverage or messier data---and ultimately, in malaria. Just starting with NA12878 because of the availability of truth and the potential impact for the primary use case of calling in human data. Some preliminary results: I ran the aforementioned comparison on chr22 with 1) 4.1.8.1 master and 2) 4.1.8.1 with haplotype-to-reference SW parameters changed from `NEW_SW_PARAMETERS` to `STANDARD_NGS` on two replicates of NA12878 (O1D1 and O2D2 from the 2018 NovaSeq snapshot experiment). On each replicate, 2) demonstrated slightly lower performance, but it was well within the sample-to-sample variation between these two replicates. Here are the corresponding vcfeval summaries:. ```; ::::::::::::::; NA12878/O1D1/4.1.8.1/summary.txt; ::::::::::::::; Threshold True-pos-baseline True-pos-call False-pos False-neg Precision Sensitivity F-measure; ----------------------------------------------------------------------------------------------------; 84.000 40778 40780 35116 1412 0.5373 0.9665 0.6907; None 41994 41994 43760 196 0.4897 0.9954 0.6564; ::::::::::::::; NA12878/O1D1/STANDARD_NGS/summary.txt; ::::::::::::::; Thres",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-710107566
https://github.com/broadinstitute/gatk/issues/5564#issuecomment-710107566:106,Deployability,pipeline,pipeline-optimizer,106,"Consolidated with #2498. Now that #6885 is done, I'm going to kick off a Bayesian optimization (using the pipeline-optimizer from https://github.com/broadinstitute/gatk-evaluation/tree/master/pipeline-optimizer I presented on long ago) over all 3 sets of SW parameters using unfiltered HaplotypeCaller -> vcfeval F1 on NA12878 chr22 (with F1 optimized on GQ threshold and enabling decomposition of variants) as the target. This is probably not what we want to ultimately do in practice---we may want to more heavily weight sensitivity after calling, hook up variant filtering, stratify on high/low confidence regions or variant characteristics, etc.---but I'm just curious to see what happens. I see two potentially useful outcomes: 1) we demonstrate that parameters don't have much of an effect and can be consolidated, or 2) we find more optimal sets of parameters. Potentially we could also show that 3) our parameters are already optimal (I'd say this would be by pure dumb luck), in which case we could at least demonstrate and document some justification for them. If the parameters don't have much of an impact on NA12878, I'm curious to see whether this holds for low coverage or messier data---and ultimately, in malaria. Just starting with NA12878 because of the availability of truth and the potential impact for the primary use case of calling in human data. Some preliminary results: I ran the aforementioned comparison on chr22 with 1) 4.1.8.1 master and 2) 4.1.8.1 with haplotype-to-reference SW parameters changed from `NEW_SW_PARAMETERS` to `STANDARD_NGS` on two replicates of NA12878 (O1D1 and O2D2 from the 2018 NovaSeq snapshot experiment). On each replicate, 2) demonstrated slightly lower performance, but it was well within the sample-to-sample variation between these two replicates. Here are the corresponding vcfeval summaries:. ```; ::::::::::::::; NA12878/O1D1/4.1.8.1/summary.txt; ::::::::::::::; Threshold True-pos-baseline True-pos-call False-pos False-neg Precision Sen",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-710107566
https://github.com/broadinstitute/gatk/issues/5564#issuecomment-710107566:192,Deployability,pipeline,pipeline-optimizer,192,"Consolidated with #2498. Now that #6885 is done, I'm going to kick off a Bayesian optimization (using the pipeline-optimizer from https://github.com/broadinstitute/gatk-evaluation/tree/master/pipeline-optimizer I presented on long ago) over all 3 sets of SW parameters using unfiltered HaplotypeCaller -> vcfeval F1 on NA12878 chr22 (with F1 optimized on GQ threshold and enabling decomposition of variants) as the target. This is probably not what we want to ultimately do in practice---we may want to more heavily weight sensitivity after calling, hook up variant filtering, stratify on high/low confidence regions or variant characteristics, etc.---but I'm just curious to see what happens. I see two potentially useful outcomes: 1) we demonstrate that parameters don't have much of an effect and can be consolidated, or 2) we find more optimal sets of parameters. Potentially we could also show that 3) our parameters are already optimal (I'd say this would be by pure dumb luck), in which case we could at least demonstrate and document some justification for them. If the parameters don't have much of an impact on NA12878, I'm curious to see whether this holds for low coverage or messier data---and ultimately, in malaria. Just starting with NA12878 because of the availability of truth and the potential impact for the primary use case of calling in human data. Some preliminary results: I ran the aforementioned comparison on chr22 with 1) 4.1.8.1 master and 2) 4.1.8.1 with haplotype-to-reference SW parameters changed from `NEW_SW_PARAMETERS` to `STANDARD_NGS` on two replicates of NA12878 (O1D1 and O2D2 from the 2018 NovaSeq snapshot experiment). On each replicate, 2) demonstrated slightly lower performance, but it was well within the sample-to-sample variation between these two replicates. Here are the corresponding vcfeval summaries:. ```; ::::::::::::::; NA12878/O1D1/4.1.8.1/summary.txt; ::::::::::::::; Threshold True-pos-baseline True-pos-call False-pos False-neg Precision Sen",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-710107566
https://github.com/broadinstitute/gatk/issues/5564#issuecomment-710107566:82,Performance,optimiz,optimization,82,"Consolidated with #2498. Now that #6885 is done, I'm going to kick off a Bayesian optimization (using the pipeline-optimizer from https://github.com/broadinstitute/gatk-evaluation/tree/master/pipeline-optimizer I presented on long ago) over all 3 sets of SW parameters using unfiltered HaplotypeCaller -> vcfeval F1 on NA12878 chr22 (with F1 optimized on GQ threshold and enabling decomposition of variants) as the target. This is probably not what we want to ultimately do in practice---we may want to more heavily weight sensitivity after calling, hook up variant filtering, stratify on high/low confidence regions or variant characteristics, etc.---but I'm just curious to see what happens. I see two potentially useful outcomes: 1) we demonstrate that parameters don't have much of an effect and can be consolidated, or 2) we find more optimal sets of parameters. Potentially we could also show that 3) our parameters are already optimal (I'd say this would be by pure dumb luck), in which case we could at least demonstrate and document some justification for them. If the parameters don't have much of an impact on NA12878, I'm curious to see whether this holds for low coverage or messier data---and ultimately, in malaria. Just starting with NA12878 because of the availability of truth and the potential impact for the primary use case of calling in human data. Some preliminary results: I ran the aforementioned comparison on chr22 with 1) 4.1.8.1 master and 2) 4.1.8.1 with haplotype-to-reference SW parameters changed from `NEW_SW_PARAMETERS` to `STANDARD_NGS` on two replicates of NA12878 (O1D1 and O2D2 from the 2018 NovaSeq snapshot experiment). On each replicate, 2) demonstrated slightly lower performance, but it was well within the sample-to-sample variation between these two replicates. Here are the corresponding vcfeval summaries:. ```; ::::::::::::::; NA12878/O1D1/4.1.8.1/summary.txt; ::::::::::::::; Threshold True-pos-baseline True-pos-call False-pos False-neg Precision Sen",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-710107566
https://github.com/broadinstitute/gatk/issues/5564#issuecomment-710107566:115,Performance,optimiz,optimizer,115,"Consolidated with #2498. Now that #6885 is done, I'm going to kick off a Bayesian optimization (using the pipeline-optimizer from https://github.com/broadinstitute/gatk-evaluation/tree/master/pipeline-optimizer I presented on long ago) over all 3 sets of SW parameters using unfiltered HaplotypeCaller -> vcfeval F1 on NA12878 chr22 (with F1 optimized on GQ threshold and enabling decomposition of variants) as the target. This is probably not what we want to ultimately do in practice---we may want to more heavily weight sensitivity after calling, hook up variant filtering, stratify on high/low confidence regions or variant characteristics, etc.---but I'm just curious to see what happens. I see two potentially useful outcomes: 1) we demonstrate that parameters don't have much of an effect and can be consolidated, or 2) we find more optimal sets of parameters. Potentially we could also show that 3) our parameters are already optimal (I'd say this would be by pure dumb luck), in which case we could at least demonstrate and document some justification for them. If the parameters don't have much of an impact on NA12878, I'm curious to see whether this holds for low coverage or messier data---and ultimately, in malaria. Just starting with NA12878 because of the availability of truth and the potential impact for the primary use case of calling in human data. Some preliminary results: I ran the aforementioned comparison on chr22 with 1) 4.1.8.1 master and 2) 4.1.8.1 with haplotype-to-reference SW parameters changed from `NEW_SW_PARAMETERS` to `STANDARD_NGS` on two replicates of NA12878 (O1D1 and O2D2 from the 2018 NovaSeq snapshot experiment). On each replicate, 2) demonstrated slightly lower performance, but it was well within the sample-to-sample variation between these two replicates. Here are the corresponding vcfeval summaries:. ```; ::::::::::::::; NA12878/O1D1/4.1.8.1/summary.txt; ::::::::::::::; Threshold True-pos-baseline True-pos-call False-pos False-neg Precision Sen",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-710107566
https://github.com/broadinstitute/gatk/issues/5564#issuecomment-710107566:201,Performance,optimiz,optimizer,201,"Consolidated with #2498. Now that #6885 is done, I'm going to kick off a Bayesian optimization (using the pipeline-optimizer from https://github.com/broadinstitute/gatk-evaluation/tree/master/pipeline-optimizer I presented on long ago) over all 3 sets of SW parameters using unfiltered HaplotypeCaller -> vcfeval F1 on NA12878 chr22 (with F1 optimized on GQ threshold and enabling decomposition of variants) as the target. This is probably not what we want to ultimately do in practice---we may want to more heavily weight sensitivity after calling, hook up variant filtering, stratify on high/low confidence regions or variant characteristics, etc.---but I'm just curious to see what happens. I see two potentially useful outcomes: 1) we demonstrate that parameters don't have much of an effect and can be consolidated, or 2) we find more optimal sets of parameters. Potentially we could also show that 3) our parameters are already optimal (I'd say this would be by pure dumb luck), in which case we could at least demonstrate and document some justification for them. If the parameters don't have much of an impact on NA12878, I'm curious to see whether this holds for low coverage or messier data---and ultimately, in malaria. Just starting with NA12878 because of the availability of truth and the potential impact for the primary use case of calling in human data. Some preliminary results: I ran the aforementioned comparison on chr22 with 1) 4.1.8.1 master and 2) 4.1.8.1 with haplotype-to-reference SW parameters changed from `NEW_SW_PARAMETERS` to `STANDARD_NGS` on two replicates of NA12878 (O1D1 and O2D2 from the 2018 NovaSeq snapshot experiment). On each replicate, 2) demonstrated slightly lower performance, but it was well within the sample-to-sample variation between these two replicates. Here are the corresponding vcfeval summaries:. ```; ::::::::::::::; NA12878/O1D1/4.1.8.1/summary.txt; ::::::::::::::; Threshold True-pos-baseline True-pos-call False-pos False-neg Precision Sen",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-710107566
https://github.com/broadinstitute/gatk/issues/5564#issuecomment-710107566:342,Performance,optimiz,optimized,342,"Consolidated with #2498. Now that #6885 is done, I'm going to kick off a Bayesian optimization (using the pipeline-optimizer from https://github.com/broadinstitute/gatk-evaluation/tree/master/pipeline-optimizer I presented on long ago) over all 3 sets of SW parameters using unfiltered HaplotypeCaller -> vcfeval F1 on NA12878 chr22 (with F1 optimized on GQ threshold and enabling decomposition of variants) as the target. This is probably not what we want to ultimately do in practice---we may want to more heavily weight sensitivity after calling, hook up variant filtering, stratify on high/low confidence regions or variant characteristics, etc.---but I'm just curious to see what happens. I see two potentially useful outcomes: 1) we demonstrate that parameters don't have much of an effect and can be consolidated, or 2) we find more optimal sets of parameters. Potentially we could also show that 3) our parameters are already optimal (I'd say this would be by pure dumb luck), in which case we could at least demonstrate and document some justification for them. If the parameters don't have much of an impact on NA12878, I'm curious to see whether this holds for low coverage or messier data---and ultimately, in malaria. Just starting with NA12878 because of the availability of truth and the potential impact for the primary use case of calling in human data. Some preliminary results: I ran the aforementioned comparison on chr22 with 1) 4.1.8.1 master and 2) 4.1.8.1 with haplotype-to-reference SW parameters changed from `NEW_SW_PARAMETERS` to `STANDARD_NGS` on two replicates of NA12878 (O1D1 and O2D2 from the 2018 NovaSeq snapshot experiment). On each replicate, 2) demonstrated slightly lower performance, but it was well within the sample-to-sample variation between these two replicates. Here are the corresponding vcfeval summaries:. ```; ::::::::::::::; NA12878/O1D1/4.1.8.1/summary.txt; ::::::::::::::; Threshold True-pos-baseline True-pos-call False-pos False-neg Precision Sen",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-710107566
https://github.com/broadinstitute/gatk/issues/5564#issuecomment-710107566:1711,Performance,perform,performance,1711,"1) we demonstrate that parameters don't have much of an effect and can be consolidated, or 2) we find more optimal sets of parameters. Potentially we could also show that 3) our parameters are already optimal (I'd say this would be by pure dumb luck), in which case we could at least demonstrate and document some justification for them. If the parameters don't have much of an impact on NA12878, I'm curious to see whether this holds for low coverage or messier data---and ultimately, in malaria. Just starting with NA12878 because of the availability of truth and the potential impact for the primary use case of calling in human data. Some preliminary results: I ran the aforementioned comparison on chr22 with 1) 4.1.8.1 master and 2) 4.1.8.1 with haplotype-to-reference SW parameters changed from `NEW_SW_PARAMETERS` to `STANDARD_NGS` on two replicates of NA12878 (O1D1 and O2D2 from the 2018 NovaSeq snapshot experiment). On each replicate, 2) demonstrated slightly lower performance, but it was well within the sample-to-sample variation between these two replicates. Here are the corresponding vcfeval summaries:. ```; ::::::::::::::; NA12878/O1D1/4.1.8.1/summary.txt; ::::::::::::::; Threshold True-pos-baseline True-pos-call False-pos False-neg Precision Sensitivity F-measure; ----------------------------------------------------------------------------------------------------; 84.000 40778 40780 35116 1412 0.5373 0.9665 0.6907; None 41994 41994 43760 196 0.4897 0.9954 0.6564; ::::::::::::::; NA12878/O1D1/STANDARD_NGS/summary.txt; ::::::::::::::; Threshold True-pos-baseline True-pos-call False-pos False-neg Precision Sensitivity F-measure; ----------------------------------------------------------------------------------------------------; 84.000 40743 40745 35255 1447 0.5361 0.9657 0.6895; None 41955 41954 43903 235 0.4886 0.9944 0.6553; ::::::::::::::; NA12878/O1D2/4.1.8.1/summary.txt; ::::::::::::::; Threshold True-pos-baseline True-pos-call False-pos False-neg Precision Sen",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-710107566
https://github.com/broadinstitute/gatk/issues/5564#issuecomment-710153874:81,Deployability,pipeline,pipeline-optimizer,81,"Now that I look at https://github.com/broadinstitute/gatk-evaluation/tree/master/pipeline-optimizer it will take a bit of work to get up to date (it was tied to a particular version of cromwell-tools and Advisor, which is python2-based, has not been actively maintained---exactly why I wanted to move to a more well supported solution...). . If it's not too much trouble, I'll try to get everything running locally on this older stuff for the first round of optimization, but this problem is probably a perfect candidate for the Neptune-based solution that @dalessioluca recently finished at https://github.com/dalessioluca/cromwell_for_ML.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-710153874
https://github.com/broadinstitute/gatk/issues/5564#issuecomment-710153874:90,Performance,optimiz,optimizer,90,"Now that I look at https://github.com/broadinstitute/gatk-evaluation/tree/master/pipeline-optimizer it will take a bit of work to get up to date (it was tied to a particular version of cromwell-tools and Advisor, which is python2-based, has not been actively maintained---exactly why I wanted to move to a more well supported solution...). . If it's not too much trouble, I'll try to get everything running locally on this older stuff for the first round of optimization, but this problem is probably a perfect candidate for the Neptune-based solution that @dalessioluca recently finished at https://github.com/dalessioluca/cromwell_for_ML.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-710153874
https://github.com/broadinstitute/gatk/issues/5564#issuecomment-710153874:458,Performance,optimiz,optimization,458,"Now that I look at https://github.com/broadinstitute/gatk-evaluation/tree/master/pipeline-optimizer it will take a bit of work to get up to date (it was tied to a particular version of cromwell-tools and Advisor, which is python2-based, has not been actively maintained---exactly why I wanted to move to a more well supported solution...). . If it's not too much trouble, I'll try to get everything running locally on this older stuff for the first round of optimization, but this problem is probably a perfect candidate for the Neptune-based solution that @dalessioluca recently finished at https://github.com/dalessioluca/cromwell_for_ML.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-710153874
https://github.com/broadinstitute/gatk/issues/5564#issuecomment-712237919:21,Performance,optimiz,optimizations,21,"I ran a few Bayesian optimizations, mostly focusing on various subsets/ranges of the read-to-haplotype and haplotype-to-reference SW parameters. I also varied whether I used part/all of chr22 and chose either F1/sensitivity as the optimization target. These experiments show that varying the SW parameters can definitely move the needle in terms of performance, even after variant normalization. For example, here are the SNP precision/sensitivity curves for an optimization of F1 over about half of chr22:. ![snp_f1](https://user-images.githubusercontent.com/11076296/96470421-44490900-11fc-11eb-96f6-83a6833b2b1f.png). And the same for indels:. ![non_snp_f1](https://user-images.githubusercontent.com/11076296/96470468-5034cb00-11fc-11eb-86a7-bbf81bc10122.png). This all raises the question of what the best optimization strategy should be. It looks like the SW parameters aren't the limiting factor for sensitivity (I would guess that might be MQ or other read filters) but can probably help improve precision. So we may want to relax some filters or optimize them jointly. We may also want to look at optimizations that include filtering, as I mention above.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-712237919
https://github.com/broadinstitute/gatk/issues/5564#issuecomment-712237919:231,Performance,optimiz,optimization,231,"I ran a few Bayesian optimizations, mostly focusing on various subsets/ranges of the read-to-haplotype and haplotype-to-reference SW parameters. I also varied whether I used part/all of chr22 and chose either F1/sensitivity as the optimization target. These experiments show that varying the SW parameters can definitely move the needle in terms of performance, even after variant normalization. For example, here are the SNP precision/sensitivity curves for an optimization of F1 over about half of chr22:. ![snp_f1](https://user-images.githubusercontent.com/11076296/96470421-44490900-11fc-11eb-96f6-83a6833b2b1f.png). And the same for indels:. ![non_snp_f1](https://user-images.githubusercontent.com/11076296/96470468-5034cb00-11fc-11eb-86a7-bbf81bc10122.png). This all raises the question of what the best optimization strategy should be. It looks like the SW parameters aren't the limiting factor for sensitivity (I would guess that might be MQ or other read filters) but can probably help improve precision. So we may want to relax some filters or optimize them jointly. We may also want to look at optimizations that include filtering, as I mention above.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-712237919
https://github.com/broadinstitute/gatk/issues/5564#issuecomment-712237919:349,Performance,perform,performance,349,"I ran a few Bayesian optimizations, mostly focusing on various subsets/ranges of the read-to-haplotype and haplotype-to-reference SW parameters. I also varied whether I used part/all of chr22 and chose either F1/sensitivity as the optimization target. These experiments show that varying the SW parameters can definitely move the needle in terms of performance, even after variant normalization. For example, here are the SNP precision/sensitivity curves for an optimization of F1 over about half of chr22:. ![snp_f1](https://user-images.githubusercontent.com/11076296/96470421-44490900-11fc-11eb-96f6-83a6833b2b1f.png). And the same for indels:. ![non_snp_f1](https://user-images.githubusercontent.com/11076296/96470468-5034cb00-11fc-11eb-86a7-bbf81bc10122.png). This all raises the question of what the best optimization strategy should be. It looks like the SW parameters aren't the limiting factor for sensitivity (I would guess that might be MQ or other read filters) but can probably help improve precision. So we may want to relax some filters or optimize them jointly. We may also want to look at optimizations that include filtering, as I mention above.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-712237919
https://github.com/broadinstitute/gatk/issues/5564#issuecomment-712237919:462,Performance,optimiz,optimization,462,"I ran a few Bayesian optimizations, mostly focusing on various subsets/ranges of the read-to-haplotype and haplotype-to-reference SW parameters. I also varied whether I used part/all of chr22 and chose either F1/sensitivity as the optimization target. These experiments show that varying the SW parameters can definitely move the needle in terms of performance, even after variant normalization. For example, here are the SNP precision/sensitivity curves for an optimization of F1 over about half of chr22:. ![snp_f1](https://user-images.githubusercontent.com/11076296/96470421-44490900-11fc-11eb-96f6-83a6833b2b1f.png). And the same for indels:. ![non_snp_f1](https://user-images.githubusercontent.com/11076296/96470468-5034cb00-11fc-11eb-86a7-bbf81bc10122.png). This all raises the question of what the best optimization strategy should be. It looks like the SW parameters aren't the limiting factor for sensitivity (I would guess that might be MQ or other read filters) but can probably help improve precision. So we may want to relax some filters or optimize them jointly. We may also want to look at optimizations that include filtering, as I mention above.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-712237919
https://github.com/broadinstitute/gatk/issues/5564#issuecomment-712237919:810,Performance,optimiz,optimization,810,"I ran a few Bayesian optimizations, mostly focusing on various subsets/ranges of the read-to-haplotype and haplotype-to-reference SW parameters. I also varied whether I used part/all of chr22 and chose either F1/sensitivity as the optimization target. These experiments show that varying the SW parameters can definitely move the needle in terms of performance, even after variant normalization. For example, here are the SNP precision/sensitivity curves for an optimization of F1 over about half of chr22:. ![snp_f1](https://user-images.githubusercontent.com/11076296/96470421-44490900-11fc-11eb-96f6-83a6833b2b1f.png). And the same for indels:. ![non_snp_f1](https://user-images.githubusercontent.com/11076296/96470468-5034cb00-11fc-11eb-86a7-bbf81bc10122.png). This all raises the question of what the best optimization strategy should be. It looks like the SW parameters aren't the limiting factor for sensitivity (I would guess that might be MQ or other read filters) but can probably help improve precision. So we may want to relax some filters or optimize them jointly. We may also want to look at optimizations that include filtering, as I mention above.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-712237919
https://github.com/broadinstitute/gatk/issues/5564#issuecomment-712237919:1054,Performance,optimiz,optimize,1054,"I ran a few Bayesian optimizations, mostly focusing on various subsets/ranges of the read-to-haplotype and haplotype-to-reference SW parameters. I also varied whether I used part/all of chr22 and chose either F1/sensitivity as the optimization target. These experiments show that varying the SW parameters can definitely move the needle in terms of performance, even after variant normalization. For example, here are the SNP precision/sensitivity curves for an optimization of F1 over about half of chr22:. ![snp_f1](https://user-images.githubusercontent.com/11076296/96470421-44490900-11fc-11eb-96f6-83a6833b2b1f.png). And the same for indels:. ![non_snp_f1](https://user-images.githubusercontent.com/11076296/96470468-5034cb00-11fc-11eb-86a7-bbf81bc10122.png). This all raises the question of what the best optimization strategy should be. It looks like the SW parameters aren't the limiting factor for sensitivity (I would guess that might be MQ or other read filters) but can probably help improve precision. So we may want to relax some filters or optimize them jointly. We may also want to look at optimizations that include filtering, as I mention above.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-712237919
https://github.com/broadinstitute/gatk/issues/5564#issuecomment-712237919:1105,Performance,optimiz,optimizations,1105,"I ran a few Bayesian optimizations, mostly focusing on various subsets/ranges of the read-to-haplotype and haplotype-to-reference SW parameters. I also varied whether I used part/all of chr22 and chose either F1/sensitivity as the optimization target. These experiments show that varying the SW parameters can definitely move the needle in terms of performance, even after variant normalization. For example, here are the SNP precision/sensitivity curves for an optimization of F1 over about half of chr22:. ![snp_f1](https://user-images.githubusercontent.com/11076296/96470421-44490900-11fc-11eb-96f6-83a6833b2b1f.png). And the same for indels:. ![non_snp_f1](https://user-images.githubusercontent.com/11076296/96470468-5034cb00-11fc-11eb-86a7-bbf81bc10122.png). This all raises the question of what the best optimization strategy should be. It looks like the SW parameters aren't the limiting factor for sensitivity (I would guess that might be MQ or other read filters) but can probably help improve precision. So we may want to relax some filters or optimize them jointly. We may also want to look at optimizations that include filtering, as I mention above.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-712237919
https://github.com/broadinstitute/gatk/issues/5564#issuecomment-712268193:288,Availability,down,down,288,"One observation that illustrates the need for care when optimizing metrics: for a few of the F1 optimizations, the haplotype-to-reference match-value parameter gets driven to its minimal value (1). Not 100% sure, but I'm guessing this might effectively boost precision by somehow cutting down on the complexity of proposed haplotypes---it depends on what the exact behavior of our SW algorithm is for negative scores. @davidbenjamin any thoughts on this behavior?. Something I don't quite understand yet is if we can impose some effective constraints on the parameters or otherwise reduce the number of independent dimensions. For example, it seems reasonable to me to fix the gap-extend penalties to -1 and let all other parameters be defined w.r.t. them. But perhaps we can also fix the match values similarly?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-712268193
https://github.com/broadinstitute/gatk/issues/5564#issuecomment-712268193:582,Energy Efficiency,reduce,reduce,582,"One observation that illustrates the need for care when optimizing metrics: for a few of the F1 optimizations, the haplotype-to-reference match-value parameter gets driven to its minimal value (1). Not 100% sure, but I'm guessing this might effectively boost precision by somehow cutting down on the complexity of proposed haplotypes---it depends on what the exact behavior of our SW algorithm is for negative scores. @davidbenjamin any thoughts on this behavior?. Something I don't quite understand yet is if we can impose some effective constraints on the parameters or otherwise reduce the number of independent dimensions. For example, it seems reasonable to me to fix the gap-extend penalties to -1 and let all other parameters be defined w.r.t. them. But perhaps we can also fix the match values similarly?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-712268193
https://github.com/broadinstitute/gatk/issues/5564#issuecomment-712268193:339,Integrability,depend,depends,339,"One observation that illustrates the need for care when optimizing metrics: for a few of the F1 optimizations, the haplotype-to-reference match-value parameter gets driven to its minimal value (1). Not 100% sure, but I'm guessing this might effectively boost precision by somehow cutting down on the complexity of proposed haplotypes---it depends on what the exact behavior of our SW algorithm is for negative scores. @davidbenjamin any thoughts on this behavior?. Something I don't quite understand yet is if we can impose some effective constraints on the parameters or otherwise reduce the number of independent dimensions. For example, it seems reasonable to me to fix the gap-extend penalties to -1 and let all other parameters be defined w.r.t. them. But perhaps we can also fix the match values similarly?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-712268193
https://github.com/broadinstitute/gatk/issues/5564#issuecomment-712268193:681,Modifiability,extend,extend,681,"One observation that illustrates the need for care when optimizing metrics: for a few of the F1 optimizations, the haplotype-to-reference match-value parameter gets driven to its minimal value (1). Not 100% sure, but I'm guessing this might effectively boost precision by somehow cutting down on the complexity of proposed haplotypes---it depends on what the exact behavior of our SW algorithm is for negative scores. @davidbenjamin any thoughts on this behavior?. Something I don't quite understand yet is if we can impose some effective constraints on the parameters or otherwise reduce the number of independent dimensions. For example, it seems reasonable to me to fix the gap-extend penalties to -1 and let all other parameters be defined w.r.t. them. But perhaps we can also fix the match values similarly?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-712268193
https://github.com/broadinstitute/gatk/issues/5564#issuecomment-712268193:56,Performance,optimiz,optimizing,56,"One observation that illustrates the need for care when optimizing metrics: for a few of the F1 optimizations, the haplotype-to-reference match-value parameter gets driven to its minimal value (1). Not 100% sure, but I'm guessing this might effectively boost precision by somehow cutting down on the complexity of proposed haplotypes---it depends on what the exact behavior of our SW algorithm is for negative scores. @davidbenjamin any thoughts on this behavior?. Something I don't quite understand yet is if we can impose some effective constraints on the parameters or otherwise reduce the number of independent dimensions. For example, it seems reasonable to me to fix the gap-extend penalties to -1 and let all other parameters be defined w.r.t. them. But perhaps we can also fix the match values similarly?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-712268193
https://github.com/broadinstitute/gatk/issues/5564#issuecomment-712268193:96,Performance,optimiz,optimizations,96,"One observation that illustrates the need for care when optimizing metrics: for a few of the F1 optimizations, the haplotype-to-reference match-value parameter gets driven to its minimal value (1). Not 100% sure, but I'm guessing this might effectively boost precision by somehow cutting down on the complexity of proposed haplotypes---it depends on what the exact behavior of our SW algorithm is for negative scores. @davidbenjamin any thoughts on this behavior?. Something I don't quite understand yet is if we can impose some effective constraints on the parameters or otherwise reduce the number of independent dimensions. For example, it seems reasonable to me to fix the gap-extend penalties to -1 and let all other parameters be defined w.r.t. them. But perhaps we can also fix the match values similarly?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-712268193
https://github.com/broadinstitute/gatk/issues/5564#issuecomment-712333444:142,Performance,optimiz,optimizing,142,"@fleharty sorry, each curve is a different set of parameters run on the same sample, and I'm plotting all curves generated over the course of optimizing those parameters.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-712333444
https://github.com/broadinstitute/gatk/issues/5564#issuecomment-712344348:154,Availability,down,down,154,"You can probably eyeball it from the 4.1.8.1 results above, which provide two points on the respective curves (although note those numbers are not broken down by SNP/indel). I’ll generate nicer plots once things are finalized, this is just what is spit out by rtg rocplot. There are a few regions of parameter space where precision seems to improve at the expense of a bit of sensitivity. Again, this might not be optimal if we are going to filter afterwards. I guess the main takeaway at this stage is that changing the parameters can result in non-negligible performance changes, probably beyond the level of sample-to-sample variation, which wasn't obvious from the first few runs I posted.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-712344348
https://github.com/broadinstitute/gatk/issues/5564#issuecomment-712344348:561,Performance,perform,performance,561,"You can probably eyeball it from the 4.1.8.1 results above, which provide two points on the respective curves (although note those numbers are not broken down by SNP/indel). I’ll generate nicer plots once things are finalized, this is just what is spit out by rtg rocplot. There are a few regions of parameter space where precision seems to improve at the expense of a bit of sensitivity. Again, this might not be optimal if we are going to filter afterwards. I guess the main takeaway at this stage is that changing the parameters can result in non-negligible performance changes, probably beyond the level of sample-to-sample variation, which wasn't obvious from the first few runs I posted.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-712344348
https://github.com/broadinstitute/gatk/issues/5564#issuecomment-712860451:91,Usability,intuit,intuition,91,"It seems to me that producing some parallel coordinate plots is the way to go to gain some intuition about how the SW and filters parameters affect the Area under the curve of the precision/recall curve. I assume that, overall we have about 10 parameters and 2-3 metrics (AUC for SNP, AUC for short Indel, AUC for long Indel). This is small enough that we should be able to gain intuition by looking at parallel coordinate plots. . This is a nice visualization package to produce parallel coordinate plots: https://facebookresearch.github.io/hiplot/index.html",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-712860451
https://github.com/broadinstitute/gatk/issues/5564#issuecomment-712860451:379,Usability,intuit,intuition,379,"It seems to me that producing some parallel coordinate plots is the way to go to gain some intuition about how the SW and filters parameters affect the Area under the curve of the precision/recall curve. I assume that, overall we have about 10 parameters and 2-3 metrics (AUC for SNP, AUC for short Indel, AUC for long Indel). This is small enough that we should be able to gain intuition by looking at parallel coordinate plots. . This is a nice visualization package to produce parallel coordinate plots: https://facebookresearch.github.io/hiplot/index.html",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-712860451
https://github.com/broadinstitute/gatk/issues/5564#issuecomment-713168743:299,Performance,optimiz,optimizing,299,"Hmm, guess I didn’t realize how important it was to subset to high-confidence regions. Most of the false positives above are coming from the low-confidence regions, so lower precision may actually indicate higher sensitivity to any real variants that may be there and missing in the truth set. When optimizing parameters in the past, have we always just focused on the high confidence regions and called it a day?. Also, do we typically run HC/M2 identically in low/high confidence regions? I’m noticing that it’s taking much longer to get through the low confidence regions.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-713168743
https://github.com/broadinstitute/gatk/issues/5564#issuecomment-713582631:16,Usability,clear,clear,16,"To be perfectly clear, do you mean high/low confidence or high/low complexity?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-713582631
https://github.com/broadinstitute/gatk/issues/5564#issuecomment-713601366:281,Testability,benchmark,benchmarks,281,"Either is fine for the purposes of the point I’m trying to make, as I would guess there’s decent overlap. But to be precise, I have started to stratify the above runs on GIAB NA12878 high/low confidence regions, which prompted the question. Also note that I haven't run any formal benchmarks of runtime---these are just informal observations---but the point probably still stands regardless of that as well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-713601366
https://github.com/broadinstitute/gatk/issues/5564#issuecomment-713785389:284,Performance,optimiz,optimizations,284,"Do you mean in production? In the ~2.92Gbp of the WGS calling regions, I see all ~2.44Gbp of the GIAB HCR, as well as ~485Mbp / ~778Mbp of the GIAB ""LCR"" (naively, just the complement of the HCR). Or did you mean in another context?. I'm kicking off runs with the CHM now. Hopefully, optimizations of sensitivity outside the CHM HCR will be more meaningful, since I see a decent amount of calls outside of it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-713785389
https://github.com/broadinstitute/gatk/issues/5564#issuecomment-714493769:203,Performance,optimiz,optimize,203,"For evaluations, we don't look at calls outside the high confidence regions. For production we deliver calls over the whole genome (except for Y in WGS, which is another story). Even for CHM, I wouldn't optimize outside the high confidence regions. For example, seg dupes are excluded from the high confidence regions. There likely will be calls there, but there's no guarantee that even a real variant should map to that copy of the segment. Of course if either @davidbenjamin or @fleharty has a differing opinion I'm open to discussion.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-714493769
https://github.com/broadinstitute/gatk/issues/5564#issuecomment-714549510:63,Performance,optimiz,optimize,63,"@ldgauthier I'm in complete agreement, I don't think we should optimize outside the high confidence regions.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-714549510
https://github.com/broadinstitute/gatk/issues/5564#issuecomment-714570055:1002,Availability,down,downweight,1002,"@takutosato had a good suggestion: to stratify to low-complexity regions in the high-confidence regions. Not sure how many variants are there, but will take a look. EDIT: looks like it's ~5k / ~54k on chr22 in CHM. More generally, I think that defining the appropriate loss function for optimization to set ""default"" parameter values obviously has no unique answer. The problem is also made a little more complicated by our current strategy of sensitive calling + non-trivial filtering. But it would be great to come up with some hard constraints (e.g., we never want runtime/cost to exceed X, we always want to maintain Y metrics in these regions on these samples) and general procedures, then apply them as equitably as possible across all method/parameter changes. Also generally, I'm a bit wary of focusing too hard on the high-confidence regions, as this might lead to overfitting or could understate the potential of method/parameter changes in more difficult regions. But probably we'll have to downweight the loss or do more manual checks in low-confidence regions until we improve truth resources there. One naive question, just want to double check: is it correct that the overall scaling of each set of SW parameters is inconsequential? E.g., if I multiply each by a constant, should I expect the same results? I would expect this to be the case (unless my hazy recollection of the details of SW scoring is off) and simple experiments bear this out, but I'm not sure if there are some edge cases or idiosyncrasies in our implementation or use of the scores that I might be missing.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-714570055
https://github.com/broadinstitute/gatk/issues/5564#issuecomment-714570055:287,Performance,optimiz,optimization,287,"@takutosato had a good suggestion: to stratify to low-complexity regions in the high-confidence regions. Not sure how many variants are there, but will take a look. EDIT: looks like it's ~5k / ~54k on chr22 in CHM. More generally, I think that defining the appropriate loss function for optimization to set ""default"" parameter values obviously has no unique answer. The problem is also made a little more complicated by our current strategy of sensitive calling + non-trivial filtering. But it would be great to come up with some hard constraints (e.g., we never want runtime/cost to exceed X, we always want to maintain Y metrics in these regions on these samples) and general procedures, then apply them as equitably as possible across all method/parameter changes. Also generally, I'm a bit wary of focusing too hard on the high-confidence regions, as this might lead to overfitting or could understate the potential of method/parameter changes in more difficult regions. But probably we'll have to downweight the loss or do more manual checks in low-confidence regions until we improve truth resources there. One naive question, just want to double check: is it correct that the overall scaling of each set of SW parameters is inconsequential? E.g., if I multiply each by a constant, should I expect the same results? I would expect this to be the case (unless my hazy recollection of the details of SW scoring is off) and simple experiments bear this out, but I'm not sure if there are some edge cases or idiosyncrasies in our implementation or use of the scores that I might be missing.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-714570055
https://github.com/broadinstitute/gatk/issues/5564#issuecomment-714570055:1427,Usability,simpl,simple,1427,"@takutosato had a good suggestion: to stratify to low-complexity regions in the high-confidence regions. Not sure how many variants are there, but will take a look. EDIT: looks like it's ~5k / ~54k on chr22 in CHM. More generally, I think that defining the appropriate loss function for optimization to set ""default"" parameter values obviously has no unique answer. The problem is also made a little more complicated by our current strategy of sensitive calling + non-trivial filtering. But it would be great to come up with some hard constraints (e.g., we never want runtime/cost to exceed X, we always want to maintain Y metrics in these regions on these samples) and general procedures, then apply them as equitably as possible across all method/parameter changes. Also generally, I'm a bit wary of focusing too hard on the high-confidence regions, as this might lead to overfitting or could understate the potential of method/parameter changes in more difficult regions. But probably we'll have to downweight the loss or do more manual checks in low-confidence regions until we improve truth resources there. One naive question, just want to double check: is it correct that the overall scaling of each set of SW parameters is inconsequential? E.g., if I multiply each by a constant, should I expect the same results? I would expect this to be the case (unless my hazy recollection of the details of SW scoring is off) and simple experiments bear this out, but I'm not sure if there are some edge cases or idiosyncrasies in our implementation or use of the scores that I might be missing.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-714570055
https://github.com/broadinstitute/gatk/issues/5564#issuecomment-715380429:96,Energy Efficiency,reduce,reduce,96,"@samuelklee I would run these experiments with the `-linked-de-bruijn-graph` option, which will reduce the number of haplotypes in a more principled way.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-715380429
https://github.com/broadinstitute/gatk/issues/5564#issuecomment-715407619:124,Performance,optimiz,optimizations,124,"Thanks @davidbenjamin, I can try that out. Any other parameters or modes that you feel might be gating any of these metrics/optimizations, which should be explored jointly with the SW parameters?. I guess the same question applies for `linked-de-bruijn-graph`, which is currently marked as experimental: what would be the procedure/criteria for changing the default behavior? Hopefully, we can answer this question for the case of a binary parameter before tackling 12 parameters! In general, I'm interested in establishing clear processes so it's easier for anybody to propose improvements. If there's no clear answer just yet, I'm happy to stop at exposing these parameters, perhaps consolidating defaults to one of the current sets if that is not too disagreeable (which is just slightly more complicated than a binary decision). Don't want to rabbit hole if there's no need. Hopefully, at the least, the blog-like documentation above will provide useful pointers to anyone that might want to tackle similar efforts in the future.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-715407619
https://github.com/broadinstitute/gatk/issues/5564#issuecomment-715407619:524,Usability,clear,clear,524,"Thanks @davidbenjamin, I can try that out. Any other parameters or modes that you feel might be gating any of these metrics/optimizations, which should be explored jointly with the SW parameters?. I guess the same question applies for `linked-de-bruijn-graph`, which is currently marked as experimental: what would be the procedure/criteria for changing the default behavior? Hopefully, we can answer this question for the case of a binary parameter before tackling 12 parameters! In general, I'm interested in establishing clear processes so it's easier for anybody to propose improvements. If there's no clear answer just yet, I'm happy to stop at exposing these parameters, perhaps consolidating defaults to one of the current sets if that is not too disagreeable (which is just slightly more complicated than a binary decision). Don't want to rabbit hole if there's no need. Hopefully, at the least, the blog-like documentation above will provide useful pointers to anyone that might want to tackle similar efforts in the future.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-715407619
https://github.com/broadinstitute/gatk/issues/5564#issuecomment-715407619:606,Usability,clear,clear,606,"Thanks @davidbenjamin, I can try that out. Any other parameters or modes that you feel might be gating any of these metrics/optimizations, which should be explored jointly with the SW parameters?. I guess the same question applies for `linked-de-bruijn-graph`, which is currently marked as experimental: what would be the procedure/criteria for changing the default behavior? Hopefully, we can answer this question for the case of a binary parameter before tackling 12 parameters! In general, I'm interested in establishing clear processes so it's easier for anybody to propose improvements. If there's no clear answer just yet, I'm happy to stop at exposing these parameters, perhaps consolidating defaults to one of the current sets if that is not too disagreeable (which is just slightly more complicated than a binary decision). Don't want to rabbit hole if there's no need. Hopefully, at the least, the blog-like documentation above will provide useful pointers to anyone that might want to tackle similar efforts in the future.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-715407619
https://github.com/broadinstitute/gatk/issues/5564#issuecomment-715465692:369,Modifiability,extend,extend,369,"![weighted](https://user-images.githubusercontent.com/11076296/97032266-8ab9a300-152f-11eb-8d73-148ff99963be.png). Here is the result of optimizing for sensitivity in the high-confidence, low-compexity region of chr22 in CHM, allowing haplotype-to-reference and read-to-haplotype (match, mismatch, gap open) to range over ([1, 20], [-20, -1], [-20, -1]) and fixing gap extend penalties to -1. The optimal (match, mismatch, gap open) parameters found in this run appear to be:. haplotype-to-reference: 2, -8, -19; read-to-haplotype: 1, -4, -3. I wouldn't put much stock in interpreting these parameters or their exact values for now, but it does appear that the match values and the haplotype-to-reference gap-open penalty might be saturating the bounds of the search. Plots of the type suggested by @dalessioluca might be more illuminating. Compare with default performance:. ````; Threshold True-pos-baseline True-pos-call False-pos False-neg Precision Sensitivity F-measure; ----------------------------------------------------------------------------------------------------; 9.000 4003 4019 494 1036 0.8905 0.7944 0.8397; None 4009 4025 511 1030 0.8873 0.7956 0.8390; ````. That the corresponding curve with a precision/sensitivity endpoint of (0.8873, 0.7956) above isn't at the top of the pack means that we could squeeze out some extra calls by varying the SW parameters. Of course, this doesn't account for negative impact elsewhere. One could imagine writing a loss where this sensitivity is optimized while putting minimum constraints on precision, sensitivity, and/or F1 in the high-confidence, high-complexity regions (the assumption being the truth set is complete in those regions), or some weightings/variations thereof. EDIT: Actually, looks like overall performance in the high-confidence region improves:. ````; Threshold True-pos-baseline True-pos-call False-pos False-neg Precision Sensitivity F-measure; ----------------------------------------------------------------------------",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-715465692
https://github.com/broadinstitute/gatk/issues/5564#issuecomment-715465692:137,Performance,optimiz,optimizing,137,"![weighted](https://user-images.githubusercontent.com/11076296/97032266-8ab9a300-152f-11eb-8d73-148ff99963be.png). Here is the result of optimizing for sensitivity in the high-confidence, low-compexity region of chr22 in CHM, allowing haplotype-to-reference and read-to-haplotype (match, mismatch, gap open) to range over ([1, 20], [-20, -1], [-20, -1]) and fixing gap extend penalties to -1. The optimal (match, mismatch, gap open) parameters found in this run appear to be:. haplotype-to-reference: 2, -8, -19; read-to-haplotype: 1, -4, -3. I wouldn't put much stock in interpreting these parameters or their exact values for now, but it does appear that the match values and the haplotype-to-reference gap-open penalty might be saturating the bounds of the search. Plots of the type suggested by @dalessioluca might be more illuminating. Compare with default performance:. ````; Threshold True-pos-baseline True-pos-call False-pos False-neg Precision Sensitivity F-measure; ----------------------------------------------------------------------------------------------------; 9.000 4003 4019 494 1036 0.8905 0.7944 0.8397; None 4009 4025 511 1030 0.8873 0.7956 0.8390; ````. That the corresponding curve with a precision/sensitivity endpoint of (0.8873, 0.7956) above isn't at the top of the pack means that we could squeeze out some extra calls by varying the SW parameters. Of course, this doesn't account for negative impact elsewhere. One could imagine writing a loss where this sensitivity is optimized while putting minimum constraints on precision, sensitivity, and/or F1 in the high-confidence, high-complexity regions (the assumption being the truth set is complete in those regions), or some weightings/variations thereof. EDIT: Actually, looks like overall performance in the high-confidence region improves:. ````; Threshold True-pos-baseline True-pos-call False-pos False-neg Precision Sensitivity F-measure; ----------------------------------------------------------------------------",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-715465692
https://github.com/broadinstitute/gatk/issues/5564#issuecomment-715465692:862,Performance,perform,performance,862,"![weighted](https://user-images.githubusercontent.com/11076296/97032266-8ab9a300-152f-11eb-8d73-148ff99963be.png). Here is the result of optimizing for sensitivity in the high-confidence, low-compexity region of chr22 in CHM, allowing haplotype-to-reference and read-to-haplotype (match, mismatch, gap open) to range over ([1, 20], [-20, -1], [-20, -1]) and fixing gap extend penalties to -1. The optimal (match, mismatch, gap open) parameters found in this run appear to be:. haplotype-to-reference: 2, -8, -19; read-to-haplotype: 1, -4, -3. I wouldn't put much stock in interpreting these parameters or their exact values for now, but it does appear that the match values and the haplotype-to-reference gap-open penalty might be saturating the bounds of the search. Plots of the type suggested by @dalessioluca might be more illuminating. Compare with default performance:. ````; Threshold True-pos-baseline True-pos-call False-pos False-neg Precision Sensitivity F-measure; ----------------------------------------------------------------------------------------------------; 9.000 4003 4019 494 1036 0.8905 0.7944 0.8397; None 4009 4025 511 1030 0.8873 0.7956 0.8390; ````. That the corresponding curve with a precision/sensitivity endpoint of (0.8873, 0.7956) above isn't at the top of the pack means that we could squeeze out some extra calls by varying the SW parameters. Of course, this doesn't account for negative impact elsewhere. One could imagine writing a loss where this sensitivity is optimized while putting minimum constraints on precision, sensitivity, and/or F1 in the high-confidence, high-complexity regions (the assumption being the truth set is complete in those regions), or some weightings/variations thereof. EDIT: Actually, looks like overall performance in the high-confidence region improves:. ````; Threshold True-pos-baseline True-pos-call False-pos False-neg Precision Sensitivity F-measure; ----------------------------------------------------------------------------",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-715465692
https://github.com/broadinstitute/gatk/issues/5564#issuecomment-715465692:1501,Performance,optimiz,optimized,1501,"is run appear to be:. haplotype-to-reference: 2, -8, -19; read-to-haplotype: 1, -4, -3. I wouldn't put much stock in interpreting these parameters or their exact values for now, but it does appear that the match values and the haplotype-to-reference gap-open penalty might be saturating the bounds of the search. Plots of the type suggested by @dalessioluca might be more illuminating. Compare with default performance:. ````; Threshold True-pos-baseline True-pos-call False-pos False-neg Precision Sensitivity F-measure; ----------------------------------------------------------------------------------------------------; 9.000 4003 4019 494 1036 0.8905 0.7944 0.8397; None 4009 4025 511 1030 0.8873 0.7956 0.8390; ````. That the corresponding curve with a precision/sensitivity endpoint of (0.8873, 0.7956) above isn't at the top of the pack means that we could squeeze out some extra calls by varying the SW parameters. Of course, this doesn't account for negative impact elsewhere. One could imagine writing a loss where this sensitivity is optimized while putting minimum constraints on precision, sensitivity, and/or F1 in the high-confidence, high-complexity regions (the assumption being the truth set is complete in those regions), or some weightings/variations thereof. EDIT: Actually, looks like overall performance in the high-confidence region improves:. ````; Threshold True-pos-baseline True-pos-call False-pos False-neg Precision Sensitivity F-measure; ----------------------------------------------------------------------------------------------------; 12.000 49955 49955 1932 2065 0.9628 0.9603 0.9615; None 49988 49988 1994 2032 0.9616 0.9609 0.9613; ````; vs. defaults:; ````; Threshold True-pos-baseline True-pos-call False-pos False-neg Precision Sensitivity F-measure; ----------------------------------------------------------------------------------------------------; 12.000 49837 49865 2012 2183 0.9612 0.9580 0.9596; None 49870 49898 2077 2150 0.9600 0.9587 0.9594; ````",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-715465692
https://github.com/broadinstitute/gatk/issues/5564#issuecomment-715465692:1771,Performance,perform,performance,1771,"is run appear to be:. haplotype-to-reference: 2, -8, -19; read-to-haplotype: 1, -4, -3. I wouldn't put much stock in interpreting these parameters or their exact values for now, but it does appear that the match values and the haplotype-to-reference gap-open penalty might be saturating the bounds of the search. Plots of the type suggested by @dalessioluca might be more illuminating. Compare with default performance:. ````; Threshold True-pos-baseline True-pos-call False-pos False-neg Precision Sensitivity F-measure; ----------------------------------------------------------------------------------------------------; 9.000 4003 4019 494 1036 0.8905 0.7944 0.8397; None 4009 4025 511 1030 0.8873 0.7956 0.8390; ````. That the corresponding curve with a precision/sensitivity endpoint of (0.8873, 0.7956) above isn't at the top of the pack means that we could squeeze out some extra calls by varying the SW parameters. Of course, this doesn't account for negative impact elsewhere. One could imagine writing a loss where this sensitivity is optimized while putting minimum constraints on precision, sensitivity, and/or F1 in the high-confidence, high-complexity regions (the assumption being the truth set is complete in those regions), or some weightings/variations thereof. EDIT: Actually, looks like overall performance in the high-confidence region improves:. ````; Threshold True-pos-baseline True-pos-call False-pos False-neg Precision Sensitivity F-measure; ----------------------------------------------------------------------------------------------------; 12.000 49955 49955 1932 2065 0.9628 0.9603 0.9615; None 49988 49988 1994 2032 0.9616 0.9609 0.9613; ````; vs. defaults:; ````; Threshold True-pos-baseline True-pos-call False-pos False-neg Precision Sensitivity F-measure; ----------------------------------------------------------------------------------------------------; 12.000 49837 49865 2012 2183 0.9612 0.9580 0.9596; None 49870 49898 2077 2150 0.9600 0.9587 0.9594; ````",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5564#issuecomment-715465692
https://github.com/broadinstitute/gatk/pull/5565#issuecomment-452841810:2145,Deployability,update,update,2145,".01%`.; > The diff coverage is `n/a`. [![Impacted file tree graph](https://codecov.io/gh/broadinstitute/gatk/pull/5565/graphs/tree.svg?width=650&token=7RuX7LsQVf&height=150&src=pr)](https://codecov.io/gh/broadinstitute/gatk/pull/5565?src=pr&el=tree). ```diff; @@ Coverage Diff @@; ## master #5565 +/- ##; ============================================; - Coverage 87.09% 87.08% -0.01% ; + Complexity 31524 31522 -2 ; ============================================; Files 1930 1930 ; Lines 145231 145231 ; Branches 16095 16095 ; ============================================; - Hits 126482 126479 -3 ; - Misses 12900 12901 +1 ; - Partials 5849 5851 +2; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5565?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...nder/utils/runtime/StreamingProcessController.java](https://codecov.io/gh/broadinstitute/gatk/pull/5565/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9ydW50aW1lL1N0cmVhbWluZ1Byb2Nlc3NDb250cm9sbGVyLmphdmE=) | `67.77% <0%> (-0.95%)` | `33% <0%> (-1%)` | |; | [...lotypecaller/readthreading/ReadThreadingGraph.java](https://codecov.io/gh/broadinstitute/gatk/pull/5565/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9yZWFkdGhyZWFkaW5nL1JlYWRUaHJlYWRpbmdHcmFwaC5qYXZh) | `88.6% <0%> (-0.26%)` | `144% <0%> (-1%)` | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5565?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5565?src=pr&el=footer). Last update [f9a2e5c...18a9e40](https://codecov.io/gh/broadinstitute/gatk/pull/5565?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5565#issuecomment-452841810
https://github.com/broadinstitute/gatk/pull/5565#issuecomment-452841810:2048,Energy Efficiency,Power,Powered,2048,".01%`.; > The diff coverage is `n/a`. [![Impacted file tree graph](https://codecov.io/gh/broadinstitute/gatk/pull/5565/graphs/tree.svg?width=650&token=7RuX7LsQVf&height=150&src=pr)](https://codecov.io/gh/broadinstitute/gatk/pull/5565?src=pr&el=tree). ```diff; @@ Coverage Diff @@; ## master #5565 +/- ##; ============================================; - Coverage 87.09% 87.08% -0.01% ; + Complexity 31524 31522 -2 ; ============================================; Files 1930 1930 ; Lines 145231 145231 ; Branches 16095 16095 ; ============================================; - Hits 126482 126479 -3 ; - Misses 12900 12901 +1 ; - Partials 5849 5851 +2; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5565?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...nder/utils/runtime/StreamingProcessController.java](https://codecov.io/gh/broadinstitute/gatk/pull/5565/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9ydW50aW1lL1N0cmVhbWluZ1Byb2Nlc3NDb250cm9sbGVyLmphdmE=) | `67.77% <0%> (-0.95%)` | `33% <0%> (-1%)` | |; | [...lotypecaller/readthreading/ReadThreadingGraph.java](https://codecov.io/gh/broadinstitute/gatk/pull/5565/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9yZWFkdGhyZWFkaW5nL1JlYWRUaHJlYWRpbmdHcmFwaC5qYXZh) | `88.6% <0%> (-0.26%)` | `144% <0%> (-1%)` | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5565?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5565?src=pr&el=footer). Last update [f9a2e5c...18a9e40](https://codecov.io/gh/broadinstitute/gatk/pull/5565?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5565#issuecomment-452841810
https://github.com/broadinstitute/gatk/pull/5565#issuecomment-452841810:1911,Usability,learn,learn,1911,".01%`.; > The diff coverage is `n/a`. [![Impacted file tree graph](https://codecov.io/gh/broadinstitute/gatk/pull/5565/graphs/tree.svg?width=650&token=7RuX7LsQVf&height=150&src=pr)](https://codecov.io/gh/broadinstitute/gatk/pull/5565?src=pr&el=tree). ```diff; @@ Coverage Diff @@; ## master #5565 +/- ##; ============================================; - Coverage 87.09% 87.08% -0.01% ; + Complexity 31524 31522 -2 ; ============================================; Files 1930 1930 ; Lines 145231 145231 ; Branches 16095 16095 ; ============================================; - Hits 126482 126479 -3 ; - Misses 12900 12901 +1 ; - Partials 5849 5851 +2; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5565?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...nder/utils/runtime/StreamingProcessController.java](https://codecov.io/gh/broadinstitute/gatk/pull/5565/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9ydW50aW1lL1N0cmVhbWluZ1Byb2Nlc3NDb250cm9sbGVyLmphdmE=) | `67.77% <0%> (-0.95%)` | `33% <0%> (-1%)` | |; | [...lotypecaller/readthreading/ReadThreadingGraph.java](https://codecov.io/gh/broadinstitute/gatk/pull/5565/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9yZWFkdGhyZWFkaW5nL1JlYWRUaHJlYWRpbmdHcmFwaC5qYXZh) | `88.6% <0%> (-0.26%)` | `144% <0%> (-1%)` | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5565?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5565?src=pr&el=footer). Last update [f9a2e5c...18a9e40](https://codecov.io/gh/broadinstitute/gatk/pull/5565?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5565#issuecomment-452841810
https://github.com/broadinstitute/gatk/pull/5566#issuecomment-452843310:1862,Modifiability,Plugin,Plugin,1862,ge Δ | Complexity Δ | |; |---|---|---|---|; | [...r/tools/walkers/mutect/Mutect2FilteringEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/5566/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9NdXRlY3QyRmlsdGVyaW5nRW5naW5lLmphdmE=) | `80.743% <0%> (-4.581%)` | `89% <0%> (ø)` | |; | [...ute/hellbender/utils/test/FuncotatorTestUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5566/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Z1bmNvdGF0b3JUZXN0VXRpbHMuamF2YQ==) | `95.161% <0%> (-3.084%)` | `7% <0%> (+1%)` | |; | [...GATKPlugin/GATKReadFilterPluginDescriptorTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5566/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vR0FUS1JlYWRGaWx0ZXJQbHVnaW5EZXNjcmlwdG9yVGVzdC5qYXZh) | `88.62% <0%> (-1.76%)` | `48% <0%> (+1%)` | |; | [...Plugin/GATKAnnotationPluginDescriptorUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5566/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vR0FUS0Fubm90YXRpb25QbHVnaW5EZXNjcmlwdG9yVW5pdFRlc3QuamF2YQ==) | `88.235% <0%> (-1.43%)` | `58% <0%> (+1%)` | |; | [.../tools/walkers/haplotypecaller/RefVsAnyResult.java](https://codecov.io/gh/broadinstitute/gatk/pull/5566/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9SZWZWc0FueVJlc3VsdC5qYXZh) | `100% <0%> (ø)` | `3% <0%> (+1%)` | :arrow_up: |; | [...ools/walkers/annotator/VariantAnnotatorEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/5566/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9WYXJpYW50QW5ub3RhdG9yRW5naW5lLmphdmE=) | `91.304% <0%> (ø)` | `70% <0%> (ø)` | :arrow_down: |; | [...line/GATKPlugin/testpluggables/TestAnnotation.java](https:,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5566#issuecomment-452843310
https://github.com/broadinstitute/gatk/pull/5566#issuecomment-452843310:1266,Testability,test,test,1266,8d8a55b?src=pr&el=desc) will **decrease** coverage by `0.012%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #5566 +/- ##; ===============================================; - Coverage 87.046% 87.034% -0.012% ; - Complexity 31524 31535 +11 ; ===============================================; Files 1928 1930 +2 ; Lines 145340 145443 +103 ; Branches 16089 16090 +1 ; ===============================================; + Hits 126513 126585 +72 ; - Misses 12966 12999 +33 ; + Partials 5861 5859 -2; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5566?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...r/tools/walkers/mutect/Mutect2FilteringEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/5566/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9NdXRlY3QyRmlsdGVyaW5nRW5naW5lLmphdmE=) | `80.743% <0%> (-4.581%)` | `89% <0%> (ø)` | |; | [...ute/hellbender/utils/test/FuncotatorTestUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5566/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Z1bmNvdGF0b3JUZXN0VXRpbHMuamF2YQ==) | `95.161% <0%> (-3.084%)` | `7% <0%> (+1%)` | |; | [...GATKPlugin/GATKReadFilterPluginDescriptorTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5566/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vR0FUS1JlYWRGaWx0ZXJQbHVnaW5EZXNjcmlwdG9yVGVzdC5qYXZh) | `88.62% <0%> (-1.76%)` | `48% <0%> (+1%)` | |; | [...Plugin/GATKAnnotationPluginDescriptorUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5566/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vR0FUS0Fubm90YXRpb25QbHVnaW5EZXNjcmlwdG9yVW5pdFRlc3QuamF2YQ==) | `88.235% <0%> (-1.43%)` | `58% <0%> (+1%)` | |; | [.../tools/walkers/haplotypecaller/RefVsAnyResult.java](https://codecov.io/gh/b,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5566#issuecomment-452843310
https://github.com/broadinstitute/gatk/pull/5566#issuecomment-452843310:2843,Testability,test,testpluggables,2843, | |; | [...Plugin/GATKAnnotationPluginDescriptorUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5566/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vR0FUS0Fubm90YXRpb25QbHVnaW5EZXNjcmlwdG9yVW5pdFRlc3QuamF2YQ==) | `88.235% <0%> (-1.43%)` | `58% <0%> (+1%)` | |; | [.../tools/walkers/haplotypecaller/RefVsAnyResult.java](https://codecov.io/gh/broadinstitute/gatk/pull/5566/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9SZWZWc0FueVJlc3VsdC5qYXZh) | `100% <0%> (ø)` | `3% <0%> (+1%)` | :arrow_up: |; | [...ools/walkers/annotator/VariantAnnotatorEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/5566/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9WYXJpYW50QW5ub3RhdG9yRW5naW5lLmphdmE=) | `91.304% <0%> (ø)` | `70% <0%> (ø)` | :arrow_down: |; | [...line/GATKPlugin/testpluggables/TestAnnotation.java](https://codecov.io/gh/broadinstitute/gatk/pull/5566/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vdGVzdHBsdWdnYWJsZXMvVGVzdEFubm90YXRpb24uamF2YQ==) | `0% <0%> (ø)` | `0% <0%> (?)` | |; | [...line/GATKPlugin/testpluggables/TestReadFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5566/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vdGVzdHBsdWdnYWJsZXMvVGVzdFJlYWRGaWx0ZXIuamF2YQ==) | `0% <0%> (ø)` | `0% <0%> (?)` | |; | [...nder/tools/funcotator/FuncotatorTestConstants.java](https://codecov.io/gh/broadinstitute/gatk/pull/5566/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0Z1bmNvdGF0b3JUZXN0Q29uc3RhbnRzLmphdmE=) | `98.333% <0%> (+0.028%)` | `1% <0%> (ø)` | :arrow_down: |; | [...dataSources/vcf/VcfFuncotationFactoryUnitTest.java](https://codecov.io/gh/broadinstitute/gatk,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5566#issuecomment-452843310
https://github.com/broadinstitute/gatk/pull/5566#issuecomment-452843310:2858,Testability,Test,TestAnnotation,2858, | |; | [...Plugin/GATKAnnotationPluginDescriptorUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5566/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vR0FUS0Fubm90YXRpb25QbHVnaW5EZXNjcmlwdG9yVW5pdFRlc3QuamF2YQ==) | `88.235% <0%> (-1.43%)` | `58% <0%> (+1%)` | |; | [.../tools/walkers/haplotypecaller/RefVsAnyResult.java](https://codecov.io/gh/broadinstitute/gatk/pull/5566/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9SZWZWc0FueVJlc3VsdC5qYXZh) | `100% <0%> (ø)` | `3% <0%> (+1%)` | :arrow_up: |; | [...ools/walkers/annotator/VariantAnnotatorEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/5566/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9WYXJpYW50QW5ub3RhdG9yRW5naW5lLmphdmE=) | `91.304% <0%> (ø)` | `70% <0%> (ø)` | :arrow_down: |; | [...line/GATKPlugin/testpluggables/TestAnnotation.java](https://codecov.io/gh/broadinstitute/gatk/pull/5566/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vdGVzdHBsdWdnYWJsZXMvVGVzdEFubm90YXRpb24uamF2YQ==) | `0% <0%> (ø)` | `0% <0%> (?)` | |; | [...line/GATKPlugin/testpluggables/TestReadFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5566/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vdGVzdHBsdWdnYWJsZXMvVGVzdFJlYWRGaWx0ZXIuamF2YQ==) | `0% <0%> (ø)` | `0% <0%> (?)` | |; | [...nder/tools/funcotator/FuncotatorTestConstants.java](https://codecov.io/gh/broadinstitute/gatk/pull/5566/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0Z1bmNvdGF0b3JUZXN0Q29uc3RhbnRzLmphdmE=) | `98.333% <0%> (+0.028%)` | `1% <0%> (ø)` | :arrow_down: |; | [...dataSources/vcf/VcfFuncotationFactoryUnitTest.java](https://codecov.io/gh/broadinstitute/gatk,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5566#issuecomment-452843310
https://github.com/broadinstitute/gatk/pull/5566#issuecomment-452843310:3149,Testability,test,testpluggables,3149,.43%)` | `58% <0%> (+1%)` | |; | [.../tools/walkers/haplotypecaller/RefVsAnyResult.java](https://codecov.io/gh/broadinstitute/gatk/pull/5566/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9SZWZWc0FueVJlc3VsdC5qYXZh) | `100% <0%> (ø)` | `3% <0%> (+1%)` | :arrow_up: |; | [...ools/walkers/annotator/VariantAnnotatorEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/5566/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9WYXJpYW50QW5ub3RhdG9yRW5naW5lLmphdmE=) | `91.304% <0%> (ø)` | `70% <0%> (ø)` | :arrow_down: |; | [...line/GATKPlugin/testpluggables/TestAnnotation.java](https://codecov.io/gh/broadinstitute/gatk/pull/5566/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vdGVzdHBsdWdnYWJsZXMvVGVzdEFubm90YXRpb24uamF2YQ==) | `0% <0%> (ø)` | `0% <0%> (?)` | |; | [...line/GATKPlugin/testpluggables/TestReadFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5566/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vdGVzdHBsdWdnYWJsZXMvVGVzdFJlYWRGaWx0ZXIuamF2YQ==) | `0% <0%> (ø)` | `0% <0%> (?)` | |; | [...nder/tools/funcotator/FuncotatorTestConstants.java](https://codecov.io/gh/broadinstitute/gatk/pull/5566/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0Z1bmNvdGF0b3JUZXN0Q29uc3RhbnRzLmphdmE=) | `98.333% <0%> (+0.028%)` | `1% <0%> (ø)` | :arrow_down: |; | [...dataSources/vcf/VcfFuncotationFactoryUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5566/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL3ZjZi9WY2ZGdW5jb3RhdGlvbkZhY3RvcnlVbml0VGVzdC5qYXZh) | `98.104% <0%> (+0.055%)` | `30% <0%> (+1%)` | :arrow_up: |; | ... and [11 more](https://codecov.io/gh/broadinstitute/g,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5566#issuecomment-452843310
https://github.com/broadinstitute/gatk/pull/5566#issuecomment-452843310:3164,Testability,Test,TestReadFilter,3164,.43%)` | `58% <0%> (+1%)` | |; | [.../tools/walkers/haplotypecaller/RefVsAnyResult.java](https://codecov.io/gh/broadinstitute/gatk/pull/5566/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9SZWZWc0FueVJlc3VsdC5qYXZh) | `100% <0%> (ø)` | `3% <0%> (+1%)` | :arrow_up: |; | [...ools/walkers/annotator/VariantAnnotatorEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/5566/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9WYXJpYW50QW5ub3RhdG9yRW5naW5lLmphdmE=) | `91.304% <0%> (ø)` | `70% <0%> (ø)` | :arrow_down: |; | [...line/GATKPlugin/testpluggables/TestAnnotation.java](https://codecov.io/gh/broadinstitute/gatk/pull/5566/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vdGVzdHBsdWdnYWJsZXMvVGVzdEFubm90YXRpb24uamF2YQ==) | `0% <0%> (ø)` | `0% <0%> (?)` | |; | [...line/GATKPlugin/testpluggables/TestReadFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5566/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vdGVzdHBsdWdnYWJsZXMvVGVzdFJlYWRGaWx0ZXIuamF2YQ==) | `0% <0%> (ø)` | `0% <0%> (?)` | |; | [...nder/tools/funcotator/FuncotatorTestConstants.java](https://codecov.io/gh/broadinstitute/gatk/pull/5566/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0Z1bmNvdGF0b3JUZXN0Q29uc3RhbnRzLmphdmE=) | `98.333% <0%> (+0.028%)` | `1% <0%> (ø)` | :arrow_down: |; | [...dataSources/vcf/VcfFuncotationFactoryUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5566/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL3ZjZi9WY2ZGdW5jb3RhdGlvbkZhY3RvcnlVbml0VGVzdC5qYXZh) | `98.104% <0%> (+0.055%)` | `30% <0%> (+1%)` | :arrow_up: |; | ... and [11 more](https://codecov.io/gh/broadinstitute/g,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5566#issuecomment-452843310
https://github.com/broadinstitute/gatk/pull/5566#issuecomment-452844171:13,Testability,test,test,13,Do we want a test for this wdl like the others do?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5566#issuecomment-452844171
https://github.com/broadinstitute/gatk/pull/5566#issuecomment-454024917:75,Deployability,pipeline,pipeline,75,"Ok, we have a working test! It runs the plumbing NA12878 through the whole pipeline. @ldgauthier or @jsotobroad this is ready for review (the wdl is a direct copy with one change to add more memory to RevertSam because I tested it with PAPI v2 and it needed more memory than was specified). Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5566#issuecomment-454024917
https://github.com/broadinstitute/gatk/pull/5566#issuecomment-454024917:22,Testability,test,test,22,"Ok, we have a working test! It runs the plumbing NA12878 through the whole pipeline. @ldgauthier or @jsotobroad this is ready for review (the wdl is a direct copy with one change to add more memory to RevertSam because I tested it with PAPI v2 and it needed more memory than was specified). Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5566#issuecomment-454024917
https://github.com/broadinstitute/gatk/pull/5566#issuecomment-454024917:221,Testability,test,tested,221,"Ok, we have a working test! It runs the plumbing NA12878 through the whole pipeline. @ldgauthier or @jsotobroad this is ready for review (the wdl is a direct copy with one change to add more memory to RevertSam because I tested it with PAPI v2 and it needed more memory than was specified). Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5566#issuecomment-454024917
https://github.com/broadinstitute/gatk/pull/5566#issuecomment-457240422:12,Testability,Test,Tests,12,@ldgauthier Tests are now passing and we no longer have a personal docker image in the wdl. Back to you!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5566#issuecomment-457240422
https://github.com/broadinstitute/gatk/pull/5567#issuecomment-454252597:25,Testability,test,test,25,@cmnbroad I will write a test for this tomorrow.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5567#issuecomment-454252597
https://github.com/broadinstitute/gatk/pull/5567#issuecomment-454390396:33,Testability,test,test,33,@bhanugandham No need to write a test (which is hard to do for someting like this). I just wanted you to run manually and make sure the output looked ok.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5567#issuecomment-454390396
https://github.com/broadinstitute/gatk/issues/5568#issuecomment-663151098:68,Integrability,message,messages,68,"I just ran GATK 4.1.7.0 with GDB 1.2.1 and I'm seeing these logging messages again. Granted I've also built a few old jars lately, but after a clean build I'm still seeing it. @nalinigans can you run the latest and confirm or deny?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5568#issuecomment-663151098
https://github.com/broadinstitute/gatk/issues/5568#issuecomment-663151098:60,Testability,log,logging,60,"I just ran GATK 4.1.7.0 with GDB 1.2.1 and I'm seeing these logging messages again. Granted I've also built a few old jars lately, but after a clean build I'm still seeing it. @nalinigans can you run the latest and confirm or deny?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5568#issuecomment-663151098
https://github.com/broadinstitute/gatk/issues/5568#issuecomment-663151885:86,Deployability,release,release,86,@ldgauthier Did you try GATK 4.1.8.0 or later as well? 4.1.8.0 introduced a major new release of GenomicsDB.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5568#issuecomment-663151885
https://github.com/broadinstitute/gatk/issues/5568#issuecomment-663152910:102,Availability,down,download,102,"@ldgauthier Also, try running with the prebuilt jars (https://github.com/broadinstitute/gatk/releases/download/4.1.8.1/gatk-4.1.8.1.zip) and/or the latest docker image to eliminate your local build environment as a variable.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5568#issuecomment-663152910
https://github.com/broadinstitute/gatk/issues/5568#issuecomment-663152910:93,Deployability,release,releases,93,"@ldgauthier Also, try running with the prebuilt jars (https://github.com/broadinstitute/gatk/releases/download/4.1.8.1/gatk-4.1.8.1.zip) and/or the latest docker image to eliminate your local build environment as a variable.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5568#issuecomment-663152910
https://github.com/broadinstitute/gatk/issues/5568#issuecomment-663152910:215,Modifiability,variab,variable,215,"@ldgauthier Also, try running with the prebuilt jars (https://github.com/broadinstitute/gatk/releases/download/4.1.8.1/gatk-4.1.8.1.zip) and/or the latest docker image to eliminate your local build environment as a variable.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5568#issuecomment-663152910
https://github.com/broadinstitute/gatk/issues/5568#issuecomment-663238869:43,Deployability,release,released,43,"I just tried with gatk 4.1.7.0 and 4.1.8.0 released zips and cannot reproduce the issue. I can only see buffer resize logging messages when I use a debug version of libtiledbgenomicsdb.so in my private builds. . That said, `gatk 4.1.7.0` picks up `libtiledbgenomicsdb.so` from the LD_LIBRARY_PATH, otherwise it extracts from the genomicsdb.jar. @ldgauthier, do you have an older version of the native `libtiledbgenomicsdb.so` in your LD_LIBRARY_PATH env? That could be one cause. Otherwise, if you move to using `gatk 4.1.8.1` as @droazen recommends, it will only pick up the native library packed with the genomicsdb 1.3.0 jar. To override the packed genomicsdb library, in versions 1.3.0+, one has to explicitly the path specify via java options -Dgenomicsdb.library.path=<path_to_libtiledbgenomicsdb.so>.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5568#issuecomment-663238869
https://github.com/broadinstitute/gatk/issues/5568#issuecomment-663238869:126,Integrability,message,messages,126,"I just tried with gatk 4.1.7.0 and 4.1.8.0 released zips and cannot reproduce the issue. I can only see buffer resize logging messages when I use a debug version of libtiledbgenomicsdb.so in my private builds. . That said, `gatk 4.1.7.0` picks up `libtiledbgenomicsdb.so` from the LD_LIBRARY_PATH, otherwise it extracts from the genomicsdb.jar. @ldgauthier, do you have an older version of the native `libtiledbgenomicsdb.so` in your LD_LIBRARY_PATH env? That could be one cause. Otherwise, if you move to using `gatk 4.1.8.1` as @droazen recommends, it will only pick up the native library packed with the genomicsdb 1.3.0 jar. To override the packed genomicsdb library, in versions 1.3.0+, one has to explicitly the path specify via java options -Dgenomicsdb.library.path=<path_to_libtiledbgenomicsdb.so>.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5568#issuecomment-663238869
https://github.com/broadinstitute/gatk/issues/5568#issuecomment-663238869:118,Testability,log,logging,118,"I just tried with gatk 4.1.7.0 and 4.1.8.0 released zips and cannot reproduce the issue. I can only see buffer resize logging messages when I use a debug version of libtiledbgenomicsdb.so in my private builds. . That said, `gatk 4.1.7.0` picks up `libtiledbgenomicsdb.so` from the LD_LIBRARY_PATH, otherwise it extracts from the genomicsdb.jar. @ldgauthier, do you have an older version of the native `libtiledbgenomicsdb.so` in your LD_LIBRARY_PATH env? That could be one cause. Otherwise, if you move to using `gatk 4.1.8.1` as @droazen recommends, it will only pick up the native library packed with the genomicsdb 1.3.0 jar. To override the packed genomicsdb library, in versions 1.3.0+, one has to explicitly the path specify via java options -Dgenomicsdb.library.path=<path_to_libtiledbgenomicsdb.so>.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5568#issuecomment-663238869
https://github.com/broadinstitute/gatk/issues/5570#issuecomment-469502322:153,Deployability,configurat,configuration,153,"I'm assuming you will have the subset of samples before creating a GenomicsDBFeatureReader object (and before creating the corresponding Protobuf export configuration object). More precisely, you are NOT requesting a line by line filter similar to:; At pos 100, compute INFO fields etc including only the samples whose QUAL > 5; At pos 102, compute INFO fields etc including only the samples whose QUAL > 5; ....",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5570#issuecomment-469502322
https://github.com/broadinstitute/gatk/issues/5570#issuecomment-469502322:153,Modifiability,config,configuration,153,"I'm assuming you will have the subset of samples before creating a GenomicsDBFeatureReader object (and before creating the corresponding Protobuf export configuration object). More precisely, you are NOT requesting a line by line filter similar to:; At pos 100, compute INFO fields etc including only the samples whose QUAL > 5; At pos 102, compute INFO fields etc including only the samples whose QUAL > 5; ....",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5570#issuecomment-469502322
https://github.com/broadinstitute/gatk/issues/5570#issuecomment-469680991:416,Deployability,configurat,configuration,416,"Right. I want to subset by sample name, effectively taking a slice of the; position by sample genotype matrix and computing Info annotations based; only in the kept samples. On Mon, Mar 4, 2019, 8:52 PM Karthik Gururaj <notifications@github.com>; wrote:. > I'm assuming you will have the subset of samples before creating a; > GenomicsDBFeatureReader object (and before creating the corresponding; > Protobuf export configuration object).; >; > More precisely, you are NOT requesting a line by line filter similar to:; > At pos 100, compute INFO fields etc including only the samples whose QUAL; > > 5; > At pos 102, compute INFO fields etc including only the samples whose QUAL; > > 5; > ....; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/5570#issuecomment-469502322>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdMZjIbDJ2eDZcB69XHiUycnumzHrks5vTc3PgaJpZM4Z7pF2>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5570#issuecomment-469680991
https://github.com/broadinstitute/gatk/issues/5570#issuecomment-469680991:416,Modifiability,config,configuration,416,"Right. I want to subset by sample name, effectively taking a slice of the; position by sample genotype matrix and computing Info annotations based; only in the kept samples. On Mon, Mar 4, 2019, 8:52 PM Karthik Gururaj <notifications@github.com>; wrote:. > I'm assuming you will have the subset of samples before creating a; > GenomicsDBFeatureReader object (and before creating the corresponding; > Protobuf export configuration object).; >; > More precisely, you are NOT requesting a line by line filter similar to:; > At pos 100, compute INFO fields etc including only the samples whose QUAL; > > 5; > At pos 102, compute INFO fields etc including only the samples whose QUAL; > > 5; > ....; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/5570#issuecomment-469502322>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdMZjIbDJ2eDZcB69XHiUycnumzHrks5vTc3PgaJpZM4Z7pF2>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5570#issuecomment-469680991
https://github.com/broadinstitute/gatk/issues/5570#issuecomment-469787368:81,Availability,error,error,81,"If the sample name does not exist in the vid map (JSON file), should we throw an error or print warning and continue?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5570#issuecomment-469787368
https://github.com/broadinstitute/gatk/issues/5570#issuecomment-512902238:99,Deployability,release,release,99,This feature has been implemented in GenomicsDB by @kgururaj and is part of the 1.1.0.1 GenomicsDB release. PR #5970 will bring in 1.1.0.1 for this feature.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5570#issuecomment-512902238
https://github.com/broadinstitute/gatk/pull/5573#issuecomment-455708523:2809,Modifiability,Plugin,Plugin,2809, (ø)` | `0 <0> (?)` | |; | [...dinstitute/hellbender/engine/GATKToolUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5573/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvR0FUS1Rvb2xVbml0VGVzdC5qYXZh) | `91.017% <100%> (+0.473%)` | `71 <0> (ø)` | :arrow_down: |; | [...ine/GATKPlugin/GATKReadFilterPluginDescriptor.java](https://codecov.io/gh/broadinstitute/gatk/pull/5573/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vR0FUS1JlYWRGaWx0ZXJQbHVnaW5EZXNjcmlwdG9yLmphdmE=) | `83.846% <100%> (+0.252%)` | `49 <2> (ø)` | :arrow_down: |; | [...GATKPlugin/GATKReadFilterPluginDescriptorTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5573/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vR0FUS1JlYWRGaWx0ZXJQbHVnaW5EZXNjcmlwdG9yVGVzdC5qYXZh) | `88.62% <50%> (-1.76%)` | `48 <1> (+1)` | |; | [...Plugin/GATKAnnotationPluginDescriptorUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5573/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vR0FUS0Fubm90YXRpb25QbHVnaW5EZXNjcmlwdG9yVW5pdFRlc3QuamF2YQ==) | `88.235% <63.158%> (-1.43%)` | `58 <1> (+1)` | |; | [...rg/broadinstitute/hellbender/utils/ClassUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5573/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9DbGFzc1V0aWxzLmphdmE=) | `86.842% <75%> (+1.128%)` | `21 <2> (+2)` | :arrow_up: |; | [...ine/GATKPlugin/GATKAnnotationPluginDescriptor.java](https://codecov.io/gh/broadinstitute/gatk/pull/5573/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vR0FUS0Fubm90YXRpb25QbHVnaW5EZXNjcmlwdG9yLmphdmE=) | `76.875% <83.333%> (+0.293%)` | `57 <3> (ø)` | :arrow_down: |; | [.../tools/walkers/haplotypecaller/RefVsAnyResult.java](https://codecov.io/,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5573#issuecomment-455708523
https://github.com/broadinstitute/gatk/pull/5573#issuecomment-455708523:1271,Testability,test,testpluggables,1271,c=pr&el=desc) will **decrease** coverage by `0.003%`.; > The diff coverage is `64.516%`. ```diff; @@ Coverage Diff @@; ## master #5573 +/- ##; ===============================================; - Coverage 87.046% 87.043% -0.003% ; - Complexity 31524 31533 +9 ; ===============================================; Files 1928 1930 +2 ; Lines 145340 145387 +47 ; Branches 16089 16088 -1 ; ===============================================; + Hits 126513 126549 +36 ; - Misses 12966 12981 +15 ; + Partials 5861 5857 -4; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5573?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...ools/walkers/annotator/VariantAnnotatorEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/5573/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9WYXJpYW50QW5ub3RhdG9yRW5naW5lLmphdmE=) | `91.304% <ø> (ø)` | `70 <0> (ø)` | :arrow_down: |; | [...line/GATKPlugin/testpluggables/TestAnnotation.java](https://codecov.io/gh/broadinstitute/gatk/pull/5573/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vdGVzdHBsdWdnYWJsZXMvVGVzdEFubm90YXRpb24uamF2YQ==) | `0% <0%> (ø)` | `0 <0> (?)` | |; | [...line/GATKPlugin/testpluggables/TestReadFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5573/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vdGVzdHBsdWdnYWJsZXMvVGVzdFJlYWRGaWx0ZXIuamF2YQ==) | `0% <0%> (ø)` | `0 <0> (?)` | |; | [...dinstitute/hellbender/engine/GATKToolUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5573/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvR0FUS1Rvb2xVbml0VGVzdC5qYXZh) | `91.017% <100%> (+0.473%)` | `71 <0> (ø)` | :arrow_down: |; | [...ine/GATKPlugin/GATKReadFilterPluginDescriptor.java](https://codecov.io/gh/broadinstitute/gatk/pull/5573/diff?src=pr&el=t,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5573#issuecomment-455708523
https://github.com/broadinstitute/gatk/pull/5573#issuecomment-455708523:1286,Testability,Test,TestAnnotation,1286,c=pr&el=desc) will **decrease** coverage by `0.003%`.; > The diff coverage is `64.516%`. ```diff; @@ Coverage Diff @@; ## master #5573 +/- ##; ===============================================; - Coverage 87.046% 87.043% -0.003% ; - Complexity 31524 31533 +9 ; ===============================================; Files 1928 1930 +2 ; Lines 145340 145387 +47 ; Branches 16089 16088 -1 ; ===============================================; + Hits 126513 126549 +36 ; - Misses 12966 12981 +15 ; + Partials 5861 5857 -4; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5573?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...ools/walkers/annotator/VariantAnnotatorEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/5573/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9WYXJpYW50QW5ub3RhdG9yRW5naW5lLmphdmE=) | `91.304% <ø> (ø)` | `70 <0> (ø)` | :arrow_down: |; | [...line/GATKPlugin/testpluggables/TestAnnotation.java](https://codecov.io/gh/broadinstitute/gatk/pull/5573/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vdGVzdHBsdWdnYWJsZXMvVGVzdEFubm90YXRpb24uamF2YQ==) | `0% <0%> (ø)` | `0 <0> (?)` | |; | [...line/GATKPlugin/testpluggables/TestReadFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5573/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vdGVzdHBsdWdnYWJsZXMvVGVzdFJlYWRGaWx0ZXIuamF2YQ==) | `0% <0%> (ø)` | `0 <0> (?)` | |; | [...dinstitute/hellbender/engine/GATKToolUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5573/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvR0FUS1Rvb2xVbml0VGVzdC5qYXZh) | `91.017% <100%> (+0.473%)` | `71 <0> (ø)` | :arrow_down: |; | [...ine/GATKPlugin/GATKReadFilterPluginDescriptor.java](https://codecov.io/gh/broadinstitute/gatk/pull/5573/diff?src=pr&el=t,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5573#issuecomment-455708523
https://github.com/broadinstitute/gatk/pull/5573#issuecomment-455708523:1575,Testability,test,testpluggables,1575,==; Files 1928 1930 +2 ; Lines 145340 145387 +47 ; Branches 16089 16088 -1 ; ===============================================; + Hits 126513 126549 +36 ; - Misses 12966 12981 +15 ; + Partials 5861 5857 -4; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5573?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...ools/walkers/annotator/VariantAnnotatorEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/5573/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9WYXJpYW50QW5ub3RhdG9yRW5naW5lLmphdmE=) | `91.304% <ø> (ø)` | `70 <0> (ø)` | :arrow_down: |; | [...line/GATKPlugin/testpluggables/TestAnnotation.java](https://codecov.io/gh/broadinstitute/gatk/pull/5573/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vdGVzdHBsdWdnYWJsZXMvVGVzdEFubm90YXRpb24uamF2YQ==) | `0% <0%> (ø)` | `0 <0> (?)` | |; | [...line/GATKPlugin/testpluggables/TestReadFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5573/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vdGVzdHBsdWdnYWJsZXMvVGVzdFJlYWRGaWx0ZXIuamF2YQ==) | `0% <0%> (ø)` | `0 <0> (?)` | |; | [...dinstitute/hellbender/engine/GATKToolUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5573/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvR0FUS1Rvb2xVbml0VGVzdC5qYXZh) | `91.017% <100%> (+0.473%)` | `71 <0> (ø)` | :arrow_down: |; | [...ine/GATKPlugin/GATKReadFilterPluginDescriptor.java](https://codecov.io/gh/broadinstitute/gatk/pull/5573/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vR0FUS1JlYWRGaWx0ZXJQbHVnaW5EZXNjcmlwdG9yLmphdmE=) | `83.846% <100%> (+0.252%)` | `49 <2> (ø)` | :arrow_down: |; | [...GATKPlugin/GATKReadFilterPluginDescriptorTest.java](https://codecov.io/gh/broadinstitute/gatk,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5573#issuecomment-455708523
https://github.com/broadinstitute/gatk/pull/5573#issuecomment-455708523:1590,Testability,Test,TestReadFilter,1590,==; Files 1928 1930 +2 ; Lines 145340 145387 +47 ; Branches 16089 16088 -1 ; ===============================================; + Hits 126513 126549 +36 ; - Misses 12966 12981 +15 ; + Partials 5861 5857 -4; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5573?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...ools/walkers/annotator/VariantAnnotatorEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/5573/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9WYXJpYW50QW5ub3RhdG9yRW5naW5lLmphdmE=) | `91.304% <ø> (ø)` | `70 <0> (ø)` | :arrow_down: |; | [...line/GATKPlugin/testpluggables/TestAnnotation.java](https://codecov.io/gh/broadinstitute/gatk/pull/5573/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vdGVzdHBsdWdnYWJsZXMvVGVzdEFubm90YXRpb24uamF2YQ==) | `0% <0%> (ø)` | `0 <0> (?)` | |; | [...line/GATKPlugin/testpluggables/TestReadFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5573/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vdGVzdHBsdWdnYWJsZXMvVGVzdFJlYWRGaWx0ZXIuamF2YQ==) | `0% <0%> (ø)` | `0 <0> (?)` | |; | [...dinstitute/hellbender/engine/GATKToolUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5573/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvR0FUS1Rvb2xVbml0VGVzdC5qYXZh) | `91.017% <100%> (+0.473%)` | `71 <0> (ø)` | :arrow_down: |; | [...ine/GATKPlugin/GATKReadFilterPluginDescriptor.java](https://codecov.io/gh/broadinstitute/gatk/pull/5573/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vR0FUS1JlYWRGaWx0ZXJQbHVnaW5EZXNjcmlwdG9yLmphdmE=) | `83.846% <100%> (+0.252%)` | `49 <2> (ø)` | :arrow_down: |; | [...GATKPlugin/GATKReadFilterPluginDescriptorTest.java](https://codecov.io/gh/broadinstitute/gatk,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5573#issuecomment-455708523
https://github.com/broadinstitute/gatk/pull/5574#issuecomment-456044768:1870,Deployability,pipeline,pipelines,1870,verage Δ | Complexity Δ | |; |---|---|---|---|; | [...stitute/hellbender/engine/spark/GATKSparkTool.java](https://codecov.io/gh/broadinstitute/gatk/pull/5574/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvR0FUS1NwYXJrVG9vbC5qYXZh) | `82.418% <100%> (+0.097%)` | `78 <0> (ø)` | :arrow_down: |; | [...stitute/hellbender/tools/HaplotypeCallerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5574/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9IYXBsb3R5cGVDYWxsZXJTcGFyay5qYXZh) | `82.759% <100%> (ø)` | `20 <1> (ø)` | :arrow_down: |; | [...e/spark/datasources/VariantsSparkSinkUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5574/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvVmFyaWFudHNTcGFya1NpbmtVbml0VGVzdC5qYXZh) | `83.212% <100%> (+1.041%)` | `28 <0> (ø)` | :arrow_down: |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5574/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `66.667% <100%> (ø)` | `2 <1> (ø)` | :arrow_down: |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5574/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `90.741% <100%> (ø)` | `13 <0> (ø)` | :arrow_down: |; | [...er/engine/spark/datasources/VariantsSparkSink.java](https://codecov.io/gh/broadinstitute/gatk/pull/5574/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvVmFyaWFudHNTcGFya1NpbmsuamF2YQ==) | `78.125% <57.143%> (-11.53%)` | `8 <1> (-1)` | |; | [...ithwaterman/SmithWatermanIntelAlignerUnitTest.java](https://codecov.io/gh/broadinstit,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5574#issuecomment-456044768
https://github.com/broadinstitute/gatk/pull/5574#issuecomment-456044768:2182,Deployability,pipeline,pipelines,2182,` | `78 <0> (ø)` | :arrow_down: |; | [...stitute/hellbender/tools/HaplotypeCallerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5574/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9IYXBsb3R5cGVDYWxsZXJTcGFyay5qYXZh) | `82.759% <100%> (ø)` | `20 <1> (ø)` | :arrow_down: |; | [...e/spark/datasources/VariantsSparkSinkUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5574/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvVmFyaWFudHNTcGFya1NpbmtVbml0VGVzdC5qYXZh) | `83.212% <100%> (+1.041%)` | `28 <0> (ø)` | :arrow_down: |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5574/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `66.667% <100%> (ø)` | `2 <1> (ø)` | :arrow_down: |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5574/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `90.741% <100%> (ø)` | `13 <0> (ø)` | :arrow_down: |; | [...er/engine/spark/datasources/VariantsSparkSink.java](https://codecov.io/gh/broadinstitute/gatk/pull/5574/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvVmFyaWFudHNTcGFya1NpbmsuamF2YQ==) | `78.125% <57.143%> (-11.53%)` | `8 <1> (-1)` | |; | [...ithwaterman/SmithWatermanIntelAlignerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5574/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXJVbml0VGVzdC5qYXZh) | `60% <0%> (ø)` | `2% <0%> (ø)` | :arrow_down: |; | [...lotypecaller/readthreading/ReadThreadingGraph.java](https://codecov.io/gh,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5574#issuecomment-456044768
https://github.com/broadinstitute/gatk/pull/5575#issuecomment-454182635:1614,Usability,Simpl,SimpleCountCollection,1614, 144995 145320 +325 ; Branches 16064 16089 +25 ; ===============================================; + Hits 126224 126498 +274 ; - Misses 12929 12963 +34 ; - Partials 5842 5859 +17; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5575?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...er/tools/copynumber/CollectAllelicCountsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5575/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL0NvbGxlY3RBbGxlbGljQ291bnRzU3BhcmsuamF2YQ==) | `96% <ø> (ø)` | `10 <0> (ø)` | :arrow_down: |; | [.../CreateReadCountPanelOfNormalsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5575/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL0NyZWF0ZVJlYWRDb3VudFBhbmVsT2ZOb3JtYWxzSW50ZWdyYXRpb25UZXN0LmphdmE=) | `96.196% <ø> (ø)` | `39 <0> (ø)` | :arrow_down: |; | [...ber/formats/collections/SimpleCountCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/5575/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2Zvcm1hdHMvY29sbGVjdGlvbnMvU2ltcGxlQ291bnRDb2xsZWN0aW9uLmphdmE=) | `100% <ø> (ø)` | `12 <0> (ø)` | :arrow_down: |; | [...s/copynumber/GermlineCNVCallerIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5575/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL0dlcm1saW5lQ05WQ2FsbGVySW50ZWdyYXRpb25UZXN0LmphdmE=) | `90.909% <ø> (ø)` | `7 <0> (ø)` | :arrow_down: |; | [...mber/denoising/HDF5SVDReadCountPanelOfNormals.java](https://codecov.io/gh/broadinstitute/gatk/pull/5575/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2Rlbm9pc2luZy9IREY1U1ZEUmVhZENvdW50UGFuZWxPZk5vcm1hbHMuamF2YQ==) | `88.406% <ø> (ø)` | `41 <0> (ø)` | :arrow_down: |; | [...s/copynumber/CollectReadCountsIntegra,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5575#issuecomment-454182635
https://github.com/broadinstitute/gatk/pull/5575#issuecomment-454570347:224,Availability,failure,failures,224,"TCGA SNP validation looks about the same on WES---perhaps a slight tradeoff of sensitivity for specificity at the 0.1% level, but nothing to write home about. WGS validations are still running due to the (intermittent?) NIO failures discussed elsewhere.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5575#issuecomment-454570347
https://github.com/broadinstitute/gatk/pull/5575#issuecomment-454570347:9,Security,validat,validation,9,"TCGA SNP validation looks about the same on WES---perhaps a slight tradeoff of sensitivity for specificity at the 0.1% level, but nothing to write home about. WGS validations are still running due to the (intermittent?) NIO failures discussed elsewhere.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5575#issuecomment-454570347
https://github.com/broadinstitute/gatk/pull/5575#issuecomment-454570347:163,Security,validat,validations,163,"TCGA SNP validation looks about the same on WES---perhaps a slight tradeoff of sensitivity for specificity at the 0.1% level, but nothing to write home about. WGS validations are still running due to the (intermittent?) NIO failures discussed elsewhere.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5575#issuecomment-454570347
https://github.com/broadinstitute/gatk/pull/5575#issuecomment-454581846:8,Security,validat,validations,8,"The WGS validations that have completed so far look fine, though. Changes at the 0.1% level, mostly improvements, but nothing appears to be obviously broken. Should still run some of the other validations to be sure, but let's get this in for 4.1.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5575#issuecomment-454581846
https://github.com/broadinstitute/gatk/pull/5575#issuecomment-454581846:193,Security,validat,validations,193,"The WGS validations that have completed so far look fine, though. Changes at the 0.1% level, mostly improvements, but nothing appears to be obviously broken. Should still run some of the other validations to be sure, but let's get this in for 4.1.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5575#issuecomment-454581846
https://github.com/broadinstitute/gatk/pull/5575#issuecomment-454765304:4,Security,validat,validations,4,"WGS validations are done and still look fine. @LeeTL1220 want to run your validations? 4.0.12.0 Docker + override jar should do the trick. In any case, I think the review can proceed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5575#issuecomment-454765304
https://github.com/broadinstitute/gatk/pull/5575#issuecomment-454765304:74,Security,validat,validations,74,"WGS validations are done and still look fine. @LeeTL1220 want to run your validations? 4.0.12.0 Docker + override jar should do the trick. In any case, I think the review can proceed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5575#issuecomment-454765304
https://github.com/broadinstitute/gatk/pull/5575#issuecomment-455193485:119,Testability,test,test,119,"@samuelklee The results are definitely improved for the WES. WGS looks about the same. Here is the reproducibility WES test on HCC1143, which is improved. ![image](https://user-images.githubusercontent.com/2152339/51325543-2e148480-1a3b-11e9-9264-ea5ce5dbc1d9.png)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5575#issuecomment-455193485
https://github.com/broadinstitute/gatk/pull/5575#issuecomment-455313570:41,Testability,test,tests,41,"Done, thanks @LeeTL1220. Will merge when tests pass.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5575#issuecomment-455313570
https://github.com/broadinstitute/gatk/pull/5576#issuecomment-454236513:232,Availability,error,error-reference,232,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5576?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@d7d62d4`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `100%`. ```diff; @@ Coverage Diff @@; ## master #5576 +/- ##; =========================================; Coverage ? 87.05% ; Complexity ? 31450 ; =========================================; Files ? 1921 ; Lines ? 144996 ; Branches ? 16064 ; =========================================; Hits ? 126219 ; Misses ? 12934 ; Partials ? 5843; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5576?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...ine/GATKPlugin/GATKAnnotationPluginDescriptor.java](https://codecov.io/gh/broadinstitute/gatk/pull/5576/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vR0FUS0Fubm90YXRpb25QbHVnaW5EZXNjcmlwdG9yLmphdmE=) | `76.582% <ø> (ø)` | `57 <0> (?)` | |; | [...ine/GATKPlugin/GATKReadFilterPluginDescriptor.java](https://codecov.io/gh/broadinstitute/gatk/pull/5576/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vR0FUS1JlYWRGaWx0ZXJQbHVnaW5EZXNjcmlwdG9yLmphdmE=) | `83.594% <100%> (ø)` | `49 <1> (?)` | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5576#issuecomment-454236513
https://github.com/broadinstitute/gatk/pull/5576#issuecomment-454236513:180,Usability,learn,learn,180,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5576?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@d7d62d4`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `100%`. ```diff; @@ Coverage Diff @@; ## master #5576 +/- ##; =========================================; Coverage ? 87.05% ; Complexity ? 31450 ; =========================================; Files ? 1921 ; Lines ? 144996 ; Branches ? 16064 ; =========================================; Hits ? 126219 ; Misses ? 12934 ; Partials ? 5843; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5576?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...ine/GATKPlugin/GATKAnnotationPluginDescriptor.java](https://codecov.io/gh/broadinstitute/gatk/pull/5576/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vR0FUS0Fubm90YXRpb25QbHVnaW5EZXNjcmlwdG9yLmphdmE=) | `76.582% <ø> (ø)` | `57 <0> (?)` | |; | [...ine/GATKPlugin/GATKReadFilterPluginDescriptor.java](https://codecov.io/gh/broadinstitute/gatk/pull/5576/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vR0FUS1JlYWRGaWx0ZXJQbHVnaW5EZXNjcmlwdG9yLmphdmE=) | `83.594% <100%> (ø)` | `49 <1> (?)` | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5576#issuecomment-454236513
https://github.com/broadinstitute/gatk/pull/5579#issuecomment-671080367:166,Availability,avail,available,166,@kachulis May I ask where is the resulting chain file for lifting over from Hg38 to B37? It seems to me that only the chain file for lifting over from B37 to Hg38 is available in the repo. Thanks.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5579#issuecomment-671080367
https://github.com/broadinstitute/gatk/issues/5582#issuecomment-630137734:86,Availability,ERROR,ERROR,86,"Hey @jemunro,. Thanks for sharing your fix. I tried it on my data but now I have this ERROR message:; ```; ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A GATK RUNTIME ERROR has occurred (version 3.8-0-ge9d806836):; ##### ERROR; ##### ERROR This might be a bug. Please check the documentation guide to see if this is a known problem.; ##### ERROR If not, please post the error message, with stack trace, to the GATK forum.; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR MESSAGE: For input string: ""NaN\1SOR=0.693""; ##### ERROR ------------------------------------------------------------------------------------------; INFO 13:46:00,793 HelpFormatter - ---------------------------------------------------------------------------------- ; ```; Would not be enough to use this code instead?:; ```; bcftools view in.vcf.gz |; sed 's/=nan/=NaN/g' |; bgzip > fixed.vcf.gz; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5582#issuecomment-630137734
https://github.com/broadinstitute/gatk/issues/5582#issuecomment-630137734:113,Availability,ERROR,ERROR,113,"Hey @jemunro,. Thanks for sharing your fix. I tried it on my data but now I have this ERROR message:; ```; ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A GATK RUNTIME ERROR has occurred (version 3.8-0-ge9d806836):; ##### ERROR; ##### ERROR This might be a bug. Please check the documentation guide to see if this is a known problem.; ##### ERROR If not, please post the error message, with stack trace, to the GATK forum.; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR MESSAGE: For input string: ""NaN\1SOR=0.693""; ##### ERROR ------------------------------------------------------------------------------------------; INFO 13:46:00,793 HelpFormatter - ---------------------------------------------------------------------------------- ; ```; Would not be enough to use this code instead?:; ```; bcftools view in.vcf.gz |; sed 's/=nan/=NaN/g' |; bgzip > fixed.vcf.gz; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5582#issuecomment-630137734
https://github.com/broadinstitute/gatk/issues/5582#issuecomment-630137734:217,Availability,ERROR,ERROR,217,"Hey @jemunro,. Thanks for sharing your fix. I tried it on my data but now I have this ERROR message:; ```; ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A GATK RUNTIME ERROR has occurred (version 3.8-0-ge9d806836):; ##### ERROR; ##### ERROR This might be a bug. Please check the documentation guide to see if this is a known problem.; ##### ERROR If not, please post the error message, with stack trace, to the GATK forum.; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR MESSAGE: For input string: ""NaN\1SOR=0.693""; ##### ERROR ------------------------------------------------------------------------------------------; INFO 13:46:00,793 HelpFormatter - ---------------------------------------------------------------------------------- ; ```; Would not be enough to use this code instead?:; ```; bcftools view in.vcf.gz |; sed 's/=nan/=NaN/g' |; bgzip > fixed.vcf.gz; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5582#issuecomment-630137734
https://github.com/broadinstitute/gatk/issues/5582#issuecomment-630137734:238,Availability,ERROR,ERROR,238,"Hey @jemunro,. Thanks for sharing your fix. I tried it on my data but now I have this ERROR message:; ```; ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A GATK RUNTIME ERROR has occurred (version 3.8-0-ge9d806836):; ##### ERROR; ##### ERROR This might be a bug. Please check the documentation guide to see if this is a known problem.; ##### ERROR If not, please post the error message, with stack trace, to the GATK forum.; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR MESSAGE: For input string: ""NaN\1SOR=0.693""; ##### ERROR ------------------------------------------------------------------------------------------; INFO 13:46:00,793 HelpFormatter - ---------------------------------------------------------------------------------- ; ```; Would not be enough to use this code instead?:; ```; bcftools view in.vcf.gz |; sed 's/=nan/=NaN/g' |; bgzip > fixed.vcf.gz; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5582#issuecomment-630137734
https://github.com/broadinstitute/gatk/issues/5582#issuecomment-630137734:292,Availability,ERROR,ERROR,292,"Hey @jemunro,. Thanks for sharing your fix. I tried it on my data but now I have this ERROR message:; ```; ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A GATK RUNTIME ERROR has occurred (version 3.8-0-ge9d806836):; ##### ERROR; ##### ERROR This might be a bug. Please check the documentation guide to see if this is a known problem.; ##### ERROR If not, please post the error message, with stack trace, to the GATK forum.; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR MESSAGE: For input string: ""NaN\1SOR=0.693""; ##### ERROR ------------------------------------------------------------------------------------------; INFO 13:46:00,793 HelpFormatter - ---------------------------------------------------------------------------------- ; ```; Would not be enough to use this code instead?:; ```; bcftools view in.vcf.gz |; sed 's/=nan/=NaN/g' |; bgzip > fixed.vcf.gz; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5582#issuecomment-630137734
https://github.com/broadinstitute/gatk/issues/5582#issuecomment-630137734:305,Availability,ERROR,ERROR,305,"Hey @jemunro,. Thanks for sharing your fix. I tried it on my data but now I have this ERROR message:; ```; ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A GATK RUNTIME ERROR has occurred (version 3.8-0-ge9d806836):; ##### ERROR; ##### ERROR This might be a bug. Please check the documentation guide to see if this is a known problem.; ##### ERROR If not, please post the error message, with stack trace, to the GATK forum.; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR MESSAGE: For input string: ""NaN\1SOR=0.693""; ##### ERROR ------------------------------------------------------------------------------------------; INFO 13:46:00,793 HelpFormatter - ---------------------------------------------------------------------------------- ; ```; Would not be enough to use this code instead?:; ```; bcftools view in.vcf.gz |; sed 's/=nan/=NaN/g' |; bgzip > fixed.vcf.gz; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5582#issuecomment-630137734
https://github.com/broadinstitute/gatk/issues/5582#issuecomment-630137734:411,Availability,ERROR,ERROR,411,"Hey @jemunro,. Thanks for sharing your fix. I tried it on my data but now I have this ERROR message:; ```; ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A GATK RUNTIME ERROR has occurred (version 3.8-0-ge9d806836):; ##### ERROR; ##### ERROR This might be a bug. Please check the documentation guide to see if this is a known problem.; ##### ERROR If not, please post the error message, with stack trace, to the GATK forum.; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR MESSAGE: For input string: ""NaN\1SOR=0.693""; ##### ERROR ------------------------------------------------------------------------------------------; INFO 13:46:00,793 HelpFormatter - ---------------------------------------------------------------------------------- ; ```; Would not be enough to use this code instead?:; ```; bcftools view in.vcf.gz |; sed 's/=nan/=NaN/g' |; bgzip > fixed.vcf.gz; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5582#issuecomment-630137734
https://github.com/broadinstitute/gatk/issues/5582#issuecomment-630137734:441,Availability,error,error,441,"Hey @jemunro,. Thanks for sharing your fix. I tried it on my data but now I have this ERROR message:; ```; ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A GATK RUNTIME ERROR has occurred (version 3.8-0-ge9d806836):; ##### ERROR; ##### ERROR This might be a bug. Please check the documentation guide to see if this is a known problem.; ##### ERROR If not, please post the error message, with stack trace, to the GATK forum.; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR MESSAGE: For input string: ""NaN\1SOR=0.693""; ##### ERROR ------------------------------------------------------------------------------------------; INFO 13:46:00,793 HelpFormatter - ---------------------------------------------------------------------------------- ; ```; Would not be enough to use this code instead?:; ```; bcftools view in.vcf.gz |; sed 's/=nan/=NaN/g' |; bgzip > fixed.vcf.gz; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5582#issuecomment-630137734
https://github.com/broadinstitute/gatk/issues/5582#issuecomment-630137734:500,Availability,ERROR,ERROR,500,"Hey @jemunro,. Thanks for sharing your fix. I tried it on my data but now I have this ERROR message:; ```; ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A GATK RUNTIME ERROR has occurred (version 3.8-0-ge9d806836):; ##### ERROR; ##### ERROR This might be a bug. Please check the documentation guide to see if this is a known problem.; ##### ERROR If not, please post the error message, with stack trace, to the GATK forum.; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR MESSAGE: For input string: ""NaN\1SOR=0.693""; ##### ERROR ------------------------------------------------------------------------------------------; INFO 13:46:00,793 HelpFormatter - ---------------------------------------------------------------------------------- ; ```; Would not be enough to use this code instead?:; ```; bcftools view in.vcf.gz |; sed 's/=nan/=NaN/g' |; bgzip > fixed.vcf.gz; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5582#issuecomment-630137734
https://github.com/broadinstitute/gatk/issues/5582#issuecomment-630137734:585,Availability,ERROR,ERROR,585,"Hey @jemunro,. Thanks for sharing your fix. I tried it on my data but now I have this ERROR message:; ```; ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A GATK RUNTIME ERROR has occurred (version 3.8-0-ge9d806836):; ##### ERROR; ##### ERROR This might be a bug. Please check the documentation guide to see if this is a known problem.; ##### ERROR If not, please post the error message, with stack trace, to the GATK forum.; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR MESSAGE: For input string: ""NaN\1SOR=0.693""; ##### ERROR ------------------------------------------------------------------------------------------; INFO 13:46:00,793 HelpFormatter - ---------------------------------------------------------------------------------- ; ```; Would not be enough to use this code instead?:; ```; bcftools view in.vcf.gz |; sed 's/=nan/=NaN/g' |; bgzip > fixed.vcf.gz; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5582#issuecomment-630137734
https://github.com/broadinstitute/gatk/issues/5582#issuecomment-630137734:664,Availability,ERROR,ERROR,664,"Hey @jemunro,. Thanks for sharing your fix. I tried it on my data but now I have this ERROR message:; ```; ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A GATK RUNTIME ERROR has occurred (version 3.8-0-ge9d806836):; ##### ERROR; ##### ERROR This might be a bug. Please check the documentation guide to see if this is a known problem.; ##### ERROR If not, please post the error message, with stack trace, to the GATK forum.; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR MESSAGE: For input string: ""NaN\1SOR=0.693""; ##### ERROR ------------------------------------------------------------------------------------------; INFO 13:46:00,793 HelpFormatter - ---------------------------------------------------------------------------------- ; ```; Would not be enough to use this code instead?:; ```; bcftools view in.vcf.gz |; sed 's/=nan/=NaN/g' |; bgzip > fixed.vcf.gz; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5582#issuecomment-630137734
https://github.com/broadinstitute/gatk/issues/5582#issuecomment-630137734:677,Availability,ERROR,ERROR,677,"Hey @jemunro,. Thanks for sharing your fix. I tried it on my data but now I have this ERROR message:; ```; ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A GATK RUNTIME ERROR has occurred (version 3.8-0-ge9d806836):; ##### ERROR; ##### ERROR This might be a bug. Please check the documentation guide to see if this is a known problem.; ##### ERROR If not, please post the error message, with stack trace, to the GATK forum.; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR MESSAGE: For input string: ""NaN\1SOR=0.693""; ##### ERROR ------------------------------------------------------------------------------------------; INFO 13:46:00,793 HelpFormatter - ---------------------------------------------------------------------------------- ; ```; Would not be enough to use this code instead?:; ```; bcftools view in.vcf.gz |; sed 's/=nan/=NaN/g' |; bgzip > fixed.vcf.gz; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5582#issuecomment-630137734
https://github.com/broadinstitute/gatk/issues/5582#issuecomment-630137734:734,Availability,ERROR,ERROR,734,"Hey @jemunro,. Thanks for sharing your fix. I tried it on my data but now I have this ERROR message:; ```; ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A GATK RUNTIME ERROR has occurred (version 3.8-0-ge9d806836):; ##### ERROR; ##### ERROR This might be a bug. Please check the documentation guide to see if this is a known problem.; ##### ERROR If not, please post the error message, with stack trace, to the GATK forum.; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR MESSAGE: For input string: ""NaN\1SOR=0.693""; ##### ERROR ------------------------------------------------------------------------------------------; INFO 13:46:00,793 HelpFormatter - ---------------------------------------------------------------------------------- ; ```; Would not be enough to use this code instead?:; ```; bcftools view in.vcf.gz |; sed 's/=nan/=NaN/g' |; bgzip > fixed.vcf.gz; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5582#issuecomment-630137734
https://github.com/broadinstitute/gatk/issues/5582#issuecomment-630137734:92,Integrability,message,message,92,"Hey @jemunro,. Thanks for sharing your fix. I tried it on my data but now I have this ERROR message:; ```; ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A GATK RUNTIME ERROR has occurred (version 3.8-0-ge9d806836):; ##### ERROR; ##### ERROR This might be a bug. Please check the documentation guide to see if this is a known problem.; ##### ERROR If not, please post the error message, with stack trace, to the GATK forum.; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR MESSAGE: For input string: ""NaN\1SOR=0.693""; ##### ERROR ------------------------------------------------------------------------------------------; INFO 13:46:00,793 HelpFormatter - ---------------------------------------------------------------------------------- ; ```; Would not be enough to use this code instead?:; ```; bcftools view in.vcf.gz |; sed 's/=nan/=NaN/g' |; bgzip > fixed.vcf.gz; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5582#issuecomment-630137734
https://github.com/broadinstitute/gatk/issues/5582#issuecomment-630137734:447,Integrability,message,message,447,"Hey @jemunro,. Thanks for sharing your fix. I tried it on my data but now I have this ERROR message:; ```; ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A GATK RUNTIME ERROR has occurred (version 3.8-0-ge9d806836):; ##### ERROR; ##### ERROR This might be a bug. Please check the documentation guide to see if this is a known problem.; ##### ERROR If not, please post the error message, with stack trace, to the GATK forum.; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR MESSAGE: For input string: ""NaN\1SOR=0.693""; ##### ERROR ------------------------------------------------------------------------------------------; INFO 13:46:00,793 HelpFormatter - ---------------------------------------------------------------------------------- ; ```; Would not be enough to use this code instead?:; ```; bcftools view in.vcf.gz |; sed 's/=nan/=NaN/g' |; bgzip > fixed.vcf.gz; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5582#issuecomment-630137734
https://github.com/broadinstitute/gatk/issues/5582#issuecomment-630137734:683,Integrability,MESSAGE,MESSAGE,683,"Hey @jemunro,. Thanks for sharing your fix. I tried it on my data but now I have this ERROR message:; ```; ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A GATK RUNTIME ERROR has occurred (version 3.8-0-ge9d806836):; ##### ERROR; ##### ERROR This might be a bug. Please check the documentation guide to see if this is a known problem.; ##### ERROR If not, please post the error message, with stack trace, to the GATK forum.; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR MESSAGE: For input string: ""NaN\1SOR=0.693""; ##### ERROR ------------------------------------------------------------------------------------------; INFO 13:46:00,793 HelpFormatter - ---------------------------------------------------------------------------------- ; ```; Would not be enough to use this code instead?:; ```; bcftools view in.vcf.gz |; sed 's/=nan/=NaN/g' |; bgzip > fixed.vcf.gz; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5582#issuecomment-630137734
https://github.com/broadinstitute/gatk/issues/5582#issuecomment-630137734:363,Usability,guid,guide,363,"Hey @jemunro,. Thanks for sharing your fix. I tried it on my data but now I have this ERROR message:; ```; ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A GATK RUNTIME ERROR has occurred (version 3.8-0-ge9d806836):; ##### ERROR; ##### ERROR This might be a bug. Please check the documentation guide to see if this is a known problem.; ##### ERROR If not, please post the error message, with stack trace, to the GATK forum.; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR MESSAGE: For input string: ""NaN\1SOR=0.693""; ##### ERROR ------------------------------------------------------------------------------------------; INFO 13:46:00,793 HelpFormatter - ---------------------------------------------------------------------------------- ; ```; Would not be enough to use this code instead?:; ```; bcftools view in.vcf.gz |; sed 's/=nan/=NaN/g' |; bgzip > fixed.vcf.gz; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5582#issuecomment-630137734
https://github.com/broadinstitute/gatk/pull/5583#issuecomment-454957265:41,Availability,error,error,41,@jmthibault79 This fails with a compiler error: . ```; :compileTestJava/home/travis/build/broadinstitute/gatk/src/test/java/org/broadinstitute/hellbender/engine/spark/datasources/VariantsSparkSinkUnitTest.java:240: error: cannot find symbol; return inferFromUncompressedData(IOUtil.isGZIPInputStream(bis) ? new GZIPInputStream(bis) : bis);; ^; symbol: method isGZIPInputStream(BufferedInputStream); location: class IOUtil; 1 error; FAILED; ```. I think you perhaps need to update the htsjdk dependency to a release that includes this change?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5583#issuecomment-454957265
https://github.com/broadinstitute/gatk/pull/5583#issuecomment-454957265:215,Availability,error,error,215,@jmthibault79 This fails with a compiler error: . ```; :compileTestJava/home/travis/build/broadinstitute/gatk/src/test/java/org/broadinstitute/hellbender/engine/spark/datasources/VariantsSparkSinkUnitTest.java:240: error: cannot find symbol; return inferFromUncompressedData(IOUtil.isGZIPInputStream(bis) ? new GZIPInputStream(bis) : bis);; ^; symbol: method isGZIPInputStream(BufferedInputStream); location: class IOUtil; 1 error; FAILED; ```. I think you perhaps need to update the htsjdk dependency to a release that includes this change?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5583#issuecomment-454957265
https://github.com/broadinstitute/gatk/pull/5583#issuecomment-454957265:425,Availability,error,error,425,@jmthibault79 This fails with a compiler error: . ```; :compileTestJava/home/travis/build/broadinstitute/gatk/src/test/java/org/broadinstitute/hellbender/engine/spark/datasources/VariantsSparkSinkUnitTest.java:240: error: cannot find symbol; return inferFromUncompressedData(IOUtil.isGZIPInputStream(bis) ? new GZIPInputStream(bis) : bis);; ^; symbol: method isGZIPInputStream(BufferedInputStream); location: class IOUtil; 1 error; FAILED; ```. I think you perhaps need to update the htsjdk dependency to a release that includes this change?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5583#issuecomment-454957265
https://github.com/broadinstitute/gatk/pull/5583#issuecomment-454957265:473,Deployability,update,update,473,@jmthibault79 This fails with a compiler error: . ```; :compileTestJava/home/travis/build/broadinstitute/gatk/src/test/java/org/broadinstitute/hellbender/engine/spark/datasources/VariantsSparkSinkUnitTest.java:240: error: cannot find symbol; return inferFromUncompressedData(IOUtil.isGZIPInputStream(bis) ? new GZIPInputStream(bis) : bis);; ^; symbol: method isGZIPInputStream(BufferedInputStream); location: class IOUtil; 1 error; FAILED; ```. I think you perhaps need to update the htsjdk dependency to a release that includes this change?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5583#issuecomment-454957265
https://github.com/broadinstitute/gatk/pull/5583#issuecomment-454957265:507,Deployability,release,release,507,@jmthibault79 This fails with a compiler error: . ```; :compileTestJava/home/travis/build/broadinstitute/gatk/src/test/java/org/broadinstitute/hellbender/engine/spark/datasources/VariantsSparkSinkUnitTest.java:240: error: cannot find symbol; return inferFromUncompressedData(IOUtil.isGZIPInputStream(bis) ? new GZIPInputStream(bis) : bis);; ^; symbol: method isGZIPInputStream(BufferedInputStream); location: class IOUtil; 1 error; FAILED; ```. I think you perhaps need to update the htsjdk dependency to a release that includes this change?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5583#issuecomment-454957265
https://github.com/broadinstitute/gatk/pull/5583#issuecomment-454957265:491,Integrability,depend,dependency,491,@jmthibault79 This fails with a compiler error: . ```; :compileTestJava/home/travis/build/broadinstitute/gatk/src/test/java/org/broadinstitute/hellbender/engine/spark/datasources/VariantsSparkSinkUnitTest.java:240: error: cannot find symbol; return inferFromUncompressedData(IOUtil.isGZIPInputStream(bis) ? new GZIPInputStream(bis) : bis);; ^; symbol: method isGZIPInputStream(BufferedInputStream); location: class IOUtil; 1 error; FAILED; ```. I think you perhaps need to update the htsjdk dependency to a release that includes this change?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5583#issuecomment-454957265
https://github.com/broadinstitute/gatk/pull/5583#issuecomment-454957265:114,Testability,test,test,114,@jmthibault79 This fails with a compiler error: . ```; :compileTestJava/home/travis/build/broadinstitute/gatk/src/test/java/org/broadinstitute/hellbender/engine/spark/datasources/VariantsSparkSinkUnitTest.java:240: error: cannot find symbol; return inferFromUncompressedData(IOUtil.isGZIPInputStream(bis) ? new GZIPInputStream(bis) : bis);; ^; symbol: method isGZIPInputStream(BufferedInputStream); location: class IOUtil; 1 error; FAILED; ```. I think you perhaps need to update the htsjdk dependency to a release that includes this change?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5583#issuecomment-454957265
https://github.com/broadinstitute/gatk/pull/5583#issuecomment-454960119:72,Deployability,update,update,72,Right. Time for my own Picard facepalm. I'll wait for the normal HTSJDK update process :),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5583#issuecomment-454960119
https://github.com/broadinstitute/gatk/pull/5586#issuecomment-455261011:3404,Usability,Simpl,SimpleCountCollection,3404,ntedData.java](https://codecov.io/gh/broadinstitute/gatk/pull/5586/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL21vZGVscy9BbGxlbGVGcmFjdGlvblNlZ21lbnRlZERhdGEuamF2YQ==) | `94.444% <0%> (-2.614%)` | `8% <0%> (-1%)` | |; | [...er/tools/copynumber/formats/records/CopyRatio.java](https://codecov.io/gh/broadinstitute/gatk/pull/5586/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2Zvcm1hdHMvcmVjb3Jkcy9Db3B5UmF0aW8uamF2YQ==) | `79.167% <0%> (-0.833%)` | `10% <0%> (ø)` | |; | [...lotypecaller/readthreading/ReadThreadingGraph.java](https://codecov.io/gh/broadinstitute/gatk/pull/5586/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9yZWFkdGhyZWFkaW5nL1JlYWRUaHJlYWRpbmdHcmFwaC5qYXZh) | `88.608% <0%> (-0.253%)` | `144% <0%> (-1%)` | |; | [...e/spark/datasources/VariantsSparkSinkUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5586/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvVmFyaWFudHNTcGFya1NpbmtVbml0VGVzdC5qYXZh) | `82.171% <0%> (ø)` | `28% <0%> (ø)` | :arrow_down: |; | [...ber/formats/collections/SimpleCountCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/5586/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2Zvcm1hdHMvY29sbGVjdGlvbnMvU2ltcGxlQ291bnRDb2xsZWN0aW9uLmphdmE=) | `100% <0%> (ø)` | `12% <0%> (ø)` | :arrow_down: |; | [...er/tools/copynumber/CollectAllelicCountsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5586/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL0NvbGxlY3RBbGxlbGljQ291bnRzU3BhcmsuamF2YQ==) | `96% <0%> (ø)` | `10% <0%> (ø)` | :arrow_down: |; | ... and [18 more](https://codecov.io/gh/broadinstitute/gatk/pull/5586/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5586#issuecomment-455261011
https://github.com/broadinstitute/gatk/pull/5588#issuecomment-455358539:3519,Availability,down,downsampling,3519,ncotationFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5588/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2ZpbHRyYXRpb25SdWxlcy9GdW5jb3RhdGlvbkZpbHRlci5qYXZh) | `100% <100%> (ø)` | `8 <4> (+4)` | :arrow_up: |; | [...r/filtrationRules/FilterFuncotationsExacUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5588/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2ZpbHRyYXRpb25SdWxlcy9GaWx0ZXJGdW5jb3RhdGlvbnNFeGFjVXRpbHMuamF2YQ==) | `81.818% <80.952%> (-0.535%)` | `12 <7> (+5)` | |; | [...walkers/genotyper/afcalc/AFCalculatorProvider.java](https://codecov.io/gh/broadinstitute/gatk/pull/5588/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9hZmNhbGMvQUZDYWxjdWxhdG9yUHJvdmlkZXIuamF2YQ==) | `22.222% <0%> (-44.444%)` | `2% <0%> (-2%)` | |; | [...notyper/afcalc/ConcurrentAFCalculatorProvider.java](https://codecov.io/gh/broadinstitute/gatk/pull/5588/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9hZmNhbGMvQ29uY3VycmVudEFGQ2FsY3VsYXRvclByb3ZpZGVyLmphdmE=) | `50% <0%> (-33.333%)` | `1% <0%> (-1%)` | |; | [...nder/utils/downsampling/PositionalDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/5588/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvUG9zaXRpb25hbERvd25zYW1wbGVyLmphdmE=) | `88.462% <0%> (-11.538%)` | `22% <0%> (+1%)` | |; | [...er/engine/spark/datasources/VariantsSparkSink.java](https://codecov.io/gh/broadinstitute/gatk/pull/5588/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvVmFyaWFudHNTcGFya1NpbmsuamF2YQ==) | `78.125% <0%> (-11.53%)` | `8% <0%> (-1%)` | |; | ... and [138 more](https://codecov.io/gh/broadinstitute/gatk/pull/5588/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5588#issuecomment-455358539
https://github.com/broadinstitute/gatk/pull/5588#issuecomment-455358539:3191,Performance,Concurren,ConcurrentAFCalculatorProvider,3191,otator/filtrationRules/FuncotationFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5588/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2ZpbHRyYXRpb25SdWxlcy9GdW5jb3RhdGlvbkZpbHRlci5qYXZh) | `100% <100%> (ø)` | `8 <4> (+4)` | :arrow_up: |; | [...r/filtrationRules/FilterFuncotationsExacUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5588/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2ZpbHRyYXRpb25SdWxlcy9GaWx0ZXJGdW5jb3RhdGlvbnNFeGFjVXRpbHMuamF2YQ==) | `81.818% <80.952%> (-0.535%)` | `12 <7> (+5)` | |; | [...walkers/genotyper/afcalc/AFCalculatorProvider.java](https://codecov.io/gh/broadinstitute/gatk/pull/5588/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9hZmNhbGMvQUZDYWxjdWxhdG9yUHJvdmlkZXIuamF2YQ==) | `22.222% <0%> (-44.444%)` | `2% <0%> (-2%)` | |; | [...notyper/afcalc/ConcurrentAFCalculatorProvider.java](https://codecov.io/gh/broadinstitute/gatk/pull/5588/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9hZmNhbGMvQ29uY3VycmVudEFGQ2FsY3VsYXRvclByb3ZpZGVyLmphdmE=) | `50% <0%> (-33.333%)` | `1% <0%> (-1%)` | |; | [...nder/utils/downsampling/PositionalDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/5588/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvUG9zaXRpb25hbERvd25zYW1wbGVyLmphdmE=) | `88.462% <0%> (-11.538%)` | `22% <0%> (+1%)` | |; | [...er/engine/spark/datasources/VariantsSparkSink.java](https://codecov.io/gh/broadinstitute/gatk/pull/5588/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvVmFyaWFudHNTcGFya1NpbmsuamF2YQ==) | `78.125% <0%> (-11.53%)` | `8% <0%> (-1%)` | |; | ... and [138 more](https://codecov.io/gh/broadinstitute/gatk/pull/5588/diff,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5588#issuecomment-455358539
https://github.com/broadinstitute/gatk/pull/5589#issuecomment-455598752:1571,Availability,down,downsampling,1571,==; Files 1928 1928 ; Lines 145320 145320 ; Branches 16089 16089 ; ===============================================; - Hits 126498 61049 -65449 ; - Misses 12961 79174 +66213 ; + Partials 5861 5097 -764; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5589?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...ls/variant/writers/GVCFBlockCombiningIterator.java](https://codecov.io/gh/broadinstitute/gatk/pull/5589/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L3dyaXRlcnMvR1ZDRkJsb2NrQ29tYmluaW5nSXRlcmF0b3IuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-1%)` | |; | [...ls/walkers/genotyper/HeterogeneousPloidyModel.java](https://codecov.io/gh/broadinstitute/gatk/pull/5589/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9IZXRlcm9nZW5lb3VzUGxvaWR5TW9kZWwuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-14%)` | |; | [...nder/utils/downsampling/FractionalDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/5589/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvRnJhY3Rpb25hbERvd25zYW1wbGVyLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-17%)` | |; | [...park/pathseq/MarkedOpticalDuplicateReadFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5589/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL01hcmtlZE9wdGljYWxEdXBsaWNhdGVSZWFkRmlsdGVyLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-4%)` | |; | [...otypecaller/RandomLikelihoodCalculationEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/5589/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9SYW5kb21MaWtlbGlob29kQ2FsY3VsYXRpb25FbmdpbmUuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-6%)` | |; | [...r/utils/solver/UnivariateSolverSpecifications.java](https://codecov.io/gh/,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5589#issuecomment-455598752
https://github.com/broadinstitute/gatk/pull/5589#issuecomment-478585734:123,Deployability,update,updates,123,"@tlangs Sorry for the delay in getting to this one. Any chance you can rebase on top of the latest WDL? I had to make some updates in the interim. I haven't seen a lot of this new WDL syntax, but it looks nice. Do you know offhand which versions of cromwell support it?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5589#issuecomment-478585734
https://github.com/broadinstitute/gatk/issues/5590#issuecomment-456627228:118,Testability,benchmark,benchmark,118,"Yes,So if I want to use the model I trained on another machine, should I train it again?; I have one more question, I benchmark hg002 vcf using default model and model I trained(use hg002 truth vcf and bed[HG002_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-22_v.3.3.2_highconf_triophased.vcf.gz]), but default model gets better recall and precision. I want to know what the default model is trainning from. Can I use this model to vqsr all vcf files?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5590#issuecomment-456627228
https://github.com/broadinstitute/gatk/pull/5594#issuecomment-456554758:1264,Availability,down,downsampling,1264,?src=pr&el=desc) will **decrease** coverage by `80.096%`.; > The diff coverage is `0%`. ```diff; @@ Coverage Diff @@; ## master #5594 +/- ##; ===============================================; - Coverage 87.046% 6.951% -80.096% ; + Complexity 31524 2797 -28727 ; ===============================================; Files 1928 1934 +6 ; Lines 145340 145727 +387 ; Branches 16089 16104 +15 ; ===============================================; - Hits 126513 10129 -116384 ; - Misses 12966 134867 +121901 ; + Partials 5861 731 -5130; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5594?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...der/tools/HaplotypeCallerSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5594/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9IYXBsb3R5cGVDYWxsZXJTcGFya0ludGVncmF0aW9uVGVzdC5qYXZh) | `2.439% <ø> (-65.854%)` | `2 <0> (-14)` | |; | [...ender/utils/downsampling/ReservoirDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/5594/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvUmVzZXJ2b2lyRG93bnNhbXBsZXIuamF2YQ==) | `0% <0%> (-100%)` | `0 <0> (-21)` | |; | [...llbender/utils/downsampling/MutectDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/5594/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvTXV0ZWN0RG93bnNhbXBsZXIuamF2YQ==) | `0% <0%> (-68.182%)` | `0 <0> (-17)` | |; | [...ownsampling/ReadsDownsamplingIteratorUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5594/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvUmVhZHNEb3duc2FtcGxpbmdJdGVyYXRvclVuaXRUZXN0LmphdmE=) | `1.639% <0%> (-64.361%)` | `1 <0> (-7)` | |; | [...ils/downsampling/ReservoirDownsamplerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5594/diff,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5594#issuecomment-456554758
https://github.com/broadinstitute/gatk/pull/5594#issuecomment-456554758:1565,Availability,down,downsampling,1565,==========; Files 1928 1934 +6 ; Lines 145340 145727 +387 ; Branches 16089 16104 +15 ; ===============================================; - Hits 126513 10129 -116384 ; - Misses 12966 134867 +121901 ; + Partials 5861 731 -5130; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5594?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...der/tools/HaplotypeCallerSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5594/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9IYXBsb3R5cGVDYWxsZXJTcGFya0ludGVncmF0aW9uVGVzdC5qYXZh) | `2.439% <ø> (-65.854%)` | `2 <0> (-14)` | |; | [...ender/utils/downsampling/ReservoirDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/5594/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvUmVzZXJ2b2lyRG93bnNhbXBsZXIuamF2YQ==) | `0% <0%> (-100%)` | `0 <0> (-21)` | |; | [...llbender/utils/downsampling/MutectDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/5594/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvTXV0ZWN0RG93bnNhbXBsZXIuamF2YQ==) | `0% <0%> (-68.182%)` | `0 <0> (-17)` | |; | [...ownsampling/ReadsDownsamplingIteratorUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5594/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvUmVhZHNEb3duc2FtcGxpbmdJdGVyYXRvclVuaXRUZXN0LmphdmE=) | `1.639% <0%> (-64.361%)` | `1 <0> (-7)` | |; | [...ils/downsampling/ReservoirDownsamplerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5594/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvUmVzZXJ2b2lyRG93bnNhbXBsZXJVbml0VGVzdC5qYXZh) | `1.449% <0%> (-75.6%)` | `1 <0> (-9)` | |; | [...nder/utils/downsampling/PositionalDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pu,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5594#issuecomment-456554758
https://github.com/broadinstitute/gatk/pull/5594#issuecomment-456554758:2171,Availability,down,downsampling,2171,C5qYXZh) | `2.439% <ø> (-65.854%)` | `2 <0> (-14)` | |; | [...ender/utils/downsampling/ReservoirDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/5594/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvUmVzZXJ2b2lyRG93bnNhbXBsZXIuamF2YQ==) | `0% <0%> (-100%)` | `0 <0> (-21)` | |; | [...llbender/utils/downsampling/MutectDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/5594/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvTXV0ZWN0RG93bnNhbXBsZXIuamF2YQ==) | `0% <0%> (-68.182%)` | `0 <0> (-17)` | |; | [...ownsampling/ReadsDownsamplingIteratorUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5594/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvUmVhZHNEb3duc2FtcGxpbmdJdGVyYXRvclVuaXRUZXN0LmphdmE=) | `1.639% <0%> (-64.361%)` | `1 <0> (-7)` | |; | [...ils/downsampling/ReservoirDownsamplerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5594/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvUmVzZXJ2b2lyRG93bnNhbXBsZXJVbml0VGVzdC5qYXZh) | `1.449% <0%> (-75.6%)` | `1 <0> (-9)` | |; | [...nder/utils/downsampling/PositionalDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/5594/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvUG9zaXRpb25hbERvd25zYW1wbGVyLmphdmE=) | `0% <0%> (-100%)` | `0 <0> (-21)` | |; | [...ls/variant/writers/GVCFBlockCombiningIterator.java](https://codecov.io/gh/broadinstitute/gatk/pull/5594/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L3dyaXRlcnMvR1ZDRkJsb2NrQ29tYmluaW5nSXRlcmF0b3IuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-1%)` | |; | [...ark/AssemblyRegionReadShardArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/5594,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5594#issuecomment-456554758
https://github.com/broadinstitute/gatk/pull/5594#issuecomment-456554758:2488,Availability,down,downsampling,2488,=) | `0% <0%> (-100%)` | `0 <0> (-21)` | |; | [...llbender/utils/downsampling/MutectDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/5594/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvTXV0ZWN0RG93bnNhbXBsZXIuamF2YQ==) | `0% <0%> (-68.182%)` | `0 <0> (-17)` | |; | [...ownsampling/ReadsDownsamplingIteratorUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5594/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvUmVhZHNEb3duc2FtcGxpbmdJdGVyYXRvclVuaXRUZXN0LmphdmE=) | `1.639% <0%> (-64.361%)` | `1 <0> (-7)` | |; | [...ils/downsampling/ReservoirDownsamplerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5594/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvUmVzZXJ2b2lyRG93bnNhbXBsZXJVbml0VGVzdC5qYXZh) | `1.449% <0%> (-75.6%)` | `1 <0> (-9)` | |; | [...nder/utils/downsampling/PositionalDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/5594/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvUG9zaXRpb25hbERvd25zYW1wbGVyLmphdmE=) | `0% <0%> (-100%)` | `0 <0> (-21)` | |; | [...ls/variant/writers/GVCFBlockCombiningIterator.java](https://codecov.io/gh/broadinstitute/gatk/pull/5594/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L3dyaXRlcnMvR1ZDRkJsb2NrQ29tYmluaW5nSXRlcmF0b3IuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-1%)` | |; | [...ark/AssemblyRegionReadShardArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/5594/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvQXNzZW1ibHlSZWdpb25SZWFkU2hhcmRBcmd1bWVudENvbGxlY3Rpb24uamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-1%)` | |; | [...nder/tools/copynumber/utils/TagGermlineEvents.java](https://codecov.io/gh/broadinstitute/gatk,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5594#issuecomment-456554758
https://github.com/broadinstitute/gatk/pull/5594#issuecomment-456900212:42,Deployability,integrat,integration,42,"I'm surprised none of the variant calling integration tests change. @cmnbroad Would you expect this to change the behavior in any common use cases or is this more of a safety check?. It's admittedly also possible that the MT calling in the Mutect2 integration test does change slightly, but that's a very lenient concordance check.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5594#issuecomment-456900212
https://github.com/broadinstitute/gatk/pull/5594#issuecomment-456900212:248,Deployability,integrat,integration,248,"I'm surprised none of the variant calling integration tests change. @cmnbroad Would you expect this to change the behavior in any common use cases or is this more of a safety check?. It's admittedly also possible that the MT calling in the Mutect2 integration test does change slightly, but that's a very lenient concordance check.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5594#issuecomment-456900212
https://github.com/broadinstitute/gatk/pull/5594#issuecomment-456900212:42,Integrability,integrat,integration,42,"I'm surprised none of the variant calling integration tests change. @cmnbroad Would you expect this to change the behavior in any common use cases or is this more of a safety check?. It's admittedly also possible that the MT calling in the Mutect2 integration test does change slightly, but that's a very lenient concordance check.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5594#issuecomment-456900212
https://github.com/broadinstitute/gatk/pull/5594#issuecomment-456900212:248,Integrability,integrat,integration,248,"I'm surprised none of the variant calling integration tests change. @cmnbroad Would you expect this to change the behavior in any common use cases or is this more of a safety check?. It's admittedly also possible that the MT calling in the Mutect2 integration test does change slightly, but that's a very lenient concordance check.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5594#issuecomment-456900212
https://github.com/broadinstitute/gatk/pull/5594#issuecomment-456900212:168,Safety,safe,safety,168,"I'm surprised none of the variant calling integration tests change. @cmnbroad Would you expect this to change the behavior in any common use cases or is this more of a safety check?. It's admittedly also possible that the MT calling in the Mutect2 integration test does change slightly, but that's a very lenient concordance check.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5594#issuecomment-456900212
https://github.com/broadinstitute/gatk/pull/5594#issuecomment-456900212:54,Testability,test,tests,54,"I'm surprised none of the variant calling integration tests change. @cmnbroad Would you expect this to change the behavior in any common use cases or is this more of a safety check?. It's admittedly also possible that the MT calling in the Mutect2 integration test does change slightly, but that's a very lenient concordance check.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5594#issuecomment-456900212
https://github.com/broadinstitute/gatk/pull/5594#issuecomment-456900212:260,Testability,test,test,260,"I'm surprised none of the variant calling integration tests change. @cmnbroad Would you expect this to change the behavior in any common use cases or is this more of a safety check?. It's admittedly also possible that the MT calling in the Mutect2 integration test does change slightly, but that's a very lenient concordance check.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5594#issuecomment-456900212
https://github.com/broadinstitute/gatk/pull/5594#issuecomment-456930026:362,Availability,mask,masks,362,"@ldgauthier Yeah, I was surprised too. The problematic pattern is interleaving `submit` and `has/consumeFinalizedItems` calls on a `ReservoirDownsampler`. `ReadsDownsamplingIterator` uses that pattern that, but I don't see any existing code that uses it with a `ReservoirDownsampler`. Interestingly, `PositionalDownsampler`, which uses a `ReservoirDownsampler`, masks the reservoir problem even when its used with `ReadsDownsamplingIterator by providing its own positional-based finalization semantics, and never consuming finalized items from the reservoir until it sees a position change. The Mutect code also doesn't interleave calls, so the change there is just to prevent triggering of the new checks I added. `AssemblyRegionWalker` does compose `Downsampler`s with a `ReadsDownsamplingIterator`, but AFACIT not directly with a `ReservoirDownsampler`.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5594#issuecomment-456930026
https://github.com/broadinstitute/gatk/pull/5594#issuecomment-456930026:752,Availability,Down,Downsampler,752,"@ldgauthier Yeah, I was surprised too. The problematic pattern is interleaving `submit` and `has/consumeFinalizedItems` calls on a `ReservoirDownsampler`. `ReadsDownsamplingIterator` uses that pattern that, but I don't see any existing code that uses it with a `ReservoirDownsampler`. Interestingly, `PositionalDownsampler`, which uses a `ReservoirDownsampler`, masks the reservoir problem even when its used with `ReadsDownsamplingIterator by providing its own positional-based finalization semantics, and never consuming finalized items from the reservoir until it sees a position change. The Mutect code also doesn't interleave calls, so the change there is just to prevent triggering of the new checks I added. `AssemblyRegionWalker` does compose `Downsampler`s with a `ReadsDownsamplingIterator`, but AFACIT not directly with a `ReservoirDownsampler`.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5594#issuecomment-456930026
https://github.com/broadinstitute/gatk/pull/5594#issuecomment-456980817:91,Availability,down,downsampling,91,"Not surprised that tests didn't change -- we only use the `PositionalDownsampler` inside a downsampling iterator for HC/M2, never a `ReservoirDownsampler` directly. I believe that the CNN tool is the first case where we wanted to use a `ReservoirDownsampler` directly inside an iterator, and ran into this bug.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5594#issuecomment-456980817
https://github.com/broadinstitute/gatk/pull/5594#issuecomment-456980817:19,Testability,test,tests,19,"Not surprised that tests didn't change -- we only use the `PositionalDownsampler` inside a downsampling iterator for HC/M2, never a `ReservoirDownsampler` directly. I believe that the CNN tool is the first case where we wanted to use a `ReservoirDownsampler` directly inside an iterator, and ran into this bug.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5594#issuecomment-456980817
https://github.com/broadinstitute/gatk/pull/5594#issuecomment-457641779:90,Deployability,update,updated,90,@cmnbroad Back to you -- `ReservoirDownsampler.consumeFinalizedItems()` still needs to be updated to return an empty list with no side effects when there are no finalized items.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5594#issuecomment-457641779
https://github.com/broadinstitute/gatk/pull/5594#issuecomment-457759988:217,Security,validat,validate,217,"Back to @droazen. Also in the last round, I didn't actually add the code in PositionalDownSampler to reject `submit` after `signalEndOfInput` was called (I added the state to keep track of it, but left out the actual validate call in submit). Letting tests run then, back to you.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5594#issuecomment-457759988
https://github.com/broadinstitute/gatk/pull/5594#issuecomment-457759988:251,Testability,test,tests,251,"Back to @droazen. Also in the last round, I didn't actually add the code in PositionalDownSampler to reject `submit` after `signalEndOfInput` was called (I added the state to keep track of it, but left out the actual validate call in submit). Letting tests run then, back to you.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5594#issuecomment-457759988
https://github.com/broadinstitute/gatk/pull/5594#issuecomment-457870723:556,Security,validat,validation,556,"Well, when the `clearItems` call is removed from the `consumeFinalizeItems` else branch, some `HaplotypeCallerSparkIntegrationTest`s [fail](https://api.travis-ci.com/v3/job/173147001/log.txt) because `PushToPullIterator` doesn't call clearItems to reset the state when `consumeFinalizeItems` returns no items, and the next submit is rejected because eoi hasn't been reset. So, since `consumeFinalizeItems` can't reset/mutate the state when there are no items, then we can't assert the precondition that `endOfInput==false` in `submit`. So I'm removing the validation of that from both `ReservoirDownsampler` and `PositionalDownsampler`.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5594#issuecomment-457870723
https://github.com/broadinstitute/gatk/pull/5594#issuecomment-457870723:183,Testability,log,log,183,"Well, when the `clearItems` call is removed from the `consumeFinalizeItems` else branch, some `HaplotypeCallerSparkIntegrationTest`s [fail](https://api.travis-ci.com/v3/job/173147001/log.txt) because `PushToPullIterator` doesn't call clearItems to reset the state when `consumeFinalizeItems` returns no items, and the next submit is rejected because eoi hasn't been reset. So, since `consumeFinalizeItems` can't reset/mutate the state when there are no items, then we can't assert the precondition that `endOfInput==false` in `submit`. So I'm removing the validation of that from both `ReservoirDownsampler` and `PositionalDownsampler`.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5594#issuecomment-457870723
https://github.com/broadinstitute/gatk/pull/5594#issuecomment-457870723:474,Testability,assert,assert,474,"Well, when the `clearItems` call is removed from the `consumeFinalizeItems` else branch, some `HaplotypeCallerSparkIntegrationTest`s [fail](https://api.travis-ci.com/v3/job/173147001/log.txt) because `PushToPullIterator` doesn't call clearItems to reset the state when `consumeFinalizeItems` returns no items, and the next submit is rejected because eoi hasn't been reset. So, since `consumeFinalizeItems` can't reset/mutate the state when there are no items, then we can't assert the precondition that `endOfInput==false` in `submit`. So I'm removing the validation of that from both `ReservoirDownsampler` and `PositionalDownsampler`.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5594#issuecomment-457870723
https://github.com/broadinstitute/gatk/pull/5594#issuecomment-457870723:16,Usability,clear,clearItems,16,"Well, when the `clearItems` call is removed from the `consumeFinalizeItems` else branch, some `HaplotypeCallerSparkIntegrationTest`s [fail](https://api.travis-ci.com/v3/job/173147001/log.txt) because `PushToPullIterator` doesn't call clearItems to reset the state when `consumeFinalizeItems` returns no items, and the next submit is rejected because eoi hasn't been reset. So, since `consumeFinalizeItems` can't reset/mutate the state when there are no items, then we can't assert the precondition that `endOfInput==false` in `submit`. So I'm removing the validation of that from both `ReservoirDownsampler` and `PositionalDownsampler`.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5594#issuecomment-457870723
https://github.com/broadinstitute/gatk/pull/5594#issuecomment-457870723:234,Usability,clear,clearItems,234,"Well, when the `clearItems` call is removed from the `consumeFinalizeItems` else branch, some `HaplotypeCallerSparkIntegrationTest`s [fail](https://api.travis-ci.com/v3/job/173147001/log.txt) because `PushToPullIterator` doesn't call clearItems to reset the state when `consumeFinalizeItems` returns no items, and the next submit is rejected because eoi hasn't been reset. So, since `consumeFinalizeItems` can't reset/mutate the state when there are no items, then we can't assert the precondition that `endOfInput==false` in `submit`. So I'm removing the validation of that from both `ReservoirDownsampler` and `PositionalDownsampler`.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5594#issuecomment-457870723
https://github.com/broadinstitute/gatk/pull/5594#issuecomment-458679171:496,Availability,down,downsampling,496,"@cmnbroad I've implemented a compromise approach in `ReservoirDownsampler.consumeFinalizedItems()` that I think satisfies both of our concerns:. * If `consumeFinalizedItems()` is called after end of input has been signaled, it always clears state (including the end of input flag itself), regardless of whether there are any finalized items; * If `consumeFinalizedItems()` is called before end of input has been signaled, it returns an empty List and does not clear state, since in that case the downsampling process is still ongoing and we want to preserve pending items. I've also added tests to verify this new behavior. Let me know what you think.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5594#issuecomment-458679171
https://github.com/broadinstitute/gatk/pull/5594#issuecomment-458679171:589,Testability,test,tests,589,"@cmnbroad I've implemented a compromise approach in `ReservoirDownsampler.consumeFinalizedItems()` that I think satisfies both of our concerns:. * If `consumeFinalizedItems()` is called after end of input has been signaled, it always clears state (including the end of input flag itself), regardless of whether there are any finalized items; * If `consumeFinalizedItems()` is called before end of input has been signaled, it returns an empty List and does not clear state, since in that case the downsampling process is still ongoing and we want to preserve pending items. I've also added tests to verify this new behavior. Let me know what you think.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5594#issuecomment-458679171
https://github.com/broadinstitute/gatk/pull/5594#issuecomment-458679171:234,Usability,clear,clears,234,"@cmnbroad I've implemented a compromise approach in `ReservoirDownsampler.consumeFinalizedItems()` that I think satisfies both of our concerns:. * If `consumeFinalizedItems()` is called after end of input has been signaled, it always clears state (including the end of input flag itself), regardless of whether there are any finalized items; * If `consumeFinalizedItems()` is called before end of input has been signaled, it returns an empty List and does not clear state, since in that case the downsampling process is still ongoing and we want to preserve pending items. I've also added tests to verify this new behavior. Let me know what you think.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5594#issuecomment-458679171
https://github.com/broadinstitute/gatk/pull/5594#issuecomment-458679171:460,Usability,clear,clear,460,"@cmnbroad I've implemented a compromise approach in `ReservoirDownsampler.consumeFinalizedItems()` that I think satisfies both of our concerns:. * If `consumeFinalizedItems()` is called after end of input has been signaled, it always clears state (including the end of input flag itself), regardless of whether there are any finalized items; * If `consumeFinalizedItems()` is called before end of input has been signaled, it returns an empty List and does not clear state, since in that case the downsampling process is still ongoing and we want to preserve pending items. I've also added tests to verify this new behavior. Let me know what you think.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5594#issuecomment-458679171
https://github.com/broadinstitute/gatk/pull/5594#issuecomment-458698474:22,Testability,test,tests,22,I'll merge as soon as tests pass (ETA ~25 minutes).,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5594#issuecomment-458698474
https://github.com/broadinstitute/gatk/pull/5595#issuecomment-456911203:30,Availability,Error,Error,30,"These are failing with:. ```; Error: (converted from warning) unable to access index for repository http://lib.stat.cmu.edu/R/CRAN/src/contrib; Execution halted; The command ""if [[ $TEST_DOCKER != true ]]; then sudo mkdir -p /usr/local/lib/R/; sudo mkdir -p site-library; sudo ln -sFv ~/site-library /usr/local/lib/R/site-library; sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys E298A3A825C0D65DFD57CBB651716619E084DAB9; sudo add-apt-repository ""deb http://cran.rstudio.com/bin/linux/ubuntu trusty/""; sudo apt-get update; sudo apt-get install -y --force-yes r-base-dev=3.1.3-1trusty; sudo apt-get install -y --force-yes r-base-core=3.1.3-1trusty; sudo Rscript scripts/docker/gatkbase/install_R_packages.R; fi;"" failed and exited with 1 during; ```; which has nothing to do with the PR.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5595#issuecomment-456911203
https://github.com/broadinstitute/gatk/pull/5595#issuecomment-456911203:528,Deployability,update,update,528,"These are failing with:. ```; Error: (converted from warning) unable to access index for repository http://lib.stat.cmu.edu/R/CRAN/src/contrib; Execution halted; The command ""if [[ $TEST_DOCKER != true ]]; then sudo mkdir -p /usr/local/lib/R/; sudo mkdir -p site-library; sudo ln -sFv ~/site-library /usr/local/lib/R/site-library; sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys E298A3A825C0D65DFD57CBB651716619E084DAB9; sudo add-apt-repository ""deb http://cran.rstudio.com/bin/linux/ubuntu trusty/""; sudo apt-get update; sudo apt-get install -y --force-yes r-base-dev=3.1.3-1trusty; sudo apt-get install -y --force-yes r-base-core=3.1.3-1trusty; sudo Rscript scripts/docker/gatkbase/install_R_packages.R; fi;"" failed and exited with 1 during; ```; which has nothing to do with the PR.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5595#issuecomment-456911203
https://github.com/broadinstitute/gatk/pull/5595#issuecomment-456911203:549,Deployability,install,install,549,"These are failing with:. ```; Error: (converted from warning) unable to access index for repository http://lib.stat.cmu.edu/R/CRAN/src/contrib; Execution halted; The command ""if [[ $TEST_DOCKER != true ]]; then sudo mkdir -p /usr/local/lib/R/; sudo mkdir -p site-library; sudo ln -sFv ~/site-library /usr/local/lib/R/site-library; sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys E298A3A825C0D65DFD57CBB651716619E084DAB9; sudo add-apt-repository ""deb http://cran.rstudio.com/bin/linux/ubuntu trusty/""; sudo apt-get update; sudo apt-get install -y --force-yes r-base-dev=3.1.3-1trusty; sudo apt-get install -y --force-yes r-base-core=3.1.3-1trusty; sudo Rscript scripts/docker/gatkbase/install_R_packages.R; fi;"" failed and exited with 1 during; ```; which has nothing to do with the PR.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5595#issuecomment-456911203
https://github.com/broadinstitute/gatk/pull/5595#issuecomment-456911203:611,Deployability,install,install,611,"These are failing with:. ```; Error: (converted from warning) unable to access index for repository http://lib.stat.cmu.edu/R/CRAN/src/contrib; Execution halted; The command ""if [[ $TEST_DOCKER != true ]]; then sudo mkdir -p /usr/local/lib/R/; sudo mkdir -p site-library; sudo ln -sFv ~/site-library /usr/local/lib/R/site-library; sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys E298A3A825C0D65DFD57CBB651716619E084DAB9; sudo add-apt-repository ""deb http://cran.rstudio.com/bin/linux/ubuntu trusty/""; sudo apt-get update; sudo apt-get install -y --force-yes r-base-dev=3.1.3-1trusty; sudo apt-get install -y --force-yes r-base-core=3.1.3-1trusty; sudo Rscript scripts/docker/gatkbase/install_R_packages.R; fi;"" failed and exited with 1 during; ```; which has nothing to do with the PR.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5595#issuecomment-456911203
https://github.com/broadinstitute/gatk/pull/5595#issuecomment-456911203:72,Security,access,access,72,"These are failing with:. ```; Error: (converted from warning) unable to access index for repository http://lib.stat.cmu.edu/R/CRAN/src/contrib; Execution halted; The command ""if [[ $TEST_DOCKER != true ]]; then sudo mkdir -p /usr/local/lib/R/; sudo mkdir -p site-library; sudo ln -sFv ~/site-library /usr/local/lib/R/site-library; sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys E298A3A825C0D65DFD57CBB651716619E084DAB9; sudo add-apt-repository ""deb http://cran.rstudio.com/bin/linux/ubuntu trusty/""; sudo apt-get update; sudo apt-get install -y --force-yes r-base-dev=3.1.3-1trusty; sudo apt-get install -y --force-yes r-base-core=3.1.3-1trusty; sudo Rscript scripts/docker/gatkbase/install_R_packages.R; fi;"" failed and exited with 1 during; ```; which has nothing to do with the PR.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5595#issuecomment-456911203
https://github.com/broadinstitute/gatk/pull/5598#issuecomment-456891301:2279,Testability,test,test,2279,/5598?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...dataSources/vcf/VcfFuncotationFactoryUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5598/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL3ZjZi9WY2ZGdW5jb3RhdGlvbkZhY3RvcnlVbml0VGVzdC5qYXZh) | `98.104% <100%> (+0.055%)` | `30 <1> (+1)` | :arrow_up: |; | [...er/tools/funcotator/FuncotatorIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5598/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0Z1bmNvdGF0b3JJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `85.253% <100%> (+0.372%)` | `113 <1> (+1)` | :arrow_up: |; | [...cotator/dataSources/vcf/VcfFuncotationFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/5598/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL3ZjZi9WY2ZGdW5jb3RhdGlvbkZhY3RvcnkuamF2YQ==) | `88.05% <100%> (+0.469%)` | `48 <0> (ø)` | :arrow_down: |; | [...nder/tools/funcotator/FuncotatorTestConstants.java](https://codecov.io/gh/broadinstitute/gatk/pull/5598/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0Z1bmNvdGF0b3JUZXN0Q29uc3RhbnRzLmphdmE=) | `98.333% <100%> (+0.028%)` | `1 <0> (ø)` | :arrow_down: |; | [...ute/hellbender/utils/test/FuncotatorTestUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5598/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Z1bmNvdGF0b3JUZXN0VXRpbHMuamF2YQ==) | `95.161% <66.667%> (-3.084%)` | `7 <1> (+1)` | |; | [...nder/utils/runtime/StreamingProcessController.java](https://codecov.io/gh/broadinstitute/gatk/pull/5598/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9ydW50aW1lL1N0cmVhbWluZ1Byb2Nlc3NDb250cm9sbGVyLmphdmE=) | `67.299% <0%> (-0.474%)` | `33% <0%> (ø)` | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5598#issuecomment-456891301
https://github.com/broadinstitute/gatk/pull/5598#issuecomment-456984341:123,Availability,failure,failures,123,@LeeTL1220 Added in a specific integration test for the `FILTER` field. Also rebased on master to fix the unrelated R test failures.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5598#issuecomment-456984341
https://github.com/broadinstitute/gatk/pull/5598#issuecomment-456984341:31,Deployability,integrat,integration,31,@LeeTL1220 Added in a specific integration test for the `FILTER` field. Also rebased on master to fix the unrelated R test failures.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5598#issuecomment-456984341
https://github.com/broadinstitute/gatk/pull/5598#issuecomment-456984341:31,Integrability,integrat,integration,31,@LeeTL1220 Added in a specific integration test for the `FILTER` field. Also rebased on master to fix the unrelated R test failures.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5598#issuecomment-456984341
https://github.com/broadinstitute/gatk/pull/5598#issuecomment-456984341:43,Testability,test,test,43,@LeeTL1220 Added in a specific integration test for the `FILTER` field. Also rebased on master to fix the unrelated R test failures.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5598#issuecomment-456984341
https://github.com/broadinstitute/gatk/pull/5598#issuecomment-456984341:118,Testability,test,test,118,@LeeTL1220 Added in a specific integration test for the `FILTER` field. Also rebased on master to fix the unrelated R test failures.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5598#issuecomment-456984341
https://github.com/broadinstitute/gatk/pull/5599#issuecomment-456937576:2799,Usability,Learn,LearnReadOrientationModelUnitTest,2799,YXZh) | `75.949% <ø> (ø)` | `29 <0> (-1)` | :arrow_down: |; | [...va/org/broadinstitute/hellbender/GATKBaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5599/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9HQVRLQmFzZVRlc3QuamF2YQ==) | `100% <100%> (ø)` | `7 <0> (ø)` | :arrow_down: |; | [...s/walkers/contamination/GatherPileupSummaries.java](https://codecov.io/gh/broadinstitute/gatk/pull/5599/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2NvbnRhbWluYXRpb24vR2F0aGVyUGlsZXVwU3VtbWFyaWVzLmphdmE=) | `100% <100%> (ø)` | `5 <5> (?)` | |; | [...ientation/ReadOrientationModelIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5599/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3JlYWRvcmllbnRhdGlvbi9SZWFkT3JpZW50YXRpb25Nb2RlbEludGVncmF0aW9uVGVzdC5qYXZh) | `100% <100%> (ø)` | `12 <10> (?)` | |; | [...orientation/LearnReadOrientationModelUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5599/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3JlYWRvcmllbnRhdGlvbi9MZWFyblJlYWRPcmllbnRhdGlvbk1vZGVsVW5pdFRlc3QuamF2YQ==) | `100% <100%> (ø)` | `7 <7> (?)` | |; | [...s/walkers/contamination/PileupSummaryUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5599/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2NvbnRhbWluYXRpb24vUGlsZXVwU3VtbWFyeVVuaXRUZXN0LmphdmE=) | `100% <100%> (ø)` | `6 <5> (+4)` | :arrow_up: |; | [...ation/LearnReadOrientationModelEngineUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5599/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3JlYWRvcmllbnRhdGlvbi9MZWFyblJlYWRPcmllbnRhdGlvbk1vZGVsRW5naW5lVW5pdFRlc3QuamF2YQ==) | `95.745% <100%> (+0.074%)` | `45 <2> (+2)` | :arrow_up: |; | [...ers/readorientati,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5599#issuecomment-456937576
https://github.com/broadinstitute/gatk/pull/5599#issuecomment-456937576:3441,Usability,Learn,LearnReadOrientationModelEngineUnitTest,3441,odecov.io/gh/broadinstitute/gatk/pull/5599/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2NvbnRhbWluYXRpb24vR2F0aGVyUGlsZXVwU3VtbWFyaWVzLmphdmE=) | `100% <100%> (ø)` | `5 <5> (?)` | |; | [...ientation/ReadOrientationModelIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5599/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3JlYWRvcmllbnRhdGlvbi9SZWFkT3JpZW50YXRpb25Nb2RlbEludGVncmF0aW9uVGVzdC5qYXZh) | `100% <100%> (ø)` | `12 <10> (?)` | |; | [...orientation/LearnReadOrientationModelUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5599/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3JlYWRvcmllbnRhdGlvbi9MZWFyblJlYWRPcmllbnRhdGlvbk1vZGVsVW5pdFRlc3QuamF2YQ==) | `100% <100%> (ø)` | `7 <7> (?)` | |; | [...s/walkers/contamination/PileupSummaryUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5599/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2NvbnRhbWluYXRpb24vUGlsZXVwU3VtbWFyeVVuaXRUZXN0LmphdmE=) | `100% <100%> (ø)` | `6 <5> (+4)` | :arrow_up: |; | [...ation/LearnReadOrientationModelEngineUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5599/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3JlYWRvcmllbnRhdGlvbi9MZWFyblJlYWRPcmllbnRhdGlvbk1vZGVsRW5naW5lVW5pdFRlc3QuamF2YQ==) | `95.745% <100%> (+0.074%)` | `45 <2> (+2)` | :arrow_up: |; | [...ers/readorientation/LearnReadOrientationModel.java](https://codecov.io/gh/broadinstitute/gatk/pull/5599/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3JlYWRvcmllbnRhdGlvbi9MZWFyblJlYWRPcmllbnRhdGlvbk1vZGVsLmphdmE=) | `92% <80%> (-4.078%)` | `36 <12> (+6)` | |; | ... and [6 more](https://codecov.io/gh/broadinstitute/gatk/pull/5599/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5599#issuecomment-456937576
https://github.com/broadinstitute/gatk/pull/5599#issuecomment-456937576:3813,Usability,Learn,LearnReadOrientationModel,3813,odecov.io/gh/broadinstitute/gatk/pull/5599/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2NvbnRhbWluYXRpb24vR2F0aGVyUGlsZXVwU3VtbWFyaWVzLmphdmE=) | `100% <100%> (ø)` | `5 <5> (?)` | |; | [...ientation/ReadOrientationModelIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5599/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3JlYWRvcmllbnRhdGlvbi9SZWFkT3JpZW50YXRpb25Nb2RlbEludGVncmF0aW9uVGVzdC5qYXZh) | `100% <100%> (ø)` | `12 <10> (?)` | |; | [...orientation/LearnReadOrientationModelUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5599/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3JlYWRvcmllbnRhdGlvbi9MZWFyblJlYWRPcmllbnRhdGlvbk1vZGVsVW5pdFRlc3QuamF2YQ==) | `100% <100%> (ø)` | `7 <7> (?)` | |; | [...s/walkers/contamination/PileupSummaryUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5599/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2NvbnRhbWluYXRpb24vUGlsZXVwU3VtbWFyeVVuaXRUZXN0LmphdmE=) | `100% <100%> (ø)` | `6 <5> (+4)` | :arrow_up: |; | [...ation/LearnReadOrientationModelEngineUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5599/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3JlYWRvcmllbnRhdGlvbi9MZWFyblJlYWRPcmllbnRhdGlvbk1vZGVsRW5naW5lVW5pdFRlc3QuamF2YQ==) | `95.745% <100%> (+0.074%)` | `45 <2> (+2)` | :arrow_up: |; | [...ers/readorientation/LearnReadOrientationModel.java](https://codecov.io/gh/broadinstitute/gatk/pull/5599/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3JlYWRvcmllbnRhdGlvbi9MZWFyblJlYWRPcmllbnRhdGlvbk1vZGVsLmphdmE=) | `92% <80%> (-4.078%)` | `36 <12> (+6)` | |; | ... and [6 more](https://codecov.io/gh/broadinstitute/gatk/pull/5599/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5599#issuecomment-456937576
https://github.com/broadinstitute/gatk/pull/5599#issuecomment-459482539:134,Deployability,update,updated,134,"@davidbenjamin `LearnReadOrientationModel` now takes in lists of inputs, which allows for parallelization of `CollectF1R2Counts.` The updated wdl includes this change. I also moved `GetPileupSumamries` to the M2 task, as discussed offline. All the new changes are in the third commit, ""update the wdl, prallelize...""",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5599#issuecomment-459482539
https://github.com/broadinstitute/gatk/pull/5599#issuecomment-459482539:286,Deployability,update,update,286,"@davidbenjamin `LearnReadOrientationModel` now takes in lists of inputs, which allows for parallelization of `CollectF1R2Counts.` The updated wdl includes this change. I also moved `GetPileupSumamries` to the M2 task, as discussed offline. All the new changes are in the third commit, ""update the wdl, prallelize...""",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5599#issuecomment-459482539
https://github.com/broadinstitute/gatk/pull/5599#issuecomment-459482539:16,Usability,Learn,LearnReadOrientationModel,16,"@davidbenjamin `LearnReadOrientationModel` now takes in lists of inputs, which allows for parallelization of `CollectF1R2Counts.` The updated wdl includes this change. I also moved `GetPileupSumamries` to the M2 task, as discussed offline. All the new changes are in the third commit, ""update the wdl, prallelize...""",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5599#issuecomment-459482539
https://github.com/broadinstitute/gatk/pull/5599#issuecomment-474900012:44,Deployability,update,updated,44,"@davidbenjamin at long last, back to you. I updated the nio wdl too, and it passes the Firecloud M2 wdl validation with the HCC sample, but not with the cram. But that's because that cram file is aligned to hg38, whereas the workspace uses hg19. I didn't touch anything related to the CramToBam task in the nio wdl so I think we're OK.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5599#issuecomment-474900012
https://github.com/broadinstitute/gatk/pull/5599#issuecomment-474900012:104,Security,validat,validation,104,"@davidbenjamin at long last, back to you. I updated the nio wdl too, and it passes the Firecloud M2 wdl validation with the HCC sample, but not with the cram. But that's because that cram file is aligned to hg38, whereas the workspace uses hg19. I didn't touch anything related to the CramToBam task in the nio wdl so I think we're OK.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5599#issuecomment-474900012
https://github.com/broadinstitute/gatk/pull/5601#issuecomment-456978262:158,Testability,log,logger,158,Thank you at @ldgauthier for volunteering to review and for all of the feedback. The Travis checks are still in progress but the only code change is with the logger type.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5601#issuecomment-456978262
https://github.com/broadinstitute/gatk/pull/5601#issuecomment-456978262:71,Usability,feedback,feedback,71,Thank you at @ldgauthier for volunteering to review and for all of the feedback. The Travis checks are still in progress but the only code change is with the logger type.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5601#issuecomment-456978262
https://github.com/broadinstitute/gatk/pull/5601#issuecomment-456985343:1939,Availability,down,downsampling,1939,utils/CalculateGenotypePosteriors.java](https://codecov.io/gh/broadinstitute/gatk/pull/5601/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9DYWxjdWxhdGVHZW5vdHlwZVBvc3RlcmlvcnMuamF2YQ==) | `92.857% <100%> (ø)` | `17 <0> (ø)` | :arrow_down: |; | [...walkers/genotyper/afcalc/AFCalculatorProvider.java](https://codecov.io/gh/broadinstitute/gatk/pull/5601/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9hZmNhbGMvQUZDYWxjdWxhdG9yUHJvdmlkZXIuamF2YQ==) | `22.222% <0%> (-44.444%)` | `2% <0%> (-2%)` | |; | [...notyper/afcalc/ConcurrentAFCalculatorProvider.java](https://codecov.io/gh/broadinstitute/gatk/pull/5601/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9hZmNhbGMvQ29uY3VycmVudEFGQ2FsY3VsYXRvclByb3ZpZGVyLmphdmE=) | `50% <0%> (-33.333%)` | `1% <0%> (-1%)` | |; | [...nder/utils/downsampling/PositionalDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/5601/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvUG9zaXRpb25hbERvd25zYW1wbGVyLmphdmE=) | `88.462% <0%> (-11.538%)` | `22% <0%> (+1%)` | |; | [...er/engine/spark/datasources/VariantsSparkSink.java](https://codecov.io/gh/broadinstitute/gatk/pull/5601/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvVmFyaWFudHNTcGFya1NpbmsuamF2YQ==) | `78.125% <0%> (-11.53%)` | `8% <0%> (-1%)` | |; | [...broadinstitute/hellbender/engine/FeatureInput.java](https://codecov.io/gh/broadinstitute/gatk/pull/5601/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvRmVhdHVyZUlucHV0LmphdmE=) | `88.235% <0%> (-4.82%)` | `19% <0%> (+1%)` | |; | [...r/tools/walkers/mutect/Mutect2FilteringEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/5601/diff?src=pr&el=tree#,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5601#issuecomment-456985343
https://github.com/broadinstitute/gatk/pull/5601#issuecomment-456985343:1611,Performance,Concurren,ConcurrentAFCalculatorProvider,1611,45816 +473 ; Branches 16090 16107 +17 ; ===============================================; + Hits 126517 126891 +374 ; - Misses 12966 13048 +82 ; - Partials 5860 5877 +17; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5601?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...kers/variantutils/CalculateGenotypePosteriors.java](https://codecov.io/gh/broadinstitute/gatk/pull/5601/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9DYWxjdWxhdGVHZW5vdHlwZVBvc3RlcmlvcnMuamF2YQ==) | `92.857% <100%> (ø)` | `17 <0> (ø)` | :arrow_down: |; | [...walkers/genotyper/afcalc/AFCalculatorProvider.java](https://codecov.io/gh/broadinstitute/gatk/pull/5601/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9hZmNhbGMvQUZDYWxjdWxhdG9yUHJvdmlkZXIuamF2YQ==) | `22.222% <0%> (-44.444%)` | `2% <0%> (-2%)` | |; | [...notyper/afcalc/ConcurrentAFCalculatorProvider.java](https://codecov.io/gh/broadinstitute/gatk/pull/5601/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9hZmNhbGMvQ29uY3VycmVudEFGQ2FsY3VsYXRvclByb3ZpZGVyLmphdmE=) | `50% <0%> (-33.333%)` | `1% <0%> (-1%)` | |; | [...nder/utils/downsampling/PositionalDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/5601/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvUG9zaXRpb25hbERvd25zYW1wbGVyLmphdmE=) | `88.462% <0%> (-11.538%)` | `22% <0%> (+1%)` | |; | [...er/engine/spark/datasources/VariantsSparkSink.java](https://codecov.io/gh/broadinstitute/gatk/pull/5601/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvVmFyaWFudHNTcGFya1NpbmsuamF2YQ==) | `78.125% <0%> (-11.53%)` | `8% <0%> (-1%)` | |; | [...broadinstitute/hellbender/engine/FeatureInput.java](https://codecov.io/,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5601#issuecomment-456985343
https://github.com/broadinstitute/gatk/pull/5601#issuecomment-456985343:3484,Testability,test,test,3484,E=) | `88.462% <0%> (-11.538%)` | `22% <0%> (+1%)` | |; | [...er/engine/spark/datasources/VariantsSparkSink.java](https://codecov.io/gh/broadinstitute/gatk/pull/5601/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvVmFyaWFudHNTcGFya1NpbmsuamF2YQ==) | `78.125% <0%> (-11.53%)` | `8% <0%> (-1%)` | |; | [...broadinstitute/hellbender/engine/FeatureInput.java](https://codecov.io/gh/broadinstitute/gatk/pull/5601/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvRmVhdHVyZUlucHV0LmphdmE=) | `88.235% <0%> (-4.82%)` | `19% <0%> (+1%)` | |; | [...r/tools/walkers/mutect/Mutect2FilteringEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/5601/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9NdXRlY3QyRmlsdGVyaW5nRW5naW5lLmphdmE=) | `80.743% <0%> (-4.581%)` | `89% <0%> (ø)` | |; | [...rs/genotyper/afcalc/FixedAFCalculatorProvider.java](https://codecov.io/gh/broadinstitute/gatk/pull/5601/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9hZmNhbGMvRml4ZWRBRkNhbGN1bGF0b3JQcm92aWRlci5qYXZh) | `88.889% <0%> (-3.704%)` | `12% <0%> (ø)` | |; | [...ute/hellbender/utils/test/FuncotatorTestUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5601/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXN0L0Z1bmNvdGF0b3JUZXN0VXRpbHMuamF2YQ==) | `95.161% <0%> (-3.084%)` | `7% <0%> (+1%)` | |; | [...GATKPlugin/GATKReadFilterPluginDescriptorTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5601/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vR0FUS1JlYWRGaWx0ZXJQbHVnaW5EZXNjcmlwdG9yVGVzdC5qYXZh) | `88.62% <0%> (-1.76%)` | `48% <0%> (+1%)` | |; | ... and [64 more](https://codecov.io/gh/broadinstitute/gatk/pull/5601/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5601#issuecomment-456985343
https://github.com/broadinstitute/gatk/pull/5601#issuecomment-457241853:0,Testability,Test,Testing,0,Testing with the branch gives the expected WARN.; ```; 10:36:48.710 WARN CalculateGenotypePosteriors - No PED file passed or no *non-skipped* trios found in PED file. Skipping family priors.; ```. The WARN is in the middle of the INFO fields and not separate at the bottom of the stdout:; ![screenshot 2019-01-24 10 37 19](https://user-images.githubusercontent.com/11543866/51689144-10f42e80-1fc4-11e9-8813-e809a9fb8e63.png),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5601#issuecomment-457241853
https://github.com/broadinstitute/gatk/pull/5601#issuecomment-458725009:23,Usability,feedback,feedback,23,I've incorporated your feedback @ldgauthier.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5601#issuecomment-458725009
https://github.com/broadinstitute/gatk/pull/5601#issuecomment-459140569:39,Usability,feedback,feedback,39,No worries Laura. Thanks again for the feedback.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5601#issuecomment-459140569
https://github.com/broadinstitute/gatk/pull/5602#issuecomment-457246150:30,Availability,error,errors,30,@cmnbroad You're still seeing errors after rebasing? Bleh,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5602#issuecomment-457246150
https://github.com/broadinstitute/gatk/pull/5602#issuecomment-457246918:31,Availability,error,errors,31,"I'm worried about relaxing the errors to warnings. We previously had a similar round of issues where installation was failing and producing a warning but no error and we ended up with corrupt docker images. So we added code to convert warnings to errors. What we need is to not throw a warning when a remote is unavailable if the other remotes are available, which seems like the behavior I would expect from specifying multiple remotes...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5602#issuecomment-457246918
https://github.com/broadinstitute/gatk/pull/5602#issuecomment-457246918:157,Availability,error,error,157,"I'm worried about relaxing the errors to warnings. We previously had a similar round of issues where installation was failing and producing a warning but no error and we ended up with corrupt docker images. So we added code to convert warnings to errors. What we need is to not throw a warning when a remote is unavailable if the other remotes are available, which seems like the behavior I would expect from specifying multiple remotes...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5602#issuecomment-457246918
https://github.com/broadinstitute/gatk/pull/5602#issuecomment-457246918:247,Availability,error,errors,247,"I'm worried about relaxing the errors to warnings. We previously had a similar round of issues where installation was failing and producing a warning but no error and we ended up with corrupt docker images. So we added code to convert warnings to errors. What we need is to not throw a warning when a remote is unavailable if the other remotes are available, which seems like the behavior I would expect from specifying multiple remotes...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5602#issuecomment-457246918
https://github.com/broadinstitute/gatk/pull/5602#issuecomment-457246918:348,Availability,avail,available,348,"I'm worried about relaxing the errors to warnings. We previously had a similar round of issues where installation was failing and producing a warning but no error and we ended up with corrupt docker images. So we added code to convert warnings to errors. What we need is to not throw a warning when a remote is unavailable if the other remotes are available, which seems like the behavior I would expect from specifying multiple remotes...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5602#issuecomment-457246918
https://github.com/broadinstitute/gatk/pull/5602#issuecomment-457246918:101,Deployability,install,installation,101,"I'm worried about relaxing the errors to warnings. We previously had a similar round of issues where installation was failing and producing a warning but no error and we ended up with corrupt docker images. So we added code to convert warnings to errors. What we need is to not throw a warning when a remote is unavailable if the other remotes are available, which seems like the behavior I would expect from specifying multiple remotes...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5602#issuecomment-457246918
https://github.com/broadinstitute/gatk/pull/5607#issuecomment-457738122:959,Testability,test,testutils,959,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5607?src=pr&el=h1) Report; > Merging [#5607](https://codecov.io/gh/broadinstitute/gatk/pull/5607?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/b7f90f45458a0c2064f16ede629a356b2737e17f?src=pr&el=desc) will **increase** coverage by `0.015%`.; > The diff coverage is `98.636%`. ```diff; @@ Coverage Diff @@; ## master #5607 +/- ##; ===============================================; + Coverage 87.041% 87.056% +0.015% ; - Complexity 32076 32097 +21 ; ===============================================; Files 1977 1977 ; Lines 147082 147263 +181 ; Branches 16171 16185 +14 ; ===============================================; + Hits 128021 128201 +180 ; + Misses 13157 13156 -1 ; - Partials 5904 5906 +2; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5607?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...dinstitute/hellbender/testutils/ReadTestUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5607/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90ZXN0dXRpbHMvUmVhZFRlc3RVdGlscy5qYXZh) | `95.455% <ø> (ø)` | `5 <0> (ø)` | :arrow_down: |; | [...dinstitute/hellbender/utils/pileup/ReadPileup.java](https://codecov.io/gh/broadinstitute/gatk/pull/5607/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9waWxldXAvUmVhZFBpbGV1cC5qYXZh) | `92.258% <100%> (+0.05%)` | `69 <0> (ø)` | :arrow_down: |; | [...lotypecaller/ReferenceConfidenceModelUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5607/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9SZWZlcmVuY2VDb25maWRlbmNlTW9kZWxVbml0VGVzdC5qYXZh) | `95.701% <100%> (+2.014%)` | `50 <0> (+3)` | :arrow_up: |; | [...roadinstitute/hellbender/utils/read/ReadUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5607/diff?src=pr&el=tree#diff-c3JjL21haW,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5607#issuecomment-457738122
https://github.com/broadinstitute/gatk/pull/5607#issuecomment-457744794:73,Availability,error,error,73,@jamesemery This needs to be rebased I think and it has some compilation error I think.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5607#issuecomment-457744794
https://github.com/broadinstitute/gatk/pull/5607#issuecomment-457753785:46,Testability,test,test,46,@jamesemery Have you tried a 5 minute file to test? If it's as big as it looks it should show up.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5607#issuecomment-457753785
https://github.com/broadinstitute/gatk/pull/5607#issuecomment-458250495:73,Deployability,release,release,73,"After discussing with @jamesemery we decided to wait until after the 4.1 release before merging this one, as it needs careful review/testing.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5607#issuecomment-458250495
https://github.com/broadinstitute/gatk/pull/5607#issuecomment-458250495:133,Testability,test,testing,133,"After discussing with @jamesemery we decided to wait until after the 4.1 release before merging this one, as it needs careful review/testing.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5607#issuecomment-458250495
https://github.com/broadinstitute/gatk/pull/5607#issuecomment-460420772:158,Availability,error,error,158,"@droazen @lbergelson Have just updated this branch with fixes to the mismatches from the old codepath. I have just run it over a 5gb exome bam with it set to error if it ever mismatches the results in the old codepath and it completed successfully. As far as I can tell this is correct now and could use a more close review... . @ldgauthier The last commit on this branch handles an edge-case where the old codepath will prematurely report that a read with a long deletion in its middle may end up being marked as uninformative because read.getLength() will mismatch from the length of the bases realigned, thus resulting in reads with deletions in the beginning being less informative about deletions at their end. I don't know what you think should be done about this issue as it makes the code in this branch more complicated.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5607#issuecomment-460420772
https://github.com/broadinstitute/gatk/pull/5607#issuecomment-460420772:31,Deployability,update,updated,31,"@droazen @lbergelson Have just updated this branch with fixes to the mismatches from the old codepath. I have just run it over a 5gb exome bam with it set to error if it ever mismatches the results in the old codepath and it completed successfully. As far as I can tell this is correct now and could use a more close review... . @ldgauthier The last commit on this branch handles an edge-case where the old codepath will prematurely report that a read with a long deletion in its middle may end up being marked as uninformative because read.getLength() will mismatch from the length of the bases realigned, thus resulting in reads with deletions in the beginning being less informative about deletions at their end. I don't know what you think should be done about this issue as it makes the code in this branch more complicated.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5607#issuecomment-460420772
https://github.com/broadinstitute/gatk/pull/5607#issuecomment-462497782:70,Usability,clear,clearer,70,"@lbergelson Responded to your comments, I think it should be slightly clearer to read/understand now",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5607#issuecomment-462497782
https://github.com/broadinstitute/gatk/pull/5608#issuecomment-458515123:74,Testability,test,tested,74,"> Hopefully, this will mitigate the issues on NFS and CIFS. Has this been tested? @nalinigans",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5608#issuecomment-458515123
https://github.com/broadinstitute/gatk/pull/5608#issuecomment-458665946:155,Availability,error,errors,155,"@olavurmortensen, yes, this has been tested on our systems and the fix will only mitigate NFS type of issues. However, there is improved logging of system errors now and we would like your inputs with logs and the exact NFS/CIFS configuration if you still run into issues to help us further debug what is happening. Please note that TILEDB_DISABLE_FILE_LOCKING env variable has to be set to 1 when doing the GenomicsDBImport.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5608#issuecomment-458665946
https://github.com/broadinstitute/gatk/pull/5608#issuecomment-458665946:229,Deployability,configurat,configuration,229,"@olavurmortensen, yes, this has been tested on our systems and the fix will only mitigate NFS type of issues. However, there is improved logging of system errors now and we would like your inputs with logs and the exact NFS/CIFS configuration if you still run into issues to help us further debug what is happening. Please note that TILEDB_DISABLE_FILE_LOCKING env variable has to be set to 1 when doing the GenomicsDBImport.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5608#issuecomment-458665946
https://github.com/broadinstitute/gatk/pull/5608#issuecomment-458665946:229,Modifiability,config,configuration,229,"@olavurmortensen, yes, this has been tested on our systems and the fix will only mitigate NFS type of issues. However, there is improved logging of system errors now and we would like your inputs with logs and the exact NFS/CIFS configuration if you still run into issues to help us further debug what is happening. Please note that TILEDB_DISABLE_FILE_LOCKING env variable has to be set to 1 when doing the GenomicsDBImport.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5608#issuecomment-458665946
https://github.com/broadinstitute/gatk/pull/5608#issuecomment-458665946:365,Modifiability,variab,variable,365,"@olavurmortensen, yes, this has been tested on our systems and the fix will only mitigate NFS type of issues. However, there is improved logging of system errors now and we would like your inputs with logs and the exact NFS/CIFS configuration if you still run into issues to help us further debug what is happening. Please note that TILEDB_DISABLE_FILE_LOCKING env variable has to be set to 1 when doing the GenomicsDBImport.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5608#issuecomment-458665946
https://github.com/broadinstitute/gatk/pull/5608#issuecomment-458665946:37,Testability,test,tested,37,"@olavurmortensen, yes, this has been tested on our systems and the fix will only mitigate NFS type of issues. However, there is improved logging of system errors now and we would like your inputs with logs and the exact NFS/CIFS configuration if you still run into issues to help us further debug what is happening. Please note that TILEDB_DISABLE_FILE_LOCKING env variable has to be set to 1 when doing the GenomicsDBImport.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5608#issuecomment-458665946
https://github.com/broadinstitute/gatk/pull/5608#issuecomment-458665946:137,Testability,log,logging,137,"@olavurmortensen, yes, this has been tested on our systems and the fix will only mitigate NFS type of issues. However, there is improved logging of system errors now and we would like your inputs with logs and the exact NFS/CIFS configuration if you still run into issues to help us further debug what is happening. Please note that TILEDB_DISABLE_FILE_LOCKING env variable has to be set to 1 when doing the GenomicsDBImport.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5608#issuecomment-458665946
https://github.com/broadinstitute/gatk/pull/5608#issuecomment-458665946:201,Testability,log,logs,201,"@olavurmortensen, yes, this has been tested on our systems and the fix will only mitigate NFS type of issues. However, there is improved logging of system errors now and we would like your inputs with logs and the exact NFS/CIFS configuration if you still run into issues to help us further debug what is happening. Please note that TILEDB_DISABLE_FILE_LOCKING env variable has to be set to 1 when doing the GenomicsDBImport.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5608#issuecomment-458665946
https://github.com/broadinstitute/gatk/pull/5608#issuecomment-468371003:174,Deployability,configurat,configuration,174,"@olavurmortensen, yes please file a new issue. Please include your OS/platform version, your command, all the logs, any core dumps and steps to create a CIFS mount with your configuration in the issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5608#issuecomment-468371003
https://github.com/broadinstitute/gatk/pull/5608#issuecomment-468371003:174,Modifiability,config,configuration,174,"@olavurmortensen, yes please file a new issue. Please include your OS/platform version, your command, all the logs, any core dumps and steps to create a CIFS mount with your configuration in the issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5608#issuecomment-468371003
https://github.com/broadinstitute/gatk/pull/5608#issuecomment-468371003:110,Testability,log,logs,110,"@olavurmortensen, yes please file a new issue. Please include your OS/platform version, your command, all the logs, any core dumps and steps to create a CIFS mount with your configuration in the issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5608#issuecomment-468371003
https://github.com/broadinstitute/gatk/pull/5615#issuecomment-458285149:44,Testability,Test,Tests,44,@droazen I'd like this to squeeze into 4.1. Tests pass locally after the second commit.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5615#issuecomment-458285149
https://github.com/broadinstitute/gatk/pull/5615#issuecomment-458580294:140,Usability,intuit,intuitive,140,I'm going to keep the initialization as is because it mirrors HaplotypeCaller and because I feel like defining blocks by their size is more intuitive than defining the number of blocks between two bounds.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5615#issuecomment-458580294
https://github.com/broadinstitute/gatk/pull/5616#issuecomment-458329538:1283,Deployability,pipeline,pipelines,1283,c) will **increase** coverage by `0.003%`.; > The diff coverage is `100%`. ```diff; @@ Coverage Diff @@; ## master #5616 +/- ##; ===============================================; + Coverage 87.035% 87.038% +0.003% ; - Complexity 31726 31730 +4 ; ===============================================; Files 1943 1943 ; Lines 146193 146199 +6 ; Branches 16141 16144 +3 ; ===============================================; + Hits 127239 127249 +10 ; + Misses 13067 13064 -3 ; + Partials 5887 5886 -1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5616?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...kers/haplotypecaller/ReferenceConfidenceModel.java](https://codecov.io/gh/broadinstitute/gatk/pull/5616/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9SZWZlcmVuY2VDb25maWRlbmNlTW9kZWwuamF2YQ==) | `92.632% <100%> (+0.24%)` | `70 <0> (+1)` | :arrow_up: |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5616/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `90.741% <0%> (ø)` | `13% <0%> (ø)` | :arrow_down: |; | [...ithwaterman/SmithWatermanIntelAlignerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5616/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXJVbml0VGVzdC5qYXZh) | `60% <0%> (ø)` | `2% <0%> (ø)` | :arrow_down: |; | [...lotypecaller/readthreading/ReadThreadingGraph.java](https://codecov.io/gh/broadinstitute/gatk/pull/5616/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9yZWFkdGhyZWFkaW5nL1JlYWRUaHJlYWRpbmdHcmFwaC5qYXZh) | `88.861% <0%> (+0.253%)` | `145% <0%> (+1%)` | :arrow_up: |; | [...utils/smithwaterman/SmithWatermanIntel,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5616#issuecomment-458329538
https://github.com/broadinstitute/gatk/pull/5616#issuecomment-460423597:37,Integrability,depend,dependent,37,"@droazen this branch wasn't STRICTLY dependent on #5607, so I removed it from this branch to make reviewing easier. Its worth noting that the performance numbers and observed speedup were seen when this branch did hang off of #5607.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5616#issuecomment-460423597
https://github.com/broadinstitute/gatk/pull/5616#issuecomment-460423597:142,Performance,perform,performance,142,"@droazen this branch wasn't STRICTLY dependent on #5607, so I removed it from this branch to make reviewing easier. Its worth noting that the performance numbers and observed speedup were seen when this branch did hang off of #5607.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5616#issuecomment-460423597
https://github.com/broadinstitute/gatk/pull/5616#issuecomment-461597381:188,Performance,perform,performance,188,"@droazen Responded to comments, note that i added a further escape condition where getMatchingPriors is avoided altogether if the VCpriors list is empty. Remember that this method is in a performance sensitive part of the code so every little bit of speed counts.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5616#issuecomment-461597381
https://github.com/broadinstitute/gatk/pull/5616#issuecomment-461597381:104,Safety,avoid,avoided,104,"@droazen Responded to comments, note that i added a further escape condition where getMatchingPriors is avoided altogether if the VCpriors list is empty. Remember that this method is in a performance sensitive part of the code so every little bit of speed counts.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5616#issuecomment-461597381
https://github.com/broadinstitute/gatk/pull/5616#issuecomment-461928409:32,Availability,error,error,32,@jamesemery You have a compiler error on the latest version of this branch:. ```; :compileJava/home/travis/build/broadinstitute/gatk/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReferenceConfidenceModel.java:428: error: ';' expected; final int priorsListSize = priorList.size(); ^; 1 error; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5616#issuecomment-461928409
https://github.com/broadinstitute/gatk/pull/5616#issuecomment-461928409:242,Availability,error,error,242,@jamesemery You have a compiler error on the latest version of this branch:. ```; :compileJava/home/travis/build/broadinstitute/gatk/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReferenceConfidenceModel.java:428: error: ';' expected; final int priorsListSize = priorList.size(); ^; 1 error; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5616#issuecomment-461928409
https://github.com/broadinstitute/gatk/pull/5616#issuecomment-461928409:313,Availability,error,error,313,@jamesemery You have a compiler error on the latest version of this branch:. ```; :compileJava/home/travis/build/broadinstitute/gatk/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/ReferenceConfidenceModel.java:428: error: ';' expected; final int priorsListSize = priorList.size(); ^; 1 error; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5616#issuecomment-461928409
https://github.com/broadinstitute/gatk/pull/5617#issuecomment-458642276:2501,Availability,down,downsampling,2501,<0%> (-5%)` | |; | [...ynumber/models/AlleleFractionGlobalParameters.java](https://codecov.io/gh/broadinstitute/gatk/pull/5617/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL21vZGVscy9BbGxlbGVGcmFjdGlvbkdsb2JhbFBhcmFtZXRlcnMuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-10%)` | |; | [...ls/walkers/genotyper/HeterogeneousPloidyModel.java](https://codecov.io/gh/broadinstitute/gatk/pull/5617/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9IZXRlcm9nZW5lb3VzUGxvaWR5TW9kZWwuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-14%)` | |; | [...rs/vqsr/VariantRecalibratorArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/5617/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3Zxc3IvVmFyaWFudFJlY2FsaWJyYXRvckFyZ3VtZW50Q29sbGVjdGlvbi5qYXZh) | `0% <0%> (-100%)` | `0% <0%> (-1%)` | |; | [...nder/utils/downsampling/FractionalDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/5617/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvRnJhY3Rpb25hbERvd25zYW1wbGVyLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-17%)` | |; | [...park/pathseq/MarkedOpticalDuplicateReadFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5617/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL01hcmtlZE9wdGljYWxEdXBsaWNhdGVSZWFkRmlsdGVyLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-4%)` | |; | [.../read/markduplicates/sparkrecords/Passthrough.java](https://codecov.io/gh/broadinstitute/gatk/pull/5617/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWFkL21hcmtkdXBsaWNhdGVzL3NwYXJrcmVjb3Jkcy9QYXNzdGhyb3VnaC5qYXZh) | `0% <0%> (-100%)` | `0% <0%> (-3%)` | |; | [...otypecaller/RandomLikelihoodCalculationEngine.java](https://codecov.io/gh/broadinstitute/gatk/,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5617#issuecomment-458642276
https://github.com/broadinstitute/gatk/issues/5618#issuecomment-590953474:27,Modifiability,refactor,refactoring,27,"Now that there's been some refactoring of this code, it might be relatively straightforward to rewire the GVCFBlockCombiner to take in likelihood data from the pileup without creating a VariantContext, then pass the combined data to a VC and then to the writer.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5618#issuecomment-590953474
https://github.com/broadinstitute/gatk/pull/5622#issuecomment-458718179:89,Deployability,update,update,89,"@lucidtronix Hopefully by the time you see this the tests will have finished and you can update them if the output looks good. If it's not looking good, just let me know and we can wait until after the 4.1 release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5622#issuecomment-458718179
https://github.com/broadinstitute/gatk/pull/5622#issuecomment-458718179:206,Deployability,release,release,206,"@lucidtronix Hopefully by the time you see this the tests will have finished and you can update them if the output looks good. If it's not looking good, just let me know and we can wait until after the 4.1 release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5622#issuecomment-458718179
https://github.com/broadinstitute/gatk/pull/5622#issuecomment-458718179:52,Testability,test,tests,52,"@lucidtronix Hopefully by the time you see this the tests will have finished and you can update them if the output looks good. If it's not looking good, just let me know and we can wait until after the 4.1 release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5622#issuecomment-458718179
https://github.com/broadinstitute/gatk/pull/5622#issuecomment-458731657:1906,Usability,Simpl,SimpleInterval,1906,mplexity Δ | |; |---|---|---|---|; | [...ellbender/tools/walkers/vqsr/CNNScoreVariants.java](https://codecov.io/gh/broadinstitute/gatk/pull/5622/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3Zxc3IvQ05OU2NvcmVWYXJpYW50cy5qYXZh) | `80.444% <100%> (ø)` | `45 <0> (ø)` | :arrow_down: |; | [.../walkers/vqsr/CNNScoreVariantsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5622/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3Zxc3IvQ05OU2NvcmVWYXJpYW50c0ludGVncmF0aW9uVGVzdC5qYXZh) | `100% <100%> (ø)` | `13 <4> (ø)` | :arrow_down: |; | [...lbender/utils/iterators/IntervalLocusIterator.java](https://codecov.io/gh/broadinstitute/gatk/pull/5622/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9pdGVyYXRvcnMvSW50ZXJ2YWxMb2N1c0l0ZXJhdG9yLmphdmE=) | `92.593% <0%> (ø)` | `11% <0%> (ø)` | :arrow_down: |; | [...roadinstitute/hellbender/utils/SimpleInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/5622/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9TaW1wbGVJbnRlcnZhbC5qYXZh) | `93.182% <0%> (ø)` | `48% <0%> (ø)` | :arrow_down: |; | [...lkers/variantutils/ReblockGVCFIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5622/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9SZWJsb2NrR1ZDRkludGVncmF0aW9uVGVzdC5qYXZh) | `97.826% <0%> (ø)` | `8% <0%> (ø)` | :arrow_down: |; | [...institute/hellbender/utils/help/HelpConstants.java](https://codecov.io/gh/broadinstitute/gatk/pull/5622/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9oZWxwL0hlbHBDb25zdGFudHMuamF2YQ==) | `4.167% <0%> (ø)` | `1% <0%> (ø)` | :arrow_down: |; | [...ls/genomicsdb/GenomicsDBImportIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5622/diff?src=pr&el=,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5622#issuecomment-458731657
https://github.com/broadinstitute/gatk/pull/5622#issuecomment-458765209:127,Availability,down,downsampling,127,"A single site changed by a small amount in CNN score which was expected. (We weren't 100% sure we were testing any sites where downsampling would kick in, so this is good from a test coverage perspective. I think this is safe to include. I'm updating the test file and will push once tests pass locally.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5622#issuecomment-458765209
https://github.com/broadinstitute/gatk/pull/5622#issuecomment-458765209:221,Safety,safe,safe,221,"A single site changed by a small amount in CNN score which was expected. (We weren't 100% sure we were testing any sites where downsampling would kick in, so this is good from a test coverage perspective. I think this is safe to include. I'm updating the test file and will push once tests pass locally.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5622#issuecomment-458765209
https://github.com/broadinstitute/gatk/pull/5622#issuecomment-458765209:103,Testability,test,testing,103,"A single site changed by a small amount in CNN score which was expected. (We weren't 100% sure we were testing any sites where downsampling would kick in, so this is good from a test coverage perspective. I think this is safe to include. I'm updating the test file and will push once tests pass locally.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5622#issuecomment-458765209
https://github.com/broadinstitute/gatk/pull/5622#issuecomment-458765209:178,Testability,test,test,178,"A single site changed by a small amount in CNN score which was expected. (We weren't 100% sure we were testing any sites where downsampling would kick in, so this is good from a test coverage perspective. I think this is safe to include. I'm updating the test file and will push once tests pass locally.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5622#issuecomment-458765209
https://github.com/broadinstitute/gatk/pull/5622#issuecomment-458765209:255,Testability,test,test,255,"A single site changed by a small amount in CNN score which was expected. (We weren't 100% sure we were testing any sites where downsampling would kick in, so this is good from a test coverage perspective. I think this is safe to include. I'm updating the test file and will push once tests pass locally.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5622#issuecomment-458765209
https://github.com/broadinstitute/gatk/pull/5622#issuecomment-458765209:284,Testability,test,tests,284,"A single site changed by a small amount in CNN score which was expected. (We weren't 100% sure we were testing any sites where downsampling would kick in, so this is good from a test coverage perspective. I think this is safe to include. I'm updating the test file and will push once tests pass locally.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5622#issuecomment-458765209
https://github.com/broadinstitute/gatk/pull/5622#issuecomment-458770303:20,Availability,down,downsampler,20,So... the reservoir downsampler seems to be sensitive to the state of the random number generator. Since several tests depend on the same expected output file I keep having failures. I'm resetting the seed for each test now to see if that will work.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5622#issuecomment-458770303
https://github.com/broadinstitute/gatk/pull/5622#issuecomment-458770303:173,Availability,failure,failures,173,So... the reservoir downsampler seems to be sensitive to the state of the random number generator. Since several tests depend on the same expected output file I keep having failures. I'm resetting the seed for each test now to see if that will work.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5622#issuecomment-458770303
https://github.com/broadinstitute/gatk/pull/5622#issuecomment-458770303:119,Integrability,depend,depend,119,So... the reservoir downsampler seems to be sensitive to the state of the random number generator. Since several tests depend on the same expected output file I keep having failures. I'm resetting the seed for each test now to see if that will work.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5622#issuecomment-458770303
https://github.com/broadinstitute/gatk/pull/5622#issuecomment-458770303:113,Testability,test,tests,113,So... the reservoir downsampler seems to be sensitive to the state of the random number generator. Since several tests depend on the same expected output file I keep having failures. I'm resetting the seed for each test now to see if that will work.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5622#issuecomment-458770303
https://github.com/broadinstitute/gatk/pull/5622#issuecomment-458770303:215,Testability,test,test,215,So... the reservoir downsampler seems to be sensitive to the state of the random number generator. Since several tests depend on the same expected output file I keep having failures. I'm resetting the seed for each test now to see if that will work.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5622#issuecomment-458770303
https://github.com/broadinstitute/gatk/pull/5622#issuecomment-458771419:85,Testability,test,test,85,"@lucidtronix Try adding calls to `Utils.resetRandomGenerator()` at the start of each test case. We do this in `HaplotypeCallerIntegrationTest` as well, for the same reason.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5622#issuecomment-458771419
https://github.com/broadinstitute/gatk/issues/5625#issuecomment-900609908:8,Modifiability,refactor,refactoring,8,"Lots of refactoring was done for the Segmenter classes in #6499. At least for segmentation, all use cases (CR-only, AF-only, CR+AF, single-sample, multi-sample) now go through `MultisampleMultidimensionalKernelSegmenter`. `AlleleFractionKernelSegmenter` and `CopyRatioKernelSegmenter` classes still exist, but both simply call the `MultisampleMultidimensionalKernelSegmenter` class; this was done so preexisting tests for those two classes could be reused. I'm fine with calling this done. We can always open a new issue in the unlikely event we refactor the modelling code.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5625#issuecomment-900609908
https://github.com/broadinstitute/gatk/issues/5625#issuecomment-900609908:546,Modifiability,refactor,refactor,546,"Lots of refactoring was done for the Segmenter classes in #6499. At least for segmentation, all use cases (CR-only, AF-only, CR+AF, single-sample, multi-sample) now go through `MultisampleMultidimensionalKernelSegmenter`. `AlleleFractionKernelSegmenter` and `CopyRatioKernelSegmenter` classes still exist, but both simply call the `MultisampleMultidimensionalKernelSegmenter` class; this was done so preexisting tests for those two classes could be reused. I'm fine with calling this done. We can always open a new issue in the unlikely event we refactor the modelling code.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5625#issuecomment-900609908
https://github.com/broadinstitute/gatk/issues/5625#issuecomment-900609908:412,Testability,test,tests,412,"Lots of refactoring was done for the Segmenter classes in #6499. At least for segmentation, all use cases (CR-only, AF-only, CR+AF, single-sample, multi-sample) now go through `MultisampleMultidimensionalKernelSegmenter`. `AlleleFractionKernelSegmenter` and `CopyRatioKernelSegmenter` classes still exist, but both simply call the `MultisampleMultidimensionalKernelSegmenter` class; this was done so preexisting tests for those two classes could be reused. I'm fine with calling this done. We can always open a new issue in the unlikely event we refactor the modelling code.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5625#issuecomment-900609908
https://github.com/broadinstitute/gatk/issues/5625#issuecomment-900609908:315,Usability,simpl,simply,315,"Lots of refactoring was done for the Segmenter classes in #6499. At least for segmentation, all use cases (CR-only, AF-only, CR+AF, single-sample, multi-sample) now go through `MultisampleMultidimensionalKernelSegmenter`. `AlleleFractionKernelSegmenter` and `CopyRatioKernelSegmenter` classes still exist, but both simply call the `MultisampleMultidimensionalKernelSegmenter` class; this was done so preexisting tests for those two classes could be reused. I'm fine with calling this done. We can always open a new issue in the unlikely event we refactor the modelling code.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5625#issuecomment-900609908
https://github.com/broadinstitute/gatk/issues/5627#issuecomment-459716792:28,Deployability,update,update,28,"Right, seems to be a recent update, Using the very latest release works. Thanks.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5627#issuecomment-459716792
https://github.com/broadinstitute/gatk/issues/5627#issuecomment-459716792:58,Deployability,release,release,58,"Right, seems to be a recent update, Using the very latest release works. Thanks.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5627#issuecomment-459716792
https://github.com/broadinstitute/gatk/pull/5628#issuecomment-459742796:2405,Deployability,update,update,2405,"@@ Coverage Diff @@; ## master #5628 +/- ##; ============================================; - Coverage 87.03% 87.03% -0.01% ; Complexity 31726 31726 ; ============================================; Files 1943 1943 ; Lines 146193 146193 ; Branches 16141 16141 ; ============================================; - Hits 127242 127239 -3 ; - Misses 13065 13067 +2 ; - Partials 5886 5887 +1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5628?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...nder/tools/walkers/vqsr/FilterVariantTranches.java](https://codecov.io/gh/broadinstitute/gatk/pull/5628/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3Zxc3IvRmlsdGVyVmFyaWFudFRyYW5jaGVzLmphdmE=) | `92.24% <ø> (ø)` | `42 <0> (ø)` | :arrow_down: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/5628/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `71.23% <0%> (-2.74%)` | `11% <0%> (ø)` | |; | [...nder/utils/runtime/StreamingProcessController.java](https://codecov.io/gh/broadinstitute/gatk/pull/5628/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9ydW50aW1lL1N0cmVhbWluZ1Byb2Nlc3NDb250cm9sbGVyLmphdmE=) | `67.29% <0%> (-0.48%)` | `33% <0%> (ø)` | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5628?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5628?src=pr&el=footer). Last update [78df6b2...8c3a18d](https://codecov.io/gh/broadinstitute/gatk/pull/5628?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5628#issuecomment-459742796
https://github.com/broadinstitute/gatk/pull/5628#issuecomment-459742796:2308,Energy Efficiency,Power,Powered,2308,"@@ Coverage Diff @@; ## master #5628 +/- ##; ============================================; - Coverage 87.03% 87.03% -0.01% ; Complexity 31726 31726 ; ============================================; Files 1943 1943 ; Lines 146193 146193 ; Branches 16141 16141 ; ============================================; - Hits 127242 127239 -3 ; - Misses 13065 13067 +2 ; - Partials 5886 5887 +1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5628?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...nder/tools/walkers/vqsr/FilterVariantTranches.java](https://codecov.io/gh/broadinstitute/gatk/pull/5628/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3Zxc3IvRmlsdGVyVmFyaWFudFRyYW5jaGVzLmphdmE=) | `92.24% <ø> (ø)` | `42 <0> (ø)` | :arrow_down: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/5628/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `71.23% <0%> (-2.74%)` | `11% <0%> (ø)` | |; | [...nder/utils/runtime/StreamingProcessController.java](https://codecov.io/gh/broadinstitute/gatk/pull/5628/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9ydW50aW1lL1N0cmVhbWluZ1Byb2Nlc3NDb250cm9sbGVyLmphdmE=) | `67.29% <0%> (-0.48%)` | `33% <0%> (ø)` | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5628?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5628?src=pr&el=footer). Last update [78df6b2...8c3a18d](https://codecov.io/gh/broadinstitute/gatk/pull/5628?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5628#issuecomment-459742796
https://github.com/broadinstitute/gatk/pull/5628#issuecomment-459742796:2171,Usability,learn,learn,2171,"@@ Coverage Diff @@; ## master #5628 +/- ##; ============================================; - Coverage 87.03% 87.03% -0.01% ; Complexity 31726 31726 ; ============================================; Files 1943 1943 ; Lines 146193 146193 ; Branches 16141 16141 ; ============================================; - Hits 127242 127239 -3 ; - Misses 13065 13067 +2 ; - Partials 5886 5887 +1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5628?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...nder/tools/walkers/vqsr/FilterVariantTranches.java](https://codecov.io/gh/broadinstitute/gatk/pull/5628/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3Zxc3IvRmlsdGVyVmFyaWFudFRyYW5jaGVzLmphdmE=) | `92.24% <ø> (ø)` | `42 <0> (ø)` | :arrow_down: |; | [...e/hellbender/engine/spark/SparkContextFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/5628/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvU3BhcmtDb250ZXh0RmFjdG9yeS5qYXZh) | `71.23% <0%> (-2.74%)` | `11% <0%> (ø)` | |; | [...nder/utils/runtime/StreamingProcessController.java](https://codecov.io/gh/broadinstitute/gatk/pull/5628/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9ydW50aW1lL1N0cmVhbWluZ1Byb2Nlc3NDb250cm9sbGVyLmphdmE=) | `67.29% <0%> (-0.48%)` | `33% <0%> (ø)` | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5628?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5628?src=pr&el=footer). Last update [78df6b2...8c3a18d](https://codecov.io/gh/broadinstitute/gatk/pull/5628?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5628#issuecomment-459742796
https://github.com/broadinstitute/gatk/issues/5631#issuecomment-459838085:308,Availability,failure,failure,308,"@jean-philippe-martin, when you have a chance could you please take a look at the stack trace above and give your thoughts? Our NIO library dependency was not upgraded between 4.0.11.0 and 4.0.12.0 (it was last upgraded in 4.0.9.0), so it's not clear what it is about 4.0.12.0 that is leading to this higher failure rate. . We've already tried a custom build of 4.0.12.0 that included the version of htsjdk from 4.0.11.0, but that didn't help.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5631#issuecomment-459838085
https://github.com/broadinstitute/gatk/issues/5631#issuecomment-459838085:159,Deployability,upgrade,upgraded,159,"@jean-philippe-martin, when you have a chance could you please take a look at the stack trace above and give your thoughts? Our NIO library dependency was not upgraded between 4.0.11.0 and 4.0.12.0 (it was last upgraded in 4.0.9.0), so it's not clear what it is about 4.0.12.0 that is leading to this higher failure rate. . We've already tried a custom build of 4.0.12.0 that included the version of htsjdk from 4.0.11.0, but that didn't help.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5631#issuecomment-459838085
https://github.com/broadinstitute/gatk/issues/5631#issuecomment-459838085:211,Deployability,upgrade,upgraded,211,"@jean-philippe-martin, when you have a chance could you please take a look at the stack trace above and give your thoughts? Our NIO library dependency was not upgraded between 4.0.11.0 and 4.0.12.0 (it was last upgraded in 4.0.9.0), so it's not clear what it is about 4.0.12.0 that is leading to this higher failure rate. . We've already tried a custom build of 4.0.12.0 that included the version of htsjdk from 4.0.11.0, but that didn't help.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5631#issuecomment-459838085
https://github.com/broadinstitute/gatk/issues/5631#issuecomment-459838085:140,Integrability,depend,dependency,140,"@jean-philippe-martin, when you have a chance could you please take a look at the stack trace above and give your thoughts? Our NIO library dependency was not upgraded between 4.0.11.0 and 4.0.12.0 (it was last upgraded in 4.0.9.0), so it's not clear what it is about 4.0.12.0 that is leading to this higher failure rate. . We've already tried a custom build of 4.0.12.0 that included the version of htsjdk from 4.0.11.0, but that didn't help.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5631#issuecomment-459838085
https://github.com/broadinstitute/gatk/issues/5631#issuecomment-459838085:245,Usability,clear,clear,245,"@jean-philippe-martin, when you have a chance could you please take a look at the stack trace above and give your thoughts? Our NIO library dependency was not upgraded between 4.0.11.0 and 4.0.12.0 (it was last upgraded in 4.0.9.0), so it's not clear what it is about 4.0.12.0 that is leading to this higher failure rate. . We've already tried a custom build of 4.0.12.0 that included the version of htsjdk from 4.0.11.0, but that didn't help.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5631#issuecomment-459838085
https://github.com/broadinstitute/gatk/issues/5631#issuecomment-459842021:20,Security,access,accesses,20,"If only some of the accesses failed, then it's likely what we're seeing here is GCS refusing to serve requests because it feels it's getting too many. How many machines are trying to access the file? How many threads per machine? What storage class is the bucket?. The lower storage classes support fewer parallel accesses, and NIO's prefetching (if enabled) results in two threads per reader.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5631#issuecomment-459842021
https://github.com/broadinstitute/gatk/issues/5631#issuecomment-459842021:183,Security,access,access,183,"If only some of the accesses failed, then it's likely what we're seeing here is GCS refusing to serve requests because it feels it's getting too many. How many machines are trying to access the file? How many threads per machine? What storage class is the bucket?. The lower storage classes support fewer parallel accesses, and NIO's prefetching (if enabled) results in two threads per reader.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5631#issuecomment-459842021
https://github.com/broadinstitute/gatk/issues/5631#issuecomment-459842021:314,Security,access,accesses,314,"If only some of the accesses failed, then it's likely what we're seeing here is GCS refusing to serve requests because it feels it's getting too many. How many machines are trying to access the file? How many threads per machine? What storage class is the bucket?. The lower storage classes support fewer parallel accesses, and NIO's prefetching (if enabled) results in two threads per reader.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5631#issuecomment-459842021
https://github.com/broadinstitute/gatk/issues/5631#issuecomment-459845523:281,Security,access,access,281,"The possibility that this problem could be specific to the TCGA FC BAMs did arise in our previous discussions---not sure what storage class those are on?. However, in this workflow, at most one ReadWalker (CollectReadCounts) and one LocusWalker (CollectAllelicCounts) would try to access the same (tumor) BAM. There were several instances of (normal) BAMs which only had one LocusWalker (CollectAllelicCounts) accessing them that failed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5631#issuecomment-459845523
https://github.com/broadinstitute/gatk/issues/5631#issuecomment-459845523:410,Security,access,accessing,410,"The possibility that this problem could be specific to the TCGA FC BAMs did arise in our previous discussions---not sure what storage class those are on?. However, in this workflow, at most one ReadWalker (CollectReadCounts) and one LocusWalker (CollectAllelicCounts) would try to access the same (tumor) BAM. There were several instances of (normal) BAMs which only had one LocusWalker (CollectAllelicCounts) accessing them that failed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5631#issuecomment-459845523
https://github.com/broadinstitute/gatk/issues/5631#issuecomment-459927501:8,Availability,failure,failure,8,Rate of failure still seems high in 4.1.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5631#issuecomment-459927501
https://github.com/broadinstitute/gatk/issues/5631#issuecomment-466520895:130,Deployability,upgrade,upgraded,130,"@samuelklee When you get a chance, could you repeat your test with latest gatk/master? We recently (ie., within the past 2 weeks) upgraded to a newer gcloud release, and I'm curious to test whether that had an effect.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5631#issuecomment-466520895
https://github.com/broadinstitute/gatk/issues/5631#issuecomment-466520895:157,Deployability,release,release,157,"@samuelklee When you get a chance, could you repeat your test with latest gatk/master? We recently (ie., within the past 2 weeks) upgraded to a newer gcloud release, and I'm curious to test whether that had an effect.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5631#issuecomment-466520895
https://github.com/broadinstitute/gatk/issues/5631#issuecomment-466520895:57,Testability,test,test,57,"@samuelklee When you get a chance, could you repeat your test with latest gatk/master? We recently (ie., within the past 2 weeks) upgraded to a newer gcloud release, and I'm curious to test whether that had an effect.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5631#issuecomment-466520895
https://github.com/broadinstitute/gatk/issues/5631#issuecomment-466520895:185,Testability,test,test,185,"@samuelklee When you get a chance, could you repeat your test with latest gatk/master? We recently (ie., within the past 2 weeks) upgraded to a newer gcloud release, and I'm curious to test whether that had an effect.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5631#issuecomment-466520895
https://github.com/broadinstitute/gatk/issues/5631#issuecomment-466853197:69,Availability,failure,failure,69,"I collected coverage over 200 WGS BAMs on FC and didn't get a single failure, so hopefully this has indeed been fixed! Thanks @droazen, will close for now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5631#issuecomment-466853197
https://github.com/broadinstitute/gatk/issues/5631#issuecomment-467134259:68,Deployability,upgrade,upgrade,68,"@samuelklee That's really good news! Do you think it was the gcloud upgrade that did the trick, then?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5631#issuecomment-467134259
https://github.com/broadinstitute/gatk/issues/5631#issuecomment-526270716:1118,Deployability,configurat,configuration,1118,"Multiple causes can cause closed connections when reading from GCS, almost all of which are outside of our control. This will never be ""completely fixed"" in the sense that even if the code is perfect it's completely possible to send too many requests to GCS, and it'll respond by closing connections. The main factors that I know of are:. - number of concurrent accesses to the GCS bucket in question; - number of concurrent accesses to the GCP project in question; - storage class of the GCS bucket in question (the more expensive ones have more replicas, thus can handle a higher load). If you're running into those difficulties I would suggest trying to reduce the load (reduce the number of concurrent workers or threads) and making sure it's not a single-region storage bucket. If that fails, perhaps try using a different bucket that no one else is also using (to reduce other sources of load). If I understand correctly that you didn't change the version you're using but are suddenly seeing more issues than before, then perhaps the cause is a server-side change from GCS (outside of our control), a change in configuration (are you reading from a bucket of a different class from before), or perhaps just an increase of other activity on the same bucket/project. The current code is very persistent in its retries: as you can see from the messages it spent a whole half hour waiting. If it's an overload situation then you may get better performance by reducing the worker count (as they will have to retry less).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5631#issuecomment-526270716
https://github.com/broadinstitute/gatk/issues/5631#issuecomment-526270716:657,Energy Efficiency,reduce,reduce,657,"Multiple causes can cause closed connections when reading from GCS, almost all of which are outside of our control. This will never be ""completely fixed"" in the sense that even if the code is perfect it's completely possible to send too many requests to GCS, and it'll respond by closing connections. The main factors that I know of are:. - number of concurrent accesses to the GCS bucket in question; - number of concurrent accesses to the GCP project in question; - storage class of the GCS bucket in question (the more expensive ones have more replicas, thus can handle a higher load). If you're running into those difficulties I would suggest trying to reduce the load (reduce the number of concurrent workers or threads) and making sure it's not a single-region storage bucket. If that fails, perhaps try using a different bucket that no one else is also using (to reduce other sources of load). If I understand correctly that you didn't change the version you're using but are suddenly seeing more issues than before, then perhaps the cause is a server-side change from GCS (outside of our control), a change in configuration (are you reading from a bucket of a different class from before), or perhaps just an increase of other activity on the same bucket/project. The current code is very persistent in its retries: as you can see from the messages it spent a whole half hour waiting. If it's an overload situation then you may get better performance by reducing the worker count (as they will have to retry less).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5631#issuecomment-526270716
https://github.com/broadinstitute/gatk/issues/5631#issuecomment-526270716:674,Energy Efficiency,reduce,reduce,674,"Multiple causes can cause closed connections when reading from GCS, almost all of which are outside of our control. This will never be ""completely fixed"" in the sense that even if the code is perfect it's completely possible to send too many requests to GCS, and it'll respond by closing connections. The main factors that I know of are:. - number of concurrent accesses to the GCS bucket in question; - number of concurrent accesses to the GCP project in question; - storage class of the GCS bucket in question (the more expensive ones have more replicas, thus can handle a higher load). If you're running into those difficulties I would suggest trying to reduce the load (reduce the number of concurrent workers or threads) and making sure it's not a single-region storage bucket. If that fails, perhaps try using a different bucket that no one else is also using (to reduce other sources of load). If I understand correctly that you didn't change the version you're using but are suddenly seeing more issues than before, then perhaps the cause is a server-side change from GCS (outside of our control), a change in configuration (are you reading from a bucket of a different class from before), or perhaps just an increase of other activity on the same bucket/project. The current code is very persistent in its retries: as you can see from the messages it spent a whole half hour waiting. If it's an overload situation then you may get better performance by reducing the worker count (as they will have to retry less).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5631#issuecomment-526270716
https://github.com/broadinstitute/gatk/issues/5631#issuecomment-526270716:870,Energy Efficiency,reduce,reduce,870,"Multiple causes can cause closed connections when reading from GCS, almost all of which are outside of our control. This will never be ""completely fixed"" in the sense that even if the code is perfect it's completely possible to send too many requests to GCS, and it'll respond by closing connections. The main factors that I know of are:. - number of concurrent accesses to the GCS bucket in question; - number of concurrent accesses to the GCP project in question; - storage class of the GCS bucket in question (the more expensive ones have more replicas, thus can handle a higher load). If you're running into those difficulties I would suggest trying to reduce the load (reduce the number of concurrent workers or threads) and making sure it's not a single-region storage bucket. If that fails, perhaps try using a different bucket that no one else is also using (to reduce other sources of load). If I understand correctly that you didn't change the version you're using but are suddenly seeing more issues than before, then perhaps the cause is a server-side change from GCS (outside of our control), a change in configuration (are you reading from a bucket of a different class from before), or perhaps just an increase of other activity on the same bucket/project. The current code is very persistent in its retries: as you can see from the messages it spent a whole half hour waiting. If it's an overload situation then you may get better performance by reducing the worker count (as they will have to retry less).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5631#issuecomment-526270716
https://github.com/broadinstitute/gatk/issues/5631#issuecomment-526270716:1348,Integrability,message,messages,1348,"Multiple causes can cause closed connections when reading from GCS, almost all of which are outside of our control. This will never be ""completely fixed"" in the sense that even if the code is perfect it's completely possible to send too many requests to GCS, and it'll respond by closing connections. The main factors that I know of are:. - number of concurrent accesses to the GCS bucket in question; - number of concurrent accesses to the GCP project in question; - storage class of the GCS bucket in question (the more expensive ones have more replicas, thus can handle a higher load). If you're running into those difficulties I would suggest trying to reduce the load (reduce the number of concurrent workers or threads) and making sure it's not a single-region storage bucket. If that fails, perhaps try using a different bucket that no one else is also using (to reduce other sources of load). If I understand correctly that you didn't change the version you're using but are suddenly seeing more issues than before, then perhaps the cause is a server-side change from GCS (outside of our control), a change in configuration (are you reading from a bucket of a different class from before), or perhaps just an increase of other activity on the same bucket/project. The current code is very persistent in its retries: as you can see from the messages it spent a whole half hour waiting. If it's an overload situation then you may get better performance by reducing the worker count (as they will have to retry less).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5631#issuecomment-526270716
https://github.com/broadinstitute/gatk/issues/5631#issuecomment-526270716:1118,Modifiability,config,configuration,1118,"Multiple causes can cause closed connections when reading from GCS, almost all of which are outside of our control. This will never be ""completely fixed"" in the sense that even if the code is perfect it's completely possible to send too many requests to GCS, and it'll respond by closing connections. The main factors that I know of are:. - number of concurrent accesses to the GCS bucket in question; - number of concurrent accesses to the GCP project in question; - storage class of the GCS bucket in question (the more expensive ones have more replicas, thus can handle a higher load). If you're running into those difficulties I would suggest trying to reduce the load (reduce the number of concurrent workers or threads) and making sure it's not a single-region storage bucket. If that fails, perhaps try using a different bucket that no one else is also using (to reduce other sources of load). If I understand correctly that you didn't change the version you're using but are suddenly seeing more issues than before, then perhaps the cause is a server-side change from GCS (outside of our control), a change in configuration (are you reading from a bucket of a different class from before), or perhaps just an increase of other activity on the same bucket/project. The current code is very persistent in its retries: as you can see from the messages it spent a whole half hour waiting. If it's an overload situation then you may get better performance by reducing the worker count (as they will have to retry less).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5631#issuecomment-526270716
https://github.com/broadinstitute/gatk/issues/5631#issuecomment-526270716:351,Performance,concurren,concurrent,351,"Multiple causes can cause closed connections when reading from GCS, almost all of which are outside of our control. This will never be ""completely fixed"" in the sense that even if the code is perfect it's completely possible to send too many requests to GCS, and it'll respond by closing connections. The main factors that I know of are:. - number of concurrent accesses to the GCS bucket in question; - number of concurrent accesses to the GCP project in question; - storage class of the GCS bucket in question (the more expensive ones have more replicas, thus can handle a higher load). If you're running into those difficulties I would suggest trying to reduce the load (reduce the number of concurrent workers or threads) and making sure it's not a single-region storage bucket. If that fails, perhaps try using a different bucket that no one else is also using (to reduce other sources of load). If I understand correctly that you didn't change the version you're using but are suddenly seeing more issues than before, then perhaps the cause is a server-side change from GCS (outside of our control), a change in configuration (are you reading from a bucket of a different class from before), or perhaps just an increase of other activity on the same bucket/project. The current code is very persistent in its retries: as you can see from the messages it spent a whole half hour waiting. If it's an overload situation then you may get better performance by reducing the worker count (as they will have to retry less).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5631#issuecomment-526270716
https://github.com/broadinstitute/gatk/issues/5631#issuecomment-526270716:414,Performance,concurren,concurrent,414,"Multiple causes can cause closed connections when reading from GCS, almost all of which are outside of our control. This will never be ""completely fixed"" in the sense that even if the code is perfect it's completely possible to send too many requests to GCS, and it'll respond by closing connections. The main factors that I know of are:. - number of concurrent accesses to the GCS bucket in question; - number of concurrent accesses to the GCP project in question; - storage class of the GCS bucket in question (the more expensive ones have more replicas, thus can handle a higher load). If you're running into those difficulties I would suggest trying to reduce the load (reduce the number of concurrent workers or threads) and making sure it's not a single-region storage bucket. If that fails, perhaps try using a different bucket that no one else is also using (to reduce other sources of load). If I understand correctly that you didn't change the version you're using but are suddenly seeing more issues than before, then perhaps the cause is a server-side change from GCS (outside of our control), a change in configuration (are you reading from a bucket of a different class from before), or perhaps just an increase of other activity on the same bucket/project. The current code is very persistent in its retries: as you can see from the messages it spent a whole half hour waiting. If it's an overload situation then you may get better performance by reducing the worker count (as they will have to retry less).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5631#issuecomment-526270716
https://github.com/broadinstitute/gatk/issues/5631#issuecomment-526270716:582,Performance,load,load,582,"Multiple causes can cause closed connections when reading from GCS, almost all of which are outside of our control. This will never be ""completely fixed"" in the sense that even if the code is perfect it's completely possible to send too many requests to GCS, and it'll respond by closing connections. The main factors that I know of are:. - number of concurrent accesses to the GCS bucket in question; - number of concurrent accesses to the GCP project in question; - storage class of the GCS bucket in question (the more expensive ones have more replicas, thus can handle a higher load). If you're running into those difficulties I would suggest trying to reduce the load (reduce the number of concurrent workers or threads) and making sure it's not a single-region storage bucket. If that fails, perhaps try using a different bucket that no one else is also using (to reduce other sources of load). If I understand correctly that you didn't change the version you're using but are suddenly seeing more issues than before, then perhaps the cause is a server-side change from GCS (outside of our control), a change in configuration (are you reading from a bucket of a different class from before), or perhaps just an increase of other activity on the same bucket/project. The current code is very persistent in its retries: as you can see from the messages it spent a whole half hour waiting. If it's an overload situation then you may get better performance by reducing the worker count (as they will have to retry less).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5631#issuecomment-526270716
https://github.com/broadinstitute/gatk/issues/5631#issuecomment-526270716:668,Performance,load,load,668,"Multiple causes can cause closed connections when reading from GCS, almost all of which are outside of our control. This will never be ""completely fixed"" in the sense that even if the code is perfect it's completely possible to send too many requests to GCS, and it'll respond by closing connections. The main factors that I know of are:. - number of concurrent accesses to the GCS bucket in question; - number of concurrent accesses to the GCP project in question; - storage class of the GCS bucket in question (the more expensive ones have more replicas, thus can handle a higher load). If you're running into those difficulties I would suggest trying to reduce the load (reduce the number of concurrent workers or threads) and making sure it's not a single-region storage bucket. If that fails, perhaps try using a different bucket that no one else is also using (to reduce other sources of load). If I understand correctly that you didn't change the version you're using but are suddenly seeing more issues than before, then perhaps the cause is a server-side change from GCS (outside of our control), a change in configuration (are you reading from a bucket of a different class from before), or perhaps just an increase of other activity on the same bucket/project. The current code is very persistent in its retries: as you can see from the messages it spent a whole half hour waiting. If it's an overload situation then you may get better performance by reducing the worker count (as they will have to retry less).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5631#issuecomment-526270716
https://github.com/broadinstitute/gatk/issues/5631#issuecomment-526270716:695,Performance,concurren,concurrent,695,"Multiple causes can cause closed connections when reading from GCS, almost all of which are outside of our control. This will never be ""completely fixed"" in the sense that even if the code is perfect it's completely possible to send too many requests to GCS, and it'll respond by closing connections. The main factors that I know of are:. - number of concurrent accesses to the GCS bucket in question; - number of concurrent accesses to the GCP project in question; - storage class of the GCS bucket in question (the more expensive ones have more replicas, thus can handle a higher load). If you're running into those difficulties I would suggest trying to reduce the load (reduce the number of concurrent workers or threads) and making sure it's not a single-region storage bucket. If that fails, perhaps try using a different bucket that no one else is also using (to reduce other sources of load). If I understand correctly that you didn't change the version you're using but are suddenly seeing more issues than before, then perhaps the cause is a server-side change from GCS (outside of our control), a change in configuration (are you reading from a bucket of a different class from before), or perhaps just an increase of other activity on the same bucket/project. The current code is very persistent in its retries: as you can see from the messages it spent a whole half hour waiting. If it's an overload situation then you may get better performance by reducing the worker count (as they will have to retry less).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5631#issuecomment-526270716
https://github.com/broadinstitute/gatk/issues/5631#issuecomment-526270716:894,Performance,load,load,894,"Multiple causes can cause closed connections when reading from GCS, almost all of which are outside of our control. This will never be ""completely fixed"" in the sense that even if the code is perfect it's completely possible to send too many requests to GCS, and it'll respond by closing connections. The main factors that I know of are:. - number of concurrent accesses to the GCS bucket in question; - number of concurrent accesses to the GCP project in question; - storage class of the GCS bucket in question (the more expensive ones have more replicas, thus can handle a higher load). If you're running into those difficulties I would suggest trying to reduce the load (reduce the number of concurrent workers or threads) and making sure it's not a single-region storage bucket. If that fails, perhaps try using a different bucket that no one else is also using (to reduce other sources of load). If I understand correctly that you didn't change the version you're using but are suddenly seeing more issues than before, then perhaps the cause is a server-side change from GCS (outside of our control), a change in configuration (are you reading from a bucket of a different class from before), or perhaps just an increase of other activity on the same bucket/project. The current code is very persistent in its retries: as you can see from the messages it spent a whole half hour waiting. If it's an overload situation then you may get better performance by reducing the worker count (as they will have to retry less).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5631#issuecomment-526270716
https://github.com/broadinstitute/gatk/issues/5631#issuecomment-526270716:1447,Performance,perform,performance,1447,"Multiple causes can cause closed connections when reading from GCS, almost all of which are outside of our control. This will never be ""completely fixed"" in the sense that even if the code is perfect it's completely possible to send too many requests to GCS, and it'll respond by closing connections. The main factors that I know of are:. - number of concurrent accesses to the GCS bucket in question; - number of concurrent accesses to the GCP project in question; - storage class of the GCS bucket in question (the more expensive ones have more replicas, thus can handle a higher load). If you're running into those difficulties I would suggest trying to reduce the load (reduce the number of concurrent workers or threads) and making sure it's not a single-region storage bucket. If that fails, perhaps try using a different bucket that no one else is also using (to reduce other sources of load). If I understand correctly that you didn't change the version you're using but are suddenly seeing more issues than before, then perhaps the cause is a server-side change from GCS (outside of our control), a change in configuration (are you reading from a bucket of a different class from before), or perhaps just an increase of other activity on the same bucket/project. The current code is very persistent in its retries: as you can see from the messages it spent a whole half hour waiting. If it's an overload situation then you may get better performance by reducing the worker count (as they will have to retry less).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5631#issuecomment-526270716
https://github.com/broadinstitute/gatk/issues/5631#issuecomment-526270716:362,Security,access,accesses,362,"Multiple causes can cause closed connections when reading from GCS, almost all of which are outside of our control. This will never be ""completely fixed"" in the sense that even if the code is perfect it's completely possible to send too many requests to GCS, and it'll respond by closing connections. The main factors that I know of are:. - number of concurrent accesses to the GCS bucket in question; - number of concurrent accesses to the GCP project in question; - storage class of the GCS bucket in question (the more expensive ones have more replicas, thus can handle a higher load). If you're running into those difficulties I would suggest trying to reduce the load (reduce the number of concurrent workers or threads) and making sure it's not a single-region storage bucket. If that fails, perhaps try using a different bucket that no one else is also using (to reduce other sources of load). If I understand correctly that you didn't change the version you're using but are suddenly seeing more issues than before, then perhaps the cause is a server-side change from GCS (outside of our control), a change in configuration (are you reading from a bucket of a different class from before), or perhaps just an increase of other activity on the same bucket/project. The current code is very persistent in its retries: as you can see from the messages it spent a whole half hour waiting. If it's an overload situation then you may get better performance by reducing the worker count (as they will have to retry less).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5631#issuecomment-526270716
https://github.com/broadinstitute/gatk/issues/5631#issuecomment-526270716:425,Security,access,accesses,425,"Multiple causes can cause closed connections when reading from GCS, almost all of which are outside of our control. This will never be ""completely fixed"" in the sense that even if the code is perfect it's completely possible to send too many requests to GCS, and it'll respond by closing connections. The main factors that I know of are:. - number of concurrent accesses to the GCS bucket in question; - number of concurrent accesses to the GCP project in question; - storage class of the GCS bucket in question (the more expensive ones have more replicas, thus can handle a higher load). If you're running into those difficulties I would suggest trying to reduce the load (reduce the number of concurrent workers or threads) and making sure it's not a single-region storage bucket. If that fails, perhaps try using a different bucket that no one else is also using (to reduce other sources of load). If I understand correctly that you didn't change the version you're using but are suddenly seeing more issues than before, then perhaps the cause is a server-side change from GCS (outside of our control), a change in configuration (are you reading from a bucket of a different class from before), or perhaps just an increase of other activity on the same bucket/project. The current code is very persistent in its retries: as you can see from the messages it spent a whole half hour waiting. If it's an overload situation then you may get better performance by reducing the worker count (as they will have to retry less).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5631#issuecomment-526270716
https://github.com/broadinstitute/gatk/issues/5631#issuecomment-526274700:148,Security,access,accessed,148,"Thanks, JP!; Yes, you understood right. I did not change anything. It was only different days. The probability that the same bucket could have been accessed by multiple jobs/projects totally makes sense. I will try lowering the number of scattered tasks and see if it works.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5631#issuecomment-526274700
https://github.com/broadinstitute/gatk/issues/5632#issuecomment-926857837:91,Availability,avail,available,91,"The Talkowski lab version of this is in R and requires some packages that don't seem to be available anymore as well as the python tool svtk, also developed in their lab. It also localizes all the files with a separate Java program they developed. Their implementation is here (most critically gCNV_Pipeline.Rmd and gCNV_helper.jar): https://github.com/theisaacwong/talkowski/tree/master/gCNV It appears to be under active development. My simplified implementation is at https://app.terra.bio/#workspaces/broad-firecloud-dsde-methods/gCNV-CMG-test/notebooks/launch/perform_clustering.ipynb but it's still under development with some help from Brian in TAG.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5632#issuecomment-926857837
https://github.com/broadinstitute/gatk/issues/5632#issuecomment-926857837:543,Testability,test,test,543,"The Talkowski lab version of this is in R and requires some packages that don't seem to be available anymore as well as the python tool svtk, also developed in their lab. It also localizes all the files with a separate Java program they developed. Their implementation is here (most critically gCNV_Pipeline.Rmd and gCNV_helper.jar): https://github.com/theisaacwong/talkowski/tree/master/gCNV It appears to be under active development. My simplified implementation is at https://app.terra.bio/#workspaces/broad-firecloud-dsde-methods/gCNV-CMG-test/notebooks/launch/perform_clustering.ipynb but it's still under development with some help from Brian in TAG.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5632#issuecomment-926857837
https://github.com/broadinstitute/gatk/issues/5632#issuecomment-926857837:439,Usability,simpl,simplified,439,"The Talkowski lab version of this is in R and requires some packages that don't seem to be available anymore as well as the python tool svtk, also developed in their lab. It also localizes all the files with a separate Java program they developed. Their implementation is here (most critically gCNV_Pipeline.Rmd and gCNV_helper.jar): https://github.com/theisaacwong/talkowski/tree/master/gCNV It appears to be under active development. My simplified implementation is at https://app.terra.bio/#workspaces/broad-firecloud-dsde-methods/gCNV-CMG-test/notebooks/launch/perform_clustering.ipynb but it's still under development with some help from Brian in TAG.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5632#issuecomment-926857837
https://github.com/broadinstitute/gatk/issues/5632#issuecomment-926865252:23,Deployability,pipeline,pipeline,23,PCA results from the R pipeline for the full CMG cohort are in the bucket associated with my workspace: gs://fc-d3bc13de-ef61-4854-a05c-d311219008b3/pca.rda The rownames in pca$x should be the sample names. Also in the bucket are two bed files. the aux_capture_uniques was used for clustering in the R pipeline and the gencode file was used for calling. Other notes:; gCNV_helper.jar is Java 14 and may have some issues reading .vcf.gz on mac; At least a subset of the CMG calls from the R pipeline are in gs://fc-d3bc13de-ef61-4854-a05c-d311219008b3/isaacsCalls.tsv,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5632#issuecomment-926865252
https://github.com/broadinstitute/gatk/issues/5632#issuecomment-926865252:302,Deployability,pipeline,pipeline,302,PCA results from the R pipeline for the full CMG cohort are in the bucket associated with my workspace: gs://fc-d3bc13de-ef61-4854-a05c-d311219008b3/pca.rda The rownames in pca$x should be the sample names. Also in the bucket are two bed files. the aux_capture_uniques was used for clustering in the R pipeline and the gencode file was used for calling. Other notes:; gCNV_helper.jar is Java 14 and may have some issues reading .vcf.gz on mac; At least a subset of the CMG calls from the R pipeline are in gs://fc-d3bc13de-ef61-4854-a05c-d311219008b3/isaacsCalls.tsv,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5632#issuecomment-926865252
https://github.com/broadinstitute/gatk/issues/5632#issuecomment-926865252:490,Deployability,pipeline,pipeline,490,PCA results from the R pipeline for the full CMG cohort are in the bucket associated with my workspace: gs://fc-d3bc13de-ef61-4854-a05c-d311219008b3/pca.rda The rownames in pca$x should be the sample names. Also in the bucket are two bed files. the aux_capture_uniques was used for clustering in the R pipeline and the gencode file was used for calling. Other notes:; gCNV_helper.jar is Java 14 and may have some issues reading .vcf.gz on mac; At least a subset of the CMG calls from the R pipeline are in gs://fc-d3bc13de-ef61-4854-a05c-d311219008b3/isaacsCalls.tsv,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5632#issuecomment-926865252
https://github.com/broadinstitute/gatk/issues/5633#issuecomment-894527360:195,Availability,down,down,195,"I’ve also revisited this work for MalariaGEN, additionally including further cleanup of the canonical part of the WDLs (mostly low hanging fruit like adding structs, which help a lot for cutting down parameter cruft on Terra). For ease of iteration, this work broke things up into 3 pushes of a button: 1) data collection, 2) preclustering (done in a relatively modular way, so you can swap in whatever clustering script you like, as long as it outputs hard/soft responsibilities) +random selection of training cohorts, and 3) cohort mode + scattered case mode on all clusters. But no reason we couldn’t link some of those up. No problem running 16k samples, with 6 clusters and 300 training samples per, but also note I was only running a single genomic shard containing CNVs of interest for this use case. (I did manage to break Terra for a few days when I tried to attach collected counts to the data model in what I would’ve thought would be a relatively trivial way, but that’s another matter.). I’ve shared some version of these WDLs over Slack previously, but happy to also open up a branch here. I think some of this work may be replicated in GATK-SV and I’m also not sure what we want to make canonical. Surely most users will run only a single cluster. But from the perspective of our MalariaGEN collaborators, the more of what I put together for them being made canonical, the better, as this will ease future maintainability. But will leave it up to other current stakeholders.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5633#issuecomment-894527360
https://github.com/broadinstitute/gatk/issues/5633#issuecomment-894527360:1421,Modifiability,maintainab,maintainability,1421,"I’ve also revisited this work for MalariaGEN, additionally including further cleanup of the canonical part of the WDLs (mostly low hanging fruit like adding structs, which help a lot for cutting down parameter cruft on Terra). For ease of iteration, this work broke things up into 3 pushes of a button: 1) data collection, 2) preclustering (done in a relatively modular way, so you can swap in whatever clustering script you like, as long as it outputs hard/soft responsibilities) +random selection of training cohorts, and 3) cohort mode + scattered case mode on all clusters. But no reason we couldn’t link some of those up. No problem running 16k samples, with 6 clusters and 300 training samples per, but also note I was only running a single genomic shard containing CNVs of interest for this use case. (I did manage to break Terra for a few days when I tried to attach collected counts to the data model in what I would’ve thought would be a relatively trivial way, but that’s another matter.). I’ve shared some version of these WDLs over Slack previously, but happy to also open up a branch here. I think some of this work may be replicated in GATK-SV and I’m also not sure what we want to make canonical. Surely most users will run only a single cluster. But from the perspective of our MalariaGEN collaborators, the more of what I put together for them being made canonical, the better, as this will ease future maintainability. But will leave it up to other current stakeholders.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5633#issuecomment-894527360
https://github.com/broadinstitute/gatk/issues/5634#issuecomment-525798707:53,Performance,perform,performing,53,"Essentially using preclustering of samples (e.g., by performing clustering on a subset of the coverage bins) to automate building of multiple PoNs when appropriate. Proof-of-principle was implemented for germline (#5633) in https://github.com/broadinstitute/gatk-evaluation/tree/sl_mega_wdl, but it hasn't been merged yet nor do we have plans to put it in production or heavy use anytime soon---sticking with manual preclustering when needed, for now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5634#issuecomment-525798707
https://github.com/broadinstitute/gatk/pull/5635#issuecomment-460033606:2500,Deployability,pipeline,pipelines,2500,) | `84.733% <100%> (+0.237%)` | `49 <1> (+1)` | :arrow_up: |; | [...titute/hellbender/engine/AssemblyRegionWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/5635/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvQXNzZW1ibHlSZWdpb25XYWxrZXIuamF2YQ==) | `86.869% <100%> (+0.41%)` | `27 <0> (+1)` | :arrow_up: |; | [...ender/engine/spark/datasources/ReadsSparkSink.java](https://codecov.io/gh/broadinstitute/gatk/pull/5635/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVhZHNTcGFya1NpbmsuamF2YQ==) | `56.944% <0%> (-2.778%)` | `17% <0%> (ø)` | |; | [...te/hellbender/tools/PrintReadsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5635/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9QcmludFJlYWRzSW50ZWdyYXRpb25UZXN0LmphdmE=) | `96.795% <0%> (ø)` | `26% <0%> (ø)` | :arrow_down: |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5635/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `90.741% <0%> (ø)` | `13% <0%> (ø)` | :arrow_down: |; | [...hellbender/tools/spark/pipelines/SortSamSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5635/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvU29ydFNhbVNwYXJrLmphdmE=) | `100% <0%> (ø)` | `5% <0%> (-1%)` | :arrow_down: |; | [...ollections/IntervalsSkipListOneContigUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5635/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9jb2xsZWN0aW9ucy9JbnRlcnZhbHNTa2lwTGlzdE9uZUNvbnRpZ1VuaXRUZXN0LmphdmE=) | | | |; | [...r/utils/collections/IntervalsSkipListUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5635/diff?src=pr&el=tree#d,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5635#issuecomment-460033606
https://github.com/broadinstitute/gatk/pull/5635#issuecomment-460033606:2819,Deployability,pipeline,pipelines,2819,% <100%> (+0.41%)` | `27 <0> (+1)` | :arrow_up: |; | [...ender/engine/spark/datasources/ReadsSparkSink.java](https://codecov.io/gh/broadinstitute/gatk/pull/5635/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVhZHNTcGFya1NpbmsuamF2YQ==) | `56.944% <0%> (-2.778%)` | `17% <0%> (ø)` | |; | [...te/hellbender/tools/PrintReadsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5635/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9QcmludFJlYWRzSW50ZWdyYXRpb25UZXN0LmphdmE=) | `96.795% <0%> (ø)` | `26% <0%> (ø)` | :arrow_down: |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5635/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `90.741% <0%> (ø)` | `13% <0%> (ø)` | :arrow_down: |; | [...hellbender/tools/spark/pipelines/SortSamSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5635/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvU29ydFNhbVNwYXJrLmphdmE=) | `100% <0%> (ø)` | `5% <0%> (-1%)` | :arrow_down: |; | [...ollections/IntervalsSkipListOneContigUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5635/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9jb2xsZWN0aW9ucy9JbnRlcnZhbHNTa2lwTGlzdE9uZUNvbnRpZ1VuaXRUZXN0LmphdmE=) | | | |; | [...r/utils/collections/IntervalsSkipListUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5635/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9jb2xsZWN0aW9ucy9JbnRlcnZhbHNTa2lwTGlzdFVuaXRUZXN0LmphdmE=) | | | |; | [...broadinstitute/hellbender/engine/ContextShard.java](https://codecov.io/gh/broadinstitute/gatk/pull/5635/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5635#issuecomment-460033606
https://github.com/broadinstitute/gatk/pull/5635#issuecomment-461577642:634,Integrability,contract,contract,634,"@asmirnov239 Thanks for implementing this. After our conversation, I realized that the GATK3 version of the `--force-active` argument works a bit differently: it sets all of the individual per-locus probabilities of being active to 1.0, rather than preserving the true probabilities and just setting every region's `isActive` flag to true, as you're doing here. Ie., GATK3 does this:. ```; private void addIsActiveResult(final ActiveRegionWalker<M, T> walker,; final RefMetaDataTracker tracker, final ReferenceContext refContext,; final AlignmentContext locus) {; // must be called, even if we won't use the result, to satisfy walker contract; final ActivityProfileState state = walker.isActive( tracker, refContext, locus );; if ( walker.forceActive) state.isActiveProb = 1.0;; if ( ! walkerHasPresetRegions ) {; activityProfile.add(state);; }; }; ```. I'm not convinced that the GATK3 behavior is actually better. It almost seems preferable to me to keep the true ""is active"" probabilities intact (so that you get realistic region boundaries), and just tell the `HaplotypeCallerEngine` to treat all of the resulting regions as active, as you're doing in this branch, instead of overwriting all of the isActive probabilities with 1.0 as GATK3 did. But maybe there is a good argument in favor of the GATK 3 behavior. Let's see what other people think -- @ldgauthier @davidbenjamin could you please weigh in as to which of the two `--force-active` implementations described above you'd prefer? Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5635#issuecomment-461577642
https://github.com/broadinstitute/gatk/issues/5637#issuecomment-519513091:21,Deployability,release,releases,21,Fixed in recent Disq releases,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5637#issuecomment-519513091
https://github.com/broadinstitute/gatk/issues/5644#issuecomment-461596252:104,Deployability,pipeline,pipeline,104,"@tomwhite yes, this is the same problem we were seeing. Thanks much for the fix. We will try to run the pipeline again with the fix. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5644#issuecomment-461596252
https://github.com/broadinstitute/gatk/pull/5645#issuecomment-460657077:3494,Availability,down,downsampling,3494,> (-32%)` | |; | [.../utils/reference/FastaReferenceWriterUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5645/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWZlcmVuY2UvRmFzdGFSZWZlcmVuY2VXcml0ZXJVbml0VGVzdC5qYXZh) | `62.443% <0%> (-22.696%)` | `33% <0%> (-37%)` | |; | [...ellbender/tools/walkers/vqsr/CNNScoreVariants.java](https://codecov.io/gh/broadinstitute/gatk/pull/5645/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3Zxc3IvQ05OU2NvcmVWYXJpYW50cy5qYXZh) | `58.387% <0%> (-22.057%)` | `33% <0%> (-12%)` | |; | [.../walkers/vqsr/CNNScoreVariantsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5645/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3Zxc3IvQ05OU2NvcmVWYXJpYW50c0ludGVncmF0aW9uVGVzdC5qYXZh) | `78.534% <0%> (-21.466%)` | `8% <0%> (-5%)` | |; | [...ownsampling/ReadsDownsamplingIteratorUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5645/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvUmVhZHNEb3duc2FtcGxpbmdJdGVyYXRvclVuaXRUZXN0LmphdmE=) | `51.724% <0%> (-20.407%)` | `7% <0%> (-4%)` | |; | [...ender/utils/downsampling/ReservoirDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/5645/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvUmVzZXJ2b2lyRG93bnNhbXBsZXIuamF2YQ==) | `86.301% <0%> (-13.699%)` | `33% <0%> (+6%)` | |; | [...ils/downsampling/ReservoirDownsamplerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5645/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvUmVzZXJ2b2lyRG93bnNhbXBsZXJVbml0VGVzdC5qYXZh) | `77.273% <0%> (-10.356%)` | `13% <0%> (ø)` | |; | ... and [18 more](https://codecov.io/gh/broadinstitute/gatk/pull/5645/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5645#issuecomment-460657077
https://github.com/broadinstitute/gatk/pull/5645#issuecomment-460657077:3795,Availability,down,downsampling,3795,> (-32%)` | |; | [.../utils/reference/FastaReferenceWriterUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5645/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWZlcmVuY2UvRmFzdGFSZWZlcmVuY2VXcml0ZXJVbml0VGVzdC5qYXZh) | `62.443% <0%> (-22.696%)` | `33% <0%> (-37%)` | |; | [...ellbender/tools/walkers/vqsr/CNNScoreVariants.java](https://codecov.io/gh/broadinstitute/gatk/pull/5645/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3Zxc3IvQ05OU2NvcmVWYXJpYW50cy5qYXZh) | `58.387% <0%> (-22.057%)` | `33% <0%> (-12%)` | |; | [.../walkers/vqsr/CNNScoreVariantsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5645/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3Zxc3IvQ05OU2NvcmVWYXJpYW50c0ludGVncmF0aW9uVGVzdC5qYXZh) | `78.534% <0%> (-21.466%)` | `8% <0%> (-5%)` | |; | [...ownsampling/ReadsDownsamplingIteratorUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5645/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvUmVhZHNEb3duc2FtcGxpbmdJdGVyYXRvclVuaXRUZXN0LmphdmE=) | `51.724% <0%> (-20.407%)` | `7% <0%> (-4%)` | |; | [...ender/utils/downsampling/ReservoirDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/5645/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvUmVzZXJ2b2lyRG93bnNhbXBsZXIuamF2YQ==) | `86.301% <0%> (-13.699%)` | `33% <0%> (+6%)` | |; | [...ils/downsampling/ReservoirDownsamplerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5645/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvUmVzZXJ2b2lyRG93bnNhbXBsZXJVbml0VGVzdC5qYXZh) | `77.273% <0%> (-10.356%)` | `13% <0%> (ø)` | |; | ... and [18 more](https://codecov.io/gh/broadinstitute/gatk/pull/5645/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5645#issuecomment-460657077
https://github.com/broadinstitute/gatk/pull/5645#issuecomment-460657077:957,Deployability,pipeline,pipelines,957,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5645?src=pr&el=h1) Report; > Merging [#5645](https://codecov.io/gh/broadinstitute/gatk/pull/5645?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/c176be2d7fc1caab8616ec8dbb41a5cb5a8c0a71?src=pr&el=desc) will **decrease** coverage by `0.594%`.; > The diff coverage is `0%`. ```diff; @@ Coverage Diff @@; ## master #5645 +/- ##; ===============================================; - Coverage 87.035% 86.441% -0.594% ; - Complexity 31726 31896 +170 ; ===============================================; Files 1943 1943 ; Lines 146193 148531 +2338 ; Branches 16141 16607 +466 ; ===============================================; + Hits 127239 128391 +1152 ; - Misses 13067 14170 +1103 ; - Partials 5887 5970 +83; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5645?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5645/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `90.741% <0%> (ø)` | `13 <0> (ø)` | :arrow_down: |; | [...ols/funcotator/FuncotatorDataSourceDownloader.java](https://codecov.io/gh/broadinstitute/gatk/pull/5645/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0Z1bmNvdGF0b3JEYXRhU291cmNlRG93bmxvYWRlci5qYXZh) | `37.008% <0%> (-29.189%)` | `9% <0%> (-5%)` | |; | [...llbender/utils/reference/FastaReferenceWriter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5645/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWZlcmVuY2UvRmFzdGFSZWZlcmVuY2VXcml0ZXIuamF2YQ==) | `64.593% <0%> (-27.872%)` | `48% <0%> (-3%)` | |; | [...ces/gencode/GencodeFuncotationFactoryUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5645/diff?src=pr&el=tree#diff-,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5645#issuecomment-460657077
https://github.com/broadinstitute/gatk/issues/5649#issuecomment-462058940:380,Modifiability,extend,extended,380,"To provide some more background, the idea is to generate output as generated by [CollectAllelicCounts](https://software.broadinstitute.org/gatk/documentation/tooldocs/current/org_broadinstitute_hellbender_tools_copynumber_CollectAllelicCounts.php) for a pool of normals so that we can correct allelic biases in tumor-only. Would it be possible that CreateSomaticPanelofNormals is extended to cover the CollectAllelicCounts ""special case""? . @samuelklee @davidbenjamin.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5649#issuecomment-462058940
https://github.com/broadinstitute/gatk/issues/5649#issuecomment-463510176:120,Testability,test,testing,120,"This is now in PR: #5675. FilterMutectCalls is not yet hooked up to exploit any of this new information, but we will be testing ideas for that soon.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5649#issuecomment-463510176
https://github.com/broadinstitute/gatk/issues/5649#issuecomment-523620653:379,Energy Efficiency,power,powerful,379,"@lima1 The beta binomial fit ignores germline variantion. That is, if you have a variant that shows up sometimes as an artifact and sometimes as a germline variant, the tool fits only the allele fractions of the samples where it seems to be an artifact. The `FRACTION` field excludes germline variation. This is done intentionally because the `-germline-resource` is a much more powerful tool for germline filtering than a panel of normals.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5649#issuecomment-523620653
https://github.com/broadinstitute/gatk/issues/5650#issuecomment-461842780:73,Testability,test,test,73,"Great-- can do, it will take a little bit for me to put together a small test case. While I'm doing that I'll see if passing that flag will fix it. Thanks so much.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5650#issuecomment-461842780
https://github.com/broadinstitute/gatk/issues/5650#issuecomment-462148064:187,Availability,down,down,187,"Hi everyone,. I put together as small a test case as I could here: https://www.dropbox.com/s/p7x3jt6lgxesc23/gatk-missingalt-testdata.tar.gz?dl=1. Some observations that might help track down the source of the bug:. 1. Subsetting the BAM file to within 100 bases of the call with the missing alt results in files that cannot reproduce this behavior, it needs to be a larger window.; 2. If you call individually instead of in batch mode none of the individual calls have the missing variant on this test data. This example dataset results in one call with a missing ALT:. ```; GL000216.1	67968	.	C	.	39.74	.	AN=38;DP=74;MMQ=60;MQ=59.82	GT:AD:DP	0/0:1:1	0/0:0:0	0/0:5:5	0/0:3:3	0/0:6:6	0/0:6:6	0/0:2:2	0/0:1:1	0/0:2:2	0/0:5:5	0/0:5:5	0/0:4:4	0/0:9:9	0/0:4:4	0/0:2:2	0/0:2:2	0/0:0:0	0/0:10:10	0/0:7:7; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5650#issuecomment-462148064
https://github.com/broadinstitute/gatk/issues/5650#issuecomment-462148064:40,Testability,test,test,40,"Hi everyone,. I put together as small a test case as I could here: https://www.dropbox.com/s/p7x3jt6lgxesc23/gatk-missingalt-testdata.tar.gz?dl=1. Some observations that might help track down the source of the bug:. 1. Subsetting the BAM file to within 100 bases of the call with the missing alt results in files that cannot reproduce this behavior, it needs to be a larger window.; 2. If you call individually instead of in batch mode none of the individual calls have the missing variant on this test data. This example dataset results in one call with a missing ALT:. ```; GL000216.1	67968	.	C	.	39.74	.	AN=38;DP=74;MMQ=60;MQ=59.82	GT:AD:DP	0/0:1:1	0/0:0:0	0/0:5:5	0/0:3:3	0/0:6:6	0/0:6:6	0/0:2:2	0/0:1:1	0/0:2:2	0/0:5:5	0/0:5:5	0/0:4:4	0/0:9:9	0/0:4:4	0/0:2:2	0/0:2:2	0/0:0:0	0/0:10:10	0/0:7:7; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5650#issuecomment-462148064
https://github.com/broadinstitute/gatk/issues/5650#issuecomment-462148064:125,Testability,test,testdata,125,"Hi everyone,. I put together as small a test case as I could here: https://www.dropbox.com/s/p7x3jt6lgxesc23/gatk-missingalt-testdata.tar.gz?dl=1. Some observations that might help track down the source of the bug:. 1. Subsetting the BAM file to within 100 bases of the call with the missing alt results in files that cannot reproduce this behavior, it needs to be a larger window.; 2. If you call individually instead of in batch mode none of the individual calls have the missing variant on this test data. This example dataset results in one call with a missing ALT:. ```; GL000216.1	67968	.	C	.	39.74	.	AN=38;DP=74;MMQ=60;MQ=59.82	GT:AD:DP	0/0:1:1	0/0:0:0	0/0:5:5	0/0:3:3	0/0:6:6	0/0:6:6	0/0:2:2	0/0:1:1	0/0:2:2	0/0:5:5	0/0:5:5	0/0:4:4	0/0:9:9	0/0:4:4	0/0:2:2	0/0:2:2	0/0:0:0	0/0:10:10	0/0:7:7; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5650#issuecomment-462148064
https://github.com/broadinstitute/gatk/issues/5650#issuecomment-462148064:498,Testability,test,test,498,"Hi everyone,. I put together as small a test case as I could here: https://www.dropbox.com/s/p7x3jt6lgxesc23/gatk-missingalt-testdata.tar.gz?dl=1. Some observations that might help track down the source of the bug:. 1. Subsetting the BAM file to within 100 bases of the call with the missing alt results in files that cannot reproduce this behavior, it needs to be a larger window.; 2. If you call individually instead of in batch mode none of the individual calls have the missing variant on this test data. This example dataset results in one call with a missing ALT:. ```; GL000216.1	67968	.	C	.	39.74	.	AN=38;DP=74;MMQ=60;MQ=59.82	GT:AD:DP	0/0:1:1	0/0:0:0	0/0:5:5	0/0:3:3	0/0:6:6	0/0:6:6	0/0:2:2	0/0:1:1	0/0:2:2	0/0:5:5	0/0:5:5	0/0:4:4	0/0:9:9	0/0:4:4	0/0:2:2	0/0:2:2	0/0:0:0	0/0:10:10	0/0:7:7; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5650#issuecomment-462148064
https://github.com/broadinstitute/gatk/issues/5650#issuecomment-462158749:47,Deployability,release,release,47,"@roryk Did this bug occur in the previous GATK release (4.0.12.0) as well, or is 4.1.0.0 literally the very first release with this issue?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5650#issuecomment-462158749
https://github.com/broadinstitute/gatk/issues/5650#issuecomment-462158749:114,Deployability,release,release,114,"@roryk Did this bug occur in the previous GATK release (4.0.12.0) as well, or is 4.1.0.0 literally the very first release with this issue?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5650#issuecomment-462158749
https://github.com/broadinstitute/gatk/issues/5650#issuecomment-462463555:34,Testability,test,test,34,Thanks for the beautifully svelte test data @roryk ! I'll take a look this week. Did the workaround I suggested fix your issue?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5650#issuecomment-462463555
https://github.com/broadinstitute/gatk/issues/5650#issuecomment-462474405:116,Deployability,install,installed,116,"Sorry @ldgauthier, I forgot to test that, I'll do it now. Props for using the word svelte. @droazen-- we have gatk4 installed and updated via bioconda, so I'm not super sure exactly which versions had this problem, just that the current version. If it would help I could roll back `gatk4` to `4.0.12.0` and see if the issue was there as well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5650#issuecomment-462474405
https://github.com/broadinstitute/gatk/issues/5650#issuecomment-462474405:130,Deployability,update,updated,130,"Sorry @ldgauthier, I forgot to test that, I'll do it now. Props for using the word svelte. @droazen-- we have gatk4 installed and updated via bioconda, so I'm not super sure exactly which versions had this problem, just that the current version. If it would help I could roll back `gatk4` to `4.0.12.0` and see if the issue was there as well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5650#issuecomment-462474405
https://github.com/broadinstitute/gatk/issues/5650#issuecomment-462474405:31,Testability,test,test,31,"Sorry @ldgauthier, I forgot to test that, I'll do it now. Props for using the word svelte. @droazen-- we have gatk4 installed and updated via bioconda, so I'm not super sure exactly which versions had this problem, just that the current version. If it would help I could roll back `gatk4` to `4.0.12.0` and see if the issue was there as well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5650#issuecomment-462474405
https://github.com/broadinstitute/gatk/issues/5650#issuecomment-462501641:323,Testability,test,test,323,"The workaround looked good on the sample you gave me, but I'm pretty sure I found the issue so a fix is not far off. The * allele is causing problems again. It happens at a multi-allelic with a low quality alt, so it's not a *-only site, but the real alt gets dropped by the QUAL filter. I just need to put in a regression test before I submit the PR. Also, I'm taking out the repeated instances of `DepthPerSampleHC - Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null` (i.e. there will be just one in the log) because that was annoying me.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5650#issuecomment-462501641
https://github.com/broadinstitute/gatk/issues/5650#issuecomment-462501641:545,Testability,log,log,545,"The workaround looked good on the sample you gave me, but I'm pretty sure I found the issue so a fix is not far off. The * allele is causing problems again. It happens at a multi-allelic with a low quality alt, so it's not a *-only site, but the real alt gets dropped by the QUAL filter. I just need to put in a regression test before I submit the PR. Also, I'm taking out the repeated instances of `DepthPerSampleHC - Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null` (i.e. there will be just one in the log) because that was annoying me.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5650#issuecomment-462501641
https://github.com/broadinstitute/gatk/issues/5650#issuecomment-462502271:59,Testability,test,test,59,"Awesome, thanks so much. Your workaround does work on that test set. That's a bonus: that warning spam was annoying the heck out of me too.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5650#issuecomment-462502271
https://github.com/broadinstitute/gatk/issues/5651#issuecomment-475723987:118,Usability,clear,clear,118,"I don't want to make any changes to phasing until the new assembly modifications are done, because I expect that will clear up a lot of lost sensitivity.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5651#issuecomment-475723987
https://github.com/broadinstitute/gatk/issues/5651#issuecomment-712158375:206,Deployability,integrat,integration,206,"I have a version of this working in the branch `cw_phase_star_allele`, but am holding off on making a PR until https://github.com/broadinstitute/gatk/pull/6859 can be merged to avoid conflicting changes to integration test files.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5651#issuecomment-712158375
https://github.com/broadinstitute/gatk/issues/5651#issuecomment-712158375:206,Integrability,integrat,integration,206,"I have a version of this working in the branch `cw_phase_star_allele`, but am holding off on making a PR until https://github.com/broadinstitute/gatk/pull/6859 can be merged to avoid conflicting changes to integration test files.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5651#issuecomment-712158375
https://github.com/broadinstitute/gatk/issues/5651#issuecomment-712158375:177,Safety,avoid,avoid,177,"I have a version of this working in the branch `cw_phase_star_allele`, but am holding off on making a PR until https://github.com/broadinstitute/gatk/pull/6859 can be merged to avoid conflicting changes to integration test files.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5651#issuecomment-712158375
https://github.com/broadinstitute/gatk/issues/5651#issuecomment-712158375:218,Testability,test,test,218,"I have a version of this working in the branch `cw_phase_star_allele`, but am holding off on making a PR until https://github.com/broadinstitute/gatk/pull/6859 can be merged to avoid conflicting changes to integration test files.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5651#issuecomment-712158375
https://github.com/broadinstitute/gatk/issues/5654#issuecomment-572203804:86,Security,validat,validated,86,@takutosato We don't need to do this. The read orientation model is sufficiently well-validated.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5654#issuecomment-572203804
https://github.com/broadinstitute/gatk/pull/5655#issuecomment-461966772:2580,Deployability,Update,UpdateVCFSequenceDictionary,2580,> (ø)` | :arrow_down: |; | [...der/engine/spark/datasources/ReadsSparkSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/5655/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVhZHNTcGFya1NvdXJjZS5qYXZh) | `49.333% <ø> (ø)` | `13 <0> (ø)` | :arrow_down: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5655/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `70.667% <100%> (+1.484%)` | `35 <0> (ø)` | :arrow_down: |; | [...kers/haplotypecaller/ReferenceConfidenceModel.java](https://codecov.io/gh/broadinstitute/gatk/pull/5655/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9SZWZlcmVuY2VDb25maWRlbmNlTW9kZWwuamF2YQ==) | `92.632% <100%> (+1.265%)` | `70 <0> (-48)` | :arrow_down: |; | [...kers/variantutils/UpdateVCFSequenceDictionary.java](https://codecov.io/gh/broadinstitute/gatk/pull/5655/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9VcGRhdGVWQ0ZTZXF1ZW5jZURpY3Rpb25hcnkuamF2YQ==) | `88.462% <85.714%> (+3.716%)` | `16 <5> (-3)` | :arrow_down: |; | [...ls/UpdateVCFSequenceDictionaryIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5655/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9VcGRhdGVWQ0ZTZXF1ZW5jZURpY3Rpb25hcnlJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `92.727% <92.857%> (+45.166%)` | `16 <6> (+6)` | :arrow_up: |; | [...nder/utils/io/DeleteRecursivelyOnExitPathHook.java](https://codecov.io/gh/broadinstitute/gatk/pull/5655/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9pby9EZWxldGVSZWN1cnNpdmVseU9uRXhpdFBhdGhIb29rLmphdmE=) | `70% <0%> (-15%)` | `3% <0%> (-1%)` | |; | ... and [1 more](https,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5655#issuecomment-461966772
https://github.com/broadinstitute/gatk/pull/5655#issuecomment-461966772:2908,Deployability,Update,UpdateVCFSequenceDictionaryIntegrationTest,2908,.java](https://codecov.io/gh/broadinstitute/gatk/pull/5655/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVhZHNTcGFya1NvdXJjZS5qYXZh) | `49.333% <ø> (ø)` | `13 <0> (ø)` | :arrow_down: |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5655/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9nY3MvQnVja2V0VXRpbHMuamF2YQ==) | `70.667% <100%> (+1.484%)` | `35 <0> (ø)` | :arrow_down: |; | [...kers/haplotypecaller/ReferenceConfidenceModel.java](https://codecov.io/gh/broadinstitute/gatk/pull/5655/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9SZWZlcmVuY2VDb25maWRlbmNlTW9kZWwuamF2YQ==) | `92.632% <100%> (+1.265%)` | `70 <0> (-48)` | :arrow_down: |; | [...kers/variantutils/UpdateVCFSequenceDictionary.java](https://codecov.io/gh/broadinstitute/gatk/pull/5655/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9VcGRhdGVWQ0ZTZXF1ZW5jZURpY3Rpb25hcnkuamF2YQ==) | `88.462% <85.714%> (+3.716%)` | `16 <5> (-3)` | :arrow_down: |; | [...ls/UpdateVCFSequenceDictionaryIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5655/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9VcGRhdGVWQ0ZTZXF1ZW5jZURpY3Rpb25hcnlJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `92.727% <92.857%> (+45.166%)` | `16 <6> (+6)` | :arrow_up: |; | [...nder/utils/io/DeleteRecursivelyOnExitPathHook.java](https://codecov.io/gh/broadinstitute/gatk/pull/5655/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9pby9EZWxldGVSZWN1cnNpdmVseU9uRXhpdFBhdGhIb29rLmphdmE=) | `70% <0%> (-15%)` | `3% <0%> (-1%)` | |; | ... and [1 more](https://codecov.io/gh/broadinstitute/gatk/pull/5655/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5655#issuecomment-461966772
https://github.com/broadinstitute/gatk/pull/5656#issuecomment-462418780:16,Testability,test,tests,16,This is failing tests.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5656#issuecomment-462418780
https://github.com/broadinstitute/gatk/pull/5656#issuecomment-462507730:39,Testability,test,tests,39,@lbergelson Is this good to merge when tests pass?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5656#issuecomment-462507730
https://github.com/broadinstitute/gatk/issues/5657#issuecomment-462375938:49,Deployability,release,release,49,This PR is now merged and changes will be in the release after v4.1.0.0.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5657#issuecomment-462375938
https://github.com/broadinstitute/gatk/pull/5658#issuecomment-462369317:89,Deployability,update,updates,89,"Going forward, @droazen, who should we ask that for review for these minor documentation updates?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5658#issuecomment-462369317
https://github.com/broadinstitute/gatk/pull/5658#issuecomment-462371578:71,Usability,simpl,simple,71,"@sooheelee Anyone on engine team is a good bet to ask for a review for simple documentation changes like this. For more tool specific complex documentation changes, the tool author/maintainer is probably best.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5658#issuecomment-462371578
https://github.com/broadinstitute/gatk/issues/5660#issuecomment-463020005:297,Availability,ERROR,ERROR,297,"This seems to be a regression with GATK 4.1.0.0. The code does check for compatible versions before beginning traversal. However, the following log was reported using the M2 WDL:; ```; Runtime.totalMemory()=58851328; ***********************************************************************. A USER ERROR has occurred: Bad input: Config file for datasource (file:///cromwell_root/funcotator_dataSources.v1.4.20180615/gencode/hg19/gencode.config) does not contain required key: ""ncbi_build_version"". ***********************************************************************; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5660#issuecomment-463020005
https://github.com/broadinstitute/gatk/issues/5660#issuecomment-463020005:328,Modifiability,Config,Config,328,"This seems to be a regression with GATK 4.1.0.0. The code does check for compatible versions before beginning traversal. However, the following log was reported using the M2 WDL:; ```; Runtime.totalMemory()=58851328; ***********************************************************************. A USER ERROR has occurred: Bad input: Config file for datasource (file:///cromwell_root/funcotator_dataSources.v1.4.20180615/gencode/hg19/gencode.config) does not contain required key: ""ncbi_build_version"". ***********************************************************************; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5660#issuecomment-463020005
https://github.com/broadinstitute/gatk/issues/5660#issuecomment-463020005:436,Modifiability,config,config,436,"This seems to be a regression with GATK 4.1.0.0. The code does check for compatible versions before beginning traversal. However, the following log was reported using the M2 WDL:; ```; Runtime.totalMemory()=58851328; ***********************************************************************. A USER ERROR has occurred: Bad input: Config file for datasource (file:///cromwell_root/funcotator_dataSources.v1.4.20180615/gencode/hg19/gencode.config) does not contain required key: ""ncbi_build_version"". ***********************************************************************; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5660#issuecomment-463020005
https://github.com/broadinstitute/gatk/issues/5660#issuecomment-463020005:144,Testability,log,log,144,"This seems to be a regression with GATK 4.1.0.0. The code does check for compatible versions before beginning traversal. However, the following log was reported using the M2 WDL:; ```; Runtime.totalMemory()=58851328; ***********************************************************************. A USER ERROR has occurred: Bad input: Config file for datasource (file:///cromwell_root/funcotator_dataSources.v1.4.20180615/gencode/hg19/gencode.config) does not contain required key: ""ncbi_build_version"". ***********************************************************************; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5660#issuecomment-463020005
https://github.com/broadinstitute/gatk/pull/5661#issuecomment-477729458:140,Testability,test,test,140,"As discussed in person with @ldgauthier and @davidbenjamin, the final merged version of this PR didn't contain the actual bug fix (just the test).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5661#issuecomment-477729458
https://github.com/broadinstitute/gatk/pull/5663#issuecomment-462836865:168,Availability,error,error,168,"My concern is that this Annotation only works if a pedigree file is supplied, not if the user supplies FounderIDs but i'm not sure the best way to handle that (with an error or a warning or some such).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5663#issuecomment-462836865
https://github.com/broadinstitute/gatk/pull/5663#issuecomment-462850860:3187,Deployability,pipeline,pipelines,3187,7 <0> (ø)` | :arrow_down: |; | [...bender/tools/walkers/annotator/PossibleDeNovo.java](https://codecov.io/gh/broadinstitute/gatk/pull/5663/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9Qb3NzaWJsZURlTm92by5qYXZh) | `73.214% <61.905%> (-2.976%)` | `23 <5> (+9)` | |; | [...er/tools/walkers/annotator/PedigreeAnnotation.java](https://codecov.io/gh/broadinstitute/gatk/pull/5663/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9QZWRpZ3JlZUFubm90YXRpb24uamF2YQ==) | `89.189% <84.211%> (-6.463%)` | `13 <4> (+5)` | |; | [...ct/CreateSomaticPanelOfNormalsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5663/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9DcmVhdGVTb21hdGljUGFuZWxPZk5vcm1hbHNJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `3.448% <0%> (-96.552%)` | `2% <0%> (-1%)` | |; | [...k/pipelines/ReadsPipelineSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5663/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrSW50ZWdyYXRpb25UZXN0LmphdmE=) | `1.563% <0%> (-95.313%)` | `1% <0%> (-6%)` | |; | [...adinstitute/hellbender/utils/IntegrationUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5663/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9JbnRlZ3JhdGlvblV0aWxzLmphdmE=) | `0% <0%> (-95.238%)` | `0% <0%> (-5%)` | |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5663/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `0% <0%> (-90.741%)` | `0% <0%> (-13%)` | |; | ... and [220 more](https://codecov.io/gh/broadinstitute/gatk/pull/5663/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5663#issuecomment-462850860
https://github.com/broadinstitute/gatk/pull/5663#issuecomment-462850860:3541,Deployability,Integrat,IntegrationUtils,3541,7 <0> (ø)` | :arrow_down: |; | [...bender/tools/walkers/annotator/PossibleDeNovo.java](https://codecov.io/gh/broadinstitute/gatk/pull/5663/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9Qb3NzaWJsZURlTm92by5qYXZh) | `73.214% <61.905%> (-2.976%)` | `23 <5> (+9)` | |; | [...er/tools/walkers/annotator/PedigreeAnnotation.java](https://codecov.io/gh/broadinstitute/gatk/pull/5663/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9QZWRpZ3JlZUFubm90YXRpb24uamF2YQ==) | `89.189% <84.211%> (-6.463%)` | `13 <4> (+5)` | |; | [...ct/CreateSomaticPanelOfNormalsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5663/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9DcmVhdGVTb21hdGljUGFuZWxPZk5vcm1hbHNJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `3.448% <0%> (-96.552%)` | `2% <0%> (-1%)` | |; | [...k/pipelines/ReadsPipelineSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5663/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrSW50ZWdyYXRpb25UZXN0LmphdmE=) | `1.563% <0%> (-95.313%)` | `1% <0%> (-6%)` | |; | [...adinstitute/hellbender/utils/IntegrationUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5663/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9JbnRlZ3JhdGlvblV0aWxzLmphdmE=) | `0% <0%> (-95.238%)` | `0% <0%> (-5%)` | |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5663/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `0% <0%> (-90.741%)` | `0% <0%> (-13%)` | |; | ... and [220 more](https://codecov.io/gh/broadinstitute/gatk/pull/5663/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5663#issuecomment-462850860
https://github.com/broadinstitute/gatk/pull/5663#issuecomment-462850860:3808,Deployability,pipeline,pipelines,3808,7 <0> (ø)` | :arrow_down: |; | [...bender/tools/walkers/annotator/PossibleDeNovo.java](https://codecov.io/gh/broadinstitute/gatk/pull/5663/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9Qb3NzaWJsZURlTm92by5qYXZh) | `73.214% <61.905%> (-2.976%)` | `23 <5> (+9)` | |; | [...er/tools/walkers/annotator/PedigreeAnnotation.java](https://codecov.io/gh/broadinstitute/gatk/pull/5663/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9QZWRpZ3JlZUFubm90YXRpb24uamF2YQ==) | `89.189% <84.211%> (-6.463%)` | `13 <4> (+5)` | |; | [...ct/CreateSomaticPanelOfNormalsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5663/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9DcmVhdGVTb21hdGljUGFuZWxPZk5vcm1hbHNJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `3.448% <0%> (-96.552%)` | `2% <0%> (-1%)` | |; | [...k/pipelines/ReadsPipelineSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5663/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrSW50ZWdyYXRpb25UZXN0LmphdmE=) | `1.563% <0%> (-95.313%)` | `1% <0%> (-6%)` | |; | [...adinstitute/hellbender/utils/IntegrationUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5663/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9JbnRlZ3JhdGlvblV0aWxzLmphdmE=) | `0% <0%> (-95.238%)` | `0% <0%> (-5%)` | |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5663/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `0% <0%> (-90.741%)` | `0% <0%> (-13%)` | |; | ... and [220 more](https://codecov.io/gh/broadinstitute/gatk/pull/5663/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5663#issuecomment-462850860
https://github.com/broadinstitute/gatk/pull/5663#issuecomment-462850860:3541,Integrability,Integrat,IntegrationUtils,3541,7 <0> (ø)` | :arrow_down: |; | [...bender/tools/walkers/annotator/PossibleDeNovo.java](https://codecov.io/gh/broadinstitute/gatk/pull/5663/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9Qb3NzaWJsZURlTm92by5qYXZh) | `73.214% <61.905%> (-2.976%)` | `23 <5> (+9)` | |; | [...er/tools/walkers/annotator/PedigreeAnnotation.java](https://codecov.io/gh/broadinstitute/gatk/pull/5663/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9QZWRpZ3JlZUFubm90YXRpb24uamF2YQ==) | `89.189% <84.211%> (-6.463%)` | `13 <4> (+5)` | |; | [...ct/CreateSomaticPanelOfNormalsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5663/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9DcmVhdGVTb21hdGljUGFuZWxPZk5vcm1hbHNJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `3.448% <0%> (-96.552%)` | `2% <0%> (-1%)` | |; | [...k/pipelines/ReadsPipelineSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5663/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrSW50ZWdyYXRpb25UZXN0LmphdmE=) | `1.563% <0%> (-95.313%)` | `1% <0%> (-6%)` | |; | [...adinstitute/hellbender/utils/IntegrationUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5663/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9JbnRlZ3JhdGlvblV0aWxzLmphdmE=) | `0% <0%> (-95.238%)` | `0% <0%> (-5%)` | |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5663/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `0% <0%> (-90.741%)` | `0% <0%> (-13%)` | |; | ... and [220 more](https://codecov.io/gh/broadinstitute/gatk/pull/5663/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5663#issuecomment-462850860
https://github.com/broadinstitute/gatk/pull/5663#issuecomment-463263757:203,Modifiability,refactor,refactored,203,"@ldgauthier @jamesemery If `PossibleDeNovo` can't work with just founderIDs, then the constructor that takes a set of founderIDs should be removed (??) Or better yet, should the base `Pedigree` class be refactored to make more explicit the distinction between annotation subclasses that require the full pedigree and those that just require the founderIDs (perhaps as a separate PR) ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5663#issuecomment-463263757
https://github.com/broadinstitute/gatk/pull/5663#issuecomment-463278863:298,Modifiability,plugin,plugin,298,"@cmnbroad I agree disabling some of the functionality should probably be done, I'll consider that a review comment. As to generalizing this disabling of the founderIDs, I would ere on the side of not doing it, since at the very least right now all the pedigree arguments are being populated by the plugin manager and not the annotations. I wouldn't know what to do in the case where the user asked for a pedigree annotation that did take founderIDs and one that didn't, how should that be resolved? As of right now the pedigree file and founderIDs get merged which seems sensible for other tools. Perhaps emit a warning for PossibleDenovo?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5663#issuecomment-463278863
https://github.com/broadinstitute/gatk/pull/5663#issuecomment-463372550:400,Modifiability,plugin,plugin,400,"Maybe I misunderstand the underlying model, but if some Pedigree annotations only need to know which samples are founders (ExcessHet ?) , and some need to know the full relationships (PossibleDeNovo), then I'm suggesting we change the class hierarchy to reflect that:. PedigreeAnnotation; |--TrioAnnotation; |----PossibleDeNovo; |--ExcessHet (assuming ExcessHet only needs founders...); ... Then the plugin could deterministically validate whether the user has provided sufficient args for the set of requested annotations; and if so, propagate them accordingly. A TrioAnnotation could only be populated (from the command line at least) from a file, whereas the others could be populated from either a file or just a set of IDs. I think it would simplify the annotations.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5663#issuecomment-463372550
https://github.com/broadinstitute/gatk/pull/5663#issuecomment-463372550:431,Security,validat,validate,431,"Maybe I misunderstand the underlying model, but if some Pedigree annotations only need to know which samples are founders (ExcessHet ?) , and some need to know the full relationships (PossibleDeNovo), then I'm suggesting we change the class hierarchy to reflect that:. PedigreeAnnotation; |--TrioAnnotation; |----PossibleDeNovo; |--ExcessHet (assuming ExcessHet only needs founders...); ... Then the plugin could deterministically validate whether the user has provided sufficient args for the set of requested annotations; and if so, propagate them accordingly. A TrioAnnotation could only be populated (from the command line at least) from a file, whereas the others could be populated from either a file or just a set of IDs. I think it would simplify the annotations.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5663#issuecomment-463372550
https://github.com/broadinstitute/gatk/pull/5663#issuecomment-463372550:746,Usability,simpl,simplify,746,"Maybe I misunderstand the underlying model, but if some Pedigree annotations only need to know which samples are founders (ExcessHet ?) , and some need to know the full relationships (PossibleDeNovo), then I'm suggesting we change the class hierarchy to reflect that:. PedigreeAnnotation; |--TrioAnnotation; |----PossibleDeNovo; |--ExcessHet (assuming ExcessHet only needs founders...); ... Then the plugin could deterministically validate whether the user has provided sufficient args for the set of requested annotations; and if so, propagate them accordingly. A TrioAnnotation could only be populated (from the command line at least) from a file, whereas the others could be populated from either a file or just a set of IDs. I think it would simplify the annotations.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5663#issuecomment-463372550
https://github.com/broadinstitute/gatk/pull/5663#issuecomment-466118658:25,Security,validat,validation,25,@cmnbroad I have added a validation/warning step to the pedigree annotations. It suffers from the issue where specifying both possibleDenovo and one of the other ped annotations will not affect warning between annotations. Since I'm choosing to only spit out warnings to the user this should probably be acceptable.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5663#issuecomment-466118658
https://github.com/broadinstitute/gatk/pull/5663#issuecomment-470283695:58,Safety,avoid,avoid,58,"@cmnbroad @ldgauthier Out of curiosity, we may be able to avoid the complexity entirely if we just dropped the founderID argument from the tools. founderIDs didn't exist in gatk3, it looks like it was added to GATK4 at some point when a tool needed to produce a pedigree annotation before we had support for parsing ped files. Thoughts?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5663#issuecomment-470283695
https://github.com/broadinstitute/gatk/pull/5663#issuecomment-472576463:109,Modifiability,refactor,refactoring,109,@cmnbroad Thank you for your help with this branch. I will be happy to give a speedy review to your proposed refactoring branch once this gets in.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5663#issuecomment-472576463
https://github.com/broadinstitute/gatk/pull/5665#issuecomment-462883021:17,Deployability,integrat,integration,17,"Based off of the integration test differences, this seems to only affect reference block bases following deletions (which is expected).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5665#issuecomment-462883021
https://github.com/broadinstitute/gatk/pull/5665#issuecomment-462883021:17,Integrability,integrat,integration,17,"Based off of the integration test differences, this seems to only affect reference block bases following deletions (which is expected).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5665#issuecomment-462883021
https://github.com/broadinstitute/gatk/pull/5665#issuecomment-462883021:29,Testability,test,test,29,"Based off of the integration test differences, this seems to only affect reference block bases following deletions (which is expected).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5665#issuecomment-462883021
https://github.com/broadinstitute/gatk/pull/5665#issuecomment-462897263:970,Testability,test,testutils,970,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5665?src=pr&el=h1) Report; > Merging [#5665](https://codecov.io/gh/broadinstitute/gatk/pull/5665?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/9c22c343832d1cfc114a2efd68af1ae877adad5f?src=pr&el=desc) will **decrease** coverage by `17.044%`.; > The diff coverage is `99.535%`. ```diff; @@ Coverage Diff @@; ## master #5665 +/- ##; ===============================================; - Coverage 87.05% 70.006% -17.044% ; + Complexity 31700 25058 -6642 ; ===============================================; Files 1938 1938 ; Lines 146097 146393 +296 ; Branches 16128 16174 +46 ; ===============================================; - Hits 127178 102484 -24694 ; - Misses 13033 38882 +25849 ; + Partials 5886 5027 -859; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5665?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...dinstitute/hellbender/testutils/ReadTestUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5665/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90ZXN0dXRpbHMvUmVhZFRlc3RVdGlscy5qYXZh) | `0% <ø> (-95.455%)` | `0 <0> (-5)` | |; | [...dinstitute/hellbender/utils/pileup/ReadPileup.java](https://codecov.io/gh/broadinstitute/gatk/pull/5665/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9waWxldXAvUmVhZFBpbGV1cC5qYXZh) | `89.032% <100%> (-3.176%)` | `62 <0> (-7)` | |; | [...roadinstitute/hellbender/utils/read/ReadUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5665/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWFkL1JlYWRVdGlscy5qYXZh) | `77.752% <100%> (-2.295%)` | `202 <1> (-3)` | |; | [...lotypecaller/ReferenceConfidenceModelUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5665/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdH,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5665#issuecomment-462897263
https://github.com/broadinstitute/gatk/pull/5665#issuecomment-462922677:344,Testability,test,test,344,"Yeah, I changed it in the GATK invocation in our latest pipeilnes, but; didn't change the default params... yet. That's probably a good thing to; add to the todo list. On Tue, Feb 12, 2019 at 2:28 PM jamesemery <notifications@github.com> wrote:. > *@jamesemery* commented on this pull request.; > ------------------------------; >; > In; > src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testGVCFMode.gatk4.g.vcf; > <https://github.com/broadinstitute/gatk/pull/5665#discussion_r256111207>:; >; > > @@ -924,14 +923,16 @@; > 20	10068200	.	A	<NON_REF>	.	.	END=10068200	GT:DP:GQ:MIN_DP:PL	0/0:16:45:16:0,45,675; > 20	10068201	.	T	<NON_REF>	.	.	END=10068201	GT:DP:GQ:MIN_DP:PL	0/0:18:51:18:0,51,765; > 20	10068202	.	A	<NON_REF>	.	.	END=10068203	GT:DP:GQ:MIN_DP:PL	0/0:19:54:19:0,54,810; > -20	10068204	.	A	<NON_REF>	.	.	END=10068205	GT:DP:GQ:MIN_DP:PL	0/0:21:57:20:0,57,855; > -20	10068206	.	C	<NON_REF>	.	.	END=10068206	GT:DP:GQ:MIN_DP:PL	0/0:21:54:21:0,54,810; > -20	10068207	.	C	<NON_REF>	.	.	END=10068208	GT:DP:GQ:MIN_DP:PL	0/0:22:57:21:0,57,855; > -20	10068209	.	C	<NON_REF>	.	.	END=10068209	GT:DP:GQ:MIN_DP:PL	0/0:23:63:23:0,63,945; > -20	10068210	.	T	<NON_REF>	.	.	END=10068219	GT:DP:GQ:MIN_DP:PL	0/0:27:72:26:0,72,1080; > -20	10068220	.	C	<NON_REF>	.	.	END=10068224	GT:DP:GQ:MIN_DP:PL	0/0:29:81:29:0,81,1215; > -20	10068225	.	G	<NON_REF>	.	.	END=10068225	GT:DP:GQ:MIN_DP:PL	0/0:32:90:32:0,90,1350; > -20	10068226	.	T	<NON_REF>	.	.	END=10068237	GT:DP:GQ:MIN_DP:PL	0/0:32:84:30:0,84,1260; > +20	10068204	.	A	<NON_REF>	.	.	END=10068206	GT:DP:GQ:MIN_DP:PL	0/0:21:57:20:0,57,855; >; > It looks like we block everything under 60 by single bases then block by; > 10's after that. I remember hearing some talk about improving this behavior; > elsewhere but that sounds like a discussion for another time though. Either; > way I think this branch will moderately improve our confidence after; > deletions, even if it is only a small effect.; >; > —; > You are receiving this ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5665#issuecomment-462922677
https://github.com/broadinstitute/gatk/pull/5665#issuecomment-462922677:420,Testability,test,testGVCFMode,420,"Yeah, I changed it in the GATK invocation in our latest pipeilnes, but; didn't change the default params... yet. That's probably a good thing to; add to the todo list. On Tue, Feb 12, 2019 at 2:28 PM jamesemery <notifications@github.com> wrote:. > *@jamesemery* commented on this pull request.; > ------------------------------; >; > In; > src/test/resources/org/broadinstitute/hellbender/tools/haplotypecaller/expected.testGVCFMode.gatk4.g.vcf; > <https://github.com/broadinstitute/gatk/pull/5665#discussion_r256111207>:; >; > > @@ -924,14 +923,16 @@; > 20	10068200	.	A	<NON_REF>	.	.	END=10068200	GT:DP:GQ:MIN_DP:PL	0/0:16:45:16:0,45,675; > 20	10068201	.	T	<NON_REF>	.	.	END=10068201	GT:DP:GQ:MIN_DP:PL	0/0:18:51:18:0,51,765; > 20	10068202	.	A	<NON_REF>	.	.	END=10068203	GT:DP:GQ:MIN_DP:PL	0/0:19:54:19:0,54,810; > -20	10068204	.	A	<NON_REF>	.	.	END=10068205	GT:DP:GQ:MIN_DP:PL	0/0:21:57:20:0,57,855; > -20	10068206	.	C	<NON_REF>	.	.	END=10068206	GT:DP:GQ:MIN_DP:PL	0/0:21:54:21:0,54,810; > -20	10068207	.	C	<NON_REF>	.	.	END=10068208	GT:DP:GQ:MIN_DP:PL	0/0:22:57:21:0,57,855; > -20	10068209	.	C	<NON_REF>	.	.	END=10068209	GT:DP:GQ:MIN_DP:PL	0/0:23:63:23:0,63,945; > -20	10068210	.	T	<NON_REF>	.	.	END=10068219	GT:DP:GQ:MIN_DP:PL	0/0:27:72:26:0,72,1080; > -20	10068220	.	C	<NON_REF>	.	.	END=10068224	GT:DP:GQ:MIN_DP:PL	0/0:29:81:29:0,81,1215; > -20	10068225	.	G	<NON_REF>	.	.	END=10068225	GT:DP:GQ:MIN_DP:PL	0/0:32:90:32:0,90,1350; > -20	10068226	.	T	<NON_REF>	.	.	END=10068237	GT:DP:GQ:MIN_DP:PL	0/0:32:84:30:0,84,1260; > +20	10068204	.	A	<NON_REF>	.	.	END=10068206	GT:DP:GQ:MIN_DP:PL	0/0:21:57:20:0,57,855; >; > It looks like we block everything under 60 by single bases then block by; > 10's after that. I remember hearing some talk about improving this behavior; > elsewhere but that sounds like a discussion for another time though. Either; > way I think this branch will moderately improve our confidence after; > deletions, even if it is only a small effect.; >; > —; > You are receiving this ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5665#issuecomment-462922677
https://github.com/broadinstitute/gatk/pull/5665#issuecomment-465658667:60,Energy Efficiency,reduce,reduces,60,@ldgauthier What is your verdict on this change? I think it reduces some of the legacy complexity in the reworked ReferenceConfidenceCode even if it has a small impact on the output I would estimate its moderately more correct given this change.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5665#issuecomment-465658667
https://github.com/broadinstitute/gatk/pull/5665#issuecomment-465692460:390,Energy Efficiency,reduce,reduces,390,"I agree it's more correct and the differences are very small. I remember; having a conversation about putting all the PRs that introduce changes; together or something, so go ahead and merge when it's convenient. On Wed, Feb 20, 2019 at 11:43 AM jamesemery <notifications@github.com>; wrote:. > @ldgauthier <https://github.com/ldgauthier> What is your verdict on this; > change? I think it reduces some of the legacy complexity in the reworked; > ReferenceConfidenceCode even if it has a small impact on the output I would; > estimate its moderately more correct given this change.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/5665#issuecomment-465658667>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdG_fpzMzOhs75xfs4Fj2xe4HopRPks5vPXs-gaJpZM4a3x_f>; > .; >. -- ; Laura Doyle Gauthier, Ph.D.; Associate Director, Germline Methods; Data Sciences Platform; gauthier@broadinstitute.org; Broad Institute of MIT & Harvard; 320 Charles St.; Cambridge MA 0214",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5665#issuecomment-465692460
https://github.com/broadinstitute/gatk/pull/5667#issuecomment-462937781:1594,Usability,Simpl,SimpleSVD,1594,==; Files 1938 1204 -734 ; Lines 146097 70364 -75733 ; Branches 16128 11343 -4785 ; ==============================================; - Hits 127178 45329 -81849 ; - Misses 13033 20294 +7261 ; + Partials 5886 4741 -1145; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5667?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...org/broadinstitute/hellbender/utils/MathUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5667/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9NYXRoVXRpbHMuamF2YQ==) | `48.406% <100%> (-31.194%)` | `129 <1> (-91)` | |; | [...kers/variantutils/PosteriorProbabilitiesUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5667/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9Qb3N0ZXJpb3JQcm9iYWJpbGl0aWVzVXRpbHMuamF2YQ==) | `68.944% <83.333%> (-12.466%)` | `48 <6> (-2)` | |; | [...broadinstitute/hellbender/utils/svd/SimpleSVD.java](https://codecov.io/gh/broadinstitute/gatk/pull/5667/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zdmQvU2ltcGxlU1ZELmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-5%)` | |; | [...groups/StructuralVariantDiscoveryProgramGroup.java](https://codecov.io/gh/broadinstitute/gatk/pull/5667/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL3Byb2dyYW1ncm91cHMvU3RydWN0dXJhbFZhcmlhbnREaXNjb3ZlcnlQcm9ncmFtR3JvdXAuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-3%)` | |; | [...ls/variant/writers/GVCFBlockCombiningIterator.java](https://codecov.io/gh/broadinstitute/gatk/pull/5667/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L3dyaXRlcnMvR1ZDRkJsb2NrQ29tYmluaW5nSXRlcmF0b3IuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-1%)` | |; | [...ender/utils/svd/ApacheSingularValueDecomposer.java](https://codecov.io/gh/broadinstitute/gatk/pull/5667/diff?sr,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5667#issuecomment-462937781
https://github.com/broadinstitute/gatk/issues/5670#issuecomment-463756512:159,Performance,perform,performance,159,"It seems like the problem was that the researcher was starting with a coordinate-sorted bam, whereas `MarkDuplicatesSpark` requires a name-sorted bam for good performance. @jamesemery feel free to close once you're satisfied that this is resolved, and once we've made whatever additional documentation clarifications are warranted.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5670#issuecomment-463756512
https://github.com/broadinstitute/gatk/pull/5672#issuecomment-463373944:1298,Deployability,pipeline,pipelines,1298,*decrease** coverage by `6.763%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #5672 +/- ##; ==============================================; - Coverage 87.05% 80.287% -6.763% ; + Complexity 31708 30237 -1471 ; ==============================================; Files 1940 1943 +3 ; Lines 146142 146770 +628 ; Branches 16128 16223 +95 ; ==============================================; - Hits 127216 117837 -9379 ; - Misses 13041 23220 +10179 ; + Partials 5885 5713 -172; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5672?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...transforms/markduplicates/MarkDuplicatesSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5672/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay90cmFuc2Zvcm1zL21hcmtkdXBsaWNhdGVzL01hcmtEdXBsaWNhdGVzU3BhcmsuamF2YQ==) | `94.521% <ø> (ø)` | `36 <0> (ø)` | :arrow_down: |; | [...hellbender/tools/spark/pipelines/SortSamSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5672/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvU29ydFNhbVNwYXJrLmphdmE=) | `100% <ø> (ø)` | `5 <0> (ø)` | :arrow_down: |; | [...rs/variantutils/SelectVariantsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5672/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9TZWxlY3RWYXJpYW50c0ludGVncmF0aW9uVGVzdC5qYXZh) | `0.25% <0%> (-99.75%)` | `1% <0%> (-70%)` | |; | [...kers/filters/VariantFiltrationIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5672/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2ZpbHRlcnMvVmFyaWFudEZpbHRyYXRpb25JbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `0.826% <0%> (-99.174%)` | `1% <0%> (-25%)` | |; | [...dorientation/CollectF1R2CountsIntegrationTest.java](https://codecov.io/,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5672#issuecomment-463373944
https://github.com/broadinstitute/gatk/pull/5672#issuecomment-463772659:61,Integrability,message,message,61,"Also, we should confirm that the tool itself emits a warning message to the logger when given coordinate-sorted input.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5672#issuecomment-463772659
https://github.com/broadinstitute/gatk/pull/5672#issuecomment-463772659:76,Testability,log,logger,76,"Also, we should confirm that the tool itself emits a warning message to the logger when given coordinate-sorted input.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5672#issuecomment-463772659
https://github.com/broadinstitute/gatk/pull/5672#issuecomment-466158461:11,Deployability,Update,Updated,11,"@sooheelee Updated this branch, let me know what your thoughts are (based on the google document discussion)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5672#issuecomment-466158461
https://github.com/broadinstitute/gatk/pull/5672#issuecomment-468822706:11,Deployability,Update,Updated,11,@sooheelee Updated the documentation in this branch according to the external discussion. Thoughts? Can this be merged?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5672#issuecomment-468822706
https://github.com/broadinstitute/gatk/issues/5674#issuecomment-463607139:43,Testability,test,test,43,"Yup, thx for the report. Unfortunately our test framework always creates an output file first, so it doesn't catch this. Should be an easy fix.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5674#issuecomment-463607139
https://github.com/broadinstitute/gatk/issues/5676#issuecomment-463643786:70,Deployability,update,update,70,It might be prudent to hold off on this until after #5532 so the test update is less painful.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5676#issuecomment-463643786
https://github.com/broadinstitute/gatk/issues/5676#issuecomment-463643786:65,Testability,test,test,65,It might be prudent to hold off on this until after #5532 so the test update is less painful.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5676#issuecomment-463643786
https://github.com/broadinstitute/gatk/issues/5678#issuecomment-463780367:9,Safety,safe,safe,9,Probably safe then.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5678#issuecomment-463780367
https://github.com/broadinstitute/gatk/issues/5680#issuecomment-467462740:262,Deployability,Configurat,Configuration,262,Saw it again [here](https://travis-ci.com/broadinstitute/gatk/jobs/180435353) (now restarted). If I'm reading the serialization stack in the right order:. ```; Serialization trace:; classes (sun.misc.Launcher$AppClassLoader); classLoader (org.apache.hadoop.conf.Configuration); conf (org.apache.hadoop.hdfs.DistributedFileSystem); fs (hdfs.jsr203.HadoopFileSystem); hdfs (hdfs.jsr203.HadoopPath); path (htsjdk.samtools.seekablestream.SeekablePathStream); seekableStream (htsjdk.tribble.TribbleIndexedFeatureReader); featureReader (org.broadinstitute.hellbender.engine.FeatureDataSource); featureSources (org.broadinstitute.hellbender.engine.FeatureManager); ```. it looks like we're trying to serialize a ClassLoader. The FieldSerializer does appear to use a ClassLoader to load classes during serialization.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5680#issuecomment-467462740
https://github.com/broadinstitute/gatk/issues/5680#issuecomment-467462740:262,Modifiability,Config,Configuration,262,Saw it again [here](https://travis-ci.com/broadinstitute/gatk/jobs/180435353) (now restarted). If I'm reading the serialization stack in the right order:. ```; Serialization trace:; classes (sun.misc.Launcher$AppClassLoader); classLoader (org.apache.hadoop.conf.Configuration); conf (org.apache.hadoop.hdfs.DistributedFileSystem); fs (hdfs.jsr203.HadoopFileSystem); hdfs (hdfs.jsr203.HadoopPath); path (htsjdk.samtools.seekablestream.SeekablePathStream); seekableStream (htsjdk.tribble.TribbleIndexedFeatureReader); featureReader (org.broadinstitute.hellbender.engine.FeatureDataSource); featureSources (org.broadinstitute.hellbender.engine.FeatureManager); ```. it looks like we're trying to serialize a ClassLoader. The FieldSerializer does appear to use a ClassLoader to load classes during serialization.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5680#issuecomment-467462740
https://github.com/broadinstitute/gatk/issues/5680#issuecomment-467462740:774,Performance,load,load,774,Saw it again [here](https://travis-ci.com/broadinstitute/gatk/jobs/180435353) (now restarted). If I'm reading the serialization stack in the right order:. ```; Serialization trace:; classes (sun.misc.Launcher$AppClassLoader); classLoader (org.apache.hadoop.conf.Configuration); conf (org.apache.hadoop.hdfs.DistributedFileSystem); fs (hdfs.jsr203.HadoopFileSystem); hdfs (hdfs.jsr203.HadoopPath); path (htsjdk.samtools.seekablestream.SeekablePathStream); seekableStream (htsjdk.tribble.TribbleIndexedFeatureReader); featureReader (org.broadinstitute.hellbender.engine.FeatureDataSource); featureSources (org.broadinstitute.hellbender.engine.FeatureManager); ```. it looks like we're trying to serialize a ClassLoader. The FieldSerializer does appear to use a ClassLoader to load classes during serialization.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5680#issuecomment-467462740
https://github.com/broadinstitute/gatk/issues/5680#issuecomment-469224499:458,Deployability,pipeline,pipeline,458,"I haven't been able to reproduce this locally by running `ReadsPipelineSparkIntegrationTest` repeatedly. In fact, it looks like another test is interacting with this one, since the stack trace references HDFS paths, but this test doesn't use HDFS at all. Another oddity: `TribbleIndexedFeatureReader` implies it's reading a vcf.idx file, but `HaplotypeCallerSpark`, where the exception occurs, is not reading any VCF files (although BQSR does earlier in the pipeline for known sites). Also, we shouldn't be serializing `FeatureDataSource` objects with remote resources any more, since we use Spark `--files` to copy them to the worker nodes (see https://github.com/broadinstitute/gatk/blob/master/src/main/java/org/broadinstitute/hellbender/engine/spark/GATKSparkTool.java#L699). So we shouldn't be seeing `FeatureDataSource` trying to serializing with an HDFS path. Has anyone seen this running locally on their machine, or only on Travis?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5680#issuecomment-469224499
https://github.com/broadinstitute/gatk/issues/5680#issuecomment-469224499:136,Testability,test,test,136,"I haven't been able to reproduce this locally by running `ReadsPipelineSparkIntegrationTest` repeatedly. In fact, it looks like another test is interacting with this one, since the stack trace references HDFS paths, but this test doesn't use HDFS at all. Another oddity: `TribbleIndexedFeatureReader` implies it's reading a vcf.idx file, but `HaplotypeCallerSpark`, where the exception occurs, is not reading any VCF files (although BQSR does earlier in the pipeline for known sites). Also, we shouldn't be serializing `FeatureDataSource` objects with remote resources any more, since we use Spark `--files` to copy them to the worker nodes (see https://github.com/broadinstitute/gatk/blob/master/src/main/java/org/broadinstitute/hellbender/engine/spark/GATKSparkTool.java#L699). So we shouldn't be seeing `FeatureDataSource` trying to serializing with an HDFS path. Has anyone seen this running locally on their machine, or only on Travis?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5680#issuecomment-469224499
https://github.com/broadinstitute/gatk/issues/5680#issuecomment-469224499:225,Testability,test,test,225,"I haven't been able to reproduce this locally by running `ReadsPipelineSparkIntegrationTest` repeatedly. In fact, it looks like another test is interacting with this one, since the stack trace references HDFS paths, but this test doesn't use HDFS at all. Another oddity: `TribbleIndexedFeatureReader` implies it's reading a vcf.idx file, but `HaplotypeCallerSpark`, where the exception occurs, is not reading any VCF files (although BQSR does earlier in the pipeline for known sites). Also, we shouldn't be serializing `FeatureDataSource` objects with remote resources any more, since we use Spark `--files` to copy them to the worker nodes (see https://github.com/broadinstitute/gatk/blob/master/src/main/java/org/broadinstitute/hellbender/engine/spark/GATKSparkTool.java#L699). So we shouldn't be seeing `FeatureDataSource` trying to serializing with an HDFS path. Has anyone seen this running locally on their machine, or only on Travis?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5680#issuecomment-469224499
https://github.com/broadinstitute/gatk/issues/5680#issuecomment-668654169:466,Deployability,Configurat,Configuration,466,"I think this is happening because were trying to serialize the class loader sun.misc.Launcher$AppClassLoader), which appears to be reached through the graph by way of via https://github.com/damiencarol/jsr203-hadoop/blob/master/src/main/java/hdfs/jsr203/HadoopFileSystem.java#L82. We probably need to short circuit that with a custom serializer for one of these:. Serialization trace:; classes (sun.misc.Launcher$AppClassLoader); classLoader (org.apache.hadoop.conf.Configuration); conf (org.apache.hadoop.hdfs.DistributedFileSystem); fs (hdfs.jsr203.HadoopFileSystem); hdfs (hdfs.jsr203.HadoopPath); path (htsjdk.samtools.seekablestream.SeekablePathStream); seekableStream (htsjdk.tribble.TribbleIndexedFeatureReader); featureReader (org.broadinstitute.hellbender.engine.FeatureDataSource); featureSources (org.broadinstitute.hellbender.engine.FeatureManager). See, for instance, https://github.com/dbpedia/distributed-extraction-framework/issues/9.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5680#issuecomment-668654169
https://github.com/broadinstitute/gatk/issues/5680#issuecomment-668654169:466,Modifiability,Config,Configuration,466,"I think this is happening because were trying to serialize the class loader sun.misc.Launcher$AppClassLoader), which appears to be reached through the graph by way of via https://github.com/damiencarol/jsr203-hadoop/blob/master/src/main/java/hdfs/jsr203/HadoopFileSystem.java#L82. We probably need to short circuit that with a custom serializer for one of these:. Serialization trace:; classes (sun.misc.Launcher$AppClassLoader); classLoader (org.apache.hadoop.conf.Configuration); conf (org.apache.hadoop.hdfs.DistributedFileSystem); fs (hdfs.jsr203.HadoopFileSystem); hdfs (hdfs.jsr203.HadoopPath); path (htsjdk.samtools.seekablestream.SeekablePathStream); seekableStream (htsjdk.tribble.TribbleIndexedFeatureReader); featureReader (org.broadinstitute.hellbender.engine.FeatureDataSource); featureSources (org.broadinstitute.hellbender.engine.FeatureManager). See, for instance, https://github.com/dbpedia/distributed-extraction-framework/issues/9.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5680#issuecomment-668654169
https://github.com/broadinstitute/gatk/issues/5680#issuecomment-668654169:69,Performance,load,loader,69,"I think this is happening because were trying to serialize the class loader sun.misc.Launcher$AppClassLoader), which appears to be reached through the graph by way of via https://github.com/damiencarol/jsr203-hadoop/blob/master/src/main/java/hdfs/jsr203/HadoopFileSystem.java#L82. We probably need to short circuit that with a custom serializer for one of these:. Serialization trace:; classes (sun.misc.Launcher$AppClassLoader); classLoader (org.apache.hadoop.conf.Configuration); conf (org.apache.hadoop.hdfs.DistributedFileSystem); fs (hdfs.jsr203.HadoopFileSystem); hdfs (hdfs.jsr203.HadoopPath); path (htsjdk.samtools.seekablestream.SeekablePathStream); seekableStream (htsjdk.tribble.TribbleIndexedFeatureReader); featureReader (org.broadinstitute.hellbender.engine.FeatureDataSource); featureSources (org.broadinstitute.hellbender.engine.FeatureManager). See, for instance, https://github.com/dbpedia/distributed-extraction-framework/issues/9.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5680#issuecomment-668654169
https://github.com/broadinstitute/gatk/issues/5683#issuecomment-887898295:37,Availability,error,error,37,I have been unable to reproduce this error. I have tried a few different things but none of them have resulted in this null pointer exception.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5683#issuecomment-887898295
https://github.com/broadinstitute/gatk/issues/5683#issuecomment-887905446:349,Testability,test,test,349,"Thanks for looking into this @haileypfox, as I submitted this bug report in Feb 2019 using GATK 4.1.0.0 I have since used a workaround (add an additional compression step after outputting uncompressed, eg. https://github.com/fpbarthel/GLASS/blob/333d5d01477e49bb2cf87be459d4161d4cde4483/snakemake/mutect2-post.smk#L188-L206). Did you use 4.1.0.0 to test this? Perhaps this was since fixed?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5683#issuecomment-887905446
https://github.com/broadinstitute/gatk/issues/5683#issuecomment-888363150:175,Availability,error,error,175,"@fpbarthel I did use 4.1.0.0 to test this as well as 4.0.9.0. I think that it must have been fixed, but I am glad that you were able to find a workaround. Let us know if this error occurs again though.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5683#issuecomment-888363150
https://github.com/broadinstitute/gatk/issues/5683#issuecomment-888363150:32,Testability,test,test,32,"@fpbarthel I did use 4.1.0.0 to test this as well as 4.0.9.0. I think that it must have been fixed, but I am glad that you were able to find a workaround. Let us know if this error occurs again though.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5683#issuecomment-888363150
https://github.com/broadinstitute/gatk/issues/5684#issuecomment-464516807:469,Deployability,update,updated,469,"I have been too quick on this bug diagnosis, sorry. Actually, the VCF given to FilterMutectCalls was the results of a `bcftools concat` operation. And I found out that `bcftools` is actually the culprit for setting this dot value. The value in the original Mutect2 VCF was `MPOS=-2147483648`. All such values were converted by `bcftools` into a `.`. I have replaced `bcftools` with `picard` to merge Vcfs, relaunched and I now wait for the results. I'll keep this post updated. Nonetheless, what a value of `-2147483648` is supposed to mean in `MPOS` tag ?. ```; chr1 885346 . T A . . DP=90;ECNT=8;MBQ=30,29;MFRL=309,433;MMQ=60,27;MPOS=-2147483648;NALOD=-1.307e+00;NLOD=7.24;POPAF=1.37;SAAF=0.081,0.00,0.078;SAPP=5.496e-03,0.055,0.940;TLOD=10.89; GT:AD:AF:DP:F1R2:F2R1:PGT:PID:PS 0|1:47,4:0.094:51:26,2:21,2:0|1:885342_GCT_G:885342 0|0:38,1:0.049:39:15,1:23,0:0|1:885342_GCT_G:885342; chr1 888222 . T C . . DP=78;ECNT=2;MBQ=31,31;MFRL=310,293;MMQ=60,30;MPOS=-2147483648;NALOD=-1.352e+00;NLOD=6.64;PON;POPAF=2.23;SAAF=0.051,0.00,0.049;SAPP=6.659e-03,0.023,0.970;TLOD=4.46; GT:AD:AF:DP:F1R2:F2R1:PGT:PID:PS 0|1:39,2:0.070:41:20,0:19,2:0|1:888199_TTTTCTTCACATTATA_T:888199 0|0:36,1:0.051:37:20,1:16,0:0|1:888199_TTTTCTTCACATTATA_T:888199; chr1 1401646 . TC T . . DP=75;ECNT=3;MBQ=29,30;MFRL=305,143;MMQ=60,60;MPOS=-2147483648;NALOD=1.10;NLOD=6.92;POPAF=5.40;SAAF=0.030,0.030,0.038;SAPP=8.222e-03,9.890e-03,0.982;TLOD=4.44 GT:AD:AF:DP:F1R2:F2R1:PGT:PID:PS 0|1:50,2:0.056:52:27,1:23,1:0|1:1401637_GCTGCTGA_G:1401637 0|0:23,0:0.040:23:12,0:11,0:0|1:1401637_GCTGCTGA_G:1401637; chr1 3870695 . A ACCCT . . DP=59;ECNT=2;MBQ=31,29;MFRL=303,282;MMQ=60,60;MPOS=-2147483648;NALOD=1.54;NLOD=10.23;POPAF=5.40;SAAF=0.081,0.00,0.080;SAPP=9.489e-03,0.029,0.962;TLOD=5.11 GT:AD:AF:DP:F1R2:F2R1:PGT:PID:PS 0|1:23,2:0.111:25:12,2:11,0:0|1:3870691_CCG_C:3870691 0|0:34,0:0.028:34:17,0:17,0:0|1:3870691_CCG_C:3870691; chr1 4136053 . GGTTAGTCATCATGGGAGTGA G . . DP=87;ECNT=1;MBQ=30,30;MFRL=314,306;MMQ=60,60;MPOS=-2147483648;",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5684#issuecomment-464516807
https://github.com/broadinstitute/gatk/issues/5685#issuecomment-480374611:89,Availability,ERROR,ERROR,89,I just gotten the same issue with gatk-package-4.1.1.0-local.jar. ```; 19/04/05 14:11:45 ERROR Executor: Exception in task 75.0 in stage 5.0 (TID 5210); java.lang.IllegalArgumentException: provided start is negative: -43; ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5685#issuecomment-480374611
https://github.com/broadinstitute/gatk/issues/5685#issuecomment-480385301:461,Deployability,pipeline,pipeline,461,"The only way I can think of this happening is if a read is aligned to the start of a contig (ie position 1), and has a left soft clip. Then the unclipped read start will be negative. It looks like reporters are running on hg38, so I suspect that this is occurring on alt contigs that have alignable bases at the very begging of the contig (as opposed to the primary contigs). For some reason we have not seen this in data produced by the Broad's hg38 alignment pipeline yet. I will try to push a quick fix.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5685#issuecomment-480385301
https://github.com/broadinstitute/gatk/issues/5686#issuecomment-465393400:12,Deployability,install,install,12,"Well, after install hadoop 3.1.1 with Linuxbrew, I managed to run `CreateReadCountPanelOfNormals`. Still, I think it is better not to copy input files to hadoop when running on single machine.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5686#issuecomment-465393400
https://github.com/broadinstitute/gatk/issues/5686#issuecomment-467510488:127,Deployability,configurat,configuration,127,"Glad you were able to resolve your issue. Not sure if this is specific to the CNV tool or if the exception caused by the Spark configuration is more general. Tagging engine team @droazen, but closing for now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5686#issuecomment-467510488
https://github.com/broadinstitute/gatk/issues/5686#issuecomment-467510488:127,Modifiability,config,configuration,127,"Glad you were able to resolve your issue. Not sure if this is specific to the CNV tool or if the exception caused by the Spark configuration is more general. Tagging engine team @droazen, but closing for now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5686#issuecomment-467510488
https://github.com/broadinstitute/gatk/pull/5688#issuecomment-465024734:3093,Security,validat,validation,3093,ø> (ø)` | `14 <0> (ø)` | :arrow_down: |; | [.../walkers/contamination/CalculateContamination.java](https://codecov.io/gh/broadinstitute/gatk/pull/5688/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2NvbnRhbWluYXRpb24vQ2FsY3VsYXRlQ29udGFtaW5hdGlvbi5qYXZh) | `96.552% <ø> (ø)` | `10 <0> (ø)` | :arrow_down: |; | [...ender/tools/walkers/annotator/InbreedingCoeff.java](https://codecov.io/gh/broadinstitute/gatk/pull/5688/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9JbmJyZWVkaW5nQ29lZmYuamF2YQ==) | `72.414% <ø> (-13.793%)` | `7 <0> (-3)` | |; | [...der/tools/walkers/CombineGVCFsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5688/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL0NvbWJpbmVHVkNGc0ludGVncmF0aW9uVGVzdC5qYXZh) | `1.262% <ø> (-88.675%)` | `2 <0> (-36)` | |; | [...s/walkers/validation/CalculateMixingFractions.java](https://codecov.io/gh/broadinstitute/gatk/pull/5688/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vQ2FsY3VsYXRlTWl4aW5nRnJhY3Rpb25zLmphdmE=) | `78.431% <ø> (ø)` | `15 <0> (ø)` | :arrow_down: |; | [...s/walkers/validation/MergeMutect2CallsWithMC3.java](https://codecov.io/gh/broadinstitute/gatk/pull/5688/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vTWVyZ2VNdXRlY3QyQ2FsbHNXaXRoTUMzLmphdmE=) | `81.25% <ø> (ø)` | `13 <0> (ø)` | :arrow_down: |; | [...tools/walkers/mutect/SomaticLikelihoodsEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/5688/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9Tb21hdGljTGlrZWxpaG9vZHNFbmdpbmUuamF2YQ==) | `86.667% <ø> (-2.222%)` | `17 <0> (-1)` | |; | ... and [1382 more](https://codecov.io/gh/broadinstitute/gatk/pull/5688/,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5688#issuecomment-465024734
https://github.com/broadinstitute/gatk/pull/5688#issuecomment-465024734:3415,Security,validat,validation,3415,ow_down: |; | [.../walkers/contamination/CalculateContamination.java](https://codecov.io/gh/broadinstitute/gatk/pull/5688/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2NvbnRhbWluYXRpb24vQ2FsY3VsYXRlQ29udGFtaW5hdGlvbi5qYXZh) | `96.552% <ø> (ø)` | `10 <0> (ø)` | :arrow_down: |; | [...ender/tools/walkers/annotator/InbreedingCoeff.java](https://codecov.io/gh/broadinstitute/gatk/pull/5688/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9JbmJyZWVkaW5nQ29lZmYuamF2YQ==) | `72.414% <ø> (-13.793%)` | `7 <0> (-3)` | |; | [...der/tools/walkers/CombineGVCFsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5688/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL0NvbWJpbmVHVkNGc0ludGVncmF0aW9uVGVzdC5qYXZh) | `1.262% <ø> (-88.675%)` | `2 <0> (-36)` | |; | [...s/walkers/validation/CalculateMixingFractions.java](https://codecov.io/gh/broadinstitute/gatk/pull/5688/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vQ2FsY3VsYXRlTWl4aW5nRnJhY3Rpb25zLmphdmE=) | `78.431% <ø> (ø)` | `15 <0> (ø)` | :arrow_down: |; | [...s/walkers/validation/MergeMutect2CallsWithMC3.java](https://codecov.io/gh/broadinstitute/gatk/pull/5688/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vTWVyZ2VNdXRlY3QyQ2FsbHNXaXRoTUMzLmphdmE=) | `81.25% <ø> (ø)` | `13 <0> (ø)` | :arrow_down: |; | [...tools/walkers/mutect/SomaticLikelihoodsEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/5688/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9Tb21hdGljTGlrZWxpaG9vZHNFbmdpbmUuamF2YQ==) | `86.667% <ø> (-2.222%)` | `17 <0> (-1)` | |; | ... and [1382 more](https://codecov.io/gh/broadinstitute/gatk/pull/5688/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5688#issuecomment-465024734
https://github.com/broadinstitute/gatk/pull/5689#issuecomment-465117014:945,Deployability,pipeline,pipelines,945,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5689?src=pr&el=h1) Report; > Merging [#5689](https://codecov.io/gh/broadinstitute/gatk/pull/5689?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/226f6d70a9c09318d45506c726f6744e2379d60c?src=pr&el=desc) will **decrease** coverage by `0.005%`.; > The diff coverage is `90.865%`. ```diff; @@ Coverage Diff @@; ## master #5689 +/- ##; ===============================================; - Coverage 87.069% 87.064% -0.005% ; + Complexity 31875 31850 -25 ; ===============================================; Files 1940 1941 +1 ; Lines 146738 146599 -139 ; Branches 16226 16208 -18 ; ===============================================; - Hits 127764 127635 -129 ; + Misses 13061 13057 -4 ; + Partials 5913 5907 -6; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5689?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...park/pipelines/PrintReadsSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5689/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRSZWFkc1NwYXJrSW50ZWdyYXRpb25UZXN0LmphdmE=) | `92.857% <100%> (+4.325%)` | `2 <1> (-29)` | :arrow_down: |; | [...te/hellbender/tools/PrintReadsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5689/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9QcmludFJlYWRzSW50ZWdyYXRpb25UZXN0LmphdmE=) | `100% <100%> (+3.205%)` | `3 <1> (-23)` | :arrow_down: |; | [...ender/tools/AbstractPrintReadsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5689/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9BYnN0cmFjdFByaW50UmVhZHNJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `90.777% <90.777%> (ø)` | `28 <28> (?)` | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5689#issuecomment-465117014
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-465237693:555,Security,access,access-the-gsa-public-ftp-server,555,"@byoo The easiest thing would be if you can upload it to google cloud and make it publicly visible. Then we can copy it over and you can delete it. Or if you can share your google account name I can grant you upload permission on a bucket we own. (If you want to not publish it to the world you can email it to me louisb@broadinstitute.org ) . Alternatively, if you can't use google cloud, you could upload it to the gatk ftp site. See this article here about how to connect to upload: https://gatkforums.broadinstitute.org/gatk/discussion/1215/how-can-i-access-the-gsa-public-ftp-server.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-465237693
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-465238238:20,Integrability,rout,route,20,@gspowley Could you route this bug report to whoever is able to deal with this nowadays?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-465238238
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-465272533:358,Security,access,accessible,358,@mepowers Nice to meet you. . This issue isn't resolved. What was resolved was uploading a core dump that exhibits the problem. Is it possible for you to take a look into what's the causing the invalid pointer? Let us know what additional information we can provide. The core dump is located at `gs://hellbender/bugs/5690/core.tar.gz` and should be publicly accessible.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-465272533
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-466588771:642,Availability,error,error,642,"Thanks @lbergelson - nice to meet you too. Sorry for the delay here. I had to set up gsutils on my system and am having gdb issues. . Submitting `sudo gdb /nfsdata-tmp/tools/gatk /home/bduser/mepowers/core.114856` I get back . ```; Missing separate debuginfo for the main executable file; Try: yum --enablerepo='*debug*' install /usr/lib/debug/.build-id/6c/../../../jvm/java-1.8.0-openjdk-1.8.0.111-1.b15.el7_2.x86_64/bin/java; Core was generated by `java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samt'.; Program terminated with signal 6, Aborted.; ```; I did try the yum --enablerepo, but it am getting the same error. . Any quick workarounds? Thanks in advance for the help. Will try again on Monday.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-466588771
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-466588771:321,Deployability,install,install,321,"Thanks @lbergelson - nice to meet you too. Sorry for the delay here. I had to set up gsutils on my system and am having gdb issues. . Submitting `sudo gdb /nfsdata-tmp/tools/gatk /home/bduser/mepowers/core.114856` I get back . ```; Missing separate debuginfo for the main executable file; Try: yum --enablerepo='*debug*' install /usr/lib/debug/.build-id/6c/../../../jvm/java-1.8.0-openjdk-1.8.0.111-1.b15.el7_2.x86_64/bin/java; Core was generated by `java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samt'.; Program terminated with signal 6, Aborted.; ```; I did try the yum --enablerepo, but it am getting the same error. . Any quick workarounds? Thanks in advance for the help. Will try again on Monday.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-466588771
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-466588771:568,Safety,Abort,Aborted,568,"Thanks @lbergelson - nice to meet you too. Sorry for the delay here. I had to set up gsutils on my system and am having gdb issues. . Submitting `sudo gdb /nfsdata-tmp/tools/gatk /home/bduser/mepowers/core.114856` I get back . ```; Missing separate debuginfo for the main executable file; Try: yum --enablerepo='*debug*' install /usr/lib/debug/.build-id/6c/../../../jvm/java-1.8.0-openjdk-1.8.0.111-1.b15.el7_2.x86_64/bin/java; Core was generated by `java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samt'.; Program terminated with signal 6, Aborted.; ```; I did try the yum --enablerepo, but it am getting the same error. . Any quick workarounds? Thanks in advance for the help. Will try again on Monday.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-466588771
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-485227509:446,Availability,avail,available,446,"The same for HaplotypeCaller (GATK 4.1.1.0); If this persists, and it seems like it, I will try to switch to pure-java, as retry takes couple of hours and ruins the workflow. ```; --smith-waterman / NA; Which Smith-Waterman implementation to use, generally FASTEST_AVAILABLE is the right choice; The --smith-waterman argument is an enumerated type (Implementation), which can have one of the following values:. FASTEST_AVAILABLE; use the fastest available Smith-Waterman aligner that runs on your hardware; AVX_ENABLED; use the AVX enabled Smith-Waterman aligner; JAVA; use the pure java implementation of Smith-Waterman, works on all hardware; ```. ```; *** Error in `java': munmap_chunk(): invalid pointer: 0x00007fafc8ed1000 ***; ======= Backtrace: =========; /lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7fafce3f37e5]; /lib/x86_64-linux-gnu/libc.so.6(cfree+0x1a8)[0x7fafce400698]; /home/flexray/germline/cromwell-executions/PairedEndSingleSampleWorkflow/af1ee082-8661-4a7a-adf9-1b2a67333d37/call-HaplotypeCaller/shard-40/tmp.42584bbe/libgkl_smithwaterman205796788520033039.so(_Z19runSWOnePairBT_avx2iiiiPhS_iiaPcPs+0x338)[0x7faf73bfcfa8]; /home/flexray/germline/cromwell-executions/PairedEndSingleSampleWorkflow/af1ee082-8661-4a7a-adf9-1b2a67333d37/call-HaplotypeCaller/shard-40/tmp.42584bbe/libgkl_smithwaterman205796788520033039.so(Java_com_intel_gkl_smithwaterman_IntelSmithWaterman_alignNative+0xd8)[0x7faf73bfcbf8]; [0x7fafb9a7eea2]; ```. and ; ```; *** Error in `java': double free or corruption (out): 0x00007f933d610780 ***; ======= Backtrace: =========; /lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7f93434427e5]; /lib/x86_64-linux-gnu/libc.so.6(+0x8037a)[0x7f934344b37a]; /lib/x86_64-linux-gnu/libc.so.6(cfree+0x4c)[0x7f934344f53c]; /home/flexray/germline/cromwell-executions/PairedEndSingleSampleWorkflow/fa8e6a15-021e-48cc-9429-c53596fc9c29/call-HaplotypeCaller/shard-19/tmp.ea81c1bd/libgkl_smithwaterman4419442010051805328.so(_Z19runSWOnePairBT_avx2iiiiPhS_iiaPcPs+0x338)[0x7f9248e4bfa8",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-485227509
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-485227509:659,Availability,Error,Error,659,"The same for HaplotypeCaller (GATK 4.1.1.0); If this persists, and it seems like it, I will try to switch to pure-java, as retry takes couple of hours and ruins the workflow. ```; --smith-waterman / NA; Which Smith-Waterman implementation to use, generally FASTEST_AVAILABLE is the right choice; The --smith-waterman argument is an enumerated type (Implementation), which can have one of the following values:. FASTEST_AVAILABLE; use the fastest available Smith-Waterman aligner that runs on your hardware; AVX_ENABLED; use the AVX enabled Smith-Waterman aligner; JAVA; use the pure java implementation of Smith-Waterman, works on all hardware; ```. ```; *** Error in `java': munmap_chunk(): invalid pointer: 0x00007fafc8ed1000 ***; ======= Backtrace: =========; /lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7fafce3f37e5]; /lib/x86_64-linux-gnu/libc.so.6(cfree+0x1a8)[0x7fafce400698]; /home/flexray/germline/cromwell-executions/PairedEndSingleSampleWorkflow/af1ee082-8661-4a7a-adf9-1b2a67333d37/call-HaplotypeCaller/shard-40/tmp.42584bbe/libgkl_smithwaterman205796788520033039.so(_Z19runSWOnePairBT_avx2iiiiPhS_iiaPcPs+0x338)[0x7faf73bfcfa8]; /home/flexray/germline/cromwell-executions/PairedEndSingleSampleWorkflow/af1ee082-8661-4a7a-adf9-1b2a67333d37/call-HaplotypeCaller/shard-40/tmp.42584bbe/libgkl_smithwaterman205796788520033039.so(Java_com_intel_gkl_smithwaterman_IntelSmithWaterman_alignNative+0xd8)[0x7faf73bfcbf8]; [0x7fafb9a7eea2]; ```. and ; ```; *** Error in `java': double free or corruption (out): 0x00007f933d610780 ***; ======= Backtrace: =========; /lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7f93434427e5]; /lib/x86_64-linux-gnu/libc.so.6(+0x8037a)[0x7f934344b37a]; /lib/x86_64-linux-gnu/libc.so.6(cfree+0x4c)[0x7f934344f53c]; /home/flexray/germline/cromwell-executions/PairedEndSingleSampleWorkflow/fa8e6a15-021e-48cc-9429-c53596fc9c29/call-HaplotypeCaller/shard-19/tmp.ea81c1bd/libgkl_smithwaterman4419442010051805328.so(_Z19runSWOnePairBT_avx2iiiiPhS_iiaPcPs+0x338)[0x7f9248e4bfa8",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-485227509
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-485227509:1462,Availability,Error,Error,1462,"waterman argument is an enumerated type (Implementation), which can have one of the following values:. FASTEST_AVAILABLE; use the fastest available Smith-Waterman aligner that runs on your hardware; AVX_ENABLED; use the AVX enabled Smith-Waterman aligner; JAVA; use the pure java implementation of Smith-Waterman, works on all hardware; ```. ```; *** Error in `java': munmap_chunk(): invalid pointer: 0x00007fafc8ed1000 ***; ======= Backtrace: =========; /lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7fafce3f37e5]; /lib/x86_64-linux-gnu/libc.so.6(cfree+0x1a8)[0x7fafce400698]; /home/flexray/germline/cromwell-executions/PairedEndSingleSampleWorkflow/af1ee082-8661-4a7a-adf9-1b2a67333d37/call-HaplotypeCaller/shard-40/tmp.42584bbe/libgkl_smithwaterman205796788520033039.so(_Z19runSWOnePairBT_avx2iiiiPhS_iiaPcPs+0x338)[0x7faf73bfcfa8]; /home/flexray/germline/cromwell-executions/PairedEndSingleSampleWorkflow/af1ee082-8661-4a7a-adf9-1b2a67333d37/call-HaplotypeCaller/shard-40/tmp.42584bbe/libgkl_smithwaterman205796788520033039.so(Java_com_intel_gkl_smithwaterman_IntelSmithWaterman_alignNative+0xd8)[0x7faf73bfcbf8]; [0x7fafb9a7eea2]; ```. and ; ```; *** Error in `java': double free or corruption (out): 0x00007f933d610780 ***; ======= Backtrace: =========; /lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7f93434427e5]; /lib/x86_64-linux-gnu/libc.so.6(+0x8037a)[0x7f934344b37a]; /lib/x86_64-linux-gnu/libc.so.6(cfree+0x4c)[0x7f934344f53c]; /home/flexray/germline/cromwell-executions/PairedEndSingleSampleWorkflow/fa8e6a15-021e-48cc-9429-c53596fc9c29/call-HaplotypeCaller/shard-19/tmp.ea81c1bd/libgkl_smithwaterman4419442010051805328.so(_Z19runSWOnePairBT_avx2iiiiPhS_iiaPcPs+0x338)[0x7f9248e4bfa8]; /home/flexray/germline/cromwell-executions/PairedEndSingleSampleWorkflow/fa8e6a15-021e-48cc-9429-c53596fc9c29/call-HaplotypeCaller/shard-19/tmp.ea81c1bd/libgkl_smithwaterman4419442010051805328.so(Java_com_intel_gkl_smithwaterman_IntelSmithWaterman_alignNative+0xd8)[0x7f9248e4bbf8]; [0x7f932de9ceaa]; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-485227509
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-492819820:202,Availability,error,error,202,"@mepowers Sorry for the long gap, I got distracted and then went on paternity leave. I'm not really able to help with gdb, I don't really have much experience there. . It looks like this is double free error in the Intel smith waterman code. Have you had any luck hunting it down?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-492819820
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-492819820:275,Availability,down,down,275,"@mepowers Sorry for the long gap, I got distracted and then went on paternity leave. I'm not really able to help with gdb, I don't really have much experience there. . It looks like this is double free error in the Intel smith waterman code. Have you had any luck hunting it down?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-492819820
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-631377270:97,Availability,Error,Error,97,This issue also pops up during FilterAlignmentArtifacts in GATK 4.1.7.0 (experimental). ```; *** Error in `java': munmap_chunk(): invalid pointer: 0x00007fb4c8e6e540 ***; ======= Backtrace: =========; /lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7fb4cdfee7e5]; /lib/x86_64-linux-gnu/libc.so.6(cfree+0x1a8)[0x7fb4cdffb698]; /cromwell_root/tmp.be1fb8a9/libgkl_smithwaterman4505316410124989699.so(_Z19runSWOnePairBT_avx2iiiiPhS_iiaPcPs+0x338)[0x7fb4ac3cffa8]; /cromwell_root/tmp.be1fb8a9/libgkl_smithwaterman4505316410124989699.so(Java_com_intel_gkl_smithwaterman_IntelSmithWaterman_alignNative+0xd8)[0x7fb4ac3cfbf8]; [0x7fb4b8b95f92]. ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-631377270
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-631471705:166,Availability,error,error,166,@DCarbonez Thanks for reporting. A team from intel has recently started looking into some GKL issues. I've forwarded your stack trace to them. Is this a reproducible error? Can you provide any additional information about your system that might help debug?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-631471705
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-652696262:24,Availability,error,error,24,"Dear @lbergelson,. This error occurred during the wdl implementation of gatk4-somatic-snvs-indels (https://github.com/gatk-workflows/gatk4-somatic-snvs-indels/blob/master/mutect2.wdl). Each of these steps were run on a fresh cloud instance with 9 GB ram & 2 cpu. (default). This is the underlying command: ; ```; set -e. export GATK_LOCAL_JAR=~{default=""/root/gatk.jar"" runtime_params.gatk_override}. gatk --java-options ""-Xmx~{command_mem}m"" FilterAlignmentArtifacts \; -V ~{input_vcf} \; -I ~{bam} \; --bwa-mem-index-image ~{realignment_index_bundle} \; ~{realignment_extra_args} \; -O ~{output_vcf}; ```. As it failed repeatedly, it reran 19 times:. - 10 tries were preempted ; - Twice, this error was in the log file ```*** Error in `java’: double free or corruption (out): 0x00007f6364699340 ***```; - 4 times, this error was in the log file: ```*** Error in `java’: munmap_chunk(): invalid pointer: 0x00007f685d06c840 ***```. The respective backtraces: . ```; *** Error in `java': double free or corruption (out): 0x00007f6364699340 ***; ======= Backtrace: =========; /lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7f636ba307e5]; /lib/x86_64-linux-gnu/libc.so.6(+0x8037a)[0x7f636ba3937a]; /lib/x86_64-linux-gnu/libc.so.6(cfree+0x4c)[0x7f636ba3d53c]; /cromwell_root/tmp.7626fbcf/libgkl_smithwaterman1454827346682980108.so(_Z19runSWOnePairBT_avx2iiiiPhS_iiaPcPs+0x338)[0x7f63123c8fa8]; /cromwell_root/tmp.7626fbcf/libgkl_smithwaterman1454827346682980108.so(Java_com_intel_gkl_smithwaterman_IntelSmithWaterman_alignNative+0xd8)[0x7f63123c8bf8]; [0x7f6355bff192]; ```. ```; *** Error in `java': munmap_chunk(): invalid pointer: 0x00007f685d06c840 ***; ======= Backtrace: =========; /lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7f68634c37e5]; /lib/x86_64-linux-gnu/libc.so.6(cfree+0x1a8)[0x7f68634d0698]; /cromwell_root/tmp.4eeeda3c/libgkl_smithwaterman7538158038428947321.so(_Z19runSWOnePairBT_avx2iiiiPhS_iiaPcPs+0x338)[0x7f6830cf2fa8]; /cromwell_root/tmp.4eeeda3c/libgkl_smithwaterman75381580384289473",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-652696262
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-652696262:695,Availability,error,error,695,"Dear @lbergelson,. This error occurred during the wdl implementation of gatk4-somatic-snvs-indels (https://github.com/gatk-workflows/gatk4-somatic-snvs-indels/blob/master/mutect2.wdl). Each of these steps were run on a fresh cloud instance with 9 GB ram & 2 cpu. (default). This is the underlying command: ; ```; set -e. export GATK_LOCAL_JAR=~{default=""/root/gatk.jar"" runtime_params.gatk_override}. gatk --java-options ""-Xmx~{command_mem}m"" FilterAlignmentArtifacts \; -V ~{input_vcf} \; -I ~{bam} \; --bwa-mem-index-image ~{realignment_index_bundle} \; ~{realignment_extra_args} \; -O ~{output_vcf}; ```. As it failed repeatedly, it reran 19 times:. - 10 tries were preempted ; - Twice, this error was in the log file ```*** Error in `java’: double free or corruption (out): 0x00007f6364699340 ***```; - 4 times, this error was in the log file: ```*** Error in `java’: munmap_chunk(): invalid pointer: 0x00007f685d06c840 ***```. The respective backtraces: . ```; *** Error in `java': double free or corruption (out): 0x00007f6364699340 ***; ======= Backtrace: =========; /lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7f636ba307e5]; /lib/x86_64-linux-gnu/libc.so.6(+0x8037a)[0x7f636ba3937a]; /lib/x86_64-linux-gnu/libc.so.6(cfree+0x4c)[0x7f636ba3d53c]; /cromwell_root/tmp.7626fbcf/libgkl_smithwaterman1454827346682980108.so(_Z19runSWOnePairBT_avx2iiiiPhS_iiaPcPs+0x338)[0x7f63123c8fa8]; /cromwell_root/tmp.7626fbcf/libgkl_smithwaterman1454827346682980108.so(Java_com_intel_gkl_smithwaterman_IntelSmithWaterman_alignNative+0xd8)[0x7f63123c8bf8]; [0x7f6355bff192]; ```. ```; *** Error in `java': munmap_chunk(): invalid pointer: 0x00007f685d06c840 ***; ======= Backtrace: =========; /lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7f68634c37e5]; /lib/x86_64-linux-gnu/libc.so.6(cfree+0x1a8)[0x7f68634d0698]; /cromwell_root/tmp.4eeeda3c/libgkl_smithwaterman7538158038428947321.so(_Z19runSWOnePairBT_avx2iiiiPhS_iiaPcPs+0x338)[0x7f6830cf2fa8]; /cromwell_root/tmp.4eeeda3c/libgkl_smithwaterman75381580384289473",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-652696262
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-652696262:728,Availability,Error,Error,728,"Dear @lbergelson,. This error occurred during the wdl implementation of gatk4-somatic-snvs-indels (https://github.com/gatk-workflows/gatk4-somatic-snvs-indels/blob/master/mutect2.wdl). Each of these steps were run on a fresh cloud instance with 9 GB ram & 2 cpu. (default). This is the underlying command: ; ```; set -e. export GATK_LOCAL_JAR=~{default=""/root/gatk.jar"" runtime_params.gatk_override}. gatk --java-options ""-Xmx~{command_mem}m"" FilterAlignmentArtifacts \; -V ~{input_vcf} \; -I ~{bam} \; --bwa-mem-index-image ~{realignment_index_bundle} \; ~{realignment_extra_args} \; -O ~{output_vcf}; ```. As it failed repeatedly, it reran 19 times:. - 10 tries were preempted ; - Twice, this error was in the log file ```*** Error in `java’: double free or corruption (out): 0x00007f6364699340 ***```; - 4 times, this error was in the log file: ```*** Error in `java’: munmap_chunk(): invalid pointer: 0x00007f685d06c840 ***```. The respective backtraces: . ```; *** Error in `java': double free or corruption (out): 0x00007f6364699340 ***; ======= Backtrace: =========; /lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7f636ba307e5]; /lib/x86_64-linux-gnu/libc.so.6(+0x8037a)[0x7f636ba3937a]; /lib/x86_64-linux-gnu/libc.so.6(cfree+0x4c)[0x7f636ba3d53c]; /cromwell_root/tmp.7626fbcf/libgkl_smithwaterman1454827346682980108.so(_Z19runSWOnePairBT_avx2iiiiPhS_iiaPcPs+0x338)[0x7f63123c8fa8]; /cromwell_root/tmp.7626fbcf/libgkl_smithwaterman1454827346682980108.so(Java_com_intel_gkl_smithwaterman_IntelSmithWaterman_alignNative+0xd8)[0x7f63123c8bf8]; [0x7f6355bff192]; ```. ```; *** Error in `java': munmap_chunk(): invalid pointer: 0x00007f685d06c840 ***; ======= Backtrace: =========; /lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7f68634c37e5]; /lib/x86_64-linux-gnu/libc.so.6(cfree+0x1a8)[0x7f68634d0698]; /cromwell_root/tmp.4eeeda3c/libgkl_smithwaterman7538158038428947321.so(_Z19runSWOnePairBT_avx2iiiiPhS_iiaPcPs+0x338)[0x7f6830cf2fa8]; /cromwell_root/tmp.4eeeda3c/libgkl_smithwaterman75381580384289473",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-652696262
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-652696262:821,Availability,error,error,821,"Dear @lbergelson,. This error occurred during the wdl implementation of gatk4-somatic-snvs-indels (https://github.com/gatk-workflows/gatk4-somatic-snvs-indels/blob/master/mutect2.wdl). Each of these steps were run on a fresh cloud instance with 9 GB ram & 2 cpu. (default). This is the underlying command: ; ```; set -e. export GATK_LOCAL_JAR=~{default=""/root/gatk.jar"" runtime_params.gatk_override}. gatk --java-options ""-Xmx~{command_mem}m"" FilterAlignmentArtifacts \; -V ~{input_vcf} \; -I ~{bam} \; --bwa-mem-index-image ~{realignment_index_bundle} \; ~{realignment_extra_args} \; -O ~{output_vcf}; ```. As it failed repeatedly, it reran 19 times:. - 10 tries were preempted ; - Twice, this error was in the log file ```*** Error in `java’: double free or corruption (out): 0x00007f6364699340 ***```; - 4 times, this error was in the log file: ```*** Error in `java’: munmap_chunk(): invalid pointer: 0x00007f685d06c840 ***```. The respective backtraces: . ```; *** Error in `java': double free or corruption (out): 0x00007f6364699340 ***; ======= Backtrace: =========; /lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7f636ba307e5]; /lib/x86_64-linux-gnu/libc.so.6(+0x8037a)[0x7f636ba3937a]; /lib/x86_64-linux-gnu/libc.so.6(cfree+0x4c)[0x7f636ba3d53c]; /cromwell_root/tmp.7626fbcf/libgkl_smithwaterman1454827346682980108.so(_Z19runSWOnePairBT_avx2iiiiPhS_iiaPcPs+0x338)[0x7f63123c8fa8]; /cromwell_root/tmp.7626fbcf/libgkl_smithwaterman1454827346682980108.so(Java_com_intel_gkl_smithwaterman_IntelSmithWaterman_alignNative+0xd8)[0x7f63123c8bf8]; [0x7f6355bff192]; ```. ```; *** Error in `java': munmap_chunk(): invalid pointer: 0x00007f685d06c840 ***; ======= Backtrace: =========; /lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7f68634c37e5]; /lib/x86_64-linux-gnu/libc.so.6(cfree+0x1a8)[0x7f68634d0698]; /cromwell_root/tmp.4eeeda3c/libgkl_smithwaterman7538158038428947321.so(_Z19runSWOnePairBT_avx2iiiiPhS_iiaPcPs+0x338)[0x7f6830cf2fa8]; /cromwell_root/tmp.4eeeda3c/libgkl_smithwaterman75381580384289473",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-652696262
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-652696262:855,Availability,Error,Error,855,"Dear @lbergelson,. This error occurred during the wdl implementation of gatk4-somatic-snvs-indels (https://github.com/gatk-workflows/gatk4-somatic-snvs-indels/blob/master/mutect2.wdl). Each of these steps were run on a fresh cloud instance with 9 GB ram & 2 cpu. (default). This is the underlying command: ; ```; set -e. export GATK_LOCAL_JAR=~{default=""/root/gatk.jar"" runtime_params.gatk_override}. gatk --java-options ""-Xmx~{command_mem}m"" FilterAlignmentArtifacts \; -V ~{input_vcf} \; -I ~{bam} \; --bwa-mem-index-image ~{realignment_index_bundle} \; ~{realignment_extra_args} \; -O ~{output_vcf}; ```. As it failed repeatedly, it reran 19 times:. - 10 tries were preempted ; - Twice, this error was in the log file ```*** Error in `java’: double free or corruption (out): 0x00007f6364699340 ***```; - 4 times, this error was in the log file: ```*** Error in `java’: munmap_chunk(): invalid pointer: 0x00007f685d06c840 ***```. The respective backtraces: . ```; *** Error in `java': double free or corruption (out): 0x00007f6364699340 ***; ======= Backtrace: =========; /lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7f636ba307e5]; /lib/x86_64-linux-gnu/libc.so.6(+0x8037a)[0x7f636ba3937a]; /lib/x86_64-linux-gnu/libc.so.6(cfree+0x4c)[0x7f636ba3d53c]; /cromwell_root/tmp.7626fbcf/libgkl_smithwaterman1454827346682980108.so(_Z19runSWOnePairBT_avx2iiiiPhS_iiaPcPs+0x338)[0x7f63123c8fa8]; /cromwell_root/tmp.7626fbcf/libgkl_smithwaterman1454827346682980108.so(Java_com_intel_gkl_smithwaterman_IntelSmithWaterman_alignNative+0xd8)[0x7f63123c8bf8]; [0x7f6355bff192]; ```. ```; *** Error in `java': munmap_chunk(): invalid pointer: 0x00007f685d06c840 ***; ======= Backtrace: =========; /lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7f68634c37e5]; /lib/x86_64-linux-gnu/libc.so.6(cfree+0x1a8)[0x7f68634d0698]; /cromwell_root/tmp.4eeeda3c/libgkl_smithwaterman7538158038428947321.so(_Z19runSWOnePairBT_avx2iiiiPhS_iiaPcPs+0x338)[0x7f6830cf2fa8]; /cromwell_root/tmp.4eeeda3c/libgkl_smithwaterman75381580384289473",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-652696262
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-652696262:970,Availability,Error,Error,970,"occurred during the wdl implementation of gatk4-somatic-snvs-indels (https://github.com/gatk-workflows/gatk4-somatic-snvs-indels/blob/master/mutect2.wdl). Each of these steps were run on a fresh cloud instance with 9 GB ram & 2 cpu. (default). This is the underlying command: ; ```; set -e. export GATK_LOCAL_JAR=~{default=""/root/gatk.jar"" runtime_params.gatk_override}. gatk --java-options ""-Xmx~{command_mem}m"" FilterAlignmentArtifacts \; -V ~{input_vcf} \; -I ~{bam} \; --bwa-mem-index-image ~{realignment_index_bundle} \; ~{realignment_extra_args} \; -O ~{output_vcf}; ```. As it failed repeatedly, it reran 19 times:. - 10 tries were preempted ; - Twice, this error was in the log file ```*** Error in `java’: double free or corruption (out): 0x00007f6364699340 ***```; - 4 times, this error was in the log file: ```*** Error in `java’: munmap_chunk(): invalid pointer: 0x00007f685d06c840 ***```. The respective backtraces: . ```; *** Error in `java': double free or corruption (out): 0x00007f6364699340 ***; ======= Backtrace: =========; /lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7f636ba307e5]; /lib/x86_64-linux-gnu/libc.so.6(+0x8037a)[0x7f636ba3937a]; /lib/x86_64-linux-gnu/libc.so.6(cfree+0x4c)[0x7f636ba3d53c]; /cromwell_root/tmp.7626fbcf/libgkl_smithwaterman1454827346682980108.so(_Z19runSWOnePairBT_avx2iiiiPhS_iiaPcPs+0x338)[0x7f63123c8fa8]; /cromwell_root/tmp.7626fbcf/libgkl_smithwaterman1454827346682980108.so(Java_com_intel_gkl_smithwaterman_IntelSmithWaterman_alignNative+0xd8)[0x7f63123c8bf8]; [0x7f6355bff192]; ```. ```; *** Error in `java': munmap_chunk(): invalid pointer: 0x00007f685d06c840 ***; ======= Backtrace: =========; /lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7f68634c37e5]; /lib/x86_64-linux-gnu/libc.so.6(cfree+0x1a8)[0x7f68634d0698]; /cromwell_root/tmp.4eeeda3c/libgkl_smithwaterman7538158038428947321.so(_Z19runSWOnePairBT_avx2iiiiPhS_iiaPcPs+0x338)[0x7f6830cf2fa8]; /cromwell_root/tmp.4eeeda3c/libgkl_smithwaterman7538158038428947321.so(Java_com_intel_gkl_smith",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-652696262
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-652696262:1577,Availability,Error,Error,1577,"eran 19 times:. - 10 tries were preempted ; - Twice, this error was in the log file ```*** Error in `java’: double free or corruption (out): 0x00007f6364699340 ***```; - 4 times, this error was in the log file: ```*** Error in `java’: munmap_chunk(): invalid pointer: 0x00007f685d06c840 ***```. The respective backtraces: . ```; *** Error in `java': double free or corruption (out): 0x00007f6364699340 ***; ======= Backtrace: =========; /lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7f636ba307e5]; /lib/x86_64-linux-gnu/libc.so.6(+0x8037a)[0x7f636ba3937a]; /lib/x86_64-linux-gnu/libc.so.6(cfree+0x4c)[0x7f636ba3d53c]; /cromwell_root/tmp.7626fbcf/libgkl_smithwaterman1454827346682980108.so(_Z19runSWOnePairBT_avx2iiiiPhS_iiaPcPs+0x338)[0x7f63123c8fa8]; /cromwell_root/tmp.7626fbcf/libgkl_smithwaterman1454827346682980108.so(Java_com_intel_gkl_smithwaterman_IntelSmithWaterman_alignNative+0xd8)[0x7f63123c8bf8]; [0x7f6355bff192]; ```. ```; *** Error in `java': munmap_chunk(): invalid pointer: 0x00007f685d06c840 ***; ======= Backtrace: =========; /lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7f68634c37e5]; /lib/x86_64-linux-gnu/libc.so.6(cfree+0x1a8)[0x7f68634d0698]; /cromwell_root/tmp.4eeeda3c/libgkl_smithwaterman7538158038428947321.so(_Z19runSWOnePairBT_avx2iiiiPhS_iiaPcPs+0x338)[0x7f6830cf2fa8]; /cromwell_root/tmp.4eeeda3c/libgkl_smithwaterman7538158038428947321.so(Java_com_intel_gkl_smithwaterman_IntelSmithWaterman_alignNative+0xd8)[0x7f6830cf2bf8]; [0x7f684dc31f92]; ```. In each of these occurrences, the filtered vcf file was produced, but the vcf.idx file was missing. Although the java errors occur, the last line of the log denotes the step as a success: (This might be true, but only when the option --create-output-variant-index is set to false.; `SetOperationStatus(copied 0 file(s) to <destinations_folder> succeeded""`. I also performed a test based on machine type. (outside of the full workflow, starting the steps on my own on a separate instance & replicating the steps of the wor",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-652696262
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-652696262:2235,Availability,error,errors,2235," the log file: ```*** Error in `java’: munmap_chunk(): invalid pointer: 0x00007f685d06c840 ***```. The respective backtraces: . ```; *** Error in `java': double free or corruption (out): 0x00007f6364699340 ***; ======= Backtrace: =========; /lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7f636ba307e5]; /lib/x86_64-linux-gnu/libc.so.6(+0x8037a)[0x7f636ba3937a]; /lib/x86_64-linux-gnu/libc.so.6(cfree+0x4c)[0x7f636ba3d53c]; /cromwell_root/tmp.7626fbcf/libgkl_smithwaterman1454827346682980108.so(_Z19runSWOnePairBT_avx2iiiiPhS_iiaPcPs+0x338)[0x7f63123c8fa8]; /cromwell_root/tmp.7626fbcf/libgkl_smithwaterman1454827346682980108.so(Java_com_intel_gkl_smithwaterman_IntelSmithWaterman_alignNative+0xd8)[0x7f63123c8bf8]; [0x7f6355bff192]; ```. ```; *** Error in `java': munmap_chunk(): invalid pointer: 0x00007f685d06c840 ***; ======= Backtrace: =========; /lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7f68634c37e5]; /lib/x86_64-linux-gnu/libc.so.6(cfree+0x1a8)[0x7f68634d0698]; /cromwell_root/tmp.4eeeda3c/libgkl_smithwaterman7538158038428947321.so(_Z19runSWOnePairBT_avx2iiiiPhS_iiaPcPs+0x338)[0x7f6830cf2fa8]; /cromwell_root/tmp.4eeeda3c/libgkl_smithwaterman7538158038428947321.so(Java_com_intel_gkl_smithwaterman_IntelSmithWaterman_alignNative+0xd8)[0x7f6830cf2bf8]; [0x7f684dc31f92]; ```. In each of these occurrences, the filtered vcf file was produced, but the vcf.idx file was missing. Although the java errors occur, the last line of the log denotes the step as a success: (This might be true, but only when the option --create-output-variant-index is set to false.; `SetOperationStatus(copied 0 file(s) to <destinations_folder> succeeded""`. I also performed a test based on machine type. (outside of the full workflow, starting the steps on my own on a separate instance & replicating the steps of the workflow); - Using an instance with 2 vCPU's, 7.5 GB of ram, just ran out of memory.; - Using an instance with 8 vCPU's, 30 GB of ram finished successfully, producing both the filtered vcf & vcf.idx",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-652696262
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-652696262:2481,Performance,perform,performed,2481," the log file: ```*** Error in `java’: munmap_chunk(): invalid pointer: 0x00007f685d06c840 ***```. The respective backtraces: . ```; *** Error in `java': double free or corruption (out): 0x00007f6364699340 ***; ======= Backtrace: =========; /lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7f636ba307e5]; /lib/x86_64-linux-gnu/libc.so.6(+0x8037a)[0x7f636ba3937a]; /lib/x86_64-linux-gnu/libc.so.6(cfree+0x4c)[0x7f636ba3d53c]; /cromwell_root/tmp.7626fbcf/libgkl_smithwaterman1454827346682980108.so(_Z19runSWOnePairBT_avx2iiiiPhS_iiaPcPs+0x338)[0x7f63123c8fa8]; /cromwell_root/tmp.7626fbcf/libgkl_smithwaterman1454827346682980108.so(Java_com_intel_gkl_smithwaterman_IntelSmithWaterman_alignNative+0xd8)[0x7f63123c8bf8]; [0x7f6355bff192]; ```. ```; *** Error in `java': munmap_chunk(): invalid pointer: 0x00007f685d06c840 ***; ======= Backtrace: =========; /lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7f68634c37e5]; /lib/x86_64-linux-gnu/libc.so.6(cfree+0x1a8)[0x7f68634d0698]; /cromwell_root/tmp.4eeeda3c/libgkl_smithwaterman7538158038428947321.so(_Z19runSWOnePairBT_avx2iiiiPhS_iiaPcPs+0x338)[0x7f6830cf2fa8]; /cromwell_root/tmp.4eeeda3c/libgkl_smithwaterman7538158038428947321.so(Java_com_intel_gkl_smithwaterman_IntelSmithWaterman_alignNative+0xd8)[0x7f6830cf2bf8]; [0x7f684dc31f92]; ```. In each of these occurrences, the filtered vcf file was produced, but the vcf.idx file was missing. Although the java errors occur, the last line of the log denotes the step as a success: (This might be true, but only when the option --create-output-variant-index is set to false.; `SetOperationStatus(copied 0 file(s) to <destinations_folder> succeeded""`. I also performed a test based on machine type. (outside of the full workflow, starting the steps on my own on a separate instance & replicating the steps of the workflow); - Using an instance with 2 vCPU's, 7.5 GB of ram, just ran out of memory.; - Using an instance with 8 vCPU's, 30 GB of ram finished successfully, producing both the filtered vcf & vcf.idx",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-652696262
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-652696262:712,Testability,log,log,712,"Dear @lbergelson,. This error occurred during the wdl implementation of gatk4-somatic-snvs-indels (https://github.com/gatk-workflows/gatk4-somatic-snvs-indels/blob/master/mutect2.wdl). Each of these steps were run on a fresh cloud instance with 9 GB ram & 2 cpu. (default). This is the underlying command: ; ```; set -e. export GATK_LOCAL_JAR=~{default=""/root/gatk.jar"" runtime_params.gatk_override}. gatk --java-options ""-Xmx~{command_mem}m"" FilterAlignmentArtifacts \; -V ~{input_vcf} \; -I ~{bam} \; --bwa-mem-index-image ~{realignment_index_bundle} \; ~{realignment_extra_args} \; -O ~{output_vcf}; ```. As it failed repeatedly, it reran 19 times:. - 10 tries were preempted ; - Twice, this error was in the log file ```*** Error in `java’: double free or corruption (out): 0x00007f6364699340 ***```; - 4 times, this error was in the log file: ```*** Error in `java’: munmap_chunk(): invalid pointer: 0x00007f685d06c840 ***```. The respective backtraces: . ```; *** Error in `java': double free or corruption (out): 0x00007f6364699340 ***; ======= Backtrace: =========; /lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7f636ba307e5]; /lib/x86_64-linux-gnu/libc.so.6(+0x8037a)[0x7f636ba3937a]; /lib/x86_64-linux-gnu/libc.so.6(cfree+0x4c)[0x7f636ba3d53c]; /cromwell_root/tmp.7626fbcf/libgkl_smithwaterman1454827346682980108.so(_Z19runSWOnePairBT_avx2iiiiPhS_iiaPcPs+0x338)[0x7f63123c8fa8]; /cromwell_root/tmp.7626fbcf/libgkl_smithwaterman1454827346682980108.so(Java_com_intel_gkl_smithwaterman_IntelSmithWaterman_alignNative+0xd8)[0x7f63123c8bf8]; [0x7f6355bff192]; ```. ```; *** Error in `java': munmap_chunk(): invalid pointer: 0x00007f685d06c840 ***; ======= Backtrace: =========; /lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7f68634c37e5]; /lib/x86_64-linux-gnu/libc.so.6(cfree+0x1a8)[0x7f68634d0698]; /cromwell_root/tmp.4eeeda3c/libgkl_smithwaterman7538158038428947321.so(_Z19runSWOnePairBT_avx2iiiiPhS_iiaPcPs+0x338)[0x7f6830cf2fa8]; /cromwell_root/tmp.4eeeda3c/libgkl_smithwaterman75381580384289473",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-652696262
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-652696262:838,Testability,log,log,838,"Dear @lbergelson,. This error occurred during the wdl implementation of gatk4-somatic-snvs-indels (https://github.com/gatk-workflows/gatk4-somatic-snvs-indels/blob/master/mutect2.wdl). Each of these steps were run on a fresh cloud instance with 9 GB ram & 2 cpu. (default). This is the underlying command: ; ```; set -e. export GATK_LOCAL_JAR=~{default=""/root/gatk.jar"" runtime_params.gatk_override}. gatk --java-options ""-Xmx~{command_mem}m"" FilterAlignmentArtifacts \; -V ~{input_vcf} \; -I ~{bam} \; --bwa-mem-index-image ~{realignment_index_bundle} \; ~{realignment_extra_args} \; -O ~{output_vcf}; ```. As it failed repeatedly, it reran 19 times:. - 10 tries were preempted ; - Twice, this error was in the log file ```*** Error in `java’: double free or corruption (out): 0x00007f6364699340 ***```; - 4 times, this error was in the log file: ```*** Error in `java’: munmap_chunk(): invalid pointer: 0x00007f685d06c840 ***```. The respective backtraces: . ```; *** Error in `java': double free or corruption (out): 0x00007f6364699340 ***; ======= Backtrace: =========; /lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7f636ba307e5]; /lib/x86_64-linux-gnu/libc.so.6(+0x8037a)[0x7f636ba3937a]; /lib/x86_64-linux-gnu/libc.so.6(cfree+0x4c)[0x7f636ba3d53c]; /cromwell_root/tmp.7626fbcf/libgkl_smithwaterman1454827346682980108.so(_Z19runSWOnePairBT_avx2iiiiPhS_iiaPcPs+0x338)[0x7f63123c8fa8]; /cromwell_root/tmp.7626fbcf/libgkl_smithwaterman1454827346682980108.so(Java_com_intel_gkl_smithwaterman_IntelSmithWaterman_alignNative+0xd8)[0x7f63123c8bf8]; [0x7f6355bff192]; ```. ```; *** Error in `java': munmap_chunk(): invalid pointer: 0x00007f685d06c840 ***; ======= Backtrace: =========; /lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7f68634c37e5]; /lib/x86_64-linux-gnu/libc.so.6(cfree+0x1a8)[0x7f68634d0698]; /cromwell_root/tmp.4eeeda3c/libgkl_smithwaterman7538158038428947321.so(_Z19runSWOnePairBT_avx2iiiiPhS_iiaPcPs+0x338)[0x7f6830cf2fa8]; /cromwell_root/tmp.4eeeda3c/libgkl_smithwaterman75381580384289473",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-652696262
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-652696262:2270,Testability,log,log,2270," the log file: ```*** Error in `java’: munmap_chunk(): invalid pointer: 0x00007f685d06c840 ***```. The respective backtraces: . ```; *** Error in `java': double free or corruption (out): 0x00007f6364699340 ***; ======= Backtrace: =========; /lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7f636ba307e5]; /lib/x86_64-linux-gnu/libc.so.6(+0x8037a)[0x7f636ba3937a]; /lib/x86_64-linux-gnu/libc.so.6(cfree+0x4c)[0x7f636ba3d53c]; /cromwell_root/tmp.7626fbcf/libgkl_smithwaterman1454827346682980108.so(_Z19runSWOnePairBT_avx2iiiiPhS_iiaPcPs+0x338)[0x7f63123c8fa8]; /cromwell_root/tmp.7626fbcf/libgkl_smithwaterman1454827346682980108.so(Java_com_intel_gkl_smithwaterman_IntelSmithWaterman_alignNative+0xd8)[0x7f63123c8bf8]; [0x7f6355bff192]; ```. ```; *** Error in `java': munmap_chunk(): invalid pointer: 0x00007f685d06c840 ***; ======= Backtrace: =========; /lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7f68634c37e5]; /lib/x86_64-linux-gnu/libc.so.6(cfree+0x1a8)[0x7f68634d0698]; /cromwell_root/tmp.4eeeda3c/libgkl_smithwaterman7538158038428947321.so(_Z19runSWOnePairBT_avx2iiiiPhS_iiaPcPs+0x338)[0x7f6830cf2fa8]; /cromwell_root/tmp.4eeeda3c/libgkl_smithwaterman7538158038428947321.so(Java_com_intel_gkl_smithwaterman_IntelSmithWaterman_alignNative+0xd8)[0x7f6830cf2bf8]; [0x7f684dc31f92]; ```. In each of these occurrences, the filtered vcf file was produced, but the vcf.idx file was missing. Although the java errors occur, the last line of the log denotes the step as a success: (This might be true, but only when the option --create-output-variant-index is set to false.; `SetOperationStatus(copied 0 file(s) to <destinations_folder> succeeded""`. I also performed a test based on machine type. (outside of the full workflow, starting the steps on my own on a separate instance & replicating the steps of the workflow); - Using an instance with 2 vCPU's, 7.5 GB of ram, just ran out of memory.; - Using an instance with 8 vCPU's, 30 GB of ram finished successfully, producing both the filtered vcf & vcf.idx",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-652696262
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-652696262:2493,Testability,test,test,2493," the log file: ```*** Error in `java’: munmap_chunk(): invalid pointer: 0x00007f685d06c840 ***```. The respective backtraces: . ```; *** Error in `java': double free or corruption (out): 0x00007f6364699340 ***; ======= Backtrace: =========; /lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7f636ba307e5]; /lib/x86_64-linux-gnu/libc.so.6(+0x8037a)[0x7f636ba3937a]; /lib/x86_64-linux-gnu/libc.so.6(cfree+0x4c)[0x7f636ba3d53c]; /cromwell_root/tmp.7626fbcf/libgkl_smithwaterman1454827346682980108.so(_Z19runSWOnePairBT_avx2iiiiPhS_iiaPcPs+0x338)[0x7f63123c8fa8]; /cromwell_root/tmp.7626fbcf/libgkl_smithwaterman1454827346682980108.so(Java_com_intel_gkl_smithwaterman_IntelSmithWaterman_alignNative+0xd8)[0x7f63123c8bf8]; [0x7f6355bff192]; ```. ```; *** Error in `java': munmap_chunk(): invalid pointer: 0x00007f685d06c840 ***; ======= Backtrace: =========; /lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7f68634c37e5]; /lib/x86_64-linux-gnu/libc.so.6(cfree+0x1a8)[0x7f68634d0698]; /cromwell_root/tmp.4eeeda3c/libgkl_smithwaterman7538158038428947321.so(_Z19runSWOnePairBT_avx2iiiiPhS_iiaPcPs+0x338)[0x7f6830cf2fa8]; /cromwell_root/tmp.4eeeda3c/libgkl_smithwaterman7538158038428947321.so(Java_com_intel_gkl_smithwaterman_IntelSmithWaterman_alignNative+0xd8)[0x7f6830cf2bf8]; [0x7f684dc31f92]; ```. In each of these occurrences, the filtered vcf file was produced, but the vcf.idx file was missing. Although the java errors occur, the last line of the log denotes the step as a success: (This might be true, but only when the option --create-output-variant-index is set to false.; `SetOperationStatus(copied 0 file(s) to <destinations_folder> succeeded""`. I also performed a test based on machine type. (outside of the full workflow, starting the steps on my own on a separate instance & replicating the steps of the workflow); - Using an instance with 2 vCPU's, 7.5 GB of ram, just ran out of memory.; - Using an instance with 8 vCPU's, 30 GB of ram finished successfully, producing both the filtered vcf & vcf.idx",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-652696262
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-654398146:95,Availability,down,down,95,Thank you for the additional information! Hopefully this will be helpful for the team tracking down these issues. There's going to be a new build of the GKL soon which I'm hoping will fix this.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-654398146
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-660645356:219,Availability,down,down,219,"Hi @lbergelson,. We experienced the related issue in GATK 4.1.8 (it persisted since 4.1.5 or early version as far as we know) when running `FilterAlignmentArtifacts` in one of our cluster but not the other. We narrowed down the issue, using the CPU differences (the working one does not support AVX2), to `libgkl_smithwaterman.so`. Paths are shortened for clarity in the following commands. ```; bash faa.sh ; Using GATK jar /app/gatk-package-4.1.8.0-local.jar; Running:; /bin/java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /app/gatk-package-4.1.8.0-local.jar FilterAlignmentArtifacts -V /output/sample.FilterMutectCalls.vcf.gz -R /db/hs37d5.fa --bwa-mem-index-image /db/hg38.fa.img -I /output/sample.Mutect2.bam -O sample.somatic_filter.test.vcf.gz --use-jdk-inflater true; 19:11:56.929 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/app/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_utils.so; 19:11:56.943 INFO NativeLibraryLoader - Loading libgkl_smithwaterman.so from jar:file:/app/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_smithwaterman.so; 19:11:56.944 INFO SmithWatermanAligner - Using AVX accelerated SmithWaterman implementation; 19:11:57.168 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/app/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Jul 19, 2020 7:11:57 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 19:11:57.324 INFO FilterAlignmentArtifacts - ------------------------------------------------------------; 19:11:57.324 INFO FilterAlignmentArtifacts - The Genome Analysis Toolkit (GATK) v4.1.8.0; 19:11:57.325 INFO FilterAlignmentArtifacts - For support and documentation go to https://software.broadinstitute.org/gatk/; 19:11:57.325 INFO Fil",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-660645356
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-660645356:4124,Availability,Avail,Available,4124,erAlignmentArtifacts - Inflater: JdkInflater; 19:11:57.326 INFO FilterAlignmentArtifacts - GCS max retries/reopens: 20; 19:11:57.326 INFO FilterAlignmentArtifacts - Requester pays: disabled; 19:11:57.326 WARN FilterAlignmentArtifacts - . !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: FilterAlignmentArtifacts is an EXPERIMENTAL tool and should not be used for production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 19:11:57.326 INFO FilterAlignmentArtifacts - Initializing engine; 19:11:57.666 INFO FeatureManager - Using codec VCFCodec to read file file:///output/sample.FilterMutectCalls.vcf.gz; 19:11:57.757 INFO FilterAlignmentArtifacts - Done initializing engine; 19:11:57.827 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/app/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 19:11:57.861 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 19:11:57.862 INFO IntelPairHmm - Available threads: 4; 19:11:57.862 INFO IntelPairHmm - Requested threads: 4; 19:11:57.862 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 19:11:57.862 INFO ProgressMeter - Starting traversal; 19:11:57.862 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; *** glibc detected *** /for/bar/bin/java: double free or corruption (out): 0x00007f450af58700 ***; ======= Backtrace: =========; /lib64/libc.so.6(+0x3d01675dee)[0x7f45058afdee]; /lib64/libc.so.6(+0x3d01678c80)[0x7f45058b2c80]; /tmp/libgkl_smithwaterman410767516409374085.so(_Z19runSWOnePairBT_avx2iiiiPhS_iiaPcPs+0x338)[0x7f4499f4cfa8]; /tmp/libgkl_smithwaterman410767516409374085.so(Java_com_intel_gkl_smithwaterman_IntelSmithWaterman_alignNative+0xd8)[0x7f4499f4cbf8]; [0x7f44f58be6a2]; ======= Memory map: ========; ```. Then we **disabled** AVX2 in the newer cluster using Intels [sde64](https://software.intel.com/en-us/articles/intel-software-development-emula,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-660645356
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-660645356:933,Performance,Load,Loading,933,"Hi @lbergelson,. We experienced the related issue in GATK 4.1.8 (it persisted since 4.1.5 or early version as far as we know) when running `FilterAlignmentArtifacts` in one of our cluster but not the other. We narrowed down the issue, using the CPU differences (the working one does not support AVX2), to `libgkl_smithwaterman.so`. Paths are shortened for clarity in the following commands. ```; bash faa.sh ; Using GATK jar /app/gatk-package-4.1.8.0-local.jar; Running:; /bin/java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /app/gatk-package-4.1.8.0-local.jar FilterAlignmentArtifacts -V /output/sample.FilterMutectCalls.vcf.gz -R /db/hs37d5.fa --bwa-mem-index-image /db/hg38.fa.img -I /output/sample.Mutect2.bam -O sample.somatic_filter.test.vcf.gz --use-jdk-inflater true; 19:11:56.929 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/app/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_utils.so; 19:11:56.943 INFO NativeLibraryLoader - Loading libgkl_smithwaterman.so from jar:file:/app/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_smithwaterman.so; 19:11:56.944 INFO SmithWatermanAligner - Using AVX accelerated SmithWaterman implementation; 19:11:57.168 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/app/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Jul 19, 2020 7:11:57 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 19:11:57.324 INFO FilterAlignmentArtifacts - ------------------------------------------------------------; 19:11:57.324 INFO FilterAlignmentArtifacts - The Genome Analysis Toolkit (GATK) v4.1.8.0; 19:11:57.325 INFO FilterAlignmentArtifacts - For support and documentation go to https://software.broadinstitute.org/gatk/; 19:11:57.325 INFO Fil",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-660645356
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-660645356:1086,Performance,Load,Loading,1086,".1.5 or early version as far as we know) when running `FilterAlignmentArtifacts` in one of our cluster but not the other. We narrowed down the issue, using the CPU differences (the working one does not support AVX2), to `libgkl_smithwaterman.so`. Paths are shortened for clarity in the following commands. ```; bash faa.sh ; Using GATK jar /app/gatk-package-4.1.8.0-local.jar; Running:; /bin/java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /app/gatk-package-4.1.8.0-local.jar FilterAlignmentArtifacts -V /output/sample.FilterMutectCalls.vcf.gz -R /db/hs37d5.fa --bwa-mem-index-image /db/hg38.fa.img -I /output/sample.Mutect2.bam -O sample.somatic_filter.test.vcf.gz --use-jdk-inflater true; 19:11:56.929 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/app/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_utils.so; 19:11:56.943 INFO NativeLibraryLoader - Loading libgkl_smithwaterman.so from jar:file:/app/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_smithwaterman.so; 19:11:56.944 INFO SmithWatermanAligner - Using AVX accelerated SmithWaterman implementation; 19:11:57.168 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/app/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Jul 19, 2020 7:11:57 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 19:11:57.324 INFO FilterAlignmentArtifacts - ------------------------------------------------------------; 19:11:57.324 INFO FilterAlignmentArtifacts - The Genome Analysis Toolkit (GATK) v4.1.8.0; 19:11:57.325 INFO FilterAlignmentArtifacts - For support and documentation go to https://software.broadinstitute.org/gatk/; 19:11:57.325 INFO FilterAlignmentArtifacts - Executing as foo@bar.local on Linux v2.6.32-696.6.3.el6.x86_",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-660645356
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-660645356:1348,Performance,Load,Loading,1348,"tened for clarity in the following commands. ```; bash faa.sh ; Using GATK jar /app/gatk-package-4.1.8.0-local.jar; Running:; /bin/java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /app/gatk-package-4.1.8.0-local.jar FilterAlignmentArtifacts -V /output/sample.FilterMutectCalls.vcf.gz -R /db/hs37d5.fa --bwa-mem-index-image /db/hg38.fa.img -I /output/sample.Mutect2.bam -O sample.somatic_filter.test.vcf.gz --use-jdk-inflater true; 19:11:56.929 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/app/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_utils.so; 19:11:56.943 INFO NativeLibraryLoader - Loading libgkl_smithwaterman.so from jar:file:/app/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_smithwaterman.so; 19:11:56.944 INFO SmithWatermanAligner - Using AVX accelerated SmithWaterman implementation; 19:11:57.168 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/app/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Jul 19, 2020 7:11:57 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 19:11:57.324 INFO FilterAlignmentArtifacts - ------------------------------------------------------------; 19:11:57.324 INFO FilterAlignmentArtifacts - The Genome Analysis Toolkit (GATK) v4.1.8.0; 19:11:57.325 INFO FilterAlignmentArtifacts - For support and documentation go to https://software.broadinstitute.org/gatk/; 19:11:57.325 INFO FilterAlignmentArtifacts - Executing as foo@bar.local on Linux v2.6.32-696.6.3.el6.x86_64 amd64; 19:11:57.325 INFO FilterAlignmentArtifacts - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_261-b12; 19:11:57.325 INFO FilterAlignmentArtifacts - Start Date/Time: July 19, 2020 7:11:57 PM CST; 19:11:57.325 INFO FilterAlignmentArtifacts - -----",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-660645356
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-660645356:3880,Performance,Load,Loading,3880,HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:11:57.326 INFO FilterAlignmentArtifacts - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:11:57.326 INFO FilterAlignmentArtifacts - Deflater: IntelDeflater; 19:11:57.326 INFO FilterAlignmentArtifacts - Inflater: JdkInflater; 19:11:57.326 INFO FilterAlignmentArtifacts - GCS max retries/reopens: 20; 19:11:57.326 INFO FilterAlignmentArtifacts - Requester pays: disabled; 19:11:57.326 WARN FilterAlignmentArtifacts - . !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: FilterAlignmentArtifacts is an EXPERIMENTAL tool and should not be used for production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 19:11:57.326 INFO FilterAlignmentArtifacts - Initializing engine; 19:11:57.666 INFO FeatureManager - Using codec VCFCodec to read file file:///output/sample.FilterMutectCalls.vcf.gz; 19:11:57.757 INFO FilterAlignmentArtifacts - Done initializing engine; 19:11:57.827 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/app/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 19:11:57.861 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 19:11:57.862 INFO IntelPairHmm - Available threads: 4; 19:11:57.862 INFO IntelPairHmm - Requested threads: 4; 19:11:57.862 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 19:11:57.862 INFO ProgressMeter - Starting traversal; 19:11:57.862 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; *** glibc detected *** /for/bar/bin/java: double free or corruption (out): 0x00007f450af58700 ***; ======= Backtrace: =========; /lib64/libc.so.6(+0x3d01675dee)[0x7f45058afdee]; /lib64/libc.so.6(+0x3d01678c80)[0x7f45058b2c80]; /tmp/libgkl_smithwaterman410767516409374085.so(_Z19runSWOnePairBT_avx2iiiiPhS_iiaPcPs+0x338)[0x7f4499f4cfa8]; /tmp/libgkl_smithwaterman410767516409374085.so(Java_com_intel_gkl_smithwaterman,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-660645356
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-660645356:4246,Performance,multi-thread,multi-threaded,4246,"O FilterAlignmentArtifacts - Requester pays: disabled; 19:11:57.326 WARN FilterAlignmentArtifacts - . !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: FilterAlignmentArtifacts is an EXPERIMENTAL tool and should not be used for production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 19:11:57.326 INFO FilterAlignmentArtifacts - Initializing engine; 19:11:57.666 INFO FeatureManager - Using codec VCFCodec to read file file:///output/sample.FilterMutectCalls.vcf.gz; 19:11:57.757 INFO FilterAlignmentArtifacts - Done initializing engine; 19:11:57.827 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/app/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 19:11:57.861 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 19:11:57.862 INFO IntelPairHmm - Available threads: 4; 19:11:57.862 INFO IntelPairHmm - Requested threads: 4; 19:11:57.862 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 19:11:57.862 INFO ProgressMeter - Starting traversal; 19:11:57.862 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; *** glibc detected *** /for/bar/bin/java: double free or corruption (out): 0x00007f450af58700 ***; ======= Backtrace: =========; /lib64/libc.so.6(+0x3d01675dee)[0x7f45058afdee]; /lib64/libc.so.6(+0x3d01678c80)[0x7f45058b2c80]; /tmp/libgkl_smithwaterman410767516409374085.so(_Z19runSWOnePairBT_avx2iiiiPhS_iiaPcPs+0x338)[0x7f4499f4cfa8]; /tmp/libgkl_smithwaterman410767516409374085.so(Java_com_intel_gkl_smithwaterman_IntelSmithWaterman_alignNative+0xd8)[0x7f4499f4cbf8]; [0x7f44f58be6a2]; ======= Memory map: ========; ```. Then we **disabled** AVX2 in the newer cluster using Intels [sde64](https://software.intel.com/en-us/articles/intel-software-development-emulator) with `-ivb`, which directed GATK to use the Java implementation, and the filter worked without core dump. ```; sde64 -ivb -- faa.sh",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-660645356
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-660645356:5815,Performance,Load,Loading,5815,"11:57.862 INFO IntelPairHmm - Requested threads: 4; 19:11:57.862 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 19:11:57.862 INFO ProgressMeter - Starting traversal; 19:11:57.862 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; *** glibc detected *** /for/bar/bin/java: double free or corruption (out): 0x00007f450af58700 ***; ======= Backtrace: =========; /lib64/libc.so.6(+0x3d01675dee)[0x7f45058afdee]; /lib64/libc.so.6(+0x3d01678c80)[0x7f45058b2c80]; /tmp/libgkl_smithwaterman410767516409374085.so(_Z19runSWOnePairBT_avx2iiiiPhS_iiaPcPs+0x338)[0x7f4499f4cfa8]; /tmp/libgkl_smithwaterman410767516409374085.so(Java_com_intel_gkl_smithwaterman_IntelSmithWaterman_alignNative+0xd8)[0x7f4499f4cbf8]; [0x7f44f58be6a2]; ======= Memory map: ========; ```. Then we **disabled** AVX2 in the newer cluster using Intels [sde64](https://software.intel.com/en-us/articles/intel-software-development-emulator) with `-ivb`, which directed GATK to use the Java implementation, and the filter worked without core dump. ```; sde64 -ivb -- faa.sh; Using GATK jar /app/gatk-package-4.1.8.0-local.jar; Running:; /bin/java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /app/gatk-package-4.1.8.0-local.jar FilterAlignmentArtifacts -V /output/sample.FilterMutectCalls.vcf.gz -R /db/hs37d5.fa --bwa-mem-index-image /ref/hg38.fa.img -I /output/sample.Mutect2.bam -O sample.somatic_filter2.test.vcf.gz --use-jdk-inflater true --use-jdk-deflater true; 19:41:38.956 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/app/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_utils.so; 19:41:39.332 INFO SmithWatermanAligner - AVX accelerated SmithWaterman implementation is not supported, falling back to the Java implementation; ```; Hope this helps and we're looking forward the GKL fix. Cheers,; Richard",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-660645356
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-660645356:1602,Safety,detect,detect,1602,"bble=false -Dsamjdk.compression_level=2 -jar /app/gatk-package-4.1.8.0-local.jar FilterAlignmentArtifacts -V /output/sample.FilterMutectCalls.vcf.gz -R /db/hs37d5.fa --bwa-mem-index-image /db/hg38.fa.img -I /output/sample.Mutect2.bam -O sample.somatic_filter.test.vcf.gz --use-jdk-inflater true; 19:11:56.929 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/app/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_utils.so; 19:11:56.943 INFO NativeLibraryLoader - Loading libgkl_smithwaterman.so from jar:file:/app/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_smithwaterman.so; 19:11:56.944 INFO SmithWatermanAligner - Using AVX accelerated SmithWaterman implementation; 19:11:57.168 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/app/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Jul 19, 2020 7:11:57 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 19:11:57.324 INFO FilterAlignmentArtifacts - ------------------------------------------------------------; 19:11:57.324 INFO FilterAlignmentArtifacts - The Genome Analysis Toolkit (GATK) v4.1.8.0; 19:11:57.325 INFO FilterAlignmentArtifacts - For support and documentation go to https://software.broadinstitute.org/gatk/; 19:11:57.325 INFO FilterAlignmentArtifacts - Executing as foo@bar.local on Linux v2.6.32-696.6.3.el6.x86_64 amd64; 19:11:57.325 INFO FilterAlignmentArtifacts - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_261-b12; 19:11:57.325 INFO FilterAlignmentArtifacts - Start Date/Time: July 19, 2020 7:11:57 PM CST; 19:11:57.325 INFO FilterAlignmentArtifacts - ------------------------------------------------------------; 19:11:57.325 INFO FilterAlignmentArtifacts - ------------------------------------------------------------; 19:11:57.325 INFO FilterAlignmentArtifacts - HTSJDK Version: 2.22.0; 19:11:57.325 INFO ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-660645356
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-660645356:4472,Safety,detect,detected,4472,"d should not be used for production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 19:11:57.326 INFO FilterAlignmentArtifacts - Initializing engine; 19:11:57.666 INFO FeatureManager - Using codec VCFCodec to read file file:///output/sample.FilterMutectCalls.vcf.gz; 19:11:57.757 INFO FilterAlignmentArtifacts - Done initializing engine; 19:11:57.827 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/app/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 19:11:57.861 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 19:11:57.862 INFO IntelPairHmm - Available threads: 4; 19:11:57.862 INFO IntelPairHmm - Requested threads: 4; 19:11:57.862 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 19:11:57.862 INFO ProgressMeter - Starting traversal; 19:11:57.862 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; *** glibc detected *** /for/bar/bin/java: double free or corruption (out): 0x00007f450af58700 ***; ======= Backtrace: =========; /lib64/libc.so.6(+0x3d01675dee)[0x7f45058afdee]; /lib64/libc.so.6(+0x3d01678c80)[0x7f45058b2c80]; /tmp/libgkl_smithwaterman410767516409374085.so(_Z19runSWOnePairBT_avx2iiiiPhS_iiaPcPs+0x338)[0x7f4499f4cfa8]; /tmp/libgkl_smithwaterman410767516409374085.so(Java_com_intel_gkl_smithwaterman_IntelSmithWaterman_alignNative+0xd8)[0x7f4499f4cbf8]; [0x7f44f58be6a2]; ======= Memory map: ========; ```. Then we **disabled** AVX2 in the newer cluster using Intels [sde64](https://software.intel.com/en-us/articles/intel-software-development-emulator) with `-ivb`, which directed GATK to use the Java implementation, and the filter worked without core dump. ```; sde64 -ivb -- faa.sh; Using GATK jar /app/gatk-package-4.1.8.0-local.jar; Running:; /bin/java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_le",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-660645356
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-660645356:856,Testability,test,test,856,"Hi @lbergelson,. We experienced the related issue in GATK 4.1.8 (it persisted since 4.1.5 or early version as far as we know) when running `FilterAlignmentArtifacts` in one of our cluster but not the other. We narrowed down the issue, using the CPU differences (the working one does not support AVX2), to `libgkl_smithwaterman.so`. Paths are shortened for clarity in the following commands. ```; bash faa.sh ; Using GATK jar /app/gatk-package-4.1.8.0-local.jar; Running:; /bin/java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /app/gatk-package-4.1.8.0-local.jar FilterAlignmentArtifacts -V /output/sample.FilterMutectCalls.vcf.gz -R /db/hs37d5.fa --bwa-mem-index-image /db/hg38.fa.img -I /output/sample.Mutect2.bam -O sample.somatic_filter.test.vcf.gz --use-jdk-inflater true; 19:11:56.929 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/app/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_utils.so; 19:11:56.943 INFO NativeLibraryLoader - Loading libgkl_smithwaterman.so from jar:file:/app/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_smithwaterman.so; 19:11:56.944 INFO SmithWatermanAligner - Using AVX accelerated SmithWaterman implementation; 19:11:57.168 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/app/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Jul 19, 2020 7:11:57 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 19:11:57.324 INFO FilterAlignmentArtifacts - ------------------------------------------------------------; 19:11:57.324 INFO FilterAlignmentArtifacts - The Genome Analysis Toolkit (GATK) v4.1.8.0; 19:11:57.325 INFO FilterAlignmentArtifacts - For support and documentation go to https://software.broadinstitute.org/gatk/; 19:11:57.325 INFO Fil",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-660645356
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-660645356:5714,Testability,test,test,5714,"11:57.862 INFO IntelPairHmm - Requested threads: 4; 19:11:57.862 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 19:11:57.862 INFO ProgressMeter - Starting traversal; 19:11:57.862 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; *** glibc detected *** /for/bar/bin/java: double free or corruption (out): 0x00007f450af58700 ***; ======= Backtrace: =========; /lib64/libc.so.6(+0x3d01675dee)[0x7f45058afdee]; /lib64/libc.so.6(+0x3d01678c80)[0x7f45058b2c80]; /tmp/libgkl_smithwaterman410767516409374085.so(_Z19runSWOnePairBT_avx2iiiiPhS_iiaPcPs+0x338)[0x7f4499f4cfa8]; /tmp/libgkl_smithwaterman410767516409374085.so(Java_com_intel_gkl_smithwaterman_IntelSmithWaterman_alignNative+0xd8)[0x7f4499f4cbf8]; [0x7f44f58be6a2]; ======= Memory map: ========; ```. Then we **disabled** AVX2 in the newer cluster using Intels [sde64](https://software.intel.com/en-us/articles/intel-software-development-emulator) with `-ivb`, which directed GATK to use the Java implementation, and the filter worked without core dump. ```; sde64 -ivb -- faa.sh; Using GATK jar /app/gatk-package-4.1.8.0-local.jar; Running:; /bin/java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /app/gatk-package-4.1.8.0-local.jar FilterAlignmentArtifacts -V /output/sample.FilterMutectCalls.vcf.gz -R /db/hs37d5.fa --bwa-mem-index-image /ref/hg38.fa.img -I /output/sample.Mutect2.bam -O sample.somatic_filter2.test.vcf.gz --use-jdk-inflater true --use-jdk-deflater true; 19:41:38.956 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/app/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_utils.so; 19:41:39.332 INFO SmithWatermanAligner - AVX accelerated SmithWaterman implementation is not supported, falling back to the Java implementation; ```; Hope this helps and we're looking forward the GKL fix. Cheers,; Richard",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-660645356
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-664539860:73,Availability,error,error,73,"Hello @lbergelson @mepowers . `FilterAlignmentArtifacts` task fails with error `munmap_chunk(): invalid pointer` when running mutect2 (WES Tumor-Normal) on Terra. ; I've included log file and runtime paramaters that i used just in case. used both latest gatk version- `4.1.8.1` and previous version `4.1.8.0`. runtime_params; gatk version- `4.1.8.1`; `{ ""boot_disk_size"": 12, ""command_mem"": 15500, ""cpu"": 4, ""disk"": 310, ""gatk_docker"": ""us.gcr.io/broad-gatk/gatk@sha256:8051adab0ff725e7e9c2af5997680346f3c3799b2df3785dd51d4abdd3da747b"", ""gatk_override"": null, ""machine_mem"": 16000, ""max_retries"": 2, ""preemptible"": 2 }`. runtime_params; gatk version- `4.1.8.0`. `{ ""boot_disk_size"": 12, ""command_mem"": 15500, ""cpu"": 4, ""disk"": 310, ""gatk_docker"": ""us.gcr.io/broad-gatk/gatk:4.1.8.0"", ""gatk_override"": null, ""machine_mem"": 16000, ""max_retries"": 2, ""preemptible"": 2 }`. log file; ````; 2020/07/25 01:37:53 Starting container setup.; 2020/07/25 01:37:55 Done container setup.; 2020/07/25 01:37:56 Starting localization.; 2020/07/25 01:38:02 Localization script execution started...; 2020/07/25 01:38:02 Localizing input gs://gatk-test-data/mutect2/Homo_sapiens_assembly38.index_bundle -> /cromwell_root/gatk-test-data/mutect2/Homo_sapiens_assembly38.index_bundle; 2020/07/25 01:38:40 Localizing input gs://fc-ac4624cb-a8fc-49a2-b071-d3a0ae799418/cb1feccb-0a69-42bf-ba5f-fde762934a59/Mutect2/fe3623c8-0eaf-4cd4-9f81-d1fda4073f2e/call-FilterAlignmentArtifacts/attempt-3/script -> /cromwell_root/script; 2020/07/25 01:38:45 Localization script execution complete.; 2020/07/25 01:38:58 Done localization.; 2020/07/25 01:38:59 Running user action: docker run -v /mnt/local-disk:/cromwell_root --entrypoint= us.gcr.io/broad-gatk/gatk@sha256:8051adab0ff725e7e9c2af5997680346f3c3799b2df3785dd51d4abdd3da747b /bin/bash /cromwell_root/script; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp.6c58e0ba; 01:39:02.909 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/gatk/gatk-package-4.1",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-664539860
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-664539860:5083,Availability,Avail,Available,5083,.364 INFO FilterAlignmentArtifacts - Requester pays: disabled; 01:39:03.364 WARN FilterAlignmentArtifacts - . [1m[31m !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: FilterAlignmentArtifacts is an EXPERIMENTAL tool and should not be used for production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!![0m. 01:39:03.364 INFO FilterAlignmentArtifacts - Initializing engine; 01:39:07.644 INFO FeatureManager - Using codec VCFCodec to read file gs://fc-ac4624cb-a8fc-49a2-b071-d3a0ae799418/cb1feccb-0a69-42bf-ba5f-fde762934a59/Mutect2/fe3623c8-0eaf-4cd4-9f81-d1fda4073f2e/call-Filter/22.hg38-filtered.vcf; 01:39:08.399 INFO FilterAlignmentArtifacts - Done initializing engine; 01:39:09.523 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/gatk/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 01:39:09.565 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 01:39:09.566 INFO IntelPairHmm - Available threads: 4; 01:39:09.566 INFO IntelPairHmm - Requested threads: 4; 01:39:09.566 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 01:39:09.567 INFO ProgressMeter - Starting traversal; 01:39:09.567 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; munmap_chunk(): invalid pointer; Using GATK jar /root/gatk.jar defined in environment variable GATK_LOCAL_JAR; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx11500m -jar /root/gatk.jar FilterAlignmentArtifacts -R gs://gcp-public-data--broad-references/hg38/v0/Homo_sapiens_assembly38.fasta -V gs://fc-ac4624cb-a8fc-49a2-b071-d3a0ae799418/cb1feccb-0a69-42bf-ba5f-fde762934a59/Mutect2/fe3623c8-0eaf-4cd4-9f81-d1fda4073f2e/call-Filter/22.hg38-filtered.vcf -I gs://fc-ac4624cb-a8fc-49a2-b071-d3a0ae799418/209d1183-ed9a-4755-a4b3-d595797640ea/P,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-664539860
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-664539860:5507,Modifiability,variab,variable,5507,tureManager - Using codec VCFCodec to read file gs://fc-ac4624cb-a8fc-49a2-b071-d3a0ae799418/cb1feccb-0a69-42bf-ba5f-fde762934a59/Mutect2/fe3623c8-0eaf-4cd4-9f81-d1fda4073f2e/call-Filter/22.hg38-filtered.vcf; 01:39:08.399 INFO FilterAlignmentArtifacts - Done initializing engine; 01:39:09.523 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/gatk/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 01:39:09.565 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 01:39:09.566 INFO IntelPairHmm - Available threads: 4; 01:39:09.566 INFO IntelPairHmm - Requested threads: 4; 01:39:09.566 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 01:39:09.567 INFO ProgressMeter - Starting traversal; 01:39:09.567 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; munmap_chunk(): invalid pointer; Using GATK jar /root/gatk.jar defined in environment variable GATK_LOCAL_JAR; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx11500m -jar /root/gatk.jar FilterAlignmentArtifacts -R gs://gcp-public-data--broad-references/hg38/v0/Homo_sapiens_assembly38.fasta -V gs://fc-ac4624cb-a8fc-49a2-b071-d3a0ae799418/cb1feccb-0a69-42bf-ba5f-fde762934a59/Mutect2/fe3623c8-0eaf-4cd4-9f81-d1fda4073f2e/call-Filter/22.hg38-filtered.vcf -I gs://fc-ac4624cb-a8fc-49a2-b071-d3a0ae799418/209d1183-ed9a-4755-a4b3-d595797640ea/PreProcessingForVariantDiscovery_GATK4/9f7c0ab6-b61b-4797-92f1-7929bbf677d8/call-GatherBamFiles/22.hg38.bam --bwa-mem-index-image /cromwell_root/gatk-test-data/mutect2/Homo_sapiens_assembly38.index_bundle -O 22.hg38-filtered.vcf; 2020/07/25 01:46:01 Starting delocalization.; 2020/07/25 01:46:02 Delocalization script execution started...; 2020/07/25 01:46:02 Delocalizing output /cromwell_root/memory_retry_rc -> gs://fc-ac4624cb-a,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-664539860
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-664539860:1941,Performance,Load,Loading,1941,07/25 01:37:55 Done container setup.; 2020/07/25 01:37:56 Starting localization.; 2020/07/25 01:38:02 Localization script execution started...; 2020/07/25 01:38:02 Localizing input gs://gatk-test-data/mutect2/Homo_sapiens_assembly38.index_bundle -> /cromwell_root/gatk-test-data/mutect2/Homo_sapiens_assembly38.index_bundle; 2020/07/25 01:38:40 Localizing input gs://fc-ac4624cb-a8fc-49a2-b071-d3a0ae799418/cb1feccb-0a69-42bf-ba5f-fde762934a59/Mutect2/fe3623c8-0eaf-4cd4-9f81-d1fda4073f2e/call-FilterAlignmentArtifacts/attempt-3/script -> /cromwell_root/script; 2020/07/25 01:38:45 Localization script execution complete.; 2020/07/25 01:38:58 Done localization.; 2020/07/25 01:38:59 Running user action: docker run -v /mnt/local-disk:/cromwell_root --entrypoint= us.gcr.io/broad-gatk/gatk@sha256:8051adab0ff725e7e9c2af5997680346f3c3799b2df3785dd51d4abdd3da747b /bin/bash /cromwell_root/script; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp.6c58e0ba; 01:39:02.909 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/gatk/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_utils.so; 01:39:02.925 INFO NativeLibraryLoader - Loading libgkl_smithwaterman.so from jar:file:/gatk/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_smithwaterman.so; 01:39:02.927 INFO SmithWatermanAligner - Using AVX accelerated SmithWaterman implementation; 01:39:03.142 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; 01:39:03.361 INFO FilterAlignmentArtifacts - ------------------------------------------------------------; 01:39:03.361 INFO FilterAlignmentArtifacts - The Genome Analysis Toolkit (GATK) v4.1.8.1; 01:39:03.361 INFO FilterAlignmentArtifacts - For support and documentation go to https://software.broadinstitute.org/gatk/; 01:39:03.362 INFO FilterAlignmentArtifacts - Executing as root@3f245e278eba on Linux v4.19.112+ amd64; 01:39:03.362 INFO FilterAlig,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-664539860
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-664539860:2095,Performance,Load,Loading,2095,38:02 Localizing input gs://gatk-test-data/mutect2/Homo_sapiens_assembly38.index_bundle -> /cromwell_root/gatk-test-data/mutect2/Homo_sapiens_assembly38.index_bundle; 2020/07/25 01:38:40 Localizing input gs://fc-ac4624cb-a8fc-49a2-b071-d3a0ae799418/cb1feccb-0a69-42bf-ba5f-fde762934a59/Mutect2/fe3623c8-0eaf-4cd4-9f81-d1fda4073f2e/call-FilterAlignmentArtifacts/attempt-3/script -> /cromwell_root/script; 2020/07/25 01:38:45 Localization script execution complete.; 2020/07/25 01:38:58 Done localization.; 2020/07/25 01:38:59 Running user action: docker run -v /mnt/local-disk:/cromwell_root --entrypoint= us.gcr.io/broad-gatk/gatk@sha256:8051adab0ff725e7e9c2af5997680346f3c3799b2df3785dd51d4abdd3da747b /bin/bash /cromwell_root/script; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp.6c58e0ba; 01:39:02.909 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/gatk/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_utils.so; 01:39:02.925 INFO NativeLibraryLoader - Loading libgkl_smithwaterman.so from jar:file:/gatk/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_smithwaterman.so; 01:39:02.927 INFO SmithWatermanAligner - Using AVX accelerated SmithWaterman implementation; 01:39:03.142 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; 01:39:03.361 INFO FilterAlignmentArtifacts - ------------------------------------------------------------; 01:39:03.361 INFO FilterAlignmentArtifacts - The Genome Analysis Toolkit (GATK) v4.1.8.1; 01:39:03.361 INFO FilterAlignmentArtifacts - For support and documentation go to https://software.broadinstitute.org/gatk/; 01:39:03.362 INFO FilterAlignmentArtifacts - Executing as root@3f245e278eba on Linux v4.19.112+ amd64; 01:39:03.362 INFO FilterAlignmentArtifacts - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_242-8u242-b08-0ubuntu3~18.04-b08; 01:39:03.362 INFO FilterAlignmentArtifacts - Start Date/Time:,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-664539860
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-664539860:2358,Performance,Load,Loading,2358,"-42bf-ba5f-fde762934a59/Mutect2/fe3623c8-0eaf-4cd4-9f81-d1fda4073f2e/call-FilterAlignmentArtifacts/attempt-3/script -> /cromwell_root/script; 2020/07/25 01:38:45 Localization script execution complete.; 2020/07/25 01:38:58 Done localization.; 2020/07/25 01:38:59 Running user action: docker run -v /mnt/local-disk:/cromwell_root --entrypoint= us.gcr.io/broad-gatk/gatk@sha256:8051adab0ff725e7e9c2af5997680346f3c3799b2df3785dd51d4abdd3da747b /bin/bash /cromwell_root/script; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp.6c58e0ba; 01:39:02.909 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/gatk/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_utils.so; 01:39:02.925 INFO NativeLibraryLoader - Loading libgkl_smithwaterman.so from jar:file:/gatk/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_smithwaterman.so; 01:39:02.927 INFO SmithWatermanAligner - Using AVX accelerated SmithWaterman implementation; 01:39:03.142 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gatk/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; 01:39:03.361 INFO FilterAlignmentArtifacts - ------------------------------------------------------------; 01:39:03.361 INFO FilterAlignmentArtifacts - The Genome Analysis Toolkit (GATK) v4.1.8.1; 01:39:03.361 INFO FilterAlignmentArtifacts - For support and documentation go to https://software.broadinstitute.org/gatk/; 01:39:03.362 INFO FilterAlignmentArtifacts - Executing as root@3f245e278eba on Linux v4.19.112+ amd64; 01:39:03.362 INFO FilterAlignmentArtifacts - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_242-8u242-b08-0ubuntu3~18.04-b08; 01:39:03.362 INFO FilterAlignmentArtifacts - Start Date/Time: July 25, 2020 1:39:03 AM GMT; 01:39:03.362 INFO FilterAlignmentArtifacts - ------------------------------------------------------------; 01:39:03.362 INFO FilterAlignmentArtifacts - ------------------------------------------------------------; 01:39:03.363 INFO",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-664539860
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-664539860:4838,Performance,Load,Loading,4838,_WRITE_FOR_TRIBBLE : false; 01:39:03.364 INFO FilterAlignmentArtifacts - Deflater: IntelDeflater; 01:39:03.364 INFO FilterAlignmentArtifacts - Inflater: IntelInflater; 01:39:03.364 INFO FilterAlignmentArtifacts - GCS max retries/reopens: 20; 01:39:03.364 INFO FilterAlignmentArtifacts - Requester pays: disabled; 01:39:03.364 WARN FilterAlignmentArtifacts - . [1m[31m !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: FilterAlignmentArtifacts is an EXPERIMENTAL tool and should not be used for production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!![0m. 01:39:03.364 INFO FilterAlignmentArtifacts - Initializing engine; 01:39:07.644 INFO FeatureManager - Using codec VCFCodec to read file gs://fc-ac4624cb-a8fc-49a2-b071-d3a0ae799418/cb1feccb-0a69-42bf-ba5f-fde762934a59/Mutect2/fe3623c8-0eaf-4cd4-9f81-d1fda4073f2e/call-Filter/22.hg38-filtered.vcf; 01:39:08.399 INFO FilterAlignmentArtifacts - Done initializing engine; 01:39:09.523 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/gatk/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 01:39:09.565 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 01:39:09.566 INFO IntelPairHmm - Available threads: 4; 01:39:09.566 INFO IntelPairHmm - Requested threads: 4; 01:39:09.566 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 01:39:09.567 INFO ProgressMeter - Starting traversal; 01:39:09.567 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; munmap_chunk(): invalid pointer; Using GATK jar /root/gatk.jar defined in environment variable GATK_LOCAL_JAR; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx11500m -jar /root/gatk.jar FilterAlignmentArtifacts -R gs://gcp-public-data--broad-references/hg38/v0/Homo_sapiens_assembly38.fast,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-664539860
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-664539860:5205,Performance,multi-thread,multi-threaded,5205,!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: FilterAlignmentArtifacts is an EXPERIMENTAL tool and should not be used for production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!![0m. 01:39:03.364 INFO FilterAlignmentArtifacts - Initializing engine; 01:39:07.644 INFO FeatureManager - Using codec VCFCodec to read file gs://fc-ac4624cb-a8fc-49a2-b071-d3a0ae799418/cb1feccb-0a69-42bf-ba5f-fde762934a59/Mutect2/fe3623c8-0eaf-4cd4-9f81-d1fda4073f2e/call-Filter/22.hg38-filtered.vcf; 01:39:08.399 INFO FilterAlignmentArtifacts - Done initializing engine; 01:39:09.523 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/gatk/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 01:39:09.565 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 01:39:09.566 INFO IntelPairHmm - Available threads: 4; 01:39:09.566 INFO IntelPairHmm - Requested threads: 4; 01:39:09.566 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 01:39:09.567 INFO ProgressMeter - Starting traversal; 01:39:09.567 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; munmap_chunk(): invalid pointer; Using GATK jar /root/gatk.jar defined in environment variable GATK_LOCAL_JAR; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx11500m -jar /root/gatk.jar FilterAlignmentArtifacts -R gs://gcp-public-data--broad-references/hg38/v0/Homo_sapiens_assembly38.fasta -V gs://fc-ac4624cb-a8fc-49a2-b071-d3a0ae799418/cb1feccb-0a69-42bf-ba5f-fde762934a59/Mutect2/fe3623c8-0eaf-4cd4-9f81-d1fda4073f2e/call-Filter/22.hg38-filtered.vcf -I gs://fc-ac4624cb-a8fc-49a2-b071-d3a0ae799418/209d1183-ed9a-4755-a4b3-d595797640ea/PreProcessingForVariantDiscovery_GATK4/9f7c0ab6-b61b-4797-92f1-7929bbf677d8/call-GatherBamFiles/22.hg38.bam --bwa-mem-index-image /cromwe,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-664539860
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-664539860:179,Testability,log,log,179,"Hello @lbergelson @mepowers . `FilterAlignmentArtifacts` task fails with error `munmap_chunk(): invalid pointer` when running mutect2 (WES Tumor-Normal) on Terra. ; I've included log file and runtime paramaters that i used just in case. used both latest gatk version- `4.1.8.1` and previous version `4.1.8.0`. runtime_params; gatk version- `4.1.8.1`; `{ ""boot_disk_size"": 12, ""command_mem"": 15500, ""cpu"": 4, ""disk"": 310, ""gatk_docker"": ""us.gcr.io/broad-gatk/gatk@sha256:8051adab0ff725e7e9c2af5997680346f3c3799b2df3785dd51d4abdd3da747b"", ""gatk_override"": null, ""machine_mem"": 16000, ""max_retries"": 2, ""preemptible"": 2 }`. runtime_params; gatk version- `4.1.8.0`. `{ ""boot_disk_size"": 12, ""command_mem"": 15500, ""cpu"": 4, ""disk"": 310, ""gatk_docker"": ""us.gcr.io/broad-gatk/gatk:4.1.8.0"", ""gatk_override"": null, ""machine_mem"": 16000, ""max_retries"": 2, ""preemptible"": 2 }`. log file; ````; 2020/07/25 01:37:53 Starting container setup.; 2020/07/25 01:37:55 Done container setup.; 2020/07/25 01:37:56 Starting localization.; 2020/07/25 01:38:02 Localization script execution started...; 2020/07/25 01:38:02 Localizing input gs://gatk-test-data/mutect2/Homo_sapiens_assembly38.index_bundle -> /cromwell_root/gatk-test-data/mutect2/Homo_sapiens_assembly38.index_bundle; 2020/07/25 01:38:40 Localizing input gs://fc-ac4624cb-a8fc-49a2-b071-d3a0ae799418/cb1feccb-0a69-42bf-ba5f-fde762934a59/Mutect2/fe3623c8-0eaf-4cd4-9f81-d1fda4073f2e/call-FilterAlignmentArtifacts/attempt-3/script -> /cromwell_root/script; 2020/07/25 01:38:45 Localization script execution complete.; 2020/07/25 01:38:58 Done localization.; 2020/07/25 01:38:59 Running user action: docker run -v /mnt/local-disk:/cromwell_root --entrypoint= us.gcr.io/broad-gatk/gatk@sha256:8051adab0ff725e7e9c2af5997680346f3c3799b2df3785dd51d4abdd3da747b /bin/bash /cromwell_root/script; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp.6c58e0ba; 01:39:02.909 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/gatk/gatk-package-4.1",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-664539860
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-664539860:868,Testability,log,log,868,"Hello @lbergelson @mepowers . `FilterAlignmentArtifacts` task fails with error `munmap_chunk(): invalid pointer` when running mutect2 (WES Tumor-Normal) on Terra. ; I've included log file and runtime paramaters that i used just in case. used both latest gatk version- `4.1.8.1` and previous version `4.1.8.0`. runtime_params; gatk version- `4.1.8.1`; `{ ""boot_disk_size"": 12, ""command_mem"": 15500, ""cpu"": 4, ""disk"": 310, ""gatk_docker"": ""us.gcr.io/broad-gatk/gatk@sha256:8051adab0ff725e7e9c2af5997680346f3c3799b2df3785dd51d4abdd3da747b"", ""gatk_override"": null, ""machine_mem"": 16000, ""max_retries"": 2, ""preemptible"": 2 }`. runtime_params; gatk version- `4.1.8.0`. `{ ""boot_disk_size"": 12, ""command_mem"": 15500, ""cpu"": 4, ""disk"": 310, ""gatk_docker"": ""us.gcr.io/broad-gatk/gatk:4.1.8.0"", ""gatk_override"": null, ""machine_mem"": 16000, ""max_retries"": 2, ""preemptible"": 2 }`. log file; ````; 2020/07/25 01:37:53 Starting container setup.; 2020/07/25 01:37:55 Done container setup.; 2020/07/25 01:37:56 Starting localization.; 2020/07/25 01:38:02 Localization script execution started...; 2020/07/25 01:38:02 Localizing input gs://gatk-test-data/mutect2/Homo_sapiens_assembly38.index_bundle -> /cromwell_root/gatk-test-data/mutect2/Homo_sapiens_assembly38.index_bundle; 2020/07/25 01:38:40 Localizing input gs://fc-ac4624cb-a8fc-49a2-b071-d3a0ae799418/cb1feccb-0a69-42bf-ba5f-fde762934a59/Mutect2/fe3623c8-0eaf-4cd4-9f81-d1fda4073f2e/call-FilterAlignmentArtifacts/attempt-3/script -> /cromwell_root/script; 2020/07/25 01:38:45 Localization script execution complete.; 2020/07/25 01:38:58 Done localization.; 2020/07/25 01:38:59 Running user action: docker run -v /mnt/local-disk:/cromwell_root --entrypoint= us.gcr.io/broad-gatk/gatk@sha256:8051adab0ff725e7e9c2af5997680346f3c3799b2df3785dd51d4abdd3da747b /bin/bash /cromwell_root/script; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp.6c58e0ba; 01:39:02.909 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/gatk/gatk-package-4.1",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-664539860
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-664539860:1127,Testability,test,test-data,1127,"ng mutect2 (WES Tumor-Normal) on Terra. ; I've included log file and runtime paramaters that i used just in case. used both latest gatk version- `4.1.8.1` and previous version `4.1.8.0`. runtime_params; gatk version- `4.1.8.1`; `{ ""boot_disk_size"": 12, ""command_mem"": 15500, ""cpu"": 4, ""disk"": 310, ""gatk_docker"": ""us.gcr.io/broad-gatk/gatk@sha256:8051adab0ff725e7e9c2af5997680346f3c3799b2df3785dd51d4abdd3da747b"", ""gatk_override"": null, ""machine_mem"": 16000, ""max_retries"": 2, ""preemptible"": 2 }`. runtime_params; gatk version- `4.1.8.0`. `{ ""boot_disk_size"": 12, ""command_mem"": 15500, ""cpu"": 4, ""disk"": 310, ""gatk_docker"": ""us.gcr.io/broad-gatk/gatk:4.1.8.0"", ""gatk_override"": null, ""machine_mem"": 16000, ""max_retries"": 2, ""preemptible"": 2 }`. log file; ````; 2020/07/25 01:37:53 Starting container setup.; 2020/07/25 01:37:55 Done container setup.; 2020/07/25 01:37:56 Starting localization.; 2020/07/25 01:38:02 Localization script execution started...; 2020/07/25 01:38:02 Localizing input gs://gatk-test-data/mutect2/Homo_sapiens_assembly38.index_bundle -> /cromwell_root/gatk-test-data/mutect2/Homo_sapiens_assembly38.index_bundle; 2020/07/25 01:38:40 Localizing input gs://fc-ac4624cb-a8fc-49a2-b071-d3a0ae799418/cb1feccb-0a69-42bf-ba5f-fde762934a59/Mutect2/fe3623c8-0eaf-4cd4-9f81-d1fda4073f2e/call-FilterAlignmentArtifacts/attempt-3/script -> /cromwell_root/script; 2020/07/25 01:38:45 Localization script execution complete.; 2020/07/25 01:38:58 Done localization.; 2020/07/25 01:38:59 Running user action: docker run -v /mnt/local-disk:/cromwell_root --entrypoint= us.gcr.io/broad-gatk/gatk@sha256:8051adab0ff725e7e9c2af5997680346f3c3799b2df3785dd51d4abdd3da747b /bin/bash /cromwell_root/script; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp.6c58e0ba; 01:39:02.909 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/gatk/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_utils.so; 01:39:02.925 INFO NativeLibraryLoader - Loading libgkl_smithwaterman.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-664539860
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-664539860:1205,Testability,test,test-data,1205,"rs that i used just in case. used both latest gatk version- `4.1.8.1` and previous version `4.1.8.0`. runtime_params; gatk version- `4.1.8.1`; `{ ""boot_disk_size"": 12, ""command_mem"": 15500, ""cpu"": 4, ""disk"": 310, ""gatk_docker"": ""us.gcr.io/broad-gatk/gatk@sha256:8051adab0ff725e7e9c2af5997680346f3c3799b2df3785dd51d4abdd3da747b"", ""gatk_override"": null, ""machine_mem"": 16000, ""max_retries"": 2, ""preemptible"": 2 }`. runtime_params; gatk version- `4.1.8.0`. `{ ""boot_disk_size"": 12, ""command_mem"": 15500, ""cpu"": 4, ""disk"": 310, ""gatk_docker"": ""us.gcr.io/broad-gatk/gatk:4.1.8.0"", ""gatk_override"": null, ""machine_mem"": 16000, ""max_retries"": 2, ""preemptible"": 2 }`. log file; ````; 2020/07/25 01:37:53 Starting container setup.; 2020/07/25 01:37:55 Done container setup.; 2020/07/25 01:37:56 Starting localization.; 2020/07/25 01:38:02 Localization script execution started...; 2020/07/25 01:38:02 Localizing input gs://gatk-test-data/mutect2/Homo_sapiens_assembly38.index_bundle -> /cromwell_root/gatk-test-data/mutect2/Homo_sapiens_assembly38.index_bundle; 2020/07/25 01:38:40 Localizing input gs://fc-ac4624cb-a8fc-49a2-b071-d3a0ae799418/cb1feccb-0a69-42bf-ba5f-fde762934a59/Mutect2/fe3623c8-0eaf-4cd4-9f81-d1fda4073f2e/call-FilterAlignmentArtifacts/attempt-3/script -> /cromwell_root/script; 2020/07/25 01:38:45 Localization script execution complete.; 2020/07/25 01:38:58 Done localization.; 2020/07/25 01:38:59 Running user action: docker run -v /mnt/local-disk:/cromwell_root --entrypoint= us.gcr.io/broad-gatk/gatk@sha256:8051adab0ff725e7e9c2af5997680346f3c3799b2df3785dd51d4abdd3da747b /bin/bash /cromwell_root/script; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp.6c58e0ba; 01:39:02.909 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/gatk/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_utils.so; 01:39:02.925 INFO NativeLibraryLoader - Loading libgkl_smithwaterman.so from jar:file:/gatk/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_s",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-664539860
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-664539860:6236,Testability,test,test-data,6236,d native PairHMM implementation; 01:39:09.567 INFO ProgressMeter - Starting traversal; 01:39:09.567 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; munmap_chunk(): invalid pointer; Using GATK jar /root/gatk.jar defined in environment variable GATK_LOCAL_JAR; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx11500m -jar /root/gatk.jar FilterAlignmentArtifacts -R gs://gcp-public-data--broad-references/hg38/v0/Homo_sapiens_assembly38.fasta -V gs://fc-ac4624cb-a8fc-49a2-b071-d3a0ae799418/cb1feccb-0a69-42bf-ba5f-fde762934a59/Mutect2/fe3623c8-0eaf-4cd4-9f81-d1fda4073f2e/call-Filter/22.hg38-filtered.vcf -I gs://fc-ac4624cb-a8fc-49a2-b071-d3a0ae799418/209d1183-ed9a-4755-a4b3-d595797640ea/PreProcessingForVariantDiscovery_GATK4/9f7c0ab6-b61b-4797-92f1-7929bbf677d8/call-GatherBamFiles/22.hg38.bam --bwa-mem-index-image /cromwell_root/gatk-test-data/mutect2/Homo_sapiens_assembly38.index_bundle -O 22.hg38-filtered.vcf; 2020/07/25 01:46:01 Starting delocalization.; 2020/07/25 01:46:02 Delocalization script execution started...; 2020/07/25 01:46:02 Delocalizing output /cromwell_root/memory_retry_rc -> gs://fc-ac4624cb-a8fc-49a2-b071-d3a0ae799418/cb1feccb-0a69-42bf-ba5f-fde762934a59/Mutect2/fe3623c8-0eaf-4cd4-9f81-d1fda4073f2e/call-FilterAlignmentArtifacts/attempt-3/memory_retry_rc; 2020/07/25 01:46:02 Delocalizing output /cromwell_root/rc -> gs://fc-ac4624cb-a8fc-49a2-b071-d3a0ae799418/cb1feccb-0a69-42bf-ba5f-fde762934a59/Mutect2/fe3623c8-0eaf-4cd4-9f81-d1fda4073f2e/call-FilterAlignmentArtifacts/attempt-3/rc; 2020/07/25 01:46:04 Delocalizing output /cromwell_root/stdout -> gs://fc-ac4624cb-a8fc-49a2-b071-d3a0ae799418/cb1feccb-0a69-42bf-ba5f-fde762934a59/Mutect2/fe3623c8-0eaf-4cd4-9f81-d1fda4073f2e/call-FilterAlignmentArtifacts/attempt-3/stdout; 2020/07/25 01:46:05 Delocalizing output /cromwell_root/stderr -> gs://fc-ac462,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-664539860
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-664678234:104,Deployability,release,release,104,"@sahuno Thanks for the detailed report here. As @lbergelson mentioned above, we're working on a new GKL release and will check if the issues above are resolved with the new release on Linux. We don't currently have plans to test specifically in Terra, but @lbergelson may be able to help pull in the right folks to do so once we get the new GKL release out.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-664678234
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-664678234:173,Deployability,release,release,173,"@sahuno Thanks for the detailed report here. As @lbergelson mentioned above, we're working on a new GKL release and will check if the issues above are resolved with the new release on Linux. We don't currently have plans to test specifically in Terra, but @lbergelson may be able to help pull in the right folks to do so once we get the new GKL release out.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-664678234
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-664678234:345,Deployability,release,release,345,"@sahuno Thanks for the detailed report here. As @lbergelson mentioned above, we're working on a new GKL release and will check if the issues above are resolved with the new release on Linux. We don't currently have plans to test specifically in Terra, but @lbergelson may be able to help pull in the right folks to do so once we get the new GKL release out.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-664678234
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-664678234:224,Testability,test,test,224,"@sahuno Thanks for the detailed report here. As @lbergelson mentioned above, we're working on a new GKL release and will check if the issues above are resolved with the new release on Linux. We don't currently have plans to test specifically in Terra, but @lbergelson may be able to help pull in the right folks to do so once we get the new GKL release out.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-664678234
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-781673098:244,Availability,error,error,244,"I'm getting the same issue on GATK 4.1.9.0 FilterAlignmentArtifacts. This bug has been present for 1 year. Has this been fixed?; Note: There is no work-around because FilterAlignmentArtifacts does not have a --smith-waterman option. Here is my error:; ```; 20:12:42.724 WARN FilterAlignmentArtifacts - . [1m[31m !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: FilterAlignmentArtifacts is an EXPERIMENTAL tool and should not be used for production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!![0m. 20:12:42.725 INFO FilterAlignmentArtifacts - Initializing engine; 20:12:48.403 INFO FeatureManager - Using codec VCFCodec to read file gs://fc-secure-024a1aae-a4f9-4025-aa93-f759f93a8203/50383670-4607-4e59-9bfc-4db970980f0e/Mutect2/773a91ea-25be-4d49-b97c-16527076250c/call-Filter/cacheCopy/TN-20-36-filtered.vcf; 20:12:50.117 INFO FilterAlignmentArtifacts - Done initializing engine; 20:12:51.042 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/gatk/gatk-package-4.1.9.0-SNAPSHOT-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 20:12:51.099 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 20:12:51.100 INFO IntelPairHmm - Available threads: 14; 20:12:51.100 INFO IntelPairHmm - Requested threads: 4; 20:12:51.100 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 20:12:51.100 INFO ProgressMeter - Starting traversal; 20:12:51.100 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 20:20:25.766 INFO ProgressMeter - chr3:104142090 7.6 1000 132.0; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007efc9818177e, pid=24, tid=0x00007f13b3c76700; #; # JRE version: OpenJDK Runtime Environment (8.0_242-b08) (build 1.8.0_242-8u242-b08-0ubuntu3~18.04-b08); # Java VM: OpenJDK 64-Bit Server VM (25.242-b08 mixed mode linux-amd64 ); # Problematic frame:; # C [libgkl_smithwaterman18",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-781673098
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-781673098:1218,Availability,Avail,Available,1218,"an option. Here is my error:; ```; 20:12:42.724 WARN FilterAlignmentArtifacts - . [1m[31m !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: FilterAlignmentArtifacts is an EXPERIMENTAL tool and should not be used for production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!![0m. 20:12:42.725 INFO FilterAlignmentArtifacts - Initializing engine; 20:12:48.403 INFO FeatureManager - Using codec VCFCodec to read file gs://fc-secure-024a1aae-a4f9-4025-aa93-f759f93a8203/50383670-4607-4e59-9bfc-4db970980f0e/Mutect2/773a91ea-25be-4d49-b97c-16527076250c/call-Filter/cacheCopy/TN-20-36-filtered.vcf; 20:12:50.117 INFO FilterAlignmentArtifacts - Done initializing engine; 20:12:51.042 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/gatk/gatk-package-4.1.9.0-SNAPSHOT-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 20:12:51.099 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 20:12:51.100 INFO IntelPairHmm - Available threads: 14; 20:12:51.100 INFO IntelPairHmm - Requested threads: 4; 20:12:51.100 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 20:12:51.100 INFO ProgressMeter - Starting traversal; 20:12:51.100 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 20:20:25.766 INFO ProgressMeter - chr3:104142090 7.6 1000 132.0; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007efc9818177e, pid=24, tid=0x00007f13b3c76700; #; # JRE version: OpenJDK Runtime Environment (8.0_242-b08) (build 1.8.0_242-8u242-b08-0ubuntu3~18.04-b08); # Java VM: OpenJDK 64-Bit Server VM (25.242-b08 mixed mode linux-amd64 ); # Problematic frame:; # C [libgkl_smithwaterman1809483713436863458.so+0x177e] smithWatermanBackTrack(dnaSeqPair*, int, int, int, int, int*, int)+0x60e; #; # Core dump written. Default location: /cromwell_root/core or core.24; #; # An error report file with more informat",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-781673098
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-781673098:1635,Availability,error,error,1635,"!!!!!!!!!!!!!!!![0m. 20:12:42.725 INFO FilterAlignmentArtifacts - Initializing engine; 20:12:48.403 INFO FeatureManager - Using codec VCFCodec to read file gs://fc-secure-024a1aae-a4f9-4025-aa93-f759f93a8203/50383670-4607-4e59-9bfc-4db970980f0e/Mutect2/773a91ea-25be-4d49-b97c-16527076250c/call-Filter/cacheCopy/TN-20-36-filtered.vcf; 20:12:50.117 INFO FilterAlignmentArtifacts - Done initializing engine; 20:12:51.042 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/gatk/gatk-package-4.1.9.0-SNAPSHOT-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 20:12:51.099 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 20:12:51.100 INFO IntelPairHmm - Available threads: 14; 20:12:51.100 INFO IntelPairHmm - Requested threads: 4; 20:12:51.100 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 20:12:51.100 INFO ProgressMeter - Starting traversal; 20:12:51.100 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 20:20:25.766 INFO ProgressMeter - chr3:104142090 7.6 1000 132.0; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007efc9818177e, pid=24, tid=0x00007f13b3c76700; #; # JRE version: OpenJDK Runtime Environment (8.0_242-b08) (build 1.8.0_242-8u242-b08-0ubuntu3~18.04-b08); # Java VM: OpenJDK 64-Bit Server VM (25.242-b08 mixed mode linux-amd64 ); # Problematic frame:; # C [libgkl_smithwaterman1809483713436863458.so+0x177e] smithWatermanBackTrack(dnaSeqPair*, int, int, int, int, int*, int)+0x60e; #; # Core dump written. Default location: /cromwell_root/core or core.24; #; # An error report file with more information is saved as:; # /cromwell_root/hs_err_pid24.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-781673098
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-781673098:2186,Availability,error,error,2186,"!!!!!!!!!!!!!!!![0m. 20:12:42.725 INFO FilterAlignmentArtifacts - Initializing engine; 20:12:48.403 INFO FeatureManager - Using codec VCFCodec to read file gs://fc-secure-024a1aae-a4f9-4025-aa93-f759f93a8203/50383670-4607-4e59-9bfc-4db970980f0e/Mutect2/773a91ea-25be-4d49-b97c-16527076250c/call-Filter/cacheCopy/TN-20-36-filtered.vcf; 20:12:50.117 INFO FilterAlignmentArtifacts - Done initializing engine; 20:12:51.042 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/gatk/gatk-package-4.1.9.0-SNAPSHOT-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 20:12:51.099 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 20:12:51.100 INFO IntelPairHmm - Available threads: 14; 20:12:51.100 INFO IntelPairHmm - Requested threads: 4; 20:12:51.100 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 20:12:51.100 INFO ProgressMeter - Starting traversal; 20:12:51.100 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 20:20:25.766 INFO ProgressMeter - chr3:104142090 7.6 1000 132.0; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007efc9818177e, pid=24, tid=0x00007f13b3c76700; #; # JRE version: OpenJDK Runtime Environment (8.0_242-b08) (build 1.8.0_242-8u242-b08-0ubuntu3~18.04-b08); # Java VM: OpenJDK 64-Bit Server VM (25.242-b08 mixed mode linux-amd64 ); # Problematic frame:; # C [libgkl_smithwaterman1809483713436863458.so+0x177e] smithWatermanBackTrack(dnaSeqPair*, int, int, int, int, int*, int)+0x60e; #; # Core dump written. Default location: /cromwell_root/core or core.24; #; # An error report file with more information is saved as:; # /cromwell_root/hs_err_pid24.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-781673098
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-781673098:820,Performance,cache,cacheCopy,820,"I'm getting the same issue on GATK 4.1.9.0 FilterAlignmentArtifacts. This bug has been present for 1 year. Has this been fixed?; Note: There is no work-around because FilterAlignmentArtifacts does not have a --smith-waterman option. Here is my error:; ```; 20:12:42.724 WARN FilterAlignmentArtifacts - . [1m[31m !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: FilterAlignmentArtifacts is an EXPERIMENTAL tool and should not be used for production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!![0m. 20:12:42.725 INFO FilterAlignmentArtifacts - Initializing engine; 20:12:48.403 INFO FeatureManager - Using codec VCFCodec to read file gs://fc-secure-024a1aae-a4f9-4025-aa93-f759f93a8203/50383670-4607-4e59-9bfc-4db970980f0e/Mutect2/773a91ea-25be-4d49-b97c-16527076250c/call-Filter/cacheCopy/TN-20-36-filtered.vcf; 20:12:50.117 INFO FilterAlignmentArtifacts - Done initializing engine; 20:12:51.042 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/gatk/gatk-package-4.1.9.0-SNAPSHOT-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 20:12:51.099 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 20:12:51.100 INFO IntelPairHmm - Available threads: 14; 20:12:51.100 INFO IntelPairHmm - Requested threads: 4; 20:12:51.100 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 20:12:51.100 INFO ProgressMeter - Starting traversal; 20:12:51.100 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 20:20:25.766 INFO ProgressMeter - chr3:104142090 7.6 1000 132.0; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007efc9818177e, pid=24, tid=0x00007f13b3c76700; #; # JRE version: OpenJDK Runtime Environment (8.0_242-b08) (build 1.8.0_242-8u242-b08-0ubuntu3~18.04-b08); # Java VM: OpenJDK 64-Bit Server VM (25.242-b08 mixed mode linux-amd64 ); # Problematic frame:; # C [libgkl_smithwaterman18",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-781673098
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-781673098:964,Performance,Load,Loading,964,"I'm getting the same issue on GATK 4.1.9.0 FilterAlignmentArtifacts. This bug has been present for 1 year. Has this been fixed?; Note: There is no work-around because FilterAlignmentArtifacts does not have a --smith-waterman option. Here is my error:; ```; 20:12:42.724 WARN FilterAlignmentArtifacts - . [1m[31m !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: FilterAlignmentArtifacts is an EXPERIMENTAL tool and should not be used for production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!![0m. 20:12:42.725 INFO FilterAlignmentArtifacts - Initializing engine; 20:12:48.403 INFO FeatureManager - Using codec VCFCodec to read file gs://fc-secure-024a1aae-a4f9-4025-aa93-f759f93a8203/50383670-4607-4e59-9bfc-4db970980f0e/Mutect2/773a91ea-25be-4d49-b97c-16527076250c/call-Filter/cacheCopy/TN-20-36-filtered.vcf; 20:12:50.117 INFO FilterAlignmentArtifacts - Done initializing engine; 20:12:51.042 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/gatk/gatk-package-4.1.9.0-SNAPSHOT-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 20:12:51.099 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 20:12:51.100 INFO IntelPairHmm - Available threads: 14; 20:12:51.100 INFO IntelPairHmm - Requested threads: 4; 20:12:51.100 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 20:12:51.100 INFO ProgressMeter - Starting traversal; 20:12:51.100 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 20:20:25.766 INFO ProgressMeter - chr3:104142090 7.6 1000 132.0; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007efc9818177e, pid=24, tid=0x00007f13b3c76700; #; # JRE version: OpenJDK Runtime Environment (8.0_242-b08) (build 1.8.0_242-8u242-b08-0ubuntu3~18.04-b08); # Java VM: OpenJDK 64-Bit Server VM (25.242-b08 mixed mode linux-amd64 ); # Problematic frame:; # C [libgkl_smithwaterman18",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-781673098
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-781673098:1341,Performance,multi-thread,multi-threaded,1341,"!!!!!!!!!!!!!!!!. Warning: FilterAlignmentArtifacts is an EXPERIMENTAL tool and should not be used for production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!![0m. 20:12:42.725 INFO FilterAlignmentArtifacts - Initializing engine; 20:12:48.403 INFO FeatureManager - Using codec VCFCodec to read file gs://fc-secure-024a1aae-a4f9-4025-aa93-f759f93a8203/50383670-4607-4e59-9bfc-4db970980f0e/Mutect2/773a91ea-25be-4d49-b97c-16527076250c/call-Filter/cacheCopy/TN-20-36-filtered.vcf; 20:12:50.117 INFO FilterAlignmentArtifacts - Done initializing engine; 20:12:51.042 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/gatk/gatk-package-4.1.9.0-SNAPSHOT-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 20:12:51.099 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 20:12:51.100 INFO IntelPairHmm - Available threads: 14; 20:12:51.100 INFO IntelPairHmm - Requested threads: 4; 20:12:51.100 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 20:12:51.100 INFO ProgressMeter - Starting traversal; 20:12:51.100 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 20:20:25.766 INFO ProgressMeter - chr3:104142090 7.6 1000 132.0; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007efc9818177e, pid=24, tid=0x00007f13b3c76700; #; # JRE version: OpenJDK Runtime Environment (8.0_242-b08) (build 1.8.0_242-8u242-b08-0ubuntu3~18.04-b08); # Java VM: OpenJDK 64-Bit Server VM (25.242-b08 mixed mode linux-amd64 ); # Problematic frame:; # C [libgkl_smithwaterman1809483713436863458.so+0x177e] smithWatermanBackTrack(dnaSeqPair*, int, int, int, int, int*, int)+0x60e; #; # Core dump written. Default location: /cromwell_root/core or core.24; #; # An error report file with more information is saved as:; # /cromwell_root/hs_err_pid24.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.jav",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-781673098
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-781673098:1650,Safety,detect,detected,1650,"!!!!!!!!!!!!!!!![0m. 20:12:42.725 INFO FilterAlignmentArtifacts - Initializing engine; 20:12:48.403 INFO FeatureManager - Using codec VCFCodec to read file gs://fc-secure-024a1aae-a4f9-4025-aa93-f759f93a8203/50383670-4607-4e59-9bfc-4db970980f0e/Mutect2/773a91ea-25be-4d49-b97c-16527076250c/call-Filter/cacheCopy/TN-20-36-filtered.vcf; 20:12:50.117 INFO FilterAlignmentArtifacts - Done initializing engine; 20:12:51.042 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/gatk/gatk-package-4.1.9.0-SNAPSHOT-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 20:12:51.099 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 20:12:51.100 INFO IntelPairHmm - Available threads: 14; 20:12:51.100 INFO IntelPairHmm - Requested threads: 4; 20:12:51.100 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 20:12:51.100 INFO ProgressMeter - Starting traversal; 20:12:51.100 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 20:20:25.766 INFO ProgressMeter - chr3:104142090 7.6 1000 132.0; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007efc9818177e, pid=24, tid=0x00007f13b3c76700; #; # JRE version: OpenJDK Runtime Environment (8.0_242-b08) (build 1.8.0_242-8u242-b08-0ubuntu3~18.04-b08); # Java VM: OpenJDK 64-Bit Server VM (25.242-b08 mixed mode linux-amd64 ); # Problematic frame:; # C [libgkl_smithwaterman1809483713436863458.so+0x177e] smithWatermanBackTrack(dnaSeqPair*, int, int, int, int, int*, int)+0x60e; #; # Core dump written. Default location: /cromwell_root/core or core.24; #; # An error report file with more information is saved as:; # /cromwell_root/hs_err_pid24.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-781673098
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-781673098:682,Security,secur,secure-,682,"I'm getting the same issue on GATK 4.1.9.0 FilterAlignmentArtifacts. This bug has been present for 1 year. Has this been fixed?; Note: There is no work-around because FilterAlignmentArtifacts does not have a --smith-waterman option. Here is my error:; ```; 20:12:42.724 WARN FilterAlignmentArtifacts - . [1m[31m !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: FilterAlignmentArtifacts is an EXPERIMENTAL tool and should not be used for production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!![0m. 20:12:42.725 INFO FilterAlignmentArtifacts - Initializing engine; 20:12:48.403 INFO FeatureManager - Using codec VCFCodec to read file gs://fc-secure-024a1aae-a4f9-4025-aa93-f759f93a8203/50383670-4607-4e59-9bfc-4db970980f0e/Mutect2/773a91ea-25be-4d49-b97c-16527076250c/call-Filter/cacheCopy/TN-20-36-filtered.vcf; 20:12:50.117 INFO FilterAlignmentArtifacts - Done initializing engine; 20:12:51.042 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/gatk/gatk-package-4.1.9.0-SNAPSHOT-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 20:12:51.099 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 20:12:51.100 INFO IntelPairHmm - Available threads: 14; 20:12:51.100 INFO IntelPairHmm - Requested threads: 4; 20:12:51.100 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 20:12:51.100 INFO ProgressMeter - Starting traversal; 20:12:51.100 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 20:20:25.766 INFO ProgressMeter - chr3:104142090 7.6 1000 132.0; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007efc9818177e, pid=24, tid=0x00007f13b3c76700; #; # JRE version: OpenJDK Runtime Environment (8.0_242-b08) (build 1.8.0_242-8u242-b08-0ubuntu3~18.04-b08); # Java VM: OpenJDK 64-Bit Server VM (25.242-b08 mixed mode linux-amd64 ); # Problematic frame:; # C [libgkl_smithwaterman18",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-781673098
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-781673098:2270,Testability,log,log,2270,"!!!!!!!!!!!!!!!![0m. 20:12:42.725 INFO FilterAlignmentArtifacts - Initializing engine; 20:12:48.403 INFO FeatureManager - Using codec VCFCodec to read file gs://fc-secure-024a1aae-a4f9-4025-aa93-f759f93a8203/50383670-4607-4e59-9bfc-4db970980f0e/Mutect2/773a91ea-25be-4d49-b97c-16527076250c/call-Filter/cacheCopy/TN-20-36-filtered.vcf; 20:12:50.117 INFO FilterAlignmentArtifacts - Done initializing engine; 20:12:51.042 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/gatk/gatk-package-4.1.9.0-SNAPSHOT-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 20:12:51.099 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 20:12:51.100 INFO IntelPairHmm - Available threads: 14; 20:12:51.100 INFO IntelPairHmm - Requested threads: 4; 20:12:51.100 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 20:12:51.100 INFO ProgressMeter - Starting traversal; 20:12:51.100 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 20:20:25.766 INFO ProgressMeter - chr3:104142090 7.6 1000 132.0; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007efc9818177e, pid=24, tid=0x00007f13b3c76700; #; # JRE version: OpenJDK Runtime Environment (8.0_242-b08) (build 1.8.0_242-8u242-b08-0ubuntu3~18.04-b08); # Java VM: OpenJDK 64-Bit Server VM (25.242-b08 mixed mode linux-amd64 ); # Problematic frame:; # C [libgkl_smithwaterman1809483713436863458.so+0x177e] smithWatermanBackTrack(dnaSeqPair*, int, int, int, int, int*, int)+0x60e; #; # Core dump written. Default location: /cromwell_root/core or core.24; #; # An error report file with more information is saved as:; # /cromwell_root/hs_err_pid24.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-781673098
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-781707223:88,Availability,error,error,88,"@gevro Could you try running with the latest GATK master branch, and report whether the error still occurs?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-781707223
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-781716483:28,Usability,simpl,simple,28,"@droazen - note also that a simple fix would be to add --smith-waterman as an option for FilterAlignmentArtifacts. Right now it is hard-coded in FilterAlignmentArtifacts, but that would at least allow a work-around using --smith-waterman JAVA",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-781716483
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-781806444:300,Availability,avail,available,300,"Also, I suspect that for Terra another workaround might be to request a different machine type that does not support AVX:. https://cromwell.readthedocs.io/en/stable/RuntimeAttributes/. ```; runtime {; cpu: 2; cpuPlatform: ""Intel Skylake""; }; ```. https://cloud.google.com/compute/docs/regions-zones/#available. Would appreciate any guidance on this in the meantime. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-781806444
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-781806444:332,Usability,guid,guidance,332,"Also, I suspect that for Terra another workaround might be to request a different machine type that does not support AVX:. https://cromwell.readthedocs.io/en/stable/RuntimeAttributes/. ```; runtime {; cpu: 2; cpuPlatform: ""Intel Skylake""; }; ```. https://cloud.google.com/compute/docs/regions-zones/#available. Would appreciate any guidance on this in the meantime. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-781806444
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-782096053:197,Integrability,Bridg,Bridge,197,"I found a workaround for Terra. I just tried various cpuPlatform settings in the runtime parameters for the FilterAlignmentArtifacts task and for some reason this works:; cpuPlatform: ""Intel Sandy Bridge""",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-782096053
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-782236482:61,Availability,avail,available,61,"@gevro There is a docker image snapshot of the latest master available in the [broadinstitute/gatk-nightly](https://hub.docker.com/r/broadinstitute/gatk-nightly) repository on dockerhub. The latest snapshot is `broadinstitute/gatk-nightly:2021-02-18-4.1.9.0-68-gae06fb734-NIGHTLY-SNAPSHOT`. Even though you found a workaround, it would be helpful for us to know whether this issue is resolved by the newer GKL version included in master. I agree that the tool should allow the Java SmithWaterman implementation to be selected via an argument.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-782236482
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-782779694:66,Deployability,pipeline,pipeline,66,I will try to test it next time I have a chance. I don't have the pipeline and data up anymore on Terra. But the default Terra pipeline for Mutect2 FilterAlignmentArtifacts with the default Terra cpu platform should reproduce the issue on GATK 4.1.9.0.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-782779694
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-782779694:127,Deployability,pipeline,pipeline,127,I will try to test it next time I have a chance. I don't have the pipeline and data up anymore on Terra. But the default Terra pipeline for Mutect2 FilterAlignmentArtifacts with the default Terra cpu platform should reproduce the issue on GATK 4.1.9.0.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-782779694
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-782779694:14,Testability,test,test,14,I will try to test it next time I have a chance. I don't have the pipeline and data up anymore on Terra. But the default Terra pipeline for Mutect2 FilterAlignmentArtifacts with the default Terra cpu platform should reproduce the issue on GATK 4.1.9.0.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-782779694
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-784458143:159,Deployability,release,release,159,"@gevro To amend my previous comment: it was brought to my attention that the docker image snapshot I linked to above does not actually come with the newer GKL release that might fix your issue. Sorry for the miscommunication! We're working on building a test GATK image that does contain the newer GKL release, and once we have that I'll post a link to it here.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-784458143
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-784458143:302,Deployability,release,release,302,"@gevro To amend my previous comment: it was brought to my attention that the docker image snapshot I linked to above does not actually come with the newer GKL release that might fix your issue. Sorry for the miscommunication! We're working on building a test GATK image that does contain the newer GKL release, and once we have that I'll post a link to it here.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-784458143
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-784458143:254,Testability,test,test,254,"@gevro To amend my previous comment: it was brought to my attention that the docker image snapshot I linked to above does not actually come with the newer GKL release that might fix your issue. Sorry for the miscommunication! We're working on building a test GATK image that does contain the newer GKL release, and once we have that I'll post a link to it here.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-784458143
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-789572872:28,Availability,down,downgrade,28,My current workaround is to downgrade GATK to 4.1.3.0,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-789572872
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-814103471:71,Deployability,release,release,71,@droazen Do you know if this issue has been resolved? Is the newer GKL release now included in GATK?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-814103471
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-814269292:95,Availability,avail,available,95,I have a new build of the GKL that I need to test and then integrate into a new gatk. It's not available yet though.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-814269292
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-814269292:59,Deployability,integrat,integrate,59,I have a new build of the GKL that I need to test and then integrate into a new gatk. It's not available yet though.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-814269292
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-814269292:59,Integrability,integrat,integrate,59,I have a new build of the GKL that I need to test and then integrate into a new gatk. It's not available yet though.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-814269292
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-814269292:45,Testability,test,test,45,I have a new build of the GKL that I need to test and then integrate into a new gatk. It's not available yet though.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-814269292
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-993699280:84,Deployability,release,release,84,"@gevro @yaottianran. I know this is old, but if you want to test with a recent GATK release that includes the upgraded intel gkl it has hopefully fixed this issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-993699280
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-993699280:110,Deployability,upgrade,upgraded,110,"@gevro @yaottianran. I know this is old, but if you want to test with a recent GATK release that includes the upgraded intel gkl it has hopefully fixed this issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-993699280
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-993699280:60,Testability,test,test,60,"@gevro @yaottianran. I know this is old, but if you want to test with a recent GATK release that includes the upgraded intel gkl it has hopefully fixed this issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-993699280
https://github.com/broadinstitute/gatk/issues/5690#issuecomment-993705731:199,Availability,down,downgrade,199,There is also a new argument in FilterAlignmentArtifacts `--smith-waterman` that lets you choose to use the java version or the faster but previously buggy accelerated version so there is no need to downgrade to an old gatk to work around now.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5690#issuecomment-993705731
https://github.com/broadinstitute/gatk/issues/5692#issuecomment-465564813:512,Testability,log,logged,512,"@timmykuo I assume you're referring to the `createSequenceDictionaryFromFeatureIndex` function, which only gets called when a feature file that contains no embedded sequence dictionary is used. It unconditionally issues a warning indicating that the dictionary is missing, and that the code will try to fall back and extract one from the file's associated index. So it looks correct to me. If I've misinterpreted the ticket, please include the actual command that you used, along with the actual warning that is logged, and I'll take another look.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5692#issuecomment-465564813
https://github.com/broadinstitute/gatk/pull/5693#issuecomment-466143854:136,Availability,recover,recoverAll,136,"Failing tests were from a debug bamout to my Desktop, which of course fails on Travis. Fixed that. Just need to write a unit test with `recoverAll = true`.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5693#issuecomment-466143854
https://github.com/broadinstitute/gatk/pull/5693#issuecomment-466143854:136,Safety,recover,recoverAll,136,"Failing tests were from a debug bamout to my Desktop, which of course fails on Travis. Fixed that. Just need to write a unit test with `recoverAll = true`.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5693#issuecomment-466143854
https://github.com/broadinstitute/gatk/pull/5693#issuecomment-466143854:8,Testability,test,tests,8,"Failing tests were from a debug bamout to my Desktop, which of course fails on Travis. Fixed that. Just need to write a unit test with `recoverAll = true`.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5693#issuecomment-466143854
https://github.com/broadinstitute/gatk/pull/5693#issuecomment-466143854:125,Testability,test,test,125,"Failing tests were from a debug bamout to my Desktop, which of course fails on Travis. Fixed that. Just need to write a unit test with `recoverAll = true`.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5693#issuecomment-466143854
https://github.com/broadinstitute/gatk/issues/5696#issuecomment-466087101:61,Availability,error,error,61,@nh13 Could you provide a bam and the locus to reproduce the error?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5696#issuecomment-466087101
https://github.com/broadinstitute/gatk/issues/5696#issuecomment-468859167:317,Security,access,access,317,"@davidbenjamin I've been looking at this with @nh13 and I think what's going on here is a little different that @nh13 described. Specifically when I try to reproduce this I get results very similar to those shown above, but with the MNP calling turned on I also get a second variant at `chr2:241815307`. I don't have access to the original calls @nh13 was looking at, but I suspect they may contain this call too. So I get the following with MNP support on (I'm not sure why I'm not getting them phased):. ```; chr2 241815307 . CA TG 962.73 . GT:AD:DP:GQ:PL 0/1:26,34:60:99:1000,0,758; chr2 241815308 . A G 2214.77 . GT:AD:DP:GQ:PL 1/1:1,60:61:99:1243,136,0; ```. This makes it look a lot like the issue described in #5523. I'm attaching ; ![an IGV screenshot of the region](https://user-images.githubusercontent.com/1609210/53673861-55b85880-3c47-11e9-9338-43c5ba40b5b6.png) and a SAM file, [NA24694.chr2.241815307.sam.gz](https://github.com/broadinstitute/gatk/files/2921535/NA24694.chr2.241815307.sam.gz), for the region shown that reproduces this issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5696#issuecomment-468859167
https://github.com/broadinstitute/gatk/issues/5696#issuecomment-475409316:93,Testability,test,test,93,@davidbenjamin would you be able to take a look at reproducing this issue? I think @tfenne's test case is what you want to look at.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5696#issuecomment-475409316
https://github.com/broadinstitute/gatk/pull/5697#issuecomment-466073129:3531,Deployability,pipeline,pipelines,3531,.io/gh/broadinstitute/gatk/pull/5697/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9IYXBsb3R5cGVDYWxsZXJHZW5vdHlwaW5nRW5naW5lLmphdmE=) | `79.747% <0%> (-10.084%)` | `38% <0%> (-16%)` | |; | [...kers/haplotypecaller/AssemblyBasedCallerUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5697/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9Bc3NlbWJseUJhc2VkQ2FsbGVyVXRpbHMuamF2YQ==) | `80.303% <0%> (-8.658%)` | `41% <0%> (-74%)` | |; | [.../basicshortmutpileup/BetaBinomialDistribution.java](https://codecov.io/gh/broadinstitute/gatk/pull/5697/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vYmFzaWNzaG9ydG11dHBpbGV1cC9CZXRhQmlub21pYWxEaXN0cmlidXRpb24uamF2YQ==) | `65.385% <0%> (-7.343%)` | `5% <0%> (ø)` | |; | [...lkers/contamination/MinorAlleleFractionRecord.java](https://codecov.io/gh/broadinstitute/gatk/pull/5697/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2NvbnRhbWluYXRpb24vTWlub3JBbGxlbGVGcmFjdGlvblJlY29yZC5qYXZh) | `84.783% <0%> (-6.522%)` | `5% <0%> (-3%)` | |; | [...park/pipelines/PrintReadsSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5697/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRSZWFkc1NwYXJrSW50ZWdyYXRpb25UZXN0LmphdmE=) | `88.532% <0%> (-4.325%)` | `31% <0%> (+29%)` | |; | [.../tools/walkers/mutect/SomaticGenotypingEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/5697/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9Tb21hdGljR2Vub3R5cGluZ0VuZ2luZS5qYXZh) | `90.05% <0%> (-3.499%)` | `76% <0%> (+6%)` | |; | ... and [168 more](https://codecov.io/gh/broadinstitute/gatk/pull/5697/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5697#issuecomment-466073129
https://github.com/broadinstitute/gatk/issues/5698#issuecomment-466160716:937,Security,sanitiz,sanitize,937,"Thanks @ldgauthier! I think this is what you're asking for:. ```; # gVCF without --max-mnp-distance; chr4 5743509 . C T,<NON_REF> 5888.77 . DP=135;ExcessHet=3.0103;MLEAC=2,0;MLEAF=1.00,0.00;RAW_MQandDP=486000,135 GT:AD:DP:GQ:PGT:PID:PL:PS:SB 1|1:0,135,0:135:99:0|1:5743509_C_T:5917,406,0,5917,406,5917:5743509:0,0,0,135; chr4 5743512 . T C,<NON_REF> 2745.77 . BaseQRankSum=-1.002;DP=131;ExcessHet=3.0103;MLEAC=1,0;MLEAF=0.500,0.00;MQRankSum=0.000;RAW_MQandDP=471600,131;ReadPosRankSum=2.613 GT:AD:DP:GQ:PGT:PID:PL:PS:SB 0|1:57,74,0:131:99:0|1:5743509_C_T:2774,0,2060,2945,2283,5228:5743509:0,57,0,74. # gVCF with --max-mnp-distance 5; chr4 5743509 . CTAT TTAC,TTAT,<NON_REF> 5485.73 . DP=136;ExcessHet=3.0103;MLEAC=1,1,0;MLEAF=0.500,0.500,0.00;RAW_MQandDP=489600,136 GT:AD:DP:GQ:PL:SB 1/2:0,74,56,0:130:99:5523,2213,2060,3016,0,2774,5388,2261,2994,5376:0,0,0,130; ```. I should also be able to share the BAM later today - I just need to sanitize it a little before sharing.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5698#issuecomment-466160716
https://github.com/broadinstitute/gatk/issues/5698#issuecomment-466538825:954,Availability,error,error,954,"Thanks @ldgauthier, that's definitely thought provoking. Perhaps you are right that for het-non-ref (i.e. 1/2 and similar) genotypes we should consider skipping the strand bias test. I had been assuming, incorrectly, that in a single sample case with a `1/2` genotype that the test would be based on the called alleles, not ref vs. alt. Just thinking out loud about this, I wonder if computing SOR on the `1/2` alleles would catch a small number of incorrect genotypes? I've been doing something analogous with allele balance filtering - whereby I compute a per-sample allele balance and directionality. If the genotype is imbalanced towards ref, I filter the variant. If the genotype is imbalanced towards a different allele I ""correct"" the genotype to be homozygous for that allele. In testing on reference samples from GIAB and PlatGen we are seeing that correct a handful of genotypes where the sample is really hom-alt, but called het due to a high error rate. . I'll read up on how the allele-specific strand bias works because I've never looked at that before. But I wonder if it's possible from the available annotations to get a SOR-like value for each allele that is that allele _vs_ all other alleles?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5698#issuecomment-466538825
https://github.com/broadinstitute/gatk/issues/5698#issuecomment-466538825:1107,Availability,avail,available,1107,"Thanks @ldgauthier, that's definitely thought provoking. Perhaps you are right that for het-non-ref (i.e. 1/2 and similar) genotypes we should consider skipping the strand bias test. I had been assuming, incorrectly, that in a single sample case with a `1/2` genotype that the test would be based on the called alleles, not ref vs. alt. Just thinking out loud about this, I wonder if computing SOR on the `1/2` alleles would catch a small number of incorrect genotypes? I've been doing something analogous with allele balance filtering - whereby I compute a per-sample allele balance and directionality. If the genotype is imbalanced towards ref, I filter the variant. If the genotype is imbalanced towards a different allele I ""correct"" the genotype to be homozygous for that allele. In testing on reference samples from GIAB and PlatGen we are seeing that correct a handful of genotypes where the sample is really hom-alt, but called het due to a high error rate. . I'll read up on how the allele-specific strand bias works because I've never looked at that before. But I wonder if it's possible from the available annotations to get a SOR-like value for each allele that is that allele _vs_ all other alleles?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5698#issuecomment-466538825
https://github.com/broadinstitute/gatk/issues/5698#issuecomment-466538825:177,Testability,test,test,177,"Thanks @ldgauthier, that's definitely thought provoking. Perhaps you are right that for het-non-ref (i.e. 1/2 and similar) genotypes we should consider skipping the strand bias test. I had been assuming, incorrectly, that in a single sample case with a `1/2` genotype that the test would be based on the called alleles, not ref vs. alt. Just thinking out loud about this, I wonder if computing SOR on the `1/2` alleles would catch a small number of incorrect genotypes? I've been doing something analogous with allele balance filtering - whereby I compute a per-sample allele balance and directionality. If the genotype is imbalanced towards ref, I filter the variant. If the genotype is imbalanced towards a different allele I ""correct"" the genotype to be homozygous for that allele. In testing on reference samples from GIAB and PlatGen we are seeing that correct a handful of genotypes where the sample is really hom-alt, but called het due to a high error rate. . I'll read up on how the allele-specific strand bias works because I've never looked at that before. But I wonder if it's possible from the available annotations to get a SOR-like value for each allele that is that allele _vs_ all other alleles?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5698#issuecomment-466538825
https://github.com/broadinstitute/gatk/issues/5698#issuecomment-466538825:277,Testability,test,test,277,"Thanks @ldgauthier, that's definitely thought provoking. Perhaps you are right that for het-non-ref (i.e. 1/2 and similar) genotypes we should consider skipping the strand bias test. I had been assuming, incorrectly, that in a single sample case with a `1/2` genotype that the test would be based on the called alleles, not ref vs. alt. Just thinking out loud about this, I wonder if computing SOR on the `1/2` alleles would catch a small number of incorrect genotypes? I've been doing something analogous with allele balance filtering - whereby I compute a per-sample allele balance and directionality. If the genotype is imbalanced towards ref, I filter the variant. If the genotype is imbalanced towards a different allele I ""correct"" the genotype to be homozygous for that allele. In testing on reference samples from GIAB and PlatGen we are seeing that correct a handful of genotypes where the sample is really hom-alt, but called het due to a high error rate. . I'll read up on how the allele-specific strand bias works because I've never looked at that before. But I wonder if it's possible from the available annotations to get a SOR-like value for each allele that is that allele _vs_ all other alleles?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5698#issuecomment-466538825
https://github.com/broadinstitute/gatk/issues/5698#issuecomment-466538825:788,Testability,test,testing,788,"Thanks @ldgauthier, that's definitely thought provoking. Perhaps you are right that for het-non-ref (i.e. 1/2 and similar) genotypes we should consider skipping the strand bias test. I had been assuming, incorrectly, that in a single sample case with a `1/2` genotype that the test would be based on the called alleles, not ref vs. alt. Just thinking out loud about this, I wonder if computing SOR on the `1/2` alleles would catch a small number of incorrect genotypes? I've been doing something analogous with allele balance filtering - whereby I compute a per-sample allele balance and directionality. If the genotype is imbalanced towards ref, I filter the variant. If the genotype is imbalanced towards a different allele I ""correct"" the genotype to be homozygous for that allele. In testing on reference samples from GIAB and PlatGen we are seeing that correct a handful of genotypes where the sample is really hom-alt, but called het due to a high error rate. . I'll read up on how the allele-specific strand bias works because I've never looked at that before. But I wonder if it's possible from the available annotations to get a SOR-like value for each allele that is that allele _vs_ all other alleles?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5698#issuecomment-466538825
https://github.com/broadinstitute/gatk/issues/5698#issuecomment-466563992:247,Energy Efficiency,reduce,reduced,247,"One more question related to this. In playing around I've noticed that if I run HC in GVCF mode with `-A AS_StrandOddsRatio` it will output a table like this into the gVCF: `AS_SB_TABLE=0,0|34,24|21,33|0,0`. But when I run GenotypeGVCFs this gets reduced to `AS_SOR=1.085`, and the original `AS_SB_TABLE` annotation is removed. Is there any way to get `GenotypeGVCFs` to carry the table forward into the genotypes VCF?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5698#issuecomment-466563992
https://github.com/broadinstitute/gatk/pull/5699#issuecomment-471552213:154,Deployability,release,release,154,"@mwalker174 can you take a look? There are some changes to how output directories are treated in the last commit that should perhaps be documented in the release notes, otherwise most changes are very minor. Also tried to do a bit of polishing for style, but we can probably go back and do more.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5699#issuecomment-471552213
https://github.com/broadinstitute/gatk/pull/5699#issuecomment-471799446:59,Integrability,depend,depending,59,"Thanks @mwalker174, back to you! Might need some more work depending on what you decide.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5699#issuecomment-471799446
https://github.com/broadinstitute/gatk/issues/5700#issuecomment-473091464:16,Deployability,release,release,16,"@nh13, the next release should reflect SOR documentation updates from #5703.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5700#issuecomment-473091464
https://github.com/broadinstitute/gatk/issues/5700#issuecomment-473091464:57,Deployability,update,updates,57,"@nh13, the next release should reflect SOR documentation updates from #5703.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5700#issuecomment-473091464
https://github.com/broadinstitute/gatk/pull/5701#issuecomment-465978387:186,Availability,down,downstream,186,"Thanks for adding this! Let me discuss further with @mwalker174 to understand the need and typical use cases (e.g., combining fixed-grid bins) to make sure we don't run into any gotchas downstream. I'll try to review by EOD, but in the meantime, you might want to address a few issues I see at first glance:. 1) Correct the name of the tool (PreprocessIntervals) in the commit message and description.; 2) Add descriptions of the new parameters to the tool Javadoc.; 3) Amend the corresponding WDL task and expose the new parameters in all relevant germline and somatic WDLs.; 4) We should be sure to update the relevant documentation for all germline and somatic WDLs, which emphasizes how PreprocessIntervals should be run differently for WES and WGS, if we plan on changing the default behavior of the tool in the future.; 5) Tests are failing due to a compilation warning about a redundant cast to int.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5701#issuecomment-465978387
https://github.com/broadinstitute/gatk/pull/5701#issuecomment-465978387:884,Availability,redundant,redundant,884,"Thanks for adding this! Let me discuss further with @mwalker174 to understand the need and typical use cases (e.g., combining fixed-grid bins) to make sure we don't run into any gotchas downstream. I'll try to review by EOD, but in the meantime, you might want to address a few issues I see at first glance:. 1) Correct the name of the tool (PreprocessIntervals) in the commit message and description.; 2) Add descriptions of the new parameters to the tool Javadoc.; 3) Amend the corresponding WDL task and expose the new parameters in all relevant germline and somatic WDLs.; 4) We should be sure to update the relevant documentation for all germline and somatic WDLs, which emphasizes how PreprocessIntervals should be run differently for WES and WGS, if we plan on changing the default behavior of the tool in the future.; 5) Tests are failing due to a compilation warning about a redundant cast to int.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5701#issuecomment-465978387
https://github.com/broadinstitute/gatk/pull/5701#issuecomment-465978387:601,Deployability,update,update,601,"Thanks for adding this! Let me discuss further with @mwalker174 to understand the need and typical use cases (e.g., combining fixed-grid bins) to make sure we don't run into any gotchas downstream. I'll try to review by EOD, but in the meantime, you might want to address a few issues I see at first glance:. 1) Correct the name of the tool (PreprocessIntervals) in the commit message and description.; 2) Add descriptions of the new parameters to the tool Javadoc.; 3) Amend the corresponding WDL task and expose the new parameters in all relevant germline and somatic WDLs.; 4) We should be sure to update the relevant documentation for all germline and somatic WDLs, which emphasizes how PreprocessIntervals should be run differently for WES and WGS, if we plan on changing the default behavior of the tool in the future.; 5) Tests are failing due to a compilation warning about a redundant cast to int.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5701#issuecomment-465978387
https://github.com/broadinstitute/gatk/pull/5701#issuecomment-465978387:377,Integrability,message,message,377,"Thanks for adding this! Let me discuss further with @mwalker174 to understand the need and typical use cases (e.g., combining fixed-grid bins) to make sure we don't run into any gotchas downstream. I'll try to review by EOD, but in the meantime, you might want to address a few issues I see at first glance:. 1) Correct the name of the tool (PreprocessIntervals) in the commit message and description.; 2) Add descriptions of the new parameters to the tool Javadoc.; 3) Amend the corresponding WDL task and expose the new parameters in all relevant germline and somatic WDLs.; 4) We should be sure to update the relevant documentation for all germline and somatic WDLs, which emphasizes how PreprocessIntervals should be run differently for WES and WGS, if we plan on changing the default behavior of the tool in the future.; 5) Tests are failing due to a compilation warning about a redundant cast to int.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5701#issuecomment-465978387
https://github.com/broadinstitute/gatk/pull/5701#issuecomment-465978387:884,Safety,redund,redundant,884,"Thanks for adding this! Let me discuss further with @mwalker174 to understand the need and typical use cases (e.g., combining fixed-grid bins) to make sure we don't run into any gotchas downstream. I'll try to review by EOD, but in the meantime, you might want to address a few issues I see at first glance:. 1) Correct the name of the tool (PreprocessIntervals) in the commit message and description.; 2) Add descriptions of the new parameters to the tool Javadoc.; 3) Amend the corresponding WDL task and expose the new parameters in all relevant germline and somatic WDLs.; 4) We should be sure to update the relevant documentation for all germline and somatic WDLs, which emphasizes how PreprocessIntervals should be run differently for WES and WGS, if we plan on changing the default behavior of the tool in the future.; 5) Tests are failing due to a compilation warning about a redundant cast to int.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5701#issuecomment-465978387
https://github.com/broadinstitute/gatk/pull/5701#issuecomment-465978387:507,Security,expose,expose,507,"Thanks for adding this! Let me discuss further with @mwalker174 to understand the need and typical use cases (e.g., combining fixed-grid bins) to make sure we don't run into any gotchas downstream. I'll try to review by EOD, but in the meantime, you might want to address a few issues I see at first glance:. 1) Correct the name of the tool (PreprocessIntervals) in the commit message and description.; 2) Add descriptions of the new parameters to the tool Javadoc.; 3) Amend the corresponding WDL task and expose the new parameters in all relevant germline and somatic WDLs.; 4) We should be sure to update the relevant documentation for all germline and somatic WDLs, which emphasizes how PreprocessIntervals should be run differently for WES and WGS, if we plan on changing the default behavior of the tool in the future.; 5) Tests are failing due to a compilation warning about a redundant cast to int.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5701#issuecomment-465978387
https://github.com/broadinstitute/gatk/pull/5701#issuecomment-465978387:829,Testability,Test,Tests,829,"Thanks for adding this! Let me discuss further with @mwalker174 to understand the need and typical use cases (e.g., combining fixed-grid bins) to make sure we don't run into any gotchas downstream. I'll try to review by EOD, but in the meantime, you might want to address a few issues I see at first glance:. 1) Correct the name of the tool (PreprocessIntervals) in the commit message and description.; 2) Add descriptions of the new parameters to the tool Javadoc.; 3) Amend the corresponding WDL task and expose the new parameters in all relevant germline and somatic WDLs.; 4) We should be sure to update the relevant documentation for all germline and somatic WDLs, which emphasizes how PreprocessIntervals should be run differently for WES and WGS, if we plan on changing the default behavior of the tool in the future.; 5) Tests are failing due to a compilation warning about a redundant cast to int.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5701#issuecomment-465978387
https://github.com/broadinstitute/gatk/pull/5701#issuecomment-466085263:976,Usability,Simpl,SimpleInterval,976,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5701?src=pr&el=h1) Report; > Merging [#5701](https://codecov.io/gh/broadinstitute/gatk/pull/5701?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/ac1b146fac86ddf4dcb3a93a78e602dbe9fa000e?src=pr&el=desc) will **decrease** coverage by `6.839%`.; > The diff coverage is `55.263%`. ```diff; @@ Coverage Diff @@; ## master #5701 +/- ##; ===============================================; - Coverage 87.071% 80.232% -6.839% ; + Complexity 31855 30204 -1651 ; ===============================================; Files 1940 1940 ; Lines 146679 146776 +97 ; Branches 16218 16231 +13 ; ===============================================; - Hits 127715 117762 -9953 ; - Misses 13053 23303 +10250 ; + Partials 5911 5711 -200; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5701?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...roadinstitute/hellbender/utils/SimpleInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/5701/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9TaW1wbGVJbnRlcnZhbC5qYXZh) | `93.182% <ø> (ø)` | `48 <0> (ø)` | :arrow_down: |; | [...stitute/hellbender/engine/ReferenceDataSource.java](https://codecov.io/gh/broadinstitute/gatk/pull/5701/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUmVmZXJlbmNlRGF0YVNvdXJjZS5qYXZh) | `66.667% <ø> (ø)` | `4 <0> (ø)` | :arrow_down: |; | [...copynumber/PreprocessIntervalsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5701/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL1ByZXByb2Nlc3NJbnRlcnZhbHNJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `3.008% <0%> (-89.149%)` | `2 <0> (-8)` | |; | [...broadinstitute/hellbender/utils/IntervalUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5701/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5701#issuecomment-466085263
https://github.com/broadinstitute/gatk/pull/5701#issuecomment-466100631:161,Deployability,pipeline,pipeline---possible,161,"I don't think rushing a merge is needed. This is a dead simple utility tool that really only needs to be run once or twice (if I understand the needs for the SV pipeline---possible I'm missing something). Why not just create the desired bins, either by using this dev branch or an external script, and provide that as a resource to the SV pipeline for the time being?. As for using streams for coverage collection, do you mean NIO?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5701#issuecomment-466100631
https://github.com/broadinstitute/gatk/pull/5701#issuecomment-466100631:339,Deployability,pipeline,pipeline,339,"I don't think rushing a merge is needed. This is a dead simple utility tool that really only needs to be run once or twice (if I understand the needs for the SV pipeline---possible I'm missing something). Why not just create the desired bins, either by using this dev branch or an external script, and provide that as a resource to the SV pipeline for the time being?. As for using streams for coverage collection, do you mean NIO?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5701#issuecomment-466100631
https://github.com/broadinstitute/gatk/pull/5701#issuecomment-466100631:56,Usability,simpl,simple,56,"I don't think rushing a merge is needed. This is a dead simple utility tool that really only needs to be run once or twice (if I understand the needs for the SV pipeline---possible I'm missing something). Why not just create the desired bins, either by using this dev branch or an external script, and provide that as a resource to the SV pipeline for the time being?. As for using streams for coverage collection, do you mean NIO?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5701#issuecomment-466100631
https://github.com/broadinstitute/gatk/issues/5702#issuecomment-466203330:458,Integrability,depend,depending,458,"Just noting, as we discussed, this could allow us to condense coverage files, etc. We'd want to make sure that bins are always validated and that we don't introduce use cases that corrupt the bins (e.g., filtering bins). Also not really sure how hard indexing would be. Should be in conjunction with #4717. We are probably OK shuffling around relatively large interval and count files for the time being, but we can adjust priority when it makes sense (also depending on where htsjdk development is on these issues).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5702#issuecomment-466203330
https://github.com/broadinstitute/gatk/issues/5702#issuecomment-466203330:127,Security,validat,validated,127,"Just noting, as we discussed, this could allow us to condense coverage files, etc. We'd want to make sure that bins are always validated and that we don't introduce use cases that corrupt the bins (e.g., filtering bins). Also not really sure how hard indexing would be. Should be in conjunction with #4717. We are probably OK shuffling around relatively large interval and count files for the time being, but we can adjust priority when it makes sense (also depending on where htsjdk development is on these issues).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5702#issuecomment-466203330
https://github.com/broadinstitute/gatk/pull/5703#issuecomment-466098961:1580,Deployability,pipeline,pipelines,1580,34 ; Lines 146679 147213 +534 ; Branches 16218 16214 -4 ; ===============================================; + Hits 127707 128079 +372 ; - Misses 13060 13231 +171 ; + Partials 5912 5903 -9; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5703?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...ender/tools/walkers/annotator/StrandOddsRatio.java](https://codecov.io/gh/broadinstitute/gatk/pull/5703/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9TdHJhbmRPZGRzUmF0aW8uamF2YQ==) | `94.737% <ø> (ø)` | `8 <0> (ø)` | :arrow_down: |; | [...s/annotator/allelespecific/AS\_StrandOddsRatio.java](https://codecov.io/gh/broadinstitute/gatk/pull/5703/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9hbGxlbGVzcGVjaWZpYy9BU19TdHJhbmRPZGRzUmF0aW8uamF2YQ==) | `80% <ø> (ø)` | `4 <0> (ø)` | :arrow_down: |; | [...k/pipelines/ReadsPipelineSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5703/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrSW50ZWdyYXRpb25UZXN0LmphdmE=) | `1.563% <0%> (-95.313%)` | `1% <0%> (-6%)` | |; | [...adinstitute/hellbender/utils/IntegrationUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5703/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9JbnRlZ3JhdGlvblV0aWxzLmphdmE=) | `0% <0%> (-95.238%)` | `0% <0%> (-5%)` | |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5703/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `0% <0%> (-90.741%)` | `0% <0%> (-13%)` | |; | [...titute/hellbender/engine/TwoPassVariantWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/5703/diff?src=,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5703#issuecomment-466098961
https://github.com/broadinstitute/gatk/pull/5703#issuecomment-466098961:1934,Deployability,Integrat,IntegrationUtils,1934,--|; | [...ender/tools/walkers/annotator/StrandOddsRatio.java](https://codecov.io/gh/broadinstitute/gatk/pull/5703/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9TdHJhbmRPZGRzUmF0aW8uamF2YQ==) | `94.737% <ø> (ø)` | `8 <0> (ø)` | :arrow_down: |; | [...s/annotator/allelespecific/AS\_StrandOddsRatio.java](https://codecov.io/gh/broadinstitute/gatk/pull/5703/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9hbGxlbGVzcGVjaWZpYy9BU19TdHJhbmRPZGRzUmF0aW8uamF2YQ==) | `80% <ø> (ø)` | `4 <0> (ø)` | :arrow_down: |; | [...k/pipelines/ReadsPipelineSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5703/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrSW50ZWdyYXRpb25UZXN0LmphdmE=) | `1.563% <0%> (-95.313%)` | `1% <0%> (-6%)` | |; | [...adinstitute/hellbender/utils/IntegrationUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5703/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9JbnRlZ3JhdGlvblV0aWxzLmphdmE=) | `0% <0%> (-95.238%)` | `0% <0%> (-5%)` | |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5703/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `0% <0%> (-90.741%)` | `0% <0%> (-13%)` | |; | [...titute/hellbender/engine/TwoPassVariantWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/5703/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvVHdvUGFzc1ZhcmlhbnRXYWxrZXIuamF2YQ==) | `69.231% <0%> (-26.007%)` | `6% <0%> (+2%)` | |; | [...itute/hellbender/utils/runtime/ScriptExecutor.java](https://codecov.io/gh/broadinstitute/gatk/pull/5703/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5703#issuecomment-466098961
https://github.com/broadinstitute/gatk/pull/5703#issuecomment-466098961:2201,Deployability,pipeline,pipelines,2201,)` | `8 <0> (ø)` | :arrow_down: |; | [...s/annotator/allelespecific/AS\_StrandOddsRatio.java](https://codecov.io/gh/broadinstitute/gatk/pull/5703/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9hbGxlbGVzcGVjaWZpYy9BU19TdHJhbmRPZGRzUmF0aW8uamF2YQ==) | `80% <ø> (ø)` | `4 <0> (ø)` | :arrow_down: |; | [...k/pipelines/ReadsPipelineSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5703/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrSW50ZWdyYXRpb25UZXN0LmphdmE=) | `1.563% <0%> (-95.313%)` | `1% <0%> (-6%)` | |; | [...adinstitute/hellbender/utils/IntegrationUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5703/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9JbnRlZ3JhdGlvblV0aWxzLmphdmE=) | `0% <0%> (-95.238%)` | `0% <0%> (-5%)` | |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5703/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `0% <0%> (-90.741%)` | `0% <0%> (-13%)` | |; | [...titute/hellbender/engine/TwoPassVariantWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/5703/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvVHdvUGFzc1ZhcmlhbnRXYWxrZXIuamF2YQ==) | `69.231% <0%> (-26.007%)` | `6% <0%> (+2%)` | |; | [...itute/hellbender/utils/runtime/ScriptExecutor.java](https://codecov.io/gh/broadinstitute/gatk/pull/5703/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9ydW50aW1lL1NjcmlwdEV4ZWN1dG9yLmphdmE=) | `66.667% <0%> (-14.583%)` | `7% <0%> (-3%)` | |; | [...stitute/hellbender/tools/HaplotypeCallerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5703/diff?src=pr&el=tree#diff-c3JjL2,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5703#issuecomment-466098961
https://github.com/broadinstitute/gatk/pull/5703#issuecomment-466098961:1934,Integrability,Integrat,IntegrationUtils,1934,--|; | [...ender/tools/walkers/annotator/StrandOddsRatio.java](https://codecov.io/gh/broadinstitute/gatk/pull/5703/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9TdHJhbmRPZGRzUmF0aW8uamF2YQ==) | `94.737% <ø> (ø)` | `8 <0> (ø)` | :arrow_down: |; | [...s/annotator/allelespecific/AS\_StrandOddsRatio.java](https://codecov.io/gh/broadinstitute/gatk/pull/5703/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9hbGxlbGVzcGVjaWZpYy9BU19TdHJhbmRPZGRzUmF0aW8uamF2YQ==) | `80% <ø> (ø)` | `4 <0> (ø)` | :arrow_down: |; | [...k/pipelines/ReadsPipelineSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5703/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrSW50ZWdyYXRpb25UZXN0LmphdmE=) | `1.563% <0%> (-95.313%)` | `1% <0%> (-6%)` | |; | [...adinstitute/hellbender/utils/IntegrationUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5703/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9JbnRlZ3JhdGlvblV0aWxzLmphdmE=) | `0% <0%> (-95.238%)` | `0% <0%> (-5%)` | |; | [...nder/tools/spark/pipelines/ReadsPipelineSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5703/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrLmphdmE=) | `0% <0%> (-90.741%)` | `0% <0%> (-13%)` | |; | [...titute/hellbender/engine/TwoPassVariantWalker.java](https://codecov.io/gh/broadinstitute/gatk/pull/5703/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvVHdvUGFzc1ZhcmlhbnRXYWxrZXIuamF2YQ==) | `69.231% <0%> (-26.007%)` | `6% <0%> (+2%)` | |; | [...itute/hellbender/utils/runtime/ScriptExecutor.java](https://codecov.io/gh/broadinstitute/gatk/pull/5703/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5703#issuecomment-466098961
https://github.com/broadinstitute/gatk/pull/5703#issuecomment-470555076:38,Testability,test,testing,38,I will be back after some reading and testing.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5703#issuecomment-470555076
https://github.com/broadinstitute/gatk/pull/5703#issuecomment-470581260:211,Testability,test,tested,211,"@ldgauthier, here is a solution that will render the LaTeX for the forum. `<img src=""http://latex.codecogs.com/svg.latex?$$ refRatio = \frac{min(X[0][0], X[0][1])}{max(X[0][0], X[0][1])} $$"" border=""0""/>`. I've tested that this renders on the forum to ; <img src=""http://latex.codecogs.com/svg.latex?$$ refRatio = \frac{min(X[0][0], X[0][1])}{max(X[0][0], X[0][1])} $$"" border=""0""/> . Please let me know if you want me to make these changes on your branch for the SOR and AS_SOR documentation.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5703#issuecomment-470581260
https://github.com/broadinstitute/gatk/pull/5703#issuecomment-470685949:18,Performance,perform,performed,18,"@ldgauthier, I've performed a pass. I think the _Caveat_ section of the AS_StrandOddsRatio doc could use some attention. Here it is currently (I did not touch it):. ![screenshot 2019-03-07 15 37 39](https://user-images.githubusercontent.com/11543866/53987567-60fc0000-40ef-11e9-8415-d52403f01f83.png). Here is what the rendered javadocs look like now. Let me know what you think.; ![screenshot 2019-03-07 15 37 21](https://user-images.githubusercontent.com/11543866/53987525-475ab880-40ef-11e9-8f0e-24a57a84586a.png). ![screenshot 2019-03-07 15 37 32](https://user-images.githubusercontent.com/11543866/53987535-4d509980-40ef-11e9-835b-65ceee2cdc06.png)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5703#issuecomment-470685949
https://github.com/broadinstitute/gatk/pull/5703#issuecomment-473063315:356,Deployability,update,updated,356,"@ldgauthier, I've fleshed out an example calculation using the counts you provided. . ### I added the new section ""Example calculation"" to SOR documentation and go through the calcuations step-by-step:; ![Screenshot 2019-03-14 17 05 41](https://user-images.githubusercontent.com/11543866/54391591-aa15fc00-467b-11e9-8ef0-25ad5c6ade0e.png). ---; ### Simply updated AS_SOR to point to example calculation in SOR:. ![Screenshot 2019-03-14 17 05 26](https://user-images.githubusercontent.com/11543866/54391599-b0a47380-467b-11e9-91c6-23af55ad6211.png)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5703#issuecomment-473063315
https://github.com/broadinstitute/gatk/pull/5703#issuecomment-473063315:349,Usability,Simpl,Simply,349,"@ldgauthier, I've fleshed out an example calculation using the counts you provided. . ### I added the new section ""Example calculation"" to SOR documentation and go through the calcuations step-by-step:; ![Screenshot 2019-03-14 17 05 41](https://user-images.githubusercontent.com/11543866/54391591-aa15fc00-467b-11e9-8ef0-25ad5c6ade0e.png). ---; ### Simply updated AS_SOR to point to example calculation in SOR:. ![Screenshot 2019-03-14 17 05 26](https://user-images.githubusercontent.com/11543866/54391599-b0a47380-467b-11e9-91c6-23af55ad6211.png)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5703#issuecomment-473063315
https://github.com/broadinstitute/gatk/issues/5704#issuecomment-472070794:28,Availability,down,downstream,28,"@ldgauthier this does block downstream tools, like `bcftools` from using VCFs with this annotation, for example when subsetting and trimming the alleles.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5704#issuecomment-472070794
https://github.com/broadinstitute/gatk/issues/5704#issuecomment-474867341:60,Testability,test,tests,60,"@nh13 I did get started on this. It works, but needs formal tests. I might be able to finish it up this week, but if your need is urgent and you trust me without tests, then there's a branch.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5704#issuecomment-474867341
https://github.com/broadinstitute/gatk/issues/5704#issuecomment-474867341:162,Testability,test,tests,162,"@nh13 I did get started on this. It works, but needs formal tests. I might be able to finish it up this week, but if your need is urgent and you trust me without tests, then there's a branch.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5704#issuecomment-474867341
https://github.com/broadinstitute/gatk/pull/5707#issuecomment-466295625:1828,Usability,Simpl,SimpleCountCollection,1828,decov.io/gh/broadinstitute/gatk/pull/5707?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [.../broadinstitute/hellbender/utils/tsv/DataLine.java](https://codecov.io/gh/broadinstitute/gatk/pull/5707/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90c3YvRGF0YUxpbmUuamF2YQ==) | `85.593% <0%> (-0.732%)` | `59 <0> (ø)` | |; | [...lbender/tools/copynumber/CondenseIntervalList.java](https://codecov.io/gh/broadinstitute/gatk/pull/5707/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL0NvbmRlbnNlSW50ZXJ2YWxMaXN0LmphdmE=) | `0% <0%> (ø)` | `0 <0> (?)` | |; | [...tute/hellbender/utils/tsv/TableReaderUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5707/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90c3YvVGFibGVSZWFkZXJVbml0VGVzdC5qYXZh) | `86.632% <100%> (ø)` | `43 <1> (ø)` | :arrow_down: |; | [...ber/formats/collections/SimpleCountCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/5707/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2Zvcm1hdHMvY29sbGVjdGlvbnMvU2ltcGxlQ291bnRDb2xsZWN0aW9uLmphdmE=) | `100% <100%> (ø)` | `12 <1> (ø)` | :arrow_down: |; | [...roadinstitute/hellbender/utils/tsv/TableUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5707/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90c3YvVGFibGVVdGlscy5qYXZh) | `95.238% <100%> (+0.644%)` | `8 <0> (ø)` | :arrow_down: |; | [...oadinstitute/hellbender/utils/tsv/TableReader.java](https://codecov.io/gh/broadinstitute/gatk/pull/5707/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90c3YvVGFibGVSZWFkZXIuamF2YQ==) | `60.938% <25.581%> (-19.271%)` | `41 <8> (+2)` | |; | [...oadinstitute/hellbender/utils/tsv/TableWriter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5707/diff?src,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5707#issuecomment-466295625
https://github.com/broadinstitute/gatk/issues/5709#issuecomment-466429811:92,Testability,test,test,92,"👍 Furthermore perhaps we should come up with some scheme for documenting what exists in our test util packages, as I'm always finding myself having to reinvent the wheel because I didn't think to check in some htsjdk util class for the method I need.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5709#issuecomment-466429811
https://github.com/broadinstitute/gatk/pull/5710#issuecomment-466524542:2858,Security,validat,validation,2858,52%)` | |; | [...aplotypecaller/HaplotypeCallerIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5710/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9IYXBsb3R5cGVDYWxsZXJJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `57.339% <0%> (-30.767%)` | `89% <0%> (+4%)` | |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5710/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-30%)` | `1% <0%> (-2%)` | |; | [...utils/variant/GATKVariantContextUtilsUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5710/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L0dBVEtWYXJpYW50Q29udGV4dFV0aWxzVW5pdFRlc3QuamF2YQ==) | `61.598% <0%> (-24.25%)` | `160% <0%> (ø)` | |; | [...walkers/validation/ConcordanceIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5710/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vQ29uY29yZGFuY2VJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `79.444% <0%> (-20.556%)` | `3% <0%> (-3%)` | |; | [...kers/vqsr/VariantGaussianMixtureModelUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5710/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3Zxc3IvVmFyaWFudEdhdXNzaWFuTWl4dHVyZU1vZGVsVW5pdFRlc3QuamF2YQ==) | `62.857% <0%> (-20.162%)` | `13% <0%> (ø)` | |; | [.../walkers/vqsr/TruthSensitivityTrancheUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5710/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3Zxc3IvVHJ1dGhTZW5zaXRpdml0eVRyYW5jaGVVbml0VGVzdC5qYXZh) | `66.667% <0%> (-19.048%)` | `12% <0%> (ø)` | |; | [...stitute/hellbender/utils/nio/PathLineIterator.java](h,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5710#issuecomment-466524542
https://github.com/broadinstitute/gatk/issues/5714#issuecomment-467079182:572,Testability,test,test,572,"Yes the `cnv_germline_cohort_workflow.wdl` sorry for the typo! I first encountered this using 39 samples and `num_intervals_per_scatter` set to 5000 (using the standalone jar). The output above using just 5 WES samples was trying the docker image and had `num_interval_per_scatter` set to 20 ([as that's what I saw here](https://github.com/broadinstitute/gatk/blob/master/scripts/cnv_cromwell_tests/germline/cnv_germline_cohort_workflow.json)). The interval_list contains 295,830 targets/bins. . If there's a different interval value or number of samples you'd like me to test out I'd be happy to do so.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5714#issuecomment-467079182
https://github.com/broadinstitute/gatk/issues/5714#issuecomment-467085960:122,Deployability,continuous,continuous,122,"OK, thanks @drifty914. Note that the file with num_intervals_per_scatter = 20 is a minimal test case that is run with our continuous integration tests. In real-world use, you want enough intervals in each shard to fit a denoising model---probably 5000 or more is safe. I am wondering if your issue is related to https://github.com/broadinstitute/gatk/issues/4782 and https://askubuntu.com/questions/162229/how-do-i-increase-the-open-files-limit-for-a-non-root-user. It may be that your user ulimit is not high enough for the theano compilation directory?. Let me try to put together a fix for that issue and see if it addresses yours as well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5714#issuecomment-467085960
https://github.com/broadinstitute/gatk/issues/5714#issuecomment-467085960:133,Deployability,integrat,integration,133,"OK, thanks @drifty914. Note that the file with num_intervals_per_scatter = 20 is a minimal test case that is run with our continuous integration tests. In real-world use, you want enough intervals in each shard to fit a denoising model---probably 5000 or more is safe. I am wondering if your issue is related to https://github.com/broadinstitute/gatk/issues/4782 and https://askubuntu.com/questions/162229/how-do-i-increase-the-open-files-limit-for-a-non-root-user. It may be that your user ulimit is not high enough for the theano compilation directory?. Let me try to put together a fix for that issue and see if it addresses yours as well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5714#issuecomment-467085960
https://github.com/broadinstitute/gatk/issues/5714#issuecomment-467085960:133,Integrability,integrat,integration,133,"OK, thanks @drifty914. Note that the file with num_intervals_per_scatter = 20 is a minimal test case that is run with our continuous integration tests. In real-world use, you want enough intervals in each shard to fit a denoising model---probably 5000 or more is safe. I am wondering if your issue is related to https://github.com/broadinstitute/gatk/issues/4782 and https://askubuntu.com/questions/162229/how-do-i-increase-the-open-files-limit-for-a-non-root-user. It may be that your user ulimit is not high enough for the theano compilation directory?. Let me try to put together a fix for that issue and see if it addresses yours as well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5714#issuecomment-467085960
https://github.com/broadinstitute/gatk/issues/5714#issuecomment-467085960:263,Safety,safe,safe,263,"OK, thanks @drifty914. Note that the file with num_intervals_per_scatter = 20 is a minimal test case that is run with our continuous integration tests. In real-world use, you want enough intervals in each shard to fit a denoising model---probably 5000 or more is safe. I am wondering if your issue is related to https://github.com/broadinstitute/gatk/issues/4782 and https://askubuntu.com/questions/162229/how-do-i-increase-the-open-files-limit-for-a-non-root-user. It may be that your user ulimit is not high enough for the theano compilation directory?. Let me try to put together a fix for that issue and see if it addresses yours as well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5714#issuecomment-467085960
https://github.com/broadinstitute/gatk/issues/5714#issuecomment-467085960:91,Testability,test,test,91,"OK, thanks @drifty914. Note that the file with num_intervals_per_scatter = 20 is a minimal test case that is run with our continuous integration tests. In real-world use, you want enough intervals in each shard to fit a denoising model---probably 5000 or more is safe. I am wondering if your issue is related to https://github.com/broadinstitute/gatk/issues/4782 and https://askubuntu.com/questions/162229/how-do-i-increase-the-open-files-limit-for-a-non-root-user. It may be that your user ulimit is not high enough for the theano compilation directory?. Let me try to put together a fix for that issue and see if it addresses yours as well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5714#issuecomment-467085960
https://github.com/broadinstitute/gatk/issues/5714#issuecomment-467085960:145,Testability,test,tests,145,"OK, thanks @drifty914. Note that the file with num_intervals_per_scatter = 20 is a minimal test case that is run with our continuous integration tests. In real-world use, you want enough intervals in each shard to fit a denoising model---probably 5000 or more is safe. I am wondering if your issue is related to https://github.com/broadinstitute/gatk/issues/4782 and https://askubuntu.com/questions/162229/how-do-i-increase-the-open-files-limit-for-a-non-root-user. It may be that your user ulimit is not high enough for the theano compilation directory?. Let me try to put together a fix for that issue and see if it addresses yours as well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5714#issuecomment-467085960
https://github.com/broadinstitute/gatk/issues/5714#issuecomment-468308508:39,Integrability,message,message,39,@drifty914 Do you encounter the ulimit message when you run a *single* shard (covering say 5000 intervals) of GermlineCNVCaller?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5714#issuecomment-468308508
https://github.com/broadinstitute/gatk/issues/5714#issuecomment-468502707:276,Energy Efficiency,reduce,reduce,276,"Thanks @drifty914, it sounds like you may need to limit the number of concurrent jobs that Cromwell is allowed to scatter. We typically run gCNV in the cloud and scatter across multiple VMs, so we haven't encountered this issue before. At the same time, you could also try to reduce the total number of shards (by increasing num_intervals_per_scatter), which should be fine if each shard has enough memory. We typically scatter 200 samples x 5000 intervals, which fits comfortably in VMs with 30GB of memory. We haven't gotten a chance to profile how much of this memory is being used in detail, so you might be able to get by with much less. I don't think this is a matter of a memory leak or files being left open by the tool, as it looks like your job fails during the theano compilation step. I'll try to get an idea of how many files theano opens for each compilation, but I don't think this is something we have much control over. We have thought about whether it might be possible to reuse the same compiled theano model for identically sized shards, but haven't gotten a chance to investigate this yet either.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5714#issuecomment-468502707
https://github.com/broadinstitute/gatk/issues/5714#issuecomment-468502707:70,Performance,concurren,concurrent,70,"Thanks @drifty914, it sounds like you may need to limit the number of concurrent jobs that Cromwell is allowed to scatter. We typically run gCNV in the cloud and scatter across multiple VMs, so we haven't encountered this issue before. At the same time, you could also try to reduce the total number of shards (by increasing num_intervals_per_scatter), which should be fine if each shard has enough memory. We typically scatter 200 samples x 5000 intervals, which fits comfortably in VMs with 30GB of memory. We haven't gotten a chance to profile how much of this memory is being used in detail, so you might be able to get by with much less. I don't think this is a matter of a memory leak or files being left open by the tool, as it looks like your job fails during the theano compilation step. I'll try to get an idea of how many files theano opens for each compilation, but I don't think this is something we have much control over. We have thought about whether it might be possible to reuse the same compiled theano model for identically sized shards, but haven't gotten a chance to investigate this yet either.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5714#issuecomment-468502707
https://github.com/broadinstitute/gatk/issues/5714#issuecomment-468672358:42,Deployability,pipeline,pipeline,42,"Thanks @samuelklee, I was able to get the pipeline to finish last night using the 5000 interval setting as long as I used a single thread to handle the larger memory footprint. I might be able to increase this slightly after some tuning tests. Likely the threads/memory issue is why my earlier attempts to use 5000 intervals with many more samples failed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5714#issuecomment-468672358
https://github.com/broadinstitute/gatk/issues/5714#issuecomment-468672358:237,Testability,test,tests,237,"Thanks @samuelklee, I was able to get the pipeline to finish last night using the 5000 interval setting as long as I used a single thread to handle the larger memory footprint. I might be able to increase this slightly after some tuning tests. Likely the threads/memory issue is why my earlier attempts to use 5000 intervals with many more samples failed.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5714#issuecomment-468672358
https://github.com/broadinstitute/gatk/issues/5714#issuecomment-468676205:111,Deployability,release,release,111,"OK, great to hear! I'll close this issue for now, but thanks for bringing it to our attention. We might try to release some documentation on how memory requirements, runtime, etc. scale with the size of the coverage matrix in each shard.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5714#issuecomment-468676205
https://github.com/broadinstitute/gatk/pull/5715#issuecomment-467092164:2146,Security,validat,validation,2146,vbGxlY3RSZWFkQ291bnRzLmphdmE=) | `84.746% <83.333%> (-0.439%)` | `11 <3> (+1)` | |; | [...oadinstitute/hellbender/utils/text/XReadLines.java](https://codecov.io/gh/broadinstitute/gatk/pull/5715/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90ZXh0L1hSZWFkTGluZXMuamF2YQ==) | `81.818% <0%> (-3.182%)` | `18% <0%> (+1%)` | |; | [...stitute/hellbender/utils/nio/PathLineIterator.java](https://codecov.io/gh/broadinstitute/gatk/pull/5715/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9uaW8vUGF0aExpbmVJdGVyYXRvci5qYXZh) | `61.111% <0%> (-3.175%)` | `4% <0%> (ø)` | |; | [...rs/variantutils/SelectVariantsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5715/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9TZWxlY3RWYXJpYW50c0ludGVncmF0aW9uVGVzdC5qYXZh) | `98% <0%> (-2%)` | `71% <0%> (ø)` | |; | [...llbender/tools/walkers/validation/Concordance.java](https://codecov.io/gh/broadinstitute/gatk/pull/5715/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vQ29uY29yZGFuY2UuamF2YQ==) | `87.179% <0%> (-1.417%)` | `41% <0%> (+2%)` | |; | [...walkers/validation/ConcordanceIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5715/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vQ29uY29yZGFuY2VJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `98.601% <0%> (-1.399%)` | `8% <0%> (+2%)` | |; | [...org/broadinstitute/hellbender/engine/GATKTool.java](https://codecov.io/gh/broadinstitute/gatk/pull/5715/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvR0FUS1Rvb2wuamF2YQ==) | `91.163% <0%> (-0.426%)` | `101% <0%> (+1%)` | |; | [...lbender/utils/variant/GATKVariantContextUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5715/diff?src=pr&el=,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5715#issuecomment-467092164
https://github.com/broadinstitute/gatk/pull/5715#issuecomment-467092164:2435,Security,validat,validation,2435,XMuamF2YQ==) | `81.818% <0%> (-3.182%)` | `18% <0%> (+1%)` | |; | [...stitute/hellbender/utils/nio/PathLineIterator.java](https://codecov.io/gh/broadinstitute/gatk/pull/5715/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9uaW8vUGF0aExpbmVJdGVyYXRvci5qYXZh) | `61.111% <0%> (-3.175%)` | `4% <0%> (ø)` | |; | [...rs/variantutils/SelectVariantsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5715/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9TZWxlY3RWYXJpYW50c0ludGVncmF0aW9uVGVzdC5qYXZh) | `98% <0%> (-2%)` | `71% <0%> (ø)` | |; | [...llbender/tools/walkers/validation/Concordance.java](https://codecov.io/gh/broadinstitute/gatk/pull/5715/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vQ29uY29yZGFuY2UuamF2YQ==) | `87.179% <0%> (-1.417%)` | `41% <0%> (+2%)` | |; | [...walkers/validation/ConcordanceIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5715/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vQ29uY29yZGFuY2VJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `98.601% <0%> (-1.399%)` | `8% <0%> (+2%)` | |; | [...org/broadinstitute/hellbender/engine/GATKTool.java](https://codecov.io/gh/broadinstitute/gatk/pull/5715/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvR0FUS1Rvb2wuamF2YQ==) | `91.163% <0%> (-0.426%)` | `101% <0%> (+1%)` | |; | [...lbender/utils/variant/GATKVariantContextUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5715/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L0dBVEtWYXJpYW50Q29udGV4dFV0aWxzLmphdmE=) | `84.892% <0%> (-0.172%)` | `256% <0%> (-4%)` | |; | [...ls/walkers/mutect/CreateSomaticPanelOfNormals.java](https://codecov.io/gh/broadinstitute/gatk/pull/5715/diff?src=pr&el,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5715#issuecomment-467092164
https://github.com/broadinstitute/gatk/pull/5715#issuecomment-467608484:75,Performance,optimiz,optimizations,75,"CRAM + NIO looks to be ~3 cents per sample. This essentially includes disk optimizations, since the disk size is determined by the CRAM size; this is not too large, so this results in disk costs of ~0.3 cents per sample. Note that I ran on the CRAMs in gs://broad-sv-dev-data/TCGA_blood_normals.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5715#issuecomment-467608484
https://github.com/broadinstitute/gatk/pull/5715#issuecomment-467612453:433,Performance,optimiz,optimizing,433,"CRAM w/o NIO is also ~3 cents per sample (it was marginally more expensive than CRAM w/ NIO, but within the noise). CRAM w/o NIO w/ SSD is ~5 cents. So I'd say CRAM w/ or w/o NIO is fine. Strictly speaking, we can't directly compare the BAM and CRAM costs, since they were done on different sets of TCGA samples. But both are well under the goal of ~15 cents per sample, so I think it's safe to say that we can turn our attention to optimizing inference costs.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5715#issuecomment-467612453
https://github.com/broadinstitute/gatk/pull/5715#issuecomment-467612453:387,Safety,safe,safe,387,"CRAM w/o NIO is also ~3 cents per sample (it was marginally more expensive than CRAM w/ NIO, but within the noise). CRAM w/o NIO w/ SSD is ~5 cents. So I'd say CRAM w/ or w/o NIO is fine. Strictly speaking, we can't directly compare the BAM and CRAM costs, since they were done on different sets of TCGA samples. But both are well under the goal of ~15 cents per sample, so I think it's safe to say that we can turn our attention to optimizing inference costs.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5715#issuecomment-467612453
https://github.com/broadinstitute/gatk/issues/5716#issuecomment-468360082:532,Deployability,pipeline,pipeline,532,"@vruano @mwalker174 Any estimates on cost that could help determine the priority of issue 1? Specifically, is the disk cost required to localize the entire count file for all samples a determining factor? If we can drastically reduce this cost, then we can dedicate more to increasing resolution, etc. Here is a minimal set of fixes that could enable the querying of intervals for GermlineCNVCaller (and also for DetermineGermlineContigPloidy without too much extra work, since we also subset intervals there) *only in the gCNV WGS pipeline*, without disrupting other interfaces:. 1) Write a Tribble SimpleCountCodec for the `counts.tsv` extension. I've already done this in a branch.; 2) Change GermlineCNVCaller and DetermineGermlineContigPloidy tools to accept paths.; 3) If an index is present for each count path, create a FeatureDataSource, merge the requested -L/-XL intervals, and query to perform the subset. We will also need to stream the SAM header metadata. It should not require much code to extract all this to a temporary IndexedSimpleCountCollection class. (Caveat: for now, this will work with the current gCNV convention of providing bins via -L/-XL. Technically, it will also work with the more conventional use of -L/-XL to denote contiguous regions, but we may have to perform checks that bins are not duplicated in adjacent shards if they overlap both, since querying a FeatureDataSource will return any bins that overlap the interval---rather than only those that are completely contained within it.); 4) Index read-count TSVs in the gCNV WGS pipeline after collection and modify the DetermineGermlineContigPloidy and GermlineCNVCaller tasks to take read-count paths and indices, if necessary. These changes could be confined in the gCNV WGS WDL for now. I think that should do the trick. If this is high priority, I can implement now. In the future, we might be able to promote all Locatable CNV Records to Features and write code to automatically pass the columns/encoders/de",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5716#issuecomment-468360082
https://github.com/broadinstitute/gatk/issues/5716#issuecomment-468360082:1567,Deployability,pipeline,pipeline,1567,"ire count file for all samples a determining factor? If we can drastically reduce this cost, then we can dedicate more to increasing resolution, etc. Here is a minimal set of fixes that could enable the querying of intervals for GermlineCNVCaller (and also for DetermineGermlineContigPloidy without too much extra work, since we also subset intervals there) *only in the gCNV WGS pipeline*, without disrupting other interfaces:. 1) Write a Tribble SimpleCountCodec for the `counts.tsv` extension. I've already done this in a branch.; 2) Change GermlineCNVCaller and DetermineGermlineContigPloidy tools to accept paths.; 3) If an index is present for each count path, create a FeatureDataSource, merge the requested -L/-XL intervals, and query to perform the subset. We will also need to stream the SAM header metadata. It should not require much code to extract all this to a temporary IndexedSimpleCountCollection class. (Caveat: for now, this will work with the current gCNV convention of providing bins via -L/-XL. Technically, it will also work with the more conventional use of -L/-XL to denote contiguous regions, but we may have to perform checks that bins are not duplicated in adjacent shards if they overlap both, since querying a FeatureDataSource will return any bins that overlap the interval---rather than only those that are completely contained within it.); 4) Index read-count TSVs in the gCNV WGS pipeline after collection and modify the DetermineGermlineContigPloidy and GermlineCNVCaller tasks to take read-count paths and indices, if necessary. These changes could be confined in the gCNV WGS WDL for now. I think that should do the trick. If this is high priority, I can implement now. In the future, we might be able to promote all Locatable CNV Records to Features and write code to automatically pass the columns/encoders/decoders (currently held in the Collection corresponding to each Record) to a single Tribble codec. This codec should not depend upon the file extension.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5716#issuecomment-468360082
https://github.com/broadinstitute/gatk/issues/5716#issuecomment-468360082:227,Energy Efficiency,reduce,reduce,227,"@vruano @mwalker174 Any estimates on cost that could help determine the priority of issue 1? Specifically, is the disk cost required to localize the entire count file for all samples a determining factor? If we can drastically reduce this cost, then we can dedicate more to increasing resolution, etc. Here is a minimal set of fixes that could enable the querying of intervals for GermlineCNVCaller (and also for DetermineGermlineContigPloidy without too much extra work, since we also subset intervals there) *only in the gCNV WGS pipeline*, without disrupting other interfaces:. 1) Write a Tribble SimpleCountCodec for the `counts.tsv` extension. I've already done this in a branch.; 2) Change GermlineCNVCaller and DetermineGermlineContigPloidy tools to accept paths.; 3) If an index is present for each count path, create a FeatureDataSource, merge the requested -L/-XL intervals, and query to perform the subset. We will also need to stream the SAM header metadata. It should not require much code to extract all this to a temporary IndexedSimpleCountCollection class. (Caveat: for now, this will work with the current gCNV convention of providing bins via -L/-XL. Technically, it will also work with the more conventional use of -L/-XL to denote contiguous regions, but we may have to perform checks that bins are not duplicated in adjacent shards if they overlap both, since querying a FeatureDataSource will return any bins that overlap the interval---rather than only those that are completely contained within it.); 4) Index read-count TSVs in the gCNV WGS pipeline after collection and modify the DetermineGermlineContigPloidy and GermlineCNVCaller tasks to take read-count paths and indices, if necessary. These changes could be confined in the gCNV WGS WDL for now. I think that should do the trick. If this is high priority, I can implement now. In the future, we might be able to promote all Locatable CNV Records to Features and write code to automatically pass the columns/encoders/de",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5716#issuecomment-468360082
https://github.com/broadinstitute/gatk/issues/5716#issuecomment-468360082:568,Integrability,interface,interfaces,568,"@vruano @mwalker174 Any estimates on cost that could help determine the priority of issue 1? Specifically, is the disk cost required to localize the entire count file for all samples a determining factor? If we can drastically reduce this cost, then we can dedicate more to increasing resolution, etc. Here is a minimal set of fixes that could enable the querying of intervals for GermlineCNVCaller (and also for DetermineGermlineContigPloidy without too much extra work, since we also subset intervals there) *only in the gCNV WGS pipeline*, without disrupting other interfaces:. 1) Write a Tribble SimpleCountCodec for the `counts.tsv` extension. I've already done this in a branch.; 2) Change GermlineCNVCaller and DetermineGermlineContigPloidy tools to accept paths.; 3) If an index is present for each count path, create a FeatureDataSource, merge the requested -L/-XL intervals, and query to perform the subset. We will also need to stream the SAM header metadata. It should not require much code to extract all this to a temporary IndexedSimpleCountCollection class. (Caveat: for now, this will work with the current gCNV convention of providing bins via -L/-XL. Technically, it will also work with the more conventional use of -L/-XL to denote contiguous regions, but we may have to perform checks that bins are not duplicated in adjacent shards if they overlap both, since querying a FeatureDataSource will return any bins that overlap the interval---rather than only those that are completely contained within it.); 4) Index read-count TSVs in the gCNV WGS pipeline after collection and modify the DetermineGermlineContigPloidy and GermlineCNVCaller tasks to take read-count paths and indices, if necessary. These changes could be confined in the gCNV WGS WDL for now. I think that should do the trick. If this is high priority, I can implement now. In the future, we might be able to promote all Locatable CNV Records to Features and write code to automatically pass the columns/encoders/de",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5716#issuecomment-468360082
https://github.com/broadinstitute/gatk/issues/5716#issuecomment-468360082:2121,Integrability,depend,depend,2121,"ire count file for all samples a determining factor? If we can drastically reduce this cost, then we can dedicate more to increasing resolution, etc. Here is a minimal set of fixes that could enable the querying of intervals for GermlineCNVCaller (and also for DetermineGermlineContigPloidy without too much extra work, since we also subset intervals there) *only in the gCNV WGS pipeline*, without disrupting other interfaces:. 1) Write a Tribble SimpleCountCodec for the `counts.tsv` extension. I've already done this in a branch.; 2) Change GermlineCNVCaller and DetermineGermlineContigPloidy tools to accept paths.; 3) If an index is present for each count path, create a FeatureDataSource, merge the requested -L/-XL intervals, and query to perform the subset. We will also need to stream the SAM header metadata. It should not require much code to extract all this to a temporary IndexedSimpleCountCollection class. (Caveat: for now, this will work with the current gCNV convention of providing bins via -L/-XL. Technically, it will also work with the more conventional use of -L/-XL to denote contiguous regions, but we may have to perform checks that bins are not duplicated in adjacent shards if they overlap both, since querying a FeatureDataSource will return any bins that overlap the interval---rather than only those that are completely contained within it.); 4) Index read-count TSVs in the gCNV WGS pipeline after collection and modify the DetermineGermlineContigPloidy and GermlineCNVCaller tasks to take read-count paths and indices, if necessary. These changes could be confined in the gCNV WGS WDL for now. I think that should do the trick. If this is high priority, I can implement now. In the future, we might be able to promote all Locatable CNV Records to Features and write code to automatically pass the columns/encoders/decoders (currently held in the Collection corresponding to each Record) to a single Tribble codec. This codec should not depend upon the file extension.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5716#issuecomment-468360082
https://github.com/broadinstitute/gatk/issues/5716#issuecomment-468360082:898,Performance,perform,perform,898,"@vruano @mwalker174 Any estimates on cost that could help determine the priority of issue 1? Specifically, is the disk cost required to localize the entire count file for all samples a determining factor? If we can drastically reduce this cost, then we can dedicate more to increasing resolution, etc. Here is a minimal set of fixes that could enable the querying of intervals for GermlineCNVCaller (and also for DetermineGermlineContigPloidy without too much extra work, since we also subset intervals there) *only in the gCNV WGS pipeline*, without disrupting other interfaces:. 1) Write a Tribble SimpleCountCodec for the `counts.tsv` extension. I've already done this in a branch.; 2) Change GermlineCNVCaller and DetermineGermlineContigPloidy tools to accept paths.; 3) If an index is present for each count path, create a FeatureDataSource, merge the requested -L/-XL intervals, and query to perform the subset. We will also need to stream the SAM header metadata. It should not require much code to extract all this to a temporary IndexedSimpleCountCollection class. (Caveat: for now, this will work with the current gCNV convention of providing bins via -L/-XL. Technically, it will also work with the more conventional use of -L/-XL to denote contiguous regions, but we may have to perform checks that bins are not duplicated in adjacent shards if they overlap both, since querying a FeatureDataSource will return any bins that overlap the interval---rather than only those that are completely contained within it.); 4) Index read-count TSVs in the gCNV WGS pipeline after collection and modify the DetermineGermlineContigPloidy and GermlineCNVCaller tasks to take read-count paths and indices, if necessary. These changes could be confined in the gCNV WGS WDL for now. I think that should do the trick. If this is high priority, I can implement now. In the future, we might be able to promote all Locatable CNV Records to Features and write code to automatically pass the columns/encoders/de",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5716#issuecomment-468360082
https://github.com/broadinstitute/gatk/issues/5716#issuecomment-468360082:1291,Performance,perform,perform,1291,"ire count file for all samples a determining factor? If we can drastically reduce this cost, then we can dedicate more to increasing resolution, etc. Here is a minimal set of fixes that could enable the querying of intervals for GermlineCNVCaller (and also for DetermineGermlineContigPloidy without too much extra work, since we also subset intervals there) *only in the gCNV WGS pipeline*, without disrupting other interfaces:. 1) Write a Tribble SimpleCountCodec for the `counts.tsv` extension. I've already done this in a branch.; 2) Change GermlineCNVCaller and DetermineGermlineContigPloidy tools to accept paths.; 3) If an index is present for each count path, create a FeatureDataSource, merge the requested -L/-XL intervals, and query to perform the subset. We will also need to stream the SAM header metadata. It should not require much code to extract all this to a temporary IndexedSimpleCountCollection class. (Caveat: for now, this will work with the current gCNV convention of providing bins via -L/-XL. Technically, it will also work with the more conventional use of -L/-XL to denote contiguous regions, but we may have to perform checks that bins are not duplicated in adjacent shards if they overlap both, since querying a FeatureDataSource will return any bins that overlap the interval---rather than only those that are completely contained within it.); 4) Index read-count TSVs in the gCNV WGS pipeline after collection and modify the DetermineGermlineContigPloidy and GermlineCNVCaller tasks to take read-count paths and indices, if necessary. These changes could be confined in the gCNV WGS WDL for now. I think that should do the trick. If this is high priority, I can implement now. In the future, we might be able to promote all Locatable CNV Records to Features and write code to automatically pass the columns/encoders/decoders (currently held in the Collection corresponding to each Record) to a single Tribble codec. This codec should not depend upon the file extension.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5716#issuecomment-468360082
https://github.com/broadinstitute/gatk/issues/5716#issuecomment-468360082:600,Usability,Simpl,SimpleCountCodec,600,"@vruano @mwalker174 Any estimates on cost that could help determine the priority of issue 1? Specifically, is the disk cost required to localize the entire count file for all samples a determining factor? If we can drastically reduce this cost, then we can dedicate more to increasing resolution, etc. Here is a minimal set of fixes that could enable the querying of intervals for GermlineCNVCaller (and also for DetermineGermlineContigPloidy without too much extra work, since we also subset intervals there) *only in the gCNV WGS pipeline*, without disrupting other interfaces:. 1) Write a Tribble SimpleCountCodec for the `counts.tsv` extension. I've already done this in a branch.; 2) Change GermlineCNVCaller and DetermineGermlineContigPloidy tools to accept paths.; 3) If an index is present for each count path, create a FeatureDataSource, merge the requested -L/-XL intervals, and query to perform the subset. We will also need to stream the SAM header metadata. It should not require much code to extract all this to a temporary IndexedSimpleCountCollection class. (Caveat: for now, this will work with the current gCNV convention of providing bins via -L/-XL. Technically, it will also work with the more conventional use of -L/-XL to denote contiguous regions, but we may have to perform checks that bins are not duplicated in adjacent shards if they overlap both, since querying a FeatureDataSource will return any bins that overlap the interval---rather than only those that are completely contained within it.); 4) Index read-count TSVs in the gCNV WGS pipeline after collection and modify the DetermineGermlineContigPloidy and GermlineCNVCaller tasks to take read-count paths and indices, if necessary. These changes could be confined in the gCNV WGS WDL for now. I think that should do the trick. If this is high priority, I can implement now. In the future, we might be able to promote all Locatable CNV Records to Features and write code to automatically pass the columns/encoders/de",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5716#issuecomment-468360082
https://github.com/broadinstitute/gatk/issues/5716#issuecomment-469695181:577,Deployability,update,update,577,"Hacked together a proof-of-principle in sl_indexed_counts. This enables streaming of indexed counts (when they are specified by a bucket, although we should change this to trigger on the presence of an index) only for the requested intervals in the gCNV step, which would cut disk costs to practically zero. We could enable this in the contig-ploidy step as well, although the cost benefit is not as great there since the tool is short running. The relevant code clocks in at around +250 lines and could be even more minimal after some cleanup and extraction, but we'd need to update documentation and the WDLs. All previous behavior is preserved.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5716#issuecomment-469695181
https://github.com/broadinstitute/gatk/issues/5716#issuecomment-526644201:135,Deployability,pipeline,pipeline,135,"@samuelklee Let's try to get your `sl_indexed_counts` branch in since it will have a substantial impact on the cost of the clinical SV pipeline. It's fine if it just streams from a bucket, but we do want to update the WDLs to take advantage.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5716#issuecomment-526644201
https://github.com/broadinstitute/gatk/issues/5716#issuecomment-526644201:207,Deployability,update,update,207,"@samuelklee Let's try to get your `sl_indexed_counts` branch in since it will have a substantial impact on the cost of the clinical SV pipeline. It's fine if it just streams from a bucket, but we do want to update the WDLs to take advantage.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5716#issuecomment-526644201
https://github.com/broadinstitute/gatk/issues/5716#issuecomment-551235864:10,Deployability,pipeline,pipeline,10,"In the SV pipeline, for ~100 samples in case mode the cost breakdown was:. memory: $1.04; disk: $1.50; cpu: $4.59. It seems that we are over-provisioning for disk: amount of disk size used was < 5 GB (only ~$0.14 worth of disk) but the default is 150 gb. Therefore it doesn't seem that we would save much by streaming, but we should lower the default disk size in the WDL.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5716#issuecomment-551235864
https://github.com/broadinstitute/gatk/issues/5716#issuecomment-551259792:372,Deployability,pipeline,pipeline,372,"As we just discussed at our gCNV meeting, this disk cost is for 2kbp bins. So once 100bp bins are back on the table, we'll be at 20 x $0.14 = $2.80. In the meantime, no reason not to recoup that ~$1.36! Maybe even dump it into memory and decrease the number of shards accordingly?. For now, we should probably just set the appropriate runtime parameter in the clinical SV pipeline, but then at some point (maybe when we update to WDL 1.0) go back and put some more intelligent disk-size estimation into the CNV WDLs. At some point Spec Ops did this for the somatic WDLs (where it probably doesn't make too much of a difference), but we didn't really do anything special for the gCNV WDLs.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5716#issuecomment-551259792
https://github.com/broadinstitute/gatk/issues/5716#issuecomment-551259792:420,Deployability,update,update,420,"As we just discussed at our gCNV meeting, this disk cost is for 2kbp bins. So once 100bp bins are back on the table, we'll be at 20 x $0.14 = $2.80. In the meantime, no reason not to recoup that ~$1.36! Maybe even dump it into memory and decrease the number of shards accordingly?. For now, we should probably just set the appropriate runtime parameter in the clinical SV pipeline, but then at some point (maybe when we update to WDL 1.0) go back and put some more intelligent disk-size estimation into the CNV WDLs. At some point Spec Ops did this for the somatic WDLs (where it probably doesn't make too much of a difference), but we didn't really do anything special for the gCNV WDLs.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5716#issuecomment-551259792
https://github.com/broadinstitute/gatk/issues/5716#issuecomment-926158295:133,Performance,bottleneck,bottlenecks,133,The bulk of this issue was addressed in #6266. I believe @samuelklee also did some detailed profiling and determined that the memory bottlenecks were inference-related.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5716#issuecomment-926158295
https://github.com/broadinstitute/gatk/issues/5717#issuecomment-467122014:300,Availability,error,error,300,[gatk4_errorLines.log](https://github.com/broadinstitute/gatk/files/2901904/gatk4_errorLines.log); [parallel.log](https://github.com/broadinstitute/gatk/files/2901906/parallel.log); [hs_err_pid82632.log](https://github.com/broadinstitute/gatk/files/2901907/hs_err_pid82632.log). Please find attached error logs presented by the user.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5717#issuecomment-467122014
https://github.com/broadinstitute/gatk/issues/5717#issuecomment-467122014:18,Testability,log,log,18,[gatk4_errorLines.log](https://github.com/broadinstitute/gatk/files/2901904/gatk4_errorLines.log); [parallel.log](https://github.com/broadinstitute/gatk/files/2901906/parallel.log); [hs_err_pid82632.log](https://github.com/broadinstitute/gatk/files/2901907/hs_err_pid82632.log). Please find attached error logs presented by the user.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5717#issuecomment-467122014
https://github.com/broadinstitute/gatk/issues/5717#issuecomment-467122014:93,Testability,log,log,93,[gatk4_errorLines.log](https://github.com/broadinstitute/gatk/files/2901904/gatk4_errorLines.log); [parallel.log](https://github.com/broadinstitute/gatk/files/2901906/parallel.log); [hs_err_pid82632.log](https://github.com/broadinstitute/gatk/files/2901907/hs_err_pid82632.log). Please find attached error logs presented by the user.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5717#issuecomment-467122014
https://github.com/broadinstitute/gatk/issues/5717#issuecomment-467122014:109,Testability,log,log,109,[gatk4_errorLines.log](https://github.com/broadinstitute/gatk/files/2901904/gatk4_errorLines.log); [parallel.log](https://github.com/broadinstitute/gatk/files/2901906/parallel.log); [hs_err_pid82632.log](https://github.com/broadinstitute/gatk/files/2901907/hs_err_pid82632.log). Please find attached error logs presented by the user.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5717#issuecomment-467122014
https://github.com/broadinstitute/gatk/issues/5717#issuecomment-467122014:176,Testability,log,log,176,[gatk4_errorLines.log](https://github.com/broadinstitute/gatk/files/2901904/gatk4_errorLines.log); [parallel.log](https://github.com/broadinstitute/gatk/files/2901906/parallel.log); [hs_err_pid82632.log](https://github.com/broadinstitute/gatk/files/2901907/hs_err_pid82632.log). Please find attached error logs presented by the user.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5717#issuecomment-467122014
https://github.com/broadinstitute/gatk/issues/5717#issuecomment-467122014:199,Testability,log,log,199,[gatk4_errorLines.log](https://github.com/broadinstitute/gatk/files/2901904/gatk4_errorLines.log); [parallel.log](https://github.com/broadinstitute/gatk/files/2901906/parallel.log); [hs_err_pid82632.log](https://github.com/broadinstitute/gatk/files/2901907/hs_err_pid82632.log). Please find attached error logs presented by the user.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5717#issuecomment-467122014
https://github.com/broadinstitute/gatk/issues/5717#issuecomment-467122014:273,Testability,log,log,273,[gatk4_errorLines.log](https://github.com/broadinstitute/gatk/files/2901904/gatk4_errorLines.log); [parallel.log](https://github.com/broadinstitute/gatk/files/2901906/parallel.log); [hs_err_pid82632.log](https://github.com/broadinstitute/gatk/files/2901907/hs_err_pid82632.log). Please find attached error logs presented by the user.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5717#issuecomment-467122014
https://github.com/broadinstitute/gatk/issues/5717#issuecomment-467122014:306,Testability,log,logs,306,[gatk4_errorLines.log](https://github.com/broadinstitute/gatk/files/2901904/gatk4_errorLines.log); [parallel.log](https://github.com/broadinstitute/gatk/files/2901906/parallel.log); [hs_err_pid82632.log](https://github.com/broadinstitute/gatk/files/2901907/hs_err_pid82632.log). Please find attached error logs presented by the user.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5717#issuecomment-467122014
https://github.com/broadinstitute/gatk/issues/5717#issuecomment-467384382:29,Availability,failure,failures,29,"A few comments:; * Spark job failures are usually memory related. What was the command run in this case?; * Running HaplotypeCallerSpark is memory and compute intensive and should really be done on a cluster such as a Google Cloud Dataproc cluster. There are some scripts to help with this process here: https://github.com/broadinstitute/gatk/tree/master/scripts/spark_eval. Even if you don't use the scripts, they have settings for tuning memory, workers etc, that might be helpful.; * MarkDuplicatesSpark can be run effectively on a single multi-core machine, so might be a good one to start with to get into Spark.; * Spark manages parallelism, so GNU parallel is not needed (and doesn't really work well with Spark).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5717#issuecomment-467384382
https://github.com/broadinstitute/gatk/pull/5718#issuecomment-467164762:941,Security,validat,validation,941,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5718?src=pr&el=h1) Report; > Merging [#5718](https://codecov.io/gh/broadinstitute/gatk/pull/5718?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/226f6d70a9c09318d45506c726f6744e2379d60c?src=pr&el=desc) will **decrease** coverage by `0.002%`.; > The diff coverage is `86.667%`. ```diff; @@ Coverage Diff @@; ## master #5718 +/- ##; ===============================================; - Coverage 87.069% 87.067% -0.003% ; - Complexity 31875 31880 +5 ; ===============================================; Files 1940 1940 ; Lines 146738 146756 +18 ; Branches 16226 16229 +3 ; ===============================================; + Hits 127764 127776 +12 ; - Misses 13061 13065 +4 ; - Partials 5913 5915 +2; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5718?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...walkers/validation/ConcordanceIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5718/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vQ29uY29yZGFuY2VJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `98.601% <100%> (-1.399%)` | `8 <6> (+2)` | |; | [...llbender/tools/walkers/validation/Concordance.java](https://codecov.io/gh/broadinstitute/gatk/pull/5718/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vQ29uY29yZGFuY2UuamF2YQ==) | `87.179% <50%> (-1.417%)` | `41 <0> (+2)` | |; | [...oadinstitute/hellbender/utils/pairhmm/PairHMM.java](https://codecov.io/gh/broadinstitute/gatk/pull/5718/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9wYWlyaG1tL1BhaXJITU0uamF2YQ==) | `74.82% <0%> (-3.597%)` | `24% <0%> (ø)` | |; | [...hellbender/utils/pairhmm/VectorLoglessPairHMM.java](https://codecov.io/gh/broadinstitute/gatk/pull/5718/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbn,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5718#issuecomment-467164762
https://github.com/broadinstitute/gatk/pull/5718#issuecomment-467164762:1278,Security,validat,validation,1278,c=pr&el=desc) will **decrease** coverage by `0.002%`.; > The diff coverage is `86.667%`. ```diff; @@ Coverage Diff @@; ## master #5718 +/- ##; ===============================================; - Coverage 87.069% 87.067% -0.003% ; - Complexity 31875 31880 +5 ; ===============================================; Files 1940 1940 ; Lines 146738 146756 +18 ; Branches 16226 16229 +3 ; ===============================================; + Hits 127764 127776 +12 ; - Misses 13061 13065 +4 ; - Partials 5913 5915 +2; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5718?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...walkers/validation/ConcordanceIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5718/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vQ29uY29yZGFuY2VJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `98.601% <100%> (-1.399%)` | `8 <6> (+2)` | |; | [...llbender/tools/walkers/validation/Concordance.java](https://codecov.io/gh/broadinstitute/gatk/pull/5718/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vQ29uY29yZGFuY2UuamF2YQ==) | `87.179% <50%> (-1.417%)` | `41 <0> (+2)` | |; | [...oadinstitute/hellbender/utils/pairhmm/PairHMM.java](https://codecov.io/gh/broadinstitute/gatk/pull/5718/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9wYWlyaG1tL1BhaXJITU0uamF2YQ==) | `74.82% <0%> (-3.597%)` | `24% <0%> (ø)` | |; | [...hellbender/utils/pairhmm/VectorLoglessPairHMM.java](https://codecov.io/gh/broadinstitute/gatk/pull/5718/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9wYWlyaG1tL1ZlY3RvckxvZ2xlc3NQYWlySE1NLmphdmE=) | `85.526% <0%> (-1.316%)` | `12% <0%> (ø)` | |; | [...nder/utils/runtime/StreamingProcessController.java](https://codecov.io/gh/broadinstitute/gatk/pull/5718/diff?src=pr&el=tree#diff-c3JjL21haW4va,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5718#issuecomment-467164762
https://github.com/broadinstitute/gatk/issues/5719#issuecomment-467252385:665,Security,validat,validate,665,"Hi @dislek, this type of question might be more appropriate for the GATK forum (and has actually been previously asked there, see https://gatkforums.broadinstitute.org/gatk/discussion/12543/determinegermlinecontigploidy and the thread linked in the answer). The priors file is a TSV file that is described in the tool documentation for DetermineGermlineContigPloidy. You should manually construct this TSV file, with contig names appropriate to the reference being used and prior probabilities appropriate for the quality of your data set---probably the suggestions in the example in the tool documentation are a reasonable place to start. However, you may want to validate the ploidy calls output by DetermineGermlineContigPloidy using samples where the truth is known to ensure that the model is trained correctly using your choice of priors and other model parameters.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5719#issuecomment-467252385
https://github.com/broadinstitute/gatk/pull/5723#issuecomment-519520053:0,Availability,Ping,Ping,0,Ping @jamesemery,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5723#issuecomment-519520053
https://github.com/broadinstitute/gatk/pull/5723#issuecomment-519560848:111,Testability,test,test,111,"@droazen didn't you have an objection to these PRs, (this one and #5451)? What was the issue with unifying the test code again?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5723#issuecomment-519560848
https://github.com/broadinstitute/gatk/pull/5724#issuecomment-467587055:2912,Security,validat,validation,2912,walkers/bqsr/BaseRecalibratorIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5724/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Jxc3IvQmFzZVJlY2FsaWJyYXRvckludGVncmF0aW9uVGVzdC5qYXZh) | `1.031% <0%> (-98.969%)` | `1% <0%> (-7%)` | |; | [...ers/vqsr/FilterVariantTranchesIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5724/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3Zxc3IvRmlsdGVyVmFyaWFudFRyYW5jaGVzSW50ZWdyYXRpb25UZXN0LmphdmE=) | `1.053% <0%> (-98.947%)` | `1% <0%> (-5%)` | |; | [...s/variantutils/VariantsToTableIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5724/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9WYXJpYW50c1RvVGFibGVJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `1.205% <0%> (-98.795%)` | `1% <0%> (-20%)` | |; | [...walkers/validation/ConcordanceIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5724/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vQ29uY29yZGFuY2VJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `1.563% <0%> (-98.438%)` | `1% <0%> (-5%)` | |; | [...ientation/ReadOrientationModelIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5724/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3JlYWRvcmllbnRhdGlvbi9SZWFkT3JpZW50YXRpb25Nb2RlbEludGVncmF0aW9uVGVzdC5qYXZh) | `1.667% <0%> (-98.333%)` | `1% <0%> (-5%)` | |; | [...on/FindBreakpointEvidenceSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5724/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9pbnRlZ3JhdGlvbi9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmtJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `1.754% <0%> (-98.246%)` | `1% <0%> (-6%)` | |; | [...bender/tools/s,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5724#issuecomment-467587055
https://github.com/broadinstitute/gatk/pull/5725#issuecomment-472452475:119,Deployability,update,updated,119,Actually one more question: does the expected output need to change in addition to the epsilon checking - the file was updated ?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5725#issuecomment-472452475
https://github.com/broadinstitute/gatk/pull/5725#issuecomment-475055039:93,Deployability,release,release,93,BTW This PR gives a 2X speedup to the 2D CNN so we would love to get this in before the next release...,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5725#issuecomment-475055039
https://github.com/broadinstitute/gatk/pull/5725#issuecomment-475614790:433,Energy Efficiency,reduce,reduce,433,"@lucidtronix Are the environment variables that you added to the Docker env essential to realize the speed 2x improvement ? I'm reluctant to just add them to the Docker env without understanding what they're doing and whether/how they impact other components. i.e., changing OPEN_MP thread affinity/pinning params etc. might impact the native Intel PairHMM implementation (also @samuelklee will these impact CNV) ? Another option is reduce the scope of them and set them only for the specific tool(s), possibly exposed as command line arguments. The ScriptExecutor has control over the python process' environment and could easily propagate them to the so they only affect the particular Python process. But the values would have to be provided somehow.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5725#issuecomment-475614790
https://github.com/broadinstitute/gatk/pull/5725#issuecomment-475614790:33,Modifiability,variab,variables,33,"@lucidtronix Are the environment variables that you added to the Docker env essential to realize the speed 2x improvement ? I'm reluctant to just add them to the Docker env without understanding what they're doing and whether/how they impact other components. i.e., changing OPEN_MP thread affinity/pinning params etc. might impact the native Intel PairHMM implementation (also @samuelklee will these impact CNV) ? Another option is reduce the scope of them and set them only for the specific tool(s), possibly exposed as command line arguments. The ScriptExecutor has control over the python process' environment and could easily propagate them to the so they only affect the particular Python process. But the values would have to be provided somehow.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5725#issuecomment-475614790
https://github.com/broadinstitute/gatk/pull/5725#issuecomment-475614790:511,Security,expose,exposed,511,"@lucidtronix Are the environment variables that you added to the Docker env essential to realize the speed 2x improvement ? I'm reluctant to just add them to the Docker env without understanding what they're doing and whether/how they impact other components. i.e., changing OPEN_MP thread affinity/pinning params etc. might impact the native Intel PairHMM implementation (also @samuelklee will these impact CNV) ? Another option is reduce the scope of them and set them only for the specific tool(s), possibly exposed as command line arguments. The ScriptExecutor has control over the python process' environment and could easily propagate them to the so they only affect the particular Python process. But the values would have to be provided somehow.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5725#issuecomment-475614790
https://github.com/broadinstitute/gatk/pull/5725#issuecomment-475628454:165,Usability,guid,guideline,165,"@lucidtronix @cmnbroad we set the *_NUM_THREADS flags in the WDL, but the changes to the Dockerfile will affect users who don't use the WDL (or don't follow it as a guideline for building their own scripts).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5725#issuecomment-475628454
https://github.com/broadinstitute/gatk/pull/5725#issuecomment-476605177:61,Deployability,release,release,61,"@lucidtronix It would be great to get this into the upcoming release later this week, but see my questions above about the intent of the environment variable settings, and whether they're essential to achieve the speedup. Setting OPEN_MP_NUM_THREADS for the entire docker will potentially impact the native PairHMM code, so we'll either need to remove these, narrow the scope to tool/WDL, or better understand the intent/impact of these on the native code.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5725#issuecomment-476605177
https://github.com/broadinstitute/gatk/pull/5725#issuecomment-476605177:149,Modifiability,variab,variable,149,"@lucidtronix It would be great to get this into the upcoming release later this week, but see my questions above about the intent of the environment variable settings, and whether they're essential to achieve the speedup. Setting OPEN_MP_NUM_THREADS for the entire docker will potentially impact the native PairHMM code, so we'll either need to remove these, narrow the scope to tool/WDL, or better understand the intent/impact of these on the native code.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5725#issuecomment-476605177
https://github.com/broadinstitute/gatk/pull/5725#issuecomment-476752829:137,Modifiability,variab,variables,137,@cmnbroad rebased and reverted the dockerfile. Tests pass locally. I'm also running a test in the cloud to see the impact of environment variables on speedup.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5725#issuecomment-476752829
https://github.com/broadinstitute/gatk/pull/5725#issuecomment-476752829:47,Testability,Test,Tests,47,@cmnbroad rebased and reverted the dockerfile. Tests pass locally. I'm also running a test in the cloud to see the impact of environment variables on speedup.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5725#issuecomment-476752829
https://github.com/broadinstitute/gatk/pull/5725#issuecomment-476752829:86,Testability,test,test,86,@cmnbroad rebased and reverted the dockerfile. Tests pass locally. I'm also running a test in the cloud to see the impact of environment variables on speedup.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5725#issuecomment-476752829
https://github.com/broadinstitute/gatk/pull/5725#issuecomment-476850732:81,Modifiability,variab,variables,81,@cmnbroad Thank you! I confirmed the speedup is not contigent on the environment variables.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5725#issuecomment-476850732
https://github.com/broadinstitute/gatk/issues/5727#issuecomment-470610709:555,Testability,log,logs,555,"Adding a little more fuel to the fire on this one. Our workaround for this for the time being was going to be to run HC twice - once to output a gVCF and again to output a called VCF directly. While being a little wasteful of compute we figured this would give us correctly phased calls in a genotyped VCF while also giving us the reference confidence information in a gVCF. However, we just tried that and found that there is no phasing information in the genotyped VCF produced directly from HaplotypeCaller without any `-ERC` parameter. Looking at the logs i see:. ```; 09:00:09.140 INFO HaplotypeCallerEngine - Disabling physical phasing, which is supported only for reference-model confidence output; ```. Based on this I don't think there's a workaround. I can either generate a gVCF with `-ERC GVCF` or `-ERC BP_RESOLUTION`, but then running `GenotypeGVCFs` will mangle the phase information, _or_ run without `-ERC` but then get zero phasing information. Am I missing a potential workaround? Also, I'm curious why phasing is disabled for non-ERC mode as, at least to me, it's not immediately obvious why that would be.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5727#issuecomment-470610709
https://github.com/broadinstitute/gatk/issues/5727#issuecomment-470618640:368,Availability,error,errors,368,"On a whim I took the latest code from master and commented out the two lines in HaplotypeCallerEngine:257-258 that disable phsyical phasing if `emitReferenceConfidence()` is false, and tried running HC to generate a genotyped VCF with phase. At least on a simple test of a ~200bp locus with a pair of phased variants it appears to do the right thing and not cause any errors. I know testing calling in one small locus isn't exactly comprehensive, and I'm trying now to call a larger set of regions and compare the calls generated to expected phase. Does anyone recall why this restriction was in place? I'm hoping that perhaps it was needed at the time, but isn't now and was just left in place because nobody needed it removed? I see the lines in question were last touched by @droazen in April 2016, but even that commit seems to be a large scale moving around of code rather than a commit that addressed this specific issue. I'm going to open a PR to remove those lines - mostly so I can have the tests run up in CI, and see if anything breaks.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5727#issuecomment-470618640
https://github.com/broadinstitute/gatk/issues/5727#issuecomment-470618640:263,Testability,test,test,263,"On a whim I took the latest code from master and commented out the two lines in HaplotypeCallerEngine:257-258 that disable phsyical phasing if `emitReferenceConfidence()` is false, and tried running HC to generate a genotyped VCF with phase. At least on a simple test of a ~200bp locus with a pair of phased variants it appears to do the right thing and not cause any errors. I know testing calling in one small locus isn't exactly comprehensive, and I'm trying now to call a larger set of regions and compare the calls generated to expected phase. Does anyone recall why this restriction was in place? I'm hoping that perhaps it was needed at the time, but isn't now and was just left in place because nobody needed it removed? I see the lines in question were last touched by @droazen in April 2016, but even that commit seems to be a large scale moving around of code rather than a commit that addressed this specific issue. I'm going to open a PR to remove those lines - mostly so I can have the tests run up in CI, and see if anything breaks.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5727#issuecomment-470618640
https://github.com/broadinstitute/gatk/issues/5727#issuecomment-470618640:383,Testability,test,testing,383,"On a whim I took the latest code from master and commented out the two lines in HaplotypeCallerEngine:257-258 that disable phsyical phasing if `emitReferenceConfidence()` is false, and tried running HC to generate a genotyped VCF with phase. At least on a simple test of a ~200bp locus with a pair of phased variants it appears to do the right thing and not cause any errors. I know testing calling in one small locus isn't exactly comprehensive, and I'm trying now to call a larger set of regions and compare the calls generated to expected phase. Does anyone recall why this restriction was in place? I'm hoping that perhaps it was needed at the time, but isn't now and was just left in place because nobody needed it removed? I see the lines in question were last touched by @droazen in April 2016, but even that commit seems to be a large scale moving around of code rather than a commit that addressed this specific issue. I'm going to open a PR to remove those lines - mostly so I can have the tests run up in CI, and see if anything breaks.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5727#issuecomment-470618640
https://github.com/broadinstitute/gatk/issues/5727#issuecomment-470618640:1000,Testability,test,tests,1000,"On a whim I took the latest code from master and commented out the two lines in HaplotypeCallerEngine:257-258 that disable phsyical phasing if `emitReferenceConfidence()` is false, and tried running HC to generate a genotyped VCF with phase. At least on a simple test of a ~200bp locus with a pair of phased variants it appears to do the right thing and not cause any errors. I know testing calling in one small locus isn't exactly comprehensive, and I'm trying now to call a larger set of regions and compare the calls generated to expected phase. Does anyone recall why this restriction was in place? I'm hoping that perhaps it was needed at the time, but isn't now and was just left in place because nobody needed it removed? I see the lines in question were last touched by @droazen in April 2016, but even that commit seems to be a large scale moving around of code rather than a commit that addressed this specific issue. I'm going to open a PR to remove those lines - mostly so I can have the tests run up in CI, and see if anything breaks.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5727#issuecomment-470618640
https://github.com/broadinstitute/gatk/issues/5727#issuecomment-470618640:256,Usability,simpl,simple,256,"On a whim I took the latest code from master and commented out the two lines in HaplotypeCallerEngine:257-258 that disable phsyical phasing if `emitReferenceConfidence()` is false, and tried running HC to generate a genotyped VCF with phase. At least on a simple test of a ~200bp locus with a pair of phased variants it appears to do the right thing and not cause any errors. I know testing calling in one small locus isn't exactly comprehensive, and I'm trying now to call a larger set of regions and compare the calls generated to expected phase. Does anyone recall why this restriction was in place? I'm hoping that perhaps it was needed at the time, but isn't now and was just left in place because nobody needed it removed? I see the lines in question were last touched by @droazen in April 2016, but even that commit seems to be a large scale moving around of code rather than a commit that addressed this specific issue. I'm going to open a PR to remove those lines - mostly so I can have the tests run up in CI, and see if anything breaks.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5727#issuecomment-470618640
https://github.com/broadinstitute/gatk/issues/5727#issuecomment-470679237:318,Deployability,Update,Updated,318,"@tfenne If it's the commit I think it was, it was just me porting the GATK3 HaplotypeCaller to GATK4. Checking in GATK3, those lines were actually added by @eitanbanks in 2014:. ```; commit add65e1d99209347c6be9a78d7839819ef4bcb9d; Author: Eric Banks <ebanks@broadinstitute.org>; Date: Fri Aug 15 17:47:32 2014 -0400. Updated the physical phasing in the Haplotype Caller to address requests from ATGU.; ; 1. It is now turned on by default; 2. It now phases homozygous variants; 3. Most importantly, it also phases variants that are always on opposite haplotypes; ; Changed the INFO keys to be PID and PGT, as described in the header. diff --git a/protected/gatk-tools-protected/src/main/java/org/broadinstitute/gatk/tools/walkers/haplotypecaller/HaplotypeCaller.java b/protected/gatk-tools-protected/src/main/java/org/broadinstitute/gatk/tools/walkers/haplotypecaller/HaplotypeCaller.java; index cf34b1fb4e..2ee5752f04 100644; --- a/protected/gatk-tools-protected/src/main/java/org/broadinstitute/gatk/tools/walkers/haplotypecaller/HaplotypeCaller.java; +++ b/protected/gatk-tools-protected/src/main/java/org/broadinstitute/gatk/tools/walkers/haplotypecaller/HaplotypeCaller.java; @@ -497,10 +497,11 @@ public class HaplotypeCaller extends ActiveRegionWalker<List<VariantContext>, In; protected boolean mergeVariantsViaLD = false;; ; @Advanced; - @Argument(fullName=""tryPhysicalPhasing"", shortName=""tryPhysicalPhasing"", doc=""If specified, we will add physical (read-based) phasing information"", required = false); - protected boolean tryPhysicalPhasing = false;; + @Argument(fullName=""doNotRunPhysicalPhasing"", shortName=""doNotRunPhysicalPhasing"", doc=""If specified, we will not try to add physical (read-based) phasing information"", required = false); + protected boolean doNotRunPhysicalPhasing = false;; ; - public static final String HAPLOTYPE_CALLER_PHASING_KEY = ""HCP"";; + public static final String HAPLOTYPE_CALLER_PHASING_ID_KEY = ""PID"";; + public static final String HAPLOTYPE_CALLER_PHASING",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5727#issuecomment-470679237
https://github.com/broadinstitute/gatk/issues/5727#issuecomment-470679237:1232,Modifiability,extend,extends,1232,"eCaller.java b/protected/gatk-tools-protected/src/main/java/org/broadinstitute/gatk/tools/walkers/haplotypecaller/HaplotypeCaller.java; index cf34b1fb4e..2ee5752f04 100644; --- a/protected/gatk-tools-protected/src/main/java/org/broadinstitute/gatk/tools/walkers/haplotypecaller/HaplotypeCaller.java; +++ b/protected/gatk-tools-protected/src/main/java/org/broadinstitute/gatk/tools/walkers/haplotypecaller/HaplotypeCaller.java; @@ -497,10 +497,11 @@ public class HaplotypeCaller extends ActiveRegionWalker<List<VariantContext>, In; protected boolean mergeVariantsViaLD = false;; ; @Advanced; - @Argument(fullName=""tryPhysicalPhasing"", shortName=""tryPhysicalPhasing"", doc=""If specified, we will add physical (read-based) phasing information"", required = false); - protected boolean tryPhysicalPhasing = false;; + @Argument(fullName=""doNotRunPhysicalPhasing"", shortName=""doNotRunPhysicalPhasing"", doc=""If specified, we will not try to add physical (read-based) phasing information"", required = false); + protected boolean doNotRunPhysicalPhasing = false;; ; - public static final String HAPLOTYPE_CALLER_PHASING_KEY = ""HCP"";; + public static final String HAPLOTYPE_CALLER_PHASING_ID_KEY = ""PID"";; + public static final String HAPLOTYPE_CALLER_PHASING_GT_KEY = ""PGT"";; ; // -----------------------------------------------------------------------------------------------; // arguments for debugging / developing the haplotype caller; @@ -634,12 +635,11 @@ public class HaplotypeCaller extends ActiveRegionWalker<List<VariantContext>, In; if ( emitReferenceConfidence() ) {; ; if (SCAC.genotypingOutputMode == GenotypingOutputMode.GENOTYPE_GIVEN_ALLELES); - throw new UserException.BadArgumentValue(""ERC/gt_mode"",""you cannot request reference confidence output and Genotyping Giving Alleles at the same time"");; + throw new UserException.BadArgumentValue(""ERC/gt_mode"",""you cannot request reference confidence output and GENOTYPE_GIVEN_ALLELES at the same time"");; ; SCAC.genotypeArgs.STANDARD_CONFIDENCE_FO",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5727#issuecomment-470679237
https://github.com/broadinstitute/gatk/issues/5727#issuecomment-470679237:2234,Modifiability,extend,extends,2234,"eCaller.java b/protected/gatk-tools-protected/src/main/java/org/broadinstitute/gatk/tools/walkers/haplotypecaller/HaplotypeCaller.java; index cf34b1fb4e..2ee5752f04 100644; --- a/protected/gatk-tools-protected/src/main/java/org/broadinstitute/gatk/tools/walkers/haplotypecaller/HaplotypeCaller.java; +++ b/protected/gatk-tools-protected/src/main/java/org/broadinstitute/gatk/tools/walkers/haplotypecaller/HaplotypeCaller.java; @@ -497,10 +497,11 @@ public class HaplotypeCaller extends ActiveRegionWalker<List<VariantContext>, In; protected boolean mergeVariantsViaLD = false;; ; @Advanced; - @Argument(fullName=""tryPhysicalPhasing"", shortName=""tryPhysicalPhasing"", doc=""If specified, we will add physical (read-based) phasing information"", required = false); - protected boolean tryPhysicalPhasing = false;; + @Argument(fullName=""doNotRunPhysicalPhasing"", shortName=""doNotRunPhysicalPhasing"", doc=""If specified, we will not try to add physical (read-based) phasing information"", required = false); + protected boolean doNotRunPhysicalPhasing = false;; ; - public static final String HAPLOTYPE_CALLER_PHASING_KEY = ""HCP"";; + public static final String HAPLOTYPE_CALLER_PHASING_ID_KEY = ""PID"";; + public static final String HAPLOTYPE_CALLER_PHASING_GT_KEY = ""PGT"";; ; // -----------------------------------------------------------------------------------------------; // arguments for debugging / developing the haplotype caller; @@ -634,12 +635,11 @@ public class HaplotypeCaller extends ActiveRegionWalker<List<VariantContext>, In; if ( emitReferenceConfidence() ) {; ; if (SCAC.genotypingOutputMode == GenotypingOutputMode.GENOTYPE_GIVEN_ALLELES); - throw new UserException.BadArgumentValue(""ERC/gt_mode"",""you cannot request reference confidence output and Genotyping Giving Alleles at the same time"");; + throw new UserException.BadArgumentValue(""ERC/gt_mode"",""you cannot request reference confidence output and GENOTYPE_GIVEN_ALLELES at the same time"");; ; SCAC.genotypeArgs.STANDARD_CONFIDENCE_FO",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5727#issuecomment-470679237
https://github.com/broadinstitute/gatk/issues/5727#issuecomment-470679237:3039,Modifiability,extend,extends,3039,"------------------------------------------------------------------------------------; // arguments for debugging / developing the haplotype caller; @@ -634,12 +635,11 @@ public class HaplotypeCaller extends ActiveRegionWalker<List<VariantContext>, In; if ( emitReferenceConfidence() ) {; ; if (SCAC.genotypingOutputMode == GenotypingOutputMode.GENOTYPE_GIVEN_ALLELES); - throw new UserException.BadArgumentValue(""ERC/gt_mode"",""you cannot request reference confidence output and Genotyping Giving Alleles at the same time"");; + throw new UserException.BadArgumentValue(""ERC/gt_mode"",""you cannot request reference confidence output and GENOTYPE_GIVEN_ALLELES at the same time"");; ; SCAC.genotypeArgs.STANDARD_CONFIDENCE_FOR_EMITTING = -0.0;; SCAC.genotypeArgs.STANDARD_CONFIDENCE_FOR_CALLING = -0.0;; ; -; // also, we don't need to output several of the annotations; annotationsToExclude.add(""ChromosomeCounts"");; annotationsToExclude.add(""FisherStrand"");; @@ -651,6 +651,9 @@ public class HaplotypeCaller extends ActiveRegionWalker<List<VariantContext>, In; if (!SCAC.annotateAllSitesWithPLs); logger.info(""All sites annotated with PLs forced to true for reference-model confidence output"");; SCAC.annotateAllSitesWithPLs = true;; + } else if ( ! doNotRunPhysicalPhasing ) {; + doNotRunPhysicalPhasing = true;; + logger.info(""Disabling physical phasing, which is supported only for reference-model confidence output"");; }; ; if ( SCAC.AFmodel == AFCalcFactory.Calculation.EXACT_GENERAL_PLOIDY ); @@ -678,7 +681,7 @@ public class HaplotypeCaller extends ActiveRegionWalker<List<VariantContext>, In; if( SCAC.genotypingOutputMode == GenotypingOutputMode.GENOTYPE_GIVEN_ALLELES && consensusMode ); throw new UserException(""HaplotypeCaller cannot be run in both GENOTYPE_GIVEN_ALLELES mode and in consensus mode. Please choose one or the other."");; ; - genotypingEngine = new HaplotypeCallerGenotypingEngine( getToolkit(), SCAC, tryPhysicalPhasing);; + genotypingEngine = new HaplotypeCallerGenotypingEngi",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5727#issuecomment-470679237
https://github.com/broadinstitute/gatk/issues/5727#issuecomment-470679237:3579,Modifiability,extend,extends,3579,"serException.BadArgumentValue(""ERC/gt_mode"",""you cannot request reference confidence output and GENOTYPE_GIVEN_ALLELES at the same time"");; ; SCAC.genotypeArgs.STANDARD_CONFIDENCE_FOR_EMITTING = -0.0;; SCAC.genotypeArgs.STANDARD_CONFIDENCE_FOR_CALLING = -0.0;; ; -; // also, we don't need to output several of the annotations; annotationsToExclude.add(""ChromosomeCounts"");; annotationsToExclude.add(""FisherStrand"");; @@ -651,6 +651,9 @@ public class HaplotypeCaller extends ActiveRegionWalker<List<VariantContext>, In; if (!SCAC.annotateAllSitesWithPLs); logger.info(""All sites annotated with PLs forced to true for reference-model confidence output"");; SCAC.annotateAllSitesWithPLs = true;; + } else if ( ! doNotRunPhysicalPhasing ) {; + doNotRunPhysicalPhasing = true;; + logger.info(""Disabling physical phasing, which is supported only for reference-model confidence output"");; }; ; if ( SCAC.AFmodel == AFCalcFactory.Calculation.EXACT_GENERAL_PLOIDY ); @@ -678,7 +681,7 @@ public class HaplotypeCaller extends ActiveRegionWalker<List<VariantContext>, In; if( SCAC.genotypingOutputMode == GenotypingOutputMode.GENOTYPE_GIVEN_ALLELES && consensusMode ); throw new UserException(""HaplotypeCaller cannot be run in both GENOTYPE_GIVEN_ALLELES mode and in consensus mode. Please choose one or the other."");; ; - genotypingEngine = new HaplotypeCallerGenotypingEngine( getToolkit(), SCAC, tryPhysicalPhasing);; + genotypingEngine = new HaplotypeCallerGenotypingEngine( getToolkit(), SCAC, !doNotRunPhysicalPhasing);; // initialize the output VCF header; final VariantAnnotatorEngine annotationEngine = new VariantAnnotatorEngine(Arrays.asList(annotationClassesToUse), annotationsToUse, annotationsToExclude, this, getToolkit());; ; @@ -699,8 +702,10 @@ public class HaplotypeCaller extends ActiveRegionWalker<List<VariantContext>, In; VCFConstants.DEPTH_KEY,; VCFConstants.GENOTYPE_PL_KEY);; ; - if ( tryPhysicalPhasing ); - headerInfo.add(new VCFFormatHeaderLine(HAPLOTYPE_CALLER_PHASING_KEY, VCFHeaderL",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5727#issuecomment-470679237
https://github.com/broadinstitute/gatk/issues/5727#issuecomment-470679237:4352,Modifiability,extend,extends,4352,"sing ) {; + doNotRunPhysicalPhasing = true;; + logger.info(""Disabling physical phasing, which is supported only for reference-model confidence output"");; }; ; if ( SCAC.AFmodel == AFCalcFactory.Calculation.EXACT_GENERAL_PLOIDY ); @@ -678,7 +681,7 @@ public class HaplotypeCaller extends ActiveRegionWalker<List<VariantContext>, In; if( SCAC.genotypingOutputMode == GenotypingOutputMode.GENOTYPE_GIVEN_ALLELES && consensusMode ); throw new UserException(""HaplotypeCaller cannot be run in both GENOTYPE_GIVEN_ALLELES mode and in consensus mode. Please choose one or the other."");; ; - genotypingEngine = new HaplotypeCallerGenotypingEngine( getToolkit(), SCAC, tryPhysicalPhasing);; + genotypingEngine = new HaplotypeCallerGenotypingEngine( getToolkit(), SCAC, !doNotRunPhysicalPhasing);; // initialize the output VCF header; final VariantAnnotatorEngine annotationEngine = new VariantAnnotatorEngine(Arrays.asList(annotationClassesToUse), annotationsToUse, annotationsToExclude, this, getToolkit());; ; @@ -699,8 +702,10 @@ public class HaplotypeCaller extends ActiveRegionWalker<List<VariantContext>, In; VCFConstants.DEPTH_KEY,; VCFConstants.GENOTYPE_PL_KEY);; ; - if ( tryPhysicalPhasing ); - headerInfo.add(new VCFFormatHeaderLine(HAPLOTYPE_CALLER_PHASING_KEY, VCFHeaderLineCount.UNBOUNDED, VCFHeaderLineType.String, ""Physical phasing information, each unique ID within a given sample (but not across samples) connects alternate alleles as occurring on the same haplotype""));; + if ( ! doNotRunPhysicalPhasing ) {; + headerInfo.add(new VCFFormatHeaderLine(HAPLOTYPE_CALLER_PHASING_ID_KEY, 1, VCFHeaderLineType.String, ""Physical phasing ID information, where each unique ID within a given sample (but not across samples) connects records within a phasing group""));; + headerInfo.add(new VCFFormatHeaderLine(HAPLOTYPE_CALLER_PHASING_GT_KEY, 1, VCFHeaderLineType.String, ""Physical phasing haplotype information, describing how the alternate alleles are phased in relation to one another""));; + }; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5727#issuecomment-470679237
https://github.com/broadinstitute/gatk/issues/5727#issuecomment-470679237:3128,Testability,log,logger,3128,"-; // arguments for debugging / developing the haplotype caller; @@ -634,12 +635,11 @@ public class HaplotypeCaller extends ActiveRegionWalker<List<VariantContext>, In; if ( emitReferenceConfidence() ) {; ; if (SCAC.genotypingOutputMode == GenotypingOutputMode.GENOTYPE_GIVEN_ALLELES); - throw new UserException.BadArgumentValue(""ERC/gt_mode"",""you cannot request reference confidence output and Genotyping Giving Alleles at the same time"");; + throw new UserException.BadArgumentValue(""ERC/gt_mode"",""you cannot request reference confidence output and GENOTYPE_GIVEN_ALLELES at the same time"");; ; SCAC.genotypeArgs.STANDARD_CONFIDENCE_FOR_EMITTING = -0.0;; SCAC.genotypeArgs.STANDARD_CONFIDENCE_FOR_CALLING = -0.0;; ; -; // also, we don't need to output several of the annotations; annotationsToExclude.add(""ChromosomeCounts"");; annotationsToExclude.add(""FisherStrand"");; @@ -651,6 +651,9 @@ public class HaplotypeCaller extends ActiveRegionWalker<List<VariantContext>, In; if (!SCAC.annotateAllSitesWithPLs); logger.info(""All sites annotated with PLs forced to true for reference-model confidence output"");; SCAC.annotateAllSitesWithPLs = true;; + } else if ( ! doNotRunPhysicalPhasing ) {; + doNotRunPhysicalPhasing = true;; + logger.info(""Disabling physical phasing, which is supported only for reference-model confidence output"");; }; ; if ( SCAC.AFmodel == AFCalcFactory.Calculation.EXACT_GENERAL_PLOIDY ); @@ -678,7 +681,7 @@ public class HaplotypeCaller extends ActiveRegionWalker<List<VariantContext>, In; if( SCAC.genotypingOutputMode == GenotypingOutputMode.GENOTYPE_GIVEN_ALLELES && consensusMode ); throw new UserException(""HaplotypeCaller cannot be run in both GENOTYPE_GIVEN_ALLELES mode and in consensus mode. Please choose one or the other."");; ; - genotypingEngine = new HaplotypeCallerGenotypingEngine( getToolkit(), SCAC, tryPhysicalPhasing);; + genotypingEngine = new HaplotypeCallerGenotypingEngine( getToolkit(), SCAC, !doNotRunPhysicalPhasing);; // initialize the output VCF hea",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5727#issuecomment-470679237
https://github.com/broadinstitute/gatk/issues/5727#issuecomment-470679237:3347,Testability,log,logger,3347,"mitReferenceConfidence() ) {; ; if (SCAC.genotypingOutputMode == GenotypingOutputMode.GENOTYPE_GIVEN_ALLELES); - throw new UserException.BadArgumentValue(""ERC/gt_mode"",""you cannot request reference confidence output and Genotyping Giving Alleles at the same time"");; + throw new UserException.BadArgumentValue(""ERC/gt_mode"",""you cannot request reference confidence output and GENOTYPE_GIVEN_ALLELES at the same time"");; ; SCAC.genotypeArgs.STANDARD_CONFIDENCE_FOR_EMITTING = -0.0;; SCAC.genotypeArgs.STANDARD_CONFIDENCE_FOR_CALLING = -0.0;; ; -; // also, we don't need to output several of the annotations; annotationsToExclude.add(""ChromosomeCounts"");; annotationsToExclude.add(""FisherStrand"");; @@ -651,6 +651,9 @@ public class HaplotypeCaller extends ActiveRegionWalker<List<VariantContext>, In; if (!SCAC.annotateAllSitesWithPLs); logger.info(""All sites annotated with PLs forced to true for reference-model confidence output"");; SCAC.annotateAllSitesWithPLs = true;; + } else if ( ! doNotRunPhysicalPhasing ) {; + doNotRunPhysicalPhasing = true;; + logger.info(""Disabling physical phasing, which is supported only for reference-model confidence output"");; }; ; if ( SCAC.AFmodel == AFCalcFactory.Calculation.EXACT_GENERAL_PLOIDY ); @@ -678,7 +681,7 @@ public class HaplotypeCaller extends ActiveRegionWalker<List<VariantContext>, In; if( SCAC.genotypingOutputMode == GenotypingOutputMode.GENOTYPE_GIVEN_ALLELES && consensusMode ); throw new UserException(""HaplotypeCaller cannot be run in both GENOTYPE_GIVEN_ALLELES mode and in consensus mode. Please choose one or the other."");; ; - genotypingEngine = new HaplotypeCallerGenotypingEngine( getToolkit(), SCAC, tryPhysicalPhasing);; + genotypingEngine = new HaplotypeCallerGenotypingEngine( getToolkit(), SCAC, !doNotRunPhysicalPhasing);; // initialize the output VCF header; final VariantAnnotatorEngine annotationEngine = new VariantAnnotatorEngine(Arrays.asList(annotationClassesToUse), annotationsToUse, annotationsToExclude, this, getToolki",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5727#issuecomment-470679237
https://github.com/broadinstitute/gatk/issues/5727#issuecomment-470680198:222,Testability,test,tests,222,"Thanks @droazen, I suspected that was the case from looking at the history. Though it's not clear to me from @eitanbanks' commit why he would disable it for non-ERC modes. FWIW my PR looks to have only failed where the HC tests are comparing against existing files, and the existing files don't have phasing (whereas newly generated test files do). I'm going through and double-checking that that is the case, and will hopefully amend that PR shortly.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5727#issuecomment-470680198
https://github.com/broadinstitute/gatk/issues/5727#issuecomment-470680198:333,Testability,test,test,333,"Thanks @droazen, I suspected that was the case from looking at the history. Though it's not clear to me from @eitanbanks' commit why he would disable it for non-ERC modes. FWIW my PR looks to have only failed where the HC tests are comparing against existing files, and the existing files don't have phasing (whereas newly generated test files do). I'm going through and double-checking that that is the case, and will hopefully amend that PR shortly.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5727#issuecomment-470680198
https://github.com/broadinstitute/gatk/issues/5727#issuecomment-470680198:92,Usability,clear,clear,92,"Thanks @droazen, I suspected that was the case from looking at the history. Though it's not clear to me from @eitanbanks' commit why he would disable it for non-ERC modes. FWIW my PR looks to have only failed where the HC tests are comparing against existing files, and the existing files don't have phasing (whereas newly generated test files do). I'm going through and double-checking that that is the case, and will hopefully amend that PR shortly.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5727#issuecomment-470680198
https://github.com/broadinstitute/gatk/issues/5727#issuecomment-470950825:134,Availability,error,error,134,I'm confused. Nowhere in the commit above did I disable physical phasing for non-ERC modes. The only line I touched was to change the error message to use the proper argument (GENOTYPE_GIVEN_ALLELES vs. Genotyping Giving Alleles). I have zero recollection of why physical phasing wouldn't be okay for standard HaplotypeCaller.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5727#issuecomment-470950825
https://github.com/broadinstitute/gatk/issues/5727#issuecomment-470950825:140,Integrability,message,message,140,I'm confused. Nowhere in the commit above did I disable physical phasing for non-ERC modes. The only line I touched was to change the error message to use the proper argument (GENOTYPE_GIVEN_ALLELES vs. Genotyping Giving Alleles). I have zero recollection of why physical phasing wouldn't be okay for standard HaplotypeCaller.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5727#issuecomment-470950825
https://github.com/broadinstitute/gatk/issues/5727#issuecomment-470951687:72,Testability,test,tested,72,"Oh, I see now. It was probably a bug back then?; Or maybe it was all we tested with ATGU so didn't want to support it for other cases without more testing (and then I got distracted). Way too long ago...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5727#issuecomment-470951687
https://github.com/broadinstitute/gatk/issues/5727#issuecomment-470951687:147,Testability,test,testing,147,"Oh, I see now. It was probably a bug back then?; Or maybe it was all we tested with ATGU so didn't want to support it for other cases without more testing (and then I got distracted). Way too long ago...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5727#issuecomment-470951687
https://github.com/broadinstitute/gatk/issues/5727#issuecomment-471038038:832,Deployability,update,updated,832,"@droazen @ldgauthier @eitanbanks @tfenne the issue with `GenotypeGvcfs` outputting the wrong phase will still exist, even if @tfenne makes the change to `HaplotypeCaller` (@tfenne: could you move further discussion of that fix to https://github.com/broadinstitute/gatk/pull/5772). While the above example is fairly simple to understand, since `GenotypeGvcfs` run on a single sample will simply re-capitulate the genotype from the gVCF. In this case, could we just compare the `PGT` field and the `GT` field to ensure they agree, and if they don't, swap the alleles in the `GT` field (for hets only)? . This brings up an other issue: what happens with multiple samples? If the genotype is changed for a sample, how is phasing information affected (in the PGT/PID fields too)? I couldn't find a place where the phasing information is updated when re-genotyping (`PGT/PID` are fixed). I think this is beyond my ability to fix and determine (i.e. understanding how the `GenotypingEngine` works), but unfortunately, this is still a bug. Presumably the `PGT/PID` fields are correct, as they have been used in large call-sets (ex. Exac/Gnomad) without any bug reports, so is there a simple workaround like the above single-sample case?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5727#issuecomment-471038038
https://github.com/broadinstitute/gatk/issues/5727#issuecomment-471038038:315,Usability,simpl,simple,315,"@droazen @ldgauthier @eitanbanks @tfenne the issue with `GenotypeGvcfs` outputting the wrong phase will still exist, even if @tfenne makes the change to `HaplotypeCaller` (@tfenne: could you move further discussion of that fix to https://github.com/broadinstitute/gatk/pull/5772). While the above example is fairly simple to understand, since `GenotypeGvcfs` run on a single sample will simply re-capitulate the genotype from the gVCF. In this case, could we just compare the `PGT` field and the `GT` field to ensure they agree, and if they don't, swap the alleles in the `GT` field (for hets only)? . This brings up an other issue: what happens with multiple samples? If the genotype is changed for a sample, how is phasing information affected (in the PGT/PID fields too)? I couldn't find a place where the phasing information is updated when re-genotyping (`PGT/PID` are fixed). I think this is beyond my ability to fix and determine (i.e. understanding how the `GenotypingEngine` works), but unfortunately, this is still a bug. Presumably the `PGT/PID` fields are correct, as they have been used in large call-sets (ex. Exac/Gnomad) without any bug reports, so is there a simple workaround like the above single-sample case?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5727#issuecomment-471038038
https://github.com/broadinstitute/gatk/issues/5727#issuecomment-471038038:387,Usability,simpl,simply,387,"@droazen @ldgauthier @eitanbanks @tfenne the issue with `GenotypeGvcfs` outputting the wrong phase will still exist, even if @tfenne makes the change to `HaplotypeCaller` (@tfenne: could you move further discussion of that fix to https://github.com/broadinstitute/gatk/pull/5772). While the above example is fairly simple to understand, since `GenotypeGvcfs` run on a single sample will simply re-capitulate the genotype from the gVCF. In this case, could we just compare the `PGT` field and the `GT` field to ensure they agree, and if they don't, swap the alleles in the `GT` field (for hets only)? . This brings up an other issue: what happens with multiple samples? If the genotype is changed for a sample, how is phasing information affected (in the PGT/PID fields too)? I couldn't find a place where the phasing information is updated when re-genotyping (`PGT/PID` are fixed). I think this is beyond my ability to fix and determine (i.e. understanding how the `GenotypingEngine` works), but unfortunately, this is still a bug. Presumably the `PGT/PID` fields are correct, as they have been used in large call-sets (ex. Exac/Gnomad) without any bug reports, so is there a simple workaround like the above single-sample case?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5727#issuecomment-471038038
https://github.com/broadinstitute/gatk/issues/5727#issuecomment-471038038:1176,Usability,simpl,simple,1176,"@droazen @ldgauthier @eitanbanks @tfenne the issue with `GenotypeGvcfs` outputting the wrong phase will still exist, even if @tfenne makes the change to `HaplotypeCaller` (@tfenne: could you move further discussion of that fix to https://github.com/broadinstitute/gatk/pull/5772). While the above example is fairly simple to understand, since `GenotypeGvcfs` run on a single sample will simply re-capitulate the genotype from the gVCF. In this case, could we just compare the `PGT` field and the `GT` field to ensure they agree, and if they don't, swap the alleles in the `GT` field (for hets only)? . This brings up an other issue: what happens with multiple samples? If the genotype is changed for a sample, how is phasing information affected (in the PGT/PID fields too)? I couldn't find a place where the phasing information is updated when re-genotyping (`PGT/PID` are fixed). I think this is beyond my ability to fix and determine (i.e. understanding how the `GenotypingEngine` works), but unfortunately, this is still a bug. Presumably the `PGT/PID` fields are correct, as they have been used in large call-sets (ex. Exac/Gnomad) without any bug reports, so is there a simple workaround like the above single-sample case?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5727#issuecomment-471038038
https://github.com/broadinstitute/gatk/issues/5727#issuecomment-1781017195:15606,Availability,down,down,15606,":55910600 0.9 186370 213817.0; 13:40:55.466 INFO HaplotypeCaller - 0 read(s) filtered by: MappingQualityReadFilter; 0 read(s) filtered by: MappingQualityAvailableReadFilter; 0 read(s) filtered by: MappedReadFilter; 0 read(s) filtered by: NotSecondaryAlignmentReadFilter; 0 read(s) filtered by: NotDuplicateReadFilter; 0 read(s) filtered by: PassesVendorQualityCheckReadFilter; 0 read(s) filtered by: NonZeroReferenceLengthAlignmentReadFilter; 0 read(s) filtered by: GoodCigarReadFilter; 0 read(s) filtered by: WellformedReadFilter; 0 total reads filtered out of 18 reads processed; 13:40:55.466 INFO ProgressMeter - chr19:61430410 1.0 204773 210541.8; 13:40:55.467 INFO ProgressMeter - Traversal complete. Processed 204773 total regions in 1.0 minutes.; 13:40:55.707 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 0.096771218; 13:40:55.708 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 0.04 sec; 13:40:55.709 INFO HaplotypeCaller - Shutting down engine; [October 26, 2023 at 1:40:55 PM CEST] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 0.99 minutes.; Runtime.totalMemory()=2617245696; ```. ```; ##source=HaplotypeCaller; ##bcftools_viewVersion=1.16+htslib-1.16; ##bcftools_viewCommand=view -c1 output.g.vcf; Date=Thu Oct 26 13:40:56 2023; ##bcftools_annotateVersion=1.16+htslib-1.16; ##bcftools_annotateCommand=annotate -x INFO,FORMAT/SB,FORMAT/PL; Date=Thu Oct 26 13:40:56 2023; #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT CGAAGAGGTAGGTGCGAG-1; chr19 55910646 . AC A,<NON_REF> 352.6 . . GT:AD:DP:GQ:PGT:PID:PS 0|1:6,9,0:15:99:0|1:55910646_AC_A:55910646; chr19 55910648 . AAATCCCCC A,<NON_REF> 352.6 . . GT:AD:DP:GQ:PGT:PID:PS 0|1:6,9,0:15:99:0|1:55910646_AC_A:55910646; chr19 55910653 . CCCCAT *,C,<NON_REF> 227.84 . . GT:AD:DP:GQ:PGT:PID:PS 2|1:0,9,6,0:15:99:1|0:55910646_AC_A:55910646; chr19 55910675 . T C,<NON_REF> 30.64 . . GT:AD:DP:GQ 0/1:13,2,0:15:38; ```. ```; Using GATK jar /omics/group",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5727#issuecomment-1781017195
https://github.com/broadinstitute/gatk/issues/5727#issuecomment-1781017195:19853,Availability,down,down,19853,"lizing engine; 13:40:59.909 INFO FeatureManager - Using codec VCFCodec to read file file:///omics/groups/OE0540/internal/users/gleixner/cropseq_uli/rep_ex/test3/output.g.vcf; 13:40:59.951 INFO GenotypeGVCFs - Done initializing engine; 13:41:00.006 INFO ProgressMeter - Starting traversal; 13:41:00.007 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 13:41:00.406 WARN ReferenceConfidenceVariantContextMerger - Detected invalid annotations: When trying to merge variant contexts at location chr19:55910646 the annotation MLEAC=[1, 0] was not a numerical value and was ignored; 13:41:00.476 WARN InbreedingCoeff - InbreedingCoeff will not be calculated at position chr19:55910646 and possibly subsequent; at least 10 samples must have called genotypes; 13:41:00.528 INFO ProgressMeter - unmapped 0.0 37 4277.5; 13:41:00.528 INFO ProgressMeter - Traversal complete. Processed 37 total variants in 0.0 minutes.; 13:41:00.580 INFO GenotypeGVCFs - Shutting down engine; [October 26, 2023 at 1:41:00 PM CEST] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=285212672; ```; ```; ##source=HaplotypeCaller; ##bcftools_viewVersion=1.16+htslib-1.16; ##bcftools_viewCommand=view -c1 output.vcf; Date=Thu Oct 26 13:41:08 2023; ##bcftools_annotateVersion=1.16+htslib-1.16; ##bcftools_annotateCommand=annotate -x INFO,FORMAT/SB,FORMAT/PL; Date=Thu Oct 26 13:41:08 2023; #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT CGAAGAGGTAGGTGCGAG-1; chr19 55910646 . AC A 352.6 . . GT:AD:DP:GQ:PGT:PID:PS 0|1:6,9:15:99:0|1:55910646_AC_A:55910646; chr19 55910648 . AAATCCCCC A 352.6 . . GT:AD:DP:GQ:PGT:PID:PS 0|1:6,9:15:99:0|1:55910646_AC_A:55910646; chr19 55910653 . CCCCAT *,C 227.84 . . GT:AD:DP:GQ:PGT:PID:PS 1|2:0,9,6:15:99:1|0:55910646_AC_A:55910646; chr19 55910675 . T C 30.64 . . GT:AD:DP:GQ 0/1:13,2:15:38; ```. The relevant parts of the output. HaplotypeCaller:; ```; chr19 55910648 AAATCCCCC A,<NON_REF> GT:AD:DP",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5727#issuecomment-1781017195
https://github.com/broadinstitute/gatk/issues/5727#issuecomment-1781017195:21567,Integrability,depend,depend,21567,"uent; at least 10 samples must have called genotypes; 13:41:00.528 INFO ProgressMeter - unmapped 0.0 37 4277.5; 13:41:00.528 INFO ProgressMeter - Traversal complete. Processed 37 total variants in 0.0 minutes.; 13:41:00.580 INFO GenotypeGVCFs - Shutting down engine; [October 26, 2023 at 1:41:00 PM CEST] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=285212672; ```; ```; ##source=HaplotypeCaller; ##bcftools_viewVersion=1.16+htslib-1.16; ##bcftools_viewCommand=view -c1 output.vcf; Date=Thu Oct 26 13:41:08 2023; ##bcftools_annotateVersion=1.16+htslib-1.16; ##bcftools_annotateCommand=annotate -x INFO,FORMAT/SB,FORMAT/PL; Date=Thu Oct 26 13:41:08 2023; #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT CGAAGAGGTAGGTGCGAG-1; chr19 55910646 . AC A 352.6 . . GT:AD:DP:GQ:PGT:PID:PS 0|1:6,9:15:99:0|1:55910646_AC_A:55910646; chr19 55910648 . AAATCCCCC A 352.6 . . GT:AD:DP:GQ:PGT:PID:PS 0|1:6,9:15:99:0|1:55910646_AC_A:55910646; chr19 55910653 . CCCCAT *,C 227.84 . . GT:AD:DP:GQ:PGT:PID:PS 1|2:0,9,6:15:99:1|0:55910646_AC_A:55910646; chr19 55910675 . T C 30.64 . . GT:AD:DP:GQ 0/1:13,2:15:38; ```. The relevant parts of the output. HaplotypeCaller:; ```; chr19 55910648 AAATCCCCC A,<NON_REF> GT:AD:DP:GQ:PGT:PID:PS 0|1:6,9,0 :15:99:0|1:55910646_AC_A:55910646; chr19 55910653 CCCCAT *,C,<NON_REF> GT:AD:DP:GQ:PGT:PID:PS 2|1:0,9,6,0:15:99:1|0:55910646_AC_A:55910646; ```; GenotypeGVCFs:; ```; chr19 55910648 AAATCCCCC A GT:AD:DP:GQ:PGT:PID:PS 0|1:6,9 :15:99:0|1:55910646_AC_A:55910646; chr19 55910653 CCCCAT *,C GT:AD:DP:GQ:PGT:PID:PS 1|2:0,9,6 :15:99:1|0:55910646_AC_A:55910646; ```. I understand that; - PID/PGT can only encode phasing for biallelic variants, ; - so PID/PGT + unphased GT can not be used to infer the correctly phased GT in general; - but only (and only maybe) in this case PID/PGT + wrongly phased GT can be used to infer the correctly phased GT (because the mangeling of the GT might depend on PGT). is this correct?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5727#issuecomment-1781017195
https://github.com/broadinstitute/gatk/issues/5727#issuecomment-1781017195:11059,Performance,Load,Loading,11059,"1	NM:i:7	MQ:i:60	AS:i:105	XS:i:20; EOF. bind 'set disable-completion off'. samtools view reads.sam -b > reads.bam; samtools index reads.bam. gatk HaplotypeCaller -R chr19.fa -I reads.bam -O output.g.vcf -ERC GVCF ; bcftools view output.g.vcf -c1 | bcftools annotate -x INFO,FORMAT/SB,FORMAT/PL | tail ; gatk GenotypeGVCFs -R chr19.fa -V output.g.vcf -O output.vcf ; bcftools view output.vcf -c1 | bcftools annotate -x INFO,FORMAT/SB,FORMAT/PL | tail. ```. output:; ```; Using GATK jar /omics/groups/OE0540/internal/software/jvm/gatk/4.4.0.0/gatk-package-4.4.0.0-local.jar Running: java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /omics/groups/OE0540/internal/software/jvm/gatk/4.4.0.0/gatk-package-4.4.0.0-local.jar HaplotypeCaller -R chr19.fa -I reads.bam -O output.g.vcf -ERC GVCF Picked up JAVA_TOOL_OPTIONS: -Djava.net.useSystemProxies=true 13:39:56.569 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/omics/groups/OE0540/internal/software/jvm/gatk/4.4.0.0/gatk-package-4.4.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so 13:39:56.647 INFO HaplotypeCaller - ------------------------------------------------------------ 13:39:56.660 INFO HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.4.0.0 13:39:56.666 INFO HaplotypeCaller - For support and documentation go to https://software.broadinstitute.org/gatk/ 13:39:56.666 INFO HaplotypeCaller - Executing as gleixner@odcf-worker02 on Linux v3.10.0-1160.76.1.el7.x86_64 amd64 13:39:56.666 INFO HaplotypeCaller - Java runtime: OpenJDK 64-Bit Server VM v17+35-2724 13:39:56.667 INFO HaplotypeCaller - Start Date/Time: October 26, 2023 at 1:39:56 PM CEST 13:39:56.667 INFO HaplotypeCaller - ------------------------------------------------------------ 13:39:56.667 INFO HaplotypeCaller - ------------------------------------------------------------ 13:39:56.669 INFO HaplotypeCaller - HTSJDK Ver",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5727#issuecomment-1781017195
https://github.com/broadinstitute/gatk/issues/5727#issuecomment-1781017195:13505,Performance,Load,Loading,13505,"s.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false 13:39:56.672 INFO HaplotypeCaller - Deflater: IntelDeflater 13:39:56.673 INFO HaplotypeCaller - Inflater: IntelInflater 13:39:56.674 INFO HaplotypeCaller - GCS max retries/reopens: 20 13:39:56.679 INFO HaplotypeCaller - Requester pays: disabled 13:39:56.680 INFO HaplotypeCaller - Initializing engine 13:39:56.968 INFO HaplotypeCaller - Done initializing engine 13:39:56.971 INFO HaplotypeCallerEngine - Tool is in reference confidence mode and the annotation, the following changes will be made to any specified annotations: 'StrandBiasBySample' will be enabled. 'ChromosomeCounts', 'FisherStrand', 'StrandOddsRatio' and 'QualByDepth' annotations have been disabled 13:39:57.000 INFO HaplotypeCallerEngine - Standard Emitting and Calling confidence set to -0.0 for reference-model confidence output 13:39:57.000 INFO HaplotypeCallerEngine - All sites annotated with PLs forced to true for reference-model confidence output 13:39:57.020 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/omics/groups/OE0540/internal/software/jvm/gatk/4.4.0.0/gatk-package-4.4.0.0-local.jar!/com/intel/gkl/native/libgkl_utils.so 13:39:57.026 INFO PairHMM - OpenMP multi-threaded AVX-accelerated native PairHMM implementation is not supported 13:39:57.026 WARN PairHMM - ***WARNING: Machine does not have the AVX instruction set support needed for the accelerated AVX PairHmm. Falling back to the MUCH slower LOGLESS_CACHING implementation! 13:39:57.108 INFO ProgressMeter - Starting traversal 13:39:57.110 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute 13:40:07.119 INFO ProgressMeter - chr19:8969701 0.2 29900 179382.1 13:40:17.116 INFO ProgressMeter - chr19:20264701 0.3 67550 202609.5 13:40:27.115 INFO ProgressMeter - chr19:31874701 0.5 106250 212471.7 13:40:37.116 INFO ProgressMeter - chr19:44792701 0.7 149310 223937.0 13:40:49.251 WARN InbreedingCoeff - InbreedingCoeff will not be calculated at position chr19:55910",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5727#issuecomment-1781017195
https://github.com/broadinstitute/gatk/issues/5727#issuecomment-1781017195:13703,Performance,multi-thread,multi-threaded,13703,".679 INFO HaplotypeCaller - Requester pays: disabled 13:39:56.680 INFO HaplotypeCaller - Initializing engine 13:39:56.968 INFO HaplotypeCaller - Done initializing engine 13:39:56.971 INFO HaplotypeCallerEngine - Tool is in reference confidence mode and the annotation, the following changes will be made to any specified annotations: 'StrandBiasBySample' will be enabled. 'ChromosomeCounts', 'FisherStrand', 'StrandOddsRatio' and 'QualByDepth' annotations have been disabled 13:39:57.000 INFO HaplotypeCallerEngine - Standard Emitting and Calling confidence set to -0.0 for reference-model confidence output 13:39:57.000 INFO HaplotypeCallerEngine - All sites annotated with PLs forced to true for reference-model confidence output 13:39:57.020 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/omics/groups/OE0540/internal/software/jvm/gatk/4.4.0.0/gatk-package-4.4.0.0-local.jar!/com/intel/gkl/native/libgkl_utils.so 13:39:57.026 INFO PairHMM - OpenMP multi-threaded AVX-accelerated native PairHMM implementation is not supported 13:39:57.026 WARN PairHMM - ***WARNING: Machine does not have the AVX instruction set support needed for the accelerated AVX PairHmm. Falling back to the MUCH slower LOGLESS_CACHING implementation! 13:39:57.108 INFO ProgressMeter - Starting traversal 13:39:57.110 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute 13:40:07.119 INFO ProgressMeter - chr19:8969701 0.2 29900 179382.1 13:40:17.116 INFO ProgressMeter - chr19:20264701 0.3 67550 202609.5 13:40:27.115 INFO ProgressMeter - chr19:31874701 0.5 106250 212471.7 13:40:37.116 INFO ProgressMeter - chr19:44792701 0.7 149310 223937.0 13:40:49.251 WARN InbreedingCoeff - InbreedingCoeff will not be calculated at position chr19:55910646 and possibly subsequent; at least 10 samples must have called genotypes 13:40:49.413 INFO ProgressMeter - chr19:55910600 0.9 186370 213817.0; 13:40:55.466 INFO HaplotypeCaller - 0 read(s) filtered by: MappingQualityReadFilter; 0 r",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5727#issuecomment-1781017195
https://github.com/broadinstitute/gatk/issues/5727#issuecomment-1781017195:17114,Performance,Load,Loading,17114,"EF ALT QUAL FILTER INFO FORMAT CGAAGAGGTAGGTGCGAG-1; chr19 55910646 . AC A,<NON_REF> 352.6 . . GT:AD:DP:GQ:PGT:PID:PS 0|1:6,9,0:15:99:0|1:55910646_AC_A:55910646; chr19 55910648 . AAATCCCCC A,<NON_REF> 352.6 . . GT:AD:DP:GQ:PGT:PID:PS 0|1:6,9,0:15:99:0|1:55910646_AC_A:55910646; chr19 55910653 . CCCCAT *,C,<NON_REF> 227.84 . . GT:AD:DP:GQ:PGT:PID:PS 2|1:0,9,6,0:15:99:1|0:55910646_AC_A:55910646; chr19 55910675 . T C,<NON_REF> 30.64 . . GT:AD:DP:GQ 0/1:13,2,0:15:38; ```. ```; Using GATK jar /omics/groups/OE0540/internal/software/jvm/gatk/4.4.0.0/gatk-package-4.4.0.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /omics/groups/OE0540/internal/software/jvm/gatk/4.4.0.0/gatk-package-4.4.0.0-local.jar GenotypeGVCFs -R chr19.fa -V output.g.vcf -O output.vcf; Picked up JAVA_TOOL_OPTIONS: -Djava.net.useSystemProxies=true; 13:40:59.573 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/omics/groups/OE0540/internal/software/jvm/gatk/4.4.0.0/gatk-package-4.4.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 13:40:59.636 INFO GenotypeGVCFs - ------------------------------------------------------------; 13:40:59.653 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.4.0.0; 13:40:59.653 INFO GenotypeGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 13:40:59.654 INFO GenotypeGVCFs - Executing as gleixner@odcf-worker02 on Linux v3.10.0-1160.76.1.el7.x86_64 amd64; 13:40:59.654 INFO GenotypeGVCFs - Java runtime: OpenJDK 64-Bit Server VM v17+35-2724; 13:40:59.655 INFO GenotypeGVCFs - Start Date/Time: October 26, 2023 at 1:40:59 PM CEST; 13:40:59.655 INFO GenotypeGVCFs - ------------------------------------------------------------; 13:40:59.655 INFO GenotypeGVCFs - ------------------------------------------------------------; 13:40:59.658 INFO GenotypeGVCFs - HTSJDK Version: 3.0",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5727#issuecomment-1781017195
https://github.com/broadinstitute/gatk/issues/5727#issuecomment-1781017195:19312,Safety,Detect,Detected,19312,"_READ_FOR_SAMTOOLS : false; 13:40:59.660 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 13:40:59.661 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 13:40:59.661 INFO GenotypeGVCFs - Deflater: IntelDeflater; 13:40:59.661 INFO GenotypeGVCFs - Inflater: IntelInflater; 13:40:59.661 INFO GenotypeGVCFs - GCS max retries/reopens: 20; 13:40:59.662 INFO GenotypeGVCFs - Requester pays: disabled; 13:40:59.663 INFO GenotypeGVCFs - Initializing engine; 13:40:59.909 INFO FeatureManager - Using codec VCFCodec to read file file:///omics/groups/OE0540/internal/users/gleixner/cropseq_uli/rep_ex/test3/output.g.vcf; 13:40:59.951 INFO GenotypeGVCFs - Done initializing engine; 13:41:00.006 INFO ProgressMeter - Starting traversal; 13:41:00.007 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 13:41:00.406 WARN ReferenceConfidenceVariantContextMerger - Detected invalid annotations: When trying to merge variant contexts at location chr19:55910646 the annotation MLEAC=[1, 0] was not a numerical value and was ignored; 13:41:00.476 WARN InbreedingCoeff - InbreedingCoeff will not be calculated at position chr19:55910646 and possibly subsequent; at least 10 samples must have called genotypes; 13:41:00.528 INFO ProgressMeter - unmapped 0.0 37 4277.5; 13:41:00.528 INFO ProgressMeter - Traversal complete. Processed 37 total variants in 0.0 minutes.; 13:41:00.580 INFO GenotypeGVCFs - Shutting down engine; [October 26, 2023 at 1:41:00 PM CEST] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=285212672; ```; ```; ##source=HaplotypeCaller; ##bcftools_viewVersion=1.16+htslib-1.16; ##bcftools_viewCommand=view -c1 output.vcf; Date=Thu Oct 26 13:41:08 2023; ##bcftools_annotateVersion=1.16+htslib-1.16; ##bcftools_annotateCommand=annotate -x INFO,FORMAT/SB,FORMAT/PL; Date=Thu Oct 26 13:41:08 2023; #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT CGAAG",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5727#issuecomment-1781017195
https://github.com/broadinstitute/gatk/pull/5728#issuecomment-467660715:3055,Security,validat,validation,3055,XZh) | `60.57% <100%> (ø)` | `65 <0> (ø)` | :arrow_down: |; | [...nder/tools/walkers/vqsr/FilterVariantTranches.java](https://codecov.io/gh/broadinstitute/gatk/pull/5728/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3Zxc3IvRmlsdGVyVmFyaWFudFRyYW5jaGVzLmphdmE=) | `92.241% <100%> (ø)` | `42 <0> (ø)` | :arrow_down: |; | [...ellbender/tools/funcotator/FilterFuncotations.java](https://codecov.io/gh/broadinstitute/gatk/pull/5728/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0ZpbHRlckZ1bmNvdGF0aW9ucy5qYXZh) | `93.103% <100%> (ø)` | `18 <0> (ø)` | :arrow_down: |; | [...itute/hellbender/tools/walkers/vqsr/ApplyVQSR.java](https://codecov.io/gh/broadinstitute/gatk/pull/5728/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3Zxc3IvQXBwbHlWUVNSLmphdmE=) | `75% <100%> (ø)` | `55 <0> (ø)` | :arrow_down: |; | [...r/tools/walkers/validation/RemoveNearbyIndels.java](https://codecov.io/gh/broadinstitute/gatk/pull/5728/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vUmVtb3ZlTmVhcmJ5SW5kZWxzLmphdmE=) | `90.476% <100%> (ø)` | `5 <0> (ø)` | :arrow_down: |; | [...dinstitute/hellbender/engine/GATKToolUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5728/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvR0FUS1Rvb2xVbml0VGVzdC5qYXZh) | `91.017% <100%> (ø)` | `71 <0> (ø)` | :arrow_down: |; | [...idation/AnnotateVcfWithExpectedAlleleFraction.java](https://codecov.io/gh/broadinstitute/gatk/pull/5728/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhbGlkYXRpb24vQW5ub3RhdGVWY2ZXaXRoRXhwZWN0ZWRBbGxlbGVGcmFjdGlvbi5qYXZh) | `96.429% <100%> (ø)` | `7 <0> (ø)` | :arrow_down: |; | ... and [23 more](https://codecov.io/gh/broadinstitute/gatk/pull/5728/diff?src=pr&,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5728#issuecomment-467660715
https://github.com/broadinstitute/gatk/issues/5730#issuecomment-469686524:259,Energy Efficiency,monitor,monitor,259,"Hmm, not able to reproduce this locally with master after many experiments. Here are the two original FC runs that gave different results, for reference:. https://portal.firecloud.org/#workspaces/broad-firecloud-dsde/GATK_Germline_CNV_Validation_SFARI_WES_v1/monitor/697a23c3-744e-4cd1-af2e-4773783106d2; https://portal.firecloud.org/#workspaces/broad-firecloud-dsde/GATK_Germline_CNV_Validation_SFARI_WES_v1/monitor/52625b86-7cf0-4144-ad44-1f7c60431b42. Don't see any PRs that would've affected this, but I'll double check. Another culprit might be OpenMP CPU parallelism.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5730#issuecomment-469686524
https://github.com/broadinstitute/gatk/issues/5730#issuecomment-469686524:409,Energy Efficiency,monitor,monitor,409,"Hmm, not able to reproduce this locally with master after many experiments. Here are the two original FC runs that gave different results, for reference:. https://portal.firecloud.org/#workspaces/broad-firecloud-dsde/GATK_Germline_CNV_Validation_SFARI_WES_v1/monitor/697a23c3-744e-4cd1-af2e-4773783106d2; https://portal.firecloud.org/#workspaces/broad-firecloud-dsde/GATK_Germline_CNV_Validation_SFARI_WES_v1/monitor/52625b86-7cf0-4144-ad44-1f7c60431b42. Don't see any PRs that would've affected this, but I'll double check. Another culprit might be OpenMP CPU parallelism.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5730#issuecomment-469686524
https://github.com/broadinstitute/gatk/pull/5732#issuecomment-467976599:405,Availability,avail,available,405,"@vdauwera note that this modifies the path of the CNV methods doc (which is mostly out of date, but is still linked to in some Comms materials) from docs/CNVs/CNV-methods.pdf to docs/CNV/archived/archived-CNV-methods.pdf. The extended abstract on gCNV is a very technical description of the probabilistic model, but it might be worth referencing it for interested users until a preprint or publication is available.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5732#issuecomment-467976599
https://github.com/broadinstitute/gatk/pull/5732#issuecomment-467976599:226,Modifiability,extend,extended,226,"@vdauwera note that this modifies the path of the CNV methods doc (which is mostly out of date, but is still linked to in some Comms materials) from docs/CNVs/CNV-methods.pdf to docs/CNV/archived/archived-CNV-methods.pdf. The extended abstract on gCNV is a very technical description of the probabilistic model, but it might be worth referencing it for interested users until a preprint or publication is available.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5732#issuecomment-467976599
https://github.com/broadinstitute/gatk/pull/5732#issuecomment-470293496:3800,Availability,down,downsampling,3800, :arrow_down: |; | [...copynumber/utils/segmentation/KernelSegmenter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5732/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL3V0aWxzL3NlZ21lbnRhdGlvbi9LZXJuZWxTZWdtZW50ZXIuamF2YQ==) | `95.671% <ø> (-2.164%)` | `45 <0> (-3)` | |; | [...s/copynumber/models/AlleleFractionLikelihoods.java](https://codecov.io/gh/broadinstitute/gatk/pull/5732/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL21vZGVscy9BbGxlbGVGcmFjdGlvbkxpa2VsaWhvb2RzLmphdmE=) | `97.826% <ø> (ø)` | `11 <0> (ø)` | :arrow_down: |; | [...ools/copynumber/models/AlleleFractionModeller.java](https://codecov.io/gh/broadinstitute/gatk/pull/5732/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL21vZGVscy9BbGxlbGVGcmFjdGlvbk1vZGVsbGVyLmphdmE=) | `88.406% <ø> (-5.797%)` | `14 <0> (-4)` | |; | [...ls/variant/writers/GVCFBlockCombiningIterator.java](https://codecov.io/gh/broadinstitute/gatk/pull/5732/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L3dyaXRlcnMvR1ZDRkJsb2NrQ29tYmluaW5nSXRlcmF0b3IuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-1%)` | |; | [...ls/walkers/genotyper/HeterogeneousPloidyModel.java](https://codecov.io/gh/broadinstitute/gatk/pull/5732/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9IZXRlcm9nZW5lb3VzUGxvaWR5TW9kZWwuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-14%)` | |; | [...nder/utils/downsampling/FractionalDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/5732/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvRnJhY3Rpb25hbERvd25zYW1wbGVyLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-17%)` | |; | ... and [1353 more](https://codecov.io/gh/broadinstitute/gatk/pull/5732/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5732#issuecomment-470293496
https://github.com/broadinstitute/gatk/pull/5732#issuecomment-470293496:1595,Performance,optimiz,optimization,1595,+32 ; Lines 146768 147415 +647 ; Branches 16223 16225 +2 ; ================================================; - Hits 127666 55100 -72566 ; - Misses 13189 87388 +74199 ; + Partials 5913 4927 -986; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5732?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...s/copynumber/models/AlleleFractionInitializer.java](https://codecov.io/gh/broadinstitute/gatk/pull/5732/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL21vZGVscy9BbGxlbGVGcmFjdGlvbkluaXRpYWxpemVyLmphdmE=) | `89.063% <ø> (ø)` | `17 <0> (ø)` | :arrow_down: |; | [...r/tools/copynumber/models/AlleleFractionState.java](https://codecov.io/gh/broadinstitute/gatk/pull/5732/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL21vZGVscy9BbGxlbGVGcmFjdGlvblN0YXRlLmphdmE=) | `100% <ø> (ø)` | `7 <0> (ø)` | :arrow_down: |; | [...umber/utils/optimization/PersistenceOptimizer.java](https://codecov.io/gh/broadinstitute/gatk/pull/5732/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL3V0aWxzL29wdGltaXphdGlvbi9QZXJzaXN0ZW5jZU9wdGltaXplci5qYXZh) | `77.419% <ø> (-10.753%)` | `24 <0> (-4)` | |; | [...bender/tools/copynumber/models/CopyRatioState.java](https://codecov.io/gh/broadinstitute/gatk/pull/5732/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL21vZGVscy9Db3B5UmF0aW9TdGF0ZS5qYXZh) | `100% <ø> (ø)` | `5 <0> (ø)` | :arrow_down: |; | [...copynumber/utils/segmentation/KernelSegmenter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5732/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL3V0aWxzL3NlZ21lbnRhdGlvbi9LZXJuZWxTZWdtZW50ZXIuamF2YQ==) | `95.671% <ø> (-2.164%)` | `45 <0> (-3)` | |; | [...s/copynumber/models/AlleleFractionLikelihoods.java](https://codecov.io/gh/br,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5732#issuecomment-470293496
https://github.com/broadinstitute/gatk/pull/5732#issuecomment-475257940:74,Deployability,release,release,74,@mwalker174 @mbabadi @droazen might be nice to get this one in before the release and highlight the whitepaper in the release notes.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5732#issuecomment-475257940
https://github.com/broadinstitute/gatk/pull/5732#issuecomment-475257940:118,Deployability,release,release,118,@mwalker174 @mbabadi @droazen might be nice to get this one in before the release and highlight the whitepaper in the release notes.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5732#issuecomment-475257940
https://github.com/broadinstitute/gatk/pull/5736#issuecomment-468305471:31,Testability,test,test,31,"@meganshand There's no need to test before merging because this is a bug fix for the edge case of negative infinity log likelihoods from PairHMM, regardless.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5736#issuecomment-468305471
https://github.com/broadinstitute/gatk/pull/5736#issuecomment-468305471:116,Testability,log,log,116,"@meganshand There's no need to test before merging because this is a bug fix for the edge case of negative infinity log likelihoods from PairHMM, regardless.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5736#issuecomment-468305471
https://github.com/broadinstitute/gatk/issues/5737#issuecomment-468476353:639,Deployability,update,update,639,"We'd really like to be able to move forward to newer java versions. Unfortunately we have a pretty long list of dependencies which don't support any version newer than 8 yet. In particular, our dependency on Spark is problematic. Spark is stuck on java 8 because of issues with scala on java 9+ as well as issues with their dependencies. As I understand it, Java 9+ made changes to various methods which were widely used by libraries that do low level memory management. It also deprecated some forms of cross package reflection. Spark makes heavy use of both of those things so I think there having trouble updating. . So... we'd like to update, I have no idea when will be able to. Probably not for at least a year.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5737#issuecomment-468476353
https://github.com/broadinstitute/gatk/issues/5737#issuecomment-468476353:112,Integrability,depend,dependencies,112,"We'd really like to be able to move forward to newer java versions. Unfortunately we have a pretty long list of dependencies which don't support any version newer than 8 yet. In particular, our dependency on Spark is problematic. Spark is stuck on java 8 because of issues with scala on java 9+ as well as issues with their dependencies. As I understand it, Java 9+ made changes to various methods which were widely used by libraries that do low level memory management. It also deprecated some forms of cross package reflection. Spark makes heavy use of both of those things so I think there having trouble updating. . So... we'd like to update, I have no idea when will be able to. Probably not for at least a year.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5737#issuecomment-468476353
https://github.com/broadinstitute/gatk/issues/5737#issuecomment-468476353:194,Integrability,depend,dependency,194,"We'd really like to be able to move forward to newer java versions. Unfortunately we have a pretty long list of dependencies which don't support any version newer than 8 yet. In particular, our dependency on Spark is problematic. Spark is stuck on java 8 because of issues with scala on java 9+ as well as issues with their dependencies. As I understand it, Java 9+ made changes to various methods which were widely used by libraries that do low level memory management. It also deprecated some forms of cross package reflection. Spark makes heavy use of both of those things so I think there having trouble updating. . So... we'd like to update, I have no idea when will be able to. Probably not for at least a year.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5737#issuecomment-468476353
https://github.com/broadinstitute/gatk/issues/5737#issuecomment-468476353:324,Integrability,depend,dependencies,324,"We'd really like to be able to move forward to newer java versions. Unfortunately we have a pretty long list of dependencies which don't support any version newer than 8 yet. In particular, our dependency on Spark is problematic. Spark is stuck on java 8 because of issues with scala on java 9+ as well as issues with their dependencies. As I understand it, Java 9+ made changes to various methods which were widely used by libraries that do low level memory management. It also deprecated some forms of cross package reflection. Spark makes heavy use of both of those things so I think there having trouble updating. . So... we'd like to update, I have no idea when will be able to. Probably not for at least a year.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5737#issuecomment-468476353
https://github.com/broadinstitute/gatk/issues/5738#issuecomment-468499683:266,Deployability,update,updated,266,"@lesleygray Perhaps I'm not understanding the issue---from the title, it sounds like you are trying to use the BETA version of the GATK jar/Docker with the 4.0.12.0 germline CNV WDL? The jar/Docker and WDLs all need to be from the same version of GATK, as these are updated in lockstep. It looks like the name of the argument that the warning is complaining about (`num_thermal_advi_iters`) was introduced in #4720 (and replaced `num_thermal_epochs`, which is present in your python invocation), so I'm guessing you might be using a version of the jar/Docker that is older than that?. If this is not the case, could you explain why you expected that `caller_update_convergence_threshold` be identified as the incorrect argument instead?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5738#issuecomment-468499683
https://github.com/broadinstitute/gatk/issues/5740#issuecomment-468989614:305,Integrability,message,messages,305,"@olavurmortensen, looks like TILEDB_DISABLE_FILE_LOCKING=1 did not get passed to the tool. Did you use `export TILEDB_DISABLE_FILE_LOCKING=1` as the command to set the environment variable?; If you have and see the issue, please try the attached zip that contains a shared library with some debug/tracing messages, so we can pinpoint the issue a little more.; [libgenomicsdb.zip](https://github.com/broadinstitute/gatk/files/2922767/libgenomicsdb.zip); To use the zip, from a bash shell:. ```; %: tar zxf libgenomicsdb.zip; %: export LD_LIBRARY_PATH=`pwd`:$LD_LIBRARY_PATH; %: export TILEDB_DISABLE_FILE_LOCKING=1; %: gatk --java-options ""-Xmx4g -Xms4g"" GenomicsDBImport ...; ```; Please attach the log if you still see the issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5740#issuecomment-468989614
https://github.com/broadinstitute/gatk/issues/5740#issuecomment-468989614:180,Modifiability,variab,variable,180,"@olavurmortensen, looks like TILEDB_DISABLE_FILE_LOCKING=1 did not get passed to the tool. Did you use `export TILEDB_DISABLE_FILE_LOCKING=1` as the command to set the environment variable?; If you have and see the issue, please try the attached zip that contains a shared library with some debug/tracing messages, so we can pinpoint the issue a little more.; [libgenomicsdb.zip](https://github.com/broadinstitute/gatk/files/2922767/libgenomicsdb.zip); To use the zip, from a bash shell:. ```; %: tar zxf libgenomicsdb.zip; %: export LD_LIBRARY_PATH=`pwd`:$LD_LIBRARY_PATH; %: export TILEDB_DISABLE_FILE_LOCKING=1; %: gatk --java-options ""-Xmx4g -Xms4g"" GenomicsDBImport ...; ```; Please attach the log if you still see the issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5740#issuecomment-468989614
https://github.com/broadinstitute/gatk/issues/5740#issuecomment-468989614:699,Testability,log,log,699,"@olavurmortensen, looks like TILEDB_DISABLE_FILE_LOCKING=1 did not get passed to the tool. Did you use `export TILEDB_DISABLE_FILE_LOCKING=1` as the command to set the environment variable?; If you have and see the issue, please try the attached zip that contains a shared library with some debug/tracing messages, so we can pinpoint the issue a little more.; [libgenomicsdb.zip](https://github.com/broadinstitute/gatk/files/2922767/libgenomicsdb.zip); To use the zip, from a bash shell:. ```; %: tar zxf libgenomicsdb.zip; %: export LD_LIBRARY_PATH=`pwd`:$LD_LIBRARY_PATH; %: export TILEDB_DISABLE_FILE_LOCKING=1; %: gatk --java-options ""-Xmx4g -Xms4g"" GenomicsDBImport ...; ```; Please attach the log if you still see the issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5740#issuecomment-468989614
https://github.com/broadinstitute/gatk/pull/5741#issuecomment-470277845:0,Testability,Test,Tests,0,Tests pass! (after rebasing to remove the offending ReadsPipeline Spark test),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5741#issuecomment-470277845
https://github.com/broadinstitute/gatk/pull/5741#issuecomment-470277845:72,Testability,test,test,72,Tests pass! (after rebasing to remove the offending ReadsPipeline Spark test),MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5741#issuecomment-470277845
https://github.com/broadinstitute/gatk/pull/5741#issuecomment-476344917:180,Deployability,release,release,180,@droazen can you reassign this? I'm guessing it's going to be a while before Louis gets to it and this is a feature we're using in production. It would be great to get this in the release.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5741#issuecomment-476344917
https://github.com/broadinstitute/gatk/pull/5742#issuecomment-471805688:69,Testability,test,test,69,"Yes, but I've been waiting to merge #5688 to rebase on top of it and test again. Then I will merge this one.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5742#issuecomment-471805688
https://github.com/broadinstitute/gatk/pull/5742#issuecomment-472492089:0,Testability,Test,Tested,0,Tested it again on FC.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5742#issuecomment-472492089
https://github.com/broadinstitute/gatk/pull/5745#issuecomment-473953843:61,Availability,mainten,maintenance,61,@jamesemery Would you mind taking a look at this bit of code maintenance?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5745#issuecomment-473953843
https://github.com/broadinstitute/gatk/pull/5750#issuecomment-469352829:930,Deployability,pipeline,pipelines,930,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5750?src=pr&el=h1) Report; > Merging [#5750](https://codecov.io/gh/broadinstitute/gatk/pull/5750?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/68809f0d285bcbea1d09301fe27370ec7a655dc9?src=pr&el=desc) will **decrease** coverage by `6.78%`.; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #5750 +/- ##; ==============================================; - Coverage 87.069% 80.289% -6.78% ; + Complexity 31891 30238 -1653 ; ==============================================; Files 1943 1943 ; Lines 146770 146770 ; Branches 16224 16224 ; ==============================================; - Hits 127791 117840 -9951 ; - Misses 13065 23217 +10152 ; + Partials 5914 5713 -201; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5750?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...k/pipelines/ReadsPipelineSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5750/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUmVhZHNQaXBlbGluZVNwYXJrSW50ZWdyYXRpb25UZXN0LmphdmE=) | `1.563% <ø> (-95.313%)` | `1 <0> (-6)` | |; | [...kers/filters/VariantFiltrationIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5750/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2ZpbHRlcnMvVmFyaWFudEZpbHRyYXRpb25JbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `0.826% <0%> (-99.174%)` | `1% <0%> (-25%)` | |; | [...dorientation/CollectF1R2CountsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5750/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3JlYWRvcmllbnRhdGlvbi9Db2xsZWN0RjFSMkNvdW50c0ludGVncmF0aW9uVGVzdC5qYXZh) | `0.917% <0%> (-99.083%)` | `1% <0%> (-12%)` | |; | [.../walkers/bqsr/BaseRecalibratorIntegrationTest.java](https://codecov.io/gh/broadinstitu,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5750#issuecomment-469352829
https://github.com/broadinstitute/gatk/pull/5753#issuecomment-470660338:17,Deployability,update,updated,17,@cmnbroad I have updated the document: https://software.broadinstitute.org/gatk/documentation/article?id=12836,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5753#issuecomment-470660338
https://github.com/broadinstitute/gatk/issues/5754#issuecomment-471632458:16,Performance,optimiz,optimized,16,Sampling method optimized in #5781.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5754#issuecomment-471632458
https://github.com/broadinstitute/gatk/issues/5754#issuecomment-910220751:288,Availability,down,downstream,288,"Default changed from 250 -> 20 in #5699 and exposed in #7450. Unfortunately, I don't recall if we did any benchmarking to spot check runtime/output changes, but I would expect 20 samples to be sufficient for estimating posterior means and standard deviations to the level needed for most downstream use cases.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5754#issuecomment-910220751
https://github.com/broadinstitute/gatk/issues/5754#issuecomment-910220751:44,Security,expose,exposed,44,"Default changed from 250 -> 20 in #5699 and exposed in #7450. Unfortunately, I don't recall if we did any benchmarking to spot check runtime/output changes, but I would expect 20 samples to be sufficient for estimating posterior means and standard deviations to the level needed for most downstream use cases.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5754#issuecomment-910220751
https://github.com/broadinstitute/gatk/issues/5754#issuecomment-910220751:106,Testability,benchmark,benchmarking,106,"Default changed from 250 -> 20 in #5699 and exposed in #7450. Unfortunately, I don't recall if we did any benchmarking to spot check runtime/output changes, but I would expect 20 samples to be sufficient for estimating posterior means and standard deviations to the level needed for most downstream use cases.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5754#issuecomment-910220751
https://github.com/broadinstitute/gatk/issues/5754#issuecomment-921912109:105,Availability,down,downstream,105,@samuelklee Can you briefly explain how the sampling is used in dCR approximations and how they are used downstream? I would expect only 20 samples to give noisy estimates of mean and variance…,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5754#issuecomment-921912109
https://github.com/broadinstitute/gatk/issues/5754#issuecomment-921954601:91,Usability,simpl,simple,91,"The only place I’ve used them is in the malaria genotyping method, where we calculate very simple annotations for each set of breakpoints—mostly summary statistics of the posterior means, like the minimum in a segment or the segment-level mean. We also calculate a single changepoint statistic using the posterior means. Didn’t see any indicators that posterior sampling noise was causing any issues—the only real issue I had was fixed in #7261. I think the initial reason we started emitting these is because Talkowski folks wanted to use them for plotting/visualization, in which case I would be even less worried about sampling noise. But maybe you all are using them for something else now? Even then, not sure if anyone is using the posterior variances. If we ever move towards emitting this for somatic/mosaicism at the single-bin, percent level, then I might be a bit more worried—in which case, good for us for exposing it! But if you’d like to increase the default and it doesn’t seem to add significant runtime, go for it! Might also be good to get some understanding of the sampling noise level for typical data, if only for a few different parameter values.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5754#issuecomment-921954601
https://github.com/broadinstitute/gatk/issues/5754#issuecomment-922018024:52,Safety,safe,safer,52,Thanks for that explanation. I'd rather set it to a safer value like 100 as a default - @asmirnov239 do you have any sense of how much this affects run time?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5754#issuecomment-922018024
https://github.com/broadinstitute/gatk/issues/5754#issuecomment-923036252:250,Testability,test,tests,250,"Looking at this again, plots in https://github.com/broadinstitute/gatk/issues/5764 might be useful. Probably OK to bump things up since the rest of inference will take up the bulk of runtime. Although I think one other consideration might be the WDL tests, since they run slow on Travis and already push the time limit. Perhaps set a lower value for those, if necessary? In any case, please double check all of this!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5754#issuecomment-923036252
https://github.com/broadinstitute/gatk/issues/5754#issuecomment-944002011:7,Testability,benchmark,benchmarked,7,"I have benchmarked several runs with various parameters for number of samples for emitting denoised copy ratio. In particular, with num_samples = 20, 200, 500.; The average shard run time for num_samples=20 was 2h34m, for num_samples=200 also 2h34m and for num_samples=500 it was 2h35m, so there is really no significant difference in the runtime. . Here are the concordance plots for different parameters for 3 1KG exome samples: ; ![image](https://user-images.githubusercontent.com/4894545/137433767-40666bd6-bca5-4c62-913b-d518239dfab9.png). ![image](https://user-images.githubusercontent.com/4894545/137433966-b18ab68d-defc-409b-b2da-df429b48bb68.png). ![image](https://user-images.githubusercontent.com/4894545/137433981-a3c4cff3-44db-411a-8dc0-c0c9d67c39a1.png). ![image](https://user-images.githubusercontent.com/4894545/137433987-fac46d67-bf3a-4e0f-916d-2b10535f6260.png). ![image](https://user-images.githubusercontent.com/4894545/137433994-c7da1ea8-9a82-449d-8c27-7ca873f8a75e.png). ![image](https://user-images.githubusercontent.com/4894545/137433999-8767faad-41af-488b-83d3-1607c1bc27ad.png). Since there is no effect on the runtime, and there is poor concordance for high denoised copy ratio values it makes sense to raise the default parameter to 200.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5754#issuecomment-944002011
https://github.com/broadinstitute/gatk/issues/5754#issuecomment-944207573:330,Energy Efficiency,reduce,reduced,330,"Thanks for making and documenting those plots, @asmirnov239! Does seem worthwhile to sample more if it makes no difference in the runtime. Just curious, what was the shard size?. Slightly counterintuitive that the high end is more noisy, but I guess it must be due to sampling noise of low bias---I'd expect more competition from reduced noise due to higher counts. Mind sharing the num_samples = 20 and 200 dCR files for at least one sample so I can take a quick look?. Might also be nice to see the posterior standard deviations, but if it's too much work to compile those it's fine. Perhaps we should just concatenate them anyway (I don't recall why we didn't originally add this in #5823, but maybe we had a reason). In any case, the noise doesn't look crazy in the CR regime that would've been important for the CNV genotyping stuff---phew!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5754#issuecomment-944207573
https://github.com/broadinstitute/gatk/issues/5754#issuecomment-945731946:985,Modifiability,extend,extending,985,"Thanks for that info and for sharing the files, @asmirnov239. I suspect that there are essentially two types of bins: ""nice"" and ""not so nice"". The sampling noise in the former is determined by Poisson observation noise, whereas that in the latter is determined by uncertainty in the bias posteriors. This is a bit hard to see in the plots above, and even in this version where I tried to adjust the point size and alpha:. ![image](https://user-images.githubusercontent.com/11076296/137733810-16a79ea9-ea7b-47cc-a42f-40130a949015.png). However, plotting a measure of the difference in the dCRs (from 20 and 200 posterior samples) vs. the dCR is more suggestive:. ![image](https://user-images.githubusercontent.com/11076296/137734587-1b9f6551-74b2-4097-a02c-f51d7341251c.png). As are the dCR histograms:. ![image](https://user-images.githubusercontent.com/11076296/137733867-ce0f5573-a5cc-412c-9060-56fbb09d1ef0.png). I would guess that the nice spike around CR ~ 2 and the fatter base extending up to dCR ~ 100 are distinct populations of bins. So the punchline would be that differences at high dCR are probably just noise within the noise. For ""nice"" bins at dCR ~ few, the sampling noise looks to be <1%. Not really sure what's going on at very high dCR, but I think it's safe to say that these are ""not so nice"" bins!. I've seen this pattern in other WES cohorts when plotting the posterior means vs. std devs for the biases; tried to dig up the plots on Slack, but I can't find them at the moment. Perhaps something along those lines might be worth visualizing in your model-criticism notebooks, if you don't already?. Again, hard to say this is indeed the case from the dCRs alone, but if so, it might be worth baking this sort of mixture into future versions of the model or coming up with other strategies to deal with such bins.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5754#issuecomment-945731946
https://github.com/broadinstitute/gatk/issues/5754#issuecomment-945731946:1275,Safety,safe,safe,1275,"Thanks for that info and for sharing the files, @asmirnov239. I suspect that there are essentially two types of bins: ""nice"" and ""not so nice"". The sampling noise in the former is determined by Poisson observation noise, whereas that in the latter is determined by uncertainty in the bias posteriors. This is a bit hard to see in the plots above, and even in this version where I tried to adjust the point size and alpha:. ![image](https://user-images.githubusercontent.com/11076296/137733810-16a79ea9-ea7b-47cc-a42f-40130a949015.png). However, plotting a measure of the difference in the dCRs (from 20 and 200 posterior samples) vs. the dCR is more suggestive:. ![image](https://user-images.githubusercontent.com/11076296/137734587-1b9f6551-74b2-4097-a02c-f51d7341251c.png). As are the dCR histograms:. ![image](https://user-images.githubusercontent.com/11076296/137733867-ce0f5573-a5cc-412c-9060-56fbb09d1ef0.png). I would guess that the nice spike around CR ~ 2 and the fatter base extending up to dCR ~ 100 are distinct populations of bins. So the punchline would be that differences at high dCR are probably just noise within the noise. For ""nice"" bins at dCR ~ few, the sampling noise looks to be <1%. Not really sure what's going on at very high dCR, but I think it's safe to say that these are ""not so nice"" bins!. I've seen this pattern in other WES cohorts when plotting the posterior means vs. std devs for the biases; tried to dig up the plots on Slack, but I can't find them at the moment. Perhaps something along those lines might be worth visualizing in your model-criticism notebooks, if you don't already?. Again, hard to say this is indeed the case from the dCRs alone, but if so, it might be worth baking this sort of mixture into future versions of the model or coming up with other strategies to deal with such bins.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5754#issuecomment-945731946
https://github.com/broadinstitute/gatk/pull/5760#issuecomment-469855399:4849,Deployability,update,update,4849,"W9uVGVzdC5qYXZh) | `1.66% <0%> (-98.34%)` | `1% <0%> (-5%)` | |; | [...on/FindBreakpointEvidenceSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5760/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9pbnRlZ3JhdGlvbi9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmtJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `1.75% <0%> (-98.25%)` | `1% <0%> (-6%)` | |; | [...bender/tools/spark/PileupSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5760/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QaWxldXBTcGFya0ludGVncmF0aW9uVGVzdC5qYXZh) | `2.04% <0%> (-97.96%)` | `2% <0%> (-13%)` | |; | [...tute/hellbender/tools/FlagStatIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5760/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9GbGFnU3RhdEludGVncmF0aW9uVGVzdC5qYXZh) | `2.08% <0%> (-97.92%)` | `1% <0%> (-5%)` | |; | [...rs/variantutils/SelectVariantsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5760/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9TZWxlY3RWYXJpYW50c0ludGVncmF0aW9uVGVzdC5qYXZh) | `0.25% <0%> (-97.75%)` | `1% <0%> (-70%)` | |; | ... and [154 more](https://codecov.io/gh/broadinstitute/gatk/pull/5760/diff?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5760?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5760?src=pr&el=footer). Last update [1d6f5b3...d98f9dc](https://codecov.io/gh/broadinstitute/gatk/pull/5760?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5760#issuecomment-469855399
https://github.com/broadinstitute/gatk/pull/5760#issuecomment-469855399:4752,Energy Efficiency,Power,Powered,4752,"W9uVGVzdC5qYXZh) | `1.66% <0%> (-98.34%)` | `1% <0%> (-5%)` | |; | [...on/FindBreakpointEvidenceSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5760/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9pbnRlZ3JhdGlvbi9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmtJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `1.75% <0%> (-98.25%)` | `1% <0%> (-6%)` | |; | [...bender/tools/spark/PileupSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5760/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QaWxldXBTcGFya0ludGVncmF0aW9uVGVzdC5qYXZh) | `2.04% <0%> (-97.96%)` | `2% <0%> (-13%)` | |; | [...tute/hellbender/tools/FlagStatIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5760/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9GbGFnU3RhdEludGVncmF0aW9uVGVzdC5qYXZh) | `2.08% <0%> (-97.92%)` | `1% <0%> (-5%)` | |; | [...rs/variantutils/SelectVariantsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5760/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9TZWxlY3RWYXJpYW50c0ludGVncmF0aW9uVGVzdC5qYXZh) | `0.25% <0%> (-97.75%)` | `1% <0%> (-70%)` | |; | ... and [154 more](https://codecov.io/gh/broadinstitute/gatk/pull/5760/diff?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5760?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5760?src=pr&el=footer). Last update [1d6f5b3...d98f9dc](https://codecov.io/gh/broadinstitute/gatk/pull/5760?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5760#issuecomment-469855399
https://github.com/broadinstitute/gatk/pull/5760#issuecomment-469855399:4615,Usability,learn,learn,4615,"W9uVGVzdC5qYXZh) | `1.66% <0%> (-98.34%)` | `1% <0%> (-5%)` | |; | [...on/FindBreakpointEvidenceSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5760/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9pbnRlZ3JhdGlvbi9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmtJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `1.75% <0%> (-98.25%)` | `1% <0%> (-6%)` | |; | [...bender/tools/spark/PileupSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5760/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QaWxldXBTcGFya0ludGVncmF0aW9uVGVzdC5qYXZh) | `2.04% <0%> (-97.96%)` | `2% <0%> (-13%)` | |; | [...tute/hellbender/tools/FlagStatIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5760/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9GbGFnU3RhdEludGVncmF0aW9uVGVzdC5qYXZh) | `2.08% <0%> (-97.92%)` | `1% <0%> (-5%)` | |; | [...rs/variantutils/SelectVariantsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5760/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9TZWxlY3RWYXJpYW50c0ludGVncmF0aW9uVGVzdC5qYXZh) | `0.25% <0%> (-97.75%)` | `1% <0%> (-70%)` | |; | ... and [154 more](https://codecov.io/gh/broadinstitute/gatk/pull/5760/diff?src=pr&el=tree-more) | |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5760?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5760?src=pr&el=footer). Last update [1d6f5b3...d98f9dc](https://codecov.io/gh/broadinstitute/gatk/pull/5760?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5760#issuecomment-469855399
https://github.com/broadinstitute/gatk/pull/5761#issuecomment-469880173:92,Safety,avoid,avoid,92,I was push an old branch and needed to pull from master and rebase. So I closed this one to avoid confusion @droazen,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5761#issuecomment-469880173
https://github.com/broadinstitute/gatk/pull/5762#issuecomment-474890328:104,Testability,test,test,104,@cmnbroad Thank you again! I responded/fixed all of your comments/review and will hopefully obtain some test data later this afternoon!,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5762#issuecomment-474890328
https://github.com/broadinstitute/gatk/pull/5762#issuecomment-482191369:3079,Availability,down,downsampling,3079,qYXZh) | `9.091% <9.091%> (ø)` | `1 <1> (?)` | |; | [...ellbender/tools/walkers/MethylationTypeCaller.java](https://codecov.io/gh/broadinstitute/gatk/pull/5762/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL01ldGh5bGF0aW9uVHlwZUNhbGxlci5qYXZh) | `95.522% <95.522%> (ø)` | `11 <11> (?)` | |; | [...ls/variant/writers/GVCFBlockCombiningIterator.java](https://codecov.io/gh/broadinstitute/gatk/pull/5762/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L3dyaXRlcnMvR1ZDRkJsb2NrQ29tYmluaW5nSXRlcmF0b3IuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-1%)` | |; | [...ls/walkers/genotyper/HeterogeneousPloidyModel.java](https://codecov.io/gh/broadinstitute/gatk/pull/5762/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9IZXRlcm9nZW5lb3VzUGxvaWR5TW9kZWwuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-14%)` | |; | [...nder/utils/downsampling/FractionalDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/5762/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvRnJhY3Rpb25hbERvd25zYW1wbGVyLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-17%)` | |; | [...park/pathseq/MarkedOpticalDuplicateReadFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5762/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL01hcmtlZE9wdGljYWxEdXBsaWNhdGVSZWFkRmlsdGVyLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-4%)` | |; | [...otypecaller/RandomLikelihoodCalculationEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/5762/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9SYW5kb21MaWtlbGlob29kQ2FsY3VsYXRpb25FbmdpbmUuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-6%)` | |; | ... and [1227 more](https://codecov.io/gh/broadinstitute/gatk/pull/5762/diff?s,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5762#issuecomment-482191369
https://github.com/broadinstitute/gatk/issues/5764#issuecomment-470161524:225,Energy Efficiency,reduce,reduces,225,"Forgot to mention that this is all in cohort mode, so it's conceivable that case mode could be even cheaper and that we could run more samples in each shard. Not sure if the denoising-model parameters are fixed in a way that reduces memory usage, but this should be easy enough to check.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5764#issuecomment-470161524
https://github.com/broadinstitute/gatk/issues/5764#issuecomment-470236552:321,Performance,perform,performance,321,"For reference, plots of memory usage for a 50x10000 shard:. ![gcnv-10k-mem](https://user-images.githubusercontent.com/11076296/53906618-6be46100-4019-11e9-8d70-5971fd5d2e35.png). It appears that the 0.9.0 leak only occurs during denoising + sampling. Not sure if differences in runtime are indicative of OpenBLAS vs. MKL performance or within the noise.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5764#issuecomment-470236552
https://github.com/broadinstitute/gatk/issues/5766#issuecomment-470211072:743,Deployability,deploy,deployment,743,"Thanks @clsgithubusr, we are well aware that Theano is no longer in development. There are plans to move future model implementations to pyro (https://github.com/pyro-ppl/pyro) and some prototype models have already been developed in that framework. As is stated in the post you linked, things move relatively quickly in the ML world!. Fortunately, Theano is a relatively mature and stable framework. If you use the GATK conda environment you shouldn’t have any issues. If not, I don’t think we can make any guarantees. It was a major decision for us to introduce python ML frameworks into our codebase, but it was necessary to enable methods that can take advantage of all of the developments happening in the field of ML. We understand that deployment may be more difficult as a result, but using conda and Docker should hopefully ease the burden significantly.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5766#issuecomment-470211072
https://github.com/broadinstitute/gatk/issues/5766#issuecomment-926143041:179,Integrability,depend,dependency,179,"Closing as a part of my issue clearing rampage, but let it be known Pyro is on the roadmap for future CNV models, and we are currently looking into updating PyMC3 to resolve some dependency issues with gCNV.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5766#issuecomment-926143041
https://github.com/broadinstitute/gatk/issues/5766#issuecomment-926143041:30,Usability,clear,clearing,30,"Closing as a part of my issue clearing rampage, but let it be known Pyro is on the roadmap for future CNV models, and we are currently looking into updating PyMC3 to resolve some dependency issues with gCNV.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5766#issuecomment-926143041
https://github.com/broadinstitute/gatk/pull/5767#issuecomment-470234419:70,Testability,test,tests,70,"First, it looks like you need to address the failing haplotype caller tests now: https://storage.googleapis.com/hellbender-test-logs/build_reports/master_25237.4/tests/test/index.html",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5767#issuecomment-470234419
https://github.com/broadinstitute/gatk/pull/5767#issuecomment-470234419:123,Testability,test,test-logs,123,"First, it looks like you need to address the failing haplotype caller tests now: https://storage.googleapis.com/hellbender-test-logs/build_reports/master_25237.4/tests/test/index.html",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5767#issuecomment-470234419
https://github.com/broadinstitute/gatk/pull/5767#issuecomment-470234419:162,Testability,test,tests,162,"First, it looks like you need to address the failing haplotype caller tests now: https://storage.googleapis.com/hellbender-test-logs/build_reports/master_25237.4/tests/test/index.html",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5767#issuecomment-470234419
https://github.com/broadinstitute/gatk/pull/5767#issuecomment-470234419:168,Testability,test,test,168,"First, it looks like you need to address the failing haplotype caller tests now: https://storage.googleapis.com/hellbender-test-logs/build_reports/master_25237.4/tests/test/index.html",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5767#issuecomment-470234419
https://github.com/broadinstitute/gatk/pull/5767#issuecomment-470257519:248,Modifiability,inherit,inherited,248,"@davidbenjamin @jamesemery As discussed in person, we should consider the possibility that this behavior is by design, and the band pass filter is deliberately being centered on the base before the high-quality soft clip begins (since this code is inherited from GATK3). Let's talk about this before hitting merge on this one.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5767#issuecomment-470257519
https://github.com/broadinstitute/gatk/pull/5767#issuecomment-470612215:169,Safety,avoid,avoid,169,"@droazen @jamesemery It does seem like it's by design, and as James found the behavior is to multiply the evidence by the length of the soft clip, which seems weird. We avoid this in Mutect2 and treat it like an indel. I would vote for doing the same and just eliminating the `HIGH_QUALITY_SOFT_CLIP` category.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5767#issuecomment-470612215
https://github.com/broadinstitute/gatk/pull/5768#issuecomment-470249511:304,Modifiability,rewrite,rewrite,304,"> How can F be a probability when it takes on negative values?. It's the probability of alleles being IBD *provided that inbreeding is the only source of deviation from HWE* and in the limit of infinite sample size washing out statistical noise. Under these assumptions it's always positive. How about I rewrite the docs to be much, much clearer about this?. > Also, I've never heard of it being called the Fixation Score. I hadn't heard of it, either, but Wikipedia told me so: https://en.wikipedia.org/wiki/F-statistics",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5768#issuecomment-470249511
https://github.com/broadinstitute/gatk/pull/5768#issuecomment-470249511:338,Usability,clear,clearer,338,"> How can F be a probability when it takes on negative values?. It's the probability of alleles being IBD *provided that inbreeding is the only source of deviation from HWE* and in the limit of infinite sample size washing out statistical noise. Under these assumptions it's always positive. How about I rewrite the docs to be much, much clearer about this?. > Also, I've never heard of it being called the Fixation Score. I hadn't heard of it, either, but Wikipedia told me so: https://en.wikipedia.org/wiki/F-statistics",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5768#issuecomment-470249511
https://github.com/broadinstitute/gatk/pull/5769#issuecomment-470218921:51,Deployability,update,updates,51,"@davidbenjamin here is the PR to the documentation updates we have been working on. I made a few additional stylistic changes, fyi.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5769#issuecomment-470218921
https://github.com/broadinstitute/gatk/pull/5769#issuecomment-470233081:1870,Availability,down,downsampling,1870,| Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...itute/hellbender/tools/walkers/mutect/Mutect2.java](https://codecov.io/gh/broadinstitute/gatk/pull/5769/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9NdXRlY3QyLmphdmE=) | `84.091% <ø> (ø)` | `22 <0> (ø)` | :arrow_down: |; | [...ls/variant/writers/GVCFBlockCombiningIterator.java](https://codecov.io/gh/broadinstitute/gatk/pull/5769/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L3dyaXRlcnMvR1ZDRkJsb2NrQ29tYmluaW5nSXRlcmF0b3IuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-1%)` | |; | [...ls/walkers/genotyper/HeterogeneousPloidyModel.java](https://codecov.io/gh/broadinstitute/gatk/pull/5769/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9IZXRlcm9nZW5lb3VzUGxvaWR5TW9kZWwuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-14%)` | |; | [...nder/utils/downsampling/FractionalDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/5769/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvRnJhY3Rpb25hbERvd25zYW1wbGVyLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-17%)` | |; | [...park/pathseq/MarkedOpticalDuplicateReadFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5769/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL01hcmtlZE9wdGljYWxEdXBsaWNhdGVSZWFkRmlsdGVyLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-4%)` | |; | [...otypecaller/RandomLikelihoodCalculationEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/5769/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9SYW5kb21MaWtlbGlob29kQ2FsY3VsYXRpb25FbmdpbmUuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-6%)` | |; | [...r/utils/solver/UnivariateSolverSpecifications.java](https://codecov.io/gh/,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5769#issuecomment-470233081
https://github.com/broadinstitute/gatk/pull/5772#issuecomment-470642394:1899,Deployability,pipeline,pipelines,1899, | |; |---|---|---|---|; | [...walkers/haplotypecaller/HaplotypeCallerEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/5772/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9IYXBsb3R5cGVDYWxsZXJFbmdpbmUuamF2YQ==) | `78.746% <ø> (-0.22%)` | `73 <0> (-1)` | |; | [...ils/nio/NioFileCopierWithProgressMeterResults.java](https://codecov.io/gh/broadinstitute/gatk/pull/5772/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9uaW8vTmlvRmlsZUNvcGllcldpdGhQcm9ncmVzc01ldGVyUmVzdWx0cy5qYXZh) | `0% <0%> (-94.737%)` | `0% <0%> (-9%)` | |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5772/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-74.257%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5772/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...ols/funcotator/FuncotatorDataSourceDownloader.java](https://codecov.io/gh/broadinstitute/gatk/pull/5772/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0Z1bmNvdGF0b3JEYXRhU291cmNlRG93bmxvYWRlci5qYXZh) | `0% <0%> (-66.197%)` | `0% <0%> (-14%)` | |; | [...nder/utils/nio/NioFileCopierWithProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5772/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9uaW8vTmlvRmlsZUNvcGllcldpdGhQcm9ncmVzc01ldGVyLmphdmE=) | `17% <0%> (-52.5%)` | `9% <0%> (-30%)` | |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5772/d,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5772#issuecomment-470642394
https://github.com/broadinstitute/gatk/pull/5772#issuecomment-470688534:215,Deployability,update,update,215,"I don't think this PR is going to work. I believe the changes I have made will make the tests pass, but in my own testing I'm experiencing the HC dropping variants when running with phasing on in non-ERC mode. I'll update the linked issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5772#issuecomment-470688534
https://github.com/broadinstitute/gatk/pull/5772#issuecomment-470688534:88,Testability,test,tests,88,"I don't think this PR is going to work. I believe the changes I have made will make the tests pass, but in my own testing I'm experiencing the HC dropping variants when running with phasing on in non-ERC mode. I'll update the linked issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5772#issuecomment-470688534
https://github.com/broadinstitute/gatk/pull/5772#issuecomment-470688534:114,Testability,test,testing,114,"I don't think this PR is going to work. I believe the changes I have made will make the tests pass, but in my own testing I'm experiencing the HC dropping variants when running with phasing on in non-ERC mode. I'll update the linked issue.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5772#issuecomment-470688534
https://github.com/broadinstitute/gatk/pull/5772#issuecomment-470692220:370,Deployability,update,updated,370,"@ldgauthier (and maybe @eitanbanks ?) is there any chance you could take a look at this PR sooner rather than later? I apologize for being pushy, but this is becoming a blocking issue for me as I can't find any other way to generate a single-sample VCF with correct phasing information. I'm fairly confident that the tests will pass on this build cycle, given that I've updated the test files and the tests now pass locally.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5772#issuecomment-470692220
https://github.com/broadinstitute/gatk/pull/5772#issuecomment-470692220:317,Testability,test,tests,317,"@ldgauthier (and maybe @eitanbanks ?) is there any chance you could take a look at this PR sooner rather than later? I apologize for being pushy, but this is becoming a blocking issue for me as I can't find any other way to generate a single-sample VCF with correct phasing information. I'm fairly confident that the tests will pass on this build cycle, given that I've updated the test files and the tests now pass locally.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5772#issuecomment-470692220
https://github.com/broadinstitute/gatk/pull/5772#issuecomment-470692220:382,Testability,test,test,382,"@ldgauthier (and maybe @eitanbanks ?) is there any chance you could take a look at this PR sooner rather than later? I apologize for being pushy, but this is becoming a blocking issue for me as I can't find any other way to generate a single-sample VCF with correct phasing information. I'm fairly confident that the tests will pass on this build cycle, given that I've updated the test files and the tests now pass locally.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5772#issuecomment-470692220
https://github.com/broadinstitute/gatk/pull/5772#issuecomment-470692220:401,Testability,test,tests,401,"@ldgauthier (and maybe @eitanbanks ?) is there any chance you could take a look at this PR sooner rather than later? I apologize for being pushy, but this is becoming a blocking issue for me as I can't find any other way to generate a single-sample VCF with correct phasing information. I'm fairly confident that the tests will pass on this build cycle, given that I've updated the test files and the tests now pass locally.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5772#issuecomment-470692220
https://github.com/broadinstitute/gatk/pull/5772#issuecomment-470944850:76,Testability,test,test,76,"I suspect that we restricted it to GVCF mode because we didn't have time to test VCF mode in the push to call the ExAC samples. Did you try multi-sample VCF mode? It will probably be fine, but I've got this mixed up with the MNP issue in my mind.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5772#issuecomment-470944850
https://github.com/broadinstitute/gatk/pull/5772#issuecomment-470953375:130,Testability,test,test,130,"Thanks guys. Good to know there's not some major historical reason, and likely expediency at the time. @ldgauthier I'll give it a test in multi-sample mode and report back.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5772#issuecomment-470953375
https://github.com/broadinstitute/gatk/pull/5772#issuecomment-470972598:84,Deployability,update,updated,84,"When you say that the samples have 0|0 calls, is that the GT call (as you; and Nils updated) or the PGT call? If it's PGT I don't really care as long; as GT is 0/0. If GT is 0|0 I have to think about it a little more and ask; around. On Fri, Mar 8, 2019 at 10:35 AM Tim Fennell <notifications@github.com>; wrote:. > Ok, so I ran in multi-sample mode with three samples. The results are IMHO; > a little odd, but not wrong. The reason I say a little odd is that (and; > this makes total sense thinking about it) when one sample has phased; > genotypes, all the samples get phasing information. This follows from the; > fact that the FORMAT field has to contain PS (and also PID and PGT) in; > order to emit phasing for one sample, so then the other samples have to do; > something.; >; > What happens then is that phase sets get created for all the samples, and; > you end up with some samples having e.g. pairs of 0|0 genotypes phased.; > Strictly speaking that isn't wrong .. but it is a little funny looking.; >; > I could see three options:; >; > 1. Decide that multi-sample calling to VCF with phasing enabled is too; > weird, and change the existing prohibition to be ""if emitting VCF *and*; > multi-sample disable phasing); > 2. Decide it's all ok, and just remove the existing prohibition; > 3. Split the difference and emit a warning if emitting a multi-sample; > VCF with phasing.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/5772#issuecomment-470969817>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdFesDdjKnEXqk2x0JVi2f7MZtcr9ks5vUoMngaJpZM4bjw8U>; > .; >. -- ; Laura Doyle Gauthier, Ph.D.; Associate Director, Germline Methods; Data Sciences Platform; gauthier@broadinstitute.org; Broad Institute of MIT & Harvard; 320 Charles St.; Cambridge MA 0214",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5772#issuecomment-470972598
https://github.com/broadinstitute/gatk/pull/5772#issuecomment-471062432:927,Deployability,update,updated,927,"@ldgauthier looking at things, I think there are actually a couple of issues. Here's a snippet of a 3-sample VCF generated with phasing enabled (sorry it's so wide):. ```; chr1 21900146 . C G 3516.25 . GT:AD:DP:F1R2:F2R1:GQ:PGT:PID:PL:PS 0|0:161,0:161:9,0:152,0:99:0|1:21900146_C_G:0,484,7601:21900146 0|0:183,0:183:16,0:167,0:99:0|1:21900146_C_G:0,566,8911:21900146 0|1:85,89:174:5,1:80,88:99:0|1:21900146_C_G:3525,0,3544:21900146; chr1 21900151 . T C 3493.25 . GT:AD:DP:F1R2:F2R1:GQ:PGT:PID:PL:PS 0|0:165,0:165:9,0:156,0:99:0|1:21900146_C_G:0,496,7733:21900146 0|0:188,0:188:17,0:171,0:99:0|1:21900146_C_G:0,566,8911:21900146 0|1:94,91:185:5,3:89,88:99:0|1:21900146_C_G:3502,0,3793:21900146; ```. You'll notice that both `GT` and `PGT` have phased genotypes. And in the case of samples with a homozygous genotype, the `PGT` has an incorrect heterozygous genotype. Going back and looking more closely at the test files that I updated, I also see where the `GT` is `1|1` that the `PGT` is erroneously heterozgyous. In talking to @nh13 about this, he pointed me at a section of code in `AssemblyBasedCallerGenotypingEngine` that purposefully sets the genotype to either `0|1` or `1|0` with a long note on line 512 that this is on purpose and that it'll get ""fixed"" later. Evidently that's not happening on the code path in `HaplotypeCaller` that generates a VCF as opposed to a GVCF. If this PR is likely to get accepted _and_ someone can point me in the right direction for fixing up the `PGT`, I'd be happy to try and fix that.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5772#issuecomment-471062432
https://github.com/broadinstitute/gatk/pull/5772#issuecomment-471062432:909,Testability,test,test,909,"@ldgauthier looking at things, I think there are actually a couple of issues. Here's a snippet of a 3-sample VCF generated with phasing enabled (sorry it's so wide):. ```; chr1 21900146 . C G 3516.25 . GT:AD:DP:F1R2:F2R1:GQ:PGT:PID:PL:PS 0|0:161,0:161:9,0:152,0:99:0|1:21900146_C_G:0,484,7601:21900146 0|0:183,0:183:16,0:167,0:99:0|1:21900146_C_G:0,566,8911:21900146 0|1:85,89:174:5,1:80,88:99:0|1:21900146_C_G:3525,0,3544:21900146; chr1 21900151 . T C 3493.25 . GT:AD:DP:F1R2:F2R1:GQ:PGT:PID:PL:PS 0|0:165,0:165:9,0:156,0:99:0|1:21900146_C_G:0,496,7733:21900146 0|0:188,0:188:17,0:171,0:99:0|1:21900146_C_G:0,566,8911:21900146 0|1:94,91:185:5,3:89,88:99:0|1:21900146_C_G:3502,0,3793:21900146; ```. You'll notice that both `GT` and `PGT` have phased genotypes. And in the case of samples with a homozygous genotype, the `PGT` has an incorrect heterozygous genotype. Going back and looking more closely at the test files that I updated, I also see where the `GT` is `1|1` that the `PGT` is erroneously heterozgyous. In talking to @nh13 about this, he pointed me at a section of code in `AssemblyBasedCallerGenotypingEngine` that purposefully sets the genotype to either `0|1` or `1|0` with a long note on line 512 that this is on purpose and that it'll get ""fixed"" later. Evidently that's not happening on the code path in `HaplotypeCaller` that generates a VCF as opposed to a GVCF. If this PR is likely to get accepted _and_ someone can point me in the right direction for fixing up the `PGT`, I'd be happy to try and fix that.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5772#issuecomment-471062432
https://github.com/broadinstitute/gatk/pull/5772#issuecomment-472918993:93,Testability,test,tested,93,@tfenne I would prefer this be limited to single-sample until all the multi-sample cases are tested.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5772#issuecomment-472918993
https://github.com/broadinstitute/gatk/pull/5774#issuecomment-470713542:2981,Usability,Simpl,SimpleKeyXsvFuncotationFactoryUnitTest,2981,Factory.java](https://codecov.io/gh/broadinstitute/gatk/pull/5774/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL2Nvc21pYy9Db3NtaWNGdW5jb3RhdGlvbkZhY3RvcnkuamF2YQ==) | `62.238% <100%> (-1.143%)` | `28 <1> (+1)` | |; | [...er/tools/funcotator/FuncotatorIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5774/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0Z1bmNvdGF0b3JJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `85.693% <100%> (+0.44%)` | `114 <1> (+1)` | :arrow_up: |; | [...ces/gencode/GencodeFuncotationFactoryUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5774/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL2dlbmNvZGUvR2VuY29kZUZ1bmNvdGF0aW9uRmFjdG9yeVVuaXRUZXN0LmphdmE=) | `94.047% <100%> (+0.009%)` | `68 <1> (+1)` | :arrow_up: |; | [...es/xsv/SimpleKeyXsvFuncotationFactoryUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5774/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL3hzdi9TaW1wbGVLZXlYc3ZGdW5jb3RhdGlvbkZhY3RvcnlVbml0VGVzdC5qYXZh) | `98.438% <100%> (+0.05%)` | `24 <1> (+1)` | :arrow_up: |; | [...ataSources/xsv/SimpleKeyXsvFuncotationFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/5774/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL3hzdi9TaW1wbGVLZXlYc3ZGdW5jb3RhdGlvbkZhY3RvcnkuamF2YQ==) | `85.149% <100%> (-0.851%)` | `29 <1> (ø)` | |; | [...es/xsv/LocatableXsvFuncotationFactoryUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5774/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL3hzdi9Mb2NhdGFibGVYc3ZGdW5jb3RhdGlvbkZhY3RvcnlVbml0VGVzdC5qYXZh) | `96.732% <100%> (+0.043%)` | `15 <1,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5774#issuecomment-470713542
https://github.com/broadinstitute/gatk/pull/5774#issuecomment-470713542:3346,Usability,Simpl,SimpleKeyXsvFuncotationFactory,3346,codecov.io/gh/broadinstitute/gatk/pull/5774/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0Z1bmNvdGF0b3JJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `85.693% <100%> (+0.44%)` | `114 <1> (+1)` | :arrow_up: |; | [...ces/gencode/GencodeFuncotationFactoryUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5774/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL2dlbmNvZGUvR2VuY29kZUZ1bmNvdGF0aW9uRmFjdG9yeVVuaXRUZXN0LmphdmE=) | `94.047% <100%> (+0.009%)` | `68 <1> (+1)` | :arrow_up: |; | [...es/xsv/SimpleKeyXsvFuncotationFactoryUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5774/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL3hzdi9TaW1wbGVLZXlYc3ZGdW5jb3RhdGlvbkZhY3RvcnlVbml0VGVzdC5qYXZh) | `98.438% <100%> (+0.05%)` | `24 <1> (+1)` | :arrow_up: |; | [...ataSources/xsv/SimpleKeyXsvFuncotationFactory.java](https://codecov.io/gh/broadinstitute/gatk/pull/5774/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL3hzdi9TaW1wbGVLZXlYc3ZGdW5jb3RhdGlvbkZhY3RvcnkuamF2YQ==) | `85.149% <100%> (-0.851%)` | `29 <1> (ø)` | |; | [...es/xsv/LocatableXsvFuncotationFactoryUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5774/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL2RhdGFTb3VyY2VzL3hzdi9Mb2NhdGFibGVYc3ZGdW5jb3RhdGlvbkZhY3RvcnlVbml0VGVzdC5qYXZh) | `96.732% <100%> (+0.043%)` | `15 <1> (+1)` | :arrow_up: |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5774/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-30%)` | `1% <0%> (-2%)` | |; | ... and [23 more](https,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5774#issuecomment-470713542
https://github.com/broadinstitute/gatk/pull/5774#issuecomment-471047982:44,Testability,test,test,44,Comments addressed. I also added in another test to check for this specific case and guard against it in the future.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5774#issuecomment-471047982
https://github.com/broadinstitute/gatk/issues/5776#issuecomment-470985048:206,Security,validat,validation,206,"Yeah, `--force` is the right thing to do, and I added it to build.gradle a few months ago as part of https://github.com/broadinstitute/gatk/pull/5081, but that PR has languished because my original package validation was lame, and I never went back and resolved it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5776#issuecomment-470985048
https://github.com/broadinstitute/gatk/issues/5776#issuecomment-470998923:119,Deployability,update,updates,119,"OK, great that you already were aware of it! We can probably resolve it during the upcoming round of python dependency updates.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5776#issuecomment-470998923
https://github.com/broadinstitute/gatk/issues/5776#issuecomment-470998923:108,Integrability,depend,dependency,108,"OK, great that you already were aware of it! We can probably resolve it during the upcoming round of python dependency updates.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5776#issuecomment-470998923
https://github.com/broadinstitute/gatk/issues/5777#issuecomment-724975064:77,Availability,error,error,77,"@jonn-smith - sorry for the late response, I was checking if I could find an error on my side. Currently I receive this result for an IDH2 R172 mutation. Interestingly, the dbSNP id is leading to the right variant.; ```; IDH2	3418	__UNKNOWN__	hg19	15	90631838	90631838	+	Intron	SNP	C	C	T	121913503		__UNKNOWN__	__UNKNOWN__	__UNKNOWN__	__UNKNOWN__	__UNKNOWN__	__UNKNOWN__	__UNKNOWN__	__UNKNOWN__	__UNKNOWN__	__UNKNOWN__	__UNKNOWN__	__UNKNOWN__	__UNKNOWN__	__UNKNOWN__	NA	NA	__UNKNOWN__	__UNKNOWN__	__UNKNOWN__	g.chr15:90631838C>T	ENST00000559482.5_2	-			c.e6+104G>A			IDH2_ENST00000330062.8_3_Missense_Mutation_p.G323S|IDH2_ENST00000540499.2_2_Missense_Mutation_p.G323R			P48735	IDHP_HUMAN	isocitrate dehydrogenase (NADP(+)) 2, mitochondrial	__UNKNOWN__	__UNKNOWN__	__UNKNOWN__	__UNKNOWN__	__UNKNOWN__	2-oxoglutarate metabolic process (GO:0006103)|carbohydrate metabolic process (GO:0005975)|cellular metabolic process (GO:0044237)|glyoxylate cycle (GO:0006097)|isocitrate metabolic process (GO:0006102)|small molecule metabolic process (GO:0044281)|tricarboxylic acid cycle (GO:0006099)	extracellular vesicular exosome (GO:0070062)|mitochondrial inner membrane (GO:0005743)|mitochondrial matrix (GO:0005759)|mitochondrion (GO:0005739)	isocitrate dehydrogenase (NADP+) activity (GO:0004450)|magnesium ion binding (GO:0000287)|NAD binding (GO:0051287)			NS(223)|adrenal_gland(294)|autonomic_ganglia(349)|biliary_tract(876)|bone(893)|breast(1151)|central_nervous_system(11211)|cervix(20)|endometrium(22)|eye(81)|genital_tract(1)|haematopoietic_and_lymphoid_tissue(26199)|kidney(260)|large_intestine(1302)|liver(111)|lung(320)|meninges(57)|oesophagus(176)|ovary(533)|pancreas(585)|perineum(1)|peritoneum(60)|pleura(11)|prostate(172)|salivary_gland(105)|skin(644)|small_intestine(26)|soft_tissue(479)|stomach(547)|testis(11)|thymus(26)|thyroid(239)|upper_aerodigestive_tract(127)|urinary_tract(32)|vulva(66)	47210	__UNKNOWN__	__UNKNOWN__	__UNKNOWN__	__UNKNOWN__		ATGGGCGTGCCTGCCAATGGT	0.5635910224438903	__",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5777#issuecomment-724975064
https://github.com/broadinstitute/gatk/issues/5777#issuecomment-724975064:4305,Availability,error,errors,4305,",MedGen:C3463824,OMIM:614286,Orphanet:ORPHA52688|MeSH:D015179,MedGen:CN236642|MedGen:C2239176,OMIM:114550,Orphanet:ORPHA88673,SNOMED_CT:187769009,SNOMED_CT:25370001		Acute_myeloid_leukemia|Brainstem_glioma|Neoplasm_of_brain|Myelodysplastic_syndrome|Colorectal_Neoplasms|Hepatocellular_carcinoma		NC_000015.9:g.90631838C>T	no_assertion_criteria_provided	Pathogenic/Likely_pathogenic			single_nucleotide_variant	SO:0001483			IDH2:3418	SO:0001583|missense_variant	2	121913503		375987								HGNC:5383	Approved	gene with protein product	protein-coding gene		""isocitrate dehydrogenase 2 (NADP+), mitochondrial""			15q26.1	2017-03-24		2016-04-28		1.1.1.42	ENSG00000182054					CCDS10359, CCDS76792	OTTHUMG00000149815	147650	NM_001289910	P48735	ENSG00000182054	uc002box.4		B2R6L6|B4DFL2|Q96GT3	true	false		false	false		false	false	false	IDH2:3418	falsfalse	false	false	false	true	false	false	false	false	false	true	false	false	false	true	true	false	false	true	true	true	3	false	0	false		false	false	false	SNV	0x050268000a05000002100120	1	false	133	rs121913503																						3418	90631838	false	SITE	[745, 640|576, 448]			2483	1	93	[35, 32]	[139, 140]	[60, 60]	19						7.30	93				2809.17 ; ```. It seems that it does not matter if I choose hg19 oder 38. I used `funcotator_dataSources.v1.7.20200521s` as reference.; The call for hg38 was (I slightly shortened it for readability - usually it runs in nextflow - the hg19 call was more or less the same - the -L file is usually not only for IDH2 and has a interval_list format instead of .bed):. ```; gatk Funcotator -R reference/resources_broad_hg38_v0_Homo_sapiens_assembly38.fasta -V mutect2_out.vcf -O funcotator_out.maf --output-file-format MAF --data-sources-path reference/funcotator_dataSources.v1.7.20200521s/ --ref-version hg38 -L reference/idh2_r172.bed; ```. I will create an example test set as soon as I can, have reproducible errors for you. If you already have a hint for me to try, I would be happy to hear from you. Best regards,; Daniel",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5777#issuecomment-724975064
https://github.com/broadinstitute/gatk/issues/5777#issuecomment-724975064:1809,Testability,test,testis,1809,"	__UNKNOWN__	__UNKNOWN__	__UNKNOWN__	__UNKNOWN__	__UNKNOWN__	__UNKNOWN__	__UNKNOWN__	__UNKNOWN__	__UNKNOWN__	__UNKNOWN__	__UNKNOWN__	__UNKNOWN__	NA	NA	__UNKNOWN__	__UNKNOWN__	__UNKNOWN__	g.chr15:90631838C>T	ENST00000559482.5_2	-			c.e6+104G>A			IDH2_ENST00000330062.8_3_Missense_Mutation_p.G323S|IDH2_ENST00000540499.2_2_Missense_Mutation_p.G323R			P48735	IDHP_HUMAN	isocitrate dehydrogenase (NADP(+)) 2, mitochondrial	__UNKNOWN__	__UNKNOWN__	__UNKNOWN__	__UNKNOWN__	__UNKNOWN__	2-oxoglutarate metabolic process (GO:0006103)|carbohydrate metabolic process (GO:0005975)|cellular metabolic process (GO:0044237)|glyoxylate cycle (GO:0006097)|isocitrate metabolic process (GO:0006102)|small molecule metabolic process (GO:0044281)|tricarboxylic acid cycle (GO:0006099)	extracellular vesicular exosome (GO:0070062)|mitochondrial inner membrane (GO:0005743)|mitochondrial matrix (GO:0005759)|mitochondrion (GO:0005739)	isocitrate dehydrogenase (NADP+) activity (GO:0004450)|magnesium ion binding (GO:0000287)|NAD binding (GO:0051287)			NS(223)|adrenal_gland(294)|autonomic_ganglia(349)|biliary_tract(876)|bone(893)|breast(1151)|central_nervous_system(11211)|cervix(20)|endometrium(22)|eye(81)|genital_tract(1)|haematopoietic_and_lymphoid_tissue(26199)|kidney(260)|large_intestine(1302)|liver(111)|lung(320)|meninges(57)|oesophagus(176)|ovary(533)|pancreas(585)|perineum(1)|peritoneum(60)|pleura(11)|prostate(172)|salivary_gland(105)|skin(644)|small_intestine(26)|soft_tissue(479)|stomach(547)|testis(11)|thymus(26)|thyroid(239)|upper_aerodigestive_tract(127)|urinary_tract(32)|vulva(66)	47210	__UNKNOWN__	__UNKNOWN__	__UNKNOWN__	__UNKNOWN__		ATGGGCGTGCCTGCCAATGGT	0.5635910224438903	__UNKNOWN__	__UNKNOWN__	M		GBM		__UNKNOWN__			0.424	1024	1385					""socitrate dehydrogenase 2 (NADP+), mitochondrial ""	3418	15	15q26.1	yes			M	Dom					362866	Human_Phenotype_Ontology:HP:0004808,MeSH:D015470,MedGen:C0023467,OMIM:601626,Orphanet:ORPHA519,SNOMED_CT:17788007|Human_Phenotype_Ontology:HP:0010796,MedGen:C0677865|H",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5777#issuecomment-724975064
https://github.com/broadinstitute/gatk/issues/5777#issuecomment-724975064:4260,Testability,test,test,4260,",MedGen:C3463824,OMIM:614286,Orphanet:ORPHA52688|MeSH:D015179,MedGen:CN236642|MedGen:C2239176,OMIM:114550,Orphanet:ORPHA88673,SNOMED_CT:187769009,SNOMED_CT:25370001		Acute_myeloid_leukemia|Brainstem_glioma|Neoplasm_of_brain|Myelodysplastic_syndrome|Colorectal_Neoplasms|Hepatocellular_carcinoma		NC_000015.9:g.90631838C>T	no_assertion_criteria_provided	Pathogenic/Likely_pathogenic			single_nucleotide_variant	SO:0001483			IDH2:3418	SO:0001583|missense_variant	2	121913503		375987								HGNC:5383	Approved	gene with protein product	protein-coding gene		""isocitrate dehydrogenase 2 (NADP+), mitochondrial""			15q26.1	2017-03-24		2016-04-28		1.1.1.42	ENSG00000182054					CCDS10359, CCDS76792	OTTHUMG00000149815	147650	NM_001289910	P48735	ENSG00000182054	uc002box.4		B2R6L6|B4DFL2|Q96GT3	true	false		false	false		false	false	false	IDH2:3418	falsfalse	false	false	false	true	false	false	false	false	false	true	false	false	false	true	true	false	false	true	true	true	3	false	0	false		false	false	false	SNV	0x050268000a05000002100120	1	false	133	rs121913503																						3418	90631838	false	SITE	[745, 640|576, 448]			2483	1	93	[35, 32]	[139, 140]	[60, 60]	19						7.30	93				2809.17 ; ```. It seems that it does not matter if I choose hg19 oder 38. I used `funcotator_dataSources.v1.7.20200521s` as reference.; The call for hg38 was (I slightly shortened it for readability - usually it runs in nextflow - the hg19 call was more or less the same - the -L file is usually not only for IDH2 and has a interval_list format instead of .bed):. ```; gatk Funcotator -R reference/resources_broad_hg38_v0_Homo_sapiens_assembly38.fasta -V mutect2_out.vcf -O funcotator_out.maf --output-file-format MAF --data-sources-path reference/funcotator_dataSources.v1.7.20200521s/ --ref-version hg38 -L reference/idh2_r172.bed; ```. I will create an example test set as soon as I can, have reproducible errors for you. If you already have a hint for me to try, I would be happy to hear from you. Best regards,; Daniel",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5777#issuecomment-724975064
https://github.com/broadinstitute/gatk/issues/5777#issuecomment-731047217:65,Testability,test,test,65,"Dear @jonn-smith ,; I will invite you to a private repo with the test data. Kind regards,; Daniel",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5777#issuecomment-731047217
https://github.com/broadinstitute/gatk/issues/5777#issuecomment-740719094:29,Deployability,update,update,29,"@DanielAmsel @fpbarthel ; An update on this - for some test data Daniel sent me, Funcotator is choosing transcript `ENST00000559482.1`. For this transcript there are several exons that are not expressed, leading to `intron` annotations. This is in `CANONICAL` transcript selection mode (which is the default). For example, the locus `chr15:90631830` is intronic in that transcript:. ![image](https://user-images.githubusercontent.com/11667487/101508612-e4dac000-3945-11eb-8902-27dc889c3808.png). The details on how Funcotator chooses transcripts can be found here:; https://gatk.broadinstitute.org/hc/en-us/articles/360035889931-Funcotator-Information-and-Tutorial#2.2.2",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5777#issuecomment-740719094
https://github.com/broadinstitute/gatk/issues/5777#issuecomment-740719094:55,Testability,test,test,55,"@DanielAmsel @fpbarthel ; An update on this - for some test data Daniel sent me, Funcotator is choosing transcript `ENST00000559482.1`. For this transcript there are several exons that are not expressed, leading to `intron` annotations. This is in `CANONICAL` transcript selection mode (which is the default). For example, the locus `chr15:90631830` is intronic in that transcript:. ![image](https://user-images.githubusercontent.com/11667487/101508612-e4dac000-3945-11eb-8902-27dc889c3808.png). The details on how Funcotator chooses transcripts can be found here:; https://gatk.broadinstitute.org/hc/en-us/articles/360035889931-Funcotator-Information-and-Tutorial#2.2.2",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5777#issuecomment-740719094
https://github.com/broadinstitute/gatk/pull/5781#issuecomment-471570697:59,Performance,optimiz,optimized,59,"Prior to this, gCNV shard size and VM type have never been optimized. For WES cohort mode, we arbitrarily ran with:. 37 shards of 200 samples by 5000 intervals on n1-standard-8s (8 CPU, 30GB memory, $0.08 / hr) each taking ~2 hours = ~3 cents / sample. This PR gets rid of a memory spike in the sampling of denoised copy ratios, fixes a memory leak by updating theano, and also adds some theano flags that typically yield a factor of ~2 speedup (notably, the OpenMP elemwise flag, although we also get a slight boost from using numpy MKL). This allows us to run, e.g.: . 2 shards of 50 samples by 100000 intervals on n1-standard-8s (8 CPU, 30GB memory, $0.08 / hr) each taking ~5 hours = ~1.6 cents / sample; 4 shards of 50 samples by 50000 intervals on n1-highmem-4s (4 CPU, 26GB memory, $0.05 / hr) each taking ~3.25 hours = ~1.3 cents / sample; 45 shards of 50 samples by 5000 intervals on *n1-standard-1s* (1CPU, 3.75GB memory, $0.01 / hr) each taking ~0.5 hours = ~0.5 cents / sample. For these runs, we used a slightly larger interval list and 1/4 the number of samples than in the first example, but because everything scales linearly, it's probably fair to compare the per-sample-and-interval costs. So we get a factor of ~8 savings if we keep the shard size the same. The cost was already satisfactory, but fixing the leak allows us to more easily run scatters that are not so wide, which may be crucial for running the megaWDL. Adding the OpenMP flag also lets CPU scalability work as intended. We can do a more systematic optimization for cost if desired, and we should also revalidate to make sure performance doesn't vary too much with shard size (from spot checking, it looks like marginal and/or single-bin calls may flicker on and off). Note that we have still not optimized inference for WES, although I believe @vruano has done some optimizations for WGS. @mwalker174 @vruano for WGS with 2kb bins, I would expect the cost of the gCNV step to be ~10 cents in cohort mode before infer",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5781#issuecomment-471570697
https://github.com/broadinstitute/gatk/pull/5781#issuecomment-471570697:1475,Performance,scalab,scalability,1475," in the sampling of denoised copy ratios, fixes a memory leak by updating theano, and also adds some theano flags that typically yield a factor of ~2 speedup (notably, the OpenMP elemwise flag, although we also get a slight boost from using numpy MKL). This allows us to run, e.g.: . 2 shards of 50 samples by 100000 intervals on n1-standard-8s (8 CPU, 30GB memory, $0.08 / hr) each taking ~5 hours = ~1.6 cents / sample; 4 shards of 50 samples by 50000 intervals on n1-highmem-4s (4 CPU, 26GB memory, $0.05 / hr) each taking ~3.25 hours = ~1.3 cents / sample; 45 shards of 50 samples by 5000 intervals on *n1-standard-1s* (1CPU, 3.75GB memory, $0.01 / hr) each taking ~0.5 hours = ~0.5 cents / sample. For these runs, we used a slightly larger interval list and 1/4 the number of samples than in the first example, but because everything scales linearly, it's probably fair to compare the per-sample-and-interval costs. So we get a factor of ~8 savings if we keep the shard size the same. The cost was already satisfactory, but fixing the leak allows us to more easily run scatters that are not so wide, which may be crucial for running the megaWDL. Adding the OpenMP flag also lets CPU scalability work as intended. We can do a more systematic optimization for cost if desired, and we should also revalidate to make sure performance doesn't vary too much with shard size (from spot checking, it looks like marginal and/or single-bin calls may flicker on and off). Note that we have still not optimized inference for WES, although I believe @vruano has done some optimizations for WGS. @mwalker174 @vruano for WGS with 2kb bins, I would expect the cost of the gCNV step to be ~10 cents in cohort mode before inference optimizations, assuming we address #5716 to minimize disk costs. @asmirnov239 can you review? And maybe you can address dCR output in PostprocessGermlineCNVCalls and expose the number of samples in a separate PR? We can make some further changes to the dCR format there if we need.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5781#issuecomment-471570697
https://github.com/broadinstitute/gatk/pull/5781#issuecomment-471570697:1533,Performance,optimiz,optimization,1533," in the sampling of denoised copy ratios, fixes a memory leak by updating theano, and also adds some theano flags that typically yield a factor of ~2 speedup (notably, the OpenMP elemwise flag, although we also get a slight boost from using numpy MKL). This allows us to run, e.g.: . 2 shards of 50 samples by 100000 intervals on n1-standard-8s (8 CPU, 30GB memory, $0.08 / hr) each taking ~5 hours = ~1.6 cents / sample; 4 shards of 50 samples by 50000 intervals on n1-highmem-4s (4 CPU, 26GB memory, $0.05 / hr) each taking ~3.25 hours = ~1.3 cents / sample; 45 shards of 50 samples by 5000 intervals on *n1-standard-1s* (1CPU, 3.75GB memory, $0.01 / hr) each taking ~0.5 hours = ~0.5 cents / sample. For these runs, we used a slightly larger interval list and 1/4 the number of samples than in the first example, but because everything scales linearly, it's probably fair to compare the per-sample-and-interval costs. So we get a factor of ~8 savings if we keep the shard size the same. The cost was already satisfactory, but fixing the leak allows us to more easily run scatters that are not so wide, which may be crucial for running the megaWDL. Adding the OpenMP flag also lets CPU scalability work as intended. We can do a more systematic optimization for cost if desired, and we should also revalidate to make sure performance doesn't vary too much with shard size (from spot checking, it looks like marginal and/or single-bin calls may flicker on and off). Note that we have still not optimized inference for WES, although I believe @vruano has done some optimizations for WGS. @mwalker174 @vruano for WGS with 2kb bins, I would expect the cost of the gCNV step to be ~10 cents in cohort mode before inference optimizations, assuming we address #5716 to minimize disk costs. @asmirnov239 can you review? And maybe you can address dCR output in PostprocessGermlineCNVCalls and expose the number of samples in a separate PR? We can make some further changes to the dCR format there if we need.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5781#issuecomment-471570697
https://github.com/broadinstitute/gatk/pull/5781#issuecomment-471570697:1610,Performance,perform,performance,1610," in the sampling of denoised copy ratios, fixes a memory leak by updating theano, and also adds some theano flags that typically yield a factor of ~2 speedup (notably, the OpenMP elemwise flag, although we also get a slight boost from using numpy MKL). This allows us to run, e.g.: . 2 shards of 50 samples by 100000 intervals on n1-standard-8s (8 CPU, 30GB memory, $0.08 / hr) each taking ~5 hours = ~1.6 cents / sample; 4 shards of 50 samples by 50000 intervals on n1-highmem-4s (4 CPU, 26GB memory, $0.05 / hr) each taking ~3.25 hours = ~1.3 cents / sample; 45 shards of 50 samples by 5000 intervals on *n1-standard-1s* (1CPU, 3.75GB memory, $0.01 / hr) each taking ~0.5 hours = ~0.5 cents / sample. For these runs, we used a slightly larger interval list and 1/4 the number of samples than in the first example, but because everything scales linearly, it's probably fair to compare the per-sample-and-interval costs. So we get a factor of ~8 savings if we keep the shard size the same. The cost was already satisfactory, but fixing the leak allows us to more easily run scatters that are not so wide, which may be crucial for running the megaWDL. Adding the OpenMP flag also lets CPU scalability work as intended. We can do a more systematic optimization for cost if desired, and we should also revalidate to make sure performance doesn't vary too much with shard size (from spot checking, it looks like marginal and/or single-bin calls may flicker on and off). Note that we have still not optimized inference for WES, although I believe @vruano has done some optimizations for WGS. @mwalker174 @vruano for WGS with 2kb bins, I would expect the cost of the gCNV step to be ~10 cents in cohort mode before inference optimizations, assuming we address #5716 to minimize disk costs. @asmirnov239 can you review? And maybe you can address dCR output in PostprocessGermlineCNVCalls and expose the number of samples in a separate PR? We can make some further changes to the dCR format there if we need.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5781#issuecomment-471570697
https://github.com/broadinstitute/gatk/pull/5781#issuecomment-471570697:1781,Performance,optimiz,optimized,1781," in the sampling of denoised copy ratios, fixes a memory leak by updating theano, and also adds some theano flags that typically yield a factor of ~2 speedup (notably, the OpenMP elemwise flag, although we also get a slight boost from using numpy MKL). This allows us to run, e.g.: . 2 shards of 50 samples by 100000 intervals on n1-standard-8s (8 CPU, 30GB memory, $0.08 / hr) each taking ~5 hours = ~1.6 cents / sample; 4 shards of 50 samples by 50000 intervals on n1-highmem-4s (4 CPU, 26GB memory, $0.05 / hr) each taking ~3.25 hours = ~1.3 cents / sample; 45 shards of 50 samples by 5000 intervals on *n1-standard-1s* (1CPU, 3.75GB memory, $0.01 / hr) each taking ~0.5 hours = ~0.5 cents / sample. For these runs, we used a slightly larger interval list and 1/4 the number of samples than in the first example, but because everything scales linearly, it's probably fair to compare the per-sample-and-interval costs. So we get a factor of ~8 savings if we keep the shard size the same. The cost was already satisfactory, but fixing the leak allows us to more easily run scatters that are not so wide, which may be crucial for running the megaWDL. Adding the OpenMP flag also lets CPU scalability work as intended. We can do a more systematic optimization for cost if desired, and we should also revalidate to make sure performance doesn't vary too much with shard size (from spot checking, it looks like marginal and/or single-bin calls may flicker on and off). Note that we have still not optimized inference for WES, although I believe @vruano has done some optimizations for WGS. @mwalker174 @vruano for WGS with 2kb bins, I would expect the cost of the gCNV step to be ~10 cents in cohort mode before inference optimizations, assuming we address #5716 to minimize disk costs. @asmirnov239 can you review? And maybe you can address dCR output in PostprocessGermlineCNVCalls and expose the number of samples in a separate PR? We can make some further changes to the dCR format there if we need.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5781#issuecomment-471570697
https://github.com/broadinstitute/gatk/pull/5781#issuecomment-471570697:1851,Performance,optimiz,optimizations,1851," in the sampling of denoised copy ratios, fixes a memory leak by updating theano, and also adds some theano flags that typically yield a factor of ~2 speedup (notably, the OpenMP elemwise flag, although we also get a slight boost from using numpy MKL). This allows us to run, e.g.: . 2 shards of 50 samples by 100000 intervals on n1-standard-8s (8 CPU, 30GB memory, $0.08 / hr) each taking ~5 hours = ~1.6 cents / sample; 4 shards of 50 samples by 50000 intervals on n1-highmem-4s (4 CPU, 26GB memory, $0.05 / hr) each taking ~3.25 hours = ~1.3 cents / sample; 45 shards of 50 samples by 5000 intervals on *n1-standard-1s* (1CPU, 3.75GB memory, $0.01 / hr) each taking ~0.5 hours = ~0.5 cents / sample. For these runs, we used a slightly larger interval list and 1/4 the number of samples than in the first example, but because everything scales linearly, it's probably fair to compare the per-sample-and-interval costs. So we get a factor of ~8 savings if we keep the shard size the same. The cost was already satisfactory, but fixing the leak allows us to more easily run scatters that are not so wide, which may be crucial for running the megaWDL. Adding the OpenMP flag also lets CPU scalability work as intended. We can do a more systematic optimization for cost if desired, and we should also revalidate to make sure performance doesn't vary too much with shard size (from spot checking, it looks like marginal and/or single-bin calls may flicker on and off). Note that we have still not optimized inference for WES, although I believe @vruano has done some optimizations for WGS. @mwalker174 @vruano for WGS with 2kb bins, I would expect the cost of the gCNV step to be ~10 cents in cohort mode before inference optimizations, assuming we address #5716 to minimize disk costs. @asmirnov239 can you review? And maybe you can address dCR output in PostprocessGermlineCNVCalls and expose the number of samples in a separate PR? We can make some further changes to the dCR format there if we need.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5781#issuecomment-471570697
https://github.com/broadinstitute/gatk/pull/5781#issuecomment-471570697:2006,Performance,optimiz,optimizations,2006," in the sampling of denoised copy ratios, fixes a memory leak by updating theano, and also adds some theano flags that typically yield a factor of ~2 speedup (notably, the OpenMP elemwise flag, although we also get a slight boost from using numpy MKL). This allows us to run, e.g.: . 2 shards of 50 samples by 100000 intervals on n1-standard-8s (8 CPU, 30GB memory, $0.08 / hr) each taking ~5 hours = ~1.6 cents / sample; 4 shards of 50 samples by 50000 intervals on n1-highmem-4s (4 CPU, 26GB memory, $0.05 / hr) each taking ~3.25 hours = ~1.3 cents / sample; 45 shards of 50 samples by 5000 intervals on *n1-standard-1s* (1CPU, 3.75GB memory, $0.01 / hr) each taking ~0.5 hours = ~0.5 cents / sample. For these runs, we used a slightly larger interval list and 1/4 the number of samples than in the first example, but because everything scales linearly, it's probably fair to compare the per-sample-and-interval costs. So we get a factor of ~8 savings if we keep the shard size the same. The cost was already satisfactory, but fixing the leak allows us to more easily run scatters that are not so wide, which may be crucial for running the megaWDL. Adding the OpenMP flag also lets CPU scalability work as intended. We can do a more systematic optimization for cost if desired, and we should also revalidate to make sure performance doesn't vary too much with shard size (from spot checking, it looks like marginal and/or single-bin calls may flicker on and off). Note that we have still not optimized inference for WES, although I believe @vruano has done some optimizations for WGS. @mwalker174 @vruano for WGS with 2kb bins, I would expect the cost of the gCNV step to be ~10 cents in cohort mode before inference optimizations, assuming we address #5716 to minimize disk costs. @asmirnov239 can you review? And maybe you can address dCR output in PostprocessGermlineCNVCalls and expose the number of samples in a separate PR? We can make some further changes to the dCR format there if we need.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5781#issuecomment-471570697
https://github.com/broadinstitute/gatk/pull/5781#issuecomment-471570697:2172,Security,expose,expose,2172," in the sampling of denoised copy ratios, fixes a memory leak by updating theano, and also adds some theano flags that typically yield a factor of ~2 speedup (notably, the OpenMP elemwise flag, although we also get a slight boost from using numpy MKL). This allows us to run, e.g.: . 2 shards of 50 samples by 100000 intervals on n1-standard-8s (8 CPU, 30GB memory, $0.08 / hr) each taking ~5 hours = ~1.6 cents / sample; 4 shards of 50 samples by 50000 intervals on n1-highmem-4s (4 CPU, 26GB memory, $0.05 / hr) each taking ~3.25 hours = ~1.3 cents / sample; 45 shards of 50 samples by 5000 intervals on *n1-standard-1s* (1CPU, 3.75GB memory, $0.01 / hr) each taking ~0.5 hours = ~0.5 cents / sample. For these runs, we used a slightly larger interval list and 1/4 the number of samples than in the first example, but because everything scales linearly, it's probably fair to compare the per-sample-and-interval costs. So we get a factor of ~8 savings if we keep the shard size the same. The cost was already satisfactory, but fixing the leak allows us to more easily run scatters that are not so wide, which may be crucial for running the megaWDL. Adding the OpenMP flag also lets CPU scalability work as intended. We can do a more systematic optimization for cost if desired, and we should also revalidate to make sure performance doesn't vary too much with shard size (from spot checking, it looks like marginal and/or single-bin calls may flicker on and off). Note that we have still not optimized inference for WES, although I believe @vruano has done some optimizations for WGS. @mwalker174 @vruano for WGS with 2kb bins, I would expect the cost of the gCNV step to be ~10 cents in cohort mode before inference optimizations, assuming we address #5716 to minimize disk costs. @asmirnov239 can you review? And maybe you can address dCR output in PostprocessGermlineCNVCalls and expose the number of samples in a separate PR? We can make some further changes to the dCR format there if we need.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5781#issuecomment-471570697
https://github.com/broadinstitute/gatk/issues/5782#issuecomment-471948264:14,Testability,test,test,14,"We'll need to test on a cluster as a part of this work. One benefit will be that Spark 2.4.1 will allow us to run tests using Java 11. See https://github.com/disq-bio/disq/pull/88. (Even though it looks like Spark won't support Java 11 until Spark 3, according to https://issues.apache.org/jira/browse/SPARK-24417, Spark 2.4.1 will allow us to at least run tests using Java 11.). There are also fixes for #1524 and #3840.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5782#issuecomment-471948264
https://github.com/broadinstitute/gatk/issues/5782#issuecomment-471948264:114,Testability,test,tests,114,"We'll need to test on a cluster as a part of this work. One benefit will be that Spark 2.4.1 will allow us to run tests using Java 11. See https://github.com/disq-bio/disq/pull/88. (Even though it looks like Spark won't support Java 11 until Spark 3, according to https://issues.apache.org/jira/browse/SPARK-24417, Spark 2.4.1 will allow us to at least run tests using Java 11.). There are also fixes for #1524 and #3840.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5782#issuecomment-471948264
https://github.com/broadinstitute/gatk/issues/5782#issuecomment-471948264:357,Testability,test,tests,357,"We'll need to test on a cluster as a part of this work. One benefit will be that Spark 2.4.1 will allow us to run tests using Java 11. See https://github.com/disq-bio/disq/pull/88. (Even though it looks like Spark won't support Java 11 until Spark 3, according to https://issues.apache.org/jira/browse/SPARK-24417, Spark 2.4.1 will allow us to at least run tests using Java 11.). There are also fixes for #1524 and #3840.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5782#issuecomment-471948264
https://github.com/broadinstitute/gatk/pull/5785#issuecomment-471760837:3714,Usability,Learn,LearnReadOrientationModel,3714,1> (+1)` | |; | [...oadinstitute/hellbender/utils/hmm/HMMUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5785/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9obW0vSE1NVW5pdFRlc3QuamF2YQ==) | `80.877% <100%> (ø)` | `102 <0> (ø)` | :arrow_down: |; | [...oadinstitute/hellbender/utils/tsv/TableReader.java](https://codecov.io/gh/broadinstitute/gatk/pull/5785/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90c3YvVGFibGVSZWFkZXIuamF2YQ==) | `80.612% <100%> (+0.404%)` | `39 <1> (ø)` | :arrow_down: |; | [...lkers/mutect/filtering/Mutect2FilteringEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/5785/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9maWx0ZXJpbmcvTXV0ZWN0MkZpbHRlcmluZ0VuZ2luZS5qYXZh) | `97.938% <100%> (ø)` | `42 <1> (ø)` | :arrow_down: |; | [...walkers/readorientation/AltSiteRecordUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5785/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3JlYWRvcmllbnRhdGlvbi9BbHRTaXRlUmVjb3JkVW5pdFRlc3QuamF2YQ==) | `100% <100%> (ø)` | `10 <4> (ø)` | :arrow_down: |; | [...e/hellbender/tools/walkers/mutect/MutectStats.java](https://codecov.io/gh/broadinstitute/gatk/pull/5785/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9NdXRlY3RTdGF0cy5qYXZh) | `88.889% <100%> (+0.654%)` | `5 <2> (ø)` | :arrow_down: |; | [...ers/readorientation/LearnReadOrientationModel.java](https://codecov.io/gh/broadinstitute/gatk/pull/5785/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3JlYWRvcmllbnRhdGlvbi9MZWFyblJlYWRPcmllbnRhdGlvbk1vZGVsLmphdmE=) | `96.078% <100%> (+0.039%)` | `30 <0> (ø)` | :arrow_down: |; | ... and [90 more](https://codecov.io/gh/broadinstitute/gatk/pull/5785/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5785#issuecomment-471760837
https://github.com/broadinstitute/gatk/pull/5785#issuecomment-472529525:127,Integrability,Protocol,ProtocolError,127,"It looks like the regression test failed due to some connectivity blip:. ```; pip._vendor.requests.packages.urllib3.exceptions.ProtocolError: (""Connection broken:; ConnectionResetError(104, 'Connection reset by peer')"", ; ConnectionResetError(104, 'Connection reset by peer')); ```; In the hope it's transient, could you please restart it?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5785#issuecomment-472529525
https://github.com/broadinstitute/gatk/pull/5785#issuecomment-472529525:29,Testability,test,test,29,"It looks like the regression test failed due to some connectivity blip:. ```; pip._vendor.requests.packages.urllib3.exceptions.ProtocolError: (""Connection broken:; ConnectionResetError(104, 'Connection reset by peer')"", ; ConnectionResetError(104, 'Connection reset by peer')); ```; In the hope it's transient, could you please restart it?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5785#issuecomment-472529525
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-471963750:232,Availability,error,error-reference,232,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5787?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@d9fd22f`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `12.5%`. ```diff; @@ Coverage Diff @@; ## master #5787 +/- ##; ==========================================; Coverage ? 44.104% ; Complexity ? 19589 ; ==========================================; Files ? 1973 ; Lines ? 147147 ; Branches ? 16215 ; ==========================================; Hits ? 64898 ; Misses ? 77129 ; Partials ? 5120; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5787?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...utils/activityprofile/ActivityProfileUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5787/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9hY3Rpdml0eXByb2ZpbGUvQWN0aXZpdHlQcm9maWxlVW5pdFRlc3QuamF2YQ==) | `0.442% <0%> (ø)` | `1 <0> (?)` | |; | [...ils/optimization/PersistenceOptimizerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5787/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL3V0aWxzL29wdGltaXphdGlvbi9QZXJzaXN0ZW5jZU9wdGltaXplclVuaXRUZXN0LmphdmE=) | `2% <0%> (ø)` | `1 <0> (?)` | |; | [...utils/downsampling/DownsamplingMethodUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5787/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvRG93bnNhbXBsaW5nTWV0aG9kVW5pdFRlc3QuamF2YQ==) | `3.448% <0%> (ø)` | `1 <0> (?)` | |; | [...yper/StandardCallerArgumentCollectionUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5787/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9TdGFuZGFyZENhbGxlckFyZ3VtZW50Q29sbGVjdGlvblVuaXRUZXN0LmphdmE,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-471963750
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-471963750:1423,Availability,down,downsampling,1423, ? 19589 ; ==========================================; Files ? 1973 ; Lines ? 147147 ; Branches ? 16215 ; ==========================================; Hits ? 64898 ; Misses ? 77129 ; Partials ? 5120; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5787?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...utils/activityprofile/ActivityProfileUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5787/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9hY3Rpdml0eXByb2ZpbGUvQWN0aXZpdHlQcm9maWxlVW5pdFRlc3QuamF2YQ==) | `0.442% <0%> (ø)` | `1 <0> (?)` | |; | [...ils/optimization/PersistenceOptimizerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5787/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL3V0aWxzL29wdGltaXphdGlvbi9QZXJzaXN0ZW5jZU9wdGltaXplclVuaXRUZXN0LmphdmE=) | `2% <0%> (ø)` | `1 <0> (?)` | |; | [...utils/downsampling/DownsamplingMethodUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5787/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvRG93bnNhbXBsaW5nTWV0aG9kVW5pdFRlc3QuamF2YQ==) | `3.448% <0%> (ø)` | `1 <0> (?)` | |; | [...yper/StandardCallerArgumentCollectionUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5787/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9TdGFuZGFyZENhbGxlckFyZ3VtZW50Q29sbGVjdGlvblVuaXRUZXN0LmphdmE=) | `4.098% <0%> (ø)` | `2 <0> (?)` | |; | [...lbender/utils/mcmc/ParameterizedStateUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5787/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9tY21jL1BhcmFtZXRlcml6ZWRTdGF0ZVVuaXRUZXN0LmphdmE=) | `14.286% <0%> (ø)` | `2 <0> (?)` | |; | [...itute/hellbender/engine/ProgressMeterUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-471963750
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-471963750:1436,Availability,Down,DownsamplingMethodUnitTest,1436, ? 19589 ; ==========================================; Files ? 1973 ; Lines ? 147147 ; Branches ? 16215 ; ==========================================; Hits ? 64898 ; Misses ? 77129 ; Partials ? 5120; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5787?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...utils/activityprofile/ActivityProfileUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5787/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9hY3Rpdml0eXByb2ZpbGUvQWN0aXZpdHlQcm9maWxlVW5pdFRlc3QuamF2YQ==) | `0.442% <0%> (ø)` | `1 <0> (?)` | |; | [...ils/optimization/PersistenceOptimizerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5787/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL3V0aWxzL29wdGltaXphdGlvbi9QZXJzaXN0ZW5jZU9wdGltaXplclVuaXRUZXN0LmphdmE=) | `2% <0%> (ø)` | `1 <0> (?)` | |; | [...utils/downsampling/DownsamplingMethodUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5787/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvRG93bnNhbXBsaW5nTWV0aG9kVW5pdFRlc3QuamF2YQ==) | `3.448% <0%> (ø)` | `1 <0> (?)` | |; | [...yper/StandardCallerArgumentCollectionUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5787/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9TdGFuZGFyZENhbGxlckFyZ3VtZW50Q29sbGVjdGlvblVuaXRUZXN0LmphdmE=) | `4.098% <0%> (ø)` | `2 <0> (?)` | |; | [...lbender/utils/mcmc/ParameterizedStateUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5787/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9tY21jL1BhcmFtZXRlcml6ZWRTdGF0ZVVuaXRUZXN0LmphdmE=) | `14.286% <0%> (ø)` | `2 <0> (?)` | |; | [...itute/hellbender/engine/ProgressMeterUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-471963750
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-471963750:2068,Modifiability,Parameteriz,ParameterizedStateUnitTest,2068, <0> (?)` | |; | [...ils/optimization/PersistenceOptimizerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5787/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL3V0aWxzL29wdGltaXphdGlvbi9QZXJzaXN0ZW5jZU9wdGltaXplclVuaXRUZXN0LmphdmE=) | `2% <0%> (ø)` | `1 <0> (?)` | |; | [...utils/downsampling/DownsamplingMethodUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5787/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvRG93bnNhbXBsaW5nTWV0aG9kVW5pdFRlc3QuamF2YQ==) | `3.448% <0%> (ø)` | `1 <0> (?)` | |; | [...yper/StandardCallerArgumentCollectionUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5787/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9TdGFuZGFyZENhbGxlckFyZ3VtZW50Q29sbGVjdGlvblVuaXRUZXN0LmphdmE=) | `4.098% <0%> (ø)` | `2 <0> (?)` | |; | [...lbender/utils/mcmc/ParameterizedStateUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5787/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9tY21jL1BhcmFtZXRlcml6ZWRTdGF0ZVVuaXRUZXN0LmphdmE=) | `14.286% <0%> (ø)` | `2 <0> (?)` | |; | [...itute/hellbender/engine/ProgressMeterUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5787/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUHJvZ3Jlc3NNZXRlclVuaXRUZXN0LmphdmE=) | `1.282% <0%> (ø)` | `1 <0> (?)` | |; | [...broadinstitute/hellbender/utils/UtilsUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5787/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9VdGlsc1VuaXRUZXN0LmphdmE=) | `0.206% <0%> (ø)` | `1 <0> (?)` | |; | [...eVcfWithExpectedAlleleFractionIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5787/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlb,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-471963750
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-471963750:1097,Performance,optimiz,optimization,1097,loaded for pull request base (`master@d9fd22f`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `12.5%`. ```diff; @@ Coverage Diff @@; ## master #5787 +/- ##; ==========================================; Coverage ? 44.104% ; Complexity ? 19589 ; ==========================================; Files ? 1973 ; Lines ? 147147 ; Branches ? 16215 ; ==========================================; Hits ? 64898 ; Misses ? 77129 ; Partials ? 5120; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5787?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...utils/activityprofile/ActivityProfileUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5787/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9hY3Rpdml0eXByb2ZpbGUvQWN0aXZpdHlQcm9maWxlVW5pdFRlc3QuamF2YQ==) | `0.442% <0%> (ø)` | `1 <0> (?)` | |; | [...ils/optimization/PersistenceOptimizerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5787/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL3V0aWxzL29wdGltaXphdGlvbi9QZXJzaXN0ZW5jZU9wdGltaXplclVuaXRUZXN0LmphdmE=) | `2% <0%> (ø)` | `1 <0> (?)` | |; | [...utils/downsampling/DownsamplingMethodUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5787/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvRG93bnNhbXBsaW5nTWV0aG9kVW5pdFRlc3QuamF2YQ==) | `3.448% <0%> (ø)` | `1 <0> (?)` | |; | [...yper/StandardCallerArgumentCollectionUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5787/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9TdGFuZGFyZENhbGxlckFyZ3VtZW50Q29sbGVjdGlvblVuaXRUZXN0LmphdmE=) | `4.098% <0%> (ø)` | `2 <0> (?)` | |; | [...lbender/utils/mcmc/ParameterizedStateUnitTest.java](https://codecov,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-471963750
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-471963750:180,Usability,learn,learn,180,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5787?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@d9fd22f`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `12.5%`. ```diff; @@ Coverage Diff @@; ## master #5787 +/- ##; ==========================================; Coverage ? 44.104% ; Complexity ? 19589 ; ==========================================; Files ? 1973 ; Lines ? 147147 ; Branches ? 16215 ; ==========================================; Hits ? 64898 ; Misses ? 77129 ; Partials ? 5120; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5787?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...utils/activityprofile/ActivityProfileUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5787/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9hY3Rpdml0eXByb2ZpbGUvQWN0aXZpdHlQcm9maWxlVW5pdFRlc3QuamF2YQ==) | `0.442% <0%> (ø)` | `1 <0> (?)` | |; | [...ils/optimization/PersistenceOptimizerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5787/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL3V0aWxzL29wdGltaXphdGlvbi9QZXJzaXN0ZW5jZU9wdGltaXplclVuaXRUZXN0LmphdmE=) | `2% <0%> (ø)` | `1 <0> (?)` | |; | [...utils/downsampling/DownsamplingMethodUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5787/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvRG93bnNhbXBsaW5nTWV0aG9kVW5pdFRlc3QuamF2YQ==) | `3.448% <0%> (ø)` | `1 <0> (?)` | |; | [...yper/StandardCallerArgumentCollectionUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5787/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9TdGFuZGFyZENhbGxlckFyZ3VtZW50Q29sbGVjdGlvblVuaXRUZXN0LmphdmE,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-471963750
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:248,Availability,error,errors,248,Ohh. This looks like what we have really wanted when we refactor the test suite to test spark and other tools using the same methods. This should bring restful nights to us all. Unfortunately it looks like most of the docker tests have failed with errors along the lines of this: ; ```; org.gradle.api.internal.tasks.testing.TestSuiteExecutionException: Could not complete execution for Gradle Test Executor 1.; 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:63); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:120); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:377); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(Exec,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:2371,Availability,error,error,2371,ssorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:377); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54); 	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.testng.TestNGException:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testng.TestRunner.init(TestRunner.java:298); 	at org.testng.TestRunner.<init>(TestRunner.java:183); 	at org.testng.SuiteRunner$DefaultTestRunnerFactory.newTestRunner(S,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:1869,Integrability,Message,MessageHub,1869,ionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:120); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:377); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54); 	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.testng.TestNGException:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.Te,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:1892,Integrability,Message,MessageHub,1892,35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:120); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:377); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54); 	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.testng.TestNGException:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstan,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:56,Modifiability,refactor,refactor,56,Ohh. This looks like what we have really wanted when we refactor the test suite to test spark and other tools using the same methods. This should bring restful nights to us all. Unfortunately it looks like most of the docker tests have failed with errors along the lines of this: ; ```; org.gradle.api.internal.tasks.testing.TestSuiteExecutionException: Could not complete execution for Gradle Test Executor 1.; 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:63); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:120); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:377); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(Exec,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:1938,Performance,concurren,concurrent,1938,Dispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:120); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:377); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54); 	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.testng.TestNGException:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClas,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:2046,Performance,concurren,concurrent,2046,ispatch(ContextClassLoaderDispatch.java:32); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:120); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:377); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54); 	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.testng.TestNGException:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:2131,Performance,concurren,concurrent,2131,spatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:120); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:377); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54); 	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.testng.TestNGException:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(Tes,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:2216,Performance,concurren,concurrent,2216,com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:120); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:377); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54); 	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.testng.TestNGException:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testn,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:69,Testability,test,test,69,Ohh. This looks like what we have really wanted when we refactor the test suite to test spark and other tools using the same methods. This should bring restful nights to us all. Unfortunately it looks like most of the docker tests have failed with errors along the lines of this: ; ```; org.gradle.api.internal.tasks.testing.TestSuiteExecutionException: Could not complete execution for Gradle Test Executor 1.; 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:63); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:120); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:377); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(Exec,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:83,Testability,test,test,83,Ohh. This looks like what we have really wanted when we refactor the test suite to test spark and other tools using the same methods. This should bring restful nights to us all. Unfortunately it looks like most of the docker tests have failed with errors along the lines of this: ; ```; org.gradle.api.internal.tasks.testing.TestSuiteExecutionException: Could not complete execution for Gradle Test Executor 1.; 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:63); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:120); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:377); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(Exec,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:225,Testability,test,tests,225,Ohh. This looks like what we have really wanted when we refactor the test suite to test spark and other tools using the same methods. This should bring restful nights to us all. Unfortunately it looks like most of the docker tests have failed with errors along the lines of this: ; ```; org.gradle.api.internal.tasks.testing.TestSuiteExecutionException: Could not complete execution for Gradle Test Executor 1.; 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:63); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:120); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:377); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(Exec,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:317,Testability,test,testing,317,Ohh. This looks like what we have really wanted when we refactor the test suite to test spark and other tools using the same methods. This should bring restful nights to us all. Unfortunately it looks like most of the docker tests have failed with errors along the lines of this: ; ```; org.gradle.api.internal.tasks.testing.TestSuiteExecutionException: Could not complete execution for Gradle Test Executor 1.; 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:63); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:120); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:377); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(Exec,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:325,Testability,Test,TestSuiteExecutionException,325,Ohh. This looks like what we have really wanted when we refactor the test suite to test spark and other tools using the same methods. This should bring restful nights to us all. Unfortunately it looks like most of the docker tests have failed with errors along the lines of this: ; ```; org.gradle.api.internal.tasks.testing.TestSuiteExecutionException: Could not complete execution for Gradle Test Executor 1.; 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:63); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:120); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:377); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(Exec,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:394,Testability,Test,Test,394,Ohh. This looks like what we have really wanted when we refactor the test suite to test spark and other tools using the same methods. This should bring restful nights to us all. Unfortunately it looks like most of the docker tests have failed with errors along the lines of this: ; ```; org.gradle.api.internal.tasks.testing.TestSuiteExecutionException: Could not complete execution for Gradle Test Executor 1.; 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:63); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:120); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:377); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(Exec,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:446,Testability,test,testing,446,Ohh. This looks like what we have really wanted when we refactor the test suite to test spark and other tools using the same methods. This should bring restful nights to us all. Unfortunately it looks like most of the docker tests have failed with errors along the lines of this: ; ```; org.gradle.api.internal.tasks.testing.TestSuiteExecutionException: Could not complete execution for Gradle Test Executor 1.; 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:63); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:120); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:377); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(Exec,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:1299,Testability,test,testing,1299,nternal.tasks.testing.TestSuiteExecutionException: Could not complete execution for Gradle Test Executor 1.; 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:63); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:120); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:377); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54); 	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Th,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:1314,Testability,Test,TestWorker,1314,sting.TestSuiteExecutionException: Could not complete execution for Gradle Test Executor 1.; 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:63); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:120); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:377); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54); 	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.j,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:1330,Testability,Test,TestWorker,1330,eExecutionException: Could not complete execution for Gradle Test Executor 1.; 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:63); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:120); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:377); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54); 	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Cau,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:2345,Testability,test,testng,2345,0); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:377); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54); 	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.testng.TestNGException:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testng.TestRunner.init(TestRunner.java:298); 	at org.testng.TestRunner.<init>(TestRunner.java:183); 	at org.testng.SuiteRunner$Defau,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:2352,Testability,Test,TestNGException,2352,ssorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:377); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54); 	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.testng.TestNGException:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testng.TestRunner.init(TestRunner.java:298); 	at org.testng.TestRunner.<init>(TestRunner.java:183); 	at org.testng.SuiteRunner$DefaultTestRunnerFactory.newTestRunner(S,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:2547,Testability,test,testng,2547,e(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:377); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54); 	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.testng.TestNGException:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testng.TestRunner.init(TestRunner.java:298); 	at org.testng.TestRunner.<init>(TestRunner.java:183); 	at org.testng.SuiteRunner$DefaultTestRunnerFactory.newTestRunner(SuiteRunner.java:603); 	at org.testng.SuiteRunner.init(SuiteRunner.java:196); 	at org.testng.SuiteRunner.<init>(SuiteRunner.java:127); 	at org.testng.TestNG.createSuite,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:2647,Testability,test,testng,2647,rg.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:377); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54); 	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.testng.TestNGException:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testng.TestRunner.init(TestRunner.java:298); 	at org.testng.TestRunner.<init>(TestRunner.java:183); 	at org.testng.SuiteRunner$DefaultTestRunnerFactory.newTestRunner(SuiteRunner.java:603); 	at org.testng.SuiteRunner.init(SuiteRunner.java:196); 	at org.testng.SuiteRunner.<init>(SuiteRunner.java:127); 	at org.testng.TestNG.createSuiteRunner(TestNG.java:1231); 	at org.testng.TestNG.createSuiteRunners(TestNG.java:1210); 	at org.testng,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:2728,Testability,test,testng,2728,5); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:377); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54); 	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.testng.TestNGException:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testng.TestRunner.init(TestRunner.java:298); 	at org.testng.TestRunner.<init>(TestRunner.java:183); 	at org.testng.SuiteRunner$DefaultTestRunnerFactory.newTestRunner(SuiteRunner.java:603); 	at org.testng.SuiteRunner.init(SuiteRunner.java:196); 	at org.testng.SuiteRunner.<init>(SuiteRunner.java:127); 	at org.testng.TestNG.createSuiteRunner(TestNG.java:1231); 	at org.testng.TestNG.createSuiteRunners(TestNG.java:1210); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1058); 	at org.testng.TestNG.runSuites(TestN,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:2802,Testability,test,testng,2802,nDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:377); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54); 	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.testng.TestNGException:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testng.TestRunner.init(TestRunner.java:298); 	at org.testng.TestRunner.<init>(TestRunner.java:183); 	at org.testng.SuiteRunner$DefaultTestRunnerFactory.newTestRunner(SuiteRunner.java:603); 	at org.testng.SuiteRunner.init(SuiteRunner.java:196); 	at org.testng.SuiteRunner.<init>(SuiteRunner.java:127); 	at org.testng.TestNG.createSuiteRunner(TestNG.java:1231); 	at org.testng.TestNG.createSuiteRunners(TestNG.java:1210); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1058); 	at org.testng.TestNG.runSuites(TestNG.java:997); 	at org.testng.TestNG.run(TestNG.java:965); 	at org.gradle.ap,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:2870,Testability,test,testng,2870,ageHub$Handler.run(MessageHub.java:377); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54); 	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.testng.TestNGException:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testng.TestRunner.init(TestRunner.java:298); 	at org.testng.TestRunner.<init>(TestRunner.java:183); 	at org.testng.SuiteRunner$DefaultTestRunnerFactory.newTestRunner(SuiteRunner.java:603); 	at org.testng.SuiteRunner.init(SuiteRunner.java:196); 	at org.testng.SuiteRunner.<init>(SuiteRunner.java:127); 	at org.testng.TestNG.createSuiteRunner(TestNG.java:1231); 	at org.testng.TestNG.createSuiteRunners(TestNG.java:1210); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1058); 	at org.testng.TestNG.runSuites(TestNG.java:997); 	at org.testng.TestNG.run(TestNG.java:965); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(Te,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:2877,Testability,Test,TestClass,2877,ndler.run(MessageHub.java:377); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54); 	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.testng.TestNGException:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testng.TestRunner.init(TestRunner.java:298); 	at org.testng.TestRunner.<init>(TestRunner.java:183); 	at org.testng.SuiteRunner$DefaultTestRunnerFactory.newTestRunner(SuiteRunner.java:603); 	at org.testng.SuiteRunner.init(SuiteRunner.java:196); 	at org.testng.SuiteRunner.<init>(SuiteRunner.java:127); 	at org.testng.TestNG.createSuiteRunner(TestNG.java:1231); 	at org.testng.TestNG.createSuiteRunners(TestNG.java:1210); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1058); 	at org.testng.TestNG.runSuites(TestNG.java:997); 	at org.testng.TestNG.run(TestNG.java:965); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTest,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:2900,Testability,Test,TestClass,2900,eHub.java:377); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54); 	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.testng.TestNGException:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testng.TestRunner.init(TestRunner.java:298); 	at org.testng.TestRunner.<init>(TestRunner.java:183); 	at org.testng.SuiteRunner$DefaultTestRunnerFactory.newTestRunner(SuiteRunner.java:603); 	at org.testng.SuiteRunner.init(SuiteRunner.java:196); 	at org.testng.SuiteRunner.<init>(SuiteRunner.java:127); 	at org.testng.TestNG.createSuiteRunner(TestNG.java:1231); 	at org.testng.TestNG.createSuiteRunners(TestNG.java:1210); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1058); 	at org.testng.TestNG.runSuites(TestNG.java:997); 	at org.testng.TestNG.run(TestNG.java:965); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.ja,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:2929,Testability,test,testng,2929,ernal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54); 	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.testng.TestNGException:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testng.TestRunner.init(TestRunner.java:298); 	at org.testng.TestRunner.<init>(TestRunner.java:183); 	at org.testng.SuiteRunner$DefaultTestRunnerFactory.newTestRunner(SuiteRunner.java:603); 	at org.testng.SuiteRunner.init(SuiteRunner.java:196); 	at org.testng.SuiteRunner.<init>(SuiteRunner.java:127); 	at org.testng.TestNG.createSuiteRunner(TestNG.java:1231); 	at org.testng.TestNG.createSuiteRunners(TestNG.java:1210); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1058); 	at org.testng.TestNG.runSuites(TestNG.java:997); 	at org.testng.TestNG.run(TestNG.java:965); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.intern,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:2936,Testability,Test,TestClass,2936,current.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:54); 	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.testng.TestNGException:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testng.TestRunner.init(TestRunner.java:298); 	at org.testng.TestRunner.<init>(TestRunner.java:183); 	at org.testng.SuiteRunner$DefaultTestRunnerFactory.newTestRunner(SuiteRunner.java:603); 	at org.testng.SuiteRunner.init(SuiteRunner.java:196); 	at org.testng.SuiteRunner.<init>(SuiteRunner.java:127); 	at org.testng.TestNG.createSuiteRunner(TestNG.java:1231); 	at org.testng.TestNG.createSuiteRunners(TestNG.java:1210); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1058); 	at org.testng.TestNG.runSuites(TestNG.java:997); 	at org.testng.TestNG.run(TestNG.java:965); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tasks,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:2974,Testability,Test,TestClass,2974,atchAndRecordFailures.onExecute(ExecutorPolicy.java:54); 	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.testng.TestNGException:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testng.TestRunner.init(TestRunner.java:298); 	at org.testng.TestRunner.<init>(TestRunner.java:183); 	at org.testng.SuiteRunner$DefaultTestRunnerFactory.newTestRunner(SuiteRunner.java:603); 	at org.testng.SuiteRunner.init(SuiteRunner.java:196); 	at org.testng.SuiteRunner.<init>(SuiteRunner.java:127); 	at org.testng.TestNG.createSuiteRunner(TestNG.java:1231); 	at org.testng.TestNG.createSuiteRunners(TestNG.java:1210); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1058); 	at org.testng.TestNG.runSuites(TestNG.java:997); 	at org.testng.TestNG.run(TestNG.java:965); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTe,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:3002,Testability,test,testng,3002,Policy.java:54); 	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.testng.TestNGException:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testng.TestRunner.init(TestRunner.java:298); 	at org.testng.TestRunner.<init>(TestRunner.java:183); 	at org.testng.SuiteRunner$DefaultTestRunnerFactory.newTestRunner(SuiteRunner.java:603); 	at org.testng.SuiteRunner.init(SuiteRunner.java:196); 	at org.testng.SuiteRunner.<init>(SuiteRunner.java:127); 	at org.testng.TestNG.createSuiteRunner(TestNG.java:1231); 	at org.testng.TestNG.createSuiteRunners(TestNG.java:1210); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1058); 	at org.testng.TestNG.runSuites(TestNG.java:997); 	at org.testng.TestNG.run(TestNG.java:965); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProc,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:3009,Testability,Test,TestClass,3009,va:54); 	at org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.testng.TestNGException:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testng.TestRunner.init(TestRunner.java:298); 	at org.testng.TestRunner.<init>(TestRunner.java:183); 	at org.testng.SuiteRunner$DefaultTestRunnerFactory.newTestRunner(SuiteRunner.java:603); 	at org.testng.SuiteRunner.init(SuiteRunner.java:196); 	at org.testng.SuiteRunner.<init>(SuiteRunner.java:127); 	at org.testng.TestNG.createSuiteRunner(TestNG.java:1231); 	at org.testng.TestNG.createSuiteRunners(TestNG.java:1210); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1058); 	at org.testng.TestNG.runSuites(TestNG.java:997); 	at org.testng.TestNG.run(TestNG.java:965); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.ja,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:3024,Testability,Test,TestClass,3024,org.gradle.internal.concurrent.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.testng.TestNGException:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testng.TestRunner.init(TestRunner.java:298); 	at org.testng.TestRunner.<init>(TestRunner.java:183); 	at org.testng.SuiteRunner$DefaultTestRunnerFactory.newTestRunner(SuiteRunner.java:603); 	at org.testng.SuiteRunner.init(SuiteRunner.java:196); 	at org.testng.SuiteRunner.<init>(SuiteRunner.java:127); 	at org.testng.TestNG.createSuiteRunner(TestNG.java:1231); 	at org.testng.TestNG.createSuiteRunners(TestNG.java:1210); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1058); 	at org.testng.TestNG.runSuites(TestNG.java:997); 	at org.testng.TestNG.run(TestNG.java:965); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:88); 	at o,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:3052,Testability,test,testng,3052,t.StoppableExecutorImpl$1.run(StoppableExecutorImpl.java:40); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.testng.TestNGException:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testng.TestRunner.init(TestRunner.java:298); 	at org.testng.TestRunner.<init>(TestRunner.java:183); 	at org.testng.SuiteRunner$DefaultTestRunnerFactory.newTestRunner(SuiteRunner.java:603); 	at org.testng.SuiteRunner.init(SuiteRunner.java:196); 	at org.testng.SuiteRunner.<init>(SuiteRunner.java:127); 	at org.testng.TestNG.createSuiteRunner(TestNG.java:1231); 	at org.testng.TestNG.createSuiteRunners(TestNG.java:1210); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1058); 	at org.testng.TestNG.runSuites(TestNG.java:997); 	at org.testng.TestNG.run(TestNG.java:965); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:88); 	at org.gradle.api.internal.tasks.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:3059,Testability,Test,TestClass,3059,leExecutorImpl$1.run(StoppableExecutorImpl.java:40); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.testng.TestNGException:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testng.TestRunner.init(TestRunner.java:298); 	at org.testng.TestRunner.<init>(TestRunner.java:183); 	at org.testng.SuiteRunner$DefaultTestRunnerFactory.newTestRunner(SuiteRunner.java:603); 	at org.testng.SuiteRunner.init(SuiteRunner.java:196); 	at org.testng.SuiteRunner.<init>(SuiteRunner.java:127); 	at org.testng.TestNG.createSuiteRunner(TestNG.java:1231); 	at org.testng.TestNG.createSuiteRunners(TestNG.java:1210); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1058); 	at org.testng.TestNG.runSuites(TestNG.java:997); 	at org.testng.TestNG.run(TestNG.java:965); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:88); 	at org.gradle.api.internal.tasks.testing.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:3076,Testability,Test,TestClass,3076,l$1.run(StoppableExecutorImpl.java:40); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.testng.TestNGException:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testng.TestRunner.init(TestRunner.java:298); 	at org.testng.TestRunner.<init>(TestRunner.java:183); 	at org.testng.SuiteRunner$DefaultTestRunnerFactory.newTestRunner(SuiteRunner.java:603); 	at org.testng.SuiteRunner.init(SuiteRunner.java:196); 	at org.testng.SuiteRunner.<init>(SuiteRunner.java:127); 	at org.testng.TestNG.createSuiteRunner(TestNG.java:1231); 	at org.testng.TestNG.createSuiteRunners(TestNG.java:1210); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1058); 	at org.testng.TestNG.runSuites(TestNG.java:997); 	at org.testng.TestNG.run(TestNG.java:965); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:88); 	at org.gradle.api.internal.tasks.testing.SuiteTestClass,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:3104,Testability,test,testng,3104,java:40); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.testng.TestNGException:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testng.TestRunner.init(TestRunner.java:298); 	at org.testng.TestRunner.<init>(TestRunner.java:183); 	at org.testng.SuiteRunner$DefaultTestRunnerFactory.newTestRunner(SuiteRunner.java:603); 	at org.testng.SuiteRunner.init(SuiteRunner.java:196); 	at org.testng.SuiteRunner.<init>(SuiteRunner.java:127); 	at org.testng.TestNG.createSuiteRunner(TestNG.java:1231); 	at org.testng.TestNG.createSuiteRunners(TestNG.java:1210); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1058); 	at org.testng.TestNG.runSuites(TestNG.java:997); 	at org.testng.TestNG.run(TestNG.java:965); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:88); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassP,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:3111,Testability,Test,TestRunner,3111, 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.testng.TestNGException:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testng.TestRunner.init(TestRunner.java:298); 	at org.testng.TestRunner.<init>(TestRunner.java:183); 	at org.testng.SuiteRunner$DefaultTestRunnerFactory.newTestRunner(SuiteRunner.java:603); 	at org.testng.SuiteRunner.init(SuiteRunner.java:196); 	at org.testng.SuiteRunner.<init>(SuiteRunner.java:127); 	at org.testng.TestNG.createSuiteRunner(TestNG.java:1231); 	at org.testng.TestNG.createSuiteRunners(TestNG.java:1210); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1058); 	at org.testng.TestNG.runSuites(TestNG.java:997); 	at org.testng.TestNG.run(TestNG.java:965); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:88); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:3134,Testability,Test,TestRunner,3134,ncurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.testng.TestNGException:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testng.TestRunner.init(TestRunner.java:298); 	at org.testng.TestRunner.<init>(TestRunner.java:183); 	at org.testng.SuiteRunner$DefaultTestRunnerFactory.newTestRunner(SuiteRunner.java:603); 	at org.testng.SuiteRunner.init(SuiteRunner.java:196); 	at org.testng.SuiteRunner.<init>(SuiteRunner.java:127); 	at org.testng.TestNG.createSuiteRunner(TestNG.java:1231); 	at org.testng.TestNG.createSuiteRunners(TestNG.java:1210); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1058); 	at org.testng.TestNG.runSuites(TestNG.java:997); 	at org.testng.TestNG.run(TestNG.java:965); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:88); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	... 22,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:3164,Testability,test,testng,3164,ker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.testng.TestNGException:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testng.TestRunner.init(TestRunner.java:298); 	at org.testng.TestRunner.<init>(TestRunner.java:183); 	at org.testng.SuiteRunner$DefaultTestRunnerFactory.newTestRunner(SuiteRunner.java:603); 	at org.testng.SuiteRunner.init(SuiteRunner.java:196); 	at org.testng.SuiteRunner.<init>(SuiteRunner.java:127); 	at org.testng.TestNG.createSuiteRunner(TestNG.java:1231); 	at org.testng.TestNG.createSuiteRunners(TestNG.java:1210); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1058); 	at org.testng.TestNG.runSuites(TestNG.java:997); 	at org.testng.TestNG.run(TestNG.java:965); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:88); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	... 22 more; ```; It looks to me that th,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:3171,Testability,Test,TestRunner,3171,dPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.testng.TestNGException:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testng.TestRunner.init(TestRunner.java:298); 	at org.testng.TestRunner.<init>(TestRunner.java:183); 	at org.testng.SuiteRunner$DefaultTestRunnerFactory.newTestRunner(SuiteRunner.java:603); 	at org.testng.SuiteRunner.init(SuiteRunner.java:196); 	at org.testng.SuiteRunner.<init>(SuiteRunner.java:127); 	at org.testng.TestNG.createSuiteRunner(TestNG.java:1231); 	at org.testng.TestNG.createSuiteRunners(TestNG.java:1210); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1058); 	at org.testng.TestNG.runSuites(TestNG.java:997); 	at org.testng.TestNG.run(TestNG.java:965); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:88); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	... 22 more; ```; It looks to me that this change,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:3187,Testability,Test,TestRunner,3187,java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.testng.TestNGException:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testng.TestRunner.init(TestRunner.java:298); 	at org.testng.TestRunner.<init>(TestRunner.java:183); 	at org.testng.SuiteRunner$DefaultTestRunnerFactory.newTestRunner(SuiteRunner.java:603); 	at org.testng.SuiteRunner.init(SuiteRunner.java:196); 	at org.testng.SuiteRunner.<init>(SuiteRunner.java:127); 	at org.testng.TestNG.createSuiteRunner(TestNG.java:1231); 	at org.testng.TestNG.createSuiteRunners(TestNG.java:1210); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1058); 	at org.testng.TestNG.runSuites(TestNG.java:997); 	at org.testng.TestNG.run(TestNG.java:965); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:88); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	... 22 more; ```; It looks to me that this change is whats fai,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:3217,Testability,test,testng,3217,urrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.testng.TestNGException:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testng.TestRunner.init(TestRunner.java:298); 	at org.testng.TestRunner.<init>(TestRunner.java:183); 	at org.testng.SuiteRunner$DefaultTestRunnerFactory.newTestRunner(SuiteRunner.java:603); 	at org.testng.SuiteRunner.init(SuiteRunner.java:196); 	at org.testng.SuiteRunner.<init>(SuiteRunner.java:127); 	at org.testng.TestNG.createSuiteRunner(TestNG.java:1231); 	at org.testng.TestNG.createSuiteRunners(TestNG.java:1210); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1058); 	at org.testng.TestNG.runSuites(TestNG.java:997); 	at org.testng.TestNG.run(TestNG.java:965); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:88); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	... 22 more; ```; It looks to me that this change is whats failing? https://github.com/cbeust,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:3224,Testability,Test,TestRunner,3224,readPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.testng.TestNGException:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testng.TestRunner.init(TestRunner.java:298); 	at org.testng.TestRunner.<init>(TestRunner.java:183); 	at org.testng.SuiteRunner$DefaultTestRunnerFactory.newTestRunner(SuiteRunner.java:603); 	at org.testng.SuiteRunner.init(SuiteRunner.java:196); 	at org.testng.SuiteRunner.<init>(SuiteRunner.java:127); 	at org.testng.TestNG.createSuiteRunner(TestNG.java:1231); 	at org.testng.TestNG.createSuiteRunners(TestNG.java:1210); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1058); 	at org.testng.TestNG.runSuites(TestNG.java:997); 	at org.testng.TestNG.run(TestNG.java:965); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:88); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	... 22 more; ```; It looks to me that this change is whats failing? https://github.com/cbeust/testng/p,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:3240,Testability,Test,TestRunner,3240,or$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.testng.TestNGException:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testng.TestRunner.init(TestRunner.java:298); 	at org.testng.TestRunner.<init>(TestRunner.java:183); 	at org.testng.SuiteRunner$DefaultTestRunnerFactory.newTestRunner(SuiteRunner.java:603); 	at org.testng.SuiteRunner.init(SuiteRunner.java:196); 	at org.testng.SuiteRunner.<init>(SuiteRunner.java:127); 	at org.testng.TestNG.createSuiteRunner(TestNG.java:1231); 	at org.testng.TestNG.createSuiteRunners(TestNG.java:1210); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1058); 	at org.testng.TestNG.runSuites(TestNG.java:997); 	at org.testng.TestNG.run(TestNG.java:965); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:88); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	... 22 more; ```; It looks to me that this change is whats failing? https://github.com/cbeust/testng/pull/1848/file,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:3270,Testability,test,testng,3270,or.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.testng.TestNGException:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testng.TestRunner.init(TestRunner.java:298); 	at org.testng.TestRunner.<init>(TestRunner.java:183); 	at org.testng.SuiteRunner$DefaultTestRunnerFactory.newTestRunner(SuiteRunner.java:603); 	at org.testng.SuiteRunner.init(SuiteRunner.java:196); 	at org.testng.SuiteRunner.<init>(SuiteRunner.java:127); 	at org.testng.TestNG.createSuiteRunner(TestNG.java:1231); 	at org.testng.TestNG.createSuiteRunners(TestNG.java:1210); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1058); 	at org.testng.TestNG.runSuites(TestNG.java:997); 	at org.testng.TestNG.run(TestNG.java:965); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:88); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	... 22 more; ```; It looks to me that this change is whats failing? https://github.com/cbeust/testng/pull/1848/files. We have test classes that ca,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:3277,Testability,Test,TestRunner,3277,24); 	at java.lang.Thread.run(Thread.java:748); Caused by: org.testng.TestNGException:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testng.TestRunner.init(TestRunner.java:298); 	at org.testng.TestRunner.<init>(TestRunner.java:183); 	at org.testng.SuiteRunner$DefaultTestRunnerFactory.newTestRunner(SuiteRunner.java:603); 	at org.testng.SuiteRunner.init(SuiteRunner.java:196); 	at org.testng.SuiteRunner.<init>(SuiteRunner.java:127); 	at org.testng.TestNG.createSuiteRunner(TestNG.java:1231); 	at org.testng.TestNG.createSuiteRunners(TestNG.java:1210); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1058); 	at org.testng.TestNG.runSuites(TestNG.java:997); 	at org.testng.TestNG.run(TestNG.java:965); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:88); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	... 22 more; ```; It looks to me that this change is whats failing? https://github.com/cbeust/testng/pull/1848/files. We have test classes that can't be pr,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:3295,Testability,Test,TestRunner,3295,ang.Thread.run(Thread.java:748); Caused by: org.testng.TestNGException:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testng.TestRunner.init(TestRunner.java:298); 	at org.testng.TestRunner.<init>(TestRunner.java:183); 	at org.testng.SuiteRunner$DefaultTestRunnerFactory.newTestRunner(SuiteRunner.java:603); 	at org.testng.SuiteRunner.init(SuiteRunner.java:196); 	at org.testng.SuiteRunner.<init>(SuiteRunner.java:127); 	at org.testng.TestNG.createSuiteRunner(TestNG.java:1231); 	at org.testng.TestNG.createSuiteRunners(TestNG.java:1210); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1058); 	at org.testng.TestNG.runSuites(TestNG.java:997); 	at org.testng.TestNG.run(TestNG.java:965); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:88); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	... 22 more; ```; It looks to me that this change is whats failing? https://github.com/cbeust/testng/pull/1848/files. We have test classes that can't be properly instant,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:3325,Testability,test,testng,3325,; Caused by: org.testng.TestNGException:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testng.TestRunner.init(TestRunner.java:298); 	at org.testng.TestRunner.<init>(TestRunner.java:183); 	at org.testng.SuiteRunner$DefaultTestRunnerFactory.newTestRunner(SuiteRunner.java:603); 	at org.testng.SuiteRunner.init(SuiteRunner.java:196); 	at org.testng.SuiteRunner.<init>(SuiteRunner.java:127); 	at org.testng.TestNG.createSuiteRunner(TestNG.java:1231); 	at org.testng.TestNG.createSuiteRunners(TestNG.java:1210); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1058); 	at org.testng.TestNG.runSuites(TestNG.java:997); 	at org.testng.TestNG.run(TestNG.java:965); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:88); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	... 22 more; ```; It looks to me that this change is whats failing? https://github.com/cbeust/testng/pull/1848/files. We have test classes that can't be properly instantiated in our suite that causes t,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:3414,Testability,test,testng,3414,:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testng.TestRunner.init(TestRunner.java:298); 	at org.testng.TestRunner.<init>(TestRunner.java:183); 	at org.testng.SuiteRunner$DefaultTestRunnerFactory.newTestRunner(SuiteRunner.java:603); 	at org.testng.SuiteRunner.init(SuiteRunner.java:196); 	at org.testng.SuiteRunner.<init>(SuiteRunner.java:127); 	at org.testng.TestNG.createSuiteRunner(TestNG.java:1231); 	at org.testng.TestNG.createSuiteRunners(TestNG.java:1210); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1058); 	at org.testng.TestNG.runSuites(TestNG.java:997); 	at org.testng.TestNG.run(TestNG.java:965); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:88); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	... 22 more; ```; It looks to me that this change is whats failing? https://github.com/cbeust/testng/pull/1848/files. We have test classes that can't be properly instantiated in our suite that causes the new version of testNG to fall over.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:3469,Testability,test,testng,3469,:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testng.TestRunner.init(TestRunner.java:298); 	at org.testng.TestRunner.<init>(TestRunner.java:183); 	at org.testng.SuiteRunner$DefaultTestRunnerFactory.newTestRunner(SuiteRunner.java:603); 	at org.testng.SuiteRunner.init(SuiteRunner.java:196); 	at org.testng.SuiteRunner.<init>(SuiteRunner.java:127); 	at org.testng.TestNG.createSuiteRunner(TestNG.java:1231); 	at org.testng.TestNG.createSuiteRunners(TestNG.java:1210); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1058); 	at org.testng.TestNG.runSuites(TestNG.java:997); 	at org.testng.TestNG.run(TestNG.java:965); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:88); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	... 22 more; ```; It looks to me that this change is whats failing? https://github.com/cbeust/testng/pull/1848/files. We have test classes that can't be properly instantiated in our suite that causes the new version of testNG to fall over.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:3526,Testability,test,testng,3526,:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testng.TestRunner.init(TestRunner.java:298); 	at org.testng.TestRunner.<init>(TestRunner.java:183); 	at org.testng.SuiteRunner$DefaultTestRunnerFactory.newTestRunner(SuiteRunner.java:603); 	at org.testng.SuiteRunner.init(SuiteRunner.java:196); 	at org.testng.SuiteRunner.<init>(SuiteRunner.java:127); 	at org.testng.TestNG.createSuiteRunner(TestNG.java:1231); 	at org.testng.TestNG.createSuiteRunners(TestNG.java:1210); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1058); 	at org.testng.TestNG.runSuites(TestNG.java:997); 	at org.testng.TestNG.run(TestNG.java:965); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:88); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	... 22 more; ```; It looks to me that this change is whats failing? https://github.com/cbeust/testng/pull/1848/files. We have test classes that can't be properly instantiated in our suite that causes the new version of testNG to fall over.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:3533,Testability,Test,TestNG,3533,:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testng.TestRunner.init(TestRunner.java:298); 	at org.testng.TestRunner.<init>(TestRunner.java:183); 	at org.testng.SuiteRunner$DefaultTestRunnerFactory.newTestRunner(SuiteRunner.java:603); 	at org.testng.SuiteRunner.init(SuiteRunner.java:196); 	at org.testng.SuiteRunner.<init>(SuiteRunner.java:127); 	at org.testng.TestNG.createSuiteRunner(TestNG.java:1231); 	at org.testng.TestNG.createSuiteRunners(TestNG.java:1210); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1058); 	at org.testng.TestNG.runSuites(TestNG.java:997); 	at org.testng.TestNG.run(TestNG.java:965); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:88); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	... 22 more; ```; It looks to me that this change is whats failing? https://github.com/cbeust/testng/pull/1848/files. We have test classes that can't be properly instantiated in our suite that causes the new version of testNG to fall over.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:3558,Testability,Test,TestNG,3558,:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testng.TestRunner.init(TestRunner.java:298); 	at org.testng.TestRunner.<init>(TestRunner.java:183); 	at org.testng.SuiteRunner$DefaultTestRunnerFactory.newTestRunner(SuiteRunner.java:603); 	at org.testng.SuiteRunner.init(SuiteRunner.java:196); 	at org.testng.SuiteRunner.<init>(SuiteRunner.java:127); 	at org.testng.TestNG.createSuiteRunner(TestNG.java:1231); 	at org.testng.TestNG.createSuiteRunners(TestNG.java:1210); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1058); 	at org.testng.TestNG.runSuites(TestNG.java:997); 	at org.testng.TestNG.run(TestNG.java:965); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:88); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	... 22 more; ```; It looks to me that this change is whats failing? https://github.com/cbeust/testng/pull/1848/files. We have test classes that can't be properly instantiated in our suite that causes the new version of testNG to fall over.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:3585,Testability,test,testng,3585,:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testng.TestRunner.init(TestRunner.java:298); 	at org.testng.TestRunner.<init>(TestRunner.java:183); 	at org.testng.SuiteRunner$DefaultTestRunnerFactory.newTestRunner(SuiteRunner.java:603); 	at org.testng.SuiteRunner.init(SuiteRunner.java:196); 	at org.testng.SuiteRunner.<init>(SuiteRunner.java:127); 	at org.testng.TestNG.createSuiteRunner(TestNG.java:1231); 	at org.testng.TestNG.createSuiteRunners(TestNG.java:1210); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1058); 	at org.testng.TestNG.runSuites(TestNG.java:997); 	at org.testng.TestNG.run(TestNG.java:965); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:88); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	... 22 more; ```; It looks to me that this change is whats failing? https://github.com/cbeust/testng/pull/1848/files. We have test classes that can't be properly instantiated in our suite that causes the new version of testNG to fall over.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:3592,Testability,Test,TestNG,3592,:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testng.TestRunner.init(TestRunner.java:298); 	at org.testng.TestRunner.<init>(TestRunner.java:183); 	at org.testng.SuiteRunner$DefaultTestRunnerFactory.newTestRunner(SuiteRunner.java:603); 	at org.testng.SuiteRunner.init(SuiteRunner.java:196); 	at org.testng.SuiteRunner.<init>(SuiteRunner.java:127); 	at org.testng.TestNG.createSuiteRunner(TestNG.java:1231); 	at org.testng.TestNG.createSuiteRunners(TestNG.java:1210); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1058); 	at org.testng.TestNG.runSuites(TestNG.java:997); 	at org.testng.TestNG.run(TestNG.java:965); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:88); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	... 22 more; ```; It looks to me that this change is whats failing? https://github.com/cbeust/testng/pull/1848/files. We have test classes that can't be properly instantiated in our suite that causes the new version of testNG to fall over.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:3618,Testability,Test,TestNG,3618,:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testng.TestRunner.init(TestRunner.java:298); 	at org.testng.TestRunner.<init>(TestRunner.java:183); 	at org.testng.SuiteRunner$DefaultTestRunnerFactory.newTestRunner(SuiteRunner.java:603); 	at org.testng.SuiteRunner.init(SuiteRunner.java:196); 	at org.testng.SuiteRunner.<init>(SuiteRunner.java:127); 	at org.testng.TestNG.createSuiteRunner(TestNG.java:1231); 	at org.testng.TestNG.createSuiteRunners(TestNG.java:1210); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1058); 	at org.testng.TestNG.runSuites(TestNG.java:997); 	at org.testng.TestNG.run(TestNG.java:965); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:88); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	... 22 more; ```; It looks to me that this change is whats failing? https://github.com/cbeust/testng/pull/1848/files. We have test classes that can't be properly instantiated in our suite that causes the new version of testNG to fall over.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:3645,Testability,test,testng,3645,:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testng.TestRunner.init(TestRunner.java:298); 	at org.testng.TestRunner.<init>(TestRunner.java:183); 	at org.testng.SuiteRunner$DefaultTestRunnerFactory.newTestRunner(SuiteRunner.java:603); 	at org.testng.SuiteRunner.init(SuiteRunner.java:196); 	at org.testng.SuiteRunner.<init>(SuiteRunner.java:127); 	at org.testng.TestNG.createSuiteRunner(TestNG.java:1231); 	at org.testng.TestNG.createSuiteRunners(TestNG.java:1210); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1058); 	at org.testng.TestNG.runSuites(TestNG.java:997); 	at org.testng.TestNG.run(TestNG.java:965); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:88); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	... 22 more; ```; It looks to me that this change is whats failing? https://github.com/cbeust/testng/pull/1848/files. We have test classes that can't be properly instantiated in our suite that causes the new version of testNG to fall over.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:3652,Testability,Test,TestNG,3652,:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testng.TestRunner.init(TestRunner.java:298); 	at org.testng.TestRunner.<init>(TestRunner.java:183); 	at org.testng.SuiteRunner$DefaultTestRunnerFactory.newTestRunner(SuiteRunner.java:603); 	at org.testng.SuiteRunner.init(SuiteRunner.java:196); 	at org.testng.SuiteRunner.<init>(SuiteRunner.java:127); 	at org.testng.TestNG.createSuiteRunner(TestNG.java:1231); 	at org.testng.TestNG.createSuiteRunners(TestNG.java:1210); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1058); 	at org.testng.TestNG.runSuites(TestNG.java:997); 	at org.testng.TestNG.run(TestNG.java:965); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:88); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	... 22 more; ```; It looks to me that this change is whats failing? https://github.com/cbeust/testng/pull/1848/files. We have test classes that can't be properly instantiated in our suite that causes the new version of testNG to fall over.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:3676,Testability,Test,TestNG,3676,:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testng.TestRunner.init(TestRunner.java:298); 	at org.testng.TestRunner.<init>(TestRunner.java:183); 	at org.testng.SuiteRunner$DefaultTestRunnerFactory.newTestRunner(SuiteRunner.java:603); 	at org.testng.SuiteRunner.init(SuiteRunner.java:196); 	at org.testng.SuiteRunner.<init>(SuiteRunner.java:127); 	at org.testng.TestNG.createSuiteRunner(TestNG.java:1231); 	at org.testng.TestNG.createSuiteRunners(TestNG.java:1210); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1058); 	at org.testng.TestNG.runSuites(TestNG.java:997); 	at org.testng.TestNG.run(TestNG.java:965); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:88); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	... 22 more; ```; It looks to me that this change is whats failing? https://github.com/cbeust/testng/pull/1848/files. We have test classes that can't be properly instantiated in our suite that causes the new version of testNG to fall over.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:3703,Testability,test,testng,3703,:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testng.TestRunner.init(TestRunner.java:298); 	at org.testng.TestRunner.<init>(TestRunner.java:183); 	at org.testng.SuiteRunner$DefaultTestRunnerFactory.newTestRunner(SuiteRunner.java:603); 	at org.testng.SuiteRunner.init(SuiteRunner.java:196); 	at org.testng.SuiteRunner.<init>(SuiteRunner.java:127); 	at org.testng.TestNG.createSuiteRunner(TestNG.java:1231); 	at org.testng.TestNG.createSuiteRunners(TestNG.java:1210); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1058); 	at org.testng.TestNG.runSuites(TestNG.java:997); 	at org.testng.TestNG.run(TestNG.java:965); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:88); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	... 22 more; ```; It looks to me that this change is whats failing? https://github.com/cbeust/testng/pull/1848/files. We have test classes that can't be properly instantiated in our suite that causes the new version of testNG to fall over.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:3710,Testability,Test,TestNG,3710,:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testng.TestRunner.init(TestRunner.java:298); 	at org.testng.TestRunner.<init>(TestRunner.java:183); 	at org.testng.SuiteRunner$DefaultTestRunnerFactory.newTestRunner(SuiteRunner.java:603); 	at org.testng.SuiteRunner.init(SuiteRunner.java:196); 	at org.testng.SuiteRunner.<init>(SuiteRunner.java:127); 	at org.testng.TestNG.createSuiteRunner(TestNG.java:1231); 	at org.testng.TestNG.createSuiteRunners(TestNG.java:1210); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1058); 	at org.testng.TestNG.runSuites(TestNG.java:997); 	at org.testng.TestNG.run(TestNG.java:965); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:88); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	... 22 more; ```; It looks to me that this change is whats failing? https://github.com/cbeust/testng/pull/1848/files. We have test classes that can't be properly instantiated in our suite that causes the new version of testNG to fall over.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:3727,Testability,Test,TestNG,3727,:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testng.TestRunner.init(TestRunner.java:298); 	at org.testng.TestRunner.<init>(TestRunner.java:183); 	at org.testng.SuiteRunner$DefaultTestRunnerFactory.newTestRunner(SuiteRunner.java:603); 	at org.testng.SuiteRunner.init(SuiteRunner.java:196); 	at org.testng.SuiteRunner.<init>(SuiteRunner.java:127); 	at org.testng.TestNG.createSuiteRunner(TestNG.java:1231); 	at org.testng.TestNG.createSuiteRunners(TestNG.java:1210); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1058); 	at org.testng.TestNG.runSuites(TestNG.java:997); 	at org.testng.TestNG.run(TestNG.java:965); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:88); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	... 22 more; ```; It looks to me that this change is whats failing? https://github.com/cbeust/testng/pull/1848/files. We have test classes that can't be properly instantiated in our suite that causes the new version of testNG to fall over.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:3753,Testability,test,testng,3753,:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testng.TestRunner.init(TestRunner.java:298); 	at org.testng.TestRunner.<init>(TestRunner.java:183); 	at org.testng.SuiteRunner$DefaultTestRunnerFactory.newTestRunner(SuiteRunner.java:603); 	at org.testng.SuiteRunner.init(SuiteRunner.java:196); 	at org.testng.SuiteRunner.<init>(SuiteRunner.java:127); 	at org.testng.TestNG.createSuiteRunner(TestNG.java:1231); 	at org.testng.TestNG.createSuiteRunners(TestNG.java:1210); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1058); 	at org.testng.TestNG.runSuites(TestNG.java:997); 	at org.testng.TestNG.run(TestNG.java:965); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:88); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	... 22 more; ```; It looks to me that this change is whats failing? https://github.com/cbeust/testng/pull/1848/files. We have test classes that can't be properly instantiated in our suite that causes the new version of testNG to fall over.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:3760,Testability,Test,TestNG,3760,:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testng.TestRunner.init(TestRunner.java:298); 	at org.testng.TestRunner.<init>(TestRunner.java:183); 	at org.testng.SuiteRunner$DefaultTestRunnerFactory.newTestRunner(SuiteRunner.java:603); 	at org.testng.SuiteRunner.init(SuiteRunner.java:196); 	at org.testng.SuiteRunner.<init>(SuiteRunner.java:127); 	at org.testng.TestNG.createSuiteRunner(TestNG.java:1231); 	at org.testng.TestNG.createSuiteRunners(TestNG.java:1210); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1058); 	at org.testng.TestNG.runSuites(TestNG.java:997); 	at org.testng.TestNG.run(TestNG.java:965); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:88); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	... 22 more; ```; It looks to me that this change is whats failing? https://github.com/cbeust/testng/pull/1848/files. We have test classes that can't be properly instantiated in our suite that causes the new version of testNG to fall over.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:3771,Testability,Test,TestNG,3771,:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testng.TestRunner.init(TestRunner.java:298); 	at org.testng.TestRunner.<init>(TestRunner.java:183); 	at org.testng.SuiteRunner$DefaultTestRunnerFactory.newTestRunner(SuiteRunner.java:603); 	at org.testng.SuiteRunner.init(SuiteRunner.java:196); 	at org.testng.SuiteRunner.<init>(SuiteRunner.java:127); 	at org.testng.TestNG.createSuiteRunner(TestNG.java:1231); 	at org.testng.TestNG.createSuiteRunners(TestNG.java:1210); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1058); 	at org.testng.TestNG.runSuites(TestNG.java:997); 	at org.testng.TestNG.run(TestNG.java:965); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:88); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	... 22 more; ```; It looks to me that this change is whats failing? https://github.com/cbeust/testng/pull/1848/files. We have test classes that can't be properly instantiated in our suite that causes the new version of testNG to fall over.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:3823,Testability,test,testing,3823,:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testng.TestRunner.init(TestRunner.java:298); 	at org.testng.TestRunner.<init>(TestRunner.java:183); 	at org.testng.SuiteRunner$DefaultTestRunnerFactory.newTestRunner(SuiteRunner.java:603); 	at org.testng.SuiteRunner.init(SuiteRunner.java:196); 	at org.testng.SuiteRunner.<init>(SuiteRunner.java:127); 	at org.testng.TestNG.createSuiteRunner(TestNG.java:1231); 	at org.testng.TestNG.createSuiteRunners(TestNG.java:1210); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1058); 	at org.testng.TestNG.runSuites(TestNG.java:997); 	at org.testng.TestNG.run(TestNG.java:965); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:88); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	... 22 more; ```; It looks to me that this change is whats failing? https://github.com/cbeust/testng/pull/1848/files. We have test classes that can't be properly instantiated in our suite that causes the new version of testNG to fall over.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:3831,Testability,test,testng,3831,:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testng.TestRunner.init(TestRunner.java:298); 	at org.testng.TestRunner.<init>(TestRunner.java:183); 	at org.testng.SuiteRunner$DefaultTestRunnerFactory.newTestRunner(SuiteRunner.java:603); 	at org.testng.SuiteRunner.init(SuiteRunner.java:196); 	at org.testng.SuiteRunner.<init>(SuiteRunner.java:127); 	at org.testng.TestNG.createSuiteRunner(TestNG.java:1231); 	at org.testng.TestNG.createSuiteRunners(TestNG.java:1210); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1058); 	at org.testng.TestNG.runSuites(TestNG.java:997); 	at org.testng.TestNG.run(TestNG.java:965); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:88); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	... 22 more; ```; It looks to me that this change is whats failing? https://github.com/cbeust/testng/pull/1848/files. We have test classes that can't be properly instantiated in our suite that causes the new version of testNG to fall over.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:3838,Testability,Test,TestNGTestClassProcessor,3838,:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testng.TestRunner.init(TestRunner.java:298); 	at org.testng.TestRunner.<init>(TestRunner.java:183); 	at org.testng.SuiteRunner$DefaultTestRunnerFactory.newTestRunner(SuiteRunner.java:603); 	at org.testng.SuiteRunner.init(SuiteRunner.java:196); 	at org.testng.SuiteRunner.<init>(SuiteRunner.java:127); 	at org.testng.TestNG.createSuiteRunner(TestNG.java:1231); 	at org.testng.TestNG.createSuiteRunners(TestNG.java:1210); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1058); 	at org.testng.TestNG.runSuites(TestNG.java:997); 	at org.testng.TestNG.run(TestNG.java:965); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:88); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	... 22 more; ```; It looks to me that this change is whats failing? https://github.com/cbeust/testng/pull/1848/files. We have test classes that can't be properly instantiated in our suite that causes the new version of testNG to fall over.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:3872,Testability,Test,TestNGTestClassProcessor,3872,:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testng.TestRunner.init(TestRunner.java:298); 	at org.testng.TestRunner.<init>(TestRunner.java:183); 	at org.testng.SuiteRunner$DefaultTestRunnerFactory.newTestRunner(SuiteRunner.java:603); 	at org.testng.SuiteRunner.init(SuiteRunner.java:196); 	at org.testng.SuiteRunner.<init>(SuiteRunner.java:127); 	at org.testng.TestNG.createSuiteRunner(TestNG.java:1231); 	at org.testng.TestNG.createSuiteRunners(TestNG.java:1210); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1058); 	at org.testng.TestNG.runSuites(TestNG.java:997); 	at org.testng.TestNG.run(TestNG.java:965); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:88); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	... 22 more; ```; It looks to me that this change is whats failing? https://github.com/cbeust/testng/pull/1848/files. We have test classes that can't be properly instantiated in our suite that causes the new version of testNG to fall over.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:3942,Testability,test,testing,3942,:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testng.TestRunner.init(TestRunner.java:298); 	at org.testng.TestRunner.<init>(TestRunner.java:183); 	at org.testng.SuiteRunner$DefaultTestRunnerFactory.newTestRunner(SuiteRunner.java:603); 	at org.testng.SuiteRunner.init(SuiteRunner.java:196); 	at org.testng.SuiteRunner.<init>(SuiteRunner.java:127); 	at org.testng.TestNG.createSuiteRunner(TestNG.java:1231); 	at org.testng.TestNG.createSuiteRunners(TestNG.java:1210); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1058); 	at org.testng.TestNG.runSuites(TestNG.java:997); 	at org.testng.TestNG.run(TestNG.java:965); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:88); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	... 22 more; ```; It looks to me that this change is whats failing? https://github.com/cbeust/testng/pull/1848/files. We have test classes that can't be properly instantiated in our suite that causes the new version of testNG to fall over.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:3950,Testability,test,testng,3950,:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testng.TestRunner.init(TestRunner.java:298); 	at org.testng.TestRunner.<init>(TestRunner.java:183); 	at org.testng.SuiteRunner$DefaultTestRunnerFactory.newTestRunner(SuiteRunner.java:603); 	at org.testng.SuiteRunner.init(SuiteRunner.java:196); 	at org.testng.SuiteRunner.<init>(SuiteRunner.java:127); 	at org.testng.TestNG.createSuiteRunner(TestNG.java:1231); 	at org.testng.TestNG.createSuiteRunners(TestNG.java:1210); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1058); 	at org.testng.TestNG.runSuites(TestNG.java:997); 	at org.testng.TestNG.run(TestNG.java:965); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:88); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	... 22 more; ```; It looks to me that this change is whats failing? https://github.com/cbeust/testng/pull/1848/files. We have test classes that can't be properly instantiated in our suite that causes the new version of testNG to fall over.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:3957,Testability,Test,TestNGTestClassProcessor,3957,:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testng.TestRunner.init(TestRunner.java:298); 	at org.testng.TestRunner.<init>(TestRunner.java:183); 	at org.testng.SuiteRunner$DefaultTestRunnerFactory.newTestRunner(SuiteRunner.java:603); 	at org.testng.SuiteRunner.init(SuiteRunner.java:196); 	at org.testng.SuiteRunner.<init>(SuiteRunner.java:127); 	at org.testng.TestNG.createSuiteRunner(TestNG.java:1231); 	at org.testng.TestNG.createSuiteRunners(TestNG.java:1210); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1058); 	at org.testng.TestNG.runSuites(TestNG.java:997); 	at org.testng.TestNG.run(TestNG.java:965); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:88); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	... 22 more; ```; It looks to me that this change is whats failing? https://github.com/cbeust/testng/pull/1848/files. We have test classes that can't be properly instantiated in our suite that causes the new version of testNG to fall over.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:3987,Testability,Test,TestNGTestClassProcessor,3987,:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testng.TestRunner.init(TestRunner.java:298); 	at org.testng.TestRunner.<init>(TestRunner.java:183); 	at org.testng.SuiteRunner$DefaultTestRunnerFactory.newTestRunner(SuiteRunner.java:603); 	at org.testng.SuiteRunner.init(SuiteRunner.java:196); 	at org.testng.SuiteRunner.<init>(SuiteRunner.java:127); 	at org.testng.TestNG.createSuiteRunner(TestNG.java:1231); 	at org.testng.TestNG.createSuiteRunners(TestNG.java:1210); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1058); 	at org.testng.TestNG.runSuites(TestNG.java:997); 	at org.testng.TestNG.run(TestNG.java:965); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:88); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	... 22 more; ```; It looks to me that this change is whats failing? https://github.com/cbeust/testng/pull/1848/files. We have test classes that can't be properly instantiated in our suite that causes the new version of testNG to fall over.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:4056,Testability,test,testing,4056,:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testng.TestRunner.init(TestRunner.java:298); 	at org.testng.TestRunner.<init>(TestRunner.java:183); 	at org.testng.SuiteRunner$DefaultTestRunnerFactory.newTestRunner(SuiteRunner.java:603); 	at org.testng.SuiteRunner.init(SuiteRunner.java:196); 	at org.testng.SuiteRunner.<init>(SuiteRunner.java:127); 	at org.testng.TestNG.createSuiteRunner(TestNG.java:1231); 	at org.testng.TestNG.createSuiteRunners(TestNG.java:1210); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1058); 	at org.testng.TestNG.runSuites(TestNG.java:997); 	at org.testng.TestNG.run(TestNG.java:965); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:88); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	... 22 more; ```; It looks to me that this change is whats failing? https://github.com/cbeust/testng/pull/1848/files. We have test classes that can't be properly instantiated in our suite that causes the new version of testNG to fall over.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:4222,Testability,test,testng,4222,:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testng.TestRunner.init(TestRunner.java:298); 	at org.testng.TestRunner.<init>(TestRunner.java:183); 	at org.testng.SuiteRunner$DefaultTestRunnerFactory.newTestRunner(SuiteRunner.java:603); 	at org.testng.SuiteRunner.init(SuiteRunner.java:196); 	at org.testng.SuiteRunner.<init>(SuiteRunner.java:127); 	at org.testng.TestNG.createSuiteRunner(TestNG.java:1231); 	at org.testng.TestNG.createSuiteRunners(TestNG.java:1210); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1058); 	at org.testng.TestNG.runSuites(TestNG.java:997); 	at org.testng.TestNG.run(TestNG.java:965); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:88); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	... 22 more; ```; It looks to me that this change is whats failing? https://github.com/cbeust/testng/pull/1848/files. We have test classes that can't be properly instantiated in our suite that causes the new version of testNG to fall over.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:4254,Testability,test,test,4254,:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testng.TestRunner.init(TestRunner.java:298); 	at org.testng.TestRunner.<init>(TestRunner.java:183); 	at org.testng.SuiteRunner$DefaultTestRunnerFactory.newTestRunner(SuiteRunner.java:603); 	at org.testng.SuiteRunner.init(SuiteRunner.java:196); 	at org.testng.SuiteRunner.<init>(SuiteRunner.java:127); 	at org.testng.TestNG.createSuiteRunner(TestNG.java:1231); 	at org.testng.TestNG.createSuiteRunners(TestNG.java:1210); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1058); 	at org.testng.TestNG.runSuites(TestNG.java:997); 	at org.testng.TestNG.run(TestNG.java:965); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:88); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	... 22 more; ```; It looks to me that this change is whats failing? https://github.com/cbeust/testng/pull/1848/files. We have test classes that can't be properly instantiated in our suite that causes the new version of testNG to fall over.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858:4347,Testability,test,testNG,4347,:An error occurred while instantiating class org.broadinstitute.hellbender.engine.spark.ReadsPreprocessingPipelineSparkTestData. Check to make sure it can be instantiated; 	at org.testng.internal.InstanceCreator.createInstanceUsingObjectFactory(InstanceCreator.java:134); 	at org.testng.internal.InstanceCreator.createInstance(InstanceCreator.java:79); 	at org.testng.internal.ClassImpl.getDefaultInstance(ClassImpl.java:110); 	at org.testng.internal.ClassImpl.getInstances(ClassImpl.java:195); 	at org.testng.TestClass.getInstances(TestClass.java:102); 	at org.testng.TestClass.initTestClassesAndInstances(TestClass.java:82); 	at org.testng.TestClass.init(TestClass.java:74); 	at org.testng.TestClass.<init>(TestClass.java:39); 	at org.testng.TestRunner.initMethods(TestRunner.java:466); 	at org.testng.TestRunner.init(TestRunner.java:345); 	at org.testng.TestRunner.init(TestRunner.java:298); 	at org.testng.TestRunner.<init>(TestRunner.java:183); 	at org.testng.SuiteRunner$DefaultTestRunnerFactory.newTestRunner(SuiteRunner.java:603); 	at org.testng.SuiteRunner.init(SuiteRunner.java:196); 	at org.testng.SuiteRunner.<init>(SuiteRunner.java:127); 	at org.testng.TestNG.createSuiteRunner(TestNG.java:1231); 	at org.testng.TestNG.createSuiteRunners(TestNG.java:1210); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1058); 	at org.testng.TestNG.runSuites(TestNG.java:997); 	at org.testng.TestNG.run(TestNG.java:965); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:129); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:88); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	... 22 more; ```; It looks to me that this change is whats failing? https://github.com/cbeust/testng/pull/1848/files. We have test classes that can't be properly instantiated in our suite that causes the new version of testNG to fall over.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-472107858
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-527065605:0,Testability,Test,TestNG,0,"TestNG 7.0.0 is out of beta now, so this should be OK to go in @jamesemery.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-527065605
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-563413335:20,Availability,failure,failures,20,Travis reported job failures from build [28322](https://travis-ci.com/broadinstitute/gatk/builds/140297300); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | python | openjdk8 | [28322.5](https://travis-ci.com/broadinstitute/gatk/jobs/265325379) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28322.5/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-563413335
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-563413335:109,Availability,Failure,Failures,109,Travis reported job failures from build [28322](https://travis-ci.com/broadinstitute/gatk/builds/140297300); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | python | openjdk8 | [28322.5](https://travis-ci.com/broadinstitute/gatk/jobs/265325379) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28322.5/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-563413335
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-563413335:144,Testability,Test,Test,144,Travis reported job failures from build [28322](https://travis-ci.com/broadinstitute/gatk/builds/140297300); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | python | openjdk8 | [28322.5](https://travis-ci.com/broadinstitute/gatk/jobs/265325379) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28322.5/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-563413335
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-563413335:171,Testability,Log,Logs,171,Travis reported job failures from build [28322](https://travis-ci.com/broadinstitute/gatk/builds/140297300); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | python | openjdk8 | [28322.5](https://travis-ci.com/broadinstitute/gatk/jobs/265325379) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28322.5/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-563413335
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-563413335:309,Testability,log,logs,309,Travis reported job failures from build [28322](https://travis-ci.com/broadinstitute/gatk/builds/140297300); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | python | openjdk8 | [28322.5](https://travis-ci.com/broadinstitute/gatk/jobs/265325379) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28322.5/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-563413335
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-563413335:357,Testability,test,test-logs,357,Travis reported job failures from build [28322](https://travis-ci.com/broadinstitute/gatk/builds/140297300); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | python | openjdk8 | [28322.5](https://travis-ci.com/broadinstitute/gatk/jobs/265325379) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28322.5/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-563413335
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-563413335:396,Testability,test,tests,396,Travis reported job failures from build [28322](https://travis-ci.com/broadinstitute/gatk/builds/140297300); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | python | openjdk8 | [28322.5](https://travis-ci.com/broadinstitute/gatk/jobs/265325379) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28322.5/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-563413335
https://github.com/broadinstitute/gatk/pull/5787#issuecomment-563413335:402,Testability,test,test,402,Travis reported job failures from build [28322](https://travis-ci.com/broadinstitute/gatk/builds/140297300); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | python | openjdk8 | [28322.5](https://travis-ci.com/broadinstitute/gatk/jobs/265325379) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28322.5/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5787#issuecomment-563413335
https://github.com/broadinstitute/gatk/issues/5788#issuecomment-472566997:100,Deployability,integrat,integration,100,"@yfarjoun Right, the intention of this ticket was to implement the codec in htsjdk, then add a GATK integration test proving that we can now access interval_list files as tribble features.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5788#issuecomment-472566997
https://github.com/broadinstitute/gatk/issues/5788#issuecomment-472566997:100,Integrability,integrat,integration,100,"@yfarjoun Right, the intention of this ticket was to implement the codec in htsjdk, then add a GATK integration test proving that we can now access interval_list files as tribble features.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5788#issuecomment-472566997
https://github.com/broadinstitute/gatk/issues/5788#issuecomment-472566997:141,Security,access,access,141,"@yfarjoun Right, the intention of this ticket was to implement the codec in htsjdk, then add a GATK integration test proving that we can now access interval_list files as tribble features.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5788#issuecomment-472566997
https://github.com/broadinstitute/gatk/issues/5788#issuecomment-472566997:112,Testability,test,test,112,"@yfarjoun Right, the intention of this ticket was to implement the codec in htsjdk, then add a GATK integration test proving that we can now access interval_list files as tribble features.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5788#issuecomment-472566997
https://github.com/broadinstitute/gatk/issues/5789#issuecomment-472137336:21,Testability,test,test,21,Any chance you could test with GATK 4.1.0.0 to make sure it's still happening? GATK 3.5 is no longer maintained.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5789#issuecomment-472137336
https://github.com/broadinstitute/gatk/issues/5789#issuecomment-472200516:84,Deployability,update,updated,84,"Ok. I'm sorry, but we're unable to help you then. GATK 3 is no longer maintained or updated. We recommend everyone upgrades to 4. The differences between 3 and 4 are only going to increase over time. . Is there a specific missing feature preventing you from upgrading? Or some issue that manifests in 4 but not 3?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5789#issuecomment-472200516
https://github.com/broadinstitute/gatk/issues/5789#issuecomment-472200516:115,Deployability,upgrade,upgrades,115,"Ok. I'm sorry, but we're unable to help you then. GATK 3 is no longer maintained or updated. We recommend everyone upgrades to 4. The differences between 3 and 4 are only going to increase over time. . Is there a specific missing feature preventing you from upgrading? Or some issue that manifests in 4 but not 3?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5789#issuecomment-472200516
https://github.com/broadinstitute/gatk/issues/5789#issuecomment-472916677:189,Deployability,release,release,189,"@pontikos if you use the issue template we might be able to help. ### Affected tool(s) or class(es); _Tool/class name(s), special parameters?_. ### Affected version(s); - [ ] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. #### Steps to reproduce; _Tell us how to reproduce this issue. If possible, include command lines that reproduce the problem. (The support team may follow up to ask you to upload data to reproduce the issue.)_",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5789#issuecomment-472916677
https://github.com/broadinstitute/gatk/issues/5789#issuecomment-472916677:259,Testability,test,test,259,"@pontikos if you use the issue template we might be able to help. ### Affected tool(s) or class(es); _Tool/class name(s), special parameters?_. ### Affected version(s); - [ ] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. #### Steps to reproduce; _Tell us how to reproduce this issue. If possible, include command lines that reproduce the problem. (The support team may follow up to ask you to upload data to reproduce the issue.)_",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5789#issuecomment-472916677
https://github.com/broadinstitute/gatk/pull/5792#issuecomment-472254584:1873,Deployability,pipeline,pipelines,1873,e Δ | Complexity Δ | |; |---|---|---|---|; | [...e/hellbender/utils/variant/GATKVCFHeaderLines.java](https://codecov.io/gh/broadinstitute/gatk/pull/5792/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L0dBVEtWQ0ZIZWFkZXJMaW5lcy5qYXZh) | `94.944% <100%> (ø)` | `11 <0> (ø)` | :arrow_down: |; | [...ils/nio/NioFileCopierWithProgressMeterResults.java](https://codecov.io/gh/broadinstitute/gatk/pull/5792/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9uaW8vTmlvRmlsZUNvcGllcldpdGhQcm9ncmVzc01ldGVyUmVzdWx0cy5qYXZh) | `0% <0%> (-94.737%)` | `0% <0%> (-9%)` | |; | [...s/spark/ParallelCopyGCSDirectoryIntoHDFSSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5792/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QYXJhbGxlbENvcHlHQ1NEaXJlY3RvcnlJbnRvSERGU1NwYXJrLmphdmE=) | `0% <0%> (-74.257%)` | `0% <0%> (-17%)` | |; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5792/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `0% <0%> (-66.667%)` | `0% <0%> (-2%)` | |; | [...ols/funcotator/FuncotatorDataSourceDownloader.java](https://codecov.io/gh/broadinstitute/gatk/pull/5792/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0Z1bmNvdGF0b3JEYXRhU291cmNlRG93bmxvYWRlci5qYXZh) | `0% <0%> (-66.197%)` | `0% <0%> (-14%)` | |; | [...nder/utils/nio/NioFileCopierWithProgressMeter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5792/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9uaW8vTmlvRmlsZUNvcGllcldpdGhQcm9ncmVzc01ldGVyLmphdmE=) | `17% <0%> (-52.5%)` | `9% <0%> (-30%)` | |; | [...oadinstitute/hellbender/utils/gcs/BucketUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5792/d,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5792#issuecomment-472254584
https://github.com/broadinstitute/gatk/issues/5793#issuecomment-479261344:79,Deployability,release,release,79,"I'm reopening this as I'm still having this same problem when using the latest release (4.1.1.0). The variant shown above is not emitted by `GenotypeGVCFs` when using `-stand-call-conf 100` but is when using a lower threshold, e.g. `-stand-call-conf 50`. It would be really nice to be able to use `-stand-call-conf` and have that _just_ filter out records that would result in records in the output VCF with QUAL < threshold.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5793#issuecomment-479261344
https://github.com/broadinstitute/gatk/issues/5793#issuecomment-480037602:542,Availability,down,downstream,542,"It's kind of tricky because suppose eg that we have three alt alleles each with an allele qual of 19, so that the overall variant qual is roughly 3x19 = 57. If we filter alleles with a confidence of 20, we get no alleles and the variant qual changes to 0. . Now, if instead of filtering by allele we only filter by overall variant qual we then have to keep an arbitrary number of sketchy alleles. I mean, what if we have 30 alleles each with a qual of 1? The current behavior seems preferable to me because the usual question users would ask downstream is whether some allele is real, not whether some site exhibits variation. As long as we define `-stand-call-conf` to pertain to alleles everything is consistent.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5793#issuecomment-480037602
https://github.com/broadinstitute/gatk/issues/5793#issuecomment-480071811:251,Energy Efficiency,reduce,reduced,251,"@davidbenjamin I'm not sure I follow your logic. But if you believe the current implementing is doing the expected thing I'd like to understand. In the example above, the site is multi-allelic in the gVCF. However, when run through GenotypeGVCFs it's reduced to being bi-allelic, and the QUAL of the bi-allelic site in the genotyped GVCF doesn't change - it's still `595.64`. . To rephrase the issue - I find that if I run `GenotypeGVCFs -stand-call-conf 0.0` on that variant, it emits a variant with QUAL 595.64. But if I run `GenotypeGVCFs -stand-call-conf 100` that variant doesn't get emitted. I _think_ that's wrong, or at the very least misleading.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5793#issuecomment-480071811
https://github.com/broadinstitute/gatk/issues/5793#issuecomment-480071811:42,Testability,log,logic,42,"@davidbenjamin I'm not sure I follow your logic. But if you believe the current implementing is doing the expected thing I'd like to understand. In the example above, the site is multi-allelic in the gVCF. However, when run through GenotypeGVCFs it's reduced to being bi-allelic, and the QUAL of the bi-allelic site in the genotyped GVCF doesn't change - it's still `595.64`. . To rephrase the issue - I find that if I run `GenotypeGVCFs -stand-call-conf 0.0` on that variant, it emits a variant with QUAL 595.64. But if I run `GenotypeGVCFs -stand-call-conf 100` that variant doesn't get emitted. I _think_ that's wrong, or at the very least misleading.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5793#issuecomment-480071811
https://github.com/broadinstitute/gatk/issues/5793#issuecomment-481273026:124,Energy Efficiency,reduce,reduced,124,"@ldgauthier I think it's probably best to try and get to the bottom of why this variant's qual isn't being adjusted as it's reduced from 7 alleles in the gVCF to 2 alleles in the called VCF. This is, as you guessed, all single-sample. I've attached a reduced gVCF that just includes the variant in question, and the resulting genotyped VCF from running the command line below (and their indices) ; [here](https://github.com/broadinstitute/gatk/files/3059414/gatk-5793-testcase.tar.gz). ```; gatk GenotypeGVCFs \; -R /Work/refseq/hg19/hg19.fasta \; -V HG02568.g.vcf \; -O HG02568.vcf \; -L chr11:6637700-6637800 \; -stand-call-conf 30; ```. A few observations from running the above command but varying the `-stand-call-conf` at that locus, all performed with GATK 4.1.1.0:; - Running with `-stand-call-conf 30` results in a reduction from 7->2 alleles but no change at all in QUAL; - Running with `-stand-call-conf 0` results in the same genotype and QUAL, but another allele squeaks through even though it's not referenced in the genotype; - Running with `-stand-call-conf 100` results in no variants being emitted. Circling back to one of my original statements, I believe the least confusing way for this to work would be to think of it this way:; - If you run with `-stand-call-conf 0` you should see all variants; - If you run with `-stand-call-conf n` you should only lose variants that were previously emitted with `-stand-call-conf 0` that had QUAL < n. That said, it sounds like maybe the problem is less with the filtering on QUAL and more to do with the calculation of the final QUAL that ends up in the VCF?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5793#issuecomment-481273026
https://github.com/broadinstitute/gatk/issues/5793#issuecomment-481273026:251,Energy Efficiency,reduce,reduced,251,"@ldgauthier I think it's probably best to try and get to the bottom of why this variant's qual isn't being adjusted as it's reduced from 7 alleles in the gVCF to 2 alleles in the called VCF. This is, as you guessed, all single-sample. I've attached a reduced gVCF that just includes the variant in question, and the resulting genotyped VCF from running the command line below (and their indices) ; [here](https://github.com/broadinstitute/gatk/files/3059414/gatk-5793-testcase.tar.gz). ```; gatk GenotypeGVCFs \; -R /Work/refseq/hg19/hg19.fasta \; -V HG02568.g.vcf \; -O HG02568.vcf \; -L chr11:6637700-6637800 \; -stand-call-conf 30; ```. A few observations from running the above command but varying the `-stand-call-conf` at that locus, all performed with GATK 4.1.1.0:; - Running with `-stand-call-conf 30` results in a reduction from 7->2 alleles but no change at all in QUAL; - Running with `-stand-call-conf 0` results in the same genotype and QUAL, but another allele squeaks through even though it's not referenced in the genotype; - Running with `-stand-call-conf 100` results in no variants being emitted. Circling back to one of my original statements, I believe the least confusing way for this to work would be to think of it this way:; - If you run with `-stand-call-conf 0` you should see all variants; - If you run with `-stand-call-conf n` you should only lose variants that were previously emitted with `-stand-call-conf 0` that had QUAL < n. That said, it sounds like maybe the problem is less with the filtering on QUAL and more to do with the calculation of the final QUAL that ends up in the VCF?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5793#issuecomment-481273026
https://github.com/broadinstitute/gatk/issues/5793#issuecomment-481273026:744,Performance,perform,performed,744,"@ldgauthier I think it's probably best to try and get to the bottom of why this variant's qual isn't being adjusted as it's reduced from 7 alleles in the gVCF to 2 alleles in the called VCF. This is, as you guessed, all single-sample. I've attached a reduced gVCF that just includes the variant in question, and the resulting genotyped VCF from running the command line below (and their indices) ; [here](https://github.com/broadinstitute/gatk/files/3059414/gatk-5793-testcase.tar.gz). ```; gatk GenotypeGVCFs \; -R /Work/refseq/hg19/hg19.fasta \; -V HG02568.g.vcf \; -O HG02568.vcf \; -L chr11:6637700-6637800 \; -stand-call-conf 30; ```. A few observations from running the above command but varying the `-stand-call-conf` at that locus, all performed with GATK 4.1.1.0:; - Running with `-stand-call-conf 30` results in a reduction from 7->2 alleles but no change at all in QUAL; - Running with `-stand-call-conf 0` results in the same genotype and QUAL, but another allele squeaks through even though it's not referenced in the genotype; - Running with `-stand-call-conf 100` results in no variants being emitted. Circling back to one of my original statements, I believe the least confusing way for this to work would be to think of it this way:; - If you run with `-stand-call-conf 0` you should see all variants; - If you run with `-stand-call-conf n` you should only lose variants that were previously emitted with `-stand-call-conf 0` that had QUAL < n. That said, it sounds like maybe the problem is less with the filtering on QUAL and more to do with the calculation of the final QUAL that ends up in the VCF?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5793#issuecomment-481273026
https://github.com/broadinstitute/gatk/issues/5793#issuecomment-481273026:468,Testability,test,testcase,468,"@ldgauthier I think it's probably best to try and get to the bottom of why this variant's qual isn't being adjusted as it's reduced from 7 alleles in the gVCF to 2 alleles in the called VCF. This is, as you guessed, all single-sample. I've attached a reduced gVCF that just includes the variant in question, and the resulting genotyped VCF from running the command line below (and their indices) ; [here](https://github.com/broadinstitute/gatk/files/3059414/gatk-5793-testcase.tar.gz). ```; gatk GenotypeGVCFs \; -R /Work/refseq/hg19/hg19.fasta \; -V HG02568.g.vcf \; -O HG02568.vcf \; -L chr11:6637700-6637800 \; -stand-call-conf 30; ```. A few observations from running the above command but varying the `-stand-call-conf` at that locus, all performed with GATK 4.1.1.0:; - Running with `-stand-call-conf 30` results in a reduction from 7->2 alleles but no change at all in QUAL; - Running with `-stand-call-conf 0` results in the same genotype and QUAL, but another allele squeaks through even though it's not referenced in the genotype; - Running with `-stand-call-conf 100` results in no variants being emitted. Circling back to one of my original statements, I believe the least confusing way for this to work would be to think of it this way:; - If you run with `-stand-call-conf 0` you should see all variants; - If you run with `-stand-call-conf n` you should only lose variants that were previously emitted with `-stand-call-conf 0` that had QUAL < n. That said, it sounds like maybe the problem is less with the filtering on QUAL and more to do with the calculation of the final QUAL that ends up in the VCF?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5793#issuecomment-481273026
https://github.com/broadinstitute/gatk/issues/5793#issuecomment-483785934:23,Deployability,update,update,23,"So we definitely don't update the QUAL if we drop alternate alleles:https://github.com/broadinstitute/gatk/blob/9fce0b22faf2e8db7a8662884266a1893b6b10c5/src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/GenotypingEngine.java#L259; Note that the QUAL is based off of the AFResult that had alleles removed if they exceeded the output limit, but not if they had less evidence than the calling confidence threshold. @davidbenjamin I really hate to run the AF calculator again if we drop low quality alleles. Or maybe the new qual isn't as bad as I think? Would it be a decent approximation to add up the per-allele quals for the remaining alleles?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5793#issuecomment-483785934
https://github.com/broadinstitute/gatk/pull/5795#issuecomment-472522509:3207,Usability,Learn,LearnReadOrientationModelIntegrationTest,3207,walkers/bqsr/BaseRecalibratorIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5795/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Jxc3IvQmFzZVJlY2FsaWJyYXRvckludGVncmF0aW9uVGVzdC5qYXZh) | `1.031% <0%> (-98.969%)` | `1% <0%> (-7%)` | |; | [...ers/vqsr/FilterVariantTranchesIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5795/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3Zxc3IvRmlsdGVyVmFyaWFudFRyYW5jaGVzSW50ZWdyYXRpb25UZXN0LmphdmE=) | `1.053% <0%> (-98.947%)` | `1% <0%> (-5%)` | |; | [...s/variantutils/VariantsToTableIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5795/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3ZhcmlhbnR1dGlscy9WYXJpYW50c1RvVGFibGVJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `1.205% <0%> (-98.795%)` | `1% <0%> (-20%)` | |; | [...tion/LearnReadOrientationModelIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5795/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3JlYWRvcmllbnRhdGlvbi9MZWFyblJlYWRPcmllbnRhdGlvbk1vZGVsSW50ZWdyYXRpb25UZXN0LmphdmE=) | `1.724% <0%> (-98.276%)` | `1% <0%> (-5%)` | |; | [...on/FindBreakpointEvidenceSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5795/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9zdi9pbnRlZ3JhdGlvbi9GaW5kQnJlYWtwb2ludEV2aWRlbmNlU3BhcmtJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `1.754% <0%> (-98.246%)` | `1% <0%> (-6%)` | |; | [...bender/tools/spark/PileupSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5795/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9QaWxldXBTcGFya0ludGVncmF0aW9uVGVzdC5qYXZh) | `2.041% <0%> (-97.959%)` | `2% <0%> (-13%)` | |; | ... and [154 more](https://co,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5795#issuecomment-472522509
https://github.com/broadinstitute/gatk/pull/5796#issuecomment-473394038:2189,Availability,down,downsampling,2189,uamF2YQ==) | `0.815% <0.815%> (ø)` | `2 <2> (?)` | |; | [...hellbender/tools/AnalyzeSaturationMutagenesis.java](https://codecov.io/gh/broadinstitute/gatk/pull/5796/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9BbmFseXplU2F0dXJhdGlvbk11dGFnZW5lc2lzLmphdmE=) | `5.426% <5.426%> (ø)` | `0 <0> (?)` | |; | [...ls/variant/writers/GVCFBlockCombiningIterator.java](https://codecov.io/gh/broadinstitute/gatk/pull/5796/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L3dyaXRlcnMvR1ZDRkJsb2NrQ29tYmluaW5nSXRlcmF0b3IuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-1%)` | |; | [...ls/walkers/genotyper/HeterogeneousPloidyModel.java](https://codecov.io/gh/broadinstitute/gatk/pull/5796/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9IZXRlcm9nZW5lb3VzUGxvaWR5TW9kZWwuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-14%)` | |; | [...nder/utils/downsampling/FractionalDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/5796/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvRnJhY3Rpb25hbERvd25zYW1wbGVyLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-17%)` | |; | [...park/pathseq/MarkedOpticalDuplicateReadFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5796/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL01hcmtlZE9wdGljYWxEdXBsaWNhdGVSZWFkRmlsdGVyLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-4%)` | |; | [...otypecaller/RandomLikelihoodCalculationEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/5796/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9SYW5kb21MaWtlbGlob29kQ2FsY3VsYXRpb25FbmdpbmUuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-6%)` | |; | [...r/utils/solver/UnivariateSolverSpecifications.java](https://codecov.io/gh/,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5796#issuecomment-473394038
https://github.com/broadinstitute/gatk/pull/5799#issuecomment-477265333:89,Testability,test,tests,89,"@kgururaj If you can resolve the remaining conflict, we can get this one merged now that tests are passing.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5799#issuecomment-477265333
https://github.com/broadinstitute/gatk/issues/5802#issuecomment-473419380:86,Availability,error,error,86,"Hi @bhanugandham . I wasn't able to reproduce your problem on my laptop. Based on the error message, it looks like a network config Spark issue. What environment are you running this in? If it's MacOS, can you post the contents of `/etc/hosts`? Also the error message looks like it's truncated. You might be able to get the full stack trace by adding `--verbosity DEBUG`, which would be helpful as well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5802#issuecomment-473419380
https://github.com/broadinstitute/gatk/issues/5802#issuecomment-473419380:254,Availability,error,error,254,"Hi @bhanugandham . I wasn't able to reproduce your problem on my laptop. Based on the error message, it looks like a network config Spark issue. What environment are you running this in? If it's MacOS, can you post the contents of `/etc/hosts`? Also the error message looks like it's truncated. You might be able to get the full stack trace by adding `--verbosity DEBUG`, which would be helpful as well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5802#issuecomment-473419380
https://github.com/broadinstitute/gatk/issues/5802#issuecomment-473419380:92,Integrability,message,message,92,"Hi @bhanugandham . I wasn't able to reproduce your problem on my laptop. Based on the error message, it looks like a network config Spark issue. What environment are you running this in? If it's MacOS, can you post the contents of `/etc/hosts`? Also the error message looks like it's truncated. You might be able to get the full stack trace by adding `--verbosity DEBUG`, which would be helpful as well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5802#issuecomment-473419380
https://github.com/broadinstitute/gatk/issues/5802#issuecomment-473419380:260,Integrability,message,message,260,"Hi @bhanugandham . I wasn't able to reproduce your problem on my laptop. Based on the error message, it looks like a network config Spark issue. What environment are you running this in? If it's MacOS, can you post the contents of `/etc/hosts`? Also the error message looks like it's truncated. You might be able to get the full stack trace by adding `--verbosity DEBUG`, which would be helpful as well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5802#issuecomment-473419380
https://github.com/broadinstitute/gatk/issues/5802#issuecomment-473419380:125,Modifiability,config,config,125,"Hi @bhanugandham . I wasn't able to reproduce your problem on my laptop. Based on the error message, it looks like a network config Spark issue. What environment are you running this in? If it's MacOS, can you post the contents of `/etc/hosts`? Also the error message looks like it's truncated. You might be able to get the full stack trace by adding `--verbosity DEBUG`, which would be helpful as well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5802#issuecomment-473419380
https://github.com/broadinstitute/gatk/pull/5803#issuecomment-473417970:2816,Modifiability,Polymorphi,PolymorphicNuMTFilter,2816,YXZh) | `0% <0%> (-100%)` | `0% <0%> (-8%)` | |; | [...ct/CreateSomaticPanelOfNormalsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5803/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9DcmVhdGVTb21hdGljUGFuZWxPZk5vcm1hbHNJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `3.448% <0%> (-94.253%)` | `2% <0%> (-8%)` | |; | [...ls/walkers/mutect/CreateSomaticPanelOfNormals.java](https://codecov.io/gh/broadinstitute/gatk/pull/5803/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9DcmVhdGVTb21hdGljUGFuZWxPZk5vcm1hbHMuamF2YQ==) | `0% <0%> (-91.429%)` | `0% <0%> (-23%)` | |; | [.../org/broadinstitute/hellbender/utils/IGVUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5803/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9JR1ZVdGlscy5qYXZh) | `0% <0%> (-88.889%)` | `0% <0%> (-3%)` | |; | [...alkers/mutect/filtering/PolymorphicNuMTFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5803/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9maWx0ZXJpbmcvUG9seW1vcnBoaWNOdU1URmlsdGVyLmphdmE=) | `0% <0%> (-88.235%)` | `0% <0%> (-9%)` | |; | [...aplotypecaller/HaplotypeCallerIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5803/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9IYXBsb3R5cGVDYWxsZXJJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `0.431% <0%> (-87.5%)` | `2% <0%> (-85%)` | |; | [...alkers/mutect/SomaticReferenceConfidenceModel.java](https://codecov.io/gh/broadinstitute/gatk/pull/5803/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9Tb21hdGljUmVmZXJlbmNlQ29uZmlkZW5jZU1vZGVsLmphdmE=) | `12.5% <0%> (-84.375%)` | `1% <0%> (-7%)` | |; | [...tils/variant/writers/SomaticGVCFBlockCombiner.ja,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5803#issuecomment-473417970
https://github.com/broadinstitute/gatk/issues/5804#issuecomment-652411494:1367,Availability,error,error,1367,"Just for posterity:. jhess 1:55 PM; just to clarify: what is the logic behind approximating σ_(τ/min/maj) ≈ (post90 - post10)/2? (edited) ; 1:55; what is the scale factor of 1/2 for?; 1:58; one other thing — how come σ_(min/maj) is the sum of the total CR segment’s variance (i.e. σ_τ) and the allelic segment’s variance?; 2:00; this would imply that the allelic segments are actually a sum of the random variables corresponding to the allelic and total segmentation, which I’m not sure is the case?. slee 5:32 PM; Sorry, just now seeing your questions!; 5:33; The scale factor of 1/2 is pretty arbitrary. Just trying to give an estimate of posterior width when the credible interval might be skewed. A better approach would be to refit posteriors with Gaussians/Betas as mentioned previously.; 5:35; However, I'm not actually convinced that these credible intervals are what we want to pass to the sigmas. As I also mentioned above, if sigma.tau is supposed to be a global quantity, probably the posterior median of the parameter that controls the global variance (given in the .cr.params file) might be a better thing to use. However, I never got a straight answer from anybody about whether this was a segment-level or global quantity---any idea?. slee 5:41 PM; As for using the sum of the CR variance and the MAF variance, you're right---we should be propagating error for the product of the two random variables. Not sure what I was thinking...probably just a brain fart. Not sure if it will make a difference for ABSOLUTE, but thanks for catching that!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5804#issuecomment-652411494
https://github.com/broadinstitute/gatk/issues/5804#issuecomment-652411494:405,Modifiability,variab,variables,405,"Just for posterity:. jhess 1:55 PM; just to clarify: what is the logic behind approximating σ_(τ/min/maj) ≈ (post90 - post10)/2? (edited) ; 1:55; what is the scale factor of 1/2 for?; 1:58; one other thing — how come σ_(min/maj) is the sum of the total CR segment’s variance (i.e. σ_τ) and the allelic segment’s variance?; 2:00; this would imply that the allelic segments are actually a sum of the random variables corresponding to the allelic and total segmentation, which I’m not sure is the case?. slee 5:32 PM; Sorry, just now seeing your questions!; 5:33; The scale factor of 1/2 is pretty arbitrary. Just trying to give an estimate of posterior width when the credible interval might be skewed. A better approach would be to refit posteriors with Gaussians/Betas as mentioned previously.; 5:35; However, I'm not actually convinced that these credible intervals are what we want to pass to the sigmas. As I also mentioned above, if sigma.tau is supposed to be a global quantity, probably the posterior median of the parameter that controls the global variance (given in the .cr.params file) might be a better thing to use. However, I never got a straight answer from anybody about whether this was a segment-level or global quantity---any idea?. slee 5:41 PM; As for using the sum of the CR variance and the MAF variance, you're right---we should be propagating error for the product of the two random variables. Not sure what I was thinking...probably just a brain fart. Not sure if it will make a difference for ABSOLUTE, but thanks for catching that!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5804#issuecomment-652411494
https://github.com/broadinstitute/gatk/issues/5804#issuecomment-652411494:1407,Modifiability,variab,variables,1407,"Just for posterity:. jhess 1:55 PM; just to clarify: what is the logic behind approximating σ_(τ/min/maj) ≈ (post90 - post10)/2? (edited) ; 1:55; what is the scale factor of 1/2 for?; 1:58; one other thing — how come σ_(min/maj) is the sum of the total CR segment’s variance (i.e. σ_τ) and the allelic segment’s variance?; 2:00; this would imply that the allelic segments are actually a sum of the random variables corresponding to the allelic and total segmentation, which I’m not sure is the case?. slee 5:32 PM; Sorry, just now seeing your questions!; 5:33; The scale factor of 1/2 is pretty arbitrary. Just trying to give an estimate of posterior width when the credible interval might be skewed. A better approach would be to refit posteriors with Gaussians/Betas as mentioned previously.; 5:35; However, I'm not actually convinced that these credible intervals are what we want to pass to the sigmas. As I also mentioned above, if sigma.tau is supposed to be a global quantity, probably the posterior median of the parameter that controls the global variance (given in the .cr.params file) might be a better thing to use. However, I never got a straight answer from anybody about whether this was a segment-level or global quantity---any idea?. slee 5:41 PM; As for using the sum of the CR variance and the MAF variance, you're right---we should be propagating error for the product of the two random variables. Not sure what I was thinking...probably just a brain fart. Not sure if it will make a difference for ABSOLUTE, but thanks for catching that!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5804#issuecomment-652411494
https://github.com/broadinstitute/gatk/issues/5804#issuecomment-652411494:65,Testability,log,logic,65,"Just for posterity:. jhess 1:55 PM; just to clarify: what is the logic behind approximating σ_(τ/min/maj) ≈ (post90 - post10)/2? (edited) ; 1:55; what is the scale factor of 1/2 for?; 1:58; one other thing — how come σ_(min/maj) is the sum of the total CR segment’s variance (i.e. σ_τ) and the allelic segment’s variance?; 2:00; this would imply that the allelic segments are actually a sum of the random variables corresponding to the allelic and total segmentation, which I’m not sure is the case?. slee 5:32 PM; Sorry, just now seeing your questions!; 5:33; The scale factor of 1/2 is pretty arbitrary. Just trying to give an estimate of posterior width when the credible interval might be skewed. A better approach would be to refit posteriors with Gaussians/Betas as mentioned previously.; 5:35; However, I'm not actually convinced that these credible intervals are what we want to pass to the sigmas. As I also mentioned above, if sigma.tau is supposed to be a global quantity, probably the posterior median of the parameter that controls the global variance (given in the .cr.params file) might be a better thing to use. However, I never got a straight answer from anybody about whether this was a segment-level or global quantity---any idea?. slee 5:41 PM; As for using the sum of the CR variance and the MAF variance, you're right---we should be propagating error for the product of the two random variables. Not sure what I was thinking...probably just a brain fart. Not sure if it will make a difference for ABSOLUTE, but thanks for catching that!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5804#issuecomment-652411494
https://github.com/broadinstitute/gatk/issues/5805#issuecomment-473966580:28,Testability,test,test,28,"@teepean We generally don't test on Windows, though we do try to keep things working there if possible. Is there any chance you could try running [this branch](https://github.com/broadinstitute/gatk/tree/cn_temp_dr_windows) in the same environment that previously failed, and see if it solves the problem ? Thx ?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5805#issuecomment-473966580
https://github.com/broadinstitute/gatk/issues/5805#issuecomment-473995484:38,Testability,test,test,38,"> ; > ; > @teepean We generally don't test on Windows, though we do try to keep things working there if possible. Is there any chance you could try running [this branch](https://github.com/broadinstitute/gatk/tree/cn_temp_dr_windows) in the same environment that previously failed, and see if it solves the problem ? Thx ?. This fixed the problem and everything else seems to be working correctly. Thank you!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5805#issuecomment-473995484
https://github.com/broadinstitute/gatk/issues/5805#issuecomment-474020523:29,Testability,test,testing,29,"@teepean Ok, great - thx for testing that out.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5805#issuecomment-474020523
https://github.com/broadinstitute/gatk/issues/5807#issuecomment-474059338:23,Availability,error,error,23,This was previously an error with GATK2.1-11 and was fixed then. More info on that [here](https://gatkforums.broadinstitute.org/gatk/discussion/comment/2102/#Comment_2102).; Now the same error is showing up with GATK4.1.0.0. Could this be a bug? As discussed during gatk4 office hours I am creating this issue ticket for it.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5807#issuecomment-474059338
https://github.com/broadinstitute/gatk/issues/5807#issuecomment-474059338:187,Availability,error,error,187,This was previously an error with GATK2.1-11 and was fixed then. More info on that [here](https://gatkforums.broadinstitute.org/gatk/discussion/comment/2102/#Comment_2102).; Now the same error is showing up with GATK4.1.0.0. Could this be a bug? As discussed during gatk4 office hours I am creating this issue ticket for it.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5807#issuecomment-474059338
https://github.com/broadinstitute/gatk/issues/5807#issuecomment-474129545:29,Availability,error,error,29,Another user facing the same error. https://gatkforums.broadinstitute.org/gatk/discussion/23689/baserecalibrator-java-illegalargumentexception-fromindex-toindex/p1,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5807#issuecomment-474129545
https://github.com/broadinstitute/gatk/issues/5807#issuecomment-691600264:48,Availability,error,error,48,"Is this issue still open? I'm getting a similar error like this:; ```; .; .; .; INFO: Failed to detect whether we are running on Google Compute Engine.; 19:14:42.635 INFO BaseRecalibrator - ------------------------------------------------------------; 19:14:42.635 INFO BaseRecalibrator - The Genome Analysis Toolkit (GATK) v4.1.8.1; 19:14:42.635 INFO BaseRecalibrator - For support and documentation go to https://software.broadinstitute.org/gatk/; 19:14:42.638 INFO BaseRecalibrator - Executing as XXX on Linux v3.10.0-957.12.2.el7.x86_64 amd64; 19:14:42.638 INFO BaseRecalibrator - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_212-b04; 19:14:42.638 INFO BaseRecalibrator - Start Date/Time: September 12, 2020 7:14:42 PM PDT ; 19:14:42.638 INFO BaseRecalibrator - ------------------------------------------------------------; 19:14:42.638 INFO BaseRecalibrator - ------------------------------------------------------------; 19:14:42.638 INFO BaseRecalibrator - HTSJDK Version: 2.23.0; 19:14:42.638 INFO BaseRecalibrator - Picard Version: 2.22.8; 19:14:42.638 INFO BaseRecalibrator - HTSJDK Defaults.COMPRESSION_LEVEL : 2 ; 19:14:42.638 INFO BaseRecalibrator - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:14:42.639 INFO BaseRecalibrator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:14:42.639 INFO BaseRecalibrator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:14:42.639 INFO BaseRecalibrator - Deflater: IntelDeflater; 19:14:42.639 INFO BaseRecalibrator - Inflater: IntelInflater; 19:14:42.639 INFO BaseRecalibrator - GCS max retries/reopens: 20; 19:14:42.639 INFO BaseRecalibrator - Requester pays: disabled; 19:14:42.639 INFO BaseRecalibrator - Initializing engine; 19:14:43.472 INFO FeatureManager - Using codec BEDCodec to read file XXX; 19:14:43.726 WARN IndexUtils - Feature file XXX appears to contain no sequence dictionary. Attempting to retrieve a sequence dictionary from the associated index file; 19:14:43.755 INFO BaseRecalibrator - Done ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5807#issuecomment-691600264
https://github.com/broadinstitute/gatk/issues/5807#issuecomment-691600264:2546,Availability,down,down,2546,"calibrator - GCS max retries/reopens: 20; 19:14:42.639 INFO BaseRecalibrator - Requester pays: disabled; 19:14:42.639 INFO BaseRecalibrator - Initializing engine; 19:14:43.472 INFO FeatureManager - Using codec BEDCodec to read file XXX; 19:14:43.726 WARN IndexUtils - Feature file XXX appears to contain no sequence dictionary. Attempting to retrieve a sequence dictionary from the associated index file; 19:14:43.755 INFO BaseRecalibrator - Done initializing engine; 19:14:43.760 INFO BaseRecalibrationEngine - The covariates being used here:; 19:14:43.760 INFO BaseRecalibrationEngine - ReadGroupCovariate; 19:14:43.760 INFO BaseRecalibrationEngine - QualityScoreCovariate; 19:14:43.760 INFO BaseRecalibrationEngine - ContextCovariate; 19:14:43.760 INFO BaseRecalibrationEngine - CycleCovariate; 19:14:43.779 INFO ProgressMeter - Starting traversal; 19:14:43.779 INFO ProgressMeter - Current Locus Elapsed Minutes Reads Processed Reads/Minute; 19:14:44.670 INFO BaseRecalibrator - Shutting down engine; [September 12, 2020 7:14:44 PM PDT] org.broadinstitute.hellbender.tools.walkers.bqsr.BaseRecalibrator done. Elapsed time: 0.04 minutes.; Runtime.totalMemory()=1157627904; java.lang.IllegalArgumentException: fromIndex(119) > toIndex(115); at java.util.Arrays.rangeCheck(Arrays.java:113); at java.util.Arrays.fill(Arrays.java:3044); at org.broadinstitute.hellbender.utils.recalibration.BaseRecalibrationEngine.calculateKnownSites(BaseRecalibrationEngine.java:355); at org.broadinstitute.hellbender.utils.recalibration.BaseRecalibrationEngine.calculateSkipArray(BaseRecalibrationEngine.java:324); at org.broadinstitute.hellbender.utils.recalibration.BaseRecalibrationEngine.processRead(BaseRecalibrationEngine.java:139); at org.broadinstitute.hellbender.tools.walkers.bqsr.BaseRecalibrator.apply(BaseRecalibrator.java:185); at org.broadinstitute.hellbender.engine.ReadWalker.lambda$traverse$0(ReadWalker.java:96); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5807#issuecomment-691600264
https://github.com/broadinstitute/gatk/issues/5807#issuecomment-691600264:4038,Integrability,wrap,wrapAndCopyInto,4038,.utils.recalibration.BaseRecalibrationEngine.calculateSkipArray(BaseRecalibrationEngine.java:324); at org.broadinstitute.hellbender.utils.recalibration.BaseRecalibrationEngine.processRead(BaseRecalibrationEngine.java:139); at org.broadinstitute.hellbender.tools.walkers.bqsr.BaseRecalibrator.apply(BaseRecalibrator.java:185); at org.broadinstitute.hellbender.engine.ReadWalker.lambda$traverse$0(ReadWalker.java:96); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1049); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.m,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5807#issuecomment-691600264
https://github.com/broadinstitute/gatk/issues/5807#issuecomment-691600264:96,Safety,detect,detect,96,"Is this issue still open? I'm getting a similar error like this:; ```; .; .; .; INFO: Failed to detect whether we are running on Google Compute Engine.; 19:14:42.635 INFO BaseRecalibrator - ------------------------------------------------------------; 19:14:42.635 INFO BaseRecalibrator - The Genome Analysis Toolkit (GATK) v4.1.8.1; 19:14:42.635 INFO BaseRecalibrator - For support and documentation go to https://software.broadinstitute.org/gatk/; 19:14:42.638 INFO BaseRecalibrator - Executing as XXX on Linux v3.10.0-957.12.2.el7.x86_64 amd64; 19:14:42.638 INFO BaseRecalibrator - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_212-b04; 19:14:42.638 INFO BaseRecalibrator - Start Date/Time: September 12, 2020 7:14:42 PM PDT ; 19:14:42.638 INFO BaseRecalibrator - ------------------------------------------------------------; 19:14:42.638 INFO BaseRecalibrator - ------------------------------------------------------------; 19:14:42.638 INFO BaseRecalibrator - HTSJDK Version: 2.23.0; 19:14:42.638 INFO BaseRecalibrator - Picard Version: 2.22.8; 19:14:42.638 INFO BaseRecalibrator - HTSJDK Defaults.COMPRESSION_LEVEL : 2 ; 19:14:42.638 INFO BaseRecalibrator - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:14:42.639 INFO BaseRecalibrator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:14:42.639 INFO BaseRecalibrator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:14:42.639 INFO BaseRecalibrator - Deflater: IntelDeflater; 19:14:42.639 INFO BaseRecalibrator - Inflater: IntelInflater; 19:14:42.639 INFO BaseRecalibrator - GCS max retries/reopens: 20; 19:14:42.639 INFO BaseRecalibrator - Requester pays: disabled; 19:14:42.639 INFO BaseRecalibrator - Initializing engine; 19:14:43.472 INFO FeatureManager - Using codec BEDCodec to read file XXX; 19:14:43.726 WARN IndexUtils - Feature file XXX appears to contain no sequence dictionary. Attempting to retrieve a sequence dictionary from the associated index file; 19:14:43.755 INFO BaseRecalibrator - Done ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5807#issuecomment-691600264
https://github.com/broadinstitute/gatk/pull/5808#issuecomment-474081532:232,Availability,error,error-reference,232,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5808?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@70d4303`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `57.895%`. ```diff; @@ Coverage Diff @@; ## master #5808 +/- ##; ==========================================; Coverage ? 87.005% ; Complexity ? 32113 ; ==========================================; Files ? 1974 ; Lines ? 147249 ; Branches ? 16218 ; ==========================================; Hits ? 128114 ; Misses ? 13228 ; Partials ? 5907; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5808?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...walkers/genotyper/GenotypingGivenAllelesUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5808/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9HZW5vdHlwaW5nR2l2ZW5BbGxlbGVzVXRpbHMuamF2YQ==) | `75% <ø> (ø)` | `5 <0> (?)` | |; | [...kers/haplotypecaller/AssemblyBasedCallerUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5808/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9Bc3NlbWJseUJhc2VkQ2FsbGVyVXRpbHMuamF2YQ==) | `88.961% <ø> (ø)` | `115 <0> (?)` | |; | [...utils/variant/GATKVariantContextUtilsUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5808/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L0dBVEtWYXJpYW50Q29udGV4dFV0aWxzVW5pdFRlc3QuamF2YQ==) | `85.885% <100%> (ø)` | `163 <4> (?)` | |; | [...lbender/utils/variant/GATKVariantContextUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5808/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L0dBVEtWYXJpYW50Q29udGV4dFV0aWxzLmphdmE=) | `84.892% <44.186%> (ø)` |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5808#issuecomment-474081532
https://github.com/broadinstitute/gatk/pull/5808#issuecomment-474081532:180,Usability,learn,learn,180,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5808?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@70d4303`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `57.895%`. ```diff; @@ Coverage Diff @@; ## master #5808 +/- ##; ==========================================; Coverage ? 87.005% ; Complexity ? 32113 ; ==========================================; Files ? 1974 ; Lines ? 147249 ; Branches ? 16218 ; ==========================================; Hits ? 128114 ; Misses ? 13228 ; Partials ? 5907; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5808?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...walkers/genotyper/GenotypingGivenAllelesUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5808/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9HZW5vdHlwaW5nR2l2ZW5BbGxlbGVzVXRpbHMuamF2YQ==) | `75% <ø> (ø)` | `5 <0> (?)` | |; | [...kers/haplotypecaller/AssemblyBasedCallerUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5808/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9Bc3NlbWJseUJhc2VkQ2FsbGVyVXRpbHMuamF2YQ==) | `88.961% <ø> (ø)` | `115 <0> (?)` | |; | [...utils/variant/GATKVariantContextUtilsUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5808/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L0dBVEtWYXJpYW50Q29udGV4dFV0aWxzVW5pdFRlc3QuamF2YQ==) | `85.885% <100%> (ø)` | `163 <4> (?)` | |; | [...lbender/utils/variant/GATKVariantContextUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5808/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L0dBVEtWYXJpYW50Q29udGV4dFV0aWxzLmphdmE=) | `84.892% <44.186%> (ø)` |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5808#issuecomment-474081532
https://github.com/broadinstitute/gatk/pull/5810#issuecomment-474086066:232,Availability,error,error-reference,232,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5810?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@70d4303`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #5810 +/- ##; ==========================================; Coverage ? 80.318% ; Complexity ? 30474 ; ==========================================; Files ? 1974 ; Lines ? 147194 ; Branches ? 16197 ; ==========================================; Hits ? 118224 ; Misses ? 23270 ; Partials ? 5700; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5810?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...kers/haplotypecaller/AssemblyBasedCallerUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5810/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9Bc3NlbWJseUJhc2VkQ2FsbGVyVXRpbHMuamF2YQ==) | `88.961% <ø> (ø)` | `115 <0> (?)` | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5810#issuecomment-474086066
https://github.com/broadinstitute/gatk/pull/5810#issuecomment-474086066:180,Usability,learn,learn,180,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5810?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@70d4303`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `n/a`. ```diff; @@ Coverage Diff @@; ## master #5810 +/- ##; ==========================================; Coverage ? 80.318% ; Complexity ? 30474 ; ==========================================; Files ? 1974 ; Lines ? 147194 ; Branches ? 16197 ; ==========================================; Hits ? 118224 ; Misses ? 23270 ; Partials ? 5700; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5810?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...kers/haplotypecaller/AssemblyBasedCallerUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5810/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9Bc3NlbWJseUJhc2VkQ2FsbGVyVXRpbHMuamF2YQ==) | `88.961% <ø> (ø)` | `115 <0> (?)` | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5810#issuecomment-474086066
https://github.com/broadinstitute/gatk/pull/5811#issuecomment-475256825:69,Deployability,release,release,69,@mwalker174 @droazen I think we should try to get this in before the release next Tuesday.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5811#issuecomment-475256825
https://github.com/broadinstitute/gatk/pull/5811#issuecomment-475267631:61,Testability,test,tests,61,"Added some commits to address a few more issues. Not sure if tests still pass, or if I'll need to fix up more test resources---we'll see!. Closes #5778.; Closes #5809.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5811#issuecomment-475267631
https://github.com/broadinstitute/gatk/pull/5811#issuecomment-475267631:110,Testability,test,test,110,"Added some commits to address a few more issues. Not sure if tests still pass, or if I'll need to fix up more test resources---we'll see!. Closes #5778.; Closes #5809.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5811#issuecomment-475267631
https://github.com/broadinstitute/gatk/pull/5812#issuecomment-474098651:203,Performance,optimiz,optimizations,203,"This should add support for reading bam files with CSI indexes, as well as porting the FastaReferenceWriter to htsjdk and a lot of other changes to htsjdk. @samuelklee This includes the overlap detector optimizations you wanted as well as the changes to let you write interval file to paths.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5812#issuecomment-474098651
https://github.com/broadinstitute/gatk/pull/5812#issuecomment-474098651:194,Safety,detect,detector,194,"This should add support for reading bam files with CSI indexes, as well as porting the FastaReferenceWriter to htsjdk and a lot of other changes to htsjdk. @samuelklee This includes the overlap detector optimizations you wanted as well as the changes to let you write interval file to paths.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5812#issuecomment-474098651
https://github.com/broadinstitute/gatk/pull/5812#issuecomment-474759703:24,Deployability,release,released,24,Disq 0.3.0 has now been released.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5812#issuecomment-474759703
https://github.com/broadinstitute/gatk/pull/5812#issuecomment-474932948:2182,Testability,test,testutils,2182,=) | `80.822% <ø> (ø)` | `16 <0> (ø)` | :arrow_down: |; | [...lbender/tools/IndexFeatureFileIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5812/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9JbmRleEZlYXR1cmVGaWxlSW50ZWdyYXRpb25UZXN0LmphdmE=) | `88.938% <ø> (-2.212%)` | `32 <0> (-1)` | |; | [...nder/utils/io/DeleteRecursivelyOnExitPathHook.java](https://codecov.io/gh/broadinstitute/gatk/pull/5812/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9pby9EZWxldGVSZWN1cnNpdmVseU9uRXhpdFBhdGhIb29rLmphdmE=) | `70% <0%> (-5%)` | `3 <0> (ø)` | |; | [...gine/spark/datasources/ReadsSparkSinkUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5812/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVhZHNTcGFya1NpbmtVbml0VGVzdC5qYXZh) | `75.61% <100%> (ø)` | `23 <0> (ø)` | :arrow_down: |; | [...r/testutils/testers/MarkDuplicatesSparkTester.java](https://codecov.io/gh/broadinstitute/gatk/pull/5812/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90ZXN0dXRpbHMvdGVzdGVycy9NYXJrRHVwbGljYXRlc1NwYXJrVGVzdGVyLmphdmE=) | `89.773% <100%> (ø)` | `22 <0> (ø)` | :arrow_down: |; | [...ender/tools/walkers/fasta/FastaReferenceMaker.java](https://codecov.io/gh/broadinstitute/gatk/pull/5812/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Zhc3RhL0Zhc3RhUmVmZXJlbmNlTWFrZXIuamF2YQ==) | `87.234% <100%> (+0.87%)` | `11 <0> (ø)` | :arrow_down: |; | [...nder/tools/walkers/genotyper/GenotypingEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/5812/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9HZW5vdHlwaW5nRW5naW5lLmphdmE=) | `70.248% <100%> (ø)` | `72 <0> (ø)` | :arrow_down: |; | [...der/tools/spark/CreateHadoopBamSplittingIndex.java](https://codecov.io/gh/b,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5812#issuecomment-474932948
https://github.com/broadinstitute/gatk/pull/5812#issuecomment-474932948:2192,Testability,test,testers,2192,=) | `80.822% <ø> (ø)` | `16 <0> (ø)` | :arrow_down: |; | [...lbender/tools/IndexFeatureFileIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5812/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9JbmRleEZlYXR1cmVGaWxlSW50ZWdyYXRpb25UZXN0LmphdmE=) | `88.938% <ø> (-2.212%)` | `32 <0> (-1)` | |; | [...nder/utils/io/DeleteRecursivelyOnExitPathHook.java](https://codecov.io/gh/broadinstitute/gatk/pull/5812/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9pby9EZWxldGVSZWN1cnNpdmVseU9uRXhpdFBhdGhIb29rLmphdmE=) | `70% <0%> (-5%)` | `3 <0> (ø)` | |; | [...gine/spark/datasources/ReadsSparkSinkUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5812/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvUmVhZHNTcGFya1NpbmtVbml0VGVzdC5qYXZh) | `75.61% <100%> (ø)` | `23 <0> (ø)` | :arrow_down: |; | [...r/testutils/testers/MarkDuplicatesSparkTester.java](https://codecov.io/gh/broadinstitute/gatk/pull/5812/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90ZXN0dXRpbHMvdGVzdGVycy9NYXJrRHVwbGljYXRlc1NwYXJrVGVzdGVyLmphdmE=) | `89.773% <100%> (ø)` | `22 <0> (ø)` | :arrow_down: |; | [...ender/tools/walkers/fasta/FastaReferenceMaker.java](https://codecov.io/gh/broadinstitute/gatk/pull/5812/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Zhc3RhL0Zhc3RhUmVmZXJlbmNlTWFrZXIuamF2YQ==) | `87.234% <100%> (+0.87%)` | `11 <0> (ø)` | :arrow_down: |; | [...nder/tools/walkers/genotyper/GenotypingEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/5812/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9HZW5vdHlwaW5nRW5naW5lLmphdmE=) | `70.248% <100%> (ø)` | `72 <0> (ø)` | :arrow_down: |; | [...der/tools/spark/CreateHadoopBamSplittingIndex.java](https://codecov.io/gh/b,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5812#issuecomment-474932948
https://github.com/broadinstitute/gatk/pull/5812#issuecomment-477125402:22,Deployability,upgrade,upgrade,22,"This also includes an upgrade to Picard 2.19, so its in sync with htsjdk now.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5812#issuecomment-477125402
https://github.com/broadinstitute/gatk/pull/5818#issuecomment-474567553:1892,Usability,Simpl,SimpleSVD,1892,rc=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...hellbender/engine/spark/IntervalWalkerContext.java](https://codecov.io/gh/broadinstitute/gatk/pull/5818/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvSW50ZXJ2YWxXYWxrZXJDb250ZXh0LmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-5%)` | |; | [...ls/walkers/mutect/filtering/BaseQualityFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5818/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9maWx0ZXJpbmcvQmFzZVF1YWxpdHlGaWx0ZXIuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-6%)` | |; | [...nder/tools/readersplitters/SampleNameSplitter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5818/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9yZWFkZXJzcGxpdHRlcnMvU2FtcGxlTmFtZVNwbGl0dGVyLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-2%)` | |; | [...broadinstitute/hellbender/utils/svd/SimpleSVD.java](https://codecov.io/gh/broadinstitute/gatk/pull/5818/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zdmQvU2ltcGxlU1ZELmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-5%)` | |; | [...lbender/tools/walkers/mutect/clustering/Datum.java](https://codecov.io/gh/broadinstitute/gatk/pull/5818/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9jbHVzdGVyaW5nL0RhdHVtLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-7%)` | |; | [...ark/AssemblyRegionReadShardArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/5818/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvQXNzZW1ibHlSZWdpb25SZWFkU2hhcmRBcmd1bWVudENvbGxlY3Rpb24uamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-1%)` | |; | [.../examples/metrics/single/ExampleSingleMetrics.java](https://codecov.io/gh/broadinstitute/gatk/pull/5818/diff?src=pr&el=tree#diff-c3JjL2,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5818#issuecomment-474567553
https://github.com/broadinstitute/gatk/pull/5818#issuecomment-474850615:34,Deployability,pipeline,pipelines,34,"Good point, here's the PR in dsde-pipelines: https://github.com/broadinstitute/dsde-pipelines/pull/718/files. It just updates the Picard version.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5818#issuecomment-474850615
https://github.com/broadinstitute/gatk/pull/5818#issuecomment-474850615:84,Deployability,pipeline,pipelines,84,"Good point, here's the PR in dsde-pipelines: https://github.com/broadinstitute/dsde-pipelines/pull/718/files. It just updates the Picard version.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5818#issuecomment-474850615
https://github.com/broadinstitute/gatk/pull/5818#issuecomment-474850615:118,Deployability,update,updates,118,"Good point, here's the PR in dsde-pipelines: https://github.com/broadinstitute/dsde-pipelines/pull/718/files. It just updates the Picard version.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5818#issuecomment-474850615
https://github.com/broadinstitute/gatk/pull/5819#issuecomment-474871354:26,Modifiability,variab,variable,26,"@cmnbroad I see. The ""CI"" variable does seem brittle, especially since I'm not strictly sure where it is set. I think a somewhat safer place would be to add some global test flag to the docker image would be to add it to the run_unit_tests.sh script. That way we know it is getting triggered exactly before we run the tests in just the docker environment. Is there some way of detecting what conda environment is active outside of conda.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5819#issuecomment-474871354
https://github.com/broadinstitute/gatk/pull/5819#issuecomment-474871354:129,Safety,safe,safer,129,"@cmnbroad I see. The ""CI"" variable does seem brittle, especially since I'm not strictly sure where it is set. I think a somewhat safer place would be to add some global test flag to the docker image would be to add it to the run_unit_tests.sh script. That way we know it is getting triggered exactly before we run the tests in just the docker environment. Is there some way of detecting what conda environment is active outside of conda.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5819#issuecomment-474871354
https://github.com/broadinstitute/gatk/pull/5819#issuecomment-474871354:377,Safety,detect,detecting,377,"@cmnbroad I see. The ""CI"" variable does seem brittle, especially since I'm not strictly sure where it is set. I think a somewhat safer place would be to add some global test flag to the docker image would be to add it to the run_unit_tests.sh script. That way we know it is getting triggered exactly before we run the tests in just the docker environment. Is there some way of detecting what conda environment is active outside of conda.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5819#issuecomment-474871354
https://github.com/broadinstitute/gatk/pull/5819#issuecomment-474871354:169,Testability,test,test,169,"@cmnbroad I see. The ""CI"" variable does seem brittle, especially since I'm not strictly sure where it is set. I think a somewhat safer place would be to add some global test flag to the docker image would be to add it to the run_unit_tests.sh script. That way we know it is getting triggered exactly before we run the tests in just the docker environment. Is there some way of detecting what conda environment is active outside of conda.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5819#issuecomment-474871354
https://github.com/broadinstitute/gatk/pull/5819#issuecomment-474871354:318,Testability,test,tests,318,"@cmnbroad I see. The ""CI"" variable does seem brittle, especially since I'm not strictly sure where it is set. I think a somewhat safer place would be to add some global test flag to the docker image would be to add it to the run_unit_tests.sh script. That way we know it is getting triggered exactly before we run the tests in just the docker environment. Is there some way of detecting what conda environment is active outside of conda.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5819#issuecomment-474871354
https://github.com/broadinstitute/gatk/pull/5819#issuecomment-476215753:68,Deployability,release,release,68,@jamesemery @cmnbroad Can we try to get this one in in time for the release?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5819#issuecomment-476215753
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-477432331:70,Deployability,release,release,70,@igordot I believe this is fixed in master and will be in the 4.1.1.0 release this Thursday.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-477432331
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478026887:31,Availability,error,error,31,"I tried 4.1.1.0. Although that error is fixed, now I am getting a new one:. ```; java.lang.IllegalArgumentException: log10 p: Values must be non-infinite and non-NAN; 	at org.broadinstitute.hellbender.utils.MathUtils.log10SumLog10(MathUtils.java:1023); 	at org.broadinstitute.hellbender.utils.MathUtils.log10SumLog10(MathUtils.java:995); 	at org.broadinstitute.hellbender.utils.MathUtils.log10SumLog10(MathUtils.java:999); 	at org.broadinstitute.hellbender.utils.MathUtils.normalizeLog10(MathUtils.java:1098); 	at org.broadinstitute.hellbender.utils.MathUtils.normalizeFromLog10ToLinearSpace(MathUtils.java:1074); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.posteriorProbabilityOfError(Mutect2FilteringEngine.java:91); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.posteriorProbabilityOfError(Mutect2FilteringEngine.java:76); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ContaminationFilter.calculateErrorProbability(ContaminationFilter.java:60); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorPr",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478026887
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478026887:1139,Availability,error,errorProbability,1139,non-NAN; 	at org.broadinstitute.hellbender.utils.MathUtils.log10SumLog10(MathUtils.java:1023); 	at org.broadinstitute.hellbender.utils.MathUtils.log10SumLog10(MathUtils.java:995); 	at org.broadinstitute.hellbender.utils.MathUtils.log10SumLog10(MathUtils.java:999); 	at org.broadinstitute.hellbender.utils.MathUtils.normalizeLog10(MathUtils.java:1098); 	at org.broadinstitute.hellbender.utils.MathUtils.normalizeFromLog10ToLinearSpace(MathUtils.java:1074); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.posteriorProbabilityOfError(Mutect2FilteringEngine.java:91); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.posteriorProbabilityOfError(Mutect2FilteringEngine.java:76); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ContaminationFilter.calculateErrorProbability(ContaminationFilter.java:60); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478026887
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478026887:1252,Availability,Error,ErrorProbabilities,1252,broadinstitute.hellbender.utils.MathUtils.log10SumLog10(MathUtils.java:995); 	at org.broadinstitute.hellbender.utils.MathUtils.log10SumLog10(MathUtils.java:999); 	at org.broadinstitute.hellbender.utils.MathUtils.normalizeLog10(MathUtils.java:1098); 	at org.broadinstitute.hellbender.utils.MathUtils.normalizeFromLog10ToLinearSpace(MathUtils.java:1074); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.posteriorProbabilityOfError(Mutect2FilteringEngine.java:91); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.posteriorProbabilityOfError(Mutect2FilteringEngine.java:76); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ContaminationFilter.calculateErrorProbability(ContaminationFilter.java:60); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:136); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutec,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478026887
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478026887:1284,Availability,Error,ErrorProbabilities,1284,utils.MathUtils.log10SumLog10(MathUtils.java:995); 	at org.broadinstitute.hellbender.utils.MathUtils.log10SumLog10(MathUtils.java:999); 	at org.broadinstitute.hellbender.utils.MathUtils.normalizeLog10(MathUtils.java:1098); 	at org.broadinstitute.hellbender.utils.MathUtils.normalizeFromLog10ToLinearSpace(MathUtils.java:1074); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.posteriorProbabilityOfError(Mutect2FilteringEngine.java:91); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.posteriorProbabilityOfError(Mutect2FilteringEngine.java:76); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ContaminationFilter.calculateErrorProbability(ContaminationFilter.java:60); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:136); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(Filte,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478026887
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478026887:1994,Availability,Error,ErrorProbabilities,1994,ateErrorProbability(ContaminationFilter.java:60); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:136); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:140); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:31); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:68); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractP,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478026887
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478026887:2020,Availability,Error,ErrorProbabilities,2020,taminationFilter.java:60); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:136); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:140); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:31); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:68); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478026887
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478026887:1405,Energy Efficiency,Reduce,ReduceOps,1405,999); 	at org.broadinstitute.hellbender.utils.MathUtils.normalizeLog10(MathUtils.java:1098); 	at org.broadinstitute.hellbender.utils.MathUtils.normalizeFromLog10ToLinearSpace(MathUtils.java:1074); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.posteriorProbabilityOfError(Mutect2FilteringEngine.java:91); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.posteriorProbabilityOfError(Mutect2FilteringEngine.java:76); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ContaminationFilter.calculateErrorProbability(ContaminationFilter.java:60); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:136); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:140); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWa,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478026887
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478026887:1436,Energy Efficiency,Reduce,ReduceOps,1436,nstitute.hellbender.utils.MathUtils.normalizeLog10(MathUtils.java:1098); 	at org.broadinstitute.hellbender.utils.MathUtils.normalizeFromLog10ToLinearSpace(MathUtils.java:1074); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.posteriorProbabilityOfError(Mutect2FilteringEngine.java:91); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.posteriorProbabilityOfError(Mutect2FilteringEngine.java:76); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ContaminationFilter.calculateErrorProbability(ContaminationFilter.java:60); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:136); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:140); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:31); 	at or,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478026887
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478026887:1719,Energy Efficiency,Reduce,ReduceOps,1719,r(Mutect2FilteringEngine.java:91); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.posteriorProbabilityOfError(Mutect2FilteringEngine.java:76); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ContaminationFilter.calculateErrorProbability(ContaminationFilter.java:60); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:136); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:140); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:31); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:68); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.uti,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478026887
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478026887:1729,Energy Efficiency,Reduce,ReduceOp,1729,r(Mutect2FilteringEngine.java:91); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.posteriorProbabilityOfError(Mutect2FilteringEngine.java:76); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ContaminationFilter.calculateErrorProbability(ContaminationFilter.java:60); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:136); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:140); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:31); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:68); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.uti,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478026887
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478026887:1757,Energy Efficiency,Reduce,ReduceOps,1757,.java:91); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.posteriorProbabilityOfError(Mutect2FilteringEngine.java:76); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ContaminationFilter.calculateErrorProbability(ContaminationFilter.java:60); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:136); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:140); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:31); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:68); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.Iterator.forEachRemain,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478026887
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478026887:1654,Integrability,wrap,wrapAndCopyInto,1654,iltering.Mutect2FilteringEngine.posteriorProbabilityOfError(Mutect2FilteringEngine.java:91); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.posteriorProbabilityOfError(Mutect2FilteringEngine.java:76); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ContaminationFilter.calculateErrorProbability(ContaminationFilter.java:60); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:136); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:140); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:31); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:68); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePip,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478026887
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478026887:2979,Integrability,wrap,wrapAndCopyInto,2979,rrorProbabilities.<init>(ErrorProbabilities.java:19); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:136); 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:140); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:31); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:68); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverseVariants(MultiplePassVariantWalker.java:66); 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverse(MultiplePassVariantWalker.java:31); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:984); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitut,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478026887
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478076231:80,Availability,error,error,80,"@igordot Could you provide your command line? Also, could you check whether the error persists when you use a panel of normals, or nothing at all, instead of the unmatched normal?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478076231
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478305154:45,Availability,fault,fault,45,"A few recent bugs, which are all entirely my fault, came about because the liftover of gnomAD to hg38 (there is no official hg38 gnomAD yet) exposed some new edge cases, such as `AF=.` and `AF=0`, that caused errors. I suspect that you are seeing one that we hadn't found yet. Unfortunately, we do not have nearly validation on hg38. Here's what I will do: 1) correct our hg38 gnomAD to fix liftover artifacts and put this new resource in the GATK bucket. 2) Create a Firecloud workspace with a few hg38 samples in order to reproduce the error and to make sure future changes don't create new problems 3) try to fix the error because even if 1) works it's sloppy to rely on the fact that gnomAD won't have these edge cases. I hope 1) succeeds because it will be available immediately without waiting for the next release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478305154
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478305154:209,Availability,error,errors,209,"A few recent bugs, which are all entirely my fault, came about because the liftover of gnomAD to hg38 (there is no official hg38 gnomAD yet) exposed some new edge cases, such as `AF=.` and `AF=0`, that caused errors. I suspect that you are seeing one that we hadn't found yet. Unfortunately, we do not have nearly validation on hg38. Here's what I will do: 1) correct our hg38 gnomAD to fix liftover artifacts and put this new resource in the GATK bucket. 2) Create a Firecloud workspace with a few hg38 samples in order to reproduce the error and to make sure future changes don't create new problems 3) try to fix the error because even if 1) works it's sloppy to rely on the fact that gnomAD won't have these edge cases. I hope 1) succeeds because it will be available immediately without waiting for the next release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478305154
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478305154:538,Availability,error,error,538,"A few recent bugs, which are all entirely my fault, came about because the liftover of gnomAD to hg38 (there is no official hg38 gnomAD yet) exposed some new edge cases, such as `AF=.` and `AF=0`, that caused errors. I suspect that you are seeing one that we hadn't found yet. Unfortunately, we do not have nearly validation on hg38. Here's what I will do: 1) correct our hg38 gnomAD to fix liftover artifacts and put this new resource in the GATK bucket. 2) Create a Firecloud workspace with a few hg38 samples in order to reproduce the error and to make sure future changes don't create new problems 3) try to fix the error because even if 1) works it's sloppy to rely on the fact that gnomAD won't have these edge cases. I hope 1) succeeds because it will be available immediately without waiting for the next release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478305154
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478305154:620,Availability,error,error,620,"A few recent bugs, which are all entirely my fault, came about because the liftover of gnomAD to hg38 (there is no official hg38 gnomAD yet) exposed some new edge cases, such as `AF=.` and `AF=0`, that caused errors. I suspect that you are seeing one that we hadn't found yet. Unfortunately, we do not have nearly validation on hg38. Here's what I will do: 1) correct our hg38 gnomAD to fix liftover artifacts and put this new resource in the GATK bucket. 2) Create a Firecloud workspace with a few hg38 samples in order to reproduce the error and to make sure future changes don't create new problems 3) try to fix the error because even if 1) works it's sloppy to rely on the fact that gnomAD won't have these edge cases. I hope 1) succeeds because it will be available immediately without waiting for the next release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478305154
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478305154:762,Availability,avail,available,762,"A few recent bugs, which are all entirely my fault, came about because the liftover of gnomAD to hg38 (there is no official hg38 gnomAD yet) exposed some new edge cases, such as `AF=.` and `AF=0`, that caused errors. I suspect that you are seeing one that we hadn't found yet. Unfortunately, we do not have nearly validation on hg38. Here's what I will do: 1) correct our hg38 gnomAD to fix liftover artifacts and put this new resource in the GATK bucket. 2) Create a Firecloud workspace with a few hg38 samples in order to reproduce the error and to make sure future changes don't create new problems 3) try to fix the error because even if 1) works it's sloppy to rely on the fact that gnomAD won't have these edge cases. I hope 1) succeeds because it will be available immediately without waiting for the next release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478305154
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478305154:813,Deployability,release,release,813,"A few recent bugs, which are all entirely my fault, came about because the liftover of gnomAD to hg38 (there is no official hg38 gnomAD yet) exposed some new edge cases, such as `AF=.` and `AF=0`, that caused errors. I suspect that you are seeing one that we hadn't found yet. Unfortunately, we do not have nearly validation on hg38. Here's what I will do: 1) correct our hg38 gnomAD to fix liftover artifacts and put this new resource in the GATK bucket. 2) Create a Firecloud workspace with a few hg38 samples in order to reproduce the error and to make sure future changes don't create new problems 3) try to fix the error because even if 1) works it's sloppy to rely on the fact that gnomAD won't have these edge cases. I hope 1) succeeds because it will be available immediately without waiting for the next release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478305154
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478305154:141,Security,expose,exposed,141,"A few recent bugs, which are all entirely my fault, came about because the liftover of gnomAD to hg38 (there is no official hg38 gnomAD yet) exposed some new edge cases, such as `AF=.` and `AF=0`, that caused errors. I suspect that you are seeing one that we hadn't found yet. Unfortunately, we do not have nearly validation on hg38. Here's what I will do: 1) correct our hg38 gnomAD to fix liftover artifacts and put this new resource in the GATK bucket. 2) Create a Firecloud workspace with a few hg38 samples in order to reproduce the error and to make sure future changes don't create new problems 3) try to fix the error because even if 1) works it's sloppy to rely on the fact that gnomAD won't have these edge cases. I hope 1) succeeds because it will be available immediately without waiting for the next release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478305154
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478305154:314,Security,validat,validation,314,"A few recent bugs, which are all entirely my fault, came about because the liftover of gnomAD to hg38 (there is no official hg38 gnomAD yet) exposed some new edge cases, such as `AF=.` and `AF=0`, that caused errors. I suspect that you are seeing one that we hadn't found yet. Unfortunately, we do not have nearly validation on hg38. Here's what I will do: 1) correct our hg38 gnomAD to fix liftover artifacts and put this new resource in the GATK bucket. 2) Create a Firecloud workspace with a few hg38 samples in order to reproduce the error and to make sure future changes don't create new problems 3) try to fix the error because even if 1) works it's sloppy to rely on the fact that gnomAD won't have these edge cases. I hope 1) succeeds because it will be available immediately without waiting for the next release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478305154
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478308972:173,Availability,error,error,173,"Thank you for looking into it. I am curious if that is really the problem. If the reference files were causing problems, shouldn't that impact all samples? I am seeing this error with some, but not most of the samples. Even using a different matched control sample with the same tumor sample will cause or fix the error.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478308972
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478308972:314,Availability,error,error,314,"Thank you for looking into it. I am curious if that is really the problem. If the reference files were causing problems, shouldn't that impact all samples? I am seeing this error with some, but not most of the samples. Even using a different matched control sample with the same tumor sample will cause or fix the error.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478308972
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478310143:128,Availability,error,error,128,"What we saw recently wasn't the reference itself, but rather our AF-only gnomAD resource lifted-over to the hg38 reference. The error only came up for sites that reached genotyping, which depends on the specific tumor sample as well as the lack of evidence in the normal. That's why it only appeared in some tumor-normal combinations. That being said, it might be something else. If you are able to share the unfiltered vcf file and the vcf.stats file it would be the most direct way to debug.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478310143
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478310143:188,Integrability,depend,depends,188,"What we saw recently wasn't the reference itself, but rather our AF-only gnomAD resource lifted-over to the hg38 reference. The error only came up for sites that reached genotyping, which depends on the specific tumor sample as well as the lack of evidence in the normal. That's why it only appeared in some tumor-normal combinations. That being said, it might be something else. If you are able to share the unfiltered vcf file and the vcf.stats file it would be the most direct way to debug.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478310143
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478444912:53,Availability,error,error,53,"@igordot I have not yet succeeded in reproducing the error with the few hg38 samples I have tested (2) and nothing obvious showed up in various `grep` regexes of our hg38 gnomAD (1). I am starting to think that we actually have solved all the hg38 issues and this is unrelated to my initial guess. If you can share your unfiltered vcf input it would be very helpful, but if that's not possible could you post the contents of your `contamination-table` input? I have a hunch that the small size of the panel is causing `CalculateContamination` to give an unreliable result. For targeted panels we recommend running Mutect2 without CalculateContamination. If you're running from Terra/Firecloud or from the wdl, this means leaving the optional `variants_for_contamination` input empty.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478444912
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478444912:92,Testability,test,tested,92,"@igordot I have not yet succeeded in reproducing the error with the few hg38 samples I have tested (2) and nothing obvious showed up in various `grep` regexes of our hg38 gnomAD (1). I am starting to think that we actually have solved all the hg38 issues and this is unrelated to my initial guess. If you can share your unfiltered vcf input it would be very helpful, but if that's not possible could you post the contents of your `contamination-table` input? I have a hunch that the small size of the panel is causing `CalculateContamination` to give an unreliable result. For targeted panels we recommend running Mutect2 without CalculateContamination. If you're running from Terra/Firecloud or from the wdl, this means leaving the optional `variants_for_contamination` input empty.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-478444912
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-479221105:19,Availability,error,error,19,"You are right. The error seems to be happening when contamination is 1 or NaN. That is probably due to a non-matched normal. The same panel with a true matched normal gives much more reasonable results (<0.01), so I don't know if the panel size is entirely at fault here. Should `FilterMutectCalls` just ignore contamination if the error is sufficiently high?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-479221105
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-479221105:260,Availability,fault,fault,260,"You are right. The error seems to be happening when contamination is 1 or NaN. That is probably due to a non-matched normal. The same panel with a true matched normal gives much more reasonable results (<0.01), so I don't know if the panel size is entirely at fault here. Should `FilterMutectCalls` just ignore contamination if the error is sufficiently high?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-479221105
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-479221105:332,Availability,error,error,332,"You are right. The error seems to be happening when contamination is 1 or NaN. That is probably due to a non-matched normal. The same panel with a true matched normal gives much more reasonable results (<0.01), so I don't know if the panel size is entirely at fault here. Should `FilterMutectCalls` just ignore contamination if the error is sufficiently high?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-479221105
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-479345686:823,Availability,avail,available,823,"@igordot Thanks very much for following up on this. Just to clarify, are you saying that the 1/NaN contamination occurs when you run `GetPileupSummaries` on both the tumor and a non-matched normal and then run `CalculateContamination` using both of these outputs? If so, that will definitely cause problems. Running `CalculateContamination` on just the tumor output from `GetPileupSummaries` should work much better. We went to great lengths to make `CalculateContamination` work in tumor-only mode, although I would still be wary if your target territory is less than a few megabases. Also, I would not recommend using a non-matched normal *anywhere* in `Mutect2`. Unless your panel has unique technical artifacts that don't resemble those in an exome I would recommend you run tumor-only mode but use use of the publicly-available panels of normals in the GATK bucket. A worse alternative but in my opinion still better than a non-matched normal would be to run Mutect2 in tumor-only mode *separately* on the tumor samples and the unmatched normal, then use the unmatched normal vcf as a blacklist for the tumor calls with `SelectVariants`.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-479345686
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-481902753:9,Security,access,access,9,How do I access that? I thought that the GATK resources were located here: https://console.cloud.google.com/storage/browser/genomics-public-data/resources/broad/hg38/v0/. Is there a reason this is not in the GATK resource bundle?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-481902753
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-481919351:223,Availability,down,download,223,"They're public, so just install Google Cloud gsutil and copy with `gsutil cp gs://gatk-best-practices/somatic-b37/Mutect2-exome-panel.vcf <local path to copy to>`. Or, if you're running on the cloud, you don't even need to download anything, just run Mutect2 with the cloud paths eg ; ```; gatk Mutect2 -R ref.fasta -I tumor.bam -pon gs://gatk-best-practices/somatic-b37/Mutect2-exome-panel.vcf -O calls.vcf; ```; If you install gsutil this works when running locally as well, but for speed I would recommend downloading the pon. > Is there a reason this is not in the GATK resource bundle?. Not that I can think of.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-481919351
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-481919351:509,Availability,down,downloading,509,"They're public, so just install Google Cloud gsutil and copy with `gsutil cp gs://gatk-best-practices/somatic-b37/Mutect2-exome-panel.vcf <local path to copy to>`. Or, if you're running on the cloud, you don't even need to download anything, just run Mutect2 with the cloud paths eg ; ```; gatk Mutect2 -R ref.fasta -I tumor.bam -pon gs://gatk-best-practices/somatic-b37/Mutect2-exome-panel.vcf -O calls.vcf; ```; If you install gsutil this works when running locally as well, but for speed I would recommend downloading the pon. > Is there a reason this is not in the GATK resource bundle?. Not that I can think of.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-481919351
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-481919351:24,Deployability,install,install,24,"They're public, so just install Google Cloud gsutil and copy with `gsutil cp gs://gatk-best-practices/somatic-b37/Mutect2-exome-panel.vcf <local path to copy to>`. Or, if you're running on the cloud, you don't even need to download anything, just run Mutect2 with the cloud paths eg ; ```; gatk Mutect2 -R ref.fasta -I tumor.bam -pon gs://gatk-best-practices/somatic-b37/Mutect2-exome-panel.vcf -O calls.vcf; ```; If you install gsutil this works when running locally as well, but for speed I would recommend downloading the pon. > Is there a reason this is not in the GATK resource bundle?. Not that I can think of.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-481919351
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-481919351:421,Deployability,install,install,421,"They're public, so just install Google Cloud gsutil and copy with `gsutil cp gs://gatk-best-practices/somatic-b37/Mutect2-exome-panel.vcf <local path to copy to>`. Or, if you're running on the cloud, you don't even need to download anything, just run Mutect2 with the cloud paths eg ; ```; gatk Mutect2 -R ref.fasta -I tumor.bam -pon gs://gatk-best-practices/somatic-b37/Mutect2-exome-panel.vcf -O calls.vcf; ```; If you install gsutil this works when running locally as well, but for speed I would recommend downloading the pon. > Is there a reason this is not in the GATK resource bundle?. Not that I can think of.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-481919351
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547566300:1099,Availability,error,errorProbability,1099,java.lang.IllegalArgumentException: log10 p: Values must be non-infinite and non-NAN; 2019-10-29T18:18:04.001018863Z 	at org.broadinstitute.hellbender.utils.NaturalLogUtils.logSumExp(NaturalLogUtils.java:84); 2019-10-29T18:18:04.001194549Z 	at org.broadinstitute.hellbender.utils.NaturalLogUtils.normalizeLog(NaturalLogUtils.java:51); 2019-10-29T18:18:04.001367357Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.clusterProbabilities(SomaticClusteringModel.java:203); 2019-10-29T18:18:04.001518160Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.probabilityOfSequencingError(SomaticClusteringModel.java:96); 2019-10-29T18:18:04.001673083Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.TumorEvidenceFilter.calculateErrorProbability(TumorEvidenceFilter.java:27); 2019-10-29T18:18:04.001846904Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 2019-10-29T18:18:04.002024760Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 2019-10-29T18:18:04.002140012Z 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 2019-10-29T18:18:04.002232542Z 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 2019-10-29T18:18:04.002242727Z 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 2019-10-29T18:18:04.002292461Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 2019-10-29T18:18:04.002301667Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 2019-10-29T18:18:04.002307019Z 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 2019-10-29T18:18:04.002311722Z 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 2019-10-29T18:18:04.002316449Z 	at java.util.stream.Refer,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547566300
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547566300:1243,Availability,Error,ErrorProbabilities,1243,itute.hellbender.utils.NaturalLogUtils.logSumExp(NaturalLogUtils.java:84); 2019-10-29T18:18:04.001194549Z 	at org.broadinstitute.hellbender.utils.NaturalLogUtils.normalizeLog(NaturalLogUtils.java:51); 2019-10-29T18:18:04.001367357Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.clusterProbabilities(SomaticClusteringModel.java:203); 2019-10-29T18:18:04.001518160Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.probabilityOfSequencingError(SomaticClusteringModel.java:96); 2019-10-29T18:18:04.001673083Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.TumorEvidenceFilter.calculateErrorProbability(TumorEvidenceFilter.java:27); 2019-10-29T18:18:04.001846904Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 2019-10-29T18:18:04.002024760Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 2019-10-29T18:18:04.002140012Z 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 2019-10-29T18:18:04.002232542Z 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 2019-10-29T18:18:04.002242727Z 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 2019-10-29T18:18:04.002292461Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 2019-10-29T18:18:04.002301667Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 2019-10-29T18:18:04.002307019Z 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 2019-10-29T18:18:04.002311722Z 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 2019-10-29T18:18:04.002316449Z 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 2019-10-29T18:18:04.002321526Z 	at org.broadinstitute.hellbender.tools.walkers.mutect,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547566300
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547566300:1275,Availability,Error,ErrorProbabilities,1275,uralLogUtils.logSumExp(NaturalLogUtils.java:84); 2019-10-29T18:18:04.001194549Z 	at org.broadinstitute.hellbender.utils.NaturalLogUtils.normalizeLog(NaturalLogUtils.java:51); 2019-10-29T18:18:04.001367357Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.clusterProbabilities(SomaticClusteringModel.java:203); 2019-10-29T18:18:04.001518160Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.probabilityOfSequencingError(SomaticClusteringModel.java:96); 2019-10-29T18:18:04.001673083Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.TumorEvidenceFilter.calculateErrorProbability(TumorEvidenceFilter.java:27); 2019-10-29T18:18:04.001846904Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 2019-10-29T18:18:04.002024760Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 2019-10-29T18:18:04.002140012Z 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 2019-10-29T18:18:04.002232542Z 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 2019-10-29T18:18:04.002242727Z 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 2019-10-29T18:18:04.002292461Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 2019-10-29T18:18:04.002301667Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 2019-10-29T18:18:04.002307019Z 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 2019-10-29T18:18:04.002311722Z 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 2019-10-29T18:18:04.002316449Z 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 2019-10-29T18:18:04.002321526Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabili,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547566300
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547566300:2264,Availability,Error,ErrorProbabilities,2264,1(ErrorProbabilities.java:19); 2019-10-29T18:18:04.002140012Z 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 2019-10-29T18:18:04.002232542Z 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 2019-10-29T18:18:04.002242727Z 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 2019-10-29T18:18:04.002292461Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 2019-10-29T18:18:04.002301667Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 2019-10-29T18:18:04.002307019Z 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 2019-10-29T18:18:04.002311722Z 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 2019-10-29T18:18:04.002316449Z 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 2019-10-29T18:18:04.002321526Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 2019-10-29T18:18:04.002358113Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:141); 2019-10-29T18:18:04.002377342Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:146); 2019-10-29T18:18:04.002383406Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40); 2019-10-29T18:18:04.002431769Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:77); 2019-10-29T18:18:04.002441351Z 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 2019-10-29T18:18:04.002446409Z 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 2019-10-29T18:18:04.002493533Z 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 2019-10-29,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547566300
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547566300:2290,Availability,Error,ErrorProbabilities,2290,va:19); 2019-10-29T18:18:04.002140012Z 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 2019-10-29T18:18:04.002232542Z 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 2019-10-29T18:18:04.002242727Z 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 2019-10-29T18:18:04.002292461Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 2019-10-29T18:18:04.002301667Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 2019-10-29T18:18:04.002307019Z 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 2019-10-29T18:18:04.002311722Z 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 2019-10-29T18:18:04.002316449Z 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 2019-10-29T18:18:04.002321526Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 2019-10-29T18:18:04.002358113Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:141); 2019-10-29T18:18:04.002377342Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:146); 2019-10-29T18:18:04.002383406Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40); 2019-10-29T18:18:04.002431769Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:77); 2019-10-29T18:18:04.002441351Z 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 2019-10-29T18:18:04.002446409Z 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 2019-10-29T18:18:04.002493533Z 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 2019-10-29T18:18:04.002503311Z 	,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547566300
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547566300:5279,Availability,error,error,5279,"51Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverse(MultiplePassVariantWalker.java:40); 2019-10-29T18:18:04.002731707Z 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); 2019-10-29T18:18:04.002740306Z 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 2019-10-29T18:18:04.002745164Z 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 2019-10-29T18:18:04.002777218Z 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 2019-10-29T18:18:04.002785268Z 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); 2019-10-29T18:18:04.002855927Z 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); 2019-10-29T18:18:04.002867030Z 	at org.broadinstitute.hellbender.Main.main(Main.java:291); ```; I am using ExAC lifted to hg38 as a germline resource in mutect2 with only a tumor sample, and getting the above error in filtermutectcalls. I recently updated to v4.1.3.0 to have the latest changes to mutect2. I was not having this issue with v4.0.5.1. Here is extracted information from the VCF which caused the issue. . ```; DP=1;ECNT=2;FS=0.000;MBQ=0,20;MFRL=0,91;MMQ=60,46;MPOS=6;MQ=46.00;POPAF=5.08;TLOD=4.20	GT:AD:AF:DP:F1R2:F2R1:PGT:PID:PS:SB	0|1:0,1:0.667:1:0,1:0,0:0|1:11155815_C_T:11155815:0,0,1,0; DP=1;ECNT=2;FS=0.000;MBQ=0,20;MFRL=0,91;MMQ=60,46;MPOS=16;MQ=46.00;POPAF=5.08;TLOD=4.20	GT:AD:AF:DP:F1R2:F2R1:PGT:PID:PS:SB	0|1:0,1:0.667:1:0,1:0,0:0|1:11155815_C_T:11155815:0,0,1,0; DP=1;ECNT=2;FS=0.000;MBQ=0,34;MFRL=0,272;MMQ=60,30;MPOS=25;MQ=30.00;POPAF=4.13;TLOD=4.20	GT:AD:AF:DP:F1R2:F2R1:PGT:PID:PS:SB	0|1:0,1:0.667:1:0,1:0,0:0|1:11350899_C_T:11350899:0,0,1,0; DP=1;ECNT=2;FS=0.000;MBQ=0,32;MFRL=0,272;MMQ=60,30;MPOS=15;MQ=30.00;POPAF=4.23;TLOD=4.20	GT:AD:AF:DP:F1R2:F2R1:PGT:PID:PS:SB	0|1:0,1:0.667:1:0,1:0,0:0|1:11350899_C_T:11350899:0,0,1,0; `",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547566300
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547566300:5318,Deployability,update,updated,5318,"Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverse(MultiplePassVariantWalker.java:40); 2019-10-29T18:18:04.002731707Z 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); 2019-10-29T18:18:04.002740306Z 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 2019-10-29T18:18:04.002745164Z 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 2019-10-29T18:18:04.002777218Z 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 2019-10-29T18:18:04.002785268Z 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); 2019-10-29T18:18:04.002855927Z 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); 2019-10-29T18:18:04.002867030Z 	at org.broadinstitute.hellbender.Main.main(Main.java:291); ```; I am using ExAC lifted to hg38 as a germline resource in mutect2 with only a tumor sample, and getting the above error in filtermutectcalls. I recently updated to v4.1.3.0 to have the latest changes to mutect2. I was not having this issue with v4.0.5.1. Here is extracted information from the VCF which caused the issue. . ```; DP=1;ECNT=2;FS=0.000;MBQ=0,20;MFRL=0,91;MMQ=60,46;MPOS=6;MQ=46.00;POPAF=5.08;TLOD=4.20	GT:AD:AF:DP:F1R2:F2R1:PGT:PID:PS:SB	0|1:0,1:0.667:1:0,1:0,0:0|1:11155815_C_T:11155815:0,0,1,0; DP=1;ECNT=2;FS=0.000;MBQ=0,20;MFRL=0,91;MMQ=60,46;MPOS=16;MQ=46.00;POPAF=5.08;TLOD=4.20	GT:AD:AF:DP:F1R2:F2R1:PGT:PID:PS:SB	0|1:0,1:0.667:1:0,1:0,0:0|1:11155815_C_T:11155815:0,0,1,0; DP=1;ECNT=2;FS=0.000;MBQ=0,34;MFRL=0,272;MMQ=60,30;MPOS=25;MQ=30.00;POPAF=4.13;TLOD=4.20	GT:AD:AF:DP:F1R2:F2R1:PGT:PID:PS:SB	0|1:0,1:0.667:1:0,1:0,0:0|1:11350899_C_T:11350899:0,0,1,0; DP=1;ECNT=2;FS=0.000;MBQ=0,32;MFRL=0,272;MMQ=60,30;MPOS=15;MQ=30.00;POPAF=4.23;TLOD=4.20	GT:AD:AF:DP:F1R2:F2R1:PGT:PID:PS:SB	0|1:0,1:0.667:1:0,1:0,0:0|1:11350899_C_T:11350899:0,0,1,0; ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547566300
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547566300:1458,Energy Efficiency,Reduce,ReduceOps,1458,04.001367357Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.clusterProbabilities(SomaticClusteringModel.java:203); 2019-10-29T18:18:04.001518160Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.probabilityOfSequencingError(SomaticClusteringModel.java:96); 2019-10-29T18:18:04.001673083Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.TumorEvidenceFilter.calculateErrorProbability(TumorEvidenceFilter.java:27); 2019-10-29T18:18:04.001846904Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 2019-10-29T18:18:04.002024760Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 2019-10-29T18:18:04.002140012Z 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 2019-10-29T18:18:04.002232542Z 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 2019-10-29T18:18:04.002242727Z 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 2019-10-29T18:18:04.002292461Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 2019-10-29T18:18:04.002301667Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 2019-10-29T18:18:04.002307019Z 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 2019-10-29T18:18:04.002311722Z 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 2019-10-29T18:18:04.002316449Z 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 2019-10-29T18:18:04.002321526Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 2019-10-29T18:18:04.002358113Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringE,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547566300
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547566300:1489,Energy Efficiency,Reduce,ReduceOps,1489,g.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.clusterProbabilities(SomaticClusteringModel.java:203); 2019-10-29T18:18:04.001518160Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.probabilityOfSequencingError(SomaticClusteringModel.java:96); 2019-10-29T18:18:04.001673083Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.TumorEvidenceFilter.calculateErrorProbability(TumorEvidenceFilter.java:27); 2019-10-29T18:18:04.001846904Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 2019-10-29T18:18:04.002024760Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 2019-10-29T18:18:04.002140012Z 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 2019-10-29T18:18:04.002232542Z 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 2019-10-29T18:18:04.002242727Z 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 2019-10-29T18:18:04.002292461Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 2019-10-29T18:18:04.002301667Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 2019-10-29T18:18:04.002307019Z 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 2019-10-29T18:18:04.002311722Z 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 2019-10-29T18:18:04.002316449Z 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 2019-10-29T18:18:04.002321526Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 2019-10-29T18:18:04.002358113Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:141); 2019,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547566300
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547566300:1896,Energy Efficiency,Reduce,ReduceOps,1896,.TumorEvidenceFilter.calculateErrorProbability(TumorEvidenceFilter.java:27); 2019-10-29T18:18:04.001846904Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 2019-10-29T18:18:04.002024760Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 2019-10-29T18:18:04.002140012Z 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 2019-10-29T18:18:04.002232542Z 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 2019-10-29T18:18:04.002242727Z 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 2019-10-29T18:18:04.002292461Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 2019-10-29T18:18:04.002301667Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 2019-10-29T18:18:04.002307019Z 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 2019-10-29T18:18:04.002311722Z 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 2019-10-29T18:18:04.002316449Z 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 2019-10-29T18:18:04.002321526Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 2019-10-29T18:18:04.002358113Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:141); 2019-10-29T18:18:04.002377342Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:146); 2019-10-29T18:18:04.002383406Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40); 2019-10-29T18:18:04.002431769Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traver,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547566300
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547566300:1906,Energy Efficiency,Reduce,ReduceOp,1906,.TumorEvidenceFilter.calculateErrorProbability(TumorEvidenceFilter.java:27); 2019-10-29T18:18:04.001846904Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 2019-10-29T18:18:04.002024760Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 2019-10-29T18:18:04.002140012Z 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 2019-10-29T18:18:04.002232542Z 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 2019-10-29T18:18:04.002242727Z 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 2019-10-29T18:18:04.002292461Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 2019-10-29T18:18:04.002301667Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 2019-10-29T18:18:04.002307019Z 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 2019-10-29T18:18:04.002311722Z 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 2019-10-29T18:18:04.002316449Z 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 2019-10-29T18:18:04.002321526Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 2019-10-29T18:18:04.002358113Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:141); 2019-10-29T18:18:04.002377342Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:146); 2019-10-29T18:18:04.002383406Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40); 2019-10-29T18:18:04.002431769Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traver,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547566300
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547566300:1934,Energy Efficiency,Reduce,ReduceOps,1934,culateErrorProbability(TumorEvidenceFilter.java:27); 2019-10-29T18:18:04.001846904Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 2019-10-29T18:18:04.002024760Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 2019-10-29T18:18:04.002140012Z 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 2019-10-29T18:18:04.002232542Z 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 2019-10-29T18:18:04.002242727Z 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 2019-10-29T18:18:04.002292461Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 2019-10-29T18:18:04.002301667Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 2019-10-29T18:18:04.002307019Z 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 2019-10-29T18:18:04.002311722Z 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 2019-10-29T18:18:04.002316449Z 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 2019-10-29T18:18:04.002321526Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 2019-10-29T18:18:04.002358113Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:141); 2019-10-29T18:18:04.002377342Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:146); 2019-10-29T18:18:04.002383406Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40); 2019-10-29T18:18:04.002431769Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePas,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547566300
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547566300:1800,Integrability,wrap,wrapAndCopyInto,1800,0-29T18:18:04.001673083Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.TumorEvidenceFilter.calculateErrorProbability(TumorEvidenceFilter.java:27); 2019-10-29T18:18:04.001846904Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 2019-10-29T18:18:04.002024760Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 2019-10-29T18:18:04.002140012Z 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 2019-10-29T18:18:04.002232542Z 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 2019-10-29T18:18:04.002242727Z 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 2019-10-29T18:18:04.002292461Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 2019-10-29T18:18:04.002301667Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 2019-10-29T18:18:04.002307019Z 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 2019-10-29T18:18:04.002311722Z 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 2019-10-29T18:18:04.002316449Z 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 2019-10-29T18:18:04.002321526Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 2019-10-29T18:18:04.002358113Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:141); 2019-10-29T18:18:04.002377342Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:146); 2019-10-29T18:18:04.002383406Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40); 2019-10-29T18:18:04.00,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547566300
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547566300:3559,Integrability,wrap,wrapAndCopyInto,3559,ltering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:146); 2019-10-29T18:18:04.002383406Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40); 2019-10-29T18:18:04.002431769Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:77); 2019-10-29T18:18:04.002441351Z 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 2019-10-29T18:18:04.002446409Z 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 2019-10-29T18:18:04.002493533Z 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 2019-10-29T18:18:04.002503311Z 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 2019-10-29T18:18:04.002508016Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 2019-10-29T18:18:04.002512520Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 2019-10-29T18:18:04.002574562Z 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 2019-10-29T18:18:04.002625341Z 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 2019-10-29T18:18:04.002635077Z 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 2019-10-29T18:18:04.002683298Z 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 2019-10-29T18:18:04.002692496Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverseVariants(MultiplePassVariantWalker.java:75); 2019-10-29T18:18:04.002697751Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverse(MultiplePassVariantWalker.java:40); 2019-10-29T18:18:04.002731707Z 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); 2019-10-29T18:18:04.002740306Z 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547566300
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547566300:291,Testability,log,logSumExp,291,I think this issue still persists: ; The Genome Analysis Toolkit (GATK) v4.1.3.0; ```; 2019-10-29T18:18:04.000640760Z java.lang.IllegalArgumentException: log10 p: Values must be non-infinite and non-NAN; 2019-10-29T18:18:04.001018863Z 	at org.broadinstitute.hellbender.utils.NaturalLogUtils.logSumExp(NaturalLogUtils.java:84); 2019-10-29T18:18:04.001194549Z 	at org.broadinstitute.hellbender.utils.NaturalLogUtils.normalizeLog(NaturalLogUtils.java:51); 2019-10-29T18:18:04.001367357Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.clusterProbabilities(SomaticClusteringModel.java:203); 2019-10-29T18:18:04.001518160Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.probabilityOfSequencingError(SomaticClusteringModel.java:96); 2019-10-29T18:18:04.001673083Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.TumorEvidenceFilter.calculateErrorProbability(TumorEvidenceFilter.java:27); 2019-10-29T18:18:04.001846904Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 2019-10-29T18:18:04.002024760Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 2019-10-29T18:18:04.002140012Z 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 2019-10-29T18:18:04.002232542Z 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 2019-10-29T18:18:04.002242727Z 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 2019-10-29T18:18:04.002292461Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 2019-10-29T18:18:04.002301667Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 2019-10-29T18:18:04.002307019Z 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 2019-10-29T18:18:04.002311722Z 	at java.util.s,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547566300
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547615531:46,Availability,avail,available,46,"Yes, I will try. I didn't realize 4.1.4.0 was available.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547615531
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547909227:69,Availability,error,error,69,I loaded the docker repo GATK v4.1.4.0 and had the same (or similar) error result. ```; 2019-10-30T13:35:51.791637449Z java.lang.IllegalArgumentException: log10 p: Values must be non-infinite and non-NAN; 2019-10-30T13:35:51.792001654Z 	at org.broadinstitute.hellbender.utils.NaturalLogUtils.logSumExp(NaturalLogUtils.java:84); 2019-10-30T13:35:51.792175325Z 	at org.broadinstitute.hellbender.utils.NaturalLogUtils.normalizeLog(NaturalLogUtils.java:51); 2019-10-30T13:35:51.792358868Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.clusterProbabilities(SomaticClusteringModel.java:203); 2019-10-30T13:35:51.792559803Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.probabilityOfSequencingError(SomaticClusteringModel.java:96); 2019-10-30T13:35:51.792736667Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.TumorEvidenceFilter.calculateErrorProbability(TumorEvidenceFilter.java:27); 2019-10-30T13:35:51.792905235Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 2019-10-30T13:35:51.793072365Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 2019-10-30T13:35:51.793261944Z 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 2019-10-30T13:35:51.793456807Z 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 2019-10-30T13:35:51.793619935Z 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 2019-10-30T13:35:51.793810301Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 2019-10-30T13:35:51.794006885Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 2019-10-30T13:35:51.794191116Z 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 2019-10-30T13:35:51.794367593Z 	at java.util.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547909227
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547909227:1100,Availability,error,errorProbability,1100,java.lang.IllegalArgumentException: log10 p: Values must be non-infinite and non-NAN; 2019-10-30T13:35:51.792001654Z 	at org.broadinstitute.hellbender.utils.NaturalLogUtils.logSumExp(NaturalLogUtils.java:84); 2019-10-30T13:35:51.792175325Z 	at org.broadinstitute.hellbender.utils.NaturalLogUtils.normalizeLog(NaturalLogUtils.java:51); 2019-10-30T13:35:51.792358868Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.clusterProbabilities(SomaticClusteringModel.java:203); 2019-10-30T13:35:51.792559803Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.probabilityOfSequencingError(SomaticClusteringModel.java:96); 2019-10-30T13:35:51.792736667Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.TumorEvidenceFilter.calculateErrorProbability(TumorEvidenceFilter.java:27); 2019-10-30T13:35:51.792905235Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 2019-10-30T13:35:51.793072365Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 2019-10-30T13:35:51.793261944Z 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 2019-10-30T13:35:51.793456807Z 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 2019-10-30T13:35:51.793619935Z 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 2019-10-30T13:35:51.793810301Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 2019-10-30T13:35:51.794006885Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 2019-10-30T13:35:51.794191116Z 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 2019-10-30T13:35:51.794367593Z 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 2019-10-30T13:35:51.794548129Z 	at java.util.stream.Refer,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547909227
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547909227:1244,Availability,Error,ErrorProbabilities,1244,itute.hellbender.utils.NaturalLogUtils.logSumExp(NaturalLogUtils.java:84); 2019-10-30T13:35:51.792175325Z 	at org.broadinstitute.hellbender.utils.NaturalLogUtils.normalizeLog(NaturalLogUtils.java:51); 2019-10-30T13:35:51.792358868Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.clusterProbabilities(SomaticClusteringModel.java:203); 2019-10-30T13:35:51.792559803Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.probabilityOfSequencingError(SomaticClusteringModel.java:96); 2019-10-30T13:35:51.792736667Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.TumorEvidenceFilter.calculateErrorProbability(TumorEvidenceFilter.java:27); 2019-10-30T13:35:51.792905235Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 2019-10-30T13:35:51.793072365Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 2019-10-30T13:35:51.793261944Z 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 2019-10-30T13:35:51.793456807Z 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 2019-10-30T13:35:51.793619935Z 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 2019-10-30T13:35:51.793810301Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 2019-10-30T13:35:51.794006885Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 2019-10-30T13:35:51.794191116Z 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 2019-10-30T13:35:51.794367593Z 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 2019-10-30T13:35:51.794548129Z 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 2019-10-30T13:35:51.794722501Z 	at org.broadinstitute.hellbender.tools.walkers.mutect,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547909227
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547909227:1276,Availability,Error,ErrorProbabilities,1276,uralLogUtils.logSumExp(NaturalLogUtils.java:84); 2019-10-30T13:35:51.792175325Z 	at org.broadinstitute.hellbender.utils.NaturalLogUtils.normalizeLog(NaturalLogUtils.java:51); 2019-10-30T13:35:51.792358868Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.clusterProbabilities(SomaticClusteringModel.java:203); 2019-10-30T13:35:51.792559803Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.probabilityOfSequencingError(SomaticClusteringModel.java:96); 2019-10-30T13:35:51.792736667Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.TumorEvidenceFilter.calculateErrorProbability(TumorEvidenceFilter.java:27); 2019-10-30T13:35:51.792905235Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 2019-10-30T13:35:51.793072365Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 2019-10-30T13:35:51.793261944Z 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 2019-10-30T13:35:51.793456807Z 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 2019-10-30T13:35:51.793619935Z 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 2019-10-30T13:35:51.793810301Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 2019-10-30T13:35:51.794006885Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 2019-10-30T13:35:51.794191116Z 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 2019-10-30T13:35:51.794367593Z 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 2019-10-30T13:35:51.794548129Z 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 2019-10-30T13:35:51.794722501Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabili,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547909227
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547909227:2265,Availability,Error,ErrorProbabilities,2265,1(ErrorProbabilities.java:19); 2019-10-30T13:35:51.793261944Z 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 2019-10-30T13:35:51.793456807Z 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 2019-10-30T13:35:51.793619935Z 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 2019-10-30T13:35:51.793810301Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 2019-10-30T13:35:51.794006885Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 2019-10-30T13:35:51.794191116Z 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 2019-10-30T13:35:51.794367593Z 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 2019-10-30T13:35:51.794548129Z 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 2019-10-30T13:35:51.794722501Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 2019-10-30T13:35:51.794896154Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:141); 2019-10-30T13:35:51.795082090Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:146); 2019-10-30T13:35:51.795253632Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40); 2019-10-30T13:35:51.795448274Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:77); 2019-10-30T13:35:51.795607447Z 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 2019-10-30T13:35:51.795775473Z 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 2019-10-30T13:35:51.795944490Z 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 2019-10-30,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547909227
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547909227:2291,Availability,Error,ErrorProbabilities,2291,va:19); 2019-10-30T13:35:51.793261944Z 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 2019-10-30T13:35:51.793456807Z 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 2019-10-30T13:35:51.793619935Z 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 2019-10-30T13:35:51.793810301Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 2019-10-30T13:35:51.794006885Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 2019-10-30T13:35:51.794191116Z 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 2019-10-30T13:35:51.794367593Z 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 2019-10-30T13:35:51.794548129Z 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 2019-10-30T13:35:51.794722501Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 2019-10-30T13:35:51.794896154Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:141); 2019-10-30T13:35:51.795082090Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:146); 2019-10-30T13:35:51.795253632Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40); 2019-10-30T13:35:51.795448274Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:77); 2019-10-30T13:35:51.795607447Z 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 2019-10-30T13:35:51.795775473Z 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 2019-10-30T13:35:51.795944490Z 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 2019-10-30T13:35:51.796108757Z 	,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547909227
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547909227:1459,Energy Efficiency,Reduce,ReduceOps,1459,51.792358868Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.clusterProbabilities(SomaticClusteringModel.java:203); 2019-10-30T13:35:51.792559803Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.probabilityOfSequencingError(SomaticClusteringModel.java:96); 2019-10-30T13:35:51.792736667Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.TumorEvidenceFilter.calculateErrorProbability(TumorEvidenceFilter.java:27); 2019-10-30T13:35:51.792905235Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 2019-10-30T13:35:51.793072365Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 2019-10-30T13:35:51.793261944Z 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 2019-10-30T13:35:51.793456807Z 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 2019-10-30T13:35:51.793619935Z 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 2019-10-30T13:35:51.793810301Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 2019-10-30T13:35:51.794006885Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 2019-10-30T13:35:51.794191116Z 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 2019-10-30T13:35:51.794367593Z 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 2019-10-30T13:35:51.794548129Z 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 2019-10-30T13:35:51.794722501Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 2019-10-30T13:35:51.794896154Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringE,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547909227
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547909227:1490,Energy Efficiency,Reduce,ReduceOps,1490,g.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.clusterProbabilities(SomaticClusteringModel.java:203); 2019-10-30T13:35:51.792559803Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.probabilityOfSequencingError(SomaticClusteringModel.java:96); 2019-10-30T13:35:51.792736667Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.TumorEvidenceFilter.calculateErrorProbability(TumorEvidenceFilter.java:27); 2019-10-30T13:35:51.792905235Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 2019-10-30T13:35:51.793072365Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 2019-10-30T13:35:51.793261944Z 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 2019-10-30T13:35:51.793456807Z 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 2019-10-30T13:35:51.793619935Z 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 2019-10-30T13:35:51.793810301Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 2019-10-30T13:35:51.794006885Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 2019-10-30T13:35:51.794191116Z 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 2019-10-30T13:35:51.794367593Z 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 2019-10-30T13:35:51.794548129Z 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 2019-10-30T13:35:51.794722501Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 2019-10-30T13:35:51.794896154Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:141); 2019,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547909227
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547909227:1897,Energy Efficiency,Reduce,ReduceOps,1897,.TumorEvidenceFilter.calculateErrorProbability(TumorEvidenceFilter.java:27); 2019-10-30T13:35:51.792905235Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 2019-10-30T13:35:51.793072365Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 2019-10-30T13:35:51.793261944Z 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 2019-10-30T13:35:51.793456807Z 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 2019-10-30T13:35:51.793619935Z 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 2019-10-30T13:35:51.793810301Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 2019-10-30T13:35:51.794006885Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 2019-10-30T13:35:51.794191116Z 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 2019-10-30T13:35:51.794367593Z 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 2019-10-30T13:35:51.794548129Z 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 2019-10-30T13:35:51.794722501Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 2019-10-30T13:35:51.794896154Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:141); 2019-10-30T13:35:51.795082090Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:146); 2019-10-30T13:35:51.795253632Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40); 2019-10-30T13:35:51.795448274Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traver,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547909227
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547909227:1907,Energy Efficiency,Reduce,ReduceOp,1907,.TumorEvidenceFilter.calculateErrorProbability(TumorEvidenceFilter.java:27); 2019-10-30T13:35:51.792905235Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 2019-10-30T13:35:51.793072365Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 2019-10-30T13:35:51.793261944Z 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 2019-10-30T13:35:51.793456807Z 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 2019-10-30T13:35:51.793619935Z 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 2019-10-30T13:35:51.793810301Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 2019-10-30T13:35:51.794006885Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 2019-10-30T13:35:51.794191116Z 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 2019-10-30T13:35:51.794367593Z 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 2019-10-30T13:35:51.794548129Z 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 2019-10-30T13:35:51.794722501Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 2019-10-30T13:35:51.794896154Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:141); 2019-10-30T13:35:51.795082090Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:146); 2019-10-30T13:35:51.795253632Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40); 2019-10-30T13:35:51.795448274Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traver,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547909227
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547909227:1935,Energy Efficiency,Reduce,ReduceOps,1935,culateErrorProbability(TumorEvidenceFilter.java:27); 2019-10-30T13:35:51.792905235Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 2019-10-30T13:35:51.793072365Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 2019-10-30T13:35:51.793261944Z 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 2019-10-30T13:35:51.793456807Z 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 2019-10-30T13:35:51.793619935Z 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 2019-10-30T13:35:51.793810301Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 2019-10-30T13:35:51.794006885Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 2019-10-30T13:35:51.794191116Z 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 2019-10-30T13:35:51.794367593Z 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 2019-10-30T13:35:51.794548129Z 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 2019-10-30T13:35:51.794722501Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 2019-10-30T13:35:51.794896154Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:141); 2019-10-30T13:35:51.795082090Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:146); 2019-10-30T13:35:51.795253632Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40); 2019-10-30T13:35:51.795448274Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePas,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547909227
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547909227:1801,Integrability,wrap,wrapAndCopyInto,1801,0-30T13:35:51.792736667Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.TumorEvidenceFilter.calculateErrorProbability(TumorEvidenceFilter.java:27); 2019-10-30T13:35:51.792905235Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 2019-10-30T13:35:51.793072365Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 2019-10-30T13:35:51.793261944Z 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 2019-10-30T13:35:51.793456807Z 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 2019-10-30T13:35:51.793619935Z 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 2019-10-30T13:35:51.793810301Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 2019-10-30T13:35:51.794006885Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 2019-10-30T13:35:51.794191116Z 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 2019-10-30T13:35:51.794367593Z 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 2019-10-30T13:35:51.794548129Z 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 2019-10-30T13:35:51.794722501Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.<init>(ErrorProbabilities.java:19); 2019-10-30T13:35:51.794896154Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.accumulateData(Mutect2FilteringEngine.java:141); 2019-10-30T13:35:51.795082090Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:146); 2019-10-30T13:35:51.795253632Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40); 2019-10-30T13:35:51.79,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547909227
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547909227:3560,Integrability,wrap,wrapAndCopyInto,3560,ltering.FilterMutectCalls.nthPassApply(FilterMutectCalls.java:146); 2019-10-30T13:35:51.795253632Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40); 2019-10-30T13:35:51.795448274Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:77); 2019-10-30T13:35:51.795607447Z 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 2019-10-30T13:35:51.795775473Z 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 2019-10-30T13:35:51.795944490Z 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 2019-10-30T13:35:51.796108757Z 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 2019-10-30T13:35:51.796277399Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 2019-10-30T13:35:51.796441683Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 2019-10-30T13:35:51.796940319Z 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 2019-10-30T13:35:51.797119562Z 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 2019-10-30T13:35:51.797275911Z 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 2019-10-30T13:35:51.797439525Z 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 2019-10-30T13:35:51.797567816Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverseVariants(MultiplePassVariantWalker.java:75); 2019-10-30T13:35:51.797740910Z 	at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverse(MultiplePassVariantWalker.java:40); 2019-10-30T13:35:51.797896360Z 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); 2019-10-30T13:35:51.798060735Z 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547909227
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547909227:2,Performance,load,loaded,2,I loaded the docker repo GATK v4.1.4.0 and had the same (or similar) error result. ```; 2019-10-30T13:35:51.791637449Z java.lang.IllegalArgumentException: log10 p: Values must be non-infinite and non-NAN; 2019-10-30T13:35:51.792001654Z 	at org.broadinstitute.hellbender.utils.NaturalLogUtils.logSumExp(NaturalLogUtils.java:84); 2019-10-30T13:35:51.792175325Z 	at org.broadinstitute.hellbender.utils.NaturalLogUtils.normalizeLog(NaturalLogUtils.java:51); 2019-10-30T13:35:51.792358868Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.clusterProbabilities(SomaticClusteringModel.java:203); 2019-10-30T13:35:51.792559803Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.probabilityOfSequencingError(SomaticClusteringModel.java:96); 2019-10-30T13:35:51.792736667Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.TumorEvidenceFilter.calculateErrorProbability(TumorEvidenceFilter.java:27); 2019-10-30T13:35:51.792905235Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 2019-10-30T13:35:51.793072365Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 2019-10-30T13:35:51.793261944Z 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 2019-10-30T13:35:51.793456807Z 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 2019-10-30T13:35:51.793619935Z 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 2019-10-30T13:35:51.793810301Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 2019-10-30T13:35:51.794006885Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 2019-10-30T13:35:51.794191116Z 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 2019-10-30T13:35:51.794367593Z 	at java.util.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547909227
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547909227:292,Testability,log,logSumExp,292,I loaded the docker repo GATK v4.1.4.0 and had the same (or similar) error result. ```; 2019-10-30T13:35:51.791637449Z java.lang.IllegalArgumentException: log10 p: Values must be non-infinite and non-NAN; 2019-10-30T13:35:51.792001654Z 	at org.broadinstitute.hellbender.utils.NaturalLogUtils.logSumExp(NaturalLogUtils.java:84); 2019-10-30T13:35:51.792175325Z 	at org.broadinstitute.hellbender.utils.NaturalLogUtils.normalizeLog(NaturalLogUtils.java:51); 2019-10-30T13:35:51.792358868Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.clusterProbabilities(SomaticClusteringModel.java:203); 2019-10-30T13:35:51.792559803Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.probabilityOfSequencingError(SomaticClusteringModel.java:96); 2019-10-30T13:35:51.792736667Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.TumorEvidenceFilter.calculateErrorProbability(TumorEvidenceFilter.java:27); 2019-10-30T13:35:51.792905235Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2VariantFilter.errorProbability(Mutect2VariantFilter.java:15); 2019-10-30T13:35:51.793072365Z 	at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ErrorProbabilities.lambda$new$1(ErrorProbabilities.java:19); 2019-10-30T13:35:51.793261944Z 	at java.util.stream.Collectors.lambda$toMap$58(Collectors.java:1321); 2019-10-30T13:35:51.793456807Z 	at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); 2019-10-30T13:35:51.793619935Z 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); 2019-10-30T13:35:51.793810301Z 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); 2019-10-30T13:35:51.794006885Z 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); 2019-10-30T13:35:51.794191116Z 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 2019-10-30T13:35:51.794367593Z 	at java.util.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-547909227
https://github.com/broadinstitute/gatk/issues/5821#issuecomment-548016293:587,Availability,error,error,587,"@MikeWLloyd It seems like you are running `Mutect2` in parallel, which is totally fine, and then running `FilterMutectCalls` in parallel as well, which is not how the tool works. You need to run `MergeMutectStats` on the `.vcf.stats` files and run `MergeVcfs` on the scattered `.vcf`s, and then run `FilterMutectCalls` with the merged files as inputs. This is implemented in the mutect2 WDL: https://github.com/broadinstitute/gatk/blob/master/scripts/mutect2_wdl/mutect2.wdl and the featured workspace in Terra: https://app.terra.bio/#workspaces/help-gatk/Somatic-SNVs-Indels-GATK4. The error seems to occur because the `.stats` file for the failing interval shows no callable depth. That is, every locus in the interval had a depth less than 10. Once you merge your files I would hope that somewhere in the genome there is a site with greater depth. (If not, you can adjust the threshold with the `--callable-depth` argument)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5821#issuecomment-548016293
https://github.com/broadinstitute/gatk/pull/5823#issuecomment-475397100:232,Availability,error,error-reference,232,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5823?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@06df7e8`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `75.41%`. ```diff; @@ Coverage Diff @@; ## master #5823 +/- ##; ==========================================; Coverage ? 86.834% ; Complexity ? 32337 ; ==========================================; Files ? 1994 ; Lines ? 149405 ; Branches ? 16492 ; ==========================================; Hits ? 129735 ; Misses ? 13654 ; Partials ? 6016; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5823?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...ls/copynumber/gcnv/GermlineCNVNamingConstants.java](https://codecov.io/gh/broadinstitute/gatk/pull/5823/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2djbnYvR2VybWxpbmVDTlZOYW1pbmdDb25zdGFudHMuamF2YQ==) | `0% <ø> (ø)` | `0 <0> (?)` | |; | [...ons/CopyNumberPosteriorDistributionCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/5823/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2Zvcm1hdHMvY29sbGVjdGlvbnMvQ29weU51bWJlclBvc3RlcmlvckRpc3RyaWJ1dGlvbkNvbGxlY3Rpb24uamF2YQ==) | `73.684% <0%> (ø)` | `6 <0> (?)` | |; | [...mats/collections/BaselineCopyNumberCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/5823/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2Zvcm1hdHMvY29sbGVjdGlvbnMvQmFzZWxpbmVDb3B5TnVtYmVyQ29sbGVjdGlvbi5qYXZh) | `63.636% <100%> (ø)` | `3 <0> (?)` | |; | [...ls/copynumber/formats/records/LinearCopyRatio.java](https://codecov.io/gh/broadinstitute/gatk/pull/5823/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2Zvcm1hdHMvcmVjb3,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5823#issuecomment-475397100
https://github.com/broadinstitute/gatk/pull/5823#issuecomment-475397100:180,Usability,learn,learn,180,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5823?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@06df7e8`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `75.41%`. ```diff; @@ Coverage Diff @@; ## master #5823 +/- ##; ==========================================; Coverage ? 86.834% ; Complexity ? 32337 ; ==========================================; Files ? 1994 ; Lines ? 149405 ; Branches ? 16492 ; ==========================================; Hits ? 129735 ; Misses ? 13654 ; Partials ? 6016; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5823?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...ls/copynumber/gcnv/GermlineCNVNamingConstants.java](https://codecov.io/gh/broadinstitute/gatk/pull/5823/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2djbnYvR2VybWxpbmVDTlZOYW1pbmdDb25zdGFudHMuamF2YQ==) | `0% <ø> (ø)` | `0 <0> (?)` | |; | [...ons/CopyNumberPosteriorDistributionCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/5823/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2Zvcm1hdHMvY29sbGVjdGlvbnMvQ29weU51bWJlclBvc3RlcmlvckRpc3RyaWJ1dGlvbkNvbGxlY3Rpb24uamF2YQ==) | `73.684% <0%> (ø)` | `6 <0> (?)` | |; | [...mats/collections/BaselineCopyNumberCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/5823/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2Zvcm1hdHMvY29sbGVjdGlvbnMvQmFzZWxpbmVDb3B5TnVtYmVyQ29sbGVjdGlvbi5qYXZh) | `63.636% <100%> (ø)` | `3 <0> (?)` | |; | [...ls/copynumber/formats/records/LinearCopyRatio.java](https://codecov.io/gh/broadinstitute/gatk/pull/5823/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9jb3B5bnVtYmVyL2Zvcm1hdHMvcmVjb3,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5823#issuecomment-475397100
https://github.com/broadinstitute/gatk/pull/5825#issuecomment-475703103:54,Integrability,message,messages,54,"Thanks for adding this! Incidentally, I noticed a few messages are still emitted by com.github.fommil.jni.JniLoader (which uses a different logger) in CreateReadCountPanelOfNormals when native libraries are loaded by MLlib, but probably more trouble than it's worth to clean those up. Couple of minor comments, looks fine to me but maybe engine team should chime in.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5825#issuecomment-475703103
https://github.com/broadinstitute/gatk/pull/5825#issuecomment-475703103:207,Performance,load,loaded,207,"Thanks for adding this! Incidentally, I noticed a few messages are still emitted by com.github.fommil.jni.JniLoader (which uses a different logger) in CreateReadCountPanelOfNormals when native libraries are loaded by MLlib, but probably more trouble than it's worth to clean those up. Couple of minor comments, looks fine to me but maybe engine team should chime in.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5825#issuecomment-475703103
https://github.com/broadinstitute/gatk/pull/5825#issuecomment-475703103:140,Testability,log,logger,140,"Thanks for adding this! Incidentally, I noticed a few messages are still emitted by com.github.fommil.jni.JniLoader (which uses a different logger) in CreateReadCountPanelOfNormals when native libraries are loaded by MLlib, but probably more trouble than it's worth to clean those up. Couple of minor comments, looks fine to me but maybe engine team should chime in.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5825#issuecomment-475703103
https://github.com/broadinstitute/gatk/pull/5825#issuecomment-478737141:16,Usability,feedback,feedback,16,"Thanks for your feedback, @jamesemery! I just made some changes before I saw your last comment. I liked the idea of using the tool verbosity as the default but allowing the Spark verbosity argument to override it. Even if that has no effect at the moment, I just pushed a solution for that.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5825#issuecomment-478737141
https://github.com/broadinstitute/gatk/pull/5826#issuecomment-475632849:2763,Deployability,update,update,2763,"85 13181 -4 ; - Partials 5915 5916 +1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5826?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...nder/engine/filters/ReadFilterLibraryUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5826/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZmlsdGVycy9SZWFkRmlsdGVyTGlicmFyeVVuaXRUZXN0LmphdmE=) | `100% <100%> (ø)` | `59 <1> (+1)` | :arrow_up: |; | [...e/hellbender/engine/filters/ReadFilterLibrary.java](https://codecov.io/gh/broadinstitute/gatk/pull/5826/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZmlsdGVycy9SZWFkRmlsdGVyTGlicmFyeS5qYXZh) | `94.56% <66.66%> (-0.95%)` | `1 <0> (ø)` | |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5826/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `90% <0%> (+10%)` | `3% <0%> (ø)` | :arrow_down: |; | [...ithwaterman/SmithWatermanIntelAlignerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5826/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXJVbml0VGVzdC5qYXZh) | `90% <0%> (+30%)` | `2% <0%> (ø)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5826?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5826?src=pr&el=footer). Last update [fb2b5a2...e5bcca0](https://codecov.io/gh/broadinstitute/gatk/pull/5826?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5826#issuecomment-475632849
https://github.com/broadinstitute/gatk/pull/5826#issuecomment-475632849:2666,Energy Efficiency,Power,Powered,2666,"85 13181 -4 ; - Partials 5915 5916 +1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5826?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...nder/engine/filters/ReadFilterLibraryUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5826/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZmlsdGVycy9SZWFkRmlsdGVyTGlicmFyeVVuaXRUZXN0LmphdmE=) | `100% <100%> (ø)` | `59 <1> (+1)` | :arrow_up: |; | [...e/hellbender/engine/filters/ReadFilterLibrary.java](https://codecov.io/gh/broadinstitute/gatk/pull/5826/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZmlsdGVycy9SZWFkRmlsdGVyTGlicmFyeS5qYXZh) | `94.56% <66.66%> (-0.95%)` | `1 <0> (ø)` | |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5826/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `90% <0%> (+10%)` | `3% <0%> (ø)` | :arrow_down: |; | [...ithwaterman/SmithWatermanIntelAlignerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5826/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXJVbml0VGVzdC5qYXZh) | `90% <0%> (+30%)` | `2% <0%> (ø)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5826?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5826?src=pr&el=footer). Last update [fb2b5a2...e5bcca0](https://codecov.io/gh/broadinstitute/gatk/pull/5826?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5826#issuecomment-475632849
https://github.com/broadinstitute/gatk/pull/5826#issuecomment-475632849:2529,Usability,learn,learn,2529,"85 13181 -4 ; - Partials 5915 5916 +1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5826?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...nder/engine/filters/ReadFilterLibraryUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5826/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZmlsdGVycy9SZWFkRmlsdGVyTGlicmFyeVVuaXRUZXN0LmphdmE=) | `100% <100%> (ø)` | `59 <1> (+1)` | :arrow_up: |; | [...e/hellbender/engine/filters/ReadFilterLibrary.java](https://codecov.io/gh/broadinstitute/gatk/pull/5826/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZmlsdGVycy9SZWFkRmlsdGVyTGlicmFyeS5qYXZh) | `94.56% <66.66%> (-0.95%)` | `1 <0> (ø)` | |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5826/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `90% <0%> (+10%)` | `3% <0%> (ø)` | :arrow_down: |; | [...ithwaterman/SmithWatermanIntelAlignerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5826/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXJVbml0VGVzdC5qYXZh) | `90% <0%> (+30%)` | `2% <0%> (ø)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5826?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5826?src=pr&el=footer). Last update [fb2b5a2...e5bcca0](https://codecov.io/gh/broadinstitute/gatk/pull/5826?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5826#issuecomment-475632849
https://github.com/broadinstitute/gatk/pull/5827#issuecomment-475644133:4604,Deployability,update,update,4604,"-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9jbHVzdGVyaW5nL1NvbWF0aWNDbHVzdGVyaW5nTW9kZWwuamF2YQ==) | `99.35% <100%> (ø)` | `65 <1> (ø)` | :arrow_down: |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5827/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-30%)` | `1% <0%> (-2%)` | |; | [...e/hellbender/engine/filters/ReadFilterLibrary.java](https://codecov.io/gh/broadinstitute/gatk/pull/5827/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZmlsdGVycy9SZWFkRmlsdGVyTGlicmFyeS5qYXZh) | `94.56% <0%> (-0.95%)` | `1% <0%> (ø)` | |; | [...nder/engine/filters/ReadFilterLibraryUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5827/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZmlsdGVycy9SZWFkRmlsdGVyTGlicmFyeVVuaXRUZXN0LmphdmE=) | `100% <0%> (ø)` | `59% <0%> (+1%)` | :arrow_up: |; | [...ithwaterman/SmithWatermanIntelAlignerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5827/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXJVbml0VGVzdC5qYXZh) | `60% <0%> (ø)` | `2% <0%> (ø)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5827?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5827?src=pr&el=footer). Last update [fb2b5a2...6cc5267](https://codecov.io/gh/broadinstitute/gatk/pull/5827?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5827#issuecomment-475644133
https://github.com/broadinstitute/gatk/pull/5827#issuecomment-475644133:4507,Energy Efficiency,Power,Powered,4507,"-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9jbHVzdGVyaW5nL1NvbWF0aWNDbHVzdGVyaW5nTW9kZWwuamF2YQ==) | `99.35% <100%> (ø)` | `65 <1> (ø)` | :arrow_down: |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5827/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-30%)` | `1% <0%> (-2%)` | |; | [...e/hellbender/engine/filters/ReadFilterLibrary.java](https://codecov.io/gh/broadinstitute/gatk/pull/5827/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZmlsdGVycy9SZWFkRmlsdGVyTGlicmFyeS5qYXZh) | `94.56% <0%> (-0.95%)` | `1% <0%> (ø)` | |; | [...nder/engine/filters/ReadFilterLibraryUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5827/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZmlsdGVycy9SZWFkRmlsdGVyTGlicmFyeVVuaXRUZXN0LmphdmE=) | `100% <0%> (ø)` | `59% <0%> (+1%)` | :arrow_up: |; | [...ithwaterman/SmithWatermanIntelAlignerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5827/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXJVbml0VGVzdC5qYXZh) | `60% <0%> (ø)` | `2% <0%> (ø)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5827?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5827?src=pr&el=footer). Last update [fb2b5a2...6cc5267](https://codecov.io/gh/broadinstitute/gatk/pull/5827?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5827#issuecomment-475644133
https://github.com/broadinstitute/gatk/pull/5827#issuecomment-475644133:4370,Usability,learn,learn,4370,"-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9jbHVzdGVyaW5nL1NvbWF0aWNDbHVzdGVyaW5nTW9kZWwuamF2YQ==) | `99.35% <100%> (ø)` | `65 <1> (ø)` | :arrow_down: |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5827/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-30%)` | `1% <0%> (-2%)` | |; | [...e/hellbender/engine/filters/ReadFilterLibrary.java](https://codecov.io/gh/broadinstitute/gatk/pull/5827/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZmlsdGVycy9SZWFkRmlsdGVyTGlicmFyeS5qYXZh) | `94.56% <0%> (-0.95%)` | `1% <0%> (ø)` | |; | [...nder/engine/filters/ReadFilterLibraryUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5827/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvZmlsdGVycy9SZWFkRmlsdGVyTGlicmFyeVVuaXRUZXN0LmphdmE=) | `100% <0%> (ø)` | `59% <0%> (+1%)` | :arrow_up: |; | [...ithwaterman/SmithWatermanIntelAlignerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5827/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXJVbml0VGVzdC5qYXZh) | `60% <0%> (ø)` | `2% <0%> (ø)` | :arrow_down: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5827?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5827?src=pr&el=footer). Last update [fb2b5a2...6cc5267](https://codecov.io/gh/broadinstitute/gatk/pull/5827?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5827#issuecomment-475644133
https://github.com/broadinstitute/gatk/pull/5827#issuecomment-475728493:212,Performance,optimiz,optimization,212,">In the latest filtering paradigm, how would somebody who only wanted variants with really high quality bases change the default parameters?. You could decrease `f-score-beta` (default 1.0) to bias the threshold optimization in favor of precision versus sensitivity.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5827#issuecomment-475728493
https://github.com/broadinstitute/gatk/pull/5827#issuecomment-475756509:221,Performance,optimiz,optimization,221,"> > In the latest filtering paradigm, how would somebody who only wanted variants with really high quality bases change the default parameters?; > ; > You could decrease `f-score-beta` (default 1.0) to bias the threshold optimization in favor of precision versus sensitivity. Okay. Rip it out.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5827#issuecomment-475756509
https://github.com/broadinstitute/gatk/issues/5828#issuecomment-475750843:1010,Availability,error,errors,1010,"Notes from @kvg :. Manuscript on LdBG details: https://academic.oup.com/bioinformatics/article/34/15/2556/4938484. Reference implementation of the assembler in C: https://github.com/mcveanlab/mccortex; mcveanlab/mccortex. My Java library for accessing and manipulating LdBGs and associated formats: https://github.com/mcveanlab/CortexJDK. A useful starting point is the tests I've written to produce Figure 1 (the one with the pentagram cycle) from the manuscript. Without links: https://github.com/mcveanlab/CortexJDK/blob/4ba64ee268314729c871916dfc9ee7c9c422c5cb/public/java/tests/uk/ac/ox/well/cortexjdk/utils/traversal/TraversalEngineTest.java#L210. With links: https://github.com/mcveanlab/CortexJDK/blob/4ba64ee268314729c871916dfc9ee7c9c422c5cb/public/java/tests/uk/ac/ox/well/cortexjdk/utils/traversal/TraversalEngineTest.java#L229. (Oh and FYI, there's one place where my implementation of the read threading currently doesn't match the McCortex C reference implementation - the handling of sequencing errors and replacing the errorful kmers with kmers from the graph. It's an easy thing to add; I just hadn't gotten around to it because I didn't have the need to do that alignment myself given that all my graphs and links were constructed with McCortex anyway.)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5828#issuecomment-475750843
https://github.com/broadinstitute/gatk/issues/5828#issuecomment-475750843:1035,Availability,error,errorful,1035,"Notes from @kvg :. Manuscript on LdBG details: https://academic.oup.com/bioinformatics/article/34/15/2556/4938484. Reference implementation of the assembler in C: https://github.com/mcveanlab/mccortex; mcveanlab/mccortex. My Java library for accessing and manipulating LdBGs and associated formats: https://github.com/mcveanlab/CortexJDK. A useful starting point is the tests I've written to produce Figure 1 (the one with the pentagram cycle) from the manuscript. Without links: https://github.com/mcveanlab/CortexJDK/blob/4ba64ee268314729c871916dfc9ee7c9c422c5cb/public/java/tests/uk/ac/ox/well/cortexjdk/utils/traversal/TraversalEngineTest.java#L210. With links: https://github.com/mcveanlab/CortexJDK/blob/4ba64ee268314729c871916dfc9ee7c9c422c5cb/public/java/tests/uk/ac/ox/well/cortexjdk/utils/traversal/TraversalEngineTest.java#L229. (Oh and FYI, there's one place where my implementation of the read threading currently doesn't match the McCortex C reference implementation - the handling of sequencing errors and replacing the errorful kmers with kmers from the graph. It's an easy thing to add; I just hadn't gotten around to it because I didn't have the need to do that alignment myself given that all my graphs and links were constructed with McCortex anyway.)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5828#issuecomment-475750843
https://github.com/broadinstitute/gatk/issues/5828#issuecomment-475750843:242,Security,access,accessing,242,"Notes from @kvg :. Manuscript on LdBG details: https://academic.oup.com/bioinformatics/article/34/15/2556/4938484. Reference implementation of the assembler in C: https://github.com/mcveanlab/mccortex; mcveanlab/mccortex. My Java library for accessing and manipulating LdBGs and associated formats: https://github.com/mcveanlab/CortexJDK. A useful starting point is the tests I've written to produce Figure 1 (the one with the pentagram cycle) from the manuscript. Without links: https://github.com/mcveanlab/CortexJDK/blob/4ba64ee268314729c871916dfc9ee7c9c422c5cb/public/java/tests/uk/ac/ox/well/cortexjdk/utils/traversal/TraversalEngineTest.java#L210. With links: https://github.com/mcveanlab/CortexJDK/blob/4ba64ee268314729c871916dfc9ee7c9c422c5cb/public/java/tests/uk/ac/ox/well/cortexjdk/utils/traversal/TraversalEngineTest.java#L229. (Oh and FYI, there's one place where my implementation of the read threading currently doesn't match the McCortex C reference implementation - the handling of sequencing errors and replacing the errorful kmers with kmers from the graph. It's an easy thing to add; I just hadn't gotten around to it because I didn't have the need to do that alignment myself given that all my graphs and links were constructed with McCortex anyway.)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5828#issuecomment-475750843
https://github.com/broadinstitute/gatk/issues/5828#issuecomment-475750843:370,Testability,test,tests,370,"Notes from @kvg :. Manuscript on LdBG details: https://academic.oup.com/bioinformatics/article/34/15/2556/4938484. Reference implementation of the assembler in C: https://github.com/mcveanlab/mccortex; mcveanlab/mccortex. My Java library for accessing and manipulating LdBGs and associated formats: https://github.com/mcveanlab/CortexJDK. A useful starting point is the tests I've written to produce Figure 1 (the one with the pentagram cycle) from the manuscript. Without links: https://github.com/mcveanlab/CortexJDK/blob/4ba64ee268314729c871916dfc9ee7c9c422c5cb/public/java/tests/uk/ac/ox/well/cortexjdk/utils/traversal/TraversalEngineTest.java#L210. With links: https://github.com/mcveanlab/CortexJDK/blob/4ba64ee268314729c871916dfc9ee7c9c422c5cb/public/java/tests/uk/ac/ox/well/cortexjdk/utils/traversal/TraversalEngineTest.java#L229. (Oh and FYI, there's one place where my implementation of the read threading currently doesn't match the McCortex C reference implementation - the handling of sequencing errors and replacing the errorful kmers with kmers from the graph. It's an easy thing to add; I just hadn't gotten around to it because I didn't have the need to do that alignment myself given that all my graphs and links were constructed with McCortex anyway.)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5828#issuecomment-475750843
https://github.com/broadinstitute/gatk/issues/5828#issuecomment-475750843:577,Testability,test,tests,577,"Notes from @kvg :. Manuscript on LdBG details: https://academic.oup.com/bioinformatics/article/34/15/2556/4938484. Reference implementation of the assembler in C: https://github.com/mcveanlab/mccortex; mcveanlab/mccortex. My Java library for accessing and manipulating LdBGs and associated formats: https://github.com/mcveanlab/CortexJDK. A useful starting point is the tests I've written to produce Figure 1 (the one with the pentagram cycle) from the manuscript. Without links: https://github.com/mcveanlab/CortexJDK/blob/4ba64ee268314729c871916dfc9ee7c9c422c5cb/public/java/tests/uk/ac/ox/well/cortexjdk/utils/traversal/TraversalEngineTest.java#L210. With links: https://github.com/mcveanlab/CortexJDK/blob/4ba64ee268314729c871916dfc9ee7c9c422c5cb/public/java/tests/uk/ac/ox/well/cortexjdk/utils/traversal/TraversalEngineTest.java#L229. (Oh and FYI, there's one place where my implementation of the read threading currently doesn't match the McCortex C reference implementation - the handling of sequencing errors and replacing the errorful kmers with kmers from the graph. It's an easy thing to add; I just hadn't gotten around to it because I didn't have the need to do that alignment myself given that all my graphs and links were constructed with McCortex anyway.)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5828#issuecomment-475750843
https://github.com/broadinstitute/gatk/issues/5828#issuecomment-475750843:763,Testability,test,tests,763,"Notes from @kvg :. Manuscript on LdBG details: https://academic.oup.com/bioinformatics/article/34/15/2556/4938484. Reference implementation of the assembler in C: https://github.com/mcveanlab/mccortex; mcveanlab/mccortex. My Java library for accessing and manipulating LdBGs and associated formats: https://github.com/mcveanlab/CortexJDK. A useful starting point is the tests I've written to produce Figure 1 (the one with the pentagram cycle) from the manuscript. Without links: https://github.com/mcveanlab/CortexJDK/blob/4ba64ee268314729c871916dfc9ee7c9c422c5cb/public/java/tests/uk/ac/ox/well/cortexjdk/utils/traversal/TraversalEngineTest.java#L210. With links: https://github.com/mcveanlab/CortexJDK/blob/4ba64ee268314729c871916dfc9ee7c9c422c5cb/public/java/tests/uk/ac/ox/well/cortexjdk/utils/traversal/TraversalEngineTest.java#L229. (Oh and FYI, there's one place where my implementation of the read threading currently doesn't match the McCortex C reference implementation - the handling of sequencing errors and replacing the errorful kmers with kmers from the graph. It's an easy thing to add; I just hadn't gotten around to it because I didn't have the need to do that alignment myself given that all my graphs and links were constructed with McCortex anyway.)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5828#issuecomment-475750843
https://github.com/broadinstitute/gatk/pull/5829#issuecomment-478308547:27,Usability,feedback,feedback,27,Thanks @samuelklee for the feedback! I will go over these and incorporate as much as I can before Monday.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5829#issuecomment-478308547
https://github.com/broadinstitute/gatk/pull/5829#issuecomment-478403475:35,Usability,feedback,feedback,35,"@samuelklee I've incorporated your feedback and will make a new commit that reflects these shortly. Also, as mentioned in one of the comments above, the two notebooks are on the forum now at:; - [Notebook#11685](https://gatkforums.broadinstitute.org/gatk/discussion/11685/) ; - [Notebook#11686](https://gatkforums.broadinstitute.org/gatk/discussion/11686/) . Please let me know if these are okay with you. Again, most of the content should be familiar to you as I've just condensed and reorganized the explorations I had previously shared with you.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5829#issuecomment-478403475
https://github.com/broadinstitute/gatk/pull/5829#issuecomment-478406380:102,Deployability,update,update,102,"@samuelklee, please note we will have to trim back on the current version's content. In an attempt to update the Vanilla forum version, I again hit the limit. ![Screenshot 2019-03-31 21 27 04](https://user-images.githubusercontent.com/11543866/55298441-bfb94e80-53fb-11e9-960c-ce7eaeec2ff0.png)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5829#issuecomment-478406380
https://github.com/broadinstitute/gatk/pull/5829#issuecomment-478625060:92,Availability,error,error,92,"Actually @samuelklee, it turns out FilterIntervals cannot just take `-XL`. It will give the error:; ```; ***********************************************************************. A USER ERROR has occurred: Must provide annotated intervals or counts. ***********************************************************************; ```; So I will change the relevant passage back to what I had.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5829#issuecomment-478625060
https://github.com/broadinstitute/gatk/pull/5829#issuecomment-478625060:185,Availability,ERROR,ERROR,185,"Actually @samuelklee, it turns out FilterIntervals cannot just take `-XL`. It will give the error:; ```; ***********************************************************************. A USER ERROR has occurred: Must provide annotated intervals or counts. ***********************************************************************; ```; So I will change the relevant passage back to what I had.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5829#issuecomment-478625060
https://github.com/broadinstitute/gatk/pull/5829#issuecomment-478774288:28,Usability,feedback,feedback,28,Thanks @asmirnov239 for the feedback! I will incorporate these changes shortly to the forum version and here for posterity.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5829#issuecomment-478774288
https://github.com/broadinstitute/gatk/pull/5831#issuecomment-475962016:232,Availability,error,error-reference,232,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5831?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@d27692d`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `91.207%`. ```diff; @@ Coverage Diff @@; ## master #5831 +/- ##; ==========================================; Coverage ? 80.122% ; Complexity ? 30691 ; ==========================================; Files ? 1993 ; Lines ? 149366 ; Branches ? 16486 ; ==========================================; Hits ? 119675 ; Misses ? 23893 ; Partials ? 5798; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5831?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...typecaller/PairHMMLikelihoodCalculationEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/5831/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9QYWlySE1NTGlrZWxpaG9vZENhbGN1bGF0aW9uRW5naW5lLmphdmE=) | `87.662% <ø> (ø)` | `38 <0> (?)` | |; | [...alkers/genotyper/GenotypeLikelihoodCalculator.java](https://codecov.io/gh/broadinstitute/gatk/pull/5831/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9HZW5vdHlwZUxpa2VsaWhvb2RDYWxjdWxhdG9yLmphdmE=) | `91.667% <ø> (ø)` | `46 <0> (?)` | |; | [...oadinstitute/hellbender/utils/pairhmm/PairHMM.java](https://codecov.io/gh/broadinstitute/gatk/pull/5831/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9wYWlyaG1tL1BhaXJITU0uamF2YQ==) | `78.417% <ø> (ø)` | `24 <0> (?)` | |; | [...hellbender/utils/pairhmm/VectorLoglessPairHMM.java](https://codecov.io/gh/broadinstitute/gatk/pull/5831/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9wYWlyaG1tL1ZlY3RvckxvZ2xlc3NQYWlySE1NLmphdmE=) | `86.842% <ø> (ø)` | `12 <0> (?)` | |; | [...nder/,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5831#issuecomment-475962016
https://github.com/broadinstitute/gatk/pull/5831#issuecomment-475962016:180,Usability,learn,learn,180,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5831?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@d27692d`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `91.207%`. ```diff; @@ Coverage Diff @@; ## master #5831 +/- ##; ==========================================; Coverage ? 80.122% ; Complexity ? 30691 ; ==========================================; Files ? 1993 ; Lines ? 149366 ; Branches ? 16486 ; ==========================================; Hits ? 119675 ; Misses ? 23893 ; Partials ? 5798; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5831?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...typecaller/PairHMMLikelihoodCalculationEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/5831/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9QYWlySE1NTGlrZWxpaG9vZENhbGN1bGF0aW9uRW5naW5lLmphdmE=) | `87.662% <ø> (ø)` | `38 <0> (?)` | |; | [...alkers/genotyper/GenotypeLikelihoodCalculator.java](https://codecov.io/gh/broadinstitute/gatk/pull/5831/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9HZW5vdHlwZUxpa2VsaWhvb2RDYWxjdWxhdG9yLmphdmE=) | `91.667% <ø> (ø)` | `46 <0> (?)` | |; | [...oadinstitute/hellbender/utils/pairhmm/PairHMM.java](https://codecov.io/gh/broadinstitute/gatk/pull/5831/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9wYWlyaG1tL1BhaXJITU0uamF2YQ==) | `78.417% <ø> (ø)` | `24 <0> (?)` | |; | [...hellbender/utils/pairhmm/VectorLoglessPairHMM.java](https://codecov.io/gh/broadinstitute/gatk/pull/5831/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9wYWlyaG1tL1ZlY3RvckxvZ2xlc3NQYWlySE1NLmphdmE=) | `86.842% <ø> (ø)` | `12 <0> (?)` | |; | [...nder/,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5831#issuecomment-475962016
https://github.com/broadinstitute/gatk/pull/5831#issuecomment-490599827:301,Availability,error,error,301,"@LeeTL1220 @droazen This is ready for review. It modestly improves all of our validations except Dream challenge 4, which I suspect is because the synthetic data doesn't respect mate pairing. To account for that I added an advanced option to turn off mate-awareness. @kachulis Thanks for catching the error in finding fragments.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5831#issuecomment-490599827
https://github.com/broadinstitute/gatk/pull/5831#issuecomment-490599827:78,Security,validat,validations,78,"@LeeTL1220 @droazen This is ready for review. It modestly improves all of our validations except Dream challenge 4, which I suspect is because the synthetic data doesn't respect mate pairing. To account for that I added an advanced option to turn off mate-awareness. @kachulis Thanks for catching the error in finding fragments.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5831#issuecomment-490599827
https://github.com/broadinstitute/gatk/pull/5831#issuecomment-519630216:17,Availability,failure,failure,17,I think the only failure left is a Travis thing. Back to @vruano after heavy refactoring.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5831#issuecomment-519630216
https://github.com/broadinstitute/gatk/pull/5831#issuecomment-519630216:77,Modifiability,refactor,refactoring,77,I think the only failure left is a Travis thing. Back to @vruano after heavy refactoring.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5831#issuecomment-519630216
https://github.com/broadinstitute/gatk/pull/5832#issuecomment-476229094:2975,Deployability,update,update,2975,"broadinstitute/gatk/pull/5832/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0NvbW1hbmRMaW5lUHJvZ3JhbS5qYXZh) | `84% <100%> (+0.66%)` | `43 <4> (ø)` | :arrow_down: |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5832/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-30%)` | `1% <0%> (-2%)` | |; | [...ithwaterman/SmithWatermanIntelAlignerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5832/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXJVbml0VGVzdC5qYXZh) | `60% <0%> (ø)` | `2% <0%> (ø)` | :arrow_down: |; | [...roadinstitute/hellbender/engine/PathSpecifier.java](https://codecov.io/gh/broadinstitute/gatk/pull/5832/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUGF0aFNwZWNpZmllci5qYXZh) | `67.1% <0%> (+1.31%)` | `21% <0%> (+1%)` | :arrow_up: |; | [...institute/hellbender/engine/GATKPathSpecifier.java](https://codecov.io/gh/broadinstitute/gatk/pull/5832/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvR0FUS1BhdGhTcGVjaWZpZXIuamF2YQ==) | `48.21% <0%> (+1.78%)` | `16% <0%> (+1%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5832?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5832?src=pr&el=footer). Last update [aa8e807...d462900](https://codecov.io/gh/broadinstitute/gatk/pull/5832?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5832#issuecomment-476229094
https://github.com/broadinstitute/gatk/pull/5832#issuecomment-476229094:2878,Energy Efficiency,Power,Powered,2878,"broadinstitute/gatk/pull/5832/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0NvbW1hbmRMaW5lUHJvZ3JhbS5qYXZh) | `84% <100%> (+0.66%)` | `43 <4> (ø)` | :arrow_down: |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5832/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-30%)` | `1% <0%> (-2%)` | |; | [...ithwaterman/SmithWatermanIntelAlignerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5832/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXJVbml0VGVzdC5qYXZh) | `60% <0%> (ø)` | `2% <0%> (ø)` | :arrow_down: |; | [...roadinstitute/hellbender/engine/PathSpecifier.java](https://codecov.io/gh/broadinstitute/gatk/pull/5832/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUGF0aFNwZWNpZmllci5qYXZh) | `67.1% <0%> (+1.31%)` | `21% <0%> (+1%)` | :arrow_up: |; | [...institute/hellbender/engine/GATKPathSpecifier.java](https://codecov.io/gh/broadinstitute/gatk/pull/5832/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvR0FUS1BhdGhTcGVjaWZpZXIuamF2YQ==) | `48.21% <0%> (+1.78%)` | `16% <0%> (+1%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5832?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5832?src=pr&el=footer). Last update [aa8e807...d462900](https://codecov.io/gh/broadinstitute/gatk/pull/5832?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5832#issuecomment-476229094
https://github.com/broadinstitute/gatk/pull/5832#issuecomment-476229094:2741,Usability,learn,learn,2741,"broadinstitute/gatk/pull/5832/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0NvbW1hbmRMaW5lUHJvZ3JhbS5qYXZh) | `84% <100%> (+0.66%)` | `43 <4> (ø)` | :arrow_down: |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5832/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `50% <0%> (-30%)` | `1% <0%> (-2%)` | |; | [...ithwaterman/SmithWatermanIntelAlignerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5832/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXJVbml0VGVzdC5qYXZh) | `60% <0%> (ø)` | `2% <0%> (ø)` | :arrow_down: |; | [...roadinstitute/hellbender/engine/PathSpecifier.java](https://codecov.io/gh/broadinstitute/gatk/pull/5832/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvUGF0aFNwZWNpZmllci5qYXZh) | `67.1% <0%> (+1.31%)` | `21% <0%> (+1%)` | :arrow_up: |; | [...institute/hellbender/engine/GATKPathSpecifier.java](https://codecov.io/gh/broadinstitute/gatk/pull/5832/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvR0FUS1BhdGhTcGVjaWZpZXIuamF2YQ==) | `48.21% <0%> (+1.78%)` | `16% <0%> (+1%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5832?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5832?src=pr&el=footer). Last update [aa8e807...d462900](https://codecov.io/gh/broadinstitute/gatk/pull/5832?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5832#issuecomment-476229094
https://github.com/broadinstitute/gatk/pull/5833#issuecomment-476221850:40,Deployability,integrat,integration,40,"@nh3 care to take a look? In the GGVCFs integration test, the with OxoGReadCounts.g.vcf file has ; ```; 20 10101674 . TTGTGTG T,TTG,TTGTGTGTGTGTG,TTGTGTGTGTGTGTG,<NON_REF> 1464.10 . DP=64;ExcessHet=3.0103;MLEAC=0,1,1,0,0;MLEAF=0.00,0.500,0.500,0.00,0.00;RAW_MQandDP=196622,64 GT:AD:DP:F1R2:F2R1:GQ:PL:SB 2/3:0,3,22,6,4,0:35:0,1,13,3,3,0:0,2,9,3,1,0:47:1481,1115,1205,557,577,581,932,574,0,925,973,621,47,860,972,1495,1189,615,968,1015,1570:0,0,20,15; ```; with read counts. | TTGTGTG* | T | TTG | TTGTGTGTGTGTG | TTGTGTGTGTGTGTG | <NON_REF> |; | --- | -- | -- | -- | -- | -- |; | 0 | 1 | 13 | 3 | 3 | 0 |; | 0 | 2 | 9 | 3 | 1 | 0 |. after genotyping alleles get dropped and trimmed and we have. | TTGTG* | T | TTGTGTGTGTG |; | -- | -- | -- |; | 0 | 13 | 3 |; | 0 | 9 | 3 |. Do you agree that's as expected? (I couldn't reproduce your exact example without the exact bam.)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5833#issuecomment-476221850
https://github.com/broadinstitute/gatk/pull/5833#issuecomment-476221850:40,Integrability,integrat,integration,40,"@nh3 care to take a look? In the GGVCFs integration test, the with OxoGReadCounts.g.vcf file has ; ```; 20 10101674 . TTGTGTG T,TTG,TTGTGTGTGTGTG,TTGTGTGTGTGTGTG,<NON_REF> 1464.10 . DP=64;ExcessHet=3.0103;MLEAC=0,1,1,0,0;MLEAF=0.00,0.500,0.500,0.00,0.00;RAW_MQandDP=196622,64 GT:AD:DP:F1R2:F2R1:GQ:PL:SB 2/3:0,3,22,6,4,0:35:0,1,13,3,3,0:0,2,9,3,1,0:47:1481,1115,1205,557,577,581,932,574,0,925,973,621,47,860,972,1495,1189,615,968,1015,1570:0,0,20,15; ```; with read counts. | TTGTGTG* | T | TTG | TTGTGTGTGTGTG | TTGTGTGTGTGTGTG | <NON_REF> |; | --- | -- | -- | -- | -- | -- |; | 0 | 1 | 13 | 3 | 3 | 0 |; | 0 | 2 | 9 | 3 | 1 | 0 |. after genotyping alleles get dropped and trimmed and we have. | TTGTG* | T | TTGTGTGTGTG |; | -- | -- | -- |; | 0 | 13 | 3 |; | 0 | 9 | 3 |. Do you agree that's as expected? (I couldn't reproduce your exact example without the exact bam.)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5833#issuecomment-476221850
https://github.com/broadinstitute/gatk/pull/5833#issuecomment-476221850:52,Testability,test,test,52,"@nh3 care to take a look? In the GGVCFs integration test, the with OxoGReadCounts.g.vcf file has ; ```; 20 10101674 . TTGTGTG T,TTG,TTGTGTGTGTGTG,TTGTGTGTGTGTGTG,<NON_REF> 1464.10 . DP=64;ExcessHet=3.0103;MLEAC=0,1,1,0,0;MLEAF=0.00,0.500,0.500,0.00,0.00;RAW_MQandDP=196622,64 GT:AD:DP:F1R2:F2R1:GQ:PL:SB 2/3:0,3,22,6,4,0:35:0,1,13,3,3,0:0,2,9,3,1,0:47:1481,1115,1205,557,577,581,932,574,0,925,973,621,47,860,972,1495,1189,615,968,1015,1570:0,0,20,15; ```; with read counts. | TTGTGTG* | T | TTG | TTGTGTGTGTGTG | TTGTGTGTGTGTGTG | <NON_REF> |; | --- | -- | -- | -- | -- | -- |; | 0 | 1 | 13 | 3 | 3 | 0 |; | 0 | 2 | 9 | 3 | 1 | 0 |. after genotyping alleles get dropped and trimmed and we have. | TTGTG* | T | TTGTGTGTGTG |; | -- | -- | -- |; | 0 | 13 | 3 |; | 0 | 9 | 3 |. Do you agree that's as expected? (I couldn't reproduce your exact example without the exact bam.)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5833#issuecomment-476221850
https://github.com/broadinstitute/gatk/pull/5833#issuecomment-476235495:3841,Modifiability,Plugin,Plugin,3841,AnnotationBaseTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5833/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2Fubm90YXRvci9hbGxlbGVzcGVjaWZpYy9SZWR1Y2libGVBbm5vdGF0aW9uQmFzZVRlc3QuamF2YQ==) | `2.439% <0%> (-90.244%)` | `1 <0> (-8)` | |; | [...ferenceConfidenceVariantContextMergerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5833/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL1JlZmVyZW5jZUNvbmZpZGVuY2VWYXJpYW50Q29udGV4dE1lcmdlclVuaXRUZXN0LmphdmE=) | `2.881% <0%> (-94.239%)` | `1 <0> (-25)` | |; | [...stitute/hellbender/tools/HaplotypeCallerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5833/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9IYXBsb3R5cGVDYWxsZXJTcGFyay5qYXZh) | `70.115% <0%> (ø)` | `18 <1> (ø)` | :arrow_down: |; | [...er/tools/walkers/GenotypeGVCFsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5833/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL0dlbm90eXBlR1ZDRnNJbnRlZ3JhdGlvblRlc3QuamF2YQ==) | `3.704% <0%> (-80.408%)` | `2 <0> (-37)` | |; | [...haplotypecaller/HaplotypeCallerEngineUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5833/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9IYXBsb3R5cGVDYWxsZXJFbmdpbmVVbml0VGVzdC5qYXZh) | `3.704% <0%> (-92.593%)` | `1 <0> (-5)` | |; | [...Plugin/GATKAnnotationPluginDescriptorUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5833/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL0dBVEtQbHVnaW4vR0FUS0Fubm90YXRpb25QbHVnaW5EZXNjcmlwdG9yVW5pdFRlc3QuamF2YQ==) | `7.219% <0%> (-81.016%)` | `4 <0> (-54)` | |; | ... and [1286 more](https://codecov.io/gh/broadinstitute/gatk/pull/5833/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5833#issuecomment-476235495
https://github.com/broadinstitute/gatk/pull/5834#issuecomment-476358270:42,Performance,perform,performance,42,"Sounds good. I have not characterized the performance changes (if any). There are some minor differences in output, but the output is now more correct for symbolic alleles.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5834#issuecomment-476358270
https://github.com/broadinstitute/gatk/pull/5835#issuecomment-476327874:29,Deployability,release,release,29,Not critical for this week's release.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5835#issuecomment-476327874
https://github.com/broadinstitute/gatk/pull/5837#issuecomment-476864170:2529,Availability,down,downsampling,2529,0%> (+0.131%)` | `44 <0> (+2)` | :arrow_up: |; | [...ellbender/tools/walkers/vqsr/CNNScoreVariants.java](https://codecov.io/gh/broadinstitute/gatk/pull/5837/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3Zxc3IvQ05OU2NvcmVWYXJpYW50cy5qYXZh) | `17.621% <25%> (-62.823%)` | `7 <0> (-38)` | |; | [...ls/variant/writers/GVCFBlockCombiningIterator.java](https://codecov.io/gh/broadinstitute/gatk/pull/5837/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L3dyaXRlcnMvR1ZDRkJsb2NrQ29tYmluaW5nSXRlcmF0b3IuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-1%)` | |; | [...ls/walkers/genotyper/HeterogeneousPloidyModel.java](https://codecov.io/gh/broadinstitute/gatk/pull/5837/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9IZXRlcm9nZW5lb3VzUGxvaWR5TW9kZWwuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-14%)` | |; | [...nder/utils/downsampling/FractionalDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/5837/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvRnJhY3Rpb25hbERvd25zYW1wbGVyLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-17%)` | |; | [...park/pathseq/MarkedOpticalDuplicateReadFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5837/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL01hcmtlZE9wdGljYWxEdXBsaWNhdGVSZWFkRmlsdGVyLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-4%)` | |; | [...otypecaller/RandomLikelihoodCalculationEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/5837/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9SYW5kb21MaWtlbGlob29kQ2FsY3VsYXRpb25FbmdpbmUuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-6%)` | |; | [...r/utils/solver/UnivariateSolverSpecifications.java](https://codecov.io/gh/,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5837#issuecomment-476864170
https://github.com/broadinstitute/gatk/pull/5837#issuecomment-477258880:90,Deployability,release,release,90,@lucidtronix Could you nominate a reviewer? Is this something you want in for this week's release?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5837#issuecomment-477258880
https://github.com/broadinstitute/gatk/pull/5837#issuecomment-498648895:290,Deployability,pipeline,pipeline,290,"@ldgauthier @cmnbroad @bhanugandham Sorry for the delay & mission creep in this PR. It now addresses #5964 #5939 and annotates with `PASS` thater than `.`. I also now set the default tranches `99.95` for SNPs and `99.4` for INDELs based on F1 score maximizing experiments from the clinical pipeline, for example:; <img width=""1893"" alt=""Screenshot 2019-06-04 08 09 41"" src=""https://user-images.githubusercontent.com/2604962/58878519-760e0e00-86a1-11e9-910f-cfd3657aa8f8.png"">; ; Rebased and ready for review.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5837#issuecomment-498648895
https://github.com/broadinstitute/gatk/issues/5839#issuecomment-477376375:247,Deployability,update,update,247,The htsjdk branch for this is [here](https://github.com/cmnbroad/htsjdk/tree/cn_bcf_codec_version) and the GATK branch is [here](https://github.com/broadinstitute/gatk/tree/cn_bcf_version_override). We'll need this for the next (post 2.19) htsjdk update. Will require the htsjdk branch to be merged and released before we can use the GATK branch.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5839#issuecomment-477376375
https://github.com/broadinstitute/gatk/issues/5839#issuecomment-477376375:303,Deployability,release,released,303,The htsjdk branch for this is [here](https://github.com/cmnbroad/htsjdk/tree/cn_bcf_codec_version) and the GATK branch is [here](https://github.com/broadinstitute/gatk/tree/cn_bcf_version_override). We'll need this for the next (post 2.19) htsjdk update. Will require the htsjdk branch to be merged and released before we can use the GATK branch.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5839#issuecomment-477376375
https://github.com/broadinstitute/gatk/pull/5840#issuecomment-477185044:63,Modifiability,refactor,refactoring,63,@davidbenjamin I will review this today. Thanks for doing this refactoring.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5840#issuecomment-477185044
https://github.com/broadinstitute/gatk/issues/5841#issuecomment-481372847:121,Testability,test,testing,121,"The format is the same (1 transcript per line, version numbers ignored). . I'll add this in now, but I'll need some help testing it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5841#issuecomment-481372847
https://github.com/broadinstitute/gatk/issues/5841#issuecomment-481373763:76,Testability,test,testing,76,@jonn-smith If you make the changes in a branch I can run it through the M2 testing Terra workspace.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5841#issuecomment-481373763
https://github.com/broadinstitute/gatk/issues/5841#issuecomment-481384109:143,Deployability,update,update,143,"@davidbenjamin sounds good. I already created the PR, so you can grab the WDL from there. Once it looks good, we can merge and ask @bshifaw to update the featured workspace.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5841#issuecomment-481384109
https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477635851:3450,Modifiability,Polymorphi,PolymorphicNuMTFilter,3450,ering/Mutect2FilteringEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/5842/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9maWx0ZXJpbmcvTXV0ZWN0MkZpbHRlcmluZ0VuZ2luZS5qYXZh) | `97.115% <100%> (+0.057%)` | `43 <0> (ø)` | :arrow_down: |; | [.../mutect/filtering/M2FiltersArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/5842/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9maWx0ZXJpbmcvTTJGaWx0ZXJzQXJndW1lbnRDb2xsZWN0aW9uLmphdmE=) | `93.75% <100%> (+0.417%)` | `6 <0> (ø)` | :arrow_down: |; | [...kers/mutect/filtering/MinAlleleFractionFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5842/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9maWx0ZXJpbmcvTWluQWxsZWxlRnJhY3Rpb25GaWx0ZXIuamF2YQ==) | `100% <100%> (ø)` | `7 <7> (?)` | |; | [...e/hellbender/utils/variant/GATKVCFHeaderLines.java](https://codecov.io/gh/broadinstitute/gatk/pull/5842/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L0dBVEtWQ0ZIZWFkZXJMaW5lcy5qYXZh) | `94.886% <100%> (+0.029%)` | `11 <0> (ø)` | :arrow_down: |; | [...alkers/mutect/filtering/PolymorphicNuMTFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5842/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL211dGVjdC9maWx0ZXJpbmcvUG9seW1vcnBoaWNOdU1URmlsdGVyLmphdmE=) | `88.235% <88.235%> (ø)` | `9 <9> (?)` | |; | [...lbender/utils/variant/GATKVariantContextUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5842/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L0dBVEtWYXJpYW50Q29udGV4dFV0aWxzLmphdmE=) | `87.309% <0%> (-0.306%)` | `244% <0%> (-2%)` | |; | ... and [10 more](https://codecov.io/gh/broadinstitute/gatk/pull/5842/diff?src=pr&el=tree-more) | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477635851
https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477646749:64,Deployability,release,release,64,@meganshand Is this something you are targeting for the current release? Our current plan is to release towards the end of the day today.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477646749
https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477646749:96,Deployability,release,release,96,@meganshand Is this something you are targeting for the current release? Our current plan is to release towards the end of the day today.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477646749
https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477648678:203,Deployability,release,release,203,"@droazen while that would be amazing, I don't expect @ldgauthier or @davidbenjamin to drop everything to review this (unless one of you happens to have some free time today?). Don't let this hold back a release.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477648678
https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477741728:112,Deployability,release,release,112,"Thanks @davidbenjamin! This looks much cleaner now. Still holding out a tiny bit of hope for merging before the release, if you have a chance to look at the new changes.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477741728
https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477769414:3126,Availability,FAILURE,FAILURE,3126,"tionTest.java:66); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.runVariantAnnotatorAndAssertSomething(VariantAnnotatorIntegrationTest.java:92); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertVariantContextsMatch(VariantAnnotatorIntegrationTest.java:55); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertVariantContextsMatch(VariantAnnotatorIntegrationTest.java:49); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.testWithAllAnnotations(VariantAnnotatorIntegrationTest.java:224); Exception in thread ""Thread-5"" java.nio.file.ClosedFileSystemException; 	at com.google.common.jimfs.FileSystemState.checkOpen(FileSystemState.java:64); 	at com.google.common.jimfs.JimfsFileStore.lookUp(JimfsFileStore.java:141); 	at com.google.common.jimfs.FileSystemView.lookUp(FileSystemView.java:123); 	at com.google.common.jimfs.FileSystemView.lookUpWithLock(FileSystemView.java:112); 	at com.google.common.jimfs.FileSystemView.readAttributes(FileSystemView.java:771); 	at com.google.common.jimfs.JimfsFileSystemProvider.readAttributes(JimfsFileSystemProvider.java:346); 	at java.nio.file.Files.readAttributes(Files.java:1737); 	at java.nio.file.FileTreeWalker.getAttributes(FileTreeWalker.java:219); 	at java.nio.file.FileTreeWalker.visit(FileTreeWalker.java:276); 	at java.nio.file.FileTreeWalker.walk(FileTreeWalker.java:322); 	at java.nio.file.Files.walkFileTree(Files.java:2662); 	at java.nio.file.Files.walkFileTree(Files.java:2742); 	at htsjdk.samtools.util.IOUtil.recursiveDelete(IOUtil.java:1344); 	at org.broadinstitute.hellbender.utils.io.IOUtils.deleteRecursively(IOUtils.java:1061); 	at org.broadinstitute.hellbender.utils.io.DeleteRecursivelyOnExitPathHook.runHooks(DeleteRecursivelyOnExitPathHook.java:56); 	at java.lang.Thread.run(Thread.java:748); Results: FAILURE (1604 tests, 1603 successes, 1 failures, 0 skipped); ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477769414
https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477769414:3165,Availability,failure,failures,3165,"tionTest.java:66); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.runVariantAnnotatorAndAssertSomething(VariantAnnotatorIntegrationTest.java:92); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertVariantContextsMatch(VariantAnnotatorIntegrationTest.java:55); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertVariantContextsMatch(VariantAnnotatorIntegrationTest.java:49); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.testWithAllAnnotations(VariantAnnotatorIntegrationTest.java:224); Exception in thread ""Thread-5"" java.nio.file.ClosedFileSystemException; 	at com.google.common.jimfs.FileSystemState.checkOpen(FileSystemState.java:64); 	at com.google.common.jimfs.JimfsFileStore.lookUp(JimfsFileStore.java:141); 	at com.google.common.jimfs.FileSystemView.lookUp(FileSystemView.java:123); 	at com.google.common.jimfs.FileSystemView.lookUpWithLock(FileSystemView.java:112); 	at com.google.common.jimfs.FileSystemView.readAttributes(FileSystemView.java:771); 	at com.google.common.jimfs.JimfsFileSystemProvider.readAttributes(JimfsFileSystemProvider.java:346); 	at java.nio.file.Files.readAttributes(Files.java:1737); 	at java.nio.file.FileTreeWalker.getAttributes(FileTreeWalker.java:219); 	at java.nio.file.FileTreeWalker.visit(FileTreeWalker.java:276); 	at java.nio.file.FileTreeWalker.walk(FileTreeWalker.java:322); 	at java.nio.file.Files.walkFileTree(Files.java:2662); 	at java.nio.file.Files.walkFileTree(Files.java:2742); 	at htsjdk.samtools.util.IOUtil.recursiveDelete(IOUtil.java:1344); 	at org.broadinstitute.hellbender.utils.io.IOUtils.deleteRecursively(IOUtils.java:1061); 	at org.broadinstitute.hellbender.utils.io.DeleteRecursivelyOnExitPathHook.runHooks(DeleteRecursivelyOnExitPathHook.java:56); 	at java.lang.Thread.run(Thread.java:748); Results: FAILURE (1604 tests, 1603 successes, 1 failures, 0 skipped); ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477769414
https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477769414:425,Modifiability,polymorphi,polymorphic,425,"@meganshand Latest build failed with:. ```; org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.testWithAllAnnotations FAILED; java.lang.AssertionError: Iterators differ at element [9]: FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification""> != FORMAT=<ID=NUMT,Number=1,Type=String,Description=""Potentially a polymorphic NuMT false positive rather than a real mitochondrial variant.""> expected [FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification"">] but found [FORMAT=<ID=NUMT,Number=1,Type=String,Description=""Potentially a polymorphic NuMT false positive rather than a real mitochondrial variant."">]; at org.testng.Assert.fail(Assert.java:93); at org.testng.Assert.failNotEquals(Assert.java:512); at org.testng.Assert.assertEqualsImpl(Assert.java:134); at org.testng.Assert.assertEquals(Assert.java:610); at org.testng.Assert.assertEquals(Assert.java:578); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertHeadersMatch(VariantAnnotatorIntegrationTest.java:66); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.runVariantAnnotatorAndAssertSomething(VariantAnnotatorIntegrationTest.java:92); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertVariantContextsMatch(VariantAnnotatorIntegrationTest.java:55); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertVariantContextsMatch(VariantAnnotatorIntegrationTest.java:49); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.testWithAllAnnotations(VariantAnnotatorIntegrationTest.java:224); Exception in thread ""Thread-5"" java.nio.file.ClosedFileSystemException; 	at com.google.common.jimfs.FileSystemState.checkOpen(FileSystemState.java:64); ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477769414
https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477769414:725,Modifiability,polymorphi,polymorphic,725,"@meganshand Latest build failed with:. ```; org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.testWithAllAnnotations FAILED; java.lang.AssertionError: Iterators differ at element [9]: FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification""> != FORMAT=<ID=NUMT,Number=1,Type=String,Description=""Potentially a polymorphic NuMT false positive rather than a real mitochondrial variant.""> expected [FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification"">] but found [FORMAT=<ID=NUMT,Number=1,Type=String,Description=""Potentially a polymorphic NuMT false positive rather than a real mitochondrial variant."">]; at org.testng.Assert.fail(Assert.java:93); at org.testng.Assert.failNotEquals(Assert.java:512); at org.testng.Assert.assertEqualsImpl(Assert.java:134); at org.testng.Assert.assertEquals(Assert.java:610); at org.testng.Assert.assertEquals(Assert.java:578); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertHeadersMatch(VariantAnnotatorIntegrationTest.java:66); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.runVariantAnnotatorAndAssertSomething(VariantAnnotatorIntegrationTest.java:92); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertVariantContextsMatch(VariantAnnotatorIntegrationTest.java:55); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertVariantContextsMatch(VariantAnnotatorIntegrationTest.java:49); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.testWithAllAnnotations(VariantAnnotatorIntegrationTest.java:224); Exception in thread ""Thread-5"" java.nio.file.ClosedFileSystemException; 	at com.google.common.jimfs.FileSystemState.checkOpen(FileSystemState.java:64); ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477769414
https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477769414:130,Testability,test,testWithAllAnnotations,130,"@meganshand Latest build failed with:. ```; org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.testWithAllAnnotations FAILED; java.lang.AssertionError: Iterators differ at element [9]: FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification""> != FORMAT=<ID=NUMT,Number=1,Type=String,Description=""Potentially a polymorphic NuMT false positive rather than a real mitochondrial variant.""> expected [FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification"">] but found [FORMAT=<ID=NUMT,Number=1,Type=String,Description=""Potentially a polymorphic NuMT false positive rather than a real mitochondrial variant."">]; at org.testng.Assert.fail(Assert.java:93); at org.testng.Assert.failNotEquals(Assert.java:512); at org.testng.Assert.assertEqualsImpl(Assert.java:134); at org.testng.Assert.assertEquals(Assert.java:610); at org.testng.Assert.assertEquals(Assert.java:578); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertHeadersMatch(VariantAnnotatorIntegrationTest.java:66); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.runVariantAnnotatorAndAssertSomething(VariantAnnotatorIntegrationTest.java:92); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertVariantContextsMatch(VariantAnnotatorIntegrationTest.java:55); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertVariantContextsMatch(VariantAnnotatorIntegrationTest.java:49); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.testWithAllAnnotations(VariantAnnotatorIntegrationTest.java:224); Exception in thread ""Thread-5"" java.nio.file.ClosedFileSystemException; 	at com.google.common.jimfs.FileSystemState.checkOpen(FileSystemState.java:64); ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477769414
https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477769414:171,Testability,Assert,AssertionError,171,"@meganshand Latest build failed with:. ```; org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.testWithAllAnnotations FAILED; java.lang.AssertionError: Iterators differ at element [9]: FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification""> != FORMAT=<ID=NUMT,Number=1,Type=String,Description=""Potentially a polymorphic NuMT false positive rather than a real mitochondrial variant.""> expected [FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification"">] but found [FORMAT=<ID=NUMT,Number=1,Type=String,Description=""Potentially a polymorphic NuMT false positive rather than a real mitochondrial variant."">]; at org.testng.Assert.fail(Assert.java:93); at org.testng.Assert.failNotEquals(Assert.java:512); at org.testng.Assert.assertEqualsImpl(Assert.java:134); at org.testng.Assert.assertEquals(Assert.java:610); at org.testng.Assert.assertEquals(Assert.java:578); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertHeadersMatch(VariantAnnotatorIntegrationTest.java:66); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.runVariantAnnotatorAndAssertSomething(VariantAnnotatorIntegrationTest.java:92); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertVariantContextsMatch(VariantAnnotatorIntegrationTest.java:55); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertVariantContextsMatch(VariantAnnotatorIntegrationTest.java:49); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.testWithAllAnnotations(VariantAnnotatorIntegrationTest.java:224); Exception in thread ""Thread-5"" java.nio.file.ClosedFileSystemException; 	at com.google.common.jimfs.FileSystemState.checkOpen(FileSystemState.java:64); ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477769414
https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477769414:810,Testability,test,testng,810,"@meganshand Latest build failed with:. ```; org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.testWithAllAnnotations FAILED; java.lang.AssertionError: Iterators differ at element [9]: FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification""> != FORMAT=<ID=NUMT,Number=1,Type=String,Description=""Potentially a polymorphic NuMT false positive rather than a real mitochondrial variant.""> expected [FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification"">] but found [FORMAT=<ID=NUMT,Number=1,Type=String,Description=""Potentially a polymorphic NuMT false positive rather than a real mitochondrial variant."">]; at org.testng.Assert.fail(Assert.java:93); at org.testng.Assert.failNotEquals(Assert.java:512); at org.testng.Assert.assertEqualsImpl(Assert.java:134); at org.testng.Assert.assertEquals(Assert.java:610); at org.testng.Assert.assertEquals(Assert.java:578); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertHeadersMatch(VariantAnnotatorIntegrationTest.java:66); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.runVariantAnnotatorAndAssertSomething(VariantAnnotatorIntegrationTest.java:92); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertVariantContextsMatch(VariantAnnotatorIntegrationTest.java:55); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertVariantContextsMatch(VariantAnnotatorIntegrationTest.java:49); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.testWithAllAnnotations(VariantAnnotatorIntegrationTest.java:224); Exception in thread ""Thread-5"" java.nio.file.ClosedFileSystemException; 	at com.google.common.jimfs.FileSystemState.checkOpen(FileSystemState.java:64); ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477769414
https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477769414:817,Testability,Assert,Assert,817,"@meganshand Latest build failed with:. ```; org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.testWithAllAnnotations FAILED; java.lang.AssertionError: Iterators differ at element [9]: FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification""> != FORMAT=<ID=NUMT,Number=1,Type=String,Description=""Potentially a polymorphic NuMT false positive rather than a real mitochondrial variant.""> expected [FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification"">] but found [FORMAT=<ID=NUMT,Number=1,Type=String,Description=""Potentially a polymorphic NuMT false positive rather than a real mitochondrial variant."">]; at org.testng.Assert.fail(Assert.java:93); at org.testng.Assert.failNotEquals(Assert.java:512); at org.testng.Assert.assertEqualsImpl(Assert.java:134); at org.testng.Assert.assertEquals(Assert.java:610); at org.testng.Assert.assertEquals(Assert.java:578); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertHeadersMatch(VariantAnnotatorIntegrationTest.java:66); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.runVariantAnnotatorAndAssertSomething(VariantAnnotatorIntegrationTest.java:92); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertVariantContextsMatch(VariantAnnotatorIntegrationTest.java:55); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertVariantContextsMatch(VariantAnnotatorIntegrationTest.java:49); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.testWithAllAnnotations(VariantAnnotatorIntegrationTest.java:224); Exception in thread ""Thread-5"" java.nio.file.ClosedFileSystemException; 	at com.google.common.jimfs.FileSystemState.checkOpen(FileSystemState.java:64); ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477769414
https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477769414:829,Testability,Assert,Assert,829,"@meganshand Latest build failed with:. ```; org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.testWithAllAnnotations FAILED; java.lang.AssertionError: Iterators differ at element [9]: FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification""> != FORMAT=<ID=NUMT,Number=1,Type=String,Description=""Potentially a polymorphic NuMT false positive rather than a real mitochondrial variant.""> expected [FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification"">] but found [FORMAT=<ID=NUMT,Number=1,Type=String,Description=""Potentially a polymorphic NuMT false positive rather than a real mitochondrial variant."">]; at org.testng.Assert.fail(Assert.java:93); at org.testng.Assert.failNotEquals(Assert.java:512); at org.testng.Assert.assertEqualsImpl(Assert.java:134); at org.testng.Assert.assertEquals(Assert.java:610); at org.testng.Assert.assertEquals(Assert.java:578); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertHeadersMatch(VariantAnnotatorIntegrationTest.java:66); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.runVariantAnnotatorAndAssertSomething(VariantAnnotatorIntegrationTest.java:92); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertVariantContextsMatch(VariantAnnotatorIntegrationTest.java:55); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertVariantContextsMatch(VariantAnnotatorIntegrationTest.java:49); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.testWithAllAnnotations(VariantAnnotatorIntegrationTest.java:224); Exception in thread ""Thread-5"" java.nio.file.ClosedFileSystemException; 	at com.google.common.jimfs.FileSystemState.checkOpen(FileSystemState.java:64); ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477769414
https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477769414:853,Testability,test,testng,853,"@meganshand Latest build failed with:. ```; org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.testWithAllAnnotations FAILED; java.lang.AssertionError: Iterators differ at element [9]: FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification""> != FORMAT=<ID=NUMT,Number=1,Type=String,Description=""Potentially a polymorphic NuMT false positive rather than a real mitochondrial variant.""> expected [FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification"">] but found [FORMAT=<ID=NUMT,Number=1,Type=String,Description=""Potentially a polymorphic NuMT false positive rather than a real mitochondrial variant."">]; at org.testng.Assert.fail(Assert.java:93); at org.testng.Assert.failNotEquals(Assert.java:512); at org.testng.Assert.assertEqualsImpl(Assert.java:134); at org.testng.Assert.assertEquals(Assert.java:610); at org.testng.Assert.assertEquals(Assert.java:578); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertHeadersMatch(VariantAnnotatorIntegrationTest.java:66); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.runVariantAnnotatorAndAssertSomething(VariantAnnotatorIntegrationTest.java:92); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertVariantContextsMatch(VariantAnnotatorIntegrationTest.java:55); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertVariantContextsMatch(VariantAnnotatorIntegrationTest.java:49); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.testWithAllAnnotations(VariantAnnotatorIntegrationTest.java:224); Exception in thread ""Thread-5"" java.nio.file.ClosedFileSystemException; 	at com.google.common.jimfs.FileSystemState.checkOpen(FileSystemState.java:64); ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477769414
https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477769414:860,Testability,Assert,Assert,860,"@meganshand Latest build failed with:. ```; org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.testWithAllAnnotations FAILED; java.lang.AssertionError: Iterators differ at element [9]: FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification""> != FORMAT=<ID=NUMT,Number=1,Type=String,Description=""Potentially a polymorphic NuMT false positive rather than a real mitochondrial variant.""> expected [FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification"">] but found [FORMAT=<ID=NUMT,Number=1,Type=String,Description=""Potentially a polymorphic NuMT false positive rather than a real mitochondrial variant."">]; at org.testng.Assert.fail(Assert.java:93); at org.testng.Assert.failNotEquals(Assert.java:512); at org.testng.Assert.assertEqualsImpl(Assert.java:134); at org.testng.Assert.assertEquals(Assert.java:610); at org.testng.Assert.assertEquals(Assert.java:578); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertHeadersMatch(VariantAnnotatorIntegrationTest.java:66); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.runVariantAnnotatorAndAssertSomething(VariantAnnotatorIntegrationTest.java:92); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertVariantContextsMatch(VariantAnnotatorIntegrationTest.java:55); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertVariantContextsMatch(VariantAnnotatorIntegrationTest.java:49); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.testWithAllAnnotations(VariantAnnotatorIntegrationTest.java:224); Exception in thread ""Thread-5"" java.nio.file.ClosedFileSystemException; 	at com.google.common.jimfs.FileSystemState.checkOpen(FileSystemState.java:64); ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477769414
https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477769414:881,Testability,Assert,Assert,881,"@meganshand Latest build failed with:. ```; org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.testWithAllAnnotations FAILED; java.lang.AssertionError: Iterators differ at element [9]: FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification""> != FORMAT=<ID=NUMT,Number=1,Type=String,Description=""Potentially a polymorphic NuMT false positive rather than a real mitochondrial variant.""> expected [FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification"">] but found [FORMAT=<ID=NUMT,Number=1,Type=String,Description=""Potentially a polymorphic NuMT false positive rather than a real mitochondrial variant."">]; at org.testng.Assert.fail(Assert.java:93); at org.testng.Assert.failNotEquals(Assert.java:512); at org.testng.Assert.assertEqualsImpl(Assert.java:134); at org.testng.Assert.assertEquals(Assert.java:610); at org.testng.Assert.assertEquals(Assert.java:578); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertHeadersMatch(VariantAnnotatorIntegrationTest.java:66); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.runVariantAnnotatorAndAssertSomething(VariantAnnotatorIntegrationTest.java:92); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertVariantContextsMatch(VariantAnnotatorIntegrationTest.java:55); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertVariantContextsMatch(VariantAnnotatorIntegrationTest.java:49); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.testWithAllAnnotations(VariantAnnotatorIntegrationTest.java:224); Exception in thread ""Thread-5"" java.nio.file.ClosedFileSystemException; 	at com.google.common.jimfs.FileSystemState.checkOpen(FileSystemState.java:64); ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477769414
https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477769414:906,Testability,test,testng,906,"@meganshand Latest build failed with:. ```; org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.testWithAllAnnotations FAILED; java.lang.AssertionError: Iterators differ at element [9]: FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification""> != FORMAT=<ID=NUMT,Number=1,Type=String,Description=""Potentially a polymorphic NuMT false positive rather than a real mitochondrial variant.""> expected [FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification"">] but found [FORMAT=<ID=NUMT,Number=1,Type=String,Description=""Potentially a polymorphic NuMT false positive rather than a real mitochondrial variant."">]; at org.testng.Assert.fail(Assert.java:93); at org.testng.Assert.failNotEquals(Assert.java:512); at org.testng.Assert.assertEqualsImpl(Assert.java:134); at org.testng.Assert.assertEquals(Assert.java:610); at org.testng.Assert.assertEquals(Assert.java:578); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertHeadersMatch(VariantAnnotatorIntegrationTest.java:66); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.runVariantAnnotatorAndAssertSomething(VariantAnnotatorIntegrationTest.java:92); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertVariantContextsMatch(VariantAnnotatorIntegrationTest.java:55); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertVariantContextsMatch(VariantAnnotatorIntegrationTest.java:49); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.testWithAllAnnotations(VariantAnnotatorIntegrationTest.java:224); Exception in thread ""Thread-5"" java.nio.file.ClosedFileSystemException; 	at com.google.common.jimfs.FileSystemState.checkOpen(FileSystemState.java:64); ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477769414
https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477769414:913,Testability,Assert,Assert,913,"@meganshand Latest build failed with:. ```; org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.testWithAllAnnotations FAILED; java.lang.AssertionError: Iterators differ at element [9]: FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification""> != FORMAT=<ID=NUMT,Number=1,Type=String,Description=""Potentially a polymorphic NuMT false positive rather than a real mitochondrial variant.""> expected [FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification"">] but found [FORMAT=<ID=NUMT,Number=1,Type=String,Description=""Potentially a polymorphic NuMT false positive rather than a real mitochondrial variant."">]; at org.testng.Assert.fail(Assert.java:93); at org.testng.Assert.failNotEquals(Assert.java:512); at org.testng.Assert.assertEqualsImpl(Assert.java:134); at org.testng.Assert.assertEquals(Assert.java:610); at org.testng.Assert.assertEquals(Assert.java:578); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertHeadersMatch(VariantAnnotatorIntegrationTest.java:66); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.runVariantAnnotatorAndAssertSomething(VariantAnnotatorIntegrationTest.java:92); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertVariantContextsMatch(VariantAnnotatorIntegrationTest.java:55); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertVariantContextsMatch(VariantAnnotatorIntegrationTest.java:49); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.testWithAllAnnotations(VariantAnnotatorIntegrationTest.java:224); Exception in thread ""Thread-5"" java.nio.file.ClosedFileSystemException; 	at com.google.common.jimfs.FileSystemState.checkOpen(FileSystemState.java:64); ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477769414
https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477769414:920,Testability,assert,assertEqualsImpl,920,"@meganshand Latest build failed with:. ```; org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.testWithAllAnnotations FAILED; java.lang.AssertionError: Iterators differ at element [9]: FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification""> != FORMAT=<ID=NUMT,Number=1,Type=String,Description=""Potentially a polymorphic NuMT false positive rather than a real mitochondrial variant.""> expected [FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification"">] but found [FORMAT=<ID=NUMT,Number=1,Type=String,Description=""Potentially a polymorphic NuMT false positive rather than a real mitochondrial variant."">]; at org.testng.Assert.fail(Assert.java:93); at org.testng.Assert.failNotEquals(Assert.java:512); at org.testng.Assert.assertEqualsImpl(Assert.java:134); at org.testng.Assert.assertEquals(Assert.java:610); at org.testng.Assert.assertEquals(Assert.java:578); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertHeadersMatch(VariantAnnotatorIntegrationTest.java:66); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.runVariantAnnotatorAndAssertSomething(VariantAnnotatorIntegrationTest.java:92); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertVariantContextsMatch(VariantAnnotatorIntegrationTest.java:55); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertVariantContextsMatch(VariantAnnotatorIntegrationTest.java:49); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.testWithAllAnnotations(VariantAnnotatorIntegrationTest.java:224); Exception in thread ""Thread-5"" java.nio.file.ClosedFileSystemException; 	at com.google.common.jimfs.FileSystemState.checkOpen(FileSystemState.java:64); ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477769414
https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477769414:937,Testability,Assert,Assert,937,"@meganshand Latest build failed with:. ```; org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.testWithAllAnnotations FAILED; java.lang.AssertionError: Iterators differ at element [9]: FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification""> != FORMAT=<ID=NUMT,Number=1,Type=String,Description=""Potentially a polymorphic NuMT false positive rather than a real mitochondrial variant.""> expected [FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification"">] but found [FORMAT=<ID=NUMT,Number=1,Type=String,Description=""Potentially a polymorphic NuMT false positive rather than a real mitochondrial variant."">]; at org.testng.Assert.fail(Assert.java:93); at org.testng.Assert.failNotEquals(Assert.java:512); at org.testng.Assert.assertEqualsImpl(Assert.java:134); at org.testng.Assert.assertEquals(Assert.java:610); at org.testng.Assert.assertEquals(Assert.java:578); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertHeadersMatch(VariantAnnotatorIntegrationTest.java:66); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.runVariantAnnotatorAndAssertSomething(VariantAnnotatorIntegrationTest.java:92); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertVariantContextsMatch(VariantAnnotatorIntegrationTest.java:55); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertVariantContextsMatch(VariantAnnotatorIntegrationTest.java:49); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.testWithAllAnnotations(VariantAnnotatorIntegrationTest.java:224); Exception in thread ""Thread-5"" java.nio.file.ClosedFileSystemException; 	at com.google.common.jimfs.FileSystemState.checkOpen(FileSystemState.java:64); ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477769414
https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477769414:962,Testability,test,testng,962,"@meganshand Latest build failed with:. ```; org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.testWithAllAnnotations FAILED; java.lang.AssertionError: Iterators differ at element [9]: FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification""> != FORMAT=<ID=NUMT,Number=1,Type=String,Description=""Potentially a polymorphic NuMT false positive rather than a real mitochondrial variant.""> expected [FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification"">] but found [FORMAT=<ID=NUMT,Number=1,Type=String,Description=""Potentially a polymorphic NuMT false positive rather than a real mitochondrial variant."">]; at org.testng.Assert.fail(Assert.java:93); at org.testng.Assert.failNotEquals(Assert.java:512); at org.testng.Assert.assertEqualsImpl(Assert.java:134); at org.testng.Assert.assertEquals(Assert.java:610); at org.testng.Assert.assertEquals(Assert.java:578); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertHeadersMatch(VariantAnnotatorIntegrationTest.java:66); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.runVariantAnnotatorAndAssertSomething(VariantAnnotatorIntegrationTest.java:92); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertVariantContextsMatch(VariantAnnotatorIntegrationTest.java:55); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertVariantContextsMatch(VariantAnnotatorIntegrationTest.java:49); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.testWithAllAnnotations(VariantAnnotatorIntegrationTest.java:224); Exception in thread ""Thread-5"" java.nio.file.ClosedFileSystemException; 	at com.google.common.jimfs.FileSystemState.checkOpen(FileSystemState.java:64); ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477769414
https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477769414:969,Testability,Assert,Assert,969,"@meganshand Latest build failed with:. ```; org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.testWithAllAnnotations FAILED; java.lang.AssertionError: Iterators differ at element [9]: FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification""> != FORMAT=<ID=NUMT,Number=1,Type=String,Description=""Potentially a polymorphic NuMT false positive rather than a real mitochondrial variant.""> expected [FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification"">] but found [FORMAT=<ID=NUMT,Number=1,Type=String,Description=""Potentially a polymorphic NuMT false positive rather than a real mitochondrial variant."">]; at org.testng.Assert.fail(Assert.java:93); at org.testng.Assert.failNotEquals(Assert.java:512); at org.testng.Assert.assertEqualsImpl(Assert.java:134); at org.testng.Assert.assertEquals(Assert.java:610); at org.testng.Assert.assertEquals(Assert.java:578); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertHeadersMatch(VariantAnnotatorIntegrationTest.java:66); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.runVariantAnnotatorAndAssertSomething(VariantAnnotatorIntegrationTest.java:92); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertVariantContextsMatch(VariantAnnotatorIntegrationTest.java:55); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertVariantContextsMatch(VariantAnnotatorIntegrationTest.java:49); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.testWithAllAnnotations(VariantAnnotatorIntegrationTest.java:224); Exception in thread ""Thread-5"" java.nio.file.ClosedFileSystemException; 	at com.google.common.jimfs.FileSystemState.checkOpen(FileSystemState.java:64); ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477769414
https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477769414:976,Testability,assert,assertEquals,976,"@meganshand Latest build failed with:. ```; org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.testWithAllAnnotations FAILED; java.lang.AssertionError: Iterators differ at element [9]: FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification""> != FORMAT=<ID=NUMT,Number=1,Type=String,Description=""Potentially a polymorphic NuMT false positive rather than a real mitochondrial variant.""> expected [FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification"">] but found [FORMAT=<ID=NUMT,Number=1,Type=String,Description=""Potentially a polymorphic NuMT false positive rather than a real mitochondrial variant."">]; at org.testng.Assert.fail(Assert.java:93); at org.testng.Assert.failNotEquals(Assert.java:512); at org.testng.Assert.assertEqualsImpl(Assert.java:134); at org.testng.Assert.assertEquals(Assert.java:610); at org.testng.Assert.assertEquals(Assert.java:578); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertHeadersMatch(VariantAnnotatorIntegrationTest.java:66); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.runVariantAnnotatorAndAssertSomething(VariantAnnotatorIntegrationTest.java:92); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertVariantContextsMatch(VariantAnnotatorIntegrationTest.java:55); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertVariantContextsMatch(VariantAnnotatorIntegrationTest.java:49); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.testWithAllAnnotations(VariantAnnotatorIntegrationTest.java:224); Exception in thread ""Thread-5"" java.nio.file.ClosedFileSystemException; 	at com.google.common.jimfs.FileSystemState.checkOpen(FileSystemState.java:64); ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477769414
https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477769414:989,Testability,Assert,Assert,989,"@meganshand Latest build failed with:. ```; org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.testWithAllAnnotations FAILED; java.lang.AssertionError: Iterators differ at element [9]: FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification""> != FORMAT=<ID=NUMT,Number=1,Type=String,Description=""Potentially a polymorphic NuMT false positive rather than a real mitochondrial variant.""> expected [FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification"">] but found [FORMAT=<ID=NUMT,Number=1,Type=String,Description=""Potentially a polymorphic NuMT false positive rather than a real mitochondrial variant."">]; at org.testng.Assert.fail(Assert.java:93); at org.testng.Assert.failNotEquals(Assert.java:512); at org.testng.Assert.assertEqualsImpl(Assert.java:134); at org.testng.Assert.assertEquals(Assert.java:610); at org.testng.Assert.assertEquals(Assert.java:578); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertHeadersMatch(VariantAnnotatorIntegrationTest.java:66); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.runVariantAnnotatorAndAssertSomething(VariantAnnotatorIntegrationTest.java:92); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertVariantContextsMatch(VariantAnnotatorIntegrationTest.java:55); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertVariantContextsMatch(VariantAnnotatorIntegrationTest.java:49); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.testWithAllAnnotations(VariantAnnotatorIntegrationTest.java:224); Exception in thread ""Thread-5"" java.nio.file.ClosedFileSystemException; 	at com.google.common.jimfs.FileSystemState.checkOpen(FileSystemState.java:64); ",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477769414
https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477769414:1014,Testability,test,testng,1014,"t build failed with:. ```; org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.testWithAllAnnotations FAILED; java.lang.AssertionError: Iterators differ at element [9]: FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification""> != FORMAT=<ID=NUMT,Number=1,Type=String,Description=""Potentially a polymorphic NuMT false positive rather than a real mitochondrial variant.""> expected [FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification"">] but found [FORMAT=<ID=NUMT,Number=1,Type=String,Description=""Potentially a polymorphic NuMT false positive rather than a real mitochondrial variant."">]; at org.testng.Assert.fail(Assert.java:93); at org.testng.Assert.failNotEquals(Assert.java:512); at org.testng.Assert.assertEqualsImpl(Assert.java:134); at org.testng.Assert.assertEquals(Assert.java:610); at org.testng.Assert.assertEquals(Assert.java:578); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertHeadersMatch(VariantAnnotatorIntegrationTest.java:66); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.runVariantAnnotatorAndAssertSomething(VariantAnnotatorIntegrationTest.java:92); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertVariantContextsMatch(VariantAnnotatorIntegrationTest.java:55); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertVariantContextsMatch(VariantAnnotatorIntegrationTest.java:49); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.testWithAllAnnotations(VariantAnnotatorIntegrationTest.java:224); Exception in thread ""Thread-5"" java.nio.file.ClosedFileSystemException; 	at com.google.common.jimfs.FileSystemState.checkOpen(FileSystemState.java:64); 	at com.google.co",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477769414
https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477769414:1021,Testability,Assert,Assert,1021," failed with:. ```; org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.testWithAllAnnotations FAILED; java.lang.AssertionError: Iterators differ at element [9]: FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification""> != FORMAT=<ID=NUMT,Number=1,Type=String,Description=""Potentially a polymorphic NuMT false positive rather than a real mitochondrial variant.""> expected [FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification"">] but found [FORMAT=<ID=NUMT,Number=1,Type=String,Description=""Potentially a polymorphic NuMT false positive rather than a real mitochondrial variant."">]; at org.testng.Assert.fail(Assert.java:93); at org.testng.Assert.failNotEquals(Assert.java:512); at org.testng.Assert.assertEqualsImpl(Assert.java:134); at org.testng.Assert.assertEquals(Assert.java:610); at org.testng.Assert.assertEquals(Assert.java:578); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertHeadersMatch(VariantAnnotatorIntegrationTest.java:66); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.runVariantAnnotatorAndAssertSomething(VariantAnnotatorIntegrationTest.java:92); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertVariantContextsMatch(VariantAnnotatorIntegrationTest.java:55); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertVariantContextsMatch(VariantAnnotatorIntegrationTest.java:49); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.testWithAllAnnotations(VariantAnnotatorIntegrationTest.java:224); Exception in thread ""Thread-5"" java.nio.file.ClosedFileSystemException; 	at com.google.common.jimfs.FileSystemState.checkOpen(FileSystemState.java:64); 	at com.google.common.ji",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477769414
https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477769414:1028,Testability,assert,assertEquals,1028," ```; org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.testWithAllAnnotations FAILED; java.lang.AssertionError: Iterators differ at element [9]: FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification""> != FORMAT=<ID=NUMT,Number=1,Type=String,Description=""Potentially a polymorphic NuMT false positive rather than a real mitochondrial variant.""> expected [FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification"">] but found [FORMAT=<ID=NUMT,Number=1,Type=String,Description=""Potentially a polymorphic NuMT false positive rather than a real mitochondrial variant."">]; at org.testng.Assert.fail(Assert.java:93); at org.testng.Assert.failNotEquals(Assert.java:512); at org.testng.Assert.assertEqualsImpl(Assert.java:134); at org.testng.Assert.assertEquals(Assert.java:610); at org.testng.Assert.assertEquals(Assert.java:578); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertHeadersMatch(VariantAnnotatorIntegrationTest.java:66); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.runVariantAnnotatorAndAssertSomething(VariantAnnotatorIntegrationTest.java:92); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertVariantContextsMatch(VariantAnnotatorIntegrationTest.java:55); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertVariantContextsMatch(VariantAnnotatorIntegrationTest.java:49); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.testWithAllAnnotations(VariantAnnotatorIntegrationTest.java:224); Exception in thread ""Thread-5"" java.nio.file.ClosedFileSystemException; 	at com.google.common.jimfs.FileSystemState.checkOpen(FileSystemState.java:64); 	at com.google.common.jimfs.JimfsFile",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477769414
https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477769414:1041,Testability,Assert,Assert,1041," ```; org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.testWithAllAnnotations FAILED; java.lang.AssertionError: Iterators differ at element [9]: FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification""> != FORMAT=<ID=NUMT,Number=1,Type=String,Description=""Potentially a polymorphic NuMT false positive rather than a real mitochondrial variant.""> expected [FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification"">] but found [FORMAT=<ID=NUMT,Number=1,Type=String,Description=""Potentially a polymorphic NuMT false positive rather than a real mitochondrial variant."">]; at org.testng.Assert.fail(Assert.java:93); at org.testng.Assert.failNotEquals(Assert.java:512); at org.testng.Assert.assertEqualsImpl(Assert.java:134); at org.testng.Assert.assertEquals(Assert.java:610); at org.testng.Assert.assertEquals(Assert.java:578); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertHeadersMatch(VariantAnnotatorIntegrationTest.java:66); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.runVariantAnnotatorAndAssertSomething(VariantAnnotatorIntegrationTest.java:92); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertVariantContextsMatch(VariantAnnotatorIntegrationTest.java:55); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertVariantContextsMatch(VariantAnnotatorIntegrationTest.java:49); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.testWithAllAnnotations(VariantAnnotatorIntegrationTest.java:224); Exception in thread ""Thread-5"" java.nio.file.ClosedFileSystemException; 	at com.google.common.jimfs.FileSystemState.checkOpen(FileSystemState.java:64); 	at com.google.common.jimfs.JimfsFile",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477769414
https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477769414:1148,Testability,assert,assertHeadersMatch,1148,"sertionError: Iterators differ at element [9]: FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification""> != FORMAT=<ID=NUMT,Number=1,Type=String,Description=""Potentially a polymorphic NuMT false positive rather than a real mitochondrial variant.""> expected [FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification"">] but found [FORMAT=<ID=NUMT,Number=1,Type=String,Description=""Potentially a polymorphic NuMT false positive rather than a real mitochondrial variant."">]; at org.testng.Assert.fail(Assert.java:93); at org.testng.Assert.failNotEquals(Assert.java:512); at org.testng.Assert.assertEqualsImpl(Assert.java:134); at org.testng.Assert.assertEquals(Assert.java:610); at org.testng.Assert.assertEquals(Assert.java:578); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertHeadersMatch(VariantAnnotatorIntegrationTest.java:66); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.runVariantAnnotatorAndAssertSomething(VariantAnnotatorIntegrationTest.java:92); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertVariantContextsMatch(VariantAnnotatorIntegrationTest.java:55); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertVariantContextsMatch(VariantAnnotatorIntegrationTest.java:49); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.testWithAllAnnotations(VariantAnnotatorIntegrationTest.java:224); Exception in thread ""Thread-5"" java.nio.file.ClosedFileSystemException; 	at com.google.common.jimfs.FileSystemState.checkOpen(FileSystemState.java:64); 	at com.google.common.jimfs.JimfsFileStore.lookUp(JimfsFileStore.java:141); 	at com.google.common.jimfs.FileSystemView.lookUp(FileSystemView.java:123); 	at com.google.common",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477769414
https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477769414:1467,Testability,assert,assertVariantContextsMatch,1467,"t.""> expected [FORMAT=<ID=PL,Number=G,Type=Integer,Description=""Normalized, Phred-scaled likelihoods for genotypes as defined in the VCF specification"">] but found [FORMAT=<ID=NUMT,Number=1,Type=String,Description=""Potentially a polymorphic NuMT false positive rather than a real mitochondrial variant."">]; at org.testng.Assert.fail(Assert.java:93); at org.testng.Assert.failNotEquals(Assert.java:512); at org.testng.Assert.assertEqualsImpl(Assert.java:134); at org.testng.Assert.assertEquals(Assert.java:610); at org.testng.Assert.assertEquals(Assert.java:578); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertHeadersMatch(VariantAnnotatorIntegrationTest.java:66); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.runVariantAnnotatorAndAssertSomething(VariantAnnotatorIntegrationTest.java:92); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertVariantContextsMatch(VariantAnnotatorIntegrationTest.java:55); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertVariantContextsMatch(VariantAnnotatorIntegrationTest.java:49); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.testWithAllAnnotations(VariantAnnotatorIntegrationTest.java:224); Exception in thread ""Thread-5"" java.nio.file.ClosedFileSystemException; 	at com.google.common.jimfs.FileSystemState.checkOpen(FileSystemState.java:64); 	at com.google.common.jimfs.JimfsFileStore.lookUp(JimfsFileStore.java:141); 	at com.google.common.jimfs.FileSystemView.lookUp(FileSystemView.java:123); 	at com.google.common.jimfs.FileSystemView.lookUpWithLock(FileSystemView.java:112); 	at com.google.common.jimfs.FileSystemView.readAttributes(FileSystemView.java:771); 	at com.google.common.jimfs.JimfsFileSystemProvider.readAttributes(JimfsFileSystemProvider.java:346); 	at java.nio.file.Files.readAttributes(Files.java:1737); 	at java.nio.file",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477769414
https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477769414:1625,Testability,assert,assertVariantContextsMatch,1625,"found [FORMAT=<ID=NUMT,Number=1,Type=String,Description=""Potentially a polymorphic NuMT false positive rather than a real mitochondrial variant."">]; at org.testng.Assert.fail(Assert.java:93); at org.testng.Assert.failNotEquals(Assert.java:512); at org.testng.Assert.assertEqualsImpl(Assert.java:134); at org.testng.Assert.assertEquals(Assert.java:610); at org.testng.Assert.assertEquals(Assert.java:578); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertHeadersMatch(VariantAnnotatorIntegrationTest.java:66); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.runVariantAnnotatorAndAssertSomething(VariantAnnotatorIntegrationTest.java:92); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertVariantContextsMatch(VariantAnnotatorIntegrationTest.java:55); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertVariantContextsMatch(VariantAnnotatorIntegrationTest.java:49); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.testWithAllAnnotations(VariantAnnotatorIntegrationTest.java:224); Exception in thread ""Thread-5"" java.nio.file.ClosedFileSystemException; 	at com.google.common.jimfs.FileSystemState.checkOpen(FileSystemState.java:64); 	at com.google.common.jimfs.JimfsFileStore.lookUp(JimfsFileStore.java:141); 	at com.google.common.jimfs.FileSystemView.lookUp(FileSystemView.java:123); 	at com.google.common.jimfs.FileSystemView.lookUpWithLock(FileSystemView.java:112); 	at com.google.common.jimfs.FileSystemView.readAttributes(FileSystemView.java:771); 	at com.google.common.jimfs.JimfsFileSystemProvider.readAttributes(JimfsFileSystemProvider.java:346); 	at java.nio.file.Files.readAttributes(Files.java:1737); 	at java.nio.file.FileTreeWalker.getAttributes(FileTreeWalker.java:219); 	at java.nio.file.FileTreeWalker.visit(FileTreeWalker.java:276); 	at java.nio.file.FileTreeWalker.walk",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477769414
https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477769414:1783,Testability,test,testWithAllAnnotations,1783,"testng.Assert.fail(Assert.java:93); at org.testng.Assert.failNotEquals(Assert.java:512); at org.testng.Assert.assertEqualsImpl(Assert.java:134); at org.testng.Assert.assertEquals(Assert.java:610); at org.testng.Assert.assertEquals(Assert.java:578); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertHeadersMatch(VariantAnnotatorIntegrationTest.java:66); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.runVariantAnnotatorAndAssertSomething(VariantAnnotatorIntegrationTest.java:92); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertVariantContextsMatch(VariantAnnotatorIntegrationTest.java:55); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertVariantContextsMatch(VariantAnnotatorIntegrationTest.java:49); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.testWithAllAnnotations(VariantAnnotatorIntegrationTest.java:224); Exception in thread ""Thread-5"" java.nio.file.ClosedFileSystemException; 	at com.google.common.jimfs.FileSystemState.checkOpen(FileSystemState.java:64); 	at com.google.common.jimfs.JimfsFileStore.lookUp(JimfsFileStore.java:141); 	at com.google.common.jimfs.FileSystemView.lookUp(FileSystemView.java:123); 	at com.google.common.jimfs.FileSystemView.lookUpWithLock(FileSystemView.java:112); 	at com.google.common.jimfs.FileSystemView.readAttributes(FileSystemView.java:771); 	at com.google.common.jimfs.JimfsFileSystemProvider.readAttributes(JimfsFileSystemProvider.java:346); 	at java.nio.file.Files.readAttributes(Files.java:1737); 	at java.nio.file.FileTreeWalker.getAttributes(FileTreeWalker.java:219); 	at java.nio.file.FileTreeWalker.visit(FileTreeWalker.java:276); 	at java.nio.file.FileTreeWalker.walk(FileTreeWalker.java:322); 	at java.nio.file.Files.walkFileTree(Files.java:2662); 	at java.nio.file.Files.walkFileTree(Files.java:2742); 	at htsjdk.samtools",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477769414
https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477769414:3140,Testability,test,tests,3140,"tionTest.java:66); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.runVariantAnnotatorAndAssertSomething(VariantAnnotatorIntegrationTest.java:92); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertVariantContextsMatch(VariantAnnotatorIntegrationTest.java:55); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.assertVariantContextsMatch(VariantAnnotatorIntegrationTest.java:49); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorIntegrationTest.testWithAllAnnotations(VariantAnnotatorIntegrationTest.java:224); Exception in thread ""Thread-5"" java.nio.file.ClosedFileSystemException; 	at com.google.common.jimfs.FileSystemState.checkOpen(FileSystemState.java:64); 	at com.google.common.jimfs.JimfsFileStore.lookUp(JimfsFileStore.java:141); 	at com.google.common.jimfs.FileSystemView.lookUp(FileSystemView.java:123); 	at com.google.common.jimfs.FileSystemView.lookUpWithLock(FileSystemView.java:112); 	at com.google.common.jimfs.FileSystemView.readAttributes(FileSystemView.java:771); 	at com.google.common.jimfs.JimfsFileSystemProvider.readAttributes(JimfsFileSystemProvider.java:346); 	at java.nio.file.Files.readAttributes(Files.java:1737); 	at java.nio.file.FileTreeWalker.getAttributes(FileTreeWalker.java:219); 	at java.nio.file.FileTreeWalker.visit(FileTreeWalker.java:276); 	at java.nio.file.FileTreeWalker.walk(FileTreeWalker.java:322); 	at java.nio.file.Files.walkFileTree(Files.java:2662); 	at java.nio.file.Files.walkFileTree(Files.java:2742); 	at htsjdk.samtools.util.IOUtil.recursiveDelete(IOUtil.java:1344); 	at org.broadinstitute.hellbender.utils.io.IOUtils.deleteRecursively(IOUtils.java:1061); 	at org.broadinstitute.hellbender.utils.io.DeleteRecursivelyOnExitPathHook.runHooks(DeleteRecursivelyOnExitPathHook.java:56); 	at java.lang.Thread.run(Thread.java:748); Results: FAILURE (1604 tests, 1603 successes, 1 failures, 0 skipped); ```",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5842#issuecomment-477769414
https://github.com/broadinstitute/gatk/pull/5843#issuecomment-477767829:220,Deployability,release,release,220,"@als364 Can I request that you title your pull requests more descriptively? Ie., include the tool involved in the PR title, and a concise one-line description of the improvements/fixes. This would help when writing GATK release notes, as we use the PR titles as the basis for initial release notes. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5843#issuecomment-477767829
https://github.com/broadinstitute/gatk/pull/5843#issuecomment-477767829:284,Deployability,release,release,284,"@als364 Can I request that you title your pull requests more descriptively? Ie., include the tool involved in the PR title, and a concise one-line description of the improvements/fixes. This would help when writing GATK release notes, as we use the PR titles as the basis for initial release notes. Thanks!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5843#issuecomment-477767829
https://github.com/broadinstitute/gatk/pull/5844#issuecomment-477765576:3688,Deployability,update,update,3688,"el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL0dlbm90eXBlR1ZDRnMuamF2YQ==) | `90.71% <0%> (-0.43%)` | `100% <0%> (-1%)` | |; | [...lbender/utils/variant/GATKVariantContextUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5844/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L0dBVEtWYXJpYW50Q29udGV4dFV0aWxzLmphdmE=) | `87.3% <0%> (-0.31%)` | `244% <0%> (-2%)` | |; | [...ithwaterman/SmithWatermanIntelAlignerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5844/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXJVbml0VGVzdC5qYXZh) | `60% <0%> (ø)` | `2% <0%> (ø)` | :arrow_down: |; | [...nder/utils/runtime/StreamingProcessController.java](https://codecov.io/gh/broadinstitute/gatk/pull/5844/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9ydW50aW1lL1N0cmVhbWluZ1Byb2Nlc3NDb250cm9sbGVyLmphdmE=) | `67.77% <0%> (+0.47%)` | `33% <0%> (ø)` | :arrow_down: |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5844/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `80% <0%> (+30%)` | `3% <0%> (+2%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5844?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5844?src=pr&el=footer). Last update [7c24e67...43708f1](https://codecov.io/gh/broadinstitute/gatk/pull/5844?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5844#issuecomment-477765576
https://github.com/broadinstitute/gatk/pull/5844#issuecomment-477765576:3591,Energy Efficiency,Power,Powered,3591,"el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL0dlbm90eXBlR1ZDRnMuamF2YQ==) | `90.71% <0%> (-0.43%)` | `100% <0%> (-1%)` | |; | [...lbender/utils/variant/GATKVariantContextUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5844/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L0dBVEtWYXJpYW50Q29udGV4dFV0aWxzLmphdmE=) | `87.3% <0%> (-0.31%)` | `244% <0%> (-2%)` | |; | [...ithwaterman/SmithWatermanIntelAlignerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5844/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXJVbml0VGVzdC5qYXZh) | `60% <0%> (ø)` | `2% <0%> (ø)` | :arrow_down: |; | [...nder/utils/runtime/StreamingProcessController.java](https://codecov.io/gh/broadinstitute/gatk/pull/5844/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9ydW50aW1lL1N0cmVhbWluZ1Byb2Nlc3NDb250cm9sbGVyLmphdmE=) | `67.77% <0%> (+0.47%)` | `33% <0%> (ø)` | :arrow_down: |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5844/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `80% <0%> (+30%)` | `3% <0%> (+2%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5844?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5844?src=pr&el=footer). Last update [7c24e67...43708f1](https://codecov.io/gh/broadinstitute/gatk/pull/5844?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5844#issuecomment-477765576
https://github.com/broadinstitute/gatk/pull/5844#issuecomment-477765576:3454,Usability,learn,learn,3454,"el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL0dlbm90eXBlR1ZDRnMuamF2YQ==) | `90.71% <0%> (-0.43%)` | `100% <0%> (-1%)` | |; | [...lbender/utils/variant/GATKVariantContextUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5844/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L0dBVEtWYXJpYW50Q29udGV4dFV0aWxzLmphdmE=) | `87.3% <0%> (-0.31%)` | `244% <0%> (-2%)` | |; | [...ithwaterman/SmithWatermanIntelAlignerUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5844/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXJVbml0VGVzdC5qYXZh) | `60% <0%> (ø)` | `2% <0%> (ø)` | :arrow_down: |; | [...nder/utils/runtime/StreamingProcessController.java](https://codecov.io/gh/broadinstitute/gatk/pull/5844/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9ydW50aW1lL1N0cmVhbWluZ1Byb2Nlc3NDb250cm9sbGVyLmphdmE=) | `67.77% <0%> (+0.47%)` | `33% <0%> (ø)` | :arrow_down: |; | [...utils/smithwaterman/SmithWatermanIntelAligner.java](https://codecov.io/gh/broadinstitute/gatk/pull/5844/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9zbWl0aHdhdGVybWFuL1NtaXRoV2F0ZXJtYW5JbnRlbEFsaWduZXIuamF2YQ==) | `80% <0%> (+30%)` | `3% <0%> (+2%)` | :arrow_up: |. ------. [Continue to review full report at Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5844?src=pr&el=continue).; > **Legend** - [Click here to learn more](https://docs.codecov.io/docs/codecov-delta); > `Δ = absolute <relative> (impact)`, `ø = not affected`, `? = missing data`; > Powered by [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5844?src=pr&el=footer). Last update [7c24e67...43708f1](https://codecov.io/gh/broadinstitute/gatk/pull/5844?src=pr&el=lastupdated). Read the [comment docs](https://docs.codecov.io/docs/pull-request-comments).",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5844#issuecomment-477765576
https://github.com/broadinstitute/gatk/issues/5845#issuecomment-477985961:96,Availability,avail,available,96,"That argument is only relevant to HaplotypeCaller and GenotypeGVCFs. It; should never have been available for Mutect2. On Thu, Mar 28, 2019, 11:09 PM igor <notifications@github.com> wrote:. > I just tried Mutect2 from GATK 4.1.1.0 and got an error:; >; > A USER ERROR has occurred: standard-min-confidence-threshold-for-calling is not a recognized option; >; > From the online documentation; > <https://software.broadinstitute.org/gatk/documentation/tooldocs/4.1.0.0/org_broadinstitute_hellbender_tools_walkers_mutect_Mutect2.php>; > :; >; > Note that the default was changed from 10.0 to 30.0 in version 4.1.0.0 to; > accompany the switch to use the the new quality score by default.; >; > Thus, it was still maintained in 4.1.0.0. Based on that, I am surprised; > that it was removed. I just wanted to confirm this was an intended change.; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/5845>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdCF1GhJcFOFF4YvLqB_rB0x5oquxks5vbYQFgaJpZM4cRiVD>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5845#issuecomment-477985961
https://github.com/broadinstitute/gatk/issues/5845#issuecomment-477985961:242,Availability,error,error,242,"That argument is only relevant to HaplotypeCaller and GenotypeGVCFs. It; should never have been available for Mutect2. On Thu, Mar 28, 2019, 11:09 PM igor <notifications@github.com> wrote:. > I just tried Mutect2 from GATK 4.1.1.0 and got an error:; >; > A USER ERROR has occurred: standard-min-confidence-threshold-for-calling is not a recognized option; >; > From the online documentation; > <https://software.broadinstitute.org/gatk/documentation/tooldocs/4.1.0.0/org_broadinstitute_hellbender_tools_walkers_mutect_Mutect2.php>; > :; >; > Note that the default was changed from 10.0 to 30.0 in version 4.1.0.0 to; > accompany the switch to use the the new quality score by default.; >; > Thus, it was still maintained in 4.1.0.0. Based on that, I am surprised; > that it was removed. I just wanted to confirm this was an intended change.; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/5845>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdCF1GhJcFOFF4YvLqB_rB0x5oquxks5vbYQFgaJpZM4cRiVD>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5845#issuecomment-477985961
https://github.com/broadinstitute/gatk/issues/5845#issuecomment-477985961:262,Availability,ERROR,ERROR,262,"That argument is only relevant to HaplotypeCaller and GenotypeGVCFs. It; should never have been available for Mutect2. On Thu, Mar 28, 2019, 11:09 PM igor <notifications@github.com> wrote:. > I just tried Mutect2 from GATK 4.1.1.0 and got an error:; >; > A USER ERROR has occurred: standard-min-confidence-threshold-for-calling is not a recognized option; >; > From the online documentation; > <https://software.broadinstitute.org/gatk/documentation/tooldocs/4.1.0.0/org_broadinstitute_hellbender_tools_walkers_mutect_Mutect2.php>; > :; >; > Note that the default was changed from 10.0 to 30.0 in version 4.1.0.0 to; > accompany the switch to use the the new quality score by default.; >; > Thus, it was still maintained in 4.1.0.0. Based on that, I am surprised; > that it was removed. I just wanted to confirm this was an intended change.; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/5845>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdCF1GhJcFOFF4YvLqB_rB0x5oquxks5vbYQFgaJpZM4cRiVD>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5845#issuecomment-477985961
https://github.com/broadinstitute/gatk/issues/5845#issuecomment-478008792:82,Modifiability,extend,extend,82,"@igordot It used to exist because `AssemblyBasedCallerArgumentCollection` used to extend `StandardCallerArgumentCollection`, causing `Mutect2` to have a bunch of `HaplotypeCaller` arguments that it didn't use. This was fixed in PR #5758. `FilterMutectCalls` also lost a few arguments as part of a huge change to the entire filtering model in PR #5688. I'm working on a blog post about this but for now the Mutect2 docs at https://github.com/broadinstitute/gatk/blob/master/docs/mutect/mutect.pdf are up-to-date and more user-friendly than they used to be.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5845#issuecomment-478008792
https://github.com/broadinstitute/gatk/issues/5845#issuecomment-478008792:520,Usability,user-friendly,user-friendly,520,"@igordot It used to exist because `AssemblyBasedCallerArgumentCollection` used to extend `StandardCallerArgumentCollection`, causing `Mutect2` to have a bunch of `HaplotypeCaller` arguments that it didn't use. This was fixed in PR #5758. `FilterMutectCalls` also lost a few arguments as part of a huge change to the entire filtering model in PR #5688. I'm working on a blog post about this but for now the Mutect2 docs at https://github.com/broadinstitute/gatk/blob/master/docs/mutect/mutect.pdf are up-to-date and more user-friendly than they used to be.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5845#issuecomment-478008792
https://github.com/broadinstitute/gatk/issues/5845#issuecomment-478011007:29,Availability,error,errors,29,"If you get any more of these errors, it's either an argument that never had any effect or something that you 4.1.1 got rid of. In the latter case, you don't need to replace it with anything. In 4.1.1 `FilterMutectCalls` automatically learns a lot of parameters.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5845#issuecomment-478011007
https://github.com/broadinstitute/gatk/issues/5845#issuecomment-478011007:234,Usability,learn,learns,234,"If you get any more of these errors, it's either an argument that never had any effect or something that you 4.1.1 got rid of. In the latter case, you don't need to replace it with anything. In 4.1.1 `FilterMutectCalls` automatically learns a lot of parameters.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5845#issuecomment-478011007
https://github.com/broadinstitute/gatk/issues/5848#issuecomment-480030577:23,Deployability,pipeline,pipeline-breaking,23,"PR #5840 created a few pipeline-breaking changes. Since the orientation bias annotation and filter are only standard in Mutect2 we weren't expecting it to cause problems for HaplotypeCaller users. And as far as Mutect2 is concerned the WDL is always in a working state and we hope users are running the pipeline that way. While changing the annotation name was not absolutely necessary we felt it was important because the OxoG artifact is only one example of an artifact with orientation bias. As of 2012 or so it was the best-known such artifact but the name is now misleading. We don't want users to think that we don't handle other artifacts when in fact the new orientation bias model handles every orientation bias artifact. By the way @tfenne, are you using this annotation in order to run the orientation bias filter?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5848#issuecomment-480030577
https://github.com/broadinstitute/gatk/issues/5848#issuecomment-480030577:303,Deployability,pipeline,pipeline,303,"PR #5840 created a few pipeline-breaking changes. Since the orientation bias annotation and filter are only standard in Mutect2 we weren't expecting it to cause problems for HaplotypeCaller users. And as far as Mutect2 is concerned the WDL is always in a working state and we hope users are running the pipeline that way. While changing the annotation name was not absolutely necessary we felt it was important because the OxoG artifact is only one example of an artifact with orientation bias. As of 2012 or so it was the best-known such artifact but the name is now misleading. We don't want users to think that we don't handle other artifacts when in fact the new orientation bias model handles every orientation bias artifact. By the way @tfenne, are you using this annotation in order to run the orientation bias filter?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5848#issuecomment-480030577
https://github.com/broadinstitute/gatk/issues/5848#issuecomment-480072316:63,Availability,avail,available,63,"Thanks @davidbenjamin - my thought here was that since it's an available annotation in HaplotypeCaller it would be nice to just add a line to the release notes in case anyone else had started emitting it. To answer your question, we have been emitting it in a clinical pipeline, but haven't actually been using it for downstream filtering yet.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5848#issuecomment-480072316
https://github.com/broadinstitute/gatk/issues/5848#issuecomment-480072316:318,Availability,down,downstream,318,"Thanks @davidbenjamin - my thought here was that since it's an available annotation in HaplotypeCaller it would be nice to just add a line to the release notes in case anyone else had started emitting it. To answer your question, we have been emitting it in a clinical pipeline, but haven't actually been using it for downstream filtering yet.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5848#issuecomment-480072316
https://github.com/broadinstitute/gatk/issues/5848#issuecomment-480072316:146,Deployability,release,release,146,"Thanks @davidbenjamin - my thought here was that since it's an available annotation in HaplotypeCaller it would be nice to just add a line to the release notes in case anyone else had started emitting it. To answer your question, we have been emitting it in a clinical pipeline, but haven't actually been using it for downstream filtering yet.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5848#issuecomment-480072316
https://github.com/broadinstitute/gatk/issues/5848#issuecomment-480072316:269,Deployability,pipeline,pipeline,269,"Thanks @davidbenjamin - my thought here was that since it's an available annotation in HaplotypeCaller it would be nice to just add a line to the release notes in case anyone else had started emitting it. To answer your question, we have been emitting it in a clinical pipeline, but haven't actually been using it for downstream filtering yet.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5848#issuecomment-480072316
https://github.com/broadinstitute/gatk/issues/5848#issuecomment-480964473:101,Deployability,release,release,101,"@droazen Can you add ""OxoGReadCounts annotation renamed to OrientationBiasReadCounts"" to the 4.1.1.0 release notes?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5848#issuecomment-480964473
https://github.com/broadinstitute/gatk/issues/5848#issuecomment-480970958:44,Deployability,release,release,44,"@davidbenjamin Sure, I've added that to the release notes",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5848#issuecomment-480970958
https://github.com/broadinstitute/gatk/pull/5849#issuecomment-478574401:125,Energy Efficiency,allocate,allocate,125,"A couple of thoughts after doing a little more reading on this. Depending on the source it would appear that each arena will allocate either 64MB or 128MB of virtual memory (i.e. address space). So it would probably also be fine to set this limit a bit higher. Secondly, while there's lots of discussion online that setting this doesn't negatively impact Java code running on the JVM, it is possible that native code invoked using JNI could see a modest reduction in performance _if_ a) it's highly multithreaded and b) it's doing lots of heap allocations. I don't know enough about the native pair-HMM and other native code, but it would be helpful if someone who knows more about that could weigh in.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5849#issuecomment-478574401
https://github.com/broadinstitute/gatk/pull/5849#issuecomment-478574401:64,Integrability,Depend,Depending,64,"A couple of thoughts after doing a little more reading on this. Depending on the source it would appear that each arena will allocate either 64MB or 128MB of virtual memory (i.e. address space). So it would probably also be fine to set this limit a bit higher. Secondly, while there's lots of discussion online that setting this doesn't negatively impact Java code running on the JVM, it is possible that native code invoked using JNI could see a modest reduction in performance _if_ a) it's highly multithreaded and b) it's doing lots of heap allocations. I don't know enough about the native pair-HMM and other native code, but it would be helpful if someone who knows more about that could weigh in.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5849#issuecomment-478574401
https://github.com/broadinstitute/gatk/pull/5849#issuecomment-478574401:467,Performance,perform,performance,467,"A couple of thoughts after doing a little more reading on this. Depending on the source it would appear that each arena will allocate either 64MB or 128MB of virtual memory (i.e. address space). So it would probably also be fine to set this limit a bit higher. Secondly, while there's lots of discussion online that setting this doesn't negatively impact Java code running on the JVM, it is possible that native code invoked using JNI could see a modest reduction in performance _if_ a) it's highly multithreaded and b) it's doing lots of heap allocations. I don't know enough about the native pair-HMM and other native code, but it would be helpful if someone who knows more about that could weigh in.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5849#issuecomment-478574401
https://github.com/broadinstitute/gatk/issues/5852#issuecomment-550352252:727,Availability,down,downstream,727,"@mwalker174 @asmirnov239 decided not to tackle this yet. There are a few options: 1) warn and/or filter out such contigs in PreprocessIntervals (not a fan of this), 2) filter in FilterIntervals, 3) warn/fail/filter a little earlier at DetermineGermlineContigPloidy (and also GermlineCNVCaller to be safe), 4) warn/filter at PostprocessGermlineCNVCalls, 5) fix the theano code to treat such contigs specially (haven't looked closely at it, but probably has something to do with patching the foward-backward code to handle such cases). Probably option 5 is the right answer, but only if the inferences for such single-interval contigs are at all meaningful. Otherwise I'm inclined to do option 2 and add some warnings/exceptions downstream. Might be other options as well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5852#issuecomment-550352252
https://github.com/broadinstitute/gatk/issues/5852#issuecomment-550352252:477,Deployability,patch,patching,477,"@mwalker174 @asmirnov239 decided not to tackle this yet. There are a few options: 1) warn and/or filter out such contigs in PreprocessIntervals (not a fan of this), 2) filter in FilterIntervals, 3) warn/fail/filter a little earlier at DetermineGermlineContigPloidy (and also GermlineCNVCaller to be safe), 4) warn/filter at PostprocessGermlineCNVCalls, 5) fix the theano code to treat such contigs specially (haven't looked closely at it, but probably has something to do with patching the foward-backward code to handle such cases). Probably option 5 is the right answer, but only if the inferences for such single-interval contigs are at all meaningful. Otherwise I'm inclined to do option 2 and add some warnings/exceptions downstream. Might be other options as well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5852#issuecomment-550352252
https://github.com/broadinstitute/gatk/issues/5852#issuecomment-550352252:299,Safety,safe,safe,299,"@mwalker174 @asmirnov239 decided not to tackle this yet. There are a few options: 1) warn and/or filter out such contigs in PreprocessIntervals (not a fan of this), 2) filter in FilterIntervals, 3) warn/fail/filter a little earlier at DetermineGermlineContigPloidy (and also GermlineCNVCaller to be safe), 4) warn/filter at PostprocessGermlineCNVCalls, 5) fix the theano code to treat such contigs specially (haven't looked closely at it, but probably has something to do with patching the foward-backward code to handle such cases). Probably option 5 is the right answer, but only if the inferences for such single-interval contigs are at all meaningful. Otherwise I'm inclined to do option 2 and add some warnings/exceptions downstream. Might be other options as well.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5852#issuecomment-550352252
https://github.com/broadinstitute/gatk/issues/5852#issuecomment-613371282:23,Availability,error,error,23,"I am also getting this error on chromosome 11:; ```; 11:49:44.992 INFO gcnvkernel.postprocess.viterbi_segmentation - Segmenting contig (5/12) (contig name: 9)...; 11:49:44.996 INFO gcnvkernel.postprocess.viterbi_segmentation - Segmenting contig (6/12) (contig name: 11)... Stderr: Traceback (most recent call last):; File ""/ngc/projects/gm/data/resources/envs/conda/ngs_gatk_cnv/4.1.6.0/lib/python3.6/site-packages/theano/compile/function_module.py"", line 903, in __call__; self.fn() if output_subset is None else\; File ""/ngc/projects/gm/data/resources/envs/conda/ngs_gatk_cnv/4.1.6.0/lib/python3.6/site-packages/theano/scan_module/scan_op.py"", line 963, in rval; r = p(n, [x[0] for x in i], o); File ""/ngc/projects/gm/data/resources/envs/conda/ngs_gatk_cnv/4.1.6.0/lib/python3.6/site-packages/theano/scan_module/scan_op.py"", line 952, in p; self, node); File ""scan_perform.pyx"", line 215, in theano.scan_module.scan_perform.perform; NotImplementedError: We didn't implemented yet the case where scan do 0 iteration. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/tmp/segment_gcnv_calls.6491270870870970325.py"", line 79, in <module>; viterbi_engine.write_copy_number_segments(); File ""/ngc/projects/gm/data/resources/envs/conda/ngs_gatk_cnv/4.1.6.0/lib/python3.6/site-packages/gcnvkernel/postprocess/viterbi_segmentation.py"", line 234, in write_copy_number_segments; for segment in self._viterbi_segments_generator():; File ""/ngc/projects/gm/data/resources/envs/conda/ngs_gatk_cnv/4.1.6.0/lib/python3.6/site-packages/gcnvkernel/postprocess/viterbi_segmentation.py"", line 160, in _viterbi_segments_generator; log_prior_c, log_trans_contig_tcc, copy_number_log_emission_contig_tc); File ""/ngc/projects/gm/data/resources/envs/conda/ngs_gatk_cnv/4.1.6.0/lib/python3.6/site-packages/gcnvkernel/models/theano_hmm.py"", line 88, in perform_forward_backward; prev_log_posterior_tc, admixing_rate, temperature))); File ""/ngc/projects/gm/data/res",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5852#issuecomment-613371282
https://github.com/broadinstitute/gatk/issues/5852#issuecomment-613371282:3256,Availability,error,error,3256,"ngs_gatk_cnv/4.1.6.0/lib/python3.6/site-packages/theano/gof/link.py"", line 325, in raise_with_op; reraise(exc_type, exc_value, exc_trace); File ""/ngc/projects/gm/data/resources/envs/conda/ngs_gatk_cnv/4.1.6.0/lib/python3.6/site-packages/six.py"", line 692, in reraise; raise value.with_traceback(tb); File ""/ngc/projects/gm/data/resources/envs/conda/ngs_gatk_cnv/4.1.6.0/lib/python3.6/site-packages/theano/compile/function_module.py"", line 903, in __call__; self.fn() if output_subset is None else\; File ""/ngc/projects/gm/data/resources/envs/conda/ngs_gatk_cnv/4.1.6.0/lib/python3.6/site-packages/theano/scan_module/scan_op.py"", line 963, in rval; r = p(n, [x[0] for x in i], o); File ""/ngc/projects/gm/data/resources/envs/conda/ngs_gatk_cnv/4.1.6.0/lib/python3.6/site-packages/theano/scan_module/scan_op.py"", line 952, in p; self, node); File ""scan_perform.pyx"", line 215, in theano.scan_module.scan_perform.perform; NotImplementedError: We didn't implemented yet the case where scan do 0 iteration; Apply node that caused the error: forall_inplace,cpu,scan_fn}(Elemwise{minimum,no_inplace}.0, InplaceDimShuffle{0,2,1}.0, Subtensor{int64:int64:int64}.0, IncSubtensor{InplaceSet;:int64:}.0, Shape_i{0}.0); Toposort index: 95; Inputs types: [TensorType(int64, scalar), TensorType(float64, 3D), TensorType(float64, matrix), TensorType(float64, matrix), TensorType(int64, scalar)]; Inputs shapes: [(), (0, 6, 6), (0, 6), (2, 6), ()]; Inputs strides: [(), (288, 8, 48), (48, 8), (48, 8), ()]; Inputs values: [array(0), array([], shape=(0, 6, 6), dtype=float64), array([], shape=(0, 6), dtype=float64), 'not shown', array(6)]; Inputs type_num: [7, 12, 12, 12, 7]; Outputs clients: [[Subtensor{int64:int64:int8}(forall_inplace,cpu,scan_fn}.0, ScalarFromTensor.0, ScalarFromTensor.0, Constant{1})]]. at org.broadinstitute.hellbender.utils.python.PythonExecutorBase.getScriptException(PythonExecutorBase.java:75); at org.broadinstitute.hellbender.utils.runtime.ScriptExecutor.executeCuratedArgs(ScriptExecutor",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5852#issuecomment-613371282
https://github.com/broadinstitute/gatk/issues/5852#issuecomment-613371282:926,Performance,perform,perform,926,"I am also getting this error on chromosome 11:; ```; 11:49:44.992 INFO gcnvkernel.postprocess.viterbi_segmentation - Segmenting contig (5/12) (contig name: 9)...; 11:49:44.996 INFO gcnvkernel.postprocess.viterbi_segmentation - Segmenting contig (6/12) (contig name: 11)... Stderr: Traceback (most recent call last):; File ""/ngc/projects/gm/data/resources/envs/conda/ngs_gatk_cnv/4.1.6.0/lib/python3.6/site-packages/theano/compile/function_module.py"", line 903, in __call__; self.fn() if output_subset is None else\; File ""/ngc/projects/gm/data/resources/envs/conda/ngs_gatk_cnv/4.1.6.0/lib/python3.6/site-packages/theano/scan_module/scan_op.py"", line 963, in rval; r = p(n, [x[0] for x in i], o); File ""/ngc/projects/gm/data/resources/envs/conda/ngs_gatk_cnv/4.1.6.0/lib/python3.6/site-packages/theano/scan_module/scan_op.py"", line 952, in p; self, node); File ""scan_perform.pyx"", line 215, in theano.scan_module.scan_perform.perform; NotImplementedError: We didn't implemented yet the case where scan do 0 iteration. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/tmp/segment_gcnv_calls.6491270870870970325.py"", line 79, in <module>; viterbi_engine.write_copy_number_segments(); File ""/ngc/projects/gm/data/resources/envs/conda/ngs_gatk_cnv/4.1.6.0/lib/python3.6/site-packages/gcnvkernel/postprocess/viterbi_segmentation.py"", line 234, in write_copy_number_segments; for segment in self._viterbi_segments_generator():; File ""/ngc/projects/gm/data/resources/envs/conda/ngs_gatk_cnv/4.1.6.0/lib/python3.6/site-packages/gcnvkernel/postprocess/viterbi_segmentation.py"", line 160, in _viterbi_segments_generator; log_prior_c, log_trans_contig_tcc, copy_number_log_emission_contig_tc); File ""/ngc/projects/gm/data/resources/envs/conda/ngs_gatk_cnv/4.1.6.0/lib/python3.6/site-packages/gcnvkernel/models/theano_hmm.py"", line 88, in perform_forward_backward; prev_log_posterior_tc, admixing_rate, temperature))); File ""/ngc/projects/gm/data/res",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5852#issuecomment-613371282
https://github.com/broadinstitute/gatk/issues/5852#issuecomment-613371282:3137,Performance,perform,perform,3137,"ngs_gatk_cnv/4.1.6.0/lib/python3.6/site-packages/theano/gof/link.py"", line 325, in raise_with_op; reraise(exc_type, exc_value, exc_trace); File ""/ngc/projects/gm/data/resources/envs/conda/ngs_gatk_cnv/4.1.6.0/lib/python3.6/site-packages/six.py"", line 692, in reraise; raise value.with_traceback(tb); File ""/ngc/projects/gm/data/resources/envs/conda/ngs_gatk_cnv/4.1.6.0/lib/python3.6/site-packages/theano/compile/function_module.py"", line 903, in __call__; self.fn() if output_subset is None else\; File ""/ngc/projects/gm/data/resources/envs/conda/ngs_gatk_cnv/4.1.6.0/lib/python3.6/site-packages/theano/scan_module/scan_op.py"", line 963, in rval; r = p(n, [x[0] for x in i], o); File ""/ngc/projects/gm/data/resources/envs/conda/ngs_gatk_cnv/4.1.6.0/lib/python3.6/site-packages/theano/scan_module/scan_op.py"", line 952, in p; self, node); File ""scan_perform.pyx"", line 215, in theano.scan_module.scan_perform.perform; NotImplementedError: We didn't implemented yet the case where scan do 0 iteration; Apply node that caused the error: forall_inplace,cpu,scan_fn}(Elemwise{minimum,no_inplace}.0, InplaceDimShuffle{0,2,1}.0, Subtensor{int64:int64:int64}.0, IncSubtensor{InplaceSet;:int64:}.0, Shape_i{0}.0); Toposort index: 95; Inputs types: [TensorType(int64, scalar), TensorType(float64, 3D), TensorType(float64, matrix), TensorType(float64, matrix), TensorType(int64, scalar)]; Inputs shapes: [(), (0, 6, 6), (0, 6), (2, 6), ()]; Inputs strides: [(), (288, 8, 48), (48, 8), (48, 8), ()]; Inputs values: [array(0), array([], shape=(0, 6, 6), dtype=float64), array([], shape=(0, 6), dtype=float64), 'not shown', array(6)]; Inputs type_num: [7, 12, 12, 12, 7]; Outputs clients: [[Subtensor{int64:int64:int8}(forall_inplace,cpu,scan_fn}.0, ScalarFromTensor.0, ScalarFromTensor.0, Constant{1})]]. at org.broadinstitute.hellbender.utils.python.PythonExecutorBase.getScriptException(PythonExecutorBase.java:75); at org.broadinstitute.hellbender.utils.runtime.ScriptExecutor.executeCuratedArgs(ScriptExecutor",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5852#issuecomment-613371282
https://github.com/broadinstitute/gatk/issues/5854#issuecomment-479397018:4,Availability,error,error,4,"The error message indicates that the recalibration tables have different dimensions, but unfortunately it doesn't say which table it was. Looking at the source for `RecalibrationTables` it looks like it's probably `readGroupTable`, since it is the only 2D table I can see in `allTables`. So the question becomes, why is the number of read groups different for different tables created by `BaseRecalibratorSparkFn`? They all have the same header, so the number of read groups should be the same. One thing to try to see if it affects the result is to set a different partition size with `--bam-partition-size`. It defaults to the HDFS block size, which is 128MB, but you could try another value (e.g. `67108864`, which is 64MB) to see if you get the same error. Otherwise to make more progress I would need to debug locally. Are the files sharable @akkellogg?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5854#issuecomment-479397018
https://github.com/broadinstitute/gatk/issues/5854#issuecomment-479397018:754,Availability,error,error,754,"The error message indicates that the recalibration tables have different dimensions, but unfortunately it doesn't say which table it was. Looking at the source for `RecalibrationTables` it looks like it's probably `readGroupTable`, since it is the only 2D table I can see in `allTables`. So the question becomes, why is the number of read groups different for different tables created by `BaseRecalibratorSparkFn`? They all have the same header, so the number of read groups should be the same. One thing to try to see if it affects the result is to set a different partition size with `--bam-partition-size`. It defaults to the HDFS block size, which is 128MB, but you could try another value (e.g. `67108864`, which is 64MB) to see if you get the same error. Otherwise to make more progress I would need to debug locally. Are the files sharable @akkellogg?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5854#issuecomment-479397018
https://github.com/broadinstitute/gatk/issues/5854#issuecomment-479397018:10,Integrability,message,message,10,"The error message indicates that the recalibration tables have different dimensions, but unfortunately it doesn't say which table it was. Looking at the source for `RecalibrationTables` it looks like it's probably `readGroupTable`, since it is the only 2D table I can see in `allTables`. So the question becomes, why is the number of read groups different for different tables created by `BaseRecalibratorSparkFn`? They all have the same header, so the number of read groups should be the same. One thing to try to see if it affects the result is to set a different partition size with `--bam-partition-size`. It defaults to the HDFS block size, which is 128MB, but you could try another value (e.g. `67108864`, which is 64MB) to see if you get the same error. Otherwise to make more progress I would need to debug locally. Are the files sharable @akkellogg?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5854#issuecomment-479397018
https://github.com/broadinstitute/gatk/issues/5854#issuecomment-496577052:69,Availability,error,error,69,"I just had a similar issue and debugged it using the info above. The error seems to occur when the number of ""ID"" tags and ""PU"" tags are not the same. In my case, the error was ""4,3 not equal to 12,3"" because of a malformed ""PU"" tag where there were only 4 unique ""PU"" tags but 12 unique ""ID"" tags. Presumably, the above error by akkellogg was due to 1 unique ""PU"" tag but 88 unique ""ID"" tags. I'm not sure if this is just my user error, or an actual issue with the software requiring both of those tags to uniquely match, but hopefully this will help anyone else with the issue to fix it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5854#issuecomment-496577052
https://github.com/broadinstitute/gatk/issues/5854#issuecomment-496577052:167,Availability,error,error,167,"I just had a similar issue and debugged it using the info above. The error seems to occur when the number of ""ID"" tags and ""PU"" tags are not the same. In my case, the error was ""4,3 not equal to 12,3"" because of a malformed ""PU"" tag where there were only 4 unique ""PU"" tags but 12 unique ""ID"" tags. Presumably, the above error by akkellogg was due to 1 unique ""PU"" tag but 88 unique ""ID"" tags. I'm not sure if this is just my user error, or an actual issue with the software requiring both of those tags to uniquely match, but hopefully this will help anyone else with the issue to fix it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5854#issuecomment-496577052
https://github.com/broadinstitute/gatk/issues/5854#issuecomment-496577052:321,Availability,error,error,321,"I just had a similar issue and debugged it using the info above. The error seems to occur when the number of ""ID"" tags and ""PU"" tags are not the same. In my case, the error was ""4,3 not equal to 12,3"" because of a malformed ""PU"" tag where there were only 4 unique ""PU"" tags but 12 unique ""ID"" tags. Presumably, the above error by akkellogg was due to 1 unique ""PU"" tag but 88 unique ""ID"" tags. I'm not sure if this is just my user error, or an actual issue with the software requiring both of those tags to uniquely match, but hopefully this will help anyone else with the issue to fix it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5854#issuecomment-496577052
https://github.com/broadinstitute/gatk/issues/5854#issuecomment-496577052:431,Availability,error,error,431,"I just had a similar issue and debugged it using the info above. The error seems to occur when the number of ""ID"" tags and ""PU"" tags are not the same. In my case, the error was ""4,3 not equal to 12,3"" because of a malformed ""PU"" tag where there were only 4 unique ""PU"" tags but 12 unique ""ID"" tags. Presumably, the above error by akkellogg was due to 1 unique ""PU"" tag but 88 unique ""ID"" tags. I'm not sure if this is just my user error, or an actual issue with the software requiring both of those tags to uniquely match, but hopefully this will help anyone else with the issue to fix it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5854#issuecomment-496577052
https://github.com/broadinstitute/gatk/issues/5854#issuecomment-808817724:578,Availability,ERROR,ERROR,578,"I am having a similar issue with GATK `4.1.4.1` that persists after updating to `4.2.0.0`:; ```; 00:33:06.768 INFO BaseRecalibrationEngine - The covariates being used here:; 00:33:06.768 INFO BaseRecalibrationEngine - ReadGroupCovariate; 00:33:06.768 INFO BaseRecalibrationEngine - QualityScoreCovariate; 00:33:06.768 INFO BaseRecalibrationEngine - ContextCovariate; 00:33:06.768 INFO BaseRecalibrationEngine - CycleCovariate; 21/03/28 00:33:07 INFO BlockManagerInfo: Removed broadcast_0_piece0 on fend04.cluster:42128 in memory (size: 35.5 KB, free: 5.2 GB); 21/03/28 00:33:14 ERROR Executor: Exception in task 1.0 in stage 0.0 (TID 1); java.lang.IllegalArgumentException: Table1 1,3 not equal to 2,3; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:798); at org.broadinstitute.hellbender.utils.recalibration.RecalUtils.combineTables(RecalUtils.java:560); at org.broadinstitute.hellbender.utils.recalibration.RecalibrationTables.combine(RecalibrationTables.java:144); at org.broadinstitute.hellbender.utils.recalibration.RecalibrationTables.inPlaceCombine(RecalibrationTables.java:178); at org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(JavaPairRDD.scala:1037); at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157); at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157); at scala.collection.Iterator$class.foreach(Iterator.scala:891); at scala.collection.AbstractIterator.foreach(Iterator.scala:1334); at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157); at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1334); at scala.collection.TraversableOnce$class.aggregate(TraversableOnce.scala:214); at scala.collection.AbstractIterator.aggregate(Iterator.scala:1334); at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(RDD.scala:1190); at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(RDD.scala:1190); at org.apa",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5854#issuecomment-808817724
https://github.com/broadinstitute/gatk/issues/5854#issuecomment-808817724:2571,Energy Efficiency,schedul,scheduler,2571,park.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(JavaPairRDD.scala:1037); at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157); at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157); at scala.collection.Iterator$class.foreach(Iterator.scala:891); at scala.collection.AbstractIterator.foreach(Iterator.scala:1334); at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157); at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1334); at scala.collection.TraversableOnce$class.aggregate(TraversableOnce.scala:214); at scala.collection.AbstractIterator.aggregate(Iterator.scala:1334); at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(RDD.scala:1190); at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(RDD.scala:1190); at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$27.apply(RDD.scala:1191); at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$27.apply(RDD.scala:1191); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346); at org.apache.spark.rdd.RDD.iterator(RDD.scala:310); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); at org.apache.spark.scheduler.Task.run(Task.scala:123); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5854#issuecomment-808817724
https://github.com/broadinstitute/gatk/issues/5854#issuecomment-808817724:2642,Energy Efficiency,schedul,scheduler,2642,park.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(JavaPairRDD.scala:1037); at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157); at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157); at scala.collection.Iterator$class.foreach(Iterator.scala:891); at scala.collection.AbstractIterator.foreach(Iterator.scala:1334); at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157); at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1334); at scala.collection.TraversableOnce$class.aggregate(TraversableOnce.scala:214); at scala.collection.AbstractIterator.aggregate(Iterator.scala:1334); at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(RDD.scala:1190); at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(RDD.scala:1190); at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$27.apply(RDD.scala:1191); at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$27.apply(RDD.scala:1191); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346); at org.apache.spark.rdd.RDD.iterator(RDD.scala:310); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); at org.apache.spark.scheduler.Task.run(Task.scala:123); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5854#issuecomment-808817724
https://github.com/broadinstitute/gatk/issues/5854#issuecomment-808817724:2923,Performance,concurren,concurrent,2923,park.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(JavaPairRDD.scala:1037); at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157); at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157); at scala.collection.Iterator$class.foreach(Iterator.scala:891); at scala.collection.AbstractIterator.foreach(Iterator.scala:1334); at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157); at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1334); at scala.collection.TraversableOnce$class.aggregate(TraversableOnce.scala:214); at scala.collection.AbstractIterator.aggregate(Iterator.scala:1334); at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(RDD.scala:1190); at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(RDD.scala:1190); at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$27.apply(RDD.scala:1191); at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$27.apply(RDD.scala:1191); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346); at org.apache.spark.rdd.RDD.iterator(RDD.scala:310); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); at org.apache.spark.scheduler.Task.run(Task.scala:123); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5854#issuecomment-808817724
https://github.com/broadinstitute/gatk/issues/5854#issuecomment-808817724:3007,Performance,concurren,concurrent,3007,park.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(JavaPairRDD.scala:1037); at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157); at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157); at scala.collection.Iterator$class.foreach(Iterator.scala:891); at scala.collection.AbstractIterator.foreach(Iterator.scala:1334); at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157); at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1334); at scala.collection.TraversableOnce$class.aggregate(TraversableOnce.scala:214); at scala.collection.AbstractIterator.aggregate(Iterator.scala:1334); at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(RDD.scala:1190); at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(RDD.scala:1190); at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$27.apply(RDD.scala:1191); at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$27.apply(RDD.scala:1191); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823); at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346); at org.apache.spark.rdd.RDD.iterator(RDD.scala:310); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); at org.apache.spark.scheduler.Task.run(Task.scala:123); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); ```,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5854#issuecomment-808817724
https://github.com/broadinstitute/gatk/issues/5854#issuecomment-808817724:748,Security,validat,validateArg,748,"I am having a similar issue with GATK `4.1.4.1` that persists after updating to `4.2.0.0`:; ```; 00:33:06.768 INFO BaseRecalibrationEngine - The covariates being used here:; 00:33:06.768 INFO BaseRecalibrationEngine - ReadGroupCovariate; 00:33:06.768 INFO BaseRecalibrationEngine - QualityScoreCovariate; 00:33:06.768 INFO BaseRecalibrationEngine - ContextCovariate; 00:33:06.768 INFO BaseRecalibrationEngine - CycleCovariate; 21/03/28 00:33:07 INFO BlockManagerInfo: Removed broadcast_0_piece0 on fend04.cluster:42128 in memory (size: 35.5 KB, free: 5.2 GB); 21/03/28 00:33:14 ERROR Executor: Exception in task 1.0 in stage 0.0 (TID 1); java.lang.IllegalArgumentException: Table1 1,3 not equal to 2,3; at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:798); at org.broadinstitute.hellbender.utils.recalibration.RecalUtils.combineTables(RecalUtils.java:560); at org.broadinstitute.hellbender.utils.recalibration.RecalibrationTables.combine(RecalibrationTables.java:144); at org.broadinstitute.hellbender.utils.recalibration.RecalibrationTables.inPlaceCombine(RecalibrationTables.java:178); at org.apache.spark.api.java.JavaPairRDD$$anonfun$toScalaFunction2$1.apply(JavaPairRDD.scala:1037); at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157); at scala.collection.TraversableOnce$$anonfun$foldLeft$1.apply(TraversableOnce.scala:157); at scala.collection.Iterator$class.foreach(Iterator.scala:891); at scala.collection.AbstractIterator.foreach(Iterator.scala:1334); at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157); at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1334); at scala.collection.TraversableOnce$class.aggregate(TraversableOnce.scala:214); at scala.collection.AbstractIterator.aggregate(Iterator.scala:1334); at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(RDD.scala:1190); at org.apache.spark.rdd.RDD$$anonfun$treeAggregate$1$$anonfun$26.apply(RDD.scala:1190); at org.apa",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5854#issuecomment-808817724
https://github.com/broadinstitute/gatk/issues/5857#issuecomment-479916767:862,Energy Efficiency,Adapt,AdaptiveChainPruner,862,"Your solution doesn't address your third listed drawback to the current; approach, though I'm not sure there's any way to do that that wouldn't; require a pretty dramatic change. It's not obvious to me why we wanted the given alleles in the graph; originally. Maybe the use case was variants from UG that we didn't; necessarily believe were aligned properly?. I don't have any objections, but I'd feel better if we had a better guess; at what the original method was trying to do. On Wed, Apr 3, 2019 at 9:56 PM David Benjamin <notifications@github.com>; wrote:. > In Mutect2 and HaplotypeCaller, we force-call alleles by injecting them; > into the ref haplotype, then threading these constructed haplotypes into; > the assembly graph with a large edge weight. There are several drawbacks to; > this approach:; >; > - The strange edge weights interfere with the AdaptiveChainPruner.; > - The large edge weights may not be large enough to avoid pruning when; > depth is extremely high.; > - The alleles may be lost if assembly fails.; > - If the alleles actually exist but are in phase with another variant; > we end up putting an enormous amount of weight on a false haplotype.; >; > We can get around these issue with the following method:; >; > - assemble haplotypes without regard to the force-called alleles.; > - if an allele is present in these haplotypes, do nothing further.; > - otherwise, add a haplotype in which the allele is injected into the; > reference haplotype.; >; > @LeeTL1220 <https://github.com/LeeTL1220> I prototyped this and it seems; > to resolve the missed forced alleles that Ziao found.; >; > @ldgauthier <https://github.com/ldgauthier> Can you think of any; > objections to making this change in HaplotypeCaller?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/5857>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdMcaTJg47gn",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5857#issuecomment-479916767
https://github.com/broadinstitute/gatk/issues/5857#issuecomment-479916767:622,Integrability,inject,injecting,622,"Your solution doesn't address your third listed drawback to the current; approach, though I'm not sure there's any way to do that that wouldn't; require a pretty dramatic change. It's not obvious to me why we wanted the given alleles in the graph; originally. Maybe the use case was variants from UG that we didn't; necessarily believe were aligned properly?. I don't have any objections, but I'd feel better if we had a better guess; at what the original method was trying to do. On Wed, Apr 3, 2019 at 9:56 PM David Benjamin <notifications@github.com>; wrote:. > In Mutect2 and HaplotypeCaller, we force-call alleles by injecting them; > into the ref haplotype, then threading these constructed haplotypes into; > the assembly graph with a large edge weight. There are several drawbacks to; > this approach:; >; > - The strange edge weights interfere with the AdaptiveChainPruner.; > - The large edge weights may not be large enough to avoid pruning when; > depth is extremely high.; > - The alleles may be lost if assembly fails.; > - If the alleles actually exist but are in phase with another variant; > we end up putting an enormous amount of weight on a false haplotype.; >; > We can get around these issue with the following method:; >; > - assemble haplotypes without regard to the force-called alleles.; > - if an allele is present in these haplotypes, do nothing further.; > - otherwise, add a haplotype in which the allele is injected into the; > reference haplotype.; >; > @LeeTL1220 <https://github.com/LeeTL1220> I prototyped this and it seems; > to resolve the missed forced alleles that Ziao found.; >; > @ldgauthier <https://github.com/ldgauthier> Can you think of any; > objections to making this change in HaplotypeCaller?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/5857>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdMcaTJg47gn",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5857#issuecomment-479916767
https://github.com/broadinstitute/gatk/issues/5857#issuecomment-479916767:1438,Integrability,inject,injected,1438,"raph; originally. Maybe the use case was variants from UG that we didn't; necessarily believe were aligned properly?. I don't have any objections, but I'd feel better if we had a better guess; at what the original method was trying to do. On Wed, Apr 3, 2019 at 9:56 PM David Benjamin <notifications@github.com>; wrote:. > In Mutect2 and HaplotypeCaller, we force-call alleles by injecting them; > into the ref haplotype, then threading these constructed haplotypes into; > the assembly graph with a large edge weight. There are several drawbacks to; > this approach:; >; > - The strange edge weights interfere with the AdaptiveChainPruner.; > - The large edge weights may not be large enough to avoid pruning when; > depth is extremely high.; > - The alleles may be lost if assembly fails.; > - If the alleles actually exist but are in phase with another variant; > we end up putting an enormous amount of weight on a false haplotype.; >; > We can get around these issue with the following method:; >; > - assemble haplotypes without regard to the force-called alleles.; > - if an allele is present in these haplotypes, do nothing further.; > - otherwise, add a haplotype in which the allele is injected into the; > reference haplotype.; >; > @LeeTL1220 <https://github.com/LeeTL1220> I prototyped this and it seems; > to resolve the missed forced alleles that Ziao found.; >; > @ldgauthier <https://github.com/ldgauthier> Can you think of any; > objections to making this change in HaplotypeCaller?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/5857>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdMcaTJg47gnOkE-d_AeAqXpO8zpxks5vdVvfgaJpZM4cbxVV>; > .; >. -- ; Laura Doyle Gauthier, Ph.D.; Associate Director, Germline Methods; Data Sciences Platform; gauthier@broadinstitute.org; Broad Institute of MIT & Harvard; 320 Charles St.; Cambridge MA 0214",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5857#issuecomment-479916767
https://github.com/broadinstitute/gatk/issues/5857#issuecomment-479916767:862,Modifiability,Adapt,AdaptiveChainPruner,862,"Your solution doesn't address your third listed drawback to the current; approach, though I'm not sure there's any way to do that that wouldn't; require a pretty dramatic change. It's not obvious to me why we wanted the given alleles in the graph; originally. Maybe the use case was variants from UG that we didn't; necessarily believe were aligned properly?. I don't have any objections, but I'd feel better if we had a better guess; at what the original method was trying to do. On Wed, Apr 3, 2019 at 9:56 PM David Benjamin <notifications@github.com>; wrote:. > In Mutect2 and HaplotypeCaller, we force-call alleles by injecting them; > into the ref haplotype, then threading these constructed haplotypes into; > the assembly graph with a large edge weight. There are several drawbacks to; > this approach:; >; > - The strange edge weights interfere with the AdaptiveChainPruner.; > - The large edge weights may not be large enough to avoid pruning when; > depth is extremely high.; > - The alleles may be lost if assembly fails.; > - If the alleles actually exist but are in phase with another variant; > we end up putting an enormous amount of weight on a false haplotype.; >; > We can get around these issue with the following method:; >; > - assemble haplotypes without regard to the force-called alleles.; > - if an allele is present in these haplotypes, do nothing further.; > - otherwise, add a haplotype in which the allele is injected into the; > reference haplotype.; >; > @LeeTL1220 <https://github.com/LeeTL1220> I prototyped this and it seems; > to resolve the missed forced alleles that Ziao found.; >; > @ldgauthier <https://github.com/ldgauthier> Can you think of any; > objections to making this change in HaplotypeCaller?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/5857>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdMcaTJg47gn",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5857#issuecomment-479916767
https://github.com/broadinstitute/gatk/issues/5857#issuecomment-479916767:938,Safety,avoid,avoid,938,"Your solution doesn't address your third listed drawback to the current; approach, though I'm not sure there's any way to do that that wouldn't; require a pretty dramatic change. It's not obvious to me why we wanted the given alleles in the graph; originally. Maybe the use case was variants from UG that we didn't; necessarily believe were aligned properly?. I don't have any objections, but I'd feel better if we had a better guess; at what the original method was trying to do. On Wed, Apr 3, 2019 at 9:56 PM David Benjamin <notifications@github.com>; wrote:. > In Mutect2 and HaplotypeCaller, we force-call alleles by injecting them; > into the ref haplotype, then threading these constructed haplotypes into; > the assembly graph with a large edge weight. There are several drawbacks to; > this approach:; >; > - The strange edge weights interfere with the AdaptiveChainPruner.; > - The large edge weights may not be large enough to avoid pruning when; > depth is extremely high.; > - The alleles may be lost if assembly fails.; > - If the alleles actually exist but are in phase with another variant; > we end up putting an enormous amount of weight on a false haplotype.; >; > We can get around these issue with the following method:; >; > - assemble haplotypes without regard to the force-called alleles.; > - if an allele is present in these haplotypes, do nothing further.; > - otherwise, add a haplotype in which the allele is injected into the; > reference haplotype.; >; > @LeeTL1220 <https://github.com/LeeTL1220> I prototyped this and it seems; > to resolve the missed forced alleles that Ziao found.; >; > @ldgauthier <https://github.com/ldgauthier> Can you think of any; > objections to making this change in HaplotypeCaller?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/5857>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdMcaTJg47gn",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5857#issuecomment-479916767
https://github.com/broadinstitute/gatk/issues/5857#issuecomment-479916767:622,Security,inject,injecting,622,"Your solution doesn't address your third listed drawback to the current; approach, though I'm not sure there's any way to do that that wouldn't; require a pretty dramatic change. It's not obvious to me why we wanted the given alleles in the graph; originally. Maybe the use case was variants from UG that we didn't; necessarily believe were aligned properly?. I don't have any objections, but I'd feel better if we had a better guess; at what the original method was trying to do. On Wed, Apr 3, 2019 at 9:56 PM David Benjamin <notifications@github.com>; wrote:. > In Mutect2 and HaplotypeCaller, we force-call alleles by injecting them; > into the ref haplotype, then threading these constructed haplotypes into; > the assembly graph with a large edge weight. There are several drawbacks to; > this approach:; >; > - The strange edge weights interfere with the AdaptiveChainPruner.; > - The large edge weights may not be large enough to avoid pruning when; > depth is extremely high.; > - The alleles may be lost if assembly fails.; > - If the alleles actually exist but are in phase with another variant; > we end up putting an enormous amount of weight on a false haplotype.; >; > We can get around these issue with the following method:; >; > - assemble haplotypes without regard to the force-called alleles.; > - if an allele is present in these haplotypes, do nothing further.; > - otherwise, add a haplotype in which the allele is injected into the; > reference haplotype.; >; > @LeeTL1220 <https://github.com/LeeTL1220> I prototyped this and it seems; > to resolve the missed forced alleles that Ziao found.; >; > @ldgauthier <https://github.com/ldgauthier> Can you think of any; > objections to making this change in HaplotypeCaller?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/5857>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdMcaTJg47gn",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5857#issuecomment-479916767
https://github.com/broadinstitute/gatk/issues/5857#issuecomment-479916767:1438,Security,inject,injected,1438,"raph; originally. Maybe the use case was variants from UG that we didn't; necessarily believe were aligned properly?. I don't have any objections, but I'd feel better if we had a better guess; at what the original method was trying to do. On Wed, Apr 3, 2019 at 9:56 PM David Benjamin <notifications@github.com>; wrote:. > In Mutect2 and HaplotypeCaller, we force-call alleles by injecting them; > into the ref haplotype, then threading these constructed haplotypes into; > the assembly graph with a large edge weight. There are several drawbacks to; > this approach:; >; > - The strange edge weights interfere with the AdaptiveChainPruner.; > - The large edge weights may not be large enough to avoid pruning when; > depth is extremely high.; > - The alleles may be lost if assembly fails.; > - If the alleles actually exist but are in phase with another variant; > we end up putting an enormous amount of weight on a false haplotype.; >; > We can get around these issue with the following method:; >; > - assemble haplotypes without regard to the force-called alleles.; > - if an allele is present in these haplotypes, do nothing further.; > - otherwise, add a haplotype in which the allele is injected into the; > reference haplotype.; >; > @LeeTL1220 <https://github.com/LeeTL1220> I prototyped this and it seems; > to resolve the missed forced alleles that Ziao found.; >; > @ldgauthier <https://github.com/ldgauthier> Can you think of any; > objections to making this change in HaplotypeCaller?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/5857>, or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdMcaTJg47gnOkE-d_AeAqXpO8zpxks5vdVvfgaJpZM4cbxVV>; > .; >. -- ; Laura Doyle Gauthier, Ph.D.; Associate Director, Germline Methods; Data Sciences Platform; gauthier@broadinstitute.org; Broad Institute of MIT & Harvard; 320 Charles St.; Cambridge MA 0214",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5857#issuecomment-479916767
https://github.com/broadinstitute/gatk/issues/5857#issuecomment-479931906:1181,Deployability,integrat,integration,1181,"> Your solution doesn't address your third listed drawback to the current; approach. Ah, but I believe it does if you're careful. We have this code:; ```; for ( final AssemblyResult result : assemble(correctedReads, refHaplotype, givenHaplotypes, header, aligner) ) {; if ( result.getStatus() == AssemblyResult.Status.ASSEMBLED_SOME_VARIATION ) {; // do some QC on the graph; sanityCheckGraph(result.getGraph(), refHaplotype);; // add it to graphs with meaningful non-reference features; assemblyResultByGraph.put(result.getGraph(),result);; nonRefGraphs.add(result.getGraph());; }; }. findBestPaths(nonRefGraphs, refHaplotype, refLoc, activeRegionExtendedLocation, assemblyResultByGraph, resultSet, aligner);; ```; If assembly fails eg due to cycles at every kmer then there's nothing to iterate over in the `for` loop but it still reaches `findBestPaths` (this puts assembled haplotypes into `resultSet` as a side effect, and it forces the reference haplotype in by fiat if there are no graphs). As long as the new GGA haplotypes are added after `findBestPaths` and not anywhere inside the `assemble` method or in that `for` loop it should be okay. Would you like me to write an integration test for this case?. > It's not obvious to me why we wanted the given alleles in the graph; originally. . . Regardless of the reason, I think the new proposal captures any benefit of putting them in the graph, because if they *are* in the graph it leaves them alone. If they're not in the graph, then we get a haplotype that's as close to the reference as possible, which is what the current code does. In such a case there's nothing gained by putting it in the graph. > I'd feel better if we had a better guess at what the original method was trying to do. Despite my optimism about theoretically beautiful things, me too. Who wrote the original GGA code?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5857#issuecomment-479931906
https://github.com/broadinstitute/gatk/issues/5857#issuecomment-479931906:1181,Integrability,integrat,integration,1181,"> Your solution doesn't address your third listed drawback to the current; approach. Ah, but I believe it does if you're careful. We have this code:; ```; for ( final AssemblyResult result : assemble(correctedReads, refHaplotype, givenHaplotypes, header, aligner) ) {; if ( result.getStatus() == AssemblyResult.Status.ASSEMBLED_SOME_VARIATION ) {; // do some QC on the graph; sanityCheckGraph(result.getGraph(), refHaplotype);; // add it to graphs with meaningful non-reference features; assemblyResultByGraph.put(result.getGraph(),result);; nonRefGraphs.add(result.getGraph());; }; }. findBestPaths(nonRefGraphs, refHaplotype, refLoc, activeRegionExtendedLocation, assemblyResultByGraph, resultSet, aligner);; ```; If assembly fails eg due to cycles at every kmer then there's nothing to iterate over in the `for` loop but it still reaches `findBestPaths` (this puts assembled haplotypes into `resultSet` as a side effect, and it forces the reference haplotype in by fiat if there are no graphs). As long as the new GGA haplotypes are added after `findBestPaths` and not anywhere inside the `assemble` method or in that `for` loop it should be okay. Would you like me to write an integration test for this case?. > It's not obvious to me why we wanted the given alleles in the graph; originally. . . Regardless of the reason, I think the new proposal captures any benefit of putting them in the graph, because if they *are* in the graph it leaves them alone. If they're not in the graph, then we get a haplotype that's as close to the reference as possible, which is what the current code does. In such a case there's nothing gained by putting it in the graph. > I'd feel better if we had a better guess at what the original method was trying to do. Despite my optimism about theoretically beautiful things, me too. Who wrote the original GGA code?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5857#issuecomment-479931906
https://github.com/broadinstitute/gatk/issues/5857#issuecomment-479931906:1193,Testability,test,test,1193,"> Your solution doesn't address your third listed drawback to the current; approach. Ah, but I believe it does if you're careful. We have this code:; ```; for ( final AssemblyResult result : assemble(correctedReads, refHaplotype, givenHaplotypes, header, aligner) ) {; if ( result.getStatus() == AssemblyResult.Status.ASSEMBLED_SOME_VARIATION ) {; // do some QC on the graph; sanityCheckGraph(result.getGraph(), refHaplotype);; // add it to graphs with meaningful non-reference features; assemblyResultByGraph.put(result.getGraph(),result);; nonRefGraphs.add(result.getGraph());; }; }. findBestPaths(nonRefGraphs, refHaplotype, refLoc, activeRegionExtendedLocation, assemblyResultByGraph, resultSet, aligner);; ```; If assembly fails eg due to cycles at every kmer then there's nothing to iterate over in the `for` loop but it still reaches `findBestPaths` (this puts assembled haplotypes into `resultSet` as a side effect, and it forces the reference haplotype in by fiat if there are no graphs). As long as the new GGA haplotypes are added after `findBestPaths` and not anywhere inside the `assemble` method or in that `for` loop it should be okay. Would you like me to write an integration test for this case?. > It's not obvious to me why we wanted the given alleles in the graph; originally. . . Regardless of the reason, I think the new proposal captures any benefit of putting them in the graph, because if they *are* in the graph it leaves them alone. If they're not in the graph, then we get a haplotype that's as close to the reference as possible, which is what the current code does. In such a case there's nothing gained by putting it in the graph. > I'd feel better if we had a better guess at what the original method was trying to do. Despite my optimism about theoretically beautiful things, me too. Who wrote the original GGA code?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5857#issuecomment-479931906
https://github.com/broadinstitute/gatk/issues/5857#issuecomment-480008571:0,Deployability,Update,Update,0,"Update: I wrote an integration test in my branch that runs M2 with ; `--kmer-size 1 --dont-increase-kmer-sizes-for-cycles`. It still calls the given alleles, whereas in master it does not.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5857#issuecomment-480008571
https://github.com/broadinstitute/gatk/issues/5857#issuecomment-480008571:19,Deployability,integrat,integration,19,"Update: I wrote an integration test in my branch that runs M2 with ; `--kmer-size 1 --dont-increase-kmer-sizes-for-cycles`. It still calls the given alleles, whereas in master it does not.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5857#issuecomment-480008571
https://github.com/broadinstitute/gatk/issues/5857#issuecomment-480008571:19,Integrability,integrat,integration,19,"Update: I wrote an integration test in my branch that runs M2 with ; `--kmer-size 1 --dont-increase-kmer-sizes-for-cycles`. It still calls the given alleles, whereas in master it does not.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5857#issuecomment-480008571
https://github.com/broadinstitute/gatk/issues/5857#issuecomment-480008571:31,Testability,test,test,31,"Update: I wrote an integration test in my branch that runs M2 with ; `--kmer-size 1 --dont-increase-kmer-sizes-for-cycles`. It still calls the given alleles, whereas in master it does not.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5857#issuecomment-480008571
https://github.com/broadinstitute/gatk/issues/5857#issuecomment-480291626:40,Availability,failure,failures,40,"You're totally right about the assembly failures. As we talked about in person yesterday, I worry about biasing the; likelihoods when genotyping positions near homVar variants. For the; record, the conclusion of that conversation was to inject the GGA allele; into the five best assembled haplotypes, though I'm open to something less; heuristic than ""best five"" if anyone has a good idea. (I don't want to; double the number of haplotypes by adding the GGA allele into all of them). On Thu, Apr 4, 2019 at 2:19 PM David Benjamin <notifications@github.com>; wrote:. > Update: I wrote an integration test in my branch that runs M2 with; > --kmer-size 1 --dont-increase-kmer-sizes-for-cycles. It still calls the; > given alleles, whereas in master it does not.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/5857#issuecomment-480008571>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdF1sCpAlqKNa6S_qlL_ypNX_A0eGks5vdkI7gaJpZM4cbxVV>; > .; >. -- ; Laura Doyle Gauthier, Ph.D.; Associate Director, Germline Methods; Data Sciences Platform; gauthier@broadinstitute.org; Broad Institute of MIT & Harvard; 320 Charles St.; Cambridge MA 0214",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5857#issuecomment-480291626
https://github.com/broadinstitute/gatk/issues/5857#issuecomment-480291626:568,Deployability,Update,Update,568,"You're totally right about the assembly failures. As we talked about in person yesterday, I worry about biasing the; likelihoods when genotyping positions near homVar variants. For the; record, the conclusion of that conversation was to inject the GGA allele; into the five best assembled haplotypes, though I'm open to something less; heuristic than ""best five"" if anyone has a good idea. (I don't want to; double the number of haplotypes by adding the GGA allele into all of them). On Thu, Apr 4, 2019 at 2:19 PM David Benjamin <notifications@github.com>; wrote:. > Update: I wrote an integration test in my branch that runs M2 with; > --kmer-size 1 --dont-increase-kmer-sizes-for-cycles. It still calls the; > given alleles, whereas in master it does not.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/5857#issuecomment-480008571>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdF1sCpAlqKNa6S_qlL_ypNX_A0eGks5vdkI7gaJpZM4cbxVV>; > .; >. -- ; Laura Doyle Gauthier, Ph.D.; Associate Director, Germline Methods; Data Sciences Platform; gauthier@broadinstitute.org; Broad Institute of MIT & Harvard; 320 Charles St.; Cambridge MA 0214",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5857#issuecomment-480291626
https://github.com/broadinstitute/gatk/issues/5857#issuecomment-480291626:587,Deployability,integrat,integration,587,"You're totally right about the assembly failures. As we talked about in person yesterday, I worry about biasing the; likelihoods when genotyping positions near homVar variants. For the; record, the conclusion of that conversation was to inject the GGA allele; into the five best assembled haplotypes, though I'm open to something less; heuristic than ""best five"" if anyone has a good idea. (I don't want to; double the number of haplotypes by adding the GGA allele into all of them). On Thu, Apr 4, 2019 at 2:19 PM David Benjamin <notifications@github.com>; wrote:. > Update: I wrote an integration test in my branch that runs M2 with; > --kmer-size 1 --dont-increase-kmer-sizes-for-cycles. It still calls the; > given alleles, whereas in master it does not.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/5857#issuecomment-480008571>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdF1sCpAlqKNa6S_qlL_ypNX_A0eGks5vdkI7gaJpZM4cbxVV>; > .; >. -- ; Laura Doyle Gauthier, Ph.D.; Associate Director, Germline Methods; Data Sciences Platform; gauthier@broadinstitute.org; Broad Institute of MIT & Harvard; 320 Charles St.; Cambridge MA 0214",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5857#issuecomment-480291626
https://github.com/broadinstitute/gatk/issues/5857#issuecomment-480291626:237,Integrability,inject,inject,237,"You're totally right about the assembly failures. As we talked about in person yesterday, I worry about biasing the; likelihoods when genotyping positions near homVar variants. For the; record, the conclusion of that conversation was to inject the GGA allele; into the five best assembled haplotypes, though I'm open to something less; heuristic than ""best five"" if anyone has a good idea. (I don't want to; double the number of haplotypes by adding the GGA allele into all of them). On Thu, Apr 4, 2019 at 2:19 PM David Benjamin <notifications@github.com>; wrote:. > Update: I wrote an integration test in my branch that runs M2 with; > --kmer-size 1 --dont-increase-kmer-sizes-for-cycles. It still calls the; > given alleles, whereas in master it does not.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/5857#issuecomment-480008571>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdF1sCpAlqKNa6S_qlL_ypNX_A0eGks5vdkI7gaJpZM4cbxVV>; > .; >. -- ; Laura Doyle Gauthier, Ph.D.; Associate Director, Germline Methods; Data Sciences Platform; gauthier@broadinstitute.org; Broad Institute of MIT & Harvard; 320 Charles St.; Cambridge MA 0214",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5857#issuecomment-480291626
https://github.com/broadinstitute/gatk/issues/5857#issuecomment-480291626:587,Integrability,integrat,integration,587,"You're totally right about the assembly failures. As we talked about in person yesterday, I worry about biasing the; likelihoods when genotyping positions near homVar variants. For the; record, the conclusion of that conversation was to inject the GGA allele; into the five best assembled haplotypes, though I'm open to something less; heuristic than ""best five"" if anyone has a good idea. (I don't want to; double the number of haplotypes by adding the GGA allele into all of them). On Thu, Apr 4, 2019 at 2:19 PM David Benjamin <notifications@github.com>; wrote:. > Update: I wrote an integration test in my branch that runs M2 with; > --kmer-size 1 --dont-increase-kmer-sizes-for-cycles. It still calls the; > given alleles, whereas in master it does not.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/5857#issuecomment-480008571>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdF1sCpAlqKNa6S_qlL_ypNX_A0eGks5vdkI7gaJpZM4cbxVV>; > .; >. -- ; Laura Doyle Gauthier, Ph.D.; Associate Director, Germline Methods; Data Sciences Platform; gauthier@broadinstitute.org; Broad Institute of MIT & Harvard; 320 Charles St.; Cambridge MA 0214",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5857#issuecomment-480291626
https://github.com/broadinstitute/gatk/issues/5857#issuecomment-480291626:237,Security,inject,inject,237,"You're totally right about the assembly failures. As we talked about in person yesterday, I worry about biasing the; likelihoods when genotyping positions near homVar variants. For the; record, the conclusion of that conversation was to inject the GGA allele; into the five best assembled haplotypes, though I'm open to something less; heuristic than ""best five"" if anyone has a good idea. (I don't want to; double the number of haplotypes by adding the GGA allele into all of them). On Thu, Apr 4, 2019 at 2:19 PM David Benjamin <notifications@github.com>; wrote:. > Update: I wrote an integration test in my branch that runs M2 with; > --kmer-size 1 --dont-increase-kmer-sizes-for-cycles. It still calls the; > given alleles, whereas in master it does not.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/5857#issuecomment-480008571>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdF1sCpAlqKNa6S_qlL_ypNX_A0eGks5vdkI7gaJpZM4cbxVV>; > .; >. -- ; Laura Doyle Gauthier, Ph.D.; Associate Director, Germline Methods; Data Sciences Platform; gauthier@broadinstitute.org; Broad Institute of MIT & Harvard; 320 Charles St.; Cambridge MA 0214",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5857#issuecomment-480291626
https://github.com/broadinstitute/gatk/issues/5857#issuecomment-480291626:599,Testability,test,test,599,"You're totally right about the assembly failures. As we talked about in person yesterday, I worry about biasing the; likelihoods when genotyping positions near homVar variants. For the; record, the conclusion of that conversation was to inject the GGA allele; into the five best assembled haplotypes, though I'm open to something less; heuristic than ""best five"" if anyone has a good idea. (I don't want to; double the number of haplotypes by adding the GGA allele into all of them). On Thu, Apr 4, 2019 at 2:19 PM David Benjamin <notifications@github.com>; wrote:. > Update: I wrote an integration test in my branch that runs M2 with; > --kmer-size 1 --dont-increase-kmer-sizes-for-cycles. It still calls the; > given alleles, whereas in master it does not.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/5857#issuecomment-480008571>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AGRhdF1sCpAlqKNa6S_qlL_ypNX_A0eGks5vdkI7gaJpZM4cbxVV>; > .; >. -- ; Laura Doyle Gauthier, Ph.D.; Associate Director, Germline Methods; Data Sciences Platform; gauthier@broadinstitute.org; Broad Institute of MIT & Harvard; 320 Charles St.; Cambridge MA 0214",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5857#issuecomment-480291626
https://github.com/broadinstitute/gatk/pull/5860#issuecomment-480044442:2542,Availability,down,downsampling,2542,5 <0> (+2)` | :arrow_up: |; | [...nder/tools/funcotator/FuncotatorTestConstants.java](https://codecov.io/gh/broadinstitute/gatk/pull/5860/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9mdW5jb3RhdG9yL0Z1bmNvdGF0b3JUZXN0Q29uc3RhbnRzLmphdmE=) | `98.361% <100%> (+0.027%)` | `1 <0> (ø)` | :arrow_down: |; | [...ls/variant/writers/GVCFBlockCombiningIterator.java](https://codecov.io/gh/broadinstitute/gatk/pull/5860/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy92YXJpYW50L3dyaXRlcnMvR1ZDRkJsb2NrQ29tYmluaW5nSXRlcmF0b3IuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-1%)` | |; | [...ls/walkers/genotyper/HeterogeneousPloidyModel.java](https://codecov.io/gh/broadinstitute/gatk/pull/5860/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2dlbm90eXBlci9IZXRlcm9nZW5lb3VzUGxvaWR5TW9kZWwuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-14%)` | |; | [...nder/utils/downsampling/FractionalDownsampler.java](https://codecov.io/gh/broadinstitute/gatk/pull/5860/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9kb3duc2FtcGxpbmcvRnJhY3Rpb25hbERvd25zYW1wbGVyLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-17%)` | |; | [...park/pathseq/MarkedOpticalDuplicateReadFilter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5860/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9wYXRoc2VxL01hcmtlZE9wdGljYWxEdXBsaWNhdGVSZWFkRmlsdGVyLmphdmE=) | `0% <0%> (-100%)` | `0% <0%> (-4%)` | |; | [...otypecaller/RandomLikelihoodCalculationEngine.java](https://codecov.io/gh/broadinstitute/gatk/pull/5860/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9SYW5kb21MaWtlbGlob29kQ2FsY3VsYXRpb25FbmdpbmUuamF2YQ==) | `0% <0%> (-100%)` | `0% <0%> (-6%)` | |; | [...r/utils/solver/UnivariateSolverSpecifications.java](https://codecov.io/gh/,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5860#issuecomment-480044442
https://github.com/broadinstitute/gatk/issues/5862#issuecomment-480900822:8,Testability,test,test,8,"When we test this, we should make sure it flags `AD` when there is only 1 field in there.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5862#issuecomment-480900822
https://github.com/broadinstitute/gatk/issues/5862#issuecomment-485714312:15,Availability,error,error,15,I recommend we error out when provided with `--validation-type-to-exclude ALL`. It doesn't make sense - why call the validator if you're not going to validate?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5862#issuecomment-485714312
https://github.com/broadinstitute/gatk/issues/5862#issuecomment-485714312:47,Security,validat,validation-type-to-exclude,47,I recommend we error out when provided with `--validation-type-to-exclude ALL`. It doesn't make sense - why call the validator if you're not going to validate?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5862#issuecomment-485714312
https://github.com/broadinstitute/gatk/issues/5862#issuecomment-485714312:117,Security,validat,validator,117,I recommend we error out when provided with `--validation-type-to-exclude ALL`. It doesn't make sense - why call the validator if you're not going to validate?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5862#issuecomment-485714312
https://github.com/broadinstitute/gatk/issues/5862#issuecomment-485714312:150,Security,validat,validate,150,I recommend we error out when provided with `--validation-type-to-exclude ALL`. It doesn't make sense - why call the validator if you're not going to validate?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5862#issuecomment-485714312
https://github.com/broadinstitute/gatk/issues/5862#issuecomment-498685279:558,Availability,error,error,558,"I didn't realize before that there is no ""include"" (opt-in) validation type arg, only ""exclude"". So I'm not sure what the purpose of having ""ALL"" is in the first place, if the only thing you can usefully do with it is exclude it. I think the best longer term fix would be to add an ""--validation-type-to-include"" arg, and have it default to the everything except for IDs, and then construct the actual types based on merging include/exclude args. But thats a bigger change then just fixing the current (silent do-nothing) default behavior, and requires more error checking for conflicting args. Lets start with changing it so that in the default (no args) case, we log a warning message saying that IDs will be left out since no IDS were provided, and proceed with the remaining validations. Then if we want to get more ambitious we can talk about making the bigger change. Also, as part of the initial fix, it might be a good idea to change `calculateValidationTypesToApply` so that it doesn't modify the `excludeTypes` list directly, since this is the list provided by the user, and instead uses it's own temporary list.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5862#issuecomment-498685279
https://github.com/broadinstitute/gatk/issues/5862#issuecomment-498685279:679,Integrability,message,message,679,"I didn't realize before that there is no ""include"" (opt-in) validation type arg, only ""exclude"". So I'm not sure what the purpose of having ""ALL"" is in the first place, if the only thing you can usefully do with it is exclude it. I think the best longer term fix would be to add an ""--validation-type-to-include"" arg, and have it default to the everything except for IDs, and then construct the actual types based on merging include/exclude args. But thats a bigger change then just fixing the current (silent do-nothing) default behavior, and requires more error checking for conflicting args. Lets start with changing it so that in the default (no args) case, we log a warning message saying that IDs will be left out since no IDS were provided, and proceed with the remaining validations. Then if we want to get more ambitious we can talk about making the bigger change. Also, as part of the initial fix, it might be a good idea to change `calculateValidationTypesToApply` so that it doesn't modify the `excludeTypes` list directly, since this is the list provided by the user, and instead uses it's own temporary list.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5862#issuecomment-498685279
https://github.com/broadinstitute/gatk/issues/5862#issuecomment-498685279:60,Security,validat,validation,60,"I didn't realize before that there is no ""include"" (opt-in) validation type arg, only ""exclude"". So I'm not sure what the purpose of having ""ALL"" is in the first place, if the only thing you can usefully do with it is exclude it. I think the best longer term fix would be to add an ""--validation-type-to-include"" arg, and have it default to the everything except for IDs, and then construct the actual types based on merging include/exclude args. But thats a bigger change then just fixing the current (silent do-nothing) default behavior, and requires more error checking for conflicting args. Lets start with changing it so that in the default (no args) case, we log a warning message saying that IDs will be left out since no IDS were provided, and proceed with the remaining validations. Then if we want to get more ambitious we can talk about making the bigger change. Also, as part of the initial fix, it might be a good idea to change `calculateValidationTypesToApply` so that it doesn't modify the `excludeTypes` list directly, since this is the list provided by the user, and instead uses it's own temporary list.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5862#issuecomment-498685279
https://github.com/broadinstitute/gatk/issues/5862#issuecomment-498685279:285,Security,validat,validation-type-to-include,285,"I didn't realize before that there is no ""include"" (opt-in) validation type arg, only ""exclude"". So I'm not sure what the purpose of having ""ALL"" is in the first place, if the only thing you can usefully do with it is exclude it. I think the best longer term fix would be to add an ""--validation-type-to-include"" arg, and have it default to the everything except for IDs, and then construct the actual types based on merging include/exclude args. But thats a bigger change then just fixing the current (silent do-nothing) default behavior, and requires more error checking for conflicting args. Lets start with changing it so that in the default (no args) case, we log a warning message saying that IDs will be left out since no IDS were provided, and proceed with the remaining validations. Then if we want to get more ambitious we can talk about making the bigger change. Also, as part of the initial fix, it might be a good idea to change `calculateValidationTypesToApply` so that it doesn't modify the `excludeTypes` list directly, since this is the list provided by the user, and instead uses it's own temporary list.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5862#issuecomment-498685279
https://github.com/broadinstitute/gatk/issues/5862#issuecomment-498685279:779,Security,validat,validations,779,"I didn't realize before that there is no ""include"" (opt-in) validation type arg, only ""exclude"". So I'm not sure what the purpose of having ""ALL"" is in the first place, if the only thing you can usefully do with it is exclude it. I think the best longer term fix would be to add an ""--validation-type-to-include"" arg, and have it default to the everything except for IDs, and then construct the actual types based on merging include/exclude args. But thats a bigger change then just fixing the current (silent do-nothing) default behavior, and requires more error checking for conflicting args. Lets start with changing it so that in the default (no args) case, we log a warning message saying that IDs will be left out since no IDS were provided, and proceed with the remaining validations. Then if we want to get more ambitious we can talk about making the bigger change. Also, as part of the initial fix, it might be a good idea to change `calculateValidationTypesToApply` so that it doesn't modify the `excludeTypes` list directly, since this is the list provided by the user, and instead uses it's own temporary list.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5862#issuecomment-498685279
https://github.com/broadinstitute/gatk/issues/5862#issuecomment-498685279:665,Testability,log,log,665,"I didn't realize before that there is no ""include"" (opt-in) validation type arg, only ""exclude"". So I'm not sure what the purpose of having ""ALL"" is in the first place, if the only thing you can usefully do with it is exclude it. I think the best longer term fix would be to add an ""--validation-type-to-include"" arg, and have it default to the everything except for IDs, and then construct the actual types based on merging include/exclude args. But thats a bigger change then just fixing the current (silent do-nothing) default behavior, and requires more error checking for conflicting args. Lets start with changing it so that in the default (no args) case, we log a warning message saying that IDs will be left out since no IDS were provided, and proceed with the remaining validations. Then if we want to get more ambitious we can talk about making the bigger change. Also, as part of the initial fix, it might be a good idea to change `calculateValidationTypesToApply` so that it doesn't modify the `excludeTypes` list directly, since this is the list provided by the user, and instead uses it's own temporary list.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5862#issuecomment-498685279
https://github.com/broadinstitute/gatk/pull/5863#issuecomment-486413930:74,Testability,test,tests,74,"@droazen I addressed your comments, but I also added some more fixes (and tests!)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5863#issuecomment-486413930
https://github.com/broadinstitute/gatk/issues/5865#issuecomment-480546121:205,Availability,error,error,205,@cmnbroad . I checked with @asmirnov239 and he said that this can be fixed by providing GenotypeGVCFs with the same interval list as GenomicsDBImport(so just add -L Qrob_Chr02 to GenotypeGVCFs CLI). . The error msg however is a little confusing. Can we make the error msg more descriptive?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5865#issuecomment-480546121
https://github.com/broadinstitute/gatk/issues/5865#issuecomment-480546121:262,Availability,error,error,262,@cmnbroad . I checked with @asmirnov239 and he said that this can be fixed by providing GenotypeGVCFs with the same interval list as GenomicsDBImport(so just add -L Qrob_Chr02 to GenotypeGVCFs CLI). . The error msg however is a little confusing. Can we make the error msg more descriptive?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5865#issuecomment-480546121
https://github.com/broadinstitute/gatk/issues/5865#issuecomment-480978282:281,Availability,error,error,281,"The user mentioned and I agree:; Since the interval list isn't a required argument listed in the GenotypeGVCFs documentation, perhaps a note could be added to the --all-sites parameter to indicate that it should be used in conjunction with a specified -L parameter. Clarifying the error message will also be a big help.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5865#issuecomment-480978282
https://github.com/broadinstitute/gatk/issues/5865#issuecomment-480978282:287,Integrability,message,message,287,"The user mentioned and I agree:; Since the interval list isn't a required argument listed in the GenotypeGVCFs documentation, perhaps a note could be added to the --all-sites parameter to indicate that it should be used in conjunction with a specified -L parameter. Clarifying the error message will also be a big help.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5865#issuecomment-480978282
https://github.com/broadinstitute/gatk/pull/5866#issuecomment-481260984:53,Deployability,integrat,integration,53,Closing until I find a different strategy for docker integration.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5866#issuecomment-481260984
https://github.com/broadinstitute/gatk/pull/5866#issuecomment-481260984:53,Integrability,integrat,integration,53,Closing until I find a different strategy for docker integration.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5866#issuecomment-481260984
https://github.com/broadinstitute/gatk/pull/5868#issuecomment-552904898:221,Deployability,update,update,221,"@kgururaj Ok. This branch was actually merged into GATK a while back as part of another PR, so this PR should be closed anyway. When we merge in the new GenomicsDB, we'll have to either revert these changes completely or update the expected GenomicsDB BCF version in the subclassed codec.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5868#issuecomment-552904898
https://github.com/broadinstitute/gatk/issues/5869#issuecomment-499414227:191,Deployability,install,installed,191,"I have just experienced the same problem of stack overflow with my first attempt to use gatk HaplotypeCallerSpark with the option --spark-master local[*]. My GATK version is 4.1.2.0,that was installed via bioconda. ; Should I wait for the corrected version or is there a way to circumvent the problem with extra install or by using options like --java-options '-XssOptimalValue'?; When is the corrected version expected? Is Q2 (end of June?) still an option? Will it be readily on bioconda then?; Thanks",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5869#issuecomment-499414227
https://github.com/broadinstitute/gatk/issues/5869#issuecomment-499414227:312,Deployability,install,install,312,"I have just experienced the same problem of stack overflow with my first attempt to use gatk HaplotypeCallerSpark with the option --spark-master local[*]. My GATK version is 4.1.2.0,that was installed via bioconda. ; Should I wait for the corrected version or is there a way to circumvent the problem with extra install or by using options like --java-options '-XssOptimalValue'?; When is the corrected version expected? Is Q2 (end of June?) still an option? Will it be readily on bioconda then?; Thanks",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5869#issuecomment-499414227
https://github.com/broadinstitute/gatk/issues/5869#issuecomment-499414227:362,Security,Xss,XssOptimalValue,362,"I have just experienced the same problem of stack overflow with my first attempt to use gatk HaplotypeCallerSpark with the option --spark-master local[*]. My GATK version is 4.1.2.0,that was installed via bioconda. ; Should I wait for the corrected version or is there a way to circumvent the problem with extra install or by using options like --java-options '-XssOptimalValue'?; When is the corrected version expected? Is Q2 (end of June?) still an option? Will it be readily on bioconda then?; Thanks",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5869#issuecomment-499414227
https://github.com/broadinstitute/gatk/issues/5869#issuecomment-577016491:38,Security,access,access,38,Dear GATK staff. We are now forbidden access to any webpages starting with the address https://gatkforums.broadinstitute.org/gatk/discussion/ by cloudflare. We can still access pages starting with https://gatk.broadinstitute.org/hc/en-us/ . We are connecting from various computers and netwrk in France using Firefox but it seems that it is the server itself that is blocked by Cloudflare. Have you already been notified of this problem and do you think you can solve it with cloudflare?. Thanks for your help. Best regards. Thierry Grange,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5869#issuecomment-577016491
https://github.com/broadinstitute/gatk/issues/5869#issuecomment-577016491:170,Security,access,access,170,Dear GATK staff. We are now forbidden access to any webpages starting with the address https://gatkforums.broadinstitute.org/gatk/discussion/ by cloudflare. We can still access pages starting with https://gatk.broadinstitute.org/hc/en-us/ . We are connecting from various computers and netwrk in France using Firefox but it seems that it is the server itself that is blocked by Cloudflare. Have you already been notified of this problem and do you think you can solve it with cloudflare?. Thanks for your help. Best regards. Thierry Grange,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5869#issuecomment-577016491
https://github.com/broadinstitute/gatk/issues/5869#issuecomment-577247506:234,Deployability,update,updates,234,"@thierrygrange Thanks for letting us know. The comms team is working on getting it fixed. You can follow [this thread](https://gatk.broadinstitute.org/hc/en-us/community/posts/360056211411-Known-issue-old-GATK-forum-inaccessible) for updates although probably the only update you care about is ""it's working again.""",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5869#issuecomment-577247506
https://github.com/broadinstitute/gatk/issues/5869#issuecomment-577247506:269,Deployability,update,update,269,"@thierrygrange Thanks for letting us know. The comms team is working on getting it fixed. You can follow [this thread](https://gatk.broadinstitute.org/hc/en-us/community/posts/360056211411-Known-issue-old-GATK-forum-inaccessible) for updates although probably the only update you care about is ""it's working again.""",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5869#issuecomment-577247506
https://github.com/broadinstitute/gatk/issues/5869#issuecomment-674384617:13,Availability,error,error,13,"similar same error message with ; `gatk HaplotypeCallerSpark -R ref.fa -I input.GatherBamFiles.bam -O output.g2.vcf.gz`. OpenJDK Runtime Environment (build 1.8.0_152-release-1056-b12); gatk 4.1.8.1 . ```; 07:16:06.169 INFO HaplotypeCallerEngine - Tool is in reference confidence mode and the annotation, the following changes will be made to any specified annotations: 'StrandBiasBySample' will be enabled. 'ChromosomeCounts', 'FisherStrand', 'StrandOddsRatio' and 'QualByDepth' annotations have been disabled; 20/08/15 07:16:06 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 18.5 MB, free 57.3 GB); 20/08/15 07:16:06 INFO SparkUI: Stopped Spark web UI at http://e1c-050:4041; 20/08/15 07:16:06 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 20/08/15 07:16:06 INFO MemoryStore: MemoryStore cleared; 20/08/15 07:16:06 INFO BlockManager: BlockManager stopped; 20/08/15 07:16:06 INFO BlockManagerMaster: BlockManagerMaster stopped; 20/08/15 07:16:06 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 20/08/15 07:16:06 INFO SparkContext: Successfully stopped SparkContext; 07:16:06.412 INFO HaplotypeCallerSpark - Shutting down engine; [August 15, 2020 7:16:06 AM EDT] org.broadinstitute.hellbender.tools.HaplotypeCallerSpark done. Elapsed time: 0.11 minutes.; Runtime.totalMemory()=102900432896; Exception in thread ""main"" java.lang.StackOverflowError; at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:67); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:505); at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:80); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:505); at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5869#issuecomment-674384617
https://github.com/broadinstitute/gatk/issues/5869#issuecomment-674384617:1228,Availability,down,down,1228,"CallerEngine - Tool is in reference confidence mode and the annotation, the following changes will be made to any specified annotations: 'StrandBiasBySample' will be enabled. 'ChromosomeCounts', 'FisherStrand', 'StrandOddsRatio' and 'QualByDepth' annotations have been disabled; 20/08/15 07:16:06 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 18.5 MB, free 57.3 GB); 20/08/15 07:16:06 INFO SparkUI: Stopped Spark web UI at http://e1c-050:4041; 20/08/15 07:16:06 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 20/08/15 07:16:06 INFO MemoryStore: MemoryStore cleared; 20/08/15 07:16:06 INFO BlockManager: BlockManager stopped; 20/08/15 07:16:06 INFO BlockManagerMaster: BlockManagerMaster stopped; 20/08/15 07:16:06 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 20/08/15 07:16:06 INFO SparkContext: Successfully stopped SparkContext; 07:16:06.412 INFO HaplotypeCallerSpark - Shutting down engine; [August 15, 2020 7:16:06 AM EDT] org.broadinstitute.hellbender.tools.HaplotypeCallerSpark done. Elapsed time: 0.11 minutes.; Runtime.totalMemory()=102900432896; Exception in thread ""main"" java.lang.StackOverflowError; at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:67); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:505); at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:80); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:505); at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:80); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:505); at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5869#issuecomment-674384617
https://github.com/broadinstitute/gatk/issues/5869#issuecomment-674384617:166,Deployability,release,release-,166,"similar same error message with ; `gatk HaplotypeCallerSpark -R ref.fa -I input.GatherBamFiles.bam -O output.g2.vcf.gz`. OpenJDK Runtime Environment (build 1.8.0_152-release-1056-b12); gatk 4.1.8.1 . ```; 07:16:06.169 INFO HaplotypeCallerEngine - Tool is in reference confidence mode and the annotation, the following changes will be made to any specified annotations: 'StrandBiasBySample' will be enabled. 'ChromosomeCounts', 'FisherStrand', 'StrandOddsRatio' and 'QualByDepth' annotations have been disabled; 20/08/15 07:16:06 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 18.5 MB, free 57.3 GB); 20/08/15 07:16:06 INFO SparkUI: Stopped Spark web UI at http://e1c-050:4041; 20/08/15 07:16:06 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 20/08/15 07:16:06 INFO MemoryStore: MemoryStore cleared; 20/08/15 07:16:06 INFO BlockManager: BlockManager stopped; 20/08/15 07:16:06 INFO BlockManagerMaster: BlockManagerMaster stopped; 20/08/15 07:16:06 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 20/08/15 07:16:06 INFO SparkContext: Successfully stopped SparkContext; 07:16:06.412 INFO HaplotypeCallerSpark - Shutting down engine; [August 15, 2020 7:16:06 AM EDT] org.broadinstitute.hellbender.tools.HaplotypeCallerSpark done. Elapsed time: 0.11 minutes.; Runtime.totalMemory()=102900432896; Exception in thread ""main"" java.lang.StackOverflowError; at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:67); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:505); at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:80); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:505); at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5869#issuecomment-674384617
https://github.com/broadinstitute/gatk/issues/5869#issuecomment-674384617:19,Integrability,message,message,19,"similar same error message with ; `gatk HaplotypeCallerSpark -R ref.fa -I input.GatherBamFiles.bam -O output.g2.vcf.gz`. OpenJDK Runtime Environment (build 1.8.0_152-release-1056-b12); gatk 4.1.8.1 . ```; 07:16:06.169 INFO HaplotypeCallerEngine - Tool is in reference confidence mode and the annotation, the following changes will be made to any specified annotations: 'StrandBiasBySample' will be enabled. 'ChromosomeCounts', 'FisherStrand', 'StrandOddsRatio' and 'QualByDepth' annotations have been disabled; 20/08/15 07:16:06 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 18.5 MB, free 57.3 GB); 20/08/15 07:16:06 INFO SparkUI: Stopped Spark web UI at http://e1c-050:4041; 20/08/15 07:16:06 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 20/08/15 07:16:06 INFO MemoryStore: MemoryStore cleared; 20/08/15 07:16:06 INFO BlockManager: BlockManager stopped; 20/08/15 07:16:06 INFO BlockManagerMaster: BlockManagerMaster stopped; 20/08/15 07:16:06 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 20/08/15 07:16:06 INFO SparkContext: Successfully stopped SparkContext; 07:16:06.412 INFO HaplotypeCallerSpark - Shutting down engine; [August 15, 2020 7:16:06 AM EDT] org.broadinstitute.hellbender.tools.HaplotypeCallerSpark done. Elapsed time: 0.11 minutes.; Runtime.totalMemory()=102900432896; Exception in thread ""main"" java.lang.StackOverflowError; at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:67); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:505); at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:80); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:505); at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5869#issuecomment-674384617
https://github.com/broadinstitute/gatk/issues/5869#issuecomment-674384617:853,Usability,clear,cleared,853,"similar same error message with ; `gatk HaplotypeCallerSpark -R ref.fa -I input.GatherBamFiles.bam -O output.g2.vcf.gz`. OpenJDK Runtime Environment (build 1.8.0_152-release-1056-b12); gatk 4.1.8.1 . ```; 07:16:06.169 INFO HaplotypeCallerEngine - Tool is in reference confidence mode and the annotation, the following changes will be made to any specified annotations: 'StrandBiasBySample' will be enabled. 'ChromosomeCounts', 'FisherStrand', 'StrandOddsRatio' and 'QualByDepth' annotations have been disabled; 20/08/15 07:16:06 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 18.5 MB, free 57.3 GB); 20/08/15 07:16:06 INFO SparkUI: Stopped Spark web UI at http://e1c-050:4041; 20/08/15 07:16:06 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 20/08/15 07:16:06 INFO MemoryStore: MemoryStore cleared; 20/08/15 07:16:06 INFO BlockManager: BlockManager stopped; 20/08/15 07:16:06 INFO BlockManagerMaster: BlockManagerMaster stopped; 20/08/15 07:16:06 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 20/08/15 07:16:06 INFO SparkContext: Successfully stopped SparkContext; 07:16:06.412 INFO HaplotypeCallerSpark - Shutting down engine; [August 15, 2020 7:16:06 AM EDT] org.broadinstitute.hellbender.tools.HaplotypeCallerSpark done. Elapsed time: 0.11 minutes.; Runtime.totalMemory()=102900432896; Exception in thread ""main"" java.lang.StackOverflowError; at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:67); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:505); at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:80); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:505); at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5869#issuecomment-674384617
https://github.com/broadinstitute/gatk/issues/5869#issuecomment-709409312:10,Availability,error,error,10,"A similar error message has been reported on the forum [here](https://gatk.broadinstitute.org/hc/en-us/community/posts/360073781912-Error-when-running-HaplotypeCallerSparkinfinite). . GATK Version: 4.1.9.0. The command is: ; ```; gatk# ./gatk HaplotypeCallerSpark -I HG03934.final.bam \; -O HG03934.final.g.vcf \; -R Ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --emit-ref-confidence GVCF \; -- \; --spark-runner LOCAL --spark-master 'local[20]'; ```. And a snippet of the error message: ; ```; 20/10/14 05:29:52 INFO BlockManager: BlockManager stopped; 20/10/14 05:29:52 INFO BlockManagerMaster: BlockManagerMaster stopped; 20/10/14 05:29:52 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 20/10/14 05:29:52 INFO SparkContext: Successfully stopped SparkContext; 05:29:52.033 INFO HaplotypeCallerSpark - Shutting down engine; [October 14, 2020 5:29:52 AM GMT] org.broadinstitute.hellbender.tools.HaplotypeCallerSpark done. Elapsed time: 0.12 minutes.; Runtime.totalMemory()=2976382976; Exception in thread ""main"" java.lang.StackOverflowError; at com.esotericsoftware.kryo.util.DefaultClassResolver.writeName(DefaultClassResolver.java:108); at com.esotericsoftware.kryo.util.DefaultClassResolver.writeClass(DefaultClassResolver.java:99); at com.esotericsoftware.kryo.Kryo.writeClass(Kryo.java:540); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:76); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:505); at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:80); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:505); at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:80); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:505); at com.esoterics",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5869#issuecomment-709409312
https://github.com/broadinstitute/gatk/issues/5869#issuecomment-709409312:132,Availability,Error,Error-when-running-HaplotypeCallerSparkinfinite,132,"A similar error message has been reported on the forum [here](https://gatk.broadinstitute.org/hc/en-us/community/posts/360073781912-Error-when-running-HaplotypeCallerSparkinfinite). . GATK Version: 4.1.9.0. The command is: ; ```; gatk# ./gatk HaplotypeCallerSpark -I HG03934.final.bam \; -O HG03934.final.g.vcf \; -R Ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --emit-ref-confidence GVCF \; -- \; --spark-runner LOCAL --spark-master 'local[20]'; ```. And a snippet of the error message: ; ```; 20/10/14 05:29:52 INFO BlockManager: BlockManager stopped; 20/10/14 05:29:52 INFO BlockManagerMaster: BlockManagerMaster stopped; 20/10/14 05:29:52 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 20/10/14 05:29:52 INFO SparkContext: Successfully stopped SparkContext; 05:29:52.033 INFO HaplotypeCallerSpark - Shutting down engine; [October 14, 2020 5:29:52 AM GMT] org.broadinstitute.hellbender.tools.HaplotypeCallerSpark done. Elapsed time: 0.12 minutes.; Runtime.totalMemory()=2976382976; Exception in thread ""main"" java.lang.StackOverflowError; at com.esotericsoftware.kryo.util.DefaultClassResolver.writeName(DefaultClassResolver.java:108); at com.esotericsoftware.kryo.util.DefaultClassResolver.writeClass(DefaultClassResolver.java:99); at com.esotericsoftware.kryo.Kryo.writeClass(Kryo.java:540); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:76); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:505); at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:80); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:505); at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:80); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:505); at com.esoterics",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5869#issuecomment-709409312
https://github.com/broadinstitute/gatk/issues/5869#issuecomment-709409312:475,Availability,error,error,475,"A similar error message has been reported on the forum [here](https://gatk.broadinstitute.org/hc/en-us/community/posts/360073781912-Error-when-running-HaplotypeCallerSparkinfinite). . GATK Version: 4.1.9.0. The command is: ; ```; gatk# ./gatk HaplotypeCallerSpark -I HG03934.final.bam \; -O HG03934.final.g.vcf \; -R Ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --emit-ref-confidence GVCF \; -- \; --spark-runner LOCAL --spark-master 'local[20]'; ```. And a snippet of the error message: ; ```; 20/10/14 05:29:52 INFO BlockManager: BlockManager stopped; 20/10/14 05:29:52 INFO BlockManagerMaster: BlockManagerMaster stopped; 20/10/14 05:29:52 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 20/10/14 05:29:52 INFO SparkContext: Successfully stopped SparkContext; 05:29:52.033 INFO HaplotypeCallerSpark - Shutting down engine; [October 14, 2020 5:29:52 AM GMT] org.broadinstitute.hellbender.tools.HaplotypeCallerSpark done. Elapsed time: 0.12 minutes.; Runtime.totalMemory()=2976382976; Exception in thread ""main"" java.lang.StackOverflowError; at com.esotericsoftware.kryo.util.DefaultClassResolver.writeName(DefaultClassResolver.java:108); at com.esotericsoftware.kryo.util.DefaultClassResolver.writeClass(DefaultClassResolver.java:99); at com.esotericsoftware.kryo.Kryo.writeClass(Kryo.java:540); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:76); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:505); at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:80); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:505); at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:80); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:505); at com.esoterics",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5869#issuecomment-709409312
https://github.com/broadinstitute/gatk/issues/5869#issuecomment-709409312:863,Availability,down,down,863,"A similar error message has been reported on the forum [here](https://gatk.broadinstitute.org/hc/en-us/community/posts/360073781912-Error-when-running-HaplotypeCallerSparkinfinite). . GATK Version: 4.1.9.0. The command is: ; ```; gatk# ./gatk HaplotypeCallerSpark -I HG03934.final.bam \; -O HG03934.final.g.vcf \; -R Ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --emit-ref-confidence GVCF \; -- \; --spark-runner LOCAL --spark-master 'local[20]'; ```. And a snippet of the error message: ; ```; 20/10/14 05:29:52 INFO BlockManager: BlockManager stopped; 20/10/14 05:29:52 INFO BlockManagerMaster: BlockManagerMaster stopped; 20/10/14 05:29:52 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 20/10/14 05:29:52 INFO SparkContext: Successfully stopped SparkContext; 05:29:52.033 INFO HaplotypeCallerSpark - Shutting down engine; [October 14, 2020 5:29:52 AM GMT] org.broadinstitute.hellbender.tools.HaplotypeCallerSpark done. Elapsed time: 0.12 minutes.; Runtime.totalMemory()=2976382976; Exception in thread ""main"" java.lang.StackOverflowError; at com.esotericsoftware.kryo.util.DefaultClassResolver.writeName(DefaultClassResolver.java:108); at com.esotericsoftware.kryo.util.DefaultClassResolver.writeClass(DefaultClassResolver.java:99); at com.esotericsoftware.kryo.Kryo.writeClass(Kryo.java:540); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:76); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:505); at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:80); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:505); at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:80); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:505); at com.esoterics",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5869#issuecomment-709409312
https://github.com/broadinstitute/gatk/issues/5869#issuecomment-709409312:16,Integrability,message,message,16,"A similar error message has been reported on the forum [here](https://gatk.broadinstitute.org/hc/en-us/community/posts/360073781912-Error-when-running-HaplotypeCallerSparkinfinite). . GATK Version: 4.1.9.0. The command is: ; ```; gatk# ./gatk HaplotypeCallerSpark -I HG03934.final.bam \; -O HG03934.final.g.vcf \; -R Ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --emit-ref-confidence GVCF \; -- \; --spark-runner LOCAL --spark-master 'local[20]'; ```. And a snippet of the error message: ; ```; 20/10/14 05:29:52 INFO BlockManager: BlockManager stopped; 20/10/14 05:29:52 INFO BlockManagerMaster: BlockManagerMaster stopped; 20/10/14 05:29:52 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 20/10/14 05:29:52 INFO SparkContext: Successfully stopped SparkContext; 05:29:52.033 INFO HaplotypeCallerSpark - Shutting down engine; [October 14, 2020 5:29:52 AM GMT] org.broadinstitute.hellbender.tools.HaplotypeCallerSpark done. Elapsed time: 0.12 minutes.; Runtime.totalMemory()=2976382976; Exception in thread ""main"" java.lang.StackOverflowError; at com.esotericsoftware.kryo.util.DefaultClassResolver.writeName(DefaultClassResolver.java:108); at com.esotericsoftware.kryo.util.DefaultClassResolver.writeClass(DefaultClassResolver.java:99); at com.esotericsoftware.kryo.Kryo.writeClass(Kryo.java:540); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:76); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:505); at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:80); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:505); at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:80); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:505); at com.esoterics",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5869#issuecomment-709409312
https://github.com/broadinstitute/gatk/issues/5869#issuecomment-709409312:481,Integrability,message,message,481,"A similar error message has been reported on the forum [here](https://gatk.broadinstitute.org/hc/en-us/community/posts/360073781912-Error-when-running-HaplotypeCallerSparkinfinite). . GATK Version: 4.1.9.0. The command is: ; ```; gatk# ./gatk HaplotypeCallerSpark -I HG03934.final.bam \; -O HG03934.final.g.vcf \; -R Ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --emit-ref-confidence GVCF \; -- \; --spark-runner LOCAL --spark-master 'local[20]'; ```. And a snippet of the error message: ; ```; 20/10/14 05:29:52 INFO BlockManager: BlockManager stopped; 20/10/14 05:29:52 INFO BlockManagerMaster: BlockManagerMaster stopped; 20/10/14 05:29:52 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 20/10/14 05:29:52 INFO SparkContext: Successfully stopped SparkContext; 05:29:52.033 INFO HaplotypeCallerSpark - Shutting down engine; [October 14, 2020 5:29:52 AM GMT] org.broadinstitute.hellbender.tools.HaplotypeCallerSpark done. Elapsed time: 0.12 minutes.; Runtime.totalMemory()=2976382976; Exception in thread ""main"" java.lang.StackOverflowError; at com.esotericsoftware.kryo.util.DefaultClassResolver.writeName(DefaultClassResolver.java:108); at com.esotericsoftware.kryo.util.DefaultClassResolver.writeClass(DefaultClassResolver.java:99); at com.esotericsoftware.kryo.Kryo.writeClass(Kryo.java:540); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:76); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:505); at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:80); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:505); at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:80); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:505); at com.esoterics",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5869#issuecomment-709409312
https://github.com/broadinstitute/gatk/issues/5869#issuecomment-709423856:166,Deployability,update,update,166,@jamesemery @lbergelson @cmnbroad It looks like this issue is persisting in the newest GATK version. I have asked the user for a file to replicate the issue and will update you when I get it.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5869#issuecomment-709423856
https://github.com/broadinstitute/gatk/issues/5869#issuecomment-917650984:590,Availability,down,down,590,"This issue only happens in genomes with a large number of chromosomes, such as hg38. b37 and hg19 are fine. workaround: `--conf spark.driver.extraJavaOptions=-Xss2m --conf spark.executor.extraJavaOptions=-Xss2m`. debug log:; ```; ...; 00:05 DEBUG: [kryo] Write object reference 100367: HLA-DRB1*15:03:01:01; 00:05 DEBUG: [kryo] Write object reference 100369: HLA-DRB1*15:03:01:02; 00:05 DEBUG: [kryo] Write object reference 100371: HLA-DRB1*16:02:01; 21/09/12 22:10:49 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040; 21/09/12 22:10:49 INFO StandaloneSchedulerBackend: Shutting down all executors; 21/09/12 22:10:49 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down; 21/09/12 22:10:49 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 21/09/12 22:10:49 INFO MemoryStore: MemoryStore cleared; 21/09/12 22:10:49 INFO BlockManager: BlockManager stopped; 21/09/12 22:10:49 INFO BlockManagerMaster: BlockManagerMaster stopped; 21/09/12 22:10:49 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 21/09/12 22:10:49 INFO SparkContext: Successfully stopped SparkContext; 22:10:49.533 INFO HaplotypeCallerSpark - Shutting down engine; [September 12, 2021 10:10:49 PM CST] org.broadinstitute.hellbender.tools.HaplotypeCallerSpark done. Elapsed time: 0.09 minutes.; Runtime.totalMemory()=1788346368; Exception in thread ""main"" java.lang.StackOverflowError; at com.esotericsoftware.kryo.util.MapReferenceResolver.useReferences(MapReferenceResolver.java:70); at com.esotericsoftware.kryo.Kryo.writeReferenceOrNull(Kryo.java:665); at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:570); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:79); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:508); at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectFiel",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5869#issuecomment-917650984
https://github.com/broadinstitute/gatk/issues/5869#issuecomment-917650984:708,Availability,down,down,708,"This issue only happens in genomes with a large number of chromosomes, such as hg38. b37 and hg19 are fine. workaround: `--conf spark.driver.extraJavaOptions=-Xss2m --conf spark.executor.extraJavaOptions=-Xss2m`. debug log:; ```; ...; 00:05 DEBUG: [kryo] Write object reference 100367: HLA-DRB1*15:03:01:01; 00:05 DEBUG: [kryo] Write object reference 100369: HLA-DRB1*15:03:01:02; 00:05 DEBUG: [kryo] Write object reference 100371: HLA-DRB1*16:02:01; 21/09/12 22:10:49 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040; 21/09/12 22:10:49 INFO StandaloneSchedulerBackend: Shutting down all executors; 21/09/12 22:10:49 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down; 21/09/12 22:10:49 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 21/09/12 22:10:49 INFO MemoryStore: MemoryStore cleared; 21/09/12 22:10:49 INFO BlockManager: BlockManager stopped; 21/09/12 22:10:49 INFO BlockManagerMaster: BlockManagerMaster stopped; 21/09/12 22:10:49 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 21/09/12 22:10:49 INFO SparkContext: Successfully stopped SparkContext; 22:10:49.533 INFO HaplotypeCallerSpark - Shutting down engine; [September 12, 2021 10:10:49 PM CST] org.broadinstitute.hellbender.tools.HaplotypeCallerSpark done. Elapsed time: 0.09 minutes.; Runtime.totalMemory()=1788346368; Exception in thread ""main"" java.lang.StackOverflowError; at com.esotericsoftware.kryo.util.MapReferenceResolver.useReferences(MapReferenceResolver.java:70); at com.esotericsoftware.kryo.Kryo.writeReferenceOrNull(Kryo.java:665); at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:570); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:79); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:508); at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectFiel",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5869#issuecomment-917650984
https://github.com/broadinstitute/gatk/issues/5869#issuecomment-917650984:1233,Availability,down,down,1233," spark.executor.extraJavaOptions=-Xss2m`. debug log:; ```; ...; 00:05 DEBUG: [kryo] Write object reference 100367: HLA-DRB1*15:03:01:01; 00:05 DEBUG: [kryo] Write object reference 100369: HLA-DRB1*15:03:01:02; 00:05 DEBUG: [kryo] Write object reference 100371: HLA-DRB1*16:02:01; 21/09/12 22:10:49 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040; 21/09/12 22:10:49 INFO StandaloneSchedulerBackend: Shutting down all executors; 21/09/12 22:10:49 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down; 21/09/12 22:10:49 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 21/09/12 22:10:49 INFO MemoryStore: MemoryStore cleared; 21/09/12 22:10:49 INFO BlockManager: BlockManager stopped; 21/09/12 22:10:49 INFO BlockManagerMaster: BlockManagerMaster stopped; 21/09/12 22:10:49 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 21/09/12 22:10:49 INFO SparkContext: Successfully stopped SparkContext; 22:10:49.533 INFO HaplotypeCallerSpark - Shutting down engine; [September 12, 2021 10:10:49 PM CST] org.broadinstitute.hellbender.tools.HaplotypeCallerSpark done. Elapsed time: 0.09 minutes.; Runtime.totalMemory()=1788346368; Exception in thread ""main"" java.lang.StackOverflowError; at com.esotericsoftware.kryo.util.MapReferenceResolver.useReferences(MapReferenceResolver.java:70); at com.esotericsoftware.kryo.Kryo.writeReferenceOrNull(Kryo.java:665); at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:570); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:79); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:508); at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:79); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:508); ...; ```. related https://github.com/broadinstitute/gatk/issues/6750",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5869#issuecomment-917650984
https://github.com/broadinstitute/gatk/issues/5869#issuecomment-917650984:219,Testability,log,log,219,"This issue only happens in genomes with a large number of chromosomes, such as hg38. b37 and hg19 are fine. workaround: `--conf spark.driver.extraJavaOptions=-Xss2m --conf spark.executor.extraJavaOptions=-Xss2m`. debug log:; ```; ...; 00:05 DEBUG: [kryo] Write object reference 100367: HLA-DRB1*15:03:01:01; 00:05 DEBUG: [kryo] Write object reference 100369: HLA-DRB1*15:03:01:02; 00:05 DEBUG: [kryo] Write object reference 100371: HLA-DRB1*16:02:01; 21/09/12 22:10:49 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040; 21/09/12 22:10:49 INFO StandaloneSchedulerBackend: Shutting down all executors; 21/09/12 22:10:49 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down; 21/09/12 22:10:49 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 21/09/12 22:10:49 INFO MemoryStore: MemoryStore cleared; 21/09/12 22:10:49 INFO BlockManager: BlockManager stopped; 21/09/12 22:10:49 INFO BlockManagerMaster: BlockManagerMaster stopped; 21/09/12 22:10:49 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 21/09/12 22:10:49 INFO SparkContext: Successfully stopped SparkContext; 22:10:49.533 INFO HaplotypeCallerSpark - Shutting down engine; [September 12, 2021 10:10:49 PM CST] org.broadinstitute.hellbender.tools.HaplotypeCallerSpark done. Elapsed time: 0.09 minutes.; Runtime.totalMemory()=1788346368; Exception in thread ""main"" java.lang.StackOverflowError; at com.esotericsoftware.kryo.util.MapReferenceResolver.useReferences(MapReferenceResolver.java:70); at com.esotericsoftware.kryo.Kryo.writeReferenceOrNull(Kryo.java:665); at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:570); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:79); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:508); at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectFiel",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5869#issuecomment-917650984
https://github.com/broadinstitute/gatk/issues/5869#issuecomment-917650984:858,Usability,clear,cleared,858,"This issue only happens in genomes with a large number of chromosomes, such as hg38. b37 and hg19 are fine. workaround: `--conf spark.driver.extraJavaOptions=-Xss2m --conf spark.executor.extraJavaOptions=-Xss2m`. debug log:; ```; ...; 00:05 DEBUG: [kryo] Write object reference 100367: HLA-DRB1*15:03:01:01; 00:05 DEBUG: [kryo] Write object reference 100369: HLA-DRB1*15:03:01:02; 00:05 DEBUG: [kryo] Write object reference 100371: HLA-DRB1*16:02:01; 21/09/12 22:10:49 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040; 21/09/12 22:10:49 INFO StandaloneSchedulerBackend: Shutting down all executors; 21/09/12 22:10:49 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down; 21/09/12 22:10:49 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 21/09/12 22:10:49 INFO MemoryStore: MemoryStore cleared; 21/09/12 22:10:49 INFO BlockManager: BlockManager stopped; 21/09/12 22:10:49 INFO BlockManagerMaster: BlockManagerMaster stopped; 21/09/12 22:10:49 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 21/09/12 22:10:49 INFO SparkContext: Successfully stopped SparkContext; 22:10:49.533 INFO HaplotypeCallerSpark - Shutting down engine; [September 12, 2021 10:10:49 PM CST] org.broadinstitute.hellbender.tools.HaplotypeCallerSpark done. Elapsed time: 0.09 minutes.; Runtime.totalMemory()=1788346368; Exception in thread ""main"" java.lang.StackOverflowError; at com.esotericsoftware.kryo.util.MapReferenceResolver.useReferences(MapReferenceResolver.java:70); at com.esotericsoftware.kryo.Kryo.writeReferenceOrNull(Kryo.java:665); at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:570); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:79); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:508); at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectFiel",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5869#issuecomment-917650984
https://github.com/broadinstitute/gatk/issues/5869#issuecomment-1664004695:35,Availability,error,error,35,The java. lang. StackOverflowError error in HaplotypeCallerSpark is caused by too many contigs in the reference genome file. Removing the contigs from the genome fragments will enable normal use of the HaplotypeCallerSpark function,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5869#issuecomment-1664004695
https://github.com/broadinstitute/gatk/pull/5872#issuecomment-481382172:35,Testability,test,test,35,@davidbenjamin Can you run a quick test to make sure this works properly?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5872#issuecomment-481382172
https://github.com/broadinstitute/gatk/pull/5872#issuecomment-481836556:60,Availability,error,error,60,"@LeeTL1220 . This seems to be running into a cromwell / WDL error:. ```; java.lang.IllegalArgumentException: Could not build the path ""gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt"". It may refer to a filesystem not supported by this instance of Cromwell. Supported filesystems are: HTTP, LinuxFileSystem. Failures: HTTP: gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt does not have an http or https scheme (IllegalArgumentException); LinuxFileSystem: Cannot build a local path from gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt (RuntimeException) Please refer to the documentation for more information on how to configure filesystems: http://cromwell.readthedocs.io/en/develop/backends/HPC/#filesystems; 	Could not build the path ""gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt"". It may refer to a filesystem not supported by this instance of Cromwell. Supported filesystems are: HTTP, LinuxFileSystem. Failures: HTTP: gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt does not have an http or https scheme (IllegalArgumentException); ```. Isn't cromwell supposed to handle `gs://` URLs for localizing files? Do you have any thoughts?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5872#issuecomment-481836556
https://github.com/broadinstitute/gatk/pull/5872#issuecomment-481836556:356,Availability,Failure,Failures,356,"@LeeTL1220 . This seems to be running into a cromwell / WDL error:. ```; java.lang.IllegalArgumentException: Could not build the path ""gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt"". It may refer to a filesystem not supported by this instance of Cromwell. Supported filesystems are: HTTP, LinuxFileSystem. Failures: HTTP: gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt does not have an http or https scheme (IllegalArgumentException); LinuxFileSystem: Cannot build a local path from gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt (RuntimeException) Please refer to the documentation for more information on how to configure filesystems: http://cromwell.readthedocs.io/en/develop/backends/HPC/#filesystems; 	Could not build the path ""gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt"". It may refer to a filesystem not supported by this instance of Cromwell. Supported filesystems are: HTTP, LinuxFileSystem. Failures: HTTP: gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt does not have an http or https scheme (IllegalArgumentException); ```. Isn't cromwell supposed to handle `gs://` URLs for localizing files? Do you have any thoughts?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5872#issuecomment-481836556
https://github.com/broadinstitute/gatk/pull/5872#issuecomment-481836556:1102,Availability,Failure,Failures,1102,"@LeeTL1220 . This seems to be running into a cromwell / WDL error:. ```; java.lang.IllegalArgumentException: Could not build the path ""gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt"". It may refer to a filesystem not supported by this instance of Cromwell. Supported filesystems are: HTTP, LinuxFileSystem. Failures: HTTP: gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt does not have an http or https scheme (IllegalArgumentException); LinuxFileSystem: Cannot build a local path from gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt (RuntimeException) Please refer to the documentation for more information on how to configure filesystems: http://cromwell.readthedocs.io/en/develop/backends/HPC/#filesystems; 	Could not build the path ""gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt"". It may refer to a filesystem not supported by this instance of Cromwell. Supported filesystems are: HTTP, LinuxFileSystem. Failures: HTTP: gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt does not have an http or https scheme (IllegalArgumentException); ```. Isn't cromwell supposed to handle `gs://` URLs for localizing files? Do you have any thoughts?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5872#issuecomment-481836556
https://github.com/broadinstitute/gatk/pull/5872#issuecomment-481836556:762,Modifiability,config,configure,762,"@LeeTL1220 . This seems to be running into a cromwell / WDL error:. ```; java.lang.IllegalArgumentException: Could not build the path ""gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt"". It may refer to a filesystem not supported by this instance of Cromwell. Supported filesystems are: HTTP, LinuxFileSystem. Failures: HTTP: gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt does not have an http or https scheme (IllegalArgumentException); LinuxFileSystem: Cannot build a local path from gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt (RuntimeException) Please refer to the documentation for more information on how to configure filesystems: http://cromwell.readthedocs.io/en/develop/backends/HPC/#filesystems; 	Could not build the path ""gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt"". It may refer to a filesystem not supported by this instance of Cromwell. Supported filesystems are: HTTP, LinuxFileSystem. Failures: HTTP: gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt does not have an http or https scheme (IllegalArgumentException); ```. Isn't cromwell supposed to handle `gs://` URLs for localizing files? Do you have any thoughts?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5872#issuecomment-481836556
https://github.com/broadinstitute/gatk/pull/5872#issuecomment-481853426:365,Availability,error,error,365,"Cromwell WDL tests are done on a local backend, so it cannot localize gs; paths. In other words, the WDL tests in travis need a local instance of; the file and to use that path in the json. On Wed, Apr 10, 2019 at 3:49 PM Jonn Smith <notifications@github.com> wrote:. > @LeeTL1220 <https://github.com/LeeTL1220>; >; > This seems to be running into a cromwell / WDL error:; >; > java.lang.IllegalArgumentException: Could not build the path ""gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt"". It may refer to a filesystem not supported by this instance of Cromwell. Supported filesystems are: HTTP, LinuxFileSystem. Failures: HTTP: gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt does not have an http or https scheme (IllegalArgumentException); > LinuxFileSystem: Cannot build a local path from gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt (RuntimeException) Please refer to the documentation for more information on how to configure filesystems: http://cromwell.readthedocs.io/en/develop/backends/HPC/#filesystems; > 	Could not build the path ""gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt"". It may refer to a filesystem not supported by this instance of Cromwell. Supported filesystems are: HTTP, LinuxFileSystem. Failures: HTTP: gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt does not have an http or https scheme (IllegalArgumentException); >; > Isn't cromwell supposed to handle gs:// URLs for localizing files? Do you; > have any thoughts?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/5872#issuecomment-481836556>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACDXk7Wd-RgMx2g-UPLNrvjettNMf9ixks5vfkA3gaJp",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5872#issuecomment-481853426
https://github.com/broadinstitute/gatk/pull/5872#issuecomment-481853426:661,Availability,Failure,Failures,661,"Cromwell WDL tests are done on a local backend, so it cannot localize gs; paths. In other words, the WDL tests in travis need a local instance of; the file and to use that path in the json. On Wed, Apr 10, 2019 at 3:49 PM Jonn Smith <notifications@github.com> wrote:. > @LeeTL1220 <https://github.com/LeeTL1220>; >; > This seems to be running into a cromwell / WDL error:; >; > java.lang.IllegalArgumentException: Could not build the path ""gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt"". It may refer to a filesystem not supported by this instance of Cromwell. Supported filesystems are: HTTP, LinuxFileSystem. Failures: HTTP: gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt does not have an http or https scheme (IllegalArgumentException); > LinuxFileSystem: Cannot build a local path from gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt (RuntimeException) Please refer to the documentation for more information on how to configure filesystems: http://cromwell.readthedocs.io/en/develop/backends/HPC/#filesystems; > 	Could not build the path ""gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt"". It may refer to a filesystem not supported by this instance of Cromwell. Supported filesystems are: HTTP, LinuxFileSystem. Failures: HTTP: gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt does not have an http or https scheme (IllegalArgumentException); >; > Isn't cromwell supposed to handle gs:// URLs for localizing files? Do you; > have any thoughts?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/5872#issuecomment-481836556>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACDXk7Wd-RgMx2g-UPLNrvjettNMf9ixks5vfkA3gaJp",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5872#issuecomment-481853426
https://github.com/broadinstitute/gatk/pull/5872#issuecomment-481853426:1411,Availability,Failure,Failures,1411,"vis need a local instance of; the file and to use that path in the json. On Wed, Apr 10, 2019 at 3:49 PM Jonn Smith <notifications@github.com> wrote:. > @LeeTL1220 <https://github.com/LeeTL1220>; >; > This seems to be running into a cromwell / WDL error:; >; > java.lang.IllegalArgumentException: Could not build the path ""gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt"". It may refer to a filesystem not supported by this instance of Cromwell. Supported filesystems are: HTTP, LinuxFileSystem. Failures: HTTP: gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt does not have an http or https scheme (IllegalArgumentException); > LinuxFileSystem: Cannot build a local path from gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt (RuntimeException) Please refer to the documentation for more information on how to configure filesystems: http://cromwell.readthedocs.io/en/develop/backends/HPC/#filesystems; > 	Could not build the path ""gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt"". It may refer to a filesystem not supported by this instance of Cromwell. Supported filesystems are: HTTP, LinuxFileSystem. Failures: HTTP: gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt does not have an http or https scheme (IllegalArgumentException); >; > Isn't cromwell supposed to handle gs:// URLs for localizing files? Do you; > have any thoughts?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/5872#issuecomment-481836556>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACDXk7Wd-RgMx2g-UPLNrvjettNMf9ixks5vfkA3gaJpZM4clLLK>; > .; >. -- ; Lee Lichtenstein; Broad Institute; 105 Broadway, Room 332; Cambridge, MA 02142; 617 714 8632",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5872#issuecomment-481853426
https://github.com/broadinstitute/gatk/pull/5872#issuecomment-481853426:1069,Modifiability,config,configure,1069,"nd, so it cannot localize gs; paths. In other words, the WDL tests in travis need a local instance of; the file and to use that path in the json. On Wed, Apr 10, 2019 at 3:49 PM Jonn Smith <notifications@github.com> wrote:. > @LeeTL1220 <https://github.com/LeeTL1220>; >; > This seems to be running into a cromwell / WDL error:; >; > java.lang.IllegalArgumentException: Could not build the path ""gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt"". It may refer to a filesystem not supported by this instance of Cromwell. Supported filesystems are: HTTP, LinuxFileSystem. Failures: HTTP: gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt does not have an http or https scheme (IllegalArgumentException); > LinuxFileSystem: Cannot build a local path from gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt (RuntimeException) Please refer to the documentation for more information on how to configure filesystems: http://cromwell.readthedocs.io/en/develop/backends/HPC/#filesystems; > 	Could not build the path ""gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt"". It may refer to a filesystem not supported by this instance of Cromwell. Supported filesystems are: HTTP, LinuxFileSystem. Failures: HTTP: gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt does not have an http or https scheme (IllegalArgumentException); >; > Isn't cromwell supposed to handle gs:// URLs for localizing files? Do you; > have any thoughts?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/5872#issuecomment-481836556>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACDXk7Wd-RgMx2g-UPLNrvjettNMf9ixks5vfkA3gaJpZM4clLLK>; > .; >. -- ; Lee Lichtenstein; Br",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5872#issuecomment-481853426
https://github.com/broadinstitute/gatk/pull/5872#issuecomment-481853426:13,Testability,test,tests,13,"Cromwell WDL tests are done on a local backend, so it cannot localize gs; paths. In other words, the WDL tests in travis need a local instance of; the file and to use that path in the json. On Wed, Apr 10, 2019 at 3:49 PM Jonn Smith <notifications@github.com> wrote:. > @LeeTL1220 <https://github.com/LeeTL1220>; >; > This seems to be running into a cromwell / WDL error:; >; > java.lang.IllegalArgumentException: Could not build the path ""gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt"". It may refer to a filesystem not supported by this instance of Cromwell. Supported filesystems are: HTTP, LinuxFileSystem. Failures: HTTP: gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt does not have an http or https scheme (IllegalArgumentException); > LinuxFileSystem: Cannot build a local path from gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt (RuntimeException) Please refer to the documentation for more information on how to configure filesystems: http://cromwell.readthedocs.io/en/develop/backends/HPC/#filesystems; > 	Could not build the path ""gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt"". It may refer to a filesystem not supported by this instance of Cromwell. Supported filesystems are: HTTP, LinuxFileSystem. Failures: HTTP: gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt does not have an http or https scheme (IllegalArgumentException); >; > Isn't cromwell supposed to handle gs:// URLs for localizing files? Do you; > have any thoughts?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/5872#issuecomment-481836556>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACDXk7Wd-RgMx2g-UPLNrvjettNMf9ixks5vfkA3gaJp",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5872#issuecomment-481853426
https://github.com/broadinstitute/gatk/pull/5872#issuecomment-481853426:105,Testability,test,tests,105,"Cromwell WDL tests are done on a local backend, so it cannot localize gs; paths. In other words, the WDL tests in travis need a local instance of; the file and to use that path in the json. On Wed, Apr 10, 2019 at 3:49 PM Jonn Smith <notifications@github.com> wrote:. > @LeeTL1220 <https://github.com/LeeTL1220>; >; > This seems to be running into a cromwell / WDL error:; >; > java.lang.IllegalArgumentException: Could not build the path ""gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt"". It may refer to a filesystem not supported by this instance of Cromwell. Supported filesystems are: HTTP, LinuxFileSystem. Failures: HTTP: gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt does not have an http or https scheme (IllegalArgumentException); > LinuxFileSystem: Cannot build a local path from gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt (RuntimeException) Please refer to the documentation for more information on how to configure filesystems: http://cromwell.readthedocs.io/en/develop/backends/HPC/#filesystems; > 	Could not build the path ""gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt"". It may refer to a filesystem not supported by this instance of Cromwell. Supported filesystems are: HTTP, LinuxFileSystem. Failures: HTTP: gs://broad-public-datasets/funcotator/transcriptList.exact_uniprot_matches.AKT1_CRLF2_FGFR1.txt does not have an http or https scheme (IllegalArgumentException); >; > Isn't cromwell supposed to handle gs:// URLs for localizing files? Do you; > have any thoughts?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/5872#issuecomment-481836556>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACDXk7Wd-RgMx2g-UPLNrvjettNMf9ixks5vfkA3gaJp",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5872#issuecomment-481853426
https://github.com/broadinstitute/gatk/pull/5872#issuecomment-482299167:134,Testability,test,testing,134,"@LeeTL1220 OK, so what do you recommend then? I don't want to have to embed this in the docker image for GATK, but it sounds like for testing we might have to.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5872#issuecomment-482299167
https://github.com/broadinstitute/gatk/pull/5872#issuecomment-482300908:286,Testability,test,testing,286,"You can put it in the repo, I believe. On Thu, Apr 11, 2019, 16:29 Jonn Smith <notifications@github.com> wrote:. > @LeeTL1220 <https://github.com/LeeTL1220> OK, so what do you recommend; > then? I don't want to have to embed this in the docker image for GATK, but; > it sounds like for testing we might have to.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/5872#issuecomment-482299167>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACDXk6YB_G_IQS7pSBv1nd4Rqh9mfrGVks5vf5sKgaJpZM4clLLK>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5872#issuecomment-482300908
https://github.com/broadinstitute/gatk/pull/5872#issuecomment-482416039:103,Availability,avail,available,103,"Sure, but then where would the WDL point? If the purpose for this PR was to make the WDL default to an available version of the file, that's done but it's pointing to that file on GCS. Maybe I'm missing something, but it seems like we can't test this with Travis and have the default location point to the actual GCS bucket holding the transcript list...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5872#issuecomment-482416039
https://github.com/broadinstitute/gatk/pull/5872#issuecomment-482416039:241,Testability,test,test,241,"Sure, but then where would the WDL point? If the purpose for this PR was to make the WDL default to an available version of the file, that's done but it's pointing to that file on GCS. Maybe I'm missing something, but it seems like we can't test this with Travis and have the default location point to the actual GCS bucket holding the transcript list...",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5872#issuecomment-482416039
https://github.com/broadinstitute/gatk/pull/5872#issuecomment-482550732:446,Availability,avail,available,446,"You will not be able to test that the default is correct (yet). There is; another issue filed to do WDL tests in the Cloud. We can test this in Travis, with a specified file, no problem. You put the; location in the json file. That would at least be a smoke test. On Thu, Apr 11, 2019, 22:47 Jonn Smith <notifications@github.com> wrote:. > Sure, but then where would the WDL point? If the purpose for this PR was; > to make the WDL default to an available version of the file, that's done; > but it's pointing to that file on GCS.; >; > Maybe I'm missing something, but it seems like we can't test this with; > Travis and have the default location point to the actual GCS bucket holding; > the transcript list...; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/5872#issuecomment-482416039>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACDXkw9BTAu022H6AQ01NZ8no730mVgAks5vf_PEgaJpZM4clLLK>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5872#issuecomment-482550732
https://github.com/broadinstitute/gatk/pull/5872#issuecomment-482550732:24,Testability,test,test,24,"You will not be able to test that the default is correct (yet). There is; another issue filed to do WDL tests in the Cloud. We can test this in Travis, with a specified file, no problem. You put the; location in the json file. That would at least be a smoke test. On Thu, Apr 11, 2019, 22:47 Jonn Smith <notifications@github.com> wrote:. > Sure, but then where would the WDL point? If the purpose for this PR was; > to make the WDL default to an available version of the file, that's done; > but it's pointing to that file on GCS.; >; > Maybe I'm missing something, but it seems like we can't test this with; > Travis and have the default location point to the actual GCS bucket holding; > the transcript list...; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/5872#issuecomment-482416039>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACDXkw9BTAu022H6AQ01NZ8no730mVgAks5vf_PEgaJpZM4clLLK>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5872#issuecomment-482550732
https://github.com/broadinstitute/gatk/pull/5872#issuecomment-482550732:104,Testability,test,tests,104,"You will not be able to test that the default is correct (yet). There is; another issue filed to do WDL tests in the Cloud. We can test this in Travis, with a specified file, no problem. You put the; location in the json file. That would at least be a smoke test. On Thu, Apr 11, 2019, 22:47 Jonn Smith <notifications@github.com> wrote:. > Sure, but then where would the WDL point? If the purpose for this PR was; > to make the WDL default to an available version of the file, that's done; > but it's pointing to that file on GCS.; >; > Maybe I'm missing something, but it seems like we can't test this with; > Travis and have the default location point to the actual GCS bucket holding; > the transcript list...; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/5872#issuecomment-482416039>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACDXkw9BTAu022H6AQ01NZ8no730mVgAks5vf_PEgaJpZM4clLLK>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5872#issuecomment-482550732
https://github.com/broadinstitute/gatk/pull/5872#issuecomment-482550732:131,Testability,test,test,131,"You will not be able to test that the default is correct (yet). There is; another issue filed to do WDL tests in the Cloud. We can test this in Travis, with a specified file, no problem. You put the; location in the json file. That would at least be a smoke test. On Thu, Apr 11, 2019, 22:47 Jonn Smith <notifications@github.com> wrote:. > Sure, but then where would the WDL point? If the purpose for this PR was; > to make the WDL default to an available version of the file, that's done; > but it's pointing to that file on GCS.; >; > Maybe I'm missing something, but it seems like we can't test this with; > Travis and have the default location point to the actual GCS bucket holding; > the transcript list...; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/5872#issuecomment-482416039>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACDXkw9BTAu022H6AQ01NZ8no730mVgAks5vf_PEgaJpZM4clLLK>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5872#issuecomment-482550732
https://github.com/broadinstitute/gatk/pull/5872#issuecomment-482550732:258,Testability,test,test,258,"You will not be able to test that the default is correct (yet). There is; another issue filed to do WDL tests in the Cloud. We can test this in Travis, with a specified file, no problem. You put the; location in the json file. That would at least be a smoke test. On Thu, Apr 11, 2019, 22:47 Jonn Smith <notifications@github.com> wrote:. > Sure, but then where would the WDL point? If the purpose for this PR was; > to make the WDL default to an available version of the file, that's done; > but it's pointing to that file on GCS.; >; > Maybe I'm missing something, but it seems like we can't test this with; > Travis and have the default location point to the actual GCS bucket holding; > the transcript list...; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/5872#issuecomment-482416039>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACDXkw9BTAu022H6AQ01NZ8no730mVgAks5vf_PEgaJpZM4clLLK>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5872#issuecomment-482550732
https://github.com/broadinstitute/gatk/pull/5872#issuecomment-482550732:593,Testability,test,test,593,"You will not be able to test that the default is correct (yet). There is; another issue filed to do WDL tests in the Cloud. We can test this in Travis, with a specified file, no problem. You put the; location in the json file. That would at least be a smoke test. On Thu, Apr 11, 2019, 22:47 Jonn Smith <notifications@github.com> wrote:. > Sure, but then where would the WDL point? If the purpose for this PR was; > to make the WDL default to an available version of the file, that's done; > but it's pointing to that file on GCS.; >; > Maybe I'm missing something, but it seems like we can't test this with; > Travis and have the default location point to the actual GCS bucket holding; > the transcript list...; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/pull/5872#issuecomment-482416039>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACDXkw9BTAu022H6AQ01NZ8no730mVgAks5vf_PEgaJpZM4clLLK>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5872#issuecomment-482550732
https://github.com/broadinstitute/gatk/pull/5872#issuecomment-483668246:69,Modifiability,variab,variable,69,But that smoke test doesn't actually test any new functionality. The variable was there in the WDL before and was already being used - it just had no default value.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5872#issuecomment-483668246
https://github.com/broadinstitute/gatk/pull/5872#issuecomment-483668246:15,Testability,test,test,15,But that smoke test doesn't actually test any new functionality. The variable was there in the WDL before and was already being used - it just had no default value.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5872#issuecomment-483668246
https://github.com/broadinstitute/gatk/pull/5872#issuecomment-483668246:37,Testability,test,test,37,But that smoke test doesn't actually test any new functionality. The variable was there in the WDL before and was already being used - it just had no default value.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5872#issuecomment-483668246
https://github.com/broadinstitute/gatk/pull/5872#issuecomment-494397877:80,Testability,test,tests,80,@LeeTL1220 Did we decide to merge this so that it can be in and assume that the tests we have done are good enough for it?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5872#issuecomment-494397877
https://github.com/broadinstitute/gatk/issues/5877#issuecomment-482556548:0,Deployability,Update,Update,0,"Update: it appears that SortSamSparkIntegration.testSortBAMsSharded fails locally for me even on master (when run from intellij or from gradle), so that issue appears to be unrelated to the htsjdk upgrade.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5877#issuecomment-482556548
https://github.com/broadinstitute/gatk/issues/5877#issuecomment-482556548:197,Deployability,upgrade,upgrade,197,"Update: it appears that SortSamSparkIntegration.testSortBAMsSharded fails locally for me even on master (when run from intellij or from gradle), so that issue appears to be unrelated to the htsjdk upgrade.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5877#issuecomment-482556548
https://github.com/broadinstitute/gatk/issues/5877#issuecomment-482556548:48,Testability,test,testSortBAMsSharded,48,"Update: it appears that SortSamSparkIntegration.testSortBAMsSharded fails locally for me even on master (when run from intellij or from gradle), so that issue appears to be unrelated to the htsjdk upgrade.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5877#issuecomment-482556548
https://github.com/broadinstitute/gatk/pull/5879#issuecomment-482624658:1181,Deployability,pipeline,pipelines,1181,/5879?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/8ab6604e7d91ed8885ef639fa9f00431d23464cf?src=pr&el=desc) will **not change** coverage.; > The diff coverage is `100%`. ```diff; @@ Coverage Diff @@; ## master #5879 +/- ##; ===========================================; Coverage 86.833% 86.833% ; - Complexity 32292 32293 +1 ; ===========================================; Files 1990 1990 ; Lines 149107 149107 ; Branches 16477 16477 ; ===========================================; Hits 129474 129474 ; Misses 13621 13621 ; Partials 6012 6012; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5879?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...te/hellbender/tools/CountReadsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5879/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9Db3VudFJlYWRzSW50ZWdyYXRpb25UZXN0LmphdmE=) | `91.837% <100%> (ø)` | `11 <0> (ø)` | :arrow_down: |; | [...park/pipelines/CountReadsSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5879/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvQ291bnRSZWFkc1NwYXJrSW50ZWdyYXRpb25UZXN0LmphdmE=) | `98.246% <100%> (ø)` | `9 <0> (ø)` | :arrow_down: |; | [...lotypecaller/readthreading/ReadThreadingGraph.java](https://codecov.io/gh/broadinstitute/gatk/pull/5879/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9yZWFkdGhyZWFkaW5nL1JlYWRUaHJlYWRpbmdHcmFwaC5qYXZh) | `88.725% <0%> (-0.245%)` | `159% <0%> (ø)` | |; | [...nder/utils/runtime/StreamingProcessController.java](https://codecov.io/gh/broadinstitute/gatk/pull/5879/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9ydW50aW1lL1N0cmVhbWluZ1Byb2Nlc3NDb250cm9sbGVyLmphdmE=) | `67.773% <0%> (+0.474%)` | `33% <0%> (ø)` | :arrow_down: |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5879#issuecomment-482624658
https://github.com/broadinstitute/gatk/issues/5880#issuecomment-483083056:76,Availability,error,error,76,"@droazen We have a couple of merged PRs, #5873 and #5853, between which the error should not be thrown in the next minor release. However, this does not change the fact that **users should never, ever, run the Mutect2 pipeline with an unmatched tumor-normal pair.** When there is no matched normal, one should run it in tumor-only mode with a panel of normals.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5880#issuecomment-483083056
https://github.com/broadinstitute/gatk/issues/5880#issuecomment-483083056:121,Deployability,release,release,121,"@droazen We have a couple of merged PRs, #5873 and #5853, between which the error should not be thrown in the next minor release. However, this does not change the fact that **users should never, ever, run the Mutect2 pipeline with an unmatched tumor-normal pair.** When there is no matched normal, one should run it in tumor-only mode with a panel of normals.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5880#issuecomment-483083056
https://github.com/broadinstitute/gatk/issues/5880#issuecomment-483083056:218,Deployability,pipeline,pipeline,218,"@droazen We have a couple of merged PRs, #5873 and #5853, between which the error should not be thrown in the next minor release. However, this does not change the fact that **users should never, ever, run the Mutect2 pipeline with an unmatched tumor-normal pair.** When there is no matched normal, one should run it in tumor-only mode with a panel of normals.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5880#issuecomment-483083056
https://github.com/broadinstitute/gatk/issues/5880#issuecomment-483083398:26,Security,expose,exposed,26,I'm kind of glad that 4.1 exposed this because previously unmatched pairs were silently giving wildly-inflated contamination estimates.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5880#issuecomment-483083398
https://github.com/broadinstitute/gatk/issues/5880#issuecomment-483276300:163,Availability,error,error,163,"This can occur in cases where there was a mixup with the samples, meaning the user intended to run a properly matched normal/tumor pair, but there is a provenance error. This is how @asmoe4 and myself hit this issue. So this is not the same use case as #5821, where they know there's a deliberate mismatch. While we're not expecting the contamination check to provide something sensible in this case, may I suggest that the tool provides a user-friendly message to help debug, rather than a stack traceback. This could happen to other people if they have an accidental mismatch.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5880#issuecomment-483276300
https://github.com/broadinstitute/gatk/issues/5880#issuecomment-483276300:454,Integrability,message,message,454,"This can occur in cases where there was a mixup with the samples, meaning the user intended to run a properly matched normal/tumor pair, but there is a provenance error. This is how @asmoe4 and myself hit this issue. So this is not the same use case as #5821, where they know there's a deliberate mismatch. While we're not expecting the contamination check to provide something sensible in this case, may I suggest that the tool provides a user-friendly message to help debug, rather than a stack traceback. This could happen to other people if they have an accidental mismatch.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5880#issuecomment-483276300
https://github.com/broadinstitute/gatk/issues/5880#issuecomment-483276300:440,Usability,user-friendly,user-friendly,440,"This can occur in cases where there was a mixup with the samples, meaning the user intended to run a properly matched normal/tumor pair, but there is a provenance error. This is how @asmoe4 and myself hit this issue. So this is not the same use case as #5821, where they know there's a deliberate mismatch. While we're not expecting the contamination check to provide something sensible in this case, may I suggest that the tool provides a user-friendly message to help debug, rather than a stack traceback. This could happen to other people if they have an accidental mismatch.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5880#issuecomment-483276300
https://github.com/broadinstitute/gatk/issues/5882#issuecomment-482660586:133,Security,access,accesses,133,"Not in general, because prefetching isn't always desirable. By its nature it's designed for long sequential reads rather than random accesses. In GATK though there is prefetcher code in a FeatureDataSource constructor, so anyone who uses that one will get the prefetching.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5882#issuecomment-482660586
https://github.com/broadinstitute/gatk/issues/5882#issuecomment-482678256:24,Availability,down,down,24,"@yfarjoun We should sit down at some point to discuss the best way to activate the prefetching in Picard. It may be a little less trivial than I had thought based on the above, but should still be fairly simple.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5882#issuecomment-482678256
https://github.com/broadinstitute/gatk/issues/5882#issuecomment-482678256:204,Usability,simpl,simple,204,"@yfarjoun We should sit down at some point to discuss the best way to activate the prefetching in Picard. It may be a little less trivial than I had thought based on the above, but should still be fairly simple.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5882#issuecomment-482678256
https://github.com/broadinstitute/gatk/issues/5882#issuecomment-482678782:251,Availability,down,down,251,"but for fingerprinting it seems that since it is effectively random-access,; perhaps prefetching will not be worth it?. On Fri, Apr 12, 2019 at 2:32 PM droazen <notifications@github.com> wrote:. > @yfarjoun <https://github.com/yfarjoun> We should sit down at some point; > to discuss the best way to activate the prefetching in Picard. It may be a; > little less trivial than I had thought based on the above, but should still; > be fairly simple.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/5882#issuecomment-482678256>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACnk0ptBXdOQ-9HlXMjjpFHI_zp-cQJqks5vgNEzgaJpZM4csje4>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5882#issuecomment-482678782
https://github.com/broadinstitute/gatk/issues/5882#issuecomment-482678782:68,Security,access,access,68,"but for fingerprinting it seems that since it is effectively random-access,; perhaps prefetching will not be worth it?. On Fri, Apr 12, 2019 at 2:32 PM droazen <notifications@github.com> wrote:. > @yfarjoun <https://github.com/yfarjoun> We should sit down at some point; > to discuss the best way to activate the prefetching in Picard. It may be a; > little less trivial than I had thought based on the above, but should still; > be fairly simple.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/5882#issuecomment-482678256>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACnk0ptBXdOQ-9HlXMjjpFHI_zp-cQJqks5vgNEzgaJpZM4csje4>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5882#issuecomment-482678782
https://github.com/broadinstitute/gatk/issues/5882#issuecomment-482678782:440,Usability,simpl,simple,440,"but for fingerprinting it seems that since it is effectively random-access,; perhaps prefetching will not be worth it?. On Fri, Apr 12, 2019 at 2:32 PM droazen <notifications@github.com> wrote:. > @yfarjoun <https://github.com/yfarjoun> We should sit down at some point; > to discuss the best way to activate the prefetching in Picard. It may be a; > little less trivial than I had thought based on the above, but should still; > be fairly simple.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/broadinstitute/gatk/issues/5882#issuecomment-482678256>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/ACnk0ptBXdOQ-9HlXMjjpFHI_zp-cQJqks5vgNEzgaJpZM4csje4>; > .; >",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5882#issuecomment-482678782
https://github.com/broadinstitute/gatk/issues/5882#issuecomment-482681722:140,Security,access,access,140,"@yfarjoun Well, as I said in person I believe that there are benefits to running with asynchronous prefetching turned on even in the random-access case. @jean-philippe-martin can confirm.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5882#issuecomment-482681722
https://github.com/broadinstitute/gatk/issues/5882#issuecomment-482689496:77,Security,access,access,77,"It's true that our measurements have shown some improvement even in a random access case. Surely we should be able to fabricate a more extreme case where prefetching doesn't help, so it still makes sense to offer a choice.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5882#issuecomment-482689496
https://github.com/broadinstitute/gatk/pull/5883#issuecomment-484644408:42,Deployability,update,updateCountsForPair,42,Maybe combineReports should be renamed to updateCountsForPair? Would that be better?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5883#issuecomment-484644408
https://github.com/broadinstitute/gatk/pull/5886#issuecomment-483848263:94,Deployability,pipeline,pipeline,94,"@samuelklee or @mwalker174 please review, as this feature originated as a request for the CNV pipeline (https://github.com/broadinstitute/gatk/issues/5884)",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5886#issuecomment-483848263
https://github.com/broadinstitute/gatk/pull/5887#issuecomment-483884075:232,Availability,error,error-reference,232,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5887?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@dcff818`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `92.708%`. ```diff; @@ Coverage Diff @@; ## master #5887 +/- ##; ==========================================; Coverage ? 86.825% ; Complexity ? 32305 ; ==========================================; Files ? 1991 ; Lines ? 149187 ; Branches ? 16484 ; ==========================================; Hits ? 129531 ; Misses ? 13641 ; Partials ? 6015; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5887?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...titute/hellbender/utils/IntervalUtilsUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5887/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9JbnRlcnZhbFV0aWxzVW5pdFRlc3QuamF2YQ==) | `91.906% <100%> (ø)` | `146 <0> (?)` | |; | [...nstitute/hellbender/utils/IntervalMergingRule.java](https://codecov.io/gh/broadinstitute/gatk/pull/5887/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9JbnRlcnZhbE1lcmdpbmdSdWxlLmphdmE=) | `100% <100%> (ø)` | `1 <0> (?)` | |; | [...broadinstitute/hellbender/utils/IntervalUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5887/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9JbnRlcnZhbFV0aWxzLmphdmE=) | `92.083% <100%> (ø)` | `192 <4> (?)` | |; | [...rgumentcollections/IntervalArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/5887/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL2FyZ3VtZW50Y29sbGVjdGlvbnMvSW50ZXJ2YWxBcmd1bWVudENvbGxlY3Rpb24uamF2YQ==) | `89.063% <88.636%> (ø)` | `24 <1> (?)` | |; | [...entcollections/IntervalArgumentCollectionTest.java](,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5887#issuecomment-483884075
https://github.com/broadinstitute/gatk/pull/5887#issuecomment-483884075:180,Usability,learn,learn,180,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5887?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@dcff818`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `92.708%`. ```diff; @@ Coverage Diff @@; ## master #5887 +/- ##; ==========================================; Coverage ? 86.825% ; Complexity ? 32305 ; ==========================================; Files ? 1991 ; Lines ? 149187 ; Branches ? 16484 ; ==========================================; Hits ? 129531 ; Misses ? 13641 ; Partials ? 6015; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5887?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...titute/hellbender/utils/IntervalUtilsUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5887/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9JbnRlcnZhbFV0aWxzVW5pdFRlc3QuamF2YQ==) | `91.906% <100%> (ø)` | `146 <0> (?)` | |; | [...nstitute/hellbender/utils/IntervalMergingRule.java](https://codecov.io/gh/broadinstitute/gatk/pull/5887/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9JbnRlcnZhbE1lcmdpbmdSdWxlLmphdmE=) | `100% <100%> (ø)` | `1 <0> (?)` | |; | [...broadinstitute/hellbender/utils/IntervalUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5887/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9JbnRlcnZhbFV0aWxzLmphdmE=) | `92.083% <100%> (ø)` | `192 <4> (?)` | |; | [...rgumentcollections/IntervalArgumentCollection.java](https://codecov.io/gh/broadinstitute/gatk/pull/5887/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9jbWRsaW5lL2FyZ3VtZW50Y29sbGVjdGlvbnMvSW50ZXJ2YWxBcmd1bWVudENvbGxlY3Rpb24uamF2YQ==) | `89.063% <88.636%> (ø)` | `24 <1> (?)` | |; | [...entcollections/IntervalArgumentCollectionTest.java](,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5887#issuecomment-483884075
https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567634113:253,Integrability,interface,interface,253,"@lbergelson In your opinion, how likely is this feature to cause problems? We do still call `QueryInterval.optimizeIntervals()` to merge intervals in `ReadsDataSource` before starting an iteration, and I think that's the main example of an HTSJDK query interface that can't handle overlapping intervals.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567634113
https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567634113:107,Performance,optimiz,optimizeIntervals,107,"@lbergelson In your opinion, how likely is this feature to cause problems? We do still call `QueryInterval.optimizeIntervals()` to merge intervals in `ReadsDataSource` before starting an iteration, and I think that's the main example of an HTSJDK query interface that can't handle overlapping intervals.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567634113
https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567666730:129,Security,expose,exposed,129,"Alright, I think I am in agreement with you @lbergelson about this behavior. Furthermore, all I needed out of this branch was an exposed mechanism for getting back the un-merged intervals so that I can track them myself in subtools. To that end I think I'm going to keep this branch and its tests and get rid of the merging rule argument in favor of leaving the logic for merging in place to be accessed by tools.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567666730
https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567666730:395,Security,access,accessed,395,"Alright, I think I am in agreement with you @lbergelson about this behavior. Furthermore, all I needed out of this branch was an exposed mechanism for getting back the un-merged intervals so that I can track them myself in subtools. To that end I think I'm going to keep this branch and its tests and get rid of the merging rule argument in favor of leaving the logic for merging in place to be accessed by tools.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567666730
https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567666730:291,Testability,test,tests,291,"Alright, I think I am in agreement with you @lbergelson about this behavior. Furthermore, all I needed out of this branch was an exposed mechanism for getting back the un-merged intervals so that I can track them myself in subtools. To that end I think I'm going to keep this branch and its tests and get rid of the merging rule argument in favor of leaving the logic for merging in place to be accessed by tools.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567666730
https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567666730:362,Testability,log,logic,362,"Alright, I think I am in agreement with you @lbergelson about this behavior. Furthermore, all I needed out of this branch was an exposed mechanism for getting back the un-merged intervals so that I can track them myself in subtools. To that end I think I'm going to keep this branch and its tests and get rid of the merging rule argument in favor of leaving the logic for merging in place to be accessed by tools.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567666730
https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567697957:20,Availability,failure,failures,20,Travis reported job failures from build [28430](https://travis-ci.com/broadinstitute/gatk/builds/141829192); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28430.13](https://travis-ci.com/broadinstitute/gatk/jobs/269090751) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28430.13/tests/test/index.html) |; | unit | openjdk8 | [28430.3](https://travis-ci.com/broadinstitute/gatk/jobs/269090740) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28430.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567697957
https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567697957:109,Availability,Failure,Failures,109,Travis reported job failures from build [28430](https://travis-ci.com/broadinstitute/gatk/builds/141829192); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28430.13](https://travis-ci.com/broadinstitute/gatk/jobs/269090751) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28430.13/tests/test/index.html) |; | unit | openjdk8 | [28430.3](https://travis-ci.com/broadinstitute/gatk/jobs/269090740) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28430.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567697957
https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567697957:144,Testability,Test,Test,144,Travis reported job failures from build [28430](https://travis-ci.com/broadinstitute/gatk/builds/141829192); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28430.13](https://travis-ci.com/broadinstitute/gatk/jobs/269090751) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28430.13/tests/test/index.html) |; | unit | openjdk8 | [28430.3](https://travis-ci.com/broadinstitute/gatk/jobs/269090740) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28430.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567697957
https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567697957:171,Testability,Log,Logs,171,Travis reported job failures from build [28430](https://travis-ci.com/broadinstitute/gatk/builds/141829192); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28430.13](https://travis-ci.com/broadinstitute/gatk/jobs/269090751) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28430.13/tests/test/index.html) |; | unit | openjdk8 | [28430.3](https://travis-ci.com/broadinstitute/gatk/jobs/269090740) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28430.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567697957
https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567697957:309,Testability,log,logs,309,Travis reported job failures from build [28430](https://travis-ci.com/broadinstitute/gatk/builds/141829192); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28430.13](https://travis-ci.com/broadinstitute/gatk/jobs/269090751) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28430.13/tests/test/index.html) |; | unit | openjdk8 | [28430.3](https://travis-ci.com/broadinstitute/gatk/jobs/269090740) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28430.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567697957
https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567697957:357,Testability,test,test-logs,357,Travis reported job failures from build [28430](https://travis-ci.com/broadinstitute/gatk/builds/141829192); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28430.13](https://travis-ci.com/broadinstitute/gatk/jobs/269090751) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28430.13/tests/test/index.html) |; | unit | openjdk8 | [28430.3](https://travis-ci.com/broadinstitute/gatk/jobs/269090740) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28430.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567697957
https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567697957:397,Testability,test,tests,397,Travis reported job failures from build [28430](https://travis-ci.com/broadinstitute/gatk/builds/141829192); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28430.13](https://travis-ci.com/broadinstitute/gatk/jobs/269090751) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28430.13/tests/test/index.html) |; | unit | openjdk8 | [28430.3](https://travis-ci.com/broadinstitute/gatk/jobs/269090740) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28430.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567697957
https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567697957:403,Testability,test,test,403,Travis reported job failures from build [28430](https://travis-ci.com/broadinstitute/gatk/builds/141829192); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28430.13](https://travis-ci.com/broadinstitute/gatk/jobs/269090751) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28430.13/tests/test/index.html) |; | unit | openjdk8 | [28430.3](https://travis-ci.com/broadinstitute/gatk/jobs/269090740) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28430.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567697957
https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567697957:514,Testability,log,logs,514,Travis reported job failures from build [28430](https://travis-ci.com/broadinstitute/gatk/builds/141829192); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28430.13](https://travis-ci.com/broadinstitute/gatk/jobs/269090751) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28430.13/tests/test/index.html) |; | unit | openjdk8 | [28430.3](https://travis-ci.com/broadinstitute/gatk/jobs/269090740) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28430.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567697957
https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567697957:562,Testability,test,test-logs,562,Travis reported job failures from build [28430](https://travis-ci.com/broadinstitute/gatk/builds/141829192); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28430.13](https://travis-ci.com/broadinstitute/gatk/jobs/269090751) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28430.13/tests/test/index.html) |; | unit | openjdk8 | [28430.3](https://travis-ci.com/broadinstitute/gatk/jobs/269090740) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28430.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567697957
https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567697957:601,Testability,test,tests,601,Travis reported job failures from build [28430](https://travis-ci.com/broadinstitute/gatk/builds/141829192); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28430.13](https://travis-ci.com/broadinstitute/gatk/jobs/269090751) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28430.13/tests/test/index.html) |; | unit | openjdk8 | [28430.3](https://travis-ci.com/broadinstitute/gatk/jobs/269090740) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28430.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567697957
https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567697957:607,Testability,test,test,607,Travis reported job failures from build [28430](https://travis-ci.com/broadinstitute/gatk/builds/141829192); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28430.13](https://travis-ci.com/broadinstitute/gatk/jobs/269090751) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28430.13/tests/test/index.html) |; | unit | openjdk8 | [28430.3](https://travis-ci.com/broadinstitute/gatk/jobs/269090740) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28430.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567697957
https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567703763:20,Availability,failure,failures,20,Travis reported job failures from build [28433](https://travis-ci.com/broadinstitute/gatk/builds/141830744); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28433.13](https://travis-ci.com/broadinstitute/gatk/jobs/269094667) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28433.13/tests/test/index.html) |; | unit | openjdk8 | [28433.3](https://travis-ci.com/broadinstitute/gatk/jobs/269094657) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28433.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567703763
https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567703763:109,Availability,Failure,Failures,109,Travis reported job failures from build [28433](https://travis-ci.com/broadinstitute/gatk/builds/141830744); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28433.13](https://travis-ci.com/broadinstitute/gatk/jobs/269094667) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28433.13/tests/test/index.html) |; | unit | openjdk8 | [28433.3](https://travis-ci.com/broadinstitute/gatk/jobs/269094657) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28433.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567703763
https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567703763:144,Testability,Test,Test,144,Travis reported job failures from build [28433](https://travis-ci.com/broadinstitute/gatk/builds/141830744); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28433.13](https://travis-ci.com/broadinstitute/gatk/jobs/269094667) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28433.13/tests/test/index.html) |; | unit | openjdk8 | [28433.3](https://travis-ci.com/broadinstitute/gatk/jobs/269094657) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28433.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567703763
https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567703763:171,Testability,Log,Logs,171,Travis reported job failures from build [28433](https://travis-ci.com/broadinstitute/gatk/builds/141830744); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28433.13](https://travis-ci.com/broadinstitute/gatk/jobs/269094667) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28433.13/tests/test/index.html) |; | unit | openjdk8 | [28433.3](https://travis-ci.com/broadinstitute/gatk/jobs/269094657) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28433.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567703763
https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567703763:309,Testability,log,logs,309,Travis reported job failures from build [28433](https://travis-ci.com/broadinstitute/gatk/builds/141830744); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28433.13](https://travis-ci.com/broadinstitute/gatk/jobs/269094667) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28433.13/tests/test/index.html) |; | unit | openjdk8 | [28433.3](https://travis-ci.com/broadinstitute/gatk/jobs/269094657) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28433.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567703763
https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567703763:357,Testability,test,test-logs,357,Travis reported job failures from build [28433](https://travis-ci.com/broadinstitute/gatk/builds/141830744); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28433.13](https://travis-ci.com/broadinstitute/gatk/jobs/269094667) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28433.13/tests/test/index.html) |; | unit | openjdk8 | [28433.3](https://travis-ci.com/broadinstitute/gatk/jobs/269094657) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28433.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567703763
https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567703763:397,Testability,test,tests,397,Travis reported job failures from build [28433](https://travis-ci.com/broadinstitute/gatk/builds/141830744); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28433.13](https://travis-ci.com/broadinstitute/gatk/jobs/269094667) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28433.13/tests/test/index.html) |; | unit | openjdk8 | [28433.3](https://travis-ci.com/broadinstitute/gatk/jobs/269094657) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28433.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567703763
https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567703763:403,Testability,test,test,403,Travis reported job failures from build [28433](https://travis-ci.com/broadinstitute/gatk/builds/141830744); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28433.13](https://travis-ci.com/broadinstitute/gatk/jobs/269094667) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28433.13/tests/test/index.html) |; | unit | openjdk8 | [28433.3](https://travis-ci.com/broadinstitute/gatk/jobs/269094657) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28433.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567703763
https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567703763:514,Testability,log,logs,514,Travis reported job failures from build [28433](https://travis-ci.com/broadinstitute/gatk/builds/141830744); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28433.13](https://travis-ci.com/broadinstitute/gatk/jobs/269094667) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28433.13/tests/test/index.html) |; | unit | openjdk8 | [28433.3](https://travis-ci.com/broadinstitute/gatk/jobs/269094657) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28433.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567703763
https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567703763:562,Testability,test,test-logs,562,Travis reported job failures from build [28433](https://travis-ci.com/broadinstitute/gatk/builds/141830744); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28433.13](https://travis-ci.com/broadinstitute/gatk/jobs/269094667) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28433.13/tests/test/index.html) |; | unit | openjdk8 | [28433.3](https://travis-ci.com/broadinstitute/gatk/jobs/269094657) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28433.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567703763
https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567703763:601,Testability,test,tests,601,Travis reported job failures from build [28433](https://travis-ci.com/broadinstitute/gatk/builds/141830744); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28433.13](https://travis-ci.com/broadinstitute/gatk/jobs/269094667) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28433.13/tests/test/index.html) |; | unit | openjdk8 | [28433.3](https://travis-ci.com/broadinstitute/gatk/jobs/269094657) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28433.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567703763
https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567703763:607,Testability,test,test,607,Travis reported job failures from build [28433](https://travis-ci.com/broadinstitute/gatk/builds/141830744); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28433.13](https://travis-ci.com/broadinstitute/gatk/jobs/269094667) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28433.13/tests/test/index.html) |; | unit | openjdk8 | [28433.3](https://travis-ci.com/broadinstitute/gatk/jobs/269094657) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28433.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567703763
https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567706236:20,Availability,failure,failures,20,Travis reported job failures from build [28432](https://travis-ci.com/broadinstitute/gatk/builds/141830599); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28432.13](https://travis-ci.com/broadinstitute/gatk/jobs/269094367) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28432.13/tests/test/index.html) |; | unit | openjdk8 | [28432.3](https://travis-ci.com/broadinstitute/gatk/jobs/269094355) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28432.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567706236
https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567706236:109,Availability,Failure,Failures,109,Travis reported job failures from build [28432](https://travis-ci.com/broadinstitute/gatk/builds/141830599); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28432.13](https://travis-ci.com/broadinstitute/gatk/jobs/269094367) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28432.13/tests/test/index.html) |; | unit | openjdk8 | [28432.3](https://travis-ci.com/broadinstitute/gatk/jobs/269094355) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28432.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567706236
https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567706236:144,Testability,Test,Test,144,Travis reported job failures from build [28432](https://travis-ci.com/broadinstitute/gatk/builds/141830599); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28432.13](https://travis-ci.com/broadinstitute/gatk/jobs/269094367) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28432.13/tests/test/index.html) |; | unit | openjdk8 | [28432.3](https://travis-ci.com/broadinstitute/gatk/jobs/269094355) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28432.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567706236
https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567706236:171,Testability,Log,Logs,171,Travis reported job failures from build [28432](https://travis-ci.com/broadinstitute/gatk/builds/141830599); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28432.13](https://travis-ci.com/broadinstitute/gatk/jobs/269094367) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28432.13/tests/test/index.html) |; | unit | openjdk8 | [28432.3](https://travis-ci.com/broadinstitute/gatk/jobs/269094355) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28432.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567706236
https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567706236:309,Testability,log,logs,309,Travis reported job failures from build [28432](https://travis-ci.com/broadinstitute/gatk/builds/141830599); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28432.13](https://travis-ci.com/broadinstitute/gatk/jobs/269094367) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28432.13/tests/test/index.html) |; | unit | openjdk8 | [28432.3](https://travis-ci.com/broadinstitute/gatk/jobs/269094355) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28432.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567706236
https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567706236:357,Testability,test,test-logs,357,Travis reported job failures from build [28432](https://travis-ci.com/broadinstitute/gatk/builds/141830599); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28432.13](https://travis-ci.com/broadinstitute/gatk/jobs/269094367) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28432.13/tests/test/index.html) |; | unit | openjdk8 | [28432.3](https://travis-ci.com/broadinstitute/gatk/jobs/269094355) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28432.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567706236
https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567706236:397,Testability,test,tests,397,Travis reported job failures from build [28432](https://travis-ci.com/broadinstitute/gatk/builds/141830599); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28432.13](https://travis-ci.com/broadinstitute/gatk/jobs/269094367) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28432.13/tests/test/index.html) |; | unit | openjdk8 | [28432.3](https://travis-ci.com/broadinstitute/gatk/jobs/269094355) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28432.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567706236
https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567706236:403,Testability,test,test,403,Travis reported job failures from build [28432](https://travis-ci.com/broadinstitute/gatk/builds/141830599); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28432.13](https://travis-ci.com/broadinstitute/gatk/jobs/269094367) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28432.13/tests/test/index.html) |; | unit | openjdk8 | [28432.3](https://travis-ci.com/broadinstitute/gatk/jobs/269094355) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28432.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567706236
https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567706236:514,Testability,log,logs,514,Travis reported job failures from build [28432](https://travis-ci.com/broadinstitute/gatk/builds/141830599); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28432.13](https://travis-ci.com/broadinstitute/gatk/jobs/269094367) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28432.13/tests/test/index.html) |; | unit | openjdk8 | [28432.3](https://travis-ci.com/broadinstitute/gatk/jobs/269094355) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28432.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567706236
https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567706236:562,Testability,test,test-logs,562,Travis reported job failures from build [28432](https://travis-ci.com/broadinstitute/gatk/builds/141830599); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28432.13](https://travis-ci.com/broadinstitute/gatk/jobs/269094367) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28432.13/tests/test/index.html) |; | unit | openjdk8 | [28432.3](https://travis-ci.com/broadinstitute/gatk/jobs/269094355) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28432.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567706236
https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567706236:601,Testability,test,tests,601,Travis reported job failures from build [28432](https://travis-ci.com/broadinstitute/gatk/builds/141830599); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28432.13](https://travis-ci.com/broadinstitute/gatk/jobs/269094367) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28432.13/tests/test/index.html) |; | unit | openjdk8 | [28432.3](https://travis-ci.com/broadinstitute/gatk/jobs/269094355) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28432.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567706236
https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567706236:607,Testability,test,test,607,Travis reported job failures from build [28432](https://travis-ci.com/broadinstitute/gatk/builds/141830599); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [28432.13](https://travis-ci.com/broadinstitute/gatk/jobs/269094367) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28432.13/tests/test/index.html) |; | unit | openjdk8 | [28432.3](https://travis-ci.com/broadinstitute/gatk/jobs/269094355) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28432.3/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567706236
https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567970124:48,Testability,test,test,48,@droazen I resolved your comments and fixed the test I broke. Can this be merged so we can move forward on that other branch?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5887#issuecomment-567970124
https://github.com/broadinstitute/gatk/issues/5889#issuecomment-484348592:87,Usability,clear,clear,87,"Or maybe I'm confused and the user can get either/or, based on the wdl? It wasn't very clear either way.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5889#issuecomment-484348592
https://github.com/broadinstitute/gatk/issues/5889#issuecomment-484355457:259,Availability,redundant,redundant,259,"@vdauwera I didn't even know that README existed. It's horribly out of date in a lot of ways. @LeeTL1220 Before I spend time fixing it, is there any way I could drastically shrink this file, like to 3 lines or so, or delete it entirely? I mean, most of it is redundant if you just read the WDL, and I really don't want to add maintenance of this README on top of Terra and the two official M2 wdls we still have to drag around.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5889#issuecomment-484355457
https://github.com/broadinstitute/gatk/issues/5889#issuecomment-484355457:326,Availability,mainten,maintenance,326,"@vdauwera I didn't even know that README existed. It's horribly out of date in a lot of ways. @LeeTL1220 Before I spend time fixing it, is there any way I could drastically shrink this file, like to 3 lines or so, or delete it entirely? I mean, most of it is redundant if you just read the WDL, and I really don't want to add maintenance of this README on top of Terra and the two official M2 wdls we still have to drag around.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5889#issuecomment-484355457
https://github.com/broadinstitute/gatk/issues/5889#issuecomment-484355457:259,Safety,redund,redundant,259,"@vdauwera I didn't even know that README existed. It's horribly out of date in a lot of ways. @LeeTL1220 Before I spend time fixing it, is there any way I could drastically shrink this file, like to 3 lines or so, or delete it entirely? I mean, most of it is redundant if you just read the WDL, and I really don't want to add maintenance of this README on top of Terra and the two official M2 wdls we still have to drag around.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5889#issuecomment-484355457
https://github.com/broadinstitute/gatk/issues/5889#issuecomment-484356108:41,Availability,redundant,redundant,41,I agree a lot of the detailed content is redundant and not worth maintaining in separate places. Reducing to 2 or 3 lines seems a bit too drastic though -- I would love to see something like a half-page high-level overview to serve as cliff notes for the WDL.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5889#issuecomment-484356108
https://github.com/broadinstitute/gatk/issues/5889#issuecomment-484356108:41,Safety,redund,redundant,41,I agree a lot of the detailed content is redundant and not worth maintaining in separate places. Reducing to 2 or 3 lines seems a bit too drastic though -- I would love to see something like a half-page high-level overview to serve as cliff notes for the WDL.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5889#issuecomment-484356108
https://github.com/broadinstitute/gatk/issues/5895#issuecomment-1039141762:35,Testability,test,test,35,"I recently rebased and re-ran this test. The results look similar to last time. The travis results can be found [here](https://app.travis-ci.com/github/broadinstitute/gatk/builds/246119278), while they last. The branch with the code is https://github.com/broadinstitute/gatk/tree/cn_cache_thrash_master.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5895#issuecomment-1039141762
https://github.com/broadinstitute/gatk/pull/5899#issuecomment-485579074:22,Testability,test,tests,22,"We have included unit tests for wildstar allele and the deletion spanning the interval in GenomicsDB. @ldgauthier, can you please confirm that this solves the issue?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5899#issuecomment-485579074
https://github.com/broadinstitute/gatk/issues/5900#issuecomment-485581517:87,Availability,error,error,87,@cmnbroad as discussed during gatk office hrs I created a github issue ticket for this error. Let me know if there is any other information you need from the user.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5900#issuecomment-485581517
https://github.com/broadinstitute/gatk/issues/5900#issuecomment-485873403:171,Deployability,configurat,configuration,171,"@bhanugandham As a side note, you shouldn't be running GATK4 using `java -jar` directly. You should use the included `gatk` launcher script, which sets a lot of important configuration settings, some of which have a major effect on tool performance.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5900#issuecomment-485873403
https://github.com/broadinstitute/gatk/issues/5900#issuecomment-485873403:171,Modifiability,config,configuration,171,"@bhanugandham As a side note, you shouldn't be running GATK4 using `java -jar` directly. You should use the included `gatk` launcher script, which sets a lot of important configuration settings, some of which have a major effect on tool performance.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5900#issuecomment-485873403
https://github.com/broadinstitute/gatk/issues/5900#issuecomment-485873403:237,Performance,perform,performance,237,"@bhanugandham As a side note, you shouldn't be running GATK4 using `java -jar` directly. You should use the included `gatk` launcher script, which sets a lot of important configuration settings, some of which have a major effect on tool performance.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5900#issuecomment-485873403
https://github.com/broadinstitute/gatk/issues/5900#issuecomment-541411050:21,Availability,error,error,21,I also run into this error. I am using the `gatk `launcher script. My command is `gatk Mutect2 -R /bio/bcbio/genomes/Hsapiens/hg38/seq/hg38.fa -I chenmeifang-ready.bam -max-mnp-distance 0 -O normal_1.vcf.gz`. Is there any method to work through this error?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5900#issuecomment-541411050
https://github.com/broadinstitute/gatk/issues/5900#issuecomment-541411050:250,Availability,error,error,250,I also run into this error. I am using the `gatk `launcher script. My command is `gatk Mutect2 -R /bio/bcbio/genomes/Hsapiens/hg38/seq/hg38.fa -I chenmeifang-ready.bam -max-mnp-distance 0 -O normal_1.vcf.gz`. Is there any method to work through this error?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5900#issuecomment-541411050
https://github.com/broadinstitute/gatk/issues/5900#issuecomment-541476068:144,Deployability,update,updated,144,"@bhanugandham ; I am just following gatk forum to here. I expect to find solution to go through this problem here, but this thread has not been updated for six months. So I post to ask for help.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5900#issuecomment-541476068
https://github.com/broadinstitute/gatk/issues/5900#issuecomment-582151637:105,Availability,error,error,105,@hliu2016 and @DeadlyDoll . Can you please share a problematic subset of the bam so we can recreate this error on our end. Also please post the version of GATK you are using.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5900#issuecomment-582151637
https://github.com/broadinstitute/gatk/issues/5900#issuecomment-612103255:79,Availability,error,error,79,"Hi y'all. I've been trying to run GATK GenotypeGVCFs but I keep encounter this error. I've increase memory but it does not seems to be enough. ; My script is ; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /gatk/gatk-package-4.0.6.0-local.jar GenotypeGVCFs -ploidy 1 -R /project/uma_john_gibbons/john_gibbons/AORY_AFLA/REF/Aspergillus_oryzae.ASM18445v3.dna.toplevel.fa -O /project/uma_john_gibbons/chacon_vargas/AOR-AFLA/GATK/4-Consolidate_GVCF/combined_Chr1.vcf -V gendb://Chr1/. Any thoughts?. 15:06:40.794 WARN InbreedingCoeff - Annotation will not be calculated, must provide at least 10 samples; 05:40:05.630 INFO GenotypeGVCFs - Shutting down engine; GENOMICSDB_TIMER,GenomicsDB iterator next() timer,Wall-clock time(s),2.0928187529999955,Cpu time(s),0.9772208090000016; [April 10, 2020 5:40:05 AM UTC] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 932.26 minutes.; Runtime.totalMemory()=31136546816; Exception in thread ""main"" java.lang.OutOfMemoryError: Java heap space; 	at org.broadinstitute.hellbender.tools.walkers.genotyper.GenotypeLikelihoodCalculator.<init>(GenotypeLikelihoodCalculator.java:153); 	at org.broadinstitute.hellbender.tools.walkers.genotyper.GenotypeLikelihoodCalculators.getInstance(GenotypeLikelihoodCalculators.java:269); 	at org.broadinstitute.hellbender.tools.walkers.genotyper.afcalc.GeneralPloidyExactAFCalculator.computeLofK(GeneralPloidyExactAFCalculator.java:272); 	at org.broadinstitute.hellbender.tools.walkers.genotyper.afcalc.GeneralPloidyExactAFCalculator.calculateACConformationAndUpdateQueue(GeneralPloidyExactAFCalculator.java:187); 	at org.broadinstitute.hellbender.tools.walkers.genotyper.afcalc.GeneralPloidyExactAFCalculator.fastCombineMultiallelicPool(GeneralPloidyExactAFCalculator.java:148); 	at org.broadinstitute.hellbender.tools.walkers.genotyper.afcalc.GeneralPloidyExactAFCalculator.combineS",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5900#issuecomment-612103255
https://github.com/broadinstitute/gatk/issues/5900#issuecomment-612103255:763,Availability,down,down,763,"Hi y'all. I've been trying to run GATK GenotypeGVCFs but I keep encounter this error. I've increase memory but it does not seems to be enough. ; My script is ; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /gatk/gatk-package-4.0.6.0-local.jar GenotypeGVCFs -ploidy 1 -R /project/uma_john_gibbons/john_gibbons/AORY_AFLA/REF/Aspergillus_oryzae.ASM18445v3.dna.toplevel.fa -O /project/uma_john_gibbons/chacon_vargas/AOR-AFLA/GATK/4-Consolidate_GVCF/combined_Chr1.vcf -V gendb://Chr1/. Any thoughts?. 15:06:40.794 WARN InbreedingCoeff - Annotation will not be calculated, must provide at least 10 samples; 05:40:05.630 INFO GenotypeGVCFs - Shutting down engine; GENOMICSDB_TIMER,GenomicsDB iterator next() timer,Wall-clock time(s),2.0928187529999955,Cpu time(s),0.9772208090000016; [April 10, 2020 5:40:05 AM UTC] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 932.26 minutes.; Runtime.totalMemory()=31136546816; Exception in thread ""main"" java.lang.OutOfMemoryError: Java heap space; 	at org.broadinstitute.hellbender.tools.walkers.genotyper.GenotypeLikelihoodCalculator.<init>(GenotypeLikelihoodCalculator.java:153); 	at org.broadinstitute.hellbender.tools.walkers.genotyper.GenotypeLikelihoodCalculators.getInstance(GenotypeLikelihoodCalculators.java:269); 	at org.broadinstitute.hellbender.tools.walkers.genotyper.afcalc.GeneralPloidyExactAFCalculator.computeLofK(GeneralPloidyExactAFCalculator.java:272); 	at org.broadinstitute.hellbender.tools.walkers.genotyper.afcalc.GeneralPloidyExactAFCalculator.calculateACConformationAndUpdateQueue(GeneralPloidyExactAFCalculator.java:187); 	at org.broadinstitute.hellbender.tools.walkers.genotyper.afcalc.GeneralPloidyExactAFCalculator.fastCombineMultiallelicPool(GeneralPloidyExactAFCalculator.java:148); 	at org.broadinstitute.hellbender.tools.walkers.genotyper.afcalc.GeneralPloidyExactAFCalculator.combineS",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5900#issuecomment-612103255
https://github.com/broadinstitute/gatk/issues/5900#issuecomment-612103255:3658,Integrability,wrap,wrapAndCopyInto,3658,6); 	at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.regenotypeVC(GenotypeGVCFs.java:222); 	at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs.apply(GenotypeGVCFs.java:201); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.lambda$traverse$0(VariantWalkerBase.java:151); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase$$Lambda$91/1033850902.accept(Unknown Source); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.traverse(VariantWalkerBase.java:149); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:984); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:135); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:180); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:199); Using GATK jar /gatk/gatk-package-4.0.6.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsa,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5900#issuecomment-612103255
https://github.com/broadinstitute/gatk/pull/5901#issuecomment-485959656:1222,Deployability,pipeline,pipelines,1222,ttps://codecov.io/gh/broadinstitute/gatk/commit/c644e20201e1963172ed580719392d162f41663d?src=pr&el=desc) will **increase** coverage by `0.003%`.; > The diff coverage is `100%`. ```diff; @@ Coverage Diff @@; ## master #5901 +/- ##; ==============================================; + Coverage 86.838% 86.84% +0.003% ; - Complexity 32325 32327 +2 ; ==============================================; Files 1991 1991 ; Lines 149341 149347 +6 ; Branches 16483 16482 -1 ; ==============================================; + Hits 129684 129693 +9 ; + Misses 13647 13646 -1 ; + Partials 6010 6008 -2; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5901?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...stitute/hellbender/engine/spark/GATKSparkTool.java](https://codecov.io/gh/broadinstitute/gatk/pull/5901/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvR0FUS1NwYXJrVG9vbC5qYXZh) | `82.778% <100%> (+0.91%)` | `78 <2> (+1)` | :arrow_up: |; | [.../pipelines/MarkDuplicatesSparkIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5901/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvTWFya0R1cGxpY2F0ZXNTcGFya0ludGVncmF0aW9uVGVzdC5qYXZh) | `91.367% <100%> (+0.223%)` | `42 <0> (ø)` | :arrow_down: |; | [...transforms/markduplicates/MarkDuplicatesSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5901/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay90cmFuc2Zvcm1zL21hcmtkdXBsaWNhdGVzL01hcmtEdXBsaWNhdGVzU3BhcmsuamF2YQ==) | `94.595% <100%> (+0.074%)` | `36 <6> (ø)` | :arrow_down: |; | [...roadinstitute/hellbender/utils/read/ReadUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5901/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9yZWFkL1JlYWRVdGlscy5qYXZh) | `80.328% <0%> (+0.234%)` | `208% <0%> (+1%)` | :arrow_up: |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5901#issuecomment-485959656
https://github.com/broadinstitute/gatk/issues/5903#issuecomment-486390665:117,Availability,down,download,117,@JavisPeng I think it is having trouble connecting to google cloud to get the gnomAD data. As an alternative you can download the gnomAD data directly to your machine and run against a local copy.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5903#issuecomment-486390665
https://github.com/broadinstitute/gatk/issues/5903#issuecomment-507296889:58,Availability,down,download,58,"@JavisPeng I wanted to check in. Did you have a chance to download gnomAD locally and run from that? If not, I think that will fix the issue you're seeing. If so, are you all set now?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5903#issuecomment-507296889
https://github.com/broadinstitute/gatk/issues/5903#issuecomment-510810697:19,Availability,down,downloaded,19,@jonn-smith I have downloaded the gnomAD，it becomes normal if i don't untar gnomAD,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5903#issuecomment-510810697
https://github.com/broadinstitute/gatk/issues/5903#issuecomment-516532300:218,Availability,down,download,218,Funcotator is trying to read gnomAD from a Google Bucket if the gnomAD data sources are enabled. If you cannot connect to google it will hang. This is ultimately due to the size of the gnomAD data source. . If you can download a local copy and modify the data sources to point to that local copy of gnomAD it will work just fine without an internet connection.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5903#issuecomment-516532300
https://github.com/broadinstitute/gatk/pull/5904#issuecomment-486220430:1885,Usability,Simpl,SimpleCSVWriterWrapperWithHeaderUnitTest,1885,Complexity Δ | |; |---|---|---|---|; | [...er/engine/spark/datasources/VariantsSparkSink.java](https://codecov.io/gh/broadinstitute/gatk/pull/5904/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvVmFyaWFudHNTcGFya1NpbmsuamF2YQ==) | `76.471% <0%> (-1.654%)` | `9% <0%> (+1%)` | |; | [...stitute/hellbender/tools/HaplotypeCallerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5904/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9IYXBsb3R5cGVDYWxsZXJTcGFyay5qYXZh) | `69.767% <0%> (-0.348%)` | `18% <0%> (ø)` | |; | [...transforms/markduplicates/MarkDuplicatesSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5904/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay90cmFuc2Zvcm1zL21hcmtkdXBsaWNhdGVzL01hcmtEdXBsaWNhdGVzU3BhcmsuamF2YQ==) | `94.595% <0%> (ø)` | `36% <0%> (ø)` | :arrow_down: |; | [.../tsv/SimpleCSVWriterWrapperWithHeaderUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5904/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90c3YvU2ltcGxlQ1NWV3JpdGVyV3JhcHBlcldpdGhIZWFkZXJVbml0VGVzdC5qYXZh) | `48.077% <0%> (ø)` | `7% <0%> (?)` | |; | [...nstitute/hellbender/utils/tsv/SimpleXSVWriter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5904/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90c3YvU2ltcGxlWFNWV3JpdGVyLmphdmE=) | `77.273% <0%> (ø)` | `11% <0%> (?)` | |; | [...lotypecaller/readthreading/ReadThreadingGraph.java](https://codecov.io/gh/broadinstitute/gatk/pull/5904/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9yZWFkdGhyZWFkaW5nL1JlYWRUaHJlYWRpbmdHcmFwaC5qYXZh) | `88.971% <0%> (+0.245%)` | `159% <0%> (ø)` | :arrow_down: |; | [.../walkers/vqsr/CNNScoreVariantsIntegrationTest.java](https://codecov.io/gh/broadinsti,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5904#issuecomment-486220430
https://github.com/broadinstitute/gatk/pull/5904#issuecomment-486220430:2221,Usability,Simpl,SimpleXSVWriter,2221,%> (-1.654%)` | `9% <0%> (+1%)` | |; | [...stitute/hellbender/tools/HaplotypeCallerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5904/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9IYXBsb3R5cGVDYWxsZXJTcGFyay5qYXZh) | `69.767% <0%> (-0.348%)` | `18% <0%> (ø)` | |; | [...transforms/markduplicates/MarkDuplicatesSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5904/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay90cmFuc2Zvcm1zL21hcmtkdXBsaWNhdGVzL01hcmtEdXBsaWNhdGVzU3BhcmsuamF2YQ==) | `94.595% <0%> (ø)` | `36% <0%> (ø)` | :arrow_down: |; | [.../tsv/SimpleCSVWriterWrapperWithHeaderUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5904/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90c3YvU2ltcGxlQ1NWV3JpdGVyV3JhcHBlcldpdGhIZWFkZXJVbml0VGVzdC5qYXZh) | `48.077% <0%> (ø)` | `7% <0%> (?)` | |; | [...nstitute/hellbender/utils/tsv/SimpleXSVWriter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5904/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90c3YvU2ltcGxlWFNWV3JpdGVyLmphdmE=) | `77.273% <0%> (ø)` | `11% <0%> (?)` | |; | [...lotypecaller/readthreading/ReadThreadingGraph.java](https://codecov.io/gh/broadinstitute/gatk/pull/5904/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9yZWFkdGhyZWFkaW5nL1JlYWRUaHJlYWRpbmdHcmFwaC5qYXZh) | `88.971% <0%> (+0.245%)` | `159% <0%> (ø)` | :arrow_down: |; | [.../walkers/vqsr/CNNScoreVariantsIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5904/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL3Zxc3IvQ05OU2NvcmVWYXJpYW50c0ludGVncmF0aW9uVGVzdC5qYXZh) | `96.629% <0%> (+0.562%)` | `16% <0%> (+1%)` | :arrow_up: |; | [...va/org/broadinstitute/hellbender/GATKBaseTest.java](https://code,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5904#issuecomment-486220430
https://github.com/broadinstitute/gatk/issues/5905#issuecomment-486663930:464,Availability,recover,recovering,464,"It's likely that this persists in GATK4, but this isn't high priority because in practice we've found that most of our users ignore the spanning deletion alleles or actively dislike them. There are a variety of known issues surrounding spanning deletions, including filtering of * genotypes when the upstream deletion is filtered. I've attached our b37/GRCh37 WGS interval list (no decoy contig), which is split at Ns in the reference. There are 626 intervals. If recovering all the spanning deletion at shard boundaries is important to you, you can use that list to generate your shards and not subdivide further, though I can't guarantee they will be balanced. [wgs_calling_regions.v1.interval_list.txt](https://github.com/broadinstitute/gatk/files/3116941/wgs_calling_regions.v1.interval_list.txt). I had to add a .txt extension for Github, so you'll want to rename it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5905#issuecomment-486663930
https://github.com/broadinstitute/gatk/issues/5905#issuecomment-486663930:464,Safety,recover,recovering,464,"It's likely that this persists in GATK4, but this isn't high priority because in practice we've found that most of our users ignore the spanning deletion alleles or actively dislike them. There are a variety of known issues surrounding spanning deletions, including filtering of * genotypes when the upstream deletion is filtered. I've attached our b37/GRCh37 WGS interval list (no decoy contig), which is split at Ns in the reference. There are 626 intervals. If recovering all the spanning deletion at shard boundaries is important to you, you can use that list to generate your shards and not subdivide further, though I can't guarantee they will be balanced. [wgs_calling_regions.v1.interval_list.txt](https://github.com/broadinstitute/gatk/files/3116941/wgs_calling_regions.v1.interval_list.txt). I had to add a .txt extension for Github, so you'll want to rename it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5905#issuecomment-486663930
https://github.com/broadinstitute/gatk/issues/5905#issuecomment-486906387:157,Safety,avoid,avoided,157,@ldgauthier thank you so much for your detailed answer!. I have also prepared a ~20k shard file here:. https://github.com/EvanTheB/joint_call_shards. I just avoided known gene regions. Maybe this is pointless but feels a bit safer than splitting any-old-ware. Do you have any information about how the hg38 20k shards file was created?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5905#issuecomment-486906387
https://github.com/broadinstitute/gatk/issues/5905#issuecomment-486906387:225,Safety,safe,safer,225,@ldgauthier thank you so much for your detailed answer!. I have also prepared a ~20k shard file here:. https://github.com/EvanTheB/joint_call_shards. I just avoided known gene regions. Maybe this is pointless but feels a bit safer than splitting any-old-ware. Do you have any information about how the hg38 20k shards file was created?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5905#issuecomment-486906387
https://github.com/broadinstitute/gatk/issues/5906#issuecomment-583802837:78,Modifiability,config,configured,78,"@ambarishK Could you provide your WDL script and point us to which tasks were configured with a GATK docker, which steps run, and which steps fail?",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5906#issuecomment-583802837
https://github.com/broadinstitute/gatk/issues/5906#issuecomment-583809875:126,Availability,error,error,126,@davidbenjamin I resolved the issue after passing on proper docker string value into runtime block of WDL script. There is no error now. . In case of any requirement I will communicate you. Thank you so much.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5906#issuecomment-583809875
https://github.com/broadinstitute/gatk/issues/5907#issuecomment-494105417:534,Integrability,depend,dependent,534,"Thank you @mehrzads for your contribution. It would appear that this optimization is aimed to incorporate the knowledge that we could never possibly visit a given vertex more than K times in the first K best paths. Since the graphs are prone to exponential expansion of paths this seems like an important safeguard against this exponential expansion of the graph. . Looking at the code and the algorithm behavior it is intending to copy I see that there is a degenerate case in the current code that can cause the results to be order dependent. My belief is that this code can fall over by virtue of the fact that we refuse to make new incoming edges to a given vertex if there are already too many incoming edges for that vertex. Unfortunately this heuristic doesn't strike me as being valid, because those incoming edges can have any weight, including very high weights because they are bad paths through the graph that we created at a previous step. . I think a more correct optimization would be to limit the number of edges we create LEAVING a given vertex. The logic for this is that while we may not necessarily see all of the incoming edges in the correct weight order we will necessarily see all of the leaving edges in the correct order because those paths are pulled off of the priority queue in the correct order. Thus we can safely ignore any additional paths we see leaving a given edge because by construction as they would necessarily have at least one path that is cheaper than all of the paths leaving the current node.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5907#issuecomment-494105417
https://github.com/broadinstitute/gatk/issues/5907#issuecomment-494105417:69,Performance,optimiz,optimization,69,"Thank you @mehrzads for your contribution. It would appear that this optimization is aimed to incorporate the knowledge that we could never possibly visit a given vertex more than K times in the first K best paths. Since the graphs are prone to exponential expansion of paths this seems like an important safeguard against this exponential expansion of the graph. . Looking at the code and the algorithm behavior it is intending to copy I see that there is a degenerate case in the current code that can cause the results to be order dependent. My belief is that this code can fall over by virtue of the fact that we refuse to make new incoming edges to a given vertex if there are already too many incoming edges for that vertex. Unfortunately this heuristic doesn't strike me as being valid, because those incoming edges can have any weight, including very high weights because they are bad paths through the graph that we created at a previous step. . I think a more correct optimization would be to limit the number of edges we create LEAVING a given vertex. The logic for this is that while we may not necessarily see all of the incoming edges in the correct weight order we will necessarily see all of the leaving edges in the correct order because those paths are pulled off of the priority queue in the correct order. Thus we can safely ignore any additional paths we see leaving a given edge because by construction as they would necessarily have at least one path that is cheaper than all of the paths leaving the current node.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5907#issuecomment-494105417
https://github.com/broadinstitute/gatk/issues/5907#issuecomment-494105417:978,Performance,optimiz,optimization,978,"Thank you @mehrzads for your contribution. It would appear that this optimization is aimed to incorporate the knowledge that we could never possibly visit a given vertex more than K times in the first K best paths. Since the graphs are prone to exponential expansion of paths this seems like an important safeguard against this exponential expansion of the graph. . Looking at the code and the algorithm behavior it is intending to copy I see that there is a degenerate case in the current code that can cause the results to be order dependent. My belief is that this code can fall over by virtue of the fact that we refuse to make new incoming edges to a given vertex if there are already too many incoming edges for that vertex. Unfortunately this heuristic doesn't strike me as being valid, because those incoming edges can have any weight, including very high weights because they are bad paths through the graph that we created at a previous step. . I think a more correct optimization would be to limit the number of edges we create LEAVING a given vertex. The logic for this is that while we may not necessarily see all of the incoming edges in the correct weight order we will necessarily see all of the leaving edges in the correct order because those paths are pulled off of the priority queue in the correct order. Thus we can safely ignore any additional paths we see leaving a given edge because by construction as they would necessarily have at least one path that is cheaper than all of the paths leaving the current node.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5907#issuecomment-494105417
https://github.com/broadinstitute/gatk/issues/5907#issuecomment-494105417:1298,Performance,queue,queue,1298,"Thank you @mehrzads for your contribution. It would appear that this optimization is aimed to incorporate the knowledge that we could never possibly visit a given vertex more than K times in the first K best paths. Since the graphs are prone to exponential expansion of paths this seems like an important safeguard against this exponential expansion of the graph. . Looking at the code and the algorithm behavior it is intending to copy I see that there is a degenerate case in the current code that can cause the results to be order dependent. My belief is that this code can fall over by virtue of the fact that we refuse to make new incoming edges to a given vertex if there are already too many incoming edges for that vertex. Unfortunately this heuristic doesn't strike me as being valid, because those incoming edges can have any weight, including very high weights because they are bad paths through the graph that we created at a previous step. . I think a more correct optimization would be to limit the number of edges we create LEAVING a given vertex. The logic for this is that while we may not necessarily see all of the incoming edges in the correct weight order we will necessarily see all of the leaving edges in the correct order because those paths are pulled off of the priority queue in the correct order. Thus we can safely ignore any additional paths we see leaving a given edge because by construction as they would necessarily have at least one path that is cheaper than all of the paths leaving the current node.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5907#issuecomment-494105417
https://github.com/broadinstitute/gatk/issues/5907#issuecomment-494105417:305,Safety,safe,safeguard,305,"Thank you @mehrzads for your contribution. It would appear that this optimization is aimed to incorporate the knowledge that we could never possibly visit a given vertex more than K times in the first K best paths. Since the graphs are prone to exponential expansion of paths this seems like an important safeguard against this exponential expansion of the graph. . Looking at the code and the algorithm behavior it is intending to copy I see that there is a degenerate case in the current code that can cause the results to be order dependent. My belief is that this code can fall over by virtue of the fact that we refuse to make new incoming edges to a given vertex if there are already too many incoming edges for that vertex. Unfortunately this heuristic doesn't strike me as being valid, because those incoming edges can have any weight, including very high weights because they are bad paths through the graph that we created at a previous step. . I think a more correct optimization would be to limit the number of edges we create LEAVING a given vertex. The logic for this is that while we may not necessarily see all of the incoming edges in the correct weight order we will necessarily see all of the leaving edges in the correct order because those paths are pulled off of the priority queue in the correct order. Thus we can safely ignore any additional paths we see leaving a given edge because by construction as they would necessarily have at least one path that is cheaper than all of the paths leaving the current node.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5907#issuecomment-494105417
https://github.com/broadinstitute/gatk/issues/5907#issuecomment-494105417:1338,Safety,safe,safely,1338,"Thank you @mehrzads for your contribution. It would appear that this optimization is aimed to incorporate the knowledge that we could never possibly visit a given vertex more than K times in the first K best paths. Since the graphs are prone to exponential expansion of paths this seems like an important safeguard against this exponential expansion of the graph. . Looking at the code and the algorithm behavior it is intending to copy I see that there is a degenerate case in the current code that can cause the results to be order dependent. My belief is that this code can fall over by virtue of the fact that we refuse to make new incoming edges to a given vertex if there are already too many incoming edges for that vertex. Unfortunately this heuristic doesn't strike me as being valid, because those incoming edges can have any weight, including very high weights because they are bad paths through the graph that we created at a previous step. . I think a more correct optimization would be to limit the number of edges we create LEAVING a given vertex. The logic for this is that while we may not necessarily see all of the incoming edges in the correct weight order we will necessarily see all of the leaving edges in the correct order because those paths are pulled off of the priority queue in the correct order. Thus we can safely ignore any additional paths we see leaving a given edge because by construction as they would necessarily have at least one path that is cheaper than all of the paths leaving the current node.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5907#issuecomment-494105417
https://github.com/broadinstitute/gatk/issues/5907#issuecomment-494105417:1067,Testability,log,logic,1067,"Thank you @mehrzads for your contribution. It would appear that this optimization is aimed to incorporate the knowledge that we could never possibly visit a given vertex more than K times in the first K best paths. Since the graphs are prone to exponential expansion of paths this seems like an important safeguard against this exponential expansion of the graph. . Looking at the code and the algorithm behavior it is intending to copy I see that there is a degenerate case in the current code that can cause the results to be order dependent. My belief is that this code can fall over by virtue of the fact that we refuse to make new incoming edges to a given vertex if there are already too many incoming edges for that vertex. Unfortunately this heuristic doesn't strike me as being valid, because those incoming edges can have any weight, including very high weights because they are bad paths through the graph that we created at a previous step. . I think a more correct optimization would be to limit the number of edges we create LEAVING a given vertex. The logic for this is that while we may not necessarily see all of the incoming edges in the correct weight order we will necessarily see all of the leaving edges in the correct order because those paths are pulled off of the priority queue in the correct order. Thus we can safely ignore any additional paths we see leaving a given edge because by construction as they would necessarily have at least one path that is cheaper than all of the paths leaving the current node.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5907#issuecomment-494105417
https://github.com/broadinstitute/gatk/issues/5907#issuecomment-494106970:134,Usability,simpl,simple,134,@davidbenjamin I think this must be a fairly degenerate case that would trigger this in the KBestHaplotypeFinder but I can show you a simple example demonstrating this.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5907#issuecomment-494106970
https://github.com/broadinstitute/gatk/issues/5908#issuecomment-488317874:215,Usability,simpl,simple,215,@mehrzads Thank you for posting about this issue. Have you been able to demonstrate different ref-confidence calls in active regions as a result of changing USE_CACHED_READ_INDEL_INFORMATIVENESS_VALUES? It would be simple enough to add a defensive check to ensure the reads have their transient fields purged between calls to the ReferenceConfidenceModel to be absolutely sure there is no issue.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5908#issuecomment-488317874
https://github.com/broadinstitute/gatk/issues/5908#issuecomment-488329795:276,Safety,safe,safe,276,I just ran a preliminary test and it appears that the transient attribute field is apparently getting purged between `if (trimmingResult.hasLeftFlankingRegion())` and `if (trimmingResult.hasRightFlankingRegion())` `ReferenceConfidenceModel` calls. That means this should be a safe operation but I would rather be absolutely that this won't cause problems. To that end I would like to explicitly clean the transient attribute fields before every reference confidence call for an added layer of protection.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5908#issuecomment-488329795
https://github.com/broadinstitute/gatk/issues/5908#issuecomment-488329795:25,Testability,test,test,25,I just ran a preliminary test and it appears that the transient attribute field is apparently getting purged between `if (trimmingResult.hasLeftFlankingRegion())` and `if (trimmingResult.hasRightFlankingRegion())` `ReferenceConfidenceModel` calls. That means this should be a safe operation but I would rather be absolutely that this won't cause problems. To that end I would like to explicitly clean the transient attribute fields before every reference confidence call for an added layer of protection.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5908#issuecomment-488329795
https://github.com/broadinstitute/gatk/pull/5909#issuecomment-488239579:948,Deployability,pipeline,pipelines,948,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5909?src=pr&el=h1) Report; > Merging [#5909](https://codecov.io/gh/broadinstitute/gatk/pull/5909?src=pr&el=desc) into [master](https://codecov.io/gh/broadinstitute/gatk/commit/9e759f6f440d58f1d8b2f99d5042a691f4543975?src=pr&el=desc) will **increase** coverage by `0.002%`.; > The diff coverage is `66.667%`. ```diff; @@ Coverage Diff @@; ## master #5909 +/- ##; ===============================================; + Coverage 80.117% 80.119% +0.002% ; - Complexity 30673 30674 +1 ; ===============================================; Files 1991 1991 ; Lines 149341 149342 +1 ; Branches 16481 16482 +1 ; ===============================================; + Hits 119647 119651 +4 ; + Misses 23892 23890 -2 ; + Partials 5802 5801 -1; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5909?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...nder/tools/spark/pipelines/PrintVariantsSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5909/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay9waXBlbGluZXMvUHJpbnRWYXJpYW50c1NwYXJrLmphdmE=) | `66.667% <ø> (ø)` | `2 <0> (ø)` | :arrow_down: |; | [...stitute/hellbender/tools/HaplotypeCallerSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5909/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9IYXBsb3R5cGVDYWxsZXJTcGFyay5qYXZh) | `69.767% <ø> (-0.348%)` | `18 <0> (ø)` | |; | [...e/spark/datasources/VariantsSparkSinkUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5909/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvc3BhcmsvZGF0YXNvdXJjZXMvVmFyaWFudHNTcGFya1NpbmtVbml0VGVzdC5qYXZh) | `83.212% <100%> (ø)` | `28 <0> (ø)` | :arrow_down: |; | [...er/engine/spark/datasources/VariantsSparkSink.java](https://codecov.io/gh/broadinstitute/gatk/pull/5909/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcv,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5909#issuecomment-488239579
https://github.com/broadinstitute/gatk/issues/5910#issuecomment-499224455:124,Security,expose,exposed,124,"As an addendum to this task, we would also want to improve the test coverage to the underlying methods by hitting the newly exposed API.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5910#issuecomment-499224455
https://github.com/broadinstitute/gatk/issues/5910#issuecomment-499224455:63,Testability,test,test,63,"As an addendum to this task, we would also want to improve the test coverage to the underlying methods by hitting the newly exposed API.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5910#issuecomment-499224455
https://github.com/broadinstitute/gatk/pull/5911#issuecomment-488348623:2266,Usability,Simpl,SimpleCSVWriterWrapperWithHeaderUnitTest,2266,/gatk/pull/5911?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...kers/haplotypecaller/ReferenceConfidenceModel.java](https://codecov.io/gh/broadinstitute/gatk/pull/5911/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9SZWZlcmVuY2VDb25maWRlbmNlTW9kZWwuamF2YQ==) | `92.982% <100%> (+0.031%)` | `87 <1> (+1)` | :arrow_up: |; | [...lotypecaller/ReferenceConfidenceModelUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5911/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9SZWZlcmVuY2VDb25maWRlbmNlTW9kZWxVbml0VGVzdC5qYXZh) | `95.787% <100%> (+0.086%)` | `53 <0> (+3)` | :arrow_up: |; | [...nder/utils/runtime/StreamingProcessController.java](https://codecov.io/gh/broadinstitute/gatk/pull/5911/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9ydW50aW1lL1N0cmVhbWluZ1Byb2Nlc3NDb250cm9sbGVyLmphdmE=) | `67.299% <0%> (-0.474%)` | `33% <0%> (ø)` | |; | [...transforms/markduplicates/MarkDuplicatesSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5911/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay90cmFuc2Zvcm1zL21hcmtkdXBsaWNhdGVzL01hcmtEdXBsaWNhdGVzU3BhcmsuamF2YQ==) | `94.595% <0%> (ø)` | `36% <0%> (ø)` | :arrow_down: |; | [.../tsv/SimpleCSVWriterWrapperWithHeaderUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5911/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90c3YvU2ltcGxlQ1NWV3JpdGVyV3JhcHBlcldpdGhIZWFkZXJVbml0VGVzdC5qYXZh) | `48.077% <0%> (ø)` | `7% <0%> (?)` | |; | [...nstitute/hellbender/utils/tsv/SimpleXSVWriter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5911/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90c3YvU2ltcGxlWFNWV3JpdGVyLmphdmE=) | `77.273% <0%> (ø)` | `11% <0%> (?)` | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5911#issuecomment-488348623
https://github.com/broadinstitute/gatk/pull/5911#issuecomment-488348623:2602,Usability,Simpl,SimpleXSVWriter,2602,/gatk/pull/5911?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...kers/haplotypecaller/ReferenceConfidenceModel.java](https://codecov.io/gh/broadinstitute/gatk/pull/5911/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9SZWZlcmVuY2VDb25maWRlbmNlTW9kZWwuamF2YQ==) | `92.982% <100%> (+0.031%)` | `87 <1> (+1)` | :arrow_up: |; | [...lotypecaller/ReferenceConfidenceModelUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5911/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2hhcGxvdHlwZWNhbGxlci9SZWZlcmVuY2VDb25maWRlbmNlTW9kZWxVbml0VGVzdC5qYXZh) | `95.787% <100%> (+0.086%)` | `53 <0> (+3)` | :arrow_up: |; | [...nder/utils/runtime/StreamingProcessController.java](https://codecov.io/gh/broadinstitute/gatk/pull/5911/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9ydW50aW1lL1N0cmVhbWluZ1Byb2Nlc3NDb250cm9sbGVyLmphdmE=) | `67.299% <0%> (-0.474%)` | `33% <0%> (ø)` | |; | [...transforms/markduplicates/MarkDuplicatesSpark.java](https://codecov.io/gh/broadinstitute/gatk/pull/5911/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy9zcGFyay90cmFuc2Zvcm1zL21hcmtkdXBsaWNhdGVzL01hcmtEdXBsaWNhdGVzU3BhcmsuamF2YQ==) | `94.595% <0%> (ø)` | `36% <0%> (ø)` | :arrow_down: |; | [.../tsv/SimpleCSVWriterWrapperWithHeaderUnitTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5911/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90c3YvU2ltcGxlQ1NWV3JpdGVyV3JhcHBlcldpdGhIZWFkZXJVbml0VGVzdC5qYXZh) | `48.077% <0%> (ø)` | `7% <0%> (?)` | |; | [...nstitute/hellbender/utils/tsv/SimpleXSVWriter.java](https://codecov.io/gh/broadinstitute/gatk/pull/5911/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy90c3YvU2ltcGxlWFNWV3JpdGVyLmphdmE=) | `77.273% <0%> (ø)` | `11% <0%> (?)` | |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5911#issuecomment-488348623
https://github.com/broadinstitute/gatk/pull/5911#issuecomment-489242346:38,Performance,cache,cache,38,Note to self: move the purging of the cache to the end of execution and test that leftover cache values are never present after invoking referenceConfidenceModel,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5911#issuecomment-489242346
https://github.com/broadinstitute/gatk/pull/5911#issuecomment-489242346:91,Performance,cache,cache,91,Note to self: move the purging of the cache to the end of execution and test that leftover cache values are never present after invoking referenceConfidenceModel,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5911#issuecomment-489242346
https://github.com/broadinstitute/gatk/pull/5911#issuecomment-489242346:72,Testability,test,test,72,Note to self: move the purging of the cache to the end of execution and test that leftover cache values are never present after invoking referenceConfidenceModel,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5911#issuecomment-489242346
https://github.com/broadinstitute/gatk/pull/5911#issuecomment-491914930:46,Availability,down,down,46,@droazen I have pushed the cache removal step down to a more testable point in the code and added the assertion to the existing testing infrastructure. Can you take a quick look at this branch so it can go in at some point?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5911#issuecomment-491914930
https://github.com/broadinstitute/gatk/pull/5911#issuecomment-491914930:27,Performance,cache,cache,27,@droazen I have pushed the cache removal step down to a more testable point in the code and added the assertion to the existing testing infrastructure. Can you take a quick look at this branch so it can go in at some point?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5911#issuecomment-491914930
https://github.com/broadinstitute/gatk/pull/5911#issuecomment-491914930:61,Testability,test,testable,61,@droazen I have pushed the cache removal step down to a more testable point in the code and added the assertion to the existing testing infrastructure. Can you take a quick look at this branch so it can go in at some point?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5911#issuecomment-491914930
https://github.com/broadinstitute/gatk/pull/5911#issuecomment-491914930:102,Testability,assert,assertion,102,@droazen I have pushed the cache removal step down to a more testable point in the code and added the assertion to the existing testing infrastructure. Can you take a quick look at this branch so it can go in at some point?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5911#issuecomment-491914930
https://github.com/broadinstitute/gatk/pull/5911#issuecomment-491914930:128,Testability,test,testing,128,@droazen I have pushed the cache removal step down to a more testable point in the code and added the assertion to the existing testing infrastructure. Can you take a quick look at this branch so it can go in at some point?,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5911#issuecomment-491914930
https://github.com/broadinstitute/gatk/issues/5912#issuecomment-492784881:11,Integrability,message,messages,11,"Hmn, those messages are supposed to only be produced once... something is wrong there. It's not a super high priority but we'll try to look into it.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5912#issuecomment-492784881
https://github.com/broadinstitute/gatk/issues/5912#issuecomment-708684109:47,Integrability,message,messages,47,I would also really appreciate it if these log messages contained the locus/position that generated the warning.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5912#issuecomment-708684109
https://github.com/broadinstitute/gatk/issues/5912#issuecomment-708684109:43,Testability,log,log,43,I would also really appreciate it if these log messages contained the locus/position that generated the warning.,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5912#issuecomment-708684109
https://github.com/broadinstitute/gatk/issues/5912#issuecomment-709475596:73,Integrability,message,messages,73,@tfenne @gubrins @pkaleta @aushev We've opened a PR to improve these log messages here: https://github.com/broadinstitute/gatk/pull/6891,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5912#issuecomment-709475596
https://github.com/broadinstitute/gatk/issues/5912#issuecomment-709475596:69,Testability,log,log,69,@tfenne @gubrins @pkaleta @aushev We've opened a PR to improve these log messages here: https://github.com/broadinstitute/gatk/pull/6891,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5912#issuecomment-709475596
https://github.com/broadinstitute/gatk/issues/5912#issuecomment-727516475:394,Availability,error,error,394,"hello , I met the same problem! I am a fresh . So I don't understand what above metioned . I would like to know what happened with this . Looking forward everybody's reply ! Thanks very much!!!. Here is my command . `gatk HaplotypeCaller -R /home/variation/202011/input/NCTC11134/fasta/N.far_NCTC11134.fa --emit-ref-confidence GVCF -I CD142.sorted.markdup.bam -O CD142.g.vcf`. here is reported error : ; `16:06:46.622 WARN DepthPerSampleHC - Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null. 16:06:46.623 WARN StrandBiasBySample - Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null. 16:06:46.623 WARN StrandBiasBySample - Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null. 16:06:46.623 WARN StrandBiasBySample - Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null. 16:06:46.624 WARN StrandBiasBySample - Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null. 16:06:46.624 WARN StrandBiasBySample - Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null. 16:06:46.624 WARN StrandBiasBySample - Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null. 16:06:50.918 INFO ProgressMeter - NZ_LN868938.1:634261 3.5 4090 1182.7. 16:07:01.275 INFO ProgressMeter - NZ_LN868938.1:659185 3.6 4290 1181.6`. Could you help me ! I really need your help ! And I appreciate it specially!",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5912#issuecomment-727516475
https://github.com/broadinstitute/gatk/issues/5912#issuecomment-729062949:32,Deployability,release,release,32,"@cheche0717 there hasn't been a release since the warnings were updated, but you can build a new jar yourself off of the master branch in the github repository or use the nightly Docker: https://hub.docker.com/r/broadinstitute/gatk-nightly",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5912#issuecomment-729062949
https://github.com/broadinstitute/gatk/issues/5912#issuecomment-729062949:64,Deployability,update,updated,64,"@cheche0717 there hasn't been a release since the warnings were updated, but you can build a new jar yourself off of the master branch in the github repository or use the nightly Docker: https://hub.docker.com/r/broadinstitute/gatk-nightly",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/5912#issuecomment-729062949
https://github.com/broadinstitute/gatk/pull/5913#issuecomment-489247144:232,Availability,error,error-reference,232,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5913?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@00f1e43`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `73.997%`. ```diff; @@ Coverage Diff @@; ## master #5913 +/- ##; ==========================================; Coverage ? 78.979% ; Complexity ? 30649 ; ==========================================; Files ? 2003 ; Lines ? 150459 ; Branches ? 16657 ; ==========================================; Hits ? 118831 ; Misses ? 25832 ; Partials ? 5796; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5913?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...lkers/coverage/DepthOfCoverageIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5913/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2NvdmVyYWdlL0RlcHRoT2ZDb3ZlcmFnZUludGVncmF0aW9uVGVzdC5qYXZh) | `0.758% <0.758%> (ø)` | `1 <1> (?)` | |; | [...nstitute/hellbender/utils/IntervalMergingRule.java](https://codecov.io/gh/broadinstitute/gatk/pull/5913/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9JbnRlcnZhbE1lcmdpbmdSdWxlLmphdmE=) | `100% <100%> (ø)` | `1 <0> (?)` | |; | [...org/broadinstitute/hellbender/utils/BaseUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5913/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9CYXNlVXRpbHMuamF2YQ==) | `88.462% <100%> (ø)` | `59 <3> (?)` | |; | [...itute/hellbender/engine/LocusWalkerByInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/5913/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvTG9jdXNXYWxrZXJCeUludGVydmFsLmphdmE=) | `100% <100%> (ø)` | `7 <7> (?)` | |; | [...llbender/engine/LocusWalkerByIntervalUnitTest.java](https://codecov.i,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-489247144
https://github.com/broadinstitute/gatk/pull/5913#issuecomment-489247144:180,Usability,learn,learn,180,# [Codecov](https://codecov.io/gh/broadinstitute/gatk/pull/5913?src=pr&el=h1) Report; > :exclamation: No coverage uploaded for pull request base (`master@00f1e43`). [Click here to learn what that means](https://docs.codecov.io/docs/error-reference#section-missing-base-commit).; > The diff coverage is `73.997%`. ```diff; @@ Coverage Diff @@; ## master #5913 +/- ##; ==========================================; Coverage ? 78.979% ; Complexity ? 30649 ; ==========================================; Files ? 2003 ; Lines ? 150459 ; Branches ? 16657 ; ==========================================; Hits ? 118831 ; Misses ? 25832 ; Partials ? 5796; ```. | [Impacted Files](https://codecov.io/gh/broadinstitute/gatk/pull/5913?src=pr&el=tree) | Coverage Δ | Complexity Δ | |; |---|---|---|---|; | [...lkers/coverage/DepthOfCoverageIntegrationTest.java](https://codecov.io/gh/broadinstitute/gatk/pull/5913/diff?src=pr&el=tree#diff-c3JjL3Rlc3QvamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci90b29scy93YWxrZXJzL2NvdmVyYWdlL0RlcHRoT2ZDb3ZlcmFnZUludGVncmF0aW9uVGVzdC5qYXZh) | `0.758% <0.758%> (ø)` | `1 <1> (?)` | |; | [...nstitute/hellbender/utils/IntervalMergingRule.java](https://codecov.io/gh/broadinstitute/gatk/pull/5913/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9JbnRlcnZhbE1lcmdpbmdSdWxlLmphdmE=) | `100% <100%> (ø)` | `1 <0> (?)` | |; | [...org/broadinstitute/hellbender/utils/BaseUtils.java](https://codecov.io/gh/broadinstitute/gatk/pull/5913/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci91dGlscy9CYXNlVXRpbHMuamF2YQ==) | `88.462% <100%> (ø)` | `59 <3> (?)` | |; | [...itute/hellbender/engine/LocusWalkerByInterval.java](https://codecov.io/gh/broadinstitute/gatk/pull/5913/diff?src=pr&el=tree#diff-c3JjL21haW4vamF2YS9vcmcvYnJvYWRpbnN0aXR1dGUvaGVsbGJlbmRlci9lbmdpbmUvTG9jdXNXYWxrZXJCeUludGVydmFsLmphdmE=) | `100% <100%> (ø)` | `7 <7> (?)` | |; | [...llbender/engine/LocusWalkerByIntervalUnitTest.java](https://codecov.i,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-489247144
https://github.com/broadinstitute/gatk/pull/5913#issuecomment-566779141:20,Availability,failure,failures,20,Travis reported job failures from build [28390](https://travis-ci.com/broadinstitute/gatk/builds/141504354); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | python | openjdk8 | [28390.5](https://travis-ci.com/broadinstitute/gatk/jobs/268302595) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.5/tests/test/index.html) |; | integration | oraclejdk8 | [28390.11](https://travis-ci.com/broadinstitute/gatk/jobs/268302601) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.11/tests/test/index.html) |; | integration | openjdk11 | [28390.12](https://travis-ci.com/broadinstitute/gatk/jobs/268302602) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.12/tests/test/index.html) |; | integration | openjdk8 | [28390.2](https://travis-ci.com/broadinstitute/gatk/jobs/268302592) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-566779141
https://github.com/broadinstitute/gatk/pull/5913#issuecomment-566779141:109,Availability,Failure,Failures,109,Travis reported job failures from build [28390](https://travis-ci.com/broadinstitute/gatk/builds/141504354); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | python | openjdk8 | [28390.5](https://travis-ci.com/broadinstitute/gatk/jobs/268302595) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.5/tests/test/index.html) |; | integration | oraclejdk8 | [28390.11](https://travis-ci.com/broadinstitute/gatk/jobs/268302601) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.11/tests/test/index.html) |; | integration | openjdk11 | [28390.12](https://travis-ci.com/broadinstitute/gatk/jobs/268302602) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.12/tests/test/index.html) |; | integration | openjdk8 | [28390.2](https://travis-ci.com/broadinstitute/gatk/jobs/268302592) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-566779141
https://github.com/broadinstitute/gatk/pull/5913#issuecomment-566779141:424,Deployability,integrat,integration,424,Travis reported job failures from build [28390](https://travis-ci.com/broadinstitute/gatk/builds/141504354); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | python | openjdk8 | [28390.5](https://travis-ci.com/broadinstitute/gatk/jobs/268302595) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.5/tests/test/index.html) |; | integration | oraclejdk8 | [28390.11](https://travis-ci.com/broadinstitute/gatk/jobs/268302601) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.11/tests/test/index.html) |; | integration | openjdk11 | [28390.12](https://travis-ci.com/broadinstitute/gatk/jobs/268302602) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.12/tests/test/index.html) |; | integration | openjdk8 | [28390.2](https://travis-ci.com/broadinstitute/gatk/jobs/268302592) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-566779141
https://github.com/broadinstitute/gatk/pull/5913#issuecomment-566779141:639,Deployability,integrat,integration,639,Travis reported job failures from build [28390](https://travis-ci.com/broadinstitute/gatk/builds/141504354); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | python | openjdk8 | [28390.5](https://travis-ci.com/broadinstitute/gatk/jobs/268302595) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.5/tests/test/index.html) |; | integration | oraclejdk8 | [28390.11](https://travis-ci.com/broadinstitute/gatk/jobs/268302601) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.11/tests/test/index.html) |; | integration | openjdk11 | [28390.12](https://travis-ci.com/broadinstitute/gatk/jobs/268302602) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.12/tests/test/index.html) |; | integration | openjdk8 | [28390.2](https://travis-ci.com/broadinstitute/gatk/jobs/268302592) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-566779141
https://github.com/broadinstitute/gatk/pull/5913#issuecomment-566779141:853,Deployability,integrat,integration,853,Travis reported job failures from build [28390](https://travis-ci.com/broadinstitute/gatk/builds/141504354); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | python | openjdk8 | [28390.5](https://travis-ci.com/broadinstitute/gatk/jobs/268302595) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.5/tests/test/index.html) |; | integration | oraclejdk8 | [28390.11](https://travis-ci.com/broadinstitute/gatk/jobs/268302601) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.11/tests/test/index.html) |; | integration | openjdk11 | [28390.12](https://travis-ci.com/broadinstitute/gatk/jobs/268302602) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.12/tests/test/index.html) |; | integration | openjdk8 | [28390.2](https://travis-ci.com/broadinstitute/gatk/jobs/268302592) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-566779141
https://github.com/broadinstitute/gatk/pull/5913#issuecomment-566779141:424,Integrability,integrat,integration,424,Travis reported job failures from build [28390](https://travis-ci.com/broadinstitute/gatk/builds/141504354); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | python | openjdk8 | [28390.5](https://travis-ci.com/broadinstitute/gatk/jobs/268302595) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.5/tests/test/index.html) |; | integration | oraclejdk8 | [28390.11](https://travis-ci.com/broadinstitute/gatk/jobs/268302601) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.11/tests/test/index.html) |; | integration | openjdk11 | [28390.12](https://travis-ci.com/broadinstitute/gatk/jobs/268302602) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.12/tests/test/index.html) |; | integration | openjdk8 | [28390.2](https://travis-ci.com/broadinstitute/gatk/jobs/268302592) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-566779141
https://github.com/broadinstitute/gatk/pull/5913#issuecomment-566779141:639,Integrability,integrat,integration,639,Travis reported job failures from build [28390](https://travis-ci.com/broadinstitute/gatk/builds/141504354); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | python | openjdk8 | [28390.5](https://travis-ci.com/broadinstitute/gatk/jobs/268302595) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.5/tests/test/index.html) |; | integration | oraclejdk8 | [28390.11](https://travis-ci.com/broadinstitute/gatk/jobs/268302601) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.11/tests/test/index.html) |; | integration | openjdk11 | [28390.12](https://travis-ci.com/broadinstitute/gatk/jobs/268302602) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.12/tests/test/index.html) |; | integration | openjdk8 | [28390.2](https://travis-ci.com/broadinstitute/gatk/jobs/268302592) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-566779141
https://github.com/broadinstitute/gatk/pull/5913#issuecomment-566779141:853,Integrability,integrat,integration,853,Travis reported job failures from build [28390](https://travis-ci.com/broadinstitute/gatk/builds/141504354); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | python | openjdk8 | [28390.5](https://travis-ci.com/broadinstitute/gatk/jobs/268302595) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.5/tests/test/index.html) |; | integration | oraclejdk8 | [28390.11](https://travis-ci.com/broadinstitute/gatk/jobs/268302601) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.11/tests/test/index.html) |; | integration | openjdk11 | [28390.12](https://travis-ci.com/broadinstitute/gatk/jobs/268302602) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.12/tests/test/index.html) |; | integration | openjdk8 | [28390.2](https://travis-ci.com/broadinstitute/gatk/jobs/268302592) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-566779141
https://github.com/broadinstitute/gatk/pull/5913#issuecomment-566779141:144,Testability,Test,Test,144,Travis reported job failures from build [28390](https://travis-ci.com/broadinstitute/gatk/builds/141504354); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | python | openjdk8 | [28390.5](https://travis-ci.com/broadinstitute/gatk/jobs/268302595) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.5/tests/test/index.html) |; | integration | oraclejdk8 | [28390.11](https://travis-ci.com/broadinstitute/gatk/jobs/268302601) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.11/tests/test/index.html) |; | integration | openjdk11 | [28390.12](https://travis-ci.com/broadinstitute/gatk/jobs/268302602) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.12/tests/test/index.html) |; | integration | openjdk8 | [28390.2](https://travis-ci.com/broadinstitute/gatk/jobs/268302592) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-566779141
https://github.com/broadinstitute/gatk/pull/5913#issuecomment-566779141:171,Testability,Log,Logs,171,Travis reported job failures from build [28390](https://travis-ci.com/broadinstitute/gatk/builds/141504354); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | python | openjdk8 | [28390.5](https://travis-ci.com/broadinstitute/gatk/jobs/268302595) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.5/tests/test/index.html) |; | integration | oraclejdk8 | [28390.11](https://travis-ci.com/broadinstitute/gatk/jobs/268302601) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.11/tests/test/index.html) |; | integration | openjdk11 | [28390.12](https://travis-ci.com/broadinstitute/gatk/jobs/268302602) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.12/tests/test/index.html) |; | integration | openjdk8 | [28390.2](https://travis-ci.com/broadinstitute/gatk/jobs/268302592) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-566779141
https://github.com/broadinstitute/gatk/pull/5913#issuecomment-566779141:309,Testability,log,logs,309,Travis reported job failures from build [28390](https://travis-ci.com/broadinstitute/gatk/builds/141504354); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | python | openjdk8 | [28390.5](https://travis-ci.com/broadinstitute/gatk/jobs/268302595) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.5/tests/test/index.html) |; | integration | oraclejdk8 | [28390.11](https://travis-ci.com/broadinstitute/gatk/jobs/268302601) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.11/tests/test/index.html) |; | integration | openjdk11 | [28390.12](https://travis-ci.com/broadinstitute/gatk/jobs/268302602) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.12/tests/test/index.html) |; | integration | openjdk8 | [28390.2](https://travis-ci.com/broadinstitute/gatk/jobs/268302592) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-566779141
https://github.com/broadinstitute/gatk/pull/5913#issuecomment-566779141:357,Testability,test,test-logs,357,Travis reported job failures from build [28390](https://travis-ci.com/broadinstitute/gatk/builds/141504354); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | python | openjdk8 | [28390.5](https://travis-ci.com/broadinstitute/gatk/jobs/268302595) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.5/tests/test/index.html) |; | integration | oraclejdk8 | [28390.11](https://travis-ci.com/broadinstitute/gatk/jobs/268302601) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.11/tests/test/index.html) |; | integration | openjdk11 | [28390.12](https://travis-ci.com/broadinstitute/gatk/jobs/268302602) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.12/tests/test/index.html) |; | integration | openjdk8 | [28390.2](https://travis-ci.com/broadinstitute/gatk/jobs/268302592) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-566779141
https://github.com/broadinstitute/gatk/pull/5913#issuecomment-566779141:396,Testability,test,tests,396,Travis reported job failures from build [28390](https://travis-ci.com/broadinstitute/gatk/builds/141504354); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | python | openjdk8 | [28390.5](https://travis-ci.com/broadinstitute/gatk/jobs/268302595) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.5/tests/test/index.html) |; | integration | oraclejdk8 | [28390.11](https://travis-ci.com/broadinstitute/gatk/jobs/268302601) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.11/tests/test/index.html) |; | integration | openjdk11 | [28390.12](https://travis-ci.com/broadinstitute/gatk/jobs/268302602) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.12/tests/test/index.html) |; | integration | openjdk8 | [28390.2](https://travis-ci.com/broadinstitute/gatk/jobs/268302592) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-566779141
https://github.com/broadinstitute/gatk/pull/5913#issuecomment-566779141:402,Testability,test,test,402,Travis reported job failures from build [28390](https://travis-ci.com/broadinstitute/gatk/builds/141504354); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | python | openjdk8 | [28390.5](https://travis-ci.com/broadinstitute/gatk/jobs/268302595) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.5/tests/test/index.html) |; | integration | oraclejdk8 | [28390.11](https://travis-ci.com/broadinstitute/gatk/jobs/268302601) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.11/tests/test/index.html) |; | integration | openjdk11 | [28390.12](https://travis-ci.com/broadinstitute/gatk/jobs/268302602) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.12/tests/test/index.html) |; | integration | openjdk8 | [28390.2](https://travis-ci.com/broadinstitute/gatk/jobs/268302592) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-566779141
https://github.com/broadinstitute/gatk/pull/5913#issuecomment-566779141:523,Testability,log,logs,523,Travis reported job failures from build [28390](https://travis-ci.com/broadinstitute/gatk/builds/141504354); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | python | openjdk8 | [28390.5](https://travis-ci.com/broadinstitute/gatk/jobs/268302595) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.5/tests/test/index.html) |; | integration | oraclejdk8 | [28390.11](https://travis-ci.com/broadinstitute/gatk/jobs/268302601) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.11/tests/test/index.html) |; | integration | openjdk11 | [28390.12](https://travis-ci.com/broadinstitute/gatk/jobs/268302602) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.12/tests/test/index.html) |; | integration | openjdk8 | [28390.2](https://travis-ci.com/broadinstitute/gatk/jobs/268302592) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-566779141
https://github.com/broadinstitute/gatk/pull/5913#issuecomment-566779141:571,Testability,test,test-logs,571,Travis reported job failures from build [28390](https://travis-ci.com/broadinstitute/gatk/builds/141504354); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | python | openjdk8 | [28390.5](https://travis-ci.com/broadinstitute/gatk/jobs/268302595) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.5/tests/test/index.html) |; | integration | oraclejdk8 | [28390.11](https://travis-ci.com/broadinstitute/gatk/jobs/268302601) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.11/tests/test/index.html) |; | integration | openjdk11 | [28390.12](https://travis-ci.com/broadinstitute/gatk/jobs/268302602) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.12/tests/test/index.html) |; | integration | openjdk8 | [28390.2](https://travis-ci.com/broadinstitute/gatk/jobs/268302592) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-566779141
https://github.com/broadinstitute/gatk/pull/5913#issuecomment-566779141:611,Testability,test,tests,611,Travis reported job failures from build [28390](https://travis-ci.com/broadinstitute/gatk/builds/141504354); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | python | openjdk8 | [28390.5](https://travis-ci.com/broadinstitute/gatk/jobs/268302595) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.5/tests/test/index.html) |; | integration | oraclejdk8 | [28390.11](https://travis-ci.com/broadinstitute/gatk/jobs/268302601) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.11/tests/test/index.html) |; | integration | openjdk11 | [28390.12](https://travis-ci.com/broadinstitute/gatk/jobs/268302602) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.12/tests/test/index.html) |; | integration | openjdk8 | [28390.2](https://travis-ci.com/broadinstitute/gatk/jobs/268302592) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-566779141
https://github.com/broadinstitute/gatk/pull/5913#issuecomment-566779141:617,Testability,test,test,617,Travis reported job failures from build [28390](https://travis-ci.com/broadinstitute/gatk/builds/141504354); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | python | openjdk8 | [28390.5](https://travis-ci.com/broadinstitute/gatk/jobs/268302595) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.5/tests/test/index.html) |; | integration | oraclejdk8 | [28390.11](https://travis-ci.com/broadinstitute/gatk/jobs/268302601) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.11/tests/test/index.html) |; | integration | openjdk11 | [28390.12](https://travis-ci.com/broadinstitute/gatk/jobs/268302602) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.12/tests/test/index.html) |; | integration | openjdk8 | [28390.2](https://travis-ci.com/broadinstitute/gatk/jobs/268302592) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-566779141
https://github.com/broadinstitute/gatk/pull/5913#issuecomment-566779141:737,Testability,log,logs,737,Travis reported job failures from build [28390](https://travis-ci.com/broadinstitute/gatk/builds/141504354); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | python | openjdk8 | [28390.5](https://travis-ci.com/broadinstitute/gatk/jobs/268302595) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.5/tests/test/index.html) |; | integration | oraclejdk8 | [28390.11](https://travis-ci.com/broadinstitute/gatk/jobs/268302601) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.11/tests/test/index.html) |; | integration | openjdk11 | [28390.12](https://travis-ci.com/broadinstitute/gatk/jobs/268302602) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.12/tests/test/index.html) |; | integration | openjdk8 | [28390.2](https://travis-ci.com/broadinstitute/gatk/jobs/268302592) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-566779141
https://github.com/broadinstitute/gatk/pull/5913#issuecomment-566779141:785,Testability,test,test-logs,785,Travis reported job failures from build [28390](https://travis-ci.com/broadinstitute/gatk/builds/141504354); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | python | openjdk8 | [28390.5](https://travis-ci.com/broadinstitute/gatk/jobs/268302595) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.5/tests/test/index.html) |; | integration | oraclejdk8 | [28390.11](https://travis-ci.com/broadinstitute/gatk/jobs/268302601) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.11/tests/test/index.html) |; | integration | openjdk11 | [28390.12](https://travis-ci.com/broadinstitute/gatk/jobs/268302602) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.12/tests/test/index.html) |; | integration | openjdk8 | [28390.2](https://travis-ci.com/broadinstitute/gatk/jobs/268302592) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-566779141
https://github.com/broadinstitute/gatk/pull/5913#issuecomment-566779141:825,Testability,test,tests,825,Travis reported job failures from build [28390](https://travis-ci.com/broadinstitute/gatk/builds/141504354); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | python | openjdk8 | [28390.5](https://travis-ci.com/broadinstitute/gatk/jobs/268302595) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.5/tests/test/index.html) |; | integration | oraclejdk8 | [28390.11](https://travis-ci.com/broadinstitute/gatk/jobs/268302601) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.11/tests/test/index.html) |; | integration | openjdk11 | [28390.12](https://travis-ci.com/broadinstitute/gatk/jobs/268302602) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.12/tests/test/index.html) |; | integration | openjdk8 | [28390.2](https://travis-ci.com/broadinstitute/gatk/jobs/268302592) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-566779141
https://github.com/broadinstitute/gatk/pull/5913#issuecomment-566779141:831,Testability,test,test,831,Travis reported job failures from build [28390](https://travis-ci.com/broadinstitute/gatk/builds/141504354); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | python | openjdk8 | [28390.5](https://travis-ci.com/broadinstitute/gatk/jobs/268302595) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.5/tests/test/index.html) |; | integration | oraclejdk8 | [28390.11](https://travis-ci.com/broadinstitute/gatk/jobs/268302601) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.11/tests/test/index.html) |; | integration | openjdk11 | [28390.12](https://travis-ci.com/broadinstitute/gatk/jobs/268302602) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.12/tests/test/index.html) |; | integration | openjdk8 | [28390.2](https://travis-ci.com/broadinstitute/gatk/jobs/268302592) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-566779141
https://github.com/broadinstitute/gatk/pull/5913#issuecomment-566779141:949,Testability,log,logs,949,Travis reported job failures from build [28390](https://travis-ci.com/broadinstitute/gatk/builds/141504354); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | python | openjdk8 | [28390.5](https://travis-ci.com/broadinstitute/gatk/jobs/268302595) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.5/tests/test/index.html) |; | integration | oraclejdk8 | [28390.11](https://travis-ci.com/broadinstitute/gatk/jobs/268302601) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.11/tests/test/index.html) |; | integration | openjdk11 | [28390.12](https://travis-ci.com/broadinstitute/gatk/jobs/268302602) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.12/tests/test/index.html) |; | integration | openjdk8 | [28390.2](https://travis-ci.com/broadinstitute/gatk/jobs/268302592) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-566779141
https://github.com/broadinstitute/gatk/pull/5913#issuecomment-566779141:997,Testability,test,test-logs,997,Travis reported job failures from build [28390](https://travis-ci.com/broadinstitute/gatk/builds/141504354); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | python | openjdk8 | [28390.5](https://travis-ci.com/broadinstitute/gatk/jobs/268302595) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.5/tests/test/index.html) |; | integration | oraclejdk8 | [28390.11](https://travis-ci.com/broadinstitute/gatk/jobs/268302601) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.11/tests/test/index.html) |; | integration | openjdk11 | [28390.12](https://travis-ci.com/broadinstitute/gatk/jobs/268302602) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.12/tests/test/index.html) |; | integration | openjdk8 | [28390.2](https://travis-ci.com/broadinstitute/gatk/jobs/268302592) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-566779141
https://github.com/broadinstitute/gatk/pull/5913#issuecomment-566779141:1036,Testability,test,tests,1036,Travis reported job failures from build [28390](https://travis-ci.com/broadinstitute/gatk/builds/141504354); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | python | openjdk8 | [28390.5](https://travis-ci.com/broadinstitute/gatk/jobs/268302595) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.5/tests/test/index.html) |; | integration | oraclejdk8 | [28390.11](https://travis-ci.com/broadinstitute/gatk/jobs/268302601) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.11/tests/test/index.html) |; | integration | openjdk11 | [28390.12](https://travis-ci.com/broadinstitute/gatk/jobs/268302602) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.12/tests/test/index.html) |; | integration | openjdk8 | [28390.2](https://travis-ci.com/broadinstitute/gatk/jobs/268302592) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-566779141
https://github.com/broadinstitute/gatk/pull/5913#issuecomment-566779141:1042,Testability,test,test,1042,Travis reported job failures from build [28390](https://travis-ci.com/broadinstitute/gatk/builds/141504354); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | python | openjdk8 | [28390.5](https://travis-ci.com/broadinstitute/gatk/jobs/268302595) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.5/tests/test/index.html) |; | integration | oraclejdk8 | [28390.11](https://travis-ci.com/broadinstitute/gatk/jobs/268302601) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.11/tests/test/index.html) |; | integration | openjdk11 | [28390.12](https://travis-ci.com/broadinstitute/gatk/jobs/268302602) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.12/tests/test/index.html) |; | integration | openjdk8 | [28390.2](https://travis-ci.com/broadinstitute/gatk/jobs/268302592) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28390.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-566779141
https://github.com/broadinstitute/gatk/pull/5913#issuecomment-568018197:20,Availability,failure,failures,20,Travis reported job failures from build [28445](https://travis-ci.com/broadinstitute/gatk/builds/141951149); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [28445.11](https://travis-ci.com/broadinstitute/gatk/jobs/269363611) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.11/tests/test/index.html) |; | integration | openjdk11 | [28445.12](https://travis-ci.com/broadinstitute/gatk/jobs/269363612) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.12/tests/test/index.html) |; | integration | openjdk8 | [28445.2](https://travis-ci.com/broadinstitute/gatk/jobs/269363599) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-568018197
https://github.com/broadinstitute/gatk/pull/5913#issuecomment-568018197:109,Availability,Failure,Failures,109,Travis reported job failures from build [28445](https://travis-ci.com/broadinstitute/gatk/builds/141951149); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [28445.11](https://travis-ci.com/broadinstitute/gatk/jobs/269363611) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.11/tests/test/index.html) |; | integration | openjdk11 | [28445.12](https://travis-ci.com/broadinstitute/gatk/jobs/269363612) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.12/tests/test/index.html) |; | integration | openjdk8 | [28445.2](https://travis-ci.com/broadinstitute/gatk/jobs/269363599) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-568018197
https://github.com/broadinstitute/gatk/pull/5913#issuecomment-568018197:218,Deployability,integrat,integration,218,Travis reported job failures from build [28445](https://travis-ci.com/broadinstitute/gatk/builds/141951149); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [28445.11](https://travis-ci.com/broadinstitute/gatk/jobs/269363611) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.11/tests/test/index.html) |; | integration | openjdk11 | [28445.12](https://travis-ci.com/broadinstitute/gatk/jobs/269363612) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.12/tests/test/index.html) |; | integration | openjdk8 | [28445.2](https://travis-ci.com/broadinstitute/gatk/jobs/269363599) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-568018197
https://github.com/broadinstitute/gatk/pull/5913#issuecomment-568018197:433,Deployability,integrat,integration,433,Travis reported job failures from build [28445](https://travis-ci.com/broadinstitute/gatk/builds/141951149); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [28445.11](https://travis-ci.com/broadinstitute/gatk/jobs/269363611) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.11/tests/test/index.html) |; | integration | openjdk11 | [28445.12](https://travis-ci.com/broadinstitute/gatk/jobs/269363612) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.12/tests/test/index.html) |; | integration | openjdk8 | [28445.2](https://travis-ci.com/broadinstitute/gatk/jobs/269363599) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-568018197
https://github.com/broadinstitute/gatk/pull/5913#issuecomment-568018197:647,Deployability,integrat,integration,647,Travis reported job failures from build [28445](https://travis-ci.com/broadinstitute/gatk/builds/141951149); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [28445.11](https://travis-ci.com/broadinstitute/gatk/jobs/269363611) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.11/tests/test/index.html) |; | integration | openjdk11 | [28445.12](https://travis-ci.com/broadinstitute/gatk/jobs/269363612) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.12/tests/test/index.html) |; | integration | openjdk8 | [28445.2](https://travis-ci.com/broadinstitute/gatk/jobs/269363599) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-568018197
https://github.com/broadinstitute/gatk/pull/5913#issuecomment-568018197:218,Integrability,integrat,integration,218,Travis reported job failures from build [28445](https://travis-ci.com/broadinstitute/gatk/builds/141951149); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [28445.11](https://travis-ci.com/broadinstitute/gatk/jobs/269363611) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.11/tests/test/index.html) |; | integration | openjdk11 | [28445.12](https://travis-ci.com/broadinstitute/gatk/jobs/269363612) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.12/tests/test/index.html) |; | integration | openjdk8 | [28445.2](https://travis-ci.com/broadinstitute/gatk/jobs/269363599) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-568018197
https://github.com/broadinstitute/gatk/pull/5913#issuecomment-568018197:433,Integrability,integrat,integration,433,Travis reported job failures from build [28445](https://travis-ci.com/broadinstitute/gatk/builds/141951149); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [28445.11](https://travis-ci.com/broadinstitute/gatk/jobs/269363611) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.11/tests/test/index.html) |; | integration | openjdk11 | [28445.12](https://travis-ci.com/broadinstitute/gatk/jobs/269363612) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.12/tests/test/index.html) |; | integration | openjdk8 | [28445.2](https://travis-ci.com/broadinstitute/gatk/jobs/269363599) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-568018197
https://github.com/broadinstitute/gatk/pull/5913#issuecomment-568018197:647,Integrability,integrat,integration,647,Travis reported job failures from build [28445](https://travis-ci.com/broadinstitute/gatk/builds/141951149); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [28445.11](https://travis-ci.com/broadinstitute/gatk/jobs/269363611) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.11/tests/test/index.html) |; | integration | openjdk11 | [28445.12](https://travis-ci.com/broadinstitute/gatk/jobs/269363612) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.12/tests/test/index.html) |; | integration | openjdk8 | [28445.2](https://travis-ci.com/broadinstitute/gatk/jobs/269363599) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-568018197
https://github.com/broadinstitute/gatk/pull/5913#issuecomment-568018197:144,Testability,Test,Test,144,Travis reported job failures from build [28445](https://travis-ci.com/broadinstitute/gatk/builds/141951149); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [28445.11](https://travis-ci.com/broadinstitute/gatk/jobs/269363611) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.11/tests/test/index.html) |; | integration | openjdk11 | [28445.12](https://travis-ci.com/broadinstitute/gatk/jobs/269363612) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.12/tests/test/index.html) |; | integration | openjdk8 | [28445.2](https://travis-ci.com/broadinstitute/gatk/jobs/269363599) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-568018197
https://github.com/broadinstitute/gatk/pull/5913#issuecomment-568018197:171,Testability,Log,Logs,171,Travis reported job failures from build [28445](https://travis-ci.com/broadinstitute/gatk/builds/141951149); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [28445.11](https://travis-ci.com/broadinstitute/gatk/jobs/269363611) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.11/tests/test/index.html) |; | integration | openjdk11 | [28445.12](https://travis-ci.com/broadinstitute/gatk/jobs/269363612) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.12/tests/test/index.html) |; | integration | openjdk8 | [28445.2](https://travis-ci.com/broadinstitute/gatk/jobs/269363599) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-568018197
https://github.com/broadinstitute/gatk/pull/5913#issuecomment-568018197:317,Testability,log,logs,317,Travis reported job failures from build [28445](https://travis-ci.com/broadinstitute/gatk/builds/141951149); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [28445.11](https://travis-ci.com/broadinstitute/gatk/jobs/269363611) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.11/tests/test/index.html) |; | integration | openjdk11 | [28445.12](https://travis-ci.com/broadinstitute/gatk/jobs/269363612) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.12/tests/test/index.html) |; | integration | openjdk8 | [28445.2](https://travis-ci.com/broadinstitute/gatk/jobs/269363599) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-568018197
https://github.com/broadinstitute/gatk/pull/5913#issuecomment-568018197:365,Testability,test,test-logs,365,Travis reported job failures from build [28445](https://travis-ci.com/broadinstitute/gatk/builds/141951149); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [28445.11](https://travis-ci.com/broadinstitute/gatk/jobs/269363611) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.11/tests/test/index.html) |; | integration | openjdk11 | [28445.12](https://travis-ci.com/broadinstitute/gatk/jobs/269363612) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.12/tests/test/index.html) |; | integration | openjdk8 | [28445.2](https://travis-ci.com/broadinstitute/gatk/jobs/269363599) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-568018197
https://github.com/broadinstitute/gatk/pull/5913#issuecomment-568018197:405,Testability,test,tests,405,Travis reported job failures from build [28445](https://travis-ci.com/broadinstitute/gatk/builds/141951149); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [28445.11](https://travis-ci.com/broadinstitute/gatk/jobs/269363611) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.11/tests/test/index.html) |; | integration | openjdk11 | [28445.12](https://travis-ci.com/broadinstitute/gatk/jobs/269363612) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.12/tests/test/index.html) |; | integration | openjdk8 | [28445.2](https://travis-ci.com/broadinstitute/gatk/jobs/269363599) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-568018197
https://github.com/broadinstitute/gatk/pull/5913#issuecomment-568018197:411,Testability,test,test,411,Travis reported job failures from build [28445](https://travis-ci.com/broadinstitute/gatk/builds/141951149); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [28445.11](https://travis-ci.com/broadinstitute/gatk/jobs/269363611) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.11/tests/test/index.html) |; | integration | openjdk11 | [28445.12](https://travis-ci.com/broadinstitute/gatk/jobs/269363612) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.12/tests/test/index.html) |; | integration | openjdk8 | [28445.2](https://travis-ci.com/broadinstitute/gatk/jobs/269363599) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-568018197
https://github.com/broadinstitute/gatk/pull/5913#issuecomment-568018197:531,Testability,log,logs,531,Travis reported job failures from build [28445](https://travis-ci.com/broadinstitute/gatk/builds/141951149); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [28445.11](https://travis-ci.com/broadinstitute/gatk/jobs/269363611) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.11/tests/test/index.html) |; | integration | openjdk11 | [28445.12](https://travis-ci.com/broadinstitute/gatk/jobs/269363612) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.12/tests/test/index.html) |; | integration | openjdk8 | [28445.2](https://travis-ci.com/broadinstitute/gatk/jobs/269363599) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-568018197
https://github.com/broadinstitute/gatk/pull/5913#issuecomment-568018197:579,Testability,test,test-logs,579,Travis reported job failures from build [28445](https://travis-ci.com/broadinstitute/gatk/builds/141951149); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [28445.11](https://travis-ci.com/broadinstitute/gatk/jobs/269363611) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.11/tests/test/index.html) |; | integration | openjdk11 | [28445.12](https://travis-ci.com/broadinstitute/gatk/jobs/269363612) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.12/tests/test/index.html) |; | integration | openjdk8 | [28445.2](https://travis-ci.com/broadinstitute/gatk/jobs/269363599) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-568018197
https://github.com/broadinstitute/gatk/pull/5913#issuecomment-568018197:619,Testability,test,tests,619,Travis reported job failures from build [28445](https://travis-ci.com/broadinstitute/gatk/builds/141951149); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [28445.11](https://travis-ci.com/broadinstitute/gatk/jobs/269363611) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.11/tests/test/index.html) |; | integration | openjdk11 | [28445.12](https://travis-ci.com/broadinstitute/gatk/jobs/269363612) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.12/tests/test/index.html) |; | integration | openjdk8 | [28445.2](https://travis-ci.com/broadinstitute/gatk/jobs/269363599) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-568018197
https://github.com/broadinstitute/gatk/pull/5913#issuecomment-568018197:625,Testability,test,test,625,Travis reported job failures from build [28445](https://travis-ci.com/broadinstitute/gatk/builds/141951149); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [28445.11](https://travis-ci.com/broadinstitute/gatk/jobs/269363611) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.11/tests/test/index.html) |; | integration | openjdk11 | [28445.12](https://travis-ci.com/broadinstitute/gatk/jobs/269363612) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.12/tests/test/index.html) |; | integration | openjdk8 | [28445.2](https://travis-ci.com/broadinstitute/gatk/jobs/269363599) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-568018197
https://github.com/broadinstitute/gatk/pull/5913#issuecomment-568018197:743,Testability,log,logs,743,Travis reported job failures from build [28445](https://travis-ci.com/broadinstitute/gatk/builds/141951149); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [28445.11](https://travis-ci.com/broadinstitute/gatk/jobs/269363611) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.11/tests/test/index.html) |; | integration | openjdk11 | [28445.12](https://travis-ci.com/broadinstitute/gatk/jobs/269363612) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.12/tests/test/index.html) |; | integration | openjdk8 | [28445.2](https://travis-ci.com/broadinstitute/gatk/jobs/269363599) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-568018197
https://github.com/broadinstitute/gatk/pull/5913#issuecomment-568018197:791,Testability,test,test-logs,791,Travis reported job failures from build [28445](https://travis-ci.com/broadinstitute/gatk/builds/141951149); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [28445.11](https://travis-ci.com/broadinstitute/gatk/jobs/269363611) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.11/tests/test/index.html) |; | integration | openjdk11 | [28445.12](https://travis-ci.com/broadinstitute/gatk/jobs/269363612) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.12/tests/test/index.html) |; | integration | openjdk8 | [28445.2](https://travis-ci.com/broadinstitute/gatk/jobs/269363599) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-568018197
https://github.com/broadinstitute/gatk/pull/5913#issuecomment-568018197:830,Testability,test,tests,830,Travis reported job failures from build [28445](https://travis-ci.com/broadinstitute/gatk/builds/141951149); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [28445.11](https://travis-ci.com/broadinstitute/gatk/jobs/269363611) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.11/tests/test/index.html) |; | integration | openjdk11 | [28445.12](https://travis-ci.com/broadinstitute/gatk/jobs/269363612) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.12/tests/test/index.html) |; | integration | openjdk8 | [28445.2](https://travis-ci.com/broadinstitute/gatk/jobs/269363599) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-568018197
https://github.com/broadinstitute/gatk/pull/5913#issuecomment-568018197:836,Testability,test,test,836,Travis reported job failures from build [28445](https://travis-ci.com/broadinstitute/gatk/builds/141951149); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | integration | oraclejdk8 | [28445.11](https://travis-ci.com/broadinstitute/gatk/jobs/269363611) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.11/tests/test/index.html) |; | integration | openjdk11 | [28445.12](https://travis-ci.com/broadinstitute/gatk/jobs/269363612) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.12/tests/test/index.html) |; | integration | openjdk8 | [28445.2](https://travis-ci.com/broadinstitute/gatk/jobs/269363599) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_28445.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-568018197
https://github.com/broadinstitute/gatk/pull/5913#issuecomment-601285399:211,Energy Efficiency,green,green,211,"@jamesemery How close is this to being merged? Once you've addressed all review comments to your satisfaction and have rebased to resolve the conflicts, let me know and I can give final approval after tests are green.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-601285399
https://github.com/broadinstitute/gatk/pull/5913#issuecomment-601285399:201,Testability,test,tests,201,"@jamesemery How close is this to being merged? Once you've addressed all review comments to your satisfaction and have rebased to resolve the conflicts, let me know and I can give final approval after tests are green.",MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-601285399
https://github.com/broadinstitute/gatk/pull/5913#issuecomment-601384268:20,Availability,failure,failures,20,Travis reported job failures from build [29604](https://travis-ci.com/broadinstitute/gatk/builds/154146351); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [29604.14](https://travis-ci.com/broadinstitute/gatk/jobs/300039008) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29604.14/tests/test/index.html) |; | integration | oraclejdk8 | [29604.12](https://travis-ci.com/broadinstitute/gatk/jobs/300039006) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29604.12/tests/test/index.html) |; | integration | openjdk11 | [29604.13](https://travis-ci.com/broadinstitute/gatk/jobs/300039007) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29604.13/tests/test/index.html) |; | integration | openjdk8 | [29604.2](https://travis-ci.com/broadinstitute/gatk/jobs/300038996) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29604.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-601384268
https://github.com/broadinstitute/gatk/pull/5913#issuecomment-601384268:109,Availability,Failure,Failures,109,Travis reported job failures from build [29604](https://travis-ci.com/broadinstitute/gatk/builds/154146351); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [29604.14](https://travis-ci.com/broadinstitute/gatk/jobs/300039008) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29604.14/tests/test/index.html) |; | integration | oraclejdk8 | [29604.12](https://travis-ci.com/broadinstitute/gatk/jobs/300039006) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29604.12/tests/test/index.html) |; | integration | openjdk11 | [29604.13](https://travis-ci.com/broadinstitute/gatk/jobs/300039007) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29604.13/tests/test/index.html) |; | integration | openjdk8 | [29604.2](https://travis-ci.com/broadinstitute/gatk/jobs/300038996) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29604.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-601384268
https://github.com/broadinstitute/gatk/pull/5913#issuecomment-601384268:425,Deployability,integrat,integration,425,Travis reported job failures from build [29604](https://travis-ci.com/broadinstitute/gatk/builds/154146351); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [29604.14](https://travis-ci.com/broadinstitute/gatk/jobs/300039008) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29604.14/tests/test/index.html) |; | integration | oraclejdk8 | [29604.12](https://travis-ci.com/broadinstitute/gatk/jobs/300039006) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29604.12/tests/test/index.html) |; | integration | openjdk11 | [29604.13](https://travis-ci.com/broadinstitute/gatk/jobs/300039007) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29604.13/tests/test/index.html) |; | integration | openjdk8 | [29604.2](https://travis-ci.com/broadinstitute/gatk/jobs/300038996) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29604.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-601384268
https://github.com/broadinstitute/gatk/pull/5913#issuecomment-601384268:640,Deployability,integrat,integration,640,Travis reported job failures from build [29604](https://travis-ci.com/broadinstitute/gatk/builds/154146351); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [29604.14](https://travis-ci.com/broadinstitute/gatk/jobs/300039008) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29604.14/tests/test/index.html) |; | integration | oraclejdk8 | [29604.12](https://travis-ci.com/broadinstitute/gatk/jobs/300039006) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29604.12/tests/test/index.html) |; | integration | openjdk11 | [29604.13](https://travis-ci.com/broadinstitute/gatk/jobs/300039007) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29604.13/tests/test/index.html) |; | integration | openjdk8 | [29604.2](https://travis-ci.com/broadinstitute/gatk/jobs/300038996) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29604.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-601384268
https://github.com/broadinstitute/gatk/pull/5913#issuecomment-601384268:854,Deployability,integrat,integration,854,Travis reported job failures from build [29604](https://travis-ci.com/broadinstitute/gatk/builds/154146351); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [29604.14](https://travis-ci.com/broadinstitute/gatk/jobs/300039008) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29604.14/tests/test/index.html) |; | integration | oraclejdk8 | [29604.12](https://travis-ci.com/broadinstitute/gatk/jobs/300039006) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29604.12/tests/test/index.html) |; | integration | openjdk11 | [29604.13](https://travis-ci.com/broadinstitute/gatk/jobs/300039007) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29604.13/tests/test/index.html) |; | integration | openjdk8 | [29604.2](https://travis-ci.com/broadinstitute/gatk/jobs/300038996) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29604.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-601384268
https://github.com/broadinstitute/gatk/pull/5913#issuecomment-601384268:425,Integrability,integrat,integration,425,Travis reported job failures from build [29604](https://travis-ci.com/broadinstitute/gatk/builds/154146351); Failures in the following jobs:. | Test Type | JDK | Job ID | Logs |; | --------- |---- | ------ | ---- |; | unit | openjdk11 | [29604.14](https://travis-ci.com/broadinstitute/gatk/jobs/300039008) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29604.14/tests/test/index.html) |; | integration | oraclejdk8 | [29604.12](https://travis-ci.com/broadinstitute/gatk/jobs/300039006) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29604.12/tests/test/index.html) |; | integration | openjdk11 | [29604.13](https://travis-ci.com/broadinstitute/gatk/jobs/300039007) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29604.13/tests/test/index.html) |; | integration | openjdk8 | [29604.2](https://travis-ci.com/broadinstitute/gatk/jobs/300038996) | [logs](https://storage.googleapis.com/hellbender-test-logs/build_reports/master_29604.2/tests/test/index.html) |,MatchSource.ISSUE_COMMENT,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/5913#issuecomment-601384268
